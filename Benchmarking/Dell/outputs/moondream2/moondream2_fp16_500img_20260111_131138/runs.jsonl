{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 714.818, "latencies_ms": [714.818], "images_per_second": 1.399, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A woman is standing at the dining table, preparing food in a cozy living room with yellow walls, a wooden floor, and a green accent wall.", "error": null, "sys_before": {"cpu_percent": 1.8, "ram_used_mb": 12988.7, "ram_available_mb": 109517.6, "ram_percent": 10.6}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 12988.7, "ram_available_mb": 109517.6, "ram_percent": 10.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4418.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.55, 40.55, 40.55, 50.92, 50.92, 50.92, 50.92, 50.92], "power_watts_avg": 47.03, "power_watts_peak": 50.92, "energy_joules_est": 33.63, "sample_count": 8, "duration_seconds": 0.715}, "timestamp": "2026-01-11T13:12:13.670128"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1603.042, "latencies_ms": [1603.042], "images_per_second": 0.624, "prompt_tokens": 21, "response_tokens_est": 52, "n_tiles": 1, "output_text": "TV: 1\nCabinet: 2\nRadiator: 1\nChair: 4\nDining table: 2\nWoman: 1\nFlowers: 2\nVase: 1\nFireplace: 1\nRug: 1\nTable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12988.8, "ram_available_mb": 109517.5, "ram_percent": 10.6}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 12988.0, "ram_available_mb": 109518.3, "ram_percent": 10.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4418.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.78, 40.78, 40.78, 40.78, 39.3, 39.3, 39.3, 39.3, 39.3, 38.17, 38.17, 38.17, 38.17, 38.17, 30.7, 30.7], "power_watts_avg": 38.24, "power_watts_peak": 40.78, "energy_joules_est": 61.32, "sample_count": 16, "duration_seconds": 1.604}, "timestamp": "2026-01-11T13:12:15.331692"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 978.383, "latencies_ms": [978.383], "images_per_second": 1.022, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The living room is positioned to the left of the dining area. The dining area is located in the background, separated by a small gap. The living room and dining area are separated by a small gap, further emphasizing the spatial relationship.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12988.0, "ram_available_mb": 109518.3, "ram_percent": 10.6}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 12988.6, "ram_available_mb": 109517.7, "ram_percent": 10.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4418.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [30.7, 30.7, 30.7, 40.8, 40.8, 40.8, 40.8, 40.8, 40.52, 40.52], "power_watts_avg": 37.71, "power_watts_peak": 40.8, "energy_joules_est": 36.91, "sample_count": 10, "duration_seconds": 0.979}, "timestamp": "2026-01-11T13:12:16.340989"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1472.992, "latencies_ms": [1472.992], "images_per_second": 0.679, "prompt_tokens": 19, "response_tokens_est": 80, "n_tiles": 1, "output_text": "The scene depicts a modern, open-plan living space with a dining area, kitchen, and living room. The living area features a flat-screen TV, wooden furniture, and warm lighting. A woman is standing at the dining table, seemingly engaged in conversation or preparing to eat. The room is decorated with potted plants, vases, and a fireplace, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12988.6, "ram_available_mb": 109517.7, "ram_percent": 10.6}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 12988.6, "ram_available_mb": 109517.7, "ram_percent": 10.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4418.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [40.52, 40.52, 40.52, 40.72, 40.72, 40.72, 40.72, 40.72, 40.12, 40.12, 40.12, 40.12, 40.12, 30.53, 30.53], "power_watts_avg": 39.12, "power_watts_peak": 40.72, "energy_joules_est": 57.64, "sample_count": 15, "duration_seconds": 1.473}, "timestamp": "2026-01-11T13:12:17.852001"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 781.935, "latencies_ms": [781.935], "images_per_second": 1.279, "prompt_tokens": 18, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The room features warm yellow walls and rich hardwood flooring. Natural light streams in through multiple windows, creating a bright and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12988.6, "ram_available_mb": 109517.7, "ram_percent": 10.6}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 12989.2, "ram_available_mb": 109517.1, "ram_percent": 10.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4418.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [30.53, 30.53, 30.53, 39.52, 39.52, 39.52, 39.52, 39.52], "power_watts_avg": 36.15, "power_watts_peak": 39.52, "energy_joules_est": 28.28, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-11T13:12:18.659943"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 619.663, "latencies_ms": [619.663], "images_per_second": 1.614, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A brown bear sits in a grassy area, gazing directly at the camera with a calm and curious expression.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12989.2, "ram_available_mb": 109517.1, "ram_percent": 10.6}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13116.1, "ram_available_mb": 109390.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.77, 39.77, 39.77, 39.77, 39.77, 41.73, 41.73], "power_watts_avg": 40.33, "power_watts_peak": 41.73, "energy_joules_est": 25.02, "sample_count": 7, "duration_seconds": 0.62}, "timestamp": "2026-01-11T13:12:19.371515"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1022.075, "latencies_ms": [1022.075], "images_per_second": 0.978, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "bear: 1\ngrass: 2\nfur: 2\nface: 2\nears: 2\nnose: 1\nmouth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13116.1, "ram_available_mb": 109390.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13116.7, "ram_available_mb": 109389.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [41.73, 41.73, 48.27, 48.27, 48.27, 48.27, 48.27, 40.27, 40.27, 40.27, 40.27], "power_watts_avg": 44.17, "power_watts_peak": 48.27, "energy_joules_est": 45.16, "sample_count": 11, "duration_seconds": 1.022}, "timestamp": "2026-01-11T13:12:20.481283"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 498.483, "latencies_ms": [498.483], "images_per_second": 2.006, "prompt_tokens": 25, "response_tokens_est": 17, "n_tiles": 1, "output_text": "The bear is positioned in the foreground, with the grassy background extending behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13116.7, "ram_available_mb": 109389.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13116.7, "ram_available_mb": 109389.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 14.0}, "power_stats": {"power_watts_samples": [40.27, 35.07, 35.07, 35.07, 35.07], "power_watts_avg": 36.11, "power_watts_peak": 40.27, "energy_joules_est": 18.01, "sample_count": 5, "duration_seconds": 0.499}, "timestamp": "2026-01-11T13:12:20.988400"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 726.371, "latencies_ms": [726.371], "images_per_second": 1.377, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A large brown bear is sitting on lush green grass, gazing directly at the camera. The scene appears to be in a natural, outdoor environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13116.7, "ram_available_mb": 109389.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13117.4, "ram_available_mb": 109388.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.07, 43.38, 43.38, 43.38, 43.38, 43.38, 50.11, 50.11], "power_watts_avg": 44.02, "power_watts_peak": 50.11, "energy_joules_est": 31.99, "sample_count": 8, "duration_seconds": 0.727}, "timestamp": "2026-01-11T13:12:21.795319"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1016.941, "latencies_ms": [1016.941], "images_per_second": 0.983, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The bear's fur is a light brown color. The lighting appears to be natural, possibly sunlight, giving the bear a warm and alert appearance. The bear is situated in a grassy area, suggesting it might be in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13117.4, "ram_available_mb": 109388.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13114.5, "ram_available_mb": 109391.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [50.11, 50.11, 50.11, 49.17, 49.17, 49.17, 49.17, 49.17, 40.75, 40.75, 40.75], "power_watts_avg": 47.13, "power_watts_peak": 50.11, "energy_joules_est": 47.94, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-11T13:12:22.905234"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 800.346, "latencies_ms": [800.346], "images_per_second": 1.249, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The room features a comfortable blue-comforter bed, wooden dresser with mirror, bookshelf, and potted plants, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13114.5, "ram_available_mb": 109391.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13114.5, "ram_available_mb": 109391.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.75, 40.75, 36.3, 36.3, 36.3, 36.3, 36.3, 38.85], "power_watts_avg": 37.73, "power_watts_peak": 40.75, "energy_joules_est": 30.21, "sample_count": 8, "duration_seconds": 0.801}, "timestamp": "2026-01-11T13:12:23.715456"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1276.231, "latencies_ms": [1276.231], "images_per_second": 0.784, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bed: 1\ndresser: 2\nmirror: 1\nchair: 1\nbookshelf: 5\nplant: 2\nwicker basket: 1\ncarpet: 1\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13114.5, "ram_available_mb": 109391.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13114.0, "ram_available_mb": 109392.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.85, 38.85, 38.85, 38.85, 43.51, 43.51, 43.51, 43.51, 43.51, 41.07, 41.07, 41.07, 41.07], "power_watts_avg": 41.32, "power_watts_peak": 43.51, "energy_joules_est": 52.77, "sample_count": 13, "duration_seconds": 1.277}, "timestamp": "2026-01-11T13:12:25.025227"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 929.305, "latencies_ms": [929.305], "images_per_second": 1.076, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned to the left of the image. The bookshelf is located in the background, extending from left to right. The window is situated in the background, offering a view of the greenery outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13114.0, "ram_available_mb": 109392.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13113.7, "ram_available_mb": 109392.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.07, 31.54, 31.54, 31.54, 31.54, 31.54, 40.3, 40.3, 40.3, 40.3], "power_watts_avg": 35.99, "power_watts_peak": 41.07, "energy_joules_est": 33.45, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-11T13:12:26.033021"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1013.693, "latencies_ms": [1013.693], "images_per_second": 0.986, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a cozy bedroom with a large window offering a view of lush greenery outside. The room features a comfortable bed, a wooden dresser, a bookshelf filled with books, and various decorative elements like potted plants and a wicker basket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13113.7, "ram_available_mb": 109392.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13113.0, "ram_available_mb": 109393.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.3, 39.84, 39.84, 39.84, 39.84, 39.84, 39.67, 39.67, 39.67, 39.67, 39.67], "power_watts_avg": 39.81, "power_watts_peak": 40.3, "energy_joules_est": 40.38, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-11T13:12:27.144064"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 969.64, "latencies_ms": [969.64], "images_per_second": 1.031, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The room features a blue comforter, a wooden dresser with a mirror, and a large window that lets in natural light. The walls are covered in floral wallpaper, and the carpet is light-colored.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13113.0, "ram_available_mb": 109393.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13113.0, "ram_available_mb": 109393.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.87, 40.87, 40.87, 40.87, 40.87, 39.13, 39.13, 39.13, 39.13, 39.13], "power_watts_avg": 40.0, "power_watts_peak": 40.87, "energy_joules_est": 38.81, "sample_count": 10, "duration_seconds": 0.97}, "timestamp": "2026-01-11T13:12:28.156448"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 534.869, "latencies_ms": [534.869], "images_per_second": 1.87, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A red stop sign is mounted on a metal pole at the corner of a street, with a white building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13113.0, "ram_available_mb": 109393.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13112.9, "ram_available_mb": 109393.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [39.63, 39.63, 39.63, 39.63, 39.63, 35.13], "power_watts_avg": 38.88, "power_watts_peak": 39.63, "energy_joules_est": 20.81, "sample_count": 6, "duration_seconds": 0.535}, "timestamp": "2026-01-11T13:12:28.765801"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1122.693, "latencies_ms": [1122.693], "images_per_second": 0.891, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "stop sign: 1\npole: 1\ntrailer: 1\ntruck: 1\ntrailer: 1\ntraffic light: 1\ntrees: 4\nshrubs: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13112.9, "ram_available_mb": 109393.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13111.8, "ram_available_mb": 109394.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.13, 35.13, 35.13, 35.13, 38.66, 38.66, 38.66, 38.66, 38.66, 34.5, 34.5, 34.5], "power_watts_avg": 36.44, "power_watts_peak": 38.66, "energy_joules_est": 40.92, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:12:29.975566"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 842.053, "latencies_ms": [842.053], "images_per_second": 1.188, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The stop sign is positioned in the foreground, slightly to the right of the image. The background features trees, a building, and a parked vehicle. The stop sign is situated near the center of the image, slightly to the right of the center.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13111.8, "ram_available_mb": 109394.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 13115.1, "ram_available_mb": 109391.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.5, 33.28, 33.28, 33.28, 33.28, 33.28, 34.44, 34.44, 34.44], "power_watts_avg": 33.8, "power_watts_peak": 34.5, "energy_joules_est": 28.48, "sample_count": 9, "duration_seconds": 0.842}, "timestamp": "2026-01-11T13:12:30.885144"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 683.474, "latencies_ms": [683.474], "images_per_second": 1.463, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts a stop sign at an intersection, with trees, shrubs, and a building in the background. A piece of construction equipment is visible near the stop sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13115.1, "ram_available_mb": 109391.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 13116.3, "ram_available_mb": 109390.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [34.44, 34.44, 35.61, 35.61, 35.61, 35.61, 35.61], "power_watts_avg": 35.27, "power_watts_peak": 35.61, "energy_joules_est": 24.12, "sample_count": 7, "duration_seconds": 0.684}, "timestamp": "2026-01-11T13:12:31.591860"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 518.928, "latencies_ms": [518.928], "images_per_second": 1.927, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The stop sign is red and white. The lighting appears to be natural daylight. The stop sign appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13116.3, "ram_available_mb": 109390.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13115.5, "ram_available_mb": 109390.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [34.09, 34.09, 34.09, 34.09, 34.09, 34.92], "power_watts_avg": 34.23, "power_watts_peak": 34.92, "energy_joules_est": 17.78, "sample_count": 6, "duration_seconds": 0.519}, "timestamp": "2026-01-11T13:12:32.198353"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 942.377, "latencies_ms": [942.377], "images_per_second": 1.061, "prompt_tokens": 8, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Three teddy bears are nestled together, with one brown bear resting its head on the shoulder of another brown bear, while a third brown bear lies down with its head resting on the shoulder of the third bear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13115.5, "ram_available_mb": 109390.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13114.5, "ram_available_mb": 109391.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 34.92, 43.83, 43.83, 43.83, 43.83, 43.83, 39.42], "power_watts_avg": 39.83, "power_watts_peak": 43.83, "energy_joules_est": 37.55, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-11T13:12:33.207280"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1588.896, "latencies_ms": [1588.896], "images_per_second": 0.629, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Teddy bear: 3\nTeddy bear: 2\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13114.5, "ram_available_mb": 109391.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13113.2, "ram_available_mb": 109393.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [39.42, 39.42, 39.42, 39.42, 39.8, 39.8, 39.8, 39.8, 39.8, 39.58, 39.58, 39.58, 39.58, 39.58, 30.89, 30.89], "power_watts_avg": 38.52, "power_watts_peak": 39.8, "energy_joules_est": 61.23, "sample_count": 16, "duration_seconds": 1.589}, "timestamp": "2026-01-11T13:12:34.817353"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 888.096, "latencies_ms": [888.096], "images_per_second": 1.126, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, creating a sense of proximity and closeness. The teddy bears are situated in the background, slightly out of focus, contributing to the overall composition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13113.2, "ram_available_mb": 109393.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13114.9, "ram_available_mb": 109391.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [30.89, 30.89, 30.89, 40.75, 40.75, 40.75, 40.75, 40.75, 40.45], "power_watts_avg": 37.43, "power_watts_peak": 40.75, "energy_joules_est": 33.26, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:12:35.726108"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 782.941, "latencies_ms": [782.941], "images_per_second": 1.277, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Three teddy bears are cuddled together on a surface, possibly a bed or couch. The scene suggests a cozy and warm environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13114.9, "ram_available_mb": 109391.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13113.1, "ram_available_mb": 109393.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.45, 40.45, 40.45, 40.45, 40.49, 40.49, 40.49, 40.49], "power_watts_avg": 40.47, "power_watts_peak": 40.49, "energy_joules_est": 31.71, "sample_count": 8, "duration_seconds": 0.783}, "timestamp": "2026-01-11T13:12:36.535494"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 870.859, "latencies_ms": [870.859], "images_per_second": 1.148, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The teddy bears are brown and appear to be made of a soft, plush material. The lighting in the image is soft and warm, enhancing the cozy atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13113.1, "ram_available_mb": 109393.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13111.0, "ram_available_mb": 109395.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.49, 40.53, 40.53, 40.53, 40.53, 40.53, 40.35, 40.35, 40.35], "power_watts_avg": 40.47, "power_watts_peak": 40.53, "energy_joules_est": 35.25, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:12:37.443243"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 687.073, "latencies_ms": [687.073], "images_per_second": 1.455, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a red ski jacket and black pants is skiing down a snowy slope, leaning forward and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13111.0, "ram_available_mb": 109395.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13110.0, "ram_available_mb": 109396.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 45.0}, "power_stats": {"power_watts_samples": [40.35, 40.35, 45.47, 45.47, 45.47, 45.47, 45.47], "power_watts_avg": 44.0, "power_watts_peak": 45.47, "energy_joules_est": 30.25, "sample_count": 7, "duration_seconds": 0.687}, "timestamp": "2026-01-11T13:12:38.151222"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1327.721, "latencies_ms": [1327.721], "images_per_second": 0.753, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "woman: 1\nskis: 2\nsnow: 2\ngloves: 2\nhat: 1\nsunglasses: 1\nski poles: 2\nskis: 2\nbib: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13110.0, "ram_available_mb": 109396.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13102.9, "ram_available_mb": 109403.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.45, 40.45, 40.45, 40.45, 40.45, 46.46, 46.46, 46.46, 46.46, 46.46, 40.94, 40.94, 40.94, 40.94], "power_watts_avg": 42.73, "power_watts_peak": 46.46, "energy_joules_est": 56.75, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-11T13:12:39.563801"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1078.068, "latencies_ms": [1078.068], "images_per_second": 0.928, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The skier is positioned in the foreground of the image, facing the camera. The snowy slope and ski poles are in the background, extending from the foreground towards the background. The skier is relatively close to the viewer, suggesting they are in close proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13102.9, "ram_available_mb": 109403.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13102.1, "ram_available_mb": 109404.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.94, 29.86, 29.86, 29.86, 29.86, 29.86, 39.75, 39.75, 39.75, 39.75, 39.75], "power_watts_avg": 35.36, "power_watts_peak": 40.94, "energy_joules_est": 38.14, "sample_count": 11, "duration_seconds": 1.079}, "timestamp": "2026-01-11T13:12:40.674347"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 889.899, "latencies_ms": [889.899], "images_per_second": 1.124, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A woman is skiing down a snowy slope, wearing a red jacket, black pants, and a striped hat. Red poles and markers are visible in the background, indicating a designated ski area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13102.1, "ram_available_mb": 109404.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13101.1, "ram_available_mb": 109405.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.48, 40.48, 40.48, 40.48, 40.63, 40.63, 40.63, 40.63, 40.63], "power_watts_avg": 40.57, "power_watts_peak": 40.63, "energy_joules_est": 36.12, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:12:41.584089"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1103.997, "latencies_ms": [1103.997], "images_per_second": 0.906, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The skier is wearing a red and white jacket, blue ski boots, and sunglasses. The lighting is bright and clear, indicating a sunny day. The snow appears to be well-groomed, and the overall scene suggests a pleasant skiing experience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13101.1, "ram_available_mb": 109405.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13099.6, "ram_available_mb": 109406.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.51, 40.51, 40.51, 40.51, 40.51, 40.4, 40.4, 40.4, 40.4, 40.4, 40.65], "power_watts_avg": 40.47, "power_watts_peak": 40.65, "energy_joules_est": 44.7, "sample_count": 11, "duration_seconds": 1.105}, "timestamp": "2026-01-11T13:12:42.693826"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 616.441, "latencies_ms": [616.441], "images_per_second": 1.622, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A white refrigerator stands next to a wooden cabinet in a kitchen with a white stove and beige tiled floor.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13099.6, "ram_available_mb": 109406.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13099.6, "ram_available_mb": 109406.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.65, 40.65, 40.65, 40.65, 40.91, 40.91, 40.91], "power_watts_avg": 40.76, "power_watts_peak": 40.91, "energy_joules_est": 25.15, "sample_count": 7, "duration_seconds": 0.617}, "timestamp": "2026-01-11T13:12:43.404049"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1275.272, "latencies_ms": [1275.272], "images_per_second": 0.784, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "oven: 2\nstove: 1\nrange hood: 1\ncabinets: 4\nrefrigerator: 1\ncountertop: 1\ndrawers: 3\ntile floor: 8", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13099.6, "ram_available_mb": 109406.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.91, 40.91, 46.39, 46.39, 46.39, 46.39, 46.39, 39.49, 39.49, 39.49, 39.49, 39.49, 34.5], "power_watts_avg": 41.98, "power_watts_peak": 46.39, "energy_joules_est": 53.55, "sample_count": 13, "duration_seconds": 1.276}, "timestamp": "2026-01-11T13:12:44.711759"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 841.348, "latencies_ms": [841.348], "images_per_second": 1.189, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close and centered arrangement. The stove is located to the left of the refrigerator, and the cabinets are situated above and slightly behind the stove and refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.5, 34.5, 34.5, 34.5, 40.74, 40.74, 40.74, 40.74, 40.74], "power_watts_avg": 37.97, "power_watts_peak": 40.74, "energy_joules_est": 31.96, "sample_count": 9, "duration_seconds": 0.842}, "timestamp": "2026-01-11T13:12:45.619531"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 867.726, "latencies_ms": [867.726], "images_per_second": 1.152, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The kitchen features a white stove, oven, and refrigerator, complemented by light brown wooden cabinets. The scene suggests a clean, well-maintained space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.42, 40.42, 40.42, 40.42, 40.42, 39.4, 39.4, 39.4, 39.4], "power_watts_avg": 39.97, "power_watts_peak": 40.42, "energy_joules_est": 34.7, "sample_count": 9, "duration_seconds": 0.868}, "timestamp": "2026-01-11T13:12:46.530385"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 775.1, "latencies_ms": [775.1], "images_per_second": 1.29, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The kitchen features light brown wooden cabinets and light beige tile flooring. The lighting is soft and evenly distributed, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.8, "ram_available_mb": 109408.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.4, 39.52, 39.52, 39.52, 39.52, 39.52, 40.45, 40.45], "power_watts_avg": 39.73, "power_watts_peak": 40.45, "energy_joules_est": 30.81, "sample_count": 8, "duration_seconds": 0.776}, "timestamp": "2026-01-11T13:12:47.338698"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 676.97, "latencies_ms": [676.97], "images_per_second": 1.477, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Two baseball players are running on a field, one in a white uniform and the other in a green uniform, attempting to catch the ball.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13097.8, "ram_available_mb": 109408.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13097.8, "ram_available_mb": 109408.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [40.45, 40.45, 40.45, 50.74, 50.74, 50.74, 50.74], "power_watts_avg": 46.33, "power_watts_peak": 50.74, "energy_joules_est": 31.4, "sample_count": 7, "duration_seconds": 0.678}, "timestamp": "2026-01-11T13:12:48.051692"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1716.625, "latencies_ms": [1716.625], "images_per_second": 0.583, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "baseball glove: 1\nbaseball helmet: 1\nbaseball uniform: 2\nbaseball pants: 2\nbaseball cleats: 2\nbaseball field: 2\nbaseball bat: 1\nbaseball mitt: 1\ngrass: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.8, "ram_available_mb": 109408.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [50.74, 40.88, 40.88, 40.88, 40.88, 40.88, 43.12, 43.12, 43.12, 43.12, 43.12, 42.29, 42.29, 42.29, 42.29, 42.29, 31.02, 31.02], "power_watts_avg": 41.34, "power_watts_peak": 50.74, "energy_joules_est": 70.99, "sample_count": 18, "duration_seconds": 1.717}, "timestamp": "2026-01-11T13:12:49.869304"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 820.47, "latencies_ms": [820.47], "images_per_second": 1.219, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the player running towards the right. The background features the grassy field and trees, creating a natural setting for the baseball game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [31.02, 31.02, 31.02, 37.67, 37.67, 37.67, 37.67, 37.67, 40.18], "power_watts_avg": 35.73, "power_watts_peak": 40.18, "energy_joules_est": 29.34, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:12:50.780901"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 835.979, "latencies_ms": [835.979], "images_per_second": 1.196, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two baseball players are running on a baseball field. One player is wearing a white uniform and helmet, while the other player is wearing a green uniform and cap.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.18, 40.18, 40.18, 43.27, 43.27, 43.27, 43.27, 43.27, 40.58], "power_watts_avg": 41.94, "power_watts_peak": 43.27, "energy_joules_est": 35.07, "sample_count": 9, "duration_seconds": 0.836}, "timestamp": "2026-01-11T13:12:51.692389"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 932.037, "latencies_ms": [932.037], "images_per_second": 1.073, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The players are wearing light gray uniforms. The lighting appears to be natural daylight. The uniforms appear to be made of a durable material, likely cotton or polyester. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.58, 40.58, 40.58, 40.58, 41.01, 41.01, 41.01, 41.01, 41.01, 40.95], "power_watts_avg": 40.83, "power_watts_peak": 41.01, "energy_joules_est": 38.07, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-11T13:12:52.700269"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 813.027, "latencies_ms": [813.027], "images_per_second": 1.23, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A tennis player in white attire is poised to hit a forehand shot on a blue tennis court, with a red and white tennis racket in hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.2, "ram_available_mb": 109407.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13099.3, "ram_available_mb": 109407.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.95, 40.95, 40.95, 40.95, 39.7, 39.7, 39.7, 39.7, 39.7], "power_watts_avg": 40.26, "power_watts_peak": 40.95, "energy_joules_est": 32.76, "sample_count": 9, "duration_seconds": 0.814}, "timestamp": "2026-01-11T13:12:53.611023"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1732.407, "latencies_ms": [1732.407], "images_per_second": 0.577, "prompt_tokens": 21, "response_tokens_est": 60, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis player: 1\nTennis court: 1\nTennis ball return: 1\nTennis ball: 1\nTennis ball: 1\nTennis ball: 1\nTennis player: 1\nTennis player: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.3, "ram_available_mb": 109407.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.28, 39.28, 39.28, 39.28, 39.28, 39.71, 39.71, 39.71, 39.71, 39.71, 40.69, 40.69, 40.69, 40.69, 40.69, 31.48, 31.48, 31.48], "power_watts_avg": 38.49, "power_watts_peak": 40.69, "energy_joules_est": 66.69, "sample_count": 18, "duration_seconds": 1.733}, "timestamp": "2026-01-11T13:12:55.426185"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 875.38, "latencies_ms": [875.38], "images_per_second": 1.142, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, preparing to hit the ball. The ball is in the background, slightly out of focus. The tennis court is visible in the background, extending beyond the player.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 39.0}, "power_stats": {"power_watts_samples": [31.48, 31.48, 36.49, 36.49, 36.49, 36.49, 36.49, 40.2, 40.2], "power_watts_avg": 36.2, "power_watts_peak": 40.2, "energy_joules_est": 31.71, "sample_count": 9, "duration_seconds": 0.876}, "timestamp": "2026-01-11T13:12:56.337269"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1188.803, "latencies_ms": [1188.803], "images_per_second": 0.841, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A tennis player is executing a forehand shot on a blue tennis court, leaning forward and holding a red and white tennis racket. A line judge stands behind the player, observing the match. Spectators are visible in the background, watching the ongoing game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [40.2, 40.2, 40.2, 44.84, 44.84, 44.84, 44.84, 44.84, 40.99, 40.99, 40.99, 40.99], "power_watts_avg": 42.4, "power_watts_peak": 44.84, "energy_joules_est": 50.42, "sample_count": 12, "duration_seconds": 1.189}, "timestamp": "2026-01-11T13:12:57.546182"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 937.782, "latencies_ms": [937.782], "images_per_second": 1.066, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The tennis court is green and appears to be well-lit, likely by sunlight. The tennis racket is orange and appears to be made of metal. The players are wearing white and navy blue attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.99, 31.39, 31.39, 31.39, 31.39, 31.39, 40.74, 40.74, 40.74, 40.74], "power_watts_avg": 36.09, "power_watts_peak": 40.99, "energy_joules_est": 33.86, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-11T13:12:58.558338"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 864.825, "latencies_ms": [864.825], "images_per_second": 1.156, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of young tennis players, including both boys and girls, stand proudly on a blue tennis court, holding their tennis rackets and celebrating a recent victory.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.74, 40.12, 40.12, 40.12, 40.12, 40.12, 39.94, 39.94, 39.94], "power_watts_avg": 40.13, "power_watts_peak": 40.74, "energy_joules_est": 34.73, "sample_count": 9, "duration_seconds": 0.865}, "timestamp": "2026-01-11T13:12:59.469690"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1649.194, "latencies_ms": [1649.194], "images_per_second": 0.606, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "Tennis racket: 2\nTennis ball: 1\nTennis ball bag: 1\nTennis outfit: 8\nTennis shoes: 8\nTennis court: 2\nTennis net: 1\nTennis players: 8\nTrophy: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [39.94, 39.94, 43.99, 43.99, 43.99, 43.99, 43.99, 39.94, 39.94, 39.94, 39.94, 39.94, 38.2, 38.2, 38.2, 38.2, 31.08], "power_watts_avg": 40.2, "power_watts_peak": 43.99, "energy_joules_est": 66.34, "sample_count": 17, "duration_seconds": 1.65}, "timestamp": "2026-01-11T13:13:01.182164"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 817.714, "latencies_ms": [817.714], "images_per_second": 1.223, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned in a line, with the children standing in the foreground and the adults in the background. The tennis court is situated in the background, separated from the children by a fence.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [31.08, 31.08, 31.08, 31.08, 40.0, 40.0, 40.0, 40.0, 40.0], "power_watts_avg": 36.03, "power_watts_peak": 40.0, "energy_joules_est": 29.47, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:13:02.090260"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 919.382, "latencies_ms": [919.382], "images_per_second": 1.088, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A group of young tennis players, including adults and children, pose for a photo on a blue tennis court, celebrating their victory with a trophy. The setting appears to be a sunny outdoor area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.91, 38.91, 38.91, 38.91, 38.91, 39.67, 39.67, 39.67, 39.67, 39.67], "power_watts_avg": 39.29, "power_watts_peak": 39.67, "energy_joules_est": 36.13, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-11T13:13:03.098111"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 904.483, "latencies_ms": [904.483], "images_per_second": 1.106, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The group is wearing bright, colorful clothing. The lighting appears to be natural sunlight, creating a vibrant atmosphere. The tennis court surface is blue, and the overall setting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.8, 39.8, 39.8, 39.8, 39.8, 39.45, 39.45, 39.45, 39.45, 39.45], "power_watts_avg": 39.62, "power_watts_peak": 39.8, "energy_joules_est": 35.86, "sample_count": 10, "duration_seconds": 0.905}, "timestamp": "2026-01-11T13:13:04.107442"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 735.188, "latencies_ms": [735.188], "images_per_second": 1.36, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A couple sits under a bridge, watching a swan glide across the water, while another person captures the moment with a camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.43, 39.43, 39.43, 39.43, 39.43, 39.5, 39.5, 39.5], "power_watts_avg": 39.46, "power_watts_peak": 39.5, "energy_joules_est": 29.03, "sample_count": 8, "duration_seconds": 0.736}, "timestamp": "2026-01-11T13:13:04.917432"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1157.549, "latencies_ms": [1157.549], "images_per_second": 0.864, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "bridge: 4\nswan: 1\nperson: 2\nbag: 1\nperson: 1\nperson: 1\nperson: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.2, "ram_available_mb": 109409.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13095.0, "ram_available_mb": 109411.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.5, 39.5, 46.16, 46.16, 46.16, 46.16, 46.16, 39.15, 39.15, 39.15, 39.15, 39.15], "power_watts_avg": 42.13, "power_watts_peak": 46.16, "energy_joules_est": 48.78, "sample_count": 12, "duration_seconds": 1.158}, "timestamp": "2026-01-11T13:13:06.127182"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1110.483, "latencies_ms": [1110.483], "images_per_second": 0.901, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The swan is positioned near the center of the image, near the water's edge. The river stretches across the background, separating the swan from the people and the bridge. The swan is situated in the foreground, while the river and bridge are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13095.0, "ram_available_mb": 109411.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.73, 33.73, 33.73, 33.73, 33.73, 40.33, 40.33, 40.33, 40.33, 40.33, 40.29, 40.29], "power_watts_avg": 37.57, "power_watts_peak": 40.33, "energy_joules_est": 41.73, "sample_count": 12, "duration_seconds": 1.111}, "timestamp": "2026-01-11T13:13:07.337641"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 838.066, "latencies_ms": [838.066], "images_per_second": 1.193, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene takes place under a bridge over a river, where people are relaxing and observing a swan on the water's edge. The setting is urban, with buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [40.29, 40.29, 40.29, 39.68, 39.68, 39.68, 39.68, 39.68, 39.78], "power_watts_avg": 39.89, "power_watts_peak": 40.29, "energy_joules_est": 33.45, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:13:08.244701"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1000.759, "latencies_ms": [1000.759], "images_per_second": 0.999, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene is bathed in warm sunlight, creating a golden glow on the water and the bridge. The colors are predominantly earth tones, reflecting the natural environment. The lighting suggests it might be late afternoon or early evening.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.78, 39.78, 39.78, 39.78, 40.21, 40.21, 40.21, 40.21, 40.21, 40.3], "power_watts_avg": 40.05, "power_watts_peak": 40.3, "energy_joules_est": 40.09, "sample_count": 10, "duration_seconds": 1.001}, "timestamp": "2026-01-11T13:13:09.254451"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 598.036, "latencies_ms": [598.036], "images_per_second": 1.672, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A young woman is holding a Hello Kitty phone and looking at it, possibly taking a picture or video.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [40.3, 40.3, 40.3, 40.3, 41.19, 41.19], "power_watts_avg": 40.59, "power_watts_peak": 41.19, "energy_joules_est": 24.32, "sample_count": 6, "duration_seconds": 0.599}, "timestamp": "2026-01-11T13:13:09.864237"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1229.521, "latencies_ms": [1229.521], "images_per_second": 0.813, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "phone: 1\nphone case: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13095.1, "ram_available_mb": 109411.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13096.6, "ram_available_mb": 109409.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.19, 41.19, 41.19, 50.78, 50.78, 50.78, 50.78, 50.78, 41.2, 41.2, 41.2, 41.2, 41.2], "power_watts_avg": 44.88, "power_watts_peak": 50.78, "energy_joules_est": 55.21, "sample_count": 13, "duration_seconds": 1.23}, "timestamp": "2026-01-11T13:13:11.175475"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 870.16, "latencies_ms": [870.16], "images_per_second": 1.149, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The Hello Kitty phone is held in the foreground, while the woman is positioned slightly behind and to the right of the phone. The background is blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.6, "ram_available_mb": 109409.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [31.65, 31.65, 31.65, 31.65, 31.65, 39.84, 39.84, 39.84, 39.84], "power_watts_avg": 35.29, "power_watts_peak": 39.84, "energy_joules_est": 30.73, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:13:12.084084"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1213.405, "latencies_ms": [1213.405], "images_per_second": 0.824, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "A woman is holding a Hello Kitty phone and appears to be taking a picture or selfie. She is wearing a white top with a Hello Kitty design and a green beaded bracelet. The setting appears to be an outdoor event or gathering, with other people visible in the blurred background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [39.32, 39.32, 39.32, 39.32, 39.32, 40.62, 40.62, 40.62, 40.62, 40.62, 41.37, 41.37, 41.37], "power_watts_avg": 40.29, "power_watts_peak": 41.37, "energy_joules_est": 48.93, "sample_count": 13, "duration_seconds": 1.214}, "timestamp": "2026-01-11T13:13:13.396915"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1060.464, "latencies_ms": [1060.464], "images_per_second": 0.943, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The woman is wearing a white top with a gray and black pattern. She is holding a white phone with a Hello Kitty case. The lighting appears to be natural, possibly outdoors, and the phone appears to be made of a smooth, plastic-like material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [41.37, 41.37, 37.1, 37.1, 37.1, 37.1, 37.1, 39.21, 39.21, 39.21, 39.21], "power_watts_avg": 38.65, "power_watts_peak": 41.37, "energy_joules_est": 40.99, "sample_count": 11, "duration_seconds": 1.061}, "timestamp": "2026-01-11T13:13:14.507944"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 504.88, "latencies_ms": [504.88], "images_per_second": 1.981, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A group of children are seated in a small, red train-like ride, enjoying a fun and exciting experience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [39.21, 35.04, 35.04, 35.04, 35.04, 35.04], "power_watts_avg": 35.73, "power_watts_peak": 39.21, "energy_joules_est": 18.07, "sample_count": 6, "duration_seconds": 0.506}, "timestamp": "2026-01-11T13:13:15.116606"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 791.01, "latencies_ms": [791.01], "images_per_second": 1.264, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "train: 5\ncarriages: 4\nchildren: 5\nfloor: 6\nwall: 6\nlighting: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.85, 33.85, 33.85, 33.85, 33.85, 37.06, 37.06, 37.06], "power_watts_avg": 35.05, "power_watts_peak": 37.06, "energy_joules_est": 27.74, "sample_count": 8, "duration_seconds": 0.792}, "timestamp": "2026-01-11T13:13:15.926495"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 746.304, "latencies_ms": [746.304], "images_per_second": 1.34, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main object (train car) is positioned in the foreground, closer to the viewer. The train car is situated further back in the scene, near the wall and light fixture.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.06, 37.06, 39.51, 39.51, 39.51, 39.51, 39.51, 35.56], "power_watts_avg": 38.4, "power_watts_peak": 39.51, "energy_joules_est": 28.68, "sample_count": 8, "duration_seconds": 0.747}, "timestamp": "2026-01-11T13:13:16.735441"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 667.634, "latencies_ms": [667.634], "images_per_second": 1.498, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A group of children are riding on a small, red train-like ride in a room with wooden walls. The setting appears to be a children's amusement park or similar recreational venue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.56, 35.56, 35.56, 35.56, 34.99, 34.99, 34.99], "power_watts_avg": 35.32, "power_watts_peak": 35.56, "energy_joules_est": 23.61, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:13:17.443700"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 780.819, "latencies_ms": [780.819], "images_per_second": 1.281, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The train cars are red and appear to be made of plastic or metal. The lighting is warm and creates a cozy atmosphere. The floor appears to be made of a smooth, light-colored material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [34.99, 34.99, 39.38, 39.38, 39.38, 39.38, 39.38, 35.53], "power_watts_avg": 37.8, "power_watts_peak": 39.38, "energy_joules_est": 29.53, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:13:18.252884"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 682.491, "latencies_ms": [682.491], "images_per_second": 1.465, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A black and white close-up shot captures a half-eaten sandwich on a white plate, accompanied by a small white dish containing a sauce.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [35.53, 35.53, 35.53, 35.53, 42.13, 42.13, 42.13], "power_watts_avg": 38.36, "power_watts_peak": 42.13, "energy_joules_est": 26.2, "sample_count": 7, "duration_seconds": 0.683}, "timestamp": "2026-01-11T13:13:18.964065"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1264.983, "latencies_ms": [1264.983], "images_per_second": 0.791, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "sandwich: 2\nbun: 1\ncheese: 1\ncheese spread: 1\nbacon: 1\nmayonnaise: 1\nplate: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13096.9, "ram_available_mb": 109409.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13099.1, "ram_available_mb": 109407.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.13, 42.13, 46.72, 46.72, 46.72, 46.72, 46.72, 41.52, 41.52, 41.52, 41.52, 41.52, 37.99], "power_watts_avg": 43.34, "power_watts_peak": 46.72, "energy_joules_est": 54.84, "sample_count": 13, "duration_seconds": 1.265}, "timestamp": "2026-01-11T13:13:20.276541"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 784.547, "latencies_ms": [784.547], "images_per_second": 1.275, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The sandwich is positioned in the foreground, partially obscuring the background. The small bowl of sauce is situated near the sandwich, closer to the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.1, "ram_available_mb": 109407.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13099.1, "ram_available_mb": 109407.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [37.99, 37.99, 37.99, 37.99, 41.51, 41.51, 41.51, 41.51], "power_watts_avg": 39.75, "power_watts_peak": 41.51, "energy_joules_est": 31.2, "sample_count": 8, "duration_seconds": 0.785}, "timestamp": "2026-01-11T13:13:21.086336"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1010.701, "latencies_ms": [1010.701], "images_per_second": 0.989, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a close-up view of a partially eaten sandwich on a white plate. The sandwich appears to contain chocolate and cream filling. The setting seems to be a casual dining environment, possibly a restaurant or caf\u00e9.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.1, "ram_available_mb": 109407.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.13, 41.13, 41.13, 41.13, 41.13, 42.01, 42.01, 42.01, 42.01, 42.01, 42.43], "power_watts_avg": 41.65, "power_watts_peak": 42.43, "energy_joules_est": 42.1, "sample_count": 11, "duration_seconds": 1.011}, "timestamp": "2026-01-11T13:13:22.198549"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1352.444, "latencies_ms": [1352.444], "images_per_second": 0.739, "prompt_tokens": 18, "response_tokens_est": 69, "n_tiles": 1, "output_text": "The sandwich appears to have a dark-colored filling, possibly chocolate. The lighting is soft and diffused, creating a gentle contrast between the sandwich and the plate. The sandwich is resting on a white plate, which contrasts with the dark filling. The overall image has a monochromatic palette, emphasizing the textures and colors of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [42.43, 42.43, 42.43, 42.43, 40.93, 40.93, 40.93, 40.93, 40.93, 40.88, 40.88, 40.88, 40.88, 40.88], "power_watts_avg": 41.34, "power_watts_peak": 42.43, "energy_joules_est": 55.92, "sample_count": 14, "duration_seconds": 1.353}, "timestamp": "2026-01-11T13:13:23.612050"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 499.738, "latencies_ms": [499.738], "images_per_second": 2.001, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A person in a wetsuit stands on a paddleboard, holding a paddle and gazing out at the calm ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [30.85, 30.85, 30.85, 30.85, 30.85], "power_watts_avg": 30.85, "power_watts_peak": 30.85, "energy_joules_est": 15.43, "sample_count": 5, "duration_seconds": 0.5}, "timestamp": "2026-01-11T13:13:24.122617"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 910.119, "latencies_ms": [910.119], "images_per_second": 1.099, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "person: 1\nboard: 1\npaddle: 1\nwater: 1\nshoreline: 1\nsky: 1\nbuildings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.14, 35.14, 35.14, 35.14, 35.14, 39.92, 39.92, 39.92, 39.92, 39.92], "power_watts_avg": 37.53, "power_watts_peak": 39.92, "energy_joules_est": 34.17, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-11T13:13:25.132079"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 705.965, "latencies_ms": [705.965], "images_per_second": 1.417, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The paddleboarder is positioned in the foreground, moving towards the left side of the image. The calm water extends to the background, creating a serene and expansive setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.39, 35.39, 35.39, 35.39, 35.39, 34.47, 34.47, 34.47], "power_watts_avg": 35.05, "power_watts_peak": 35.39, "energy_joules_est": 24.75, "sample_count": 8, "duration_seconds": 0.706}, "timestamp": "2026-01-11T13:13:25.939407"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 830.988, "latencies_ms": [830.988], "images_per_second": 1.203, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a lone paddleboarder navigating calm waters, skillfully maneuvering with a paddle. In the distance, a shoreline with buildings is visible, contrasting with the serene water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.47, 34.47, 38.24, 38.24, 38.24, 38.24, 38.24, 34.31, 34.31], "power_watts_avg": 36.53, "power_watts_peak": 38.24, "energy_joules_est": 30.37, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-11T13:13:26.849206"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1117.641, "latencies_ms": [1117.641], "images_per_second": 0.895, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The water appears relatively calm and dark in color. The lighting suggests a daytime scene, possibly with overcast conditions. The paddleboard is white and relatively small, suggesting it might be used for stand-up paddleboarding. The overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.31, 34.31, 34.31, 34.16, 34.16, 34.16, 34.16, 34.16, 34.4, 34.4, 34.4, 34.4], "power_watts_avg": 34.28, "power_watts_peak": 34.4, "energy_joules_est": 38.32, "sample_count": 12, "duration_seconds": 1.118}, "timestamp": "2026-01-11T13:13:28.058475"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 646.333, "latencies_ms": [646.333], "images_per_second": 1.547, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A white desk holds a silver laptop, white desktop computer, two white speakers, a white keyboard, and a white mouse, with a window and lamp nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13098.8, "ram_available_mb": 109407.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [34.4, 30.63, 30.63, 30.63, 30.63, 30.63, 34.72], "power_watts_avg": 31.75, "power_watts_peak": 34.72, "energy_joules_est": 20.55, "sample_count": 7, "duration_seconds": 0.647}, "timestamp": "2026-01-11T13:13:28.767643"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1118.566, "latencies_ms": [1118.566], "images_per_second": 0.894, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "laptop: 2\nkeyboard: 1\nmouse: 1\nprinter: 1\nspeaker: 2\nmonitor: 1\nwindow blinds: 1\ndesk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13099.0, "ram_available_mb": 109407.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 34.72, 34.72, 39.65, 39.65, 39.65, 39.65, 39.65, 35.49, 35.49, 35.49], "power_watts_avg": 36.97, "power_watts_peak": 39.65, "energy_joules_est": 41.37, "sample_count": 12, "duration_seconds": 1.119}, "timestamp": "2026-01-11T13:13:29.978980"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 679.242, "latencies_ms": [679.242], "images_per_second": 1.472, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The laptop is positioned to the left of the monitor and keyboard, closer to the viewer. The printer is situated in the background, slightly further away than the laptop and monitor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.49, 35.49, 34.74, 34.74, 34.74, 34.74, 35.03], "power_watts_avg": 35.0, "power_watts_peak": 35.49, "energy_joules_est": 23.79, "sample_count": 7, "duration_seconds": 0.68}, "timestamp": "2026-01-11T13:13:30.687088"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 972.299, "latencies_ms": [972.299], "images_per_second": 1.028, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a well-organized workspace featuring a desktop computer with a monitor, keyboard, and mouse, along with two speakers. A laptop is also present on the desk. The setting appears to be a home office or a workspace with a window providing natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.5, "ram_available_mb": 109408.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 35.03, 36.49, 36.49, 36.49, 36.49, 36.49, 36.08], "power_watts_avg": 35.86, "power_watts_peak": 36.49, "energy_joules_est": 34.88, "sample_count": 10, "duration_seconds": 0.973}, "timestamp": "2026-01-11T13:13:31.696793"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1072.021, "latencies_ms": [1072.021], "images_per_second": 0.933, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The desk is white and appears to be made of a smooth material. The lighting in the room is soft and diffused, suggesting natural light from a window with blinds. The materials include metal for the laptop, plastic for the speakers, and possibly other computer peripherals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.08, 36.08, 36.08, 36.08, 35.64, 35.64, 35.64, 35.64, 35.64, 35.7, 35.7], "power_watts_avg": 35.81, "power_watts_peak": 36.08, "energy_joules_est": 38.4, "sample_count": 11, "duration_seconds": 1.072}, "timestamp": "2026-01-11T13:13:32.806392"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 856.735, "latencies_ms": [856.735], "images_per_second": 1.167, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Vehicles travel under a green highway overpass with directional signs for North Ventura 101, Hollywood Blvd, and Sunset Blvd.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.7, 35.7, 35.7, 40.6, 40.6, 40.6, 40.6, 40.6, 40.63], "power_watts_avg": 38.97, "power_watts_peak": 40.63, "energy_joules_est": 33.4, "sample_count": 9, "duration_seconds": 0.857}, "timestamp": "2026-01-11T13:13:33.717860"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1247.569, "latencies_ms": [1247.569], "images_per_second": 0.802, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "highway overpass: 4\ngreen highway signs: 4\ntaxi: 2\nvan: 2\nSUV: 2\ncar: 2\ntrees: 2\nbuildings: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.63, 40.63, 40.63, 40.63, 40.79, 40.79, 40.79, 40.79, 40.79, 40.7, 40.7, 40.7, 40.7], "power_watts_avg": 40.71, "power_watts_peak": 40.79, "energy_joules_est": 50.8, "sample_count": 13, "duration_seconds": 1.248}, "timestamp": "2026-01-11T13:13:35.030928"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 867.317, "latencies_ms": [867.317], "images_per_second": 1.153, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The left foreground features the vehicles traveling under the overpass. The background includes more vehicles and distant highway signs. The foreground is dominated by the vehicles traveling on the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.7, 32.24, 32.24, 32.24, 32.24, 32.24, 40.71, 40.71, 40.71], "power_watts_avg": 36.01, "power_watts_peak": 40.71, "energy_joules_est": 31.24, "sample_count": 9, "duration_seconds": 0.868}, "timestamp": "2026-01-11T13:13:35.939840"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1139.528, "latencies_ms": [1139.528], "images_per_second": 0.878, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a busy highway with multiple vehicles traveling under a bridge. Green overhead signs provide directions to various locations, including Ventura, Hollywood, and Sunset Blvd. The setting appears to be an urban area with trees lining the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.71, 40.71, 46.24, 46.24, 46.24, 46.24, 46.24, 40.91, 40.91, 40.91, 40.91, 40.91], "power_watts_avg": 43.1, "power_watts_peak": 46.24, "energy_joules_est": 49.13, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-11T13:13:37.151163"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 692.495, "latencies_ms": [692.495], "images_per_second": 1.444, "prompt_tokens": 18, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The highway signs are green and white. The sky is clear and blue. The highway is busy with cars and taxis.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.01, 36.01, 36.01, 36.01, 36.01, 40.62, 40.62], "power_watts_avg": 37.33, "power_watts_peak": 40.62, "energy_joules_est": 25.86, "sample_count": 7, "duration_seconds": 0.693}, "timestamp": "2026-01-11T13:13:37.859956"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 969.721, "latencies_ms": [969.721], "images_per_second": 1.031, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A red double-decker bus, numbered 15 and labeled \"ALDWYCH,\" is prominently featured driving down a city street, with other vehicles and pedestrians visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.62, 40.62, 40.62, 49.96, 49.96, 49.96, 49.96, 49.96, 42.35, 42.35], "power_watts_avg": 45.64, "power_watts_peak": 49.96, "energy_joules_est": 44.28, "sample_count": 10, "duration_seconds": 0.97}, "timestamp": "2026-01-11T13:13:38.871812"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1150.575, "latencies_ms": [1150.575], "images_per_second": 0.869, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "double-decker bus: 2\nbuilding: 2\ntrees: 2\npeople: 2\nbus: 2\nroad: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.35, 42.35, 42.35, 41.94, 41.94, 41.94, 41.94, 41.94, 41.22, 41.22, 41.22, 41.22], "power_watts_avg": 41.8, "power_watts_peak": 42.35, "energy_joules_est": 48.11, "sample_count": 12, "duration_seconds": 1.151}, "timestamp": "2026-01-11T13:13:40.081705"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1002.21, "latencies_ms": [1002.21], "images_per_second": 0.998, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main object is a red double-decker bus driving on the right side of the road. The background includes other vehicles and buildings, suggesting an urban setting. The foreground is dominated by the bus, with people walking nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13097.3, "ram_available_mb": 109409.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13094.6, "ram_available_mb": 109411.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [32.22, 32.22, 32.22, 32.22, 32.22, 41.85, 41.85, 41.85, 41.85, 41.85], "power_watts_avg": 37.04, "power_watts_peak": 41.85, "energy_joules_est": 37.15, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-11T13:13:41.091509"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 937.676, "latencies_ms": [937.676], "images_per_second": 1.066, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A red double-decker bus is driving down a city street, passing a green park with people walking nearby. Buildings are visible in the background, and another bus can be seen in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.6, "ram_available_mb": 109411.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.95, 42.95, 42.95, 42.95, 42.95, 42.88, 42.88, 42.88, 42.88, 42.88], "power_watts_avg": 42.91, "power_watts_peak": 42.95, "energy_joules_est": 40.26, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-11T13:13:42.101308"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1202.104, "latencies_ms": [1202.104], "images_per_second": 0.832, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The red double-decker bus is brightly colored, contrasting with the gray sky. The bus has prominent headlights and windows, giving it a classic and iconic appearance. The weather appears to be overcast, contributing to a slightly muted lighting on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.67, 41.67, 41.67, 41.67, 41.67, 41.21, 41.21, 41.21, 41.21, 41.21, 42.36, 42.36], "power_watts_avg": 41.6, "power_watts_peak": 42.36, "energy_joules_est": 50.03, "sample_count": 12, "duration_seconds": 1.203}, "timestamp": "2026-01-11T13:13:43.312861"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 618.951, "latencies_ms": [618.951], "images_per_second": 1.616, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A black and white cat with yellow eyes is lying on top of an open silver laptop, gazing at the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.36, 42.36, 42.36, 41.47, 41.47, 41.47, 41.47], "power_watts_avg": 41.85, "power_watts_peak": 42.36, "energy_joules_est": 25.92, "sample_count": 7, "duration_seconds": 0.619}, "timestamp": "2026-01-11T13:13:44.021258"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1273.388, "latencies_ms": [1273.388], "images_per_second": 0.785, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "cat: 2\nlaptop: 1\nkeyboard: 1\ncord: 1\nlaptop power adapter: 1\nwall: 1\npaper: 1\ngreen pen: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.47, 41.96, 41.96, 41.96, 41.96, 41.96, 40.14, 40.14, 40.14, 40.14, 40.14, 39.7, 39.7], "power_watts_avg": 40.87, "power_watts_peak": 41.96, "energy_joules_est": 52.06, "sample_count": 13, "duration_seconds": 1.274}, "timestamp": "2026-01-11T13:13:45.331662"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 811.93, "latencies_ms": [811.93], "images_per_second": 1.232, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The black and white cat is positioned in the foreground, partially obscuring the silver laptop. The laptop is situated near the cat, occupying the central portion of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [39.7, 39.7, 39.7, 41.14, 41.14, 41.14, 41.14, 41.14, 41.04], "power_watts_avg": 40.65, "power_watts_peak": 41.14, "energy_joules_est": 33.03, "sample_count": 9, "duration_seconds": 0.813}, "timestamp": "2026-01-11T13:13:46.241012"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 837.898, "latencies_ms": [837.898], "images_per_second": 1.193, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A black and white cat is lying on top of an open laptop, seemingly enjoying the warmth and comfort of the device. The scene takes place on a surface that appears to be a desk or table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.04, 41.04, 41.04, 41.04, 40.02, 40.02, 40.02, 40.02, 40.02], "power_watts_avg": 40.48, "power_watts_peak": 41.04, "energy_joules_est": 33.94, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:13:47.147341"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 780.269, "latencies_ms": [780.269], "images_per_second": 1.282, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The black and white cat has striking yellow eyes. The laptop is silver and appears to be open. The lighting is soft and diffused, suggesting indoor lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.24, 40.24, 40.24, 40.24, 40.24, 40.85, 40.85, 40.85], "power_watts_avg": 40.47, "power_watts_peak": 40.85, "energy_joules_est": 31.59, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:13:47.956779"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 692.826, "latencies_ms": [692.826], "images_per_second": 1.443, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two large commercial airplanes fly in formation over the iconic Sydney Harbour Bridge, passing over the iconic Sydney Opera House.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.85, 40.85, 45.81, 45.81, 45.81, 45.81, 45.81], "power_watts_avg": 44.39, "power_watts_peak": 45.81, "energy_joules_est": 30.78, "sample_count": 7, "duration_seconds": 0.693}, "timestamp": "2026-01-11T13:13:48.665660"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1009.921, "latencies_ms": [1009.921], "images_per_second": 0.99, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "airplanes: 2\nbridge: 1\nsky: 1\ncity: 1\nsydney: 1\nsydney opera house: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13094.5, "ram_available_mb": 109411.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13091.9, "ram_available_mb": 109414.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.18, 41.18, 41.18, 41.18, 41.18, 47.23, 47.23, 47.23, 47.23, 47.23, 41.99], "power_watts_avg": 44.0, "power_watts_peak": 47.23, "energy_joules_est": 44.45, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-11T13:13:49.775794"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 997.784, "latencies_ms": [997.784], "images_per_second": 1.002, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The large airplane is positioned above the bridge, flying towards the right side of the image. The bridge spans across the foreground, connecting the two objects. The Sydney Opera House is visible in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13091.9, "ram_available_mb": 109414.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13091.9, "ram_available_mb": 109414.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 41.99, 40.11, 40.11, 40.11, 40.11, 40.11, 40.21], "power_watts_avg": 40.87, "power_watts_peak": 41.99, "energy_joules_est": 40.79, "sample_count": 10, "duration_seconds": 0.998}, "timestamp": "2026-01-11T13:13:50.782383"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 857.584, "latencies_ms": [857.584], "images_per_second": 1.166, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Two large airplanes are flying over a bridge, likely Sydney Harbour Bridge, amidst a cloudy sky. The bridge spans the water, with the iconic Sydney Opera House visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13091.9, "ram_available_mb": 109414.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13092.3, "ram_available_mb": 109414.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.21, 40.21, 40.21, 41.69, 41.69, 41.69, 41.69, 41.69, 41.72], "power_watts_avg": 41.2, "power_watts_peak": 41.72, "energy_joules_est": 35.34, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:13:51.693414"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 953.448, "latencies_ms": [953.448], "images_per_second": 1.049, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The sky is mostly cloudy with patches of blue. The lighting suggests an overcast day. The planes appear to be flying in formation, highlighting the impressive scale of the bridge and the Sydney Opera House.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13092.3, "ram_available_mb": 109414.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13089.4, "ram_available_mb": 109416.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.72, 41.72, 41.72, 41.72, 41.31, 41.31, 41.31, 41.31, 41.31, 41.35], "power_watts_avg": 41.48, "power_watts_peak": 41.72, "energy_joules_est": 39.56, "sample_count": 10, "duration_seconds": 0.954}, "timestamp": "2026-01-11T13:13:52.703025"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 650.652, "latencies_ms": [650.652], "images_per_second": 1.537, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A zebra stands tall and proud, displaying its striking black and white stripes as it grazes in a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.4, "ram_available_mb": 109416.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.35, 41.35, 41.35, 41.35, 40.89, 40.89, 40.89], "power_watts_avg": 41.16, "power_watts_peak": 41.35, "energy_joules_est": 26.81, "sample_count": 7, "duration_seconds": 0.651}, "timestamp": "2026-01-11T13:13:53.414156"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 838.959, "latencies_ms": [838.959], "images_per_second": 1.192, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "zebra: 2\ngrass: 2\ntree: 0\nanimal: 1\nnursing zebra: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [40.89, 40.89, 47.68, 47.68, 47.68, 47.68, 47.68, 41.04, 41.04], "power_watts_avg": 44.7, "power_watts_peak": 47.68, "energy_joules_est": 37.51, "sample_count": 9, "duration_seconds": 0.839}, "timestamp": "2026-01-11T13:13:54.324918"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 782.775, "latencies_ms": [782.775], "images_per_second": 1.278, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The zebra is positioned in the foreground, close to the camera. The zebra is feeding its young, which can be seen in the midground. The background consists of tall grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [41.04, 41.04, 41.04, 43.31, 43.31, 43.31, 43.31, 43.31], "power_watts_avg": 42.46, "power_watts_peak": 43.31, "energy_joules_est": 33.25, "sample_count": 8, "duration_seconds": 0.783}, "timestamp": "2026-01-11T13:13:55.135433"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 724.094, "latencies_ms": [724.094], "images_per_second": 1.381, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The scene depicts a zebra nursing from its mother in a grassy field. The zebra's distinctive black and white stripes contrast with the surrounding vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.9, "ram_available_mb": 109416.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.83, 40.83, 40.83, 40.83, 40.83, 41.46, 41.46, 41.46], "power_watts_avg": 41.07, "power_watts_peak": 41.46, "energy_joules_est": 29.75, "sample_count": 8, "duration_seconds": 0.724}, "timestamp": "2026-01-11T13:13:55.945154"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 906.831, "latencies_ms": [906.831], "images_per_second": 1.103, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The zebra's coat is predominantly black and white, creating a striking contrast against the lighter background. The lighting in the image appears to be natural daylight, enhancing the visibility of the zebra's stripes and features.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.9, "ram_available_mb": 109416.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13091.2, "ram_available_mb": 109415.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.46, 41.46, 46.08, 46.08, 46.08, 46.08, 46.08, 40.37, 40.37, 40.37], "power_watts_avg": 43.44, "power_watts_peak": 46.08, "energy_joules_est": 39.43, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:13:56.955943"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 724.165, "latencies_ms": [724.165], "images_per_second": 1.381, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The room features a bed with a colorful, patterned comforter, a small round table with a chair, and a stone wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13091.2, "ram_available_mb": 109415.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13091.5, "ram_available_mb": 109414.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.37, 40.37, 39.6, 39.6, 39.6, 39.6, 39.6, 39.56], "power_watts_avg": 39.79, "power_watts_peak": 40.37, "energy_joules_est": 28.84, "sample_count": 8, "duration_seconds": 0.725}, "timestamp": "2026-01-11T13:13:57.764564"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1138.083, "latencies_ms": [1138.083], "images_per_second": 0.879, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "bed: 1\ntable: 1\nchair: 1\nwindow: 2\nstone wall: 2\ndoor: 2\nlight fixture: 1\ncar: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13091.5, "ram_available_mb": 109414.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13091.5, "ram_available_mb": 109414.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.56, 39.56, 39.56, 39.56, 45.3, 45.3, 45.3, 45.3, 45.3, 40.45, 40.45, 40.45], "power_watts_avg": 42.17, "power_watts_peak": 45.3, "energy_joules_est": 48.02, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-11T13:13:58.974462"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 984.559, "latencies_ms": [984.559], "images_per_second": 1.016, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned slightly to the right of the image. The small table and chair are situated to the left of the bed. The window and door are located in the background, offering a view outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13091.5, "ram_available_mb": 109414.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13088.4, "ram_available_mb": 109417.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.45, 40.45, 35.18, 35.18, 35.18, 35.18, 35.18, 40.38, 40.38, 40.38], "power_watts_avg": 37.79, "power_watts_peak": 40.45, "energy_joules_est": 37.22, "sample_count": 10, "duration_seconds": 0.985}, "timestamp": "2026-01-11T13:13:59.986769"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 942.068, "latencies_ms": [942.068], "images_per_second": 1.061, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room features a bed with a colorful quilt, a small round table with a chair, and a stone wall. The space appears to be an apartment or bedroom, with a view of an exterior building through a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.4, "ram_available_mb": 109417.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13088.7, "ram_available_mb": 109417.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.38, 40.91, 40.91, 40.91, 40.91, 40.91, 41.24, 41.24, 41.24, 41.24], "power_watts_avg": 40.99, "power_watts_peak": 41.24, "energy_joules_est": 38.64, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-11T13:14:00.995414"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1028.557, "latencies_ms": [1028.557], "images_per_second": 0.972, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room features a purple bedspread with a geometric pattern. The walls are painted a dark purple, and the floor is covered in dark purple carpeting. A small round table with a black chair is situated near the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.7, "ram_available_mb": 109417.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.24, 41.02, 41.02, 41.02, 41.02, 41.02, 40.88, 40.88, 40.88, 40.88, 40.88], "power_watts_avg": 40.97, "power_watts_peak": 41.24, "energy_joules_est": 42.17, "sample_count": 11, "duration_seconds": 1.029}, "timestamp": "2026-01-11T13:14:02.107266"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 728.741, "latencies_ms": [728.741], "images_per_second": 1.372, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A purple bus numbered 96, labeled \"South Tyne,\" is stopped at a bus stop, waiting for passengers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.55, 38.55, 38.55, 38.55, 38.55, 40.58, 40.58, 40.58], "power_watts_avg": 39.31, "power_watts_peak": 40.58, "energy_joules_est": 28.67, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-11T13:14:02.919083"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1987.552, "latencies_ms": [1987.552], "images_per_second": 0.503, "prompt_tokens": 21, "response_tokens_est": 62, "n_tiles": 1, "output_text": "bus: 5\nperson: 1\nwindshield wipers: 2\nbus number: 96\nbus route: Metrocentre via Bens\nbus branding: South Tyne\nbus windows: 10\nbus license plate: NA52 BUU\nbus front bumper: 2\nbus front wheels: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.58, 40.58, 47.92, 47.92, 47.92, 47.92, 47.92, 40.8, 40.8, 40.8, 40.8, 40.8, 34.64, 34.64, 34.64, 34.64, 34.64, 31.85, 31.85, 31.85], "power_watts_avg": 39.68, "power_watts_peak": 47.92, "energy_joules_est": 78.87, "sample_count": 20, "duration_seconds": 1.988}, "timestamp": "2026-01-11T13:14:04.934554"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 949.033, "latencies_ms": [949.033], "images_per_second": 1.054, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving towards the viewer. The person walking nearby is positioned in the background, slightly further away. The bus is situated on a roadway, further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [31.85, 31.85, 34.62, 34.62, 34.62, 34.62, 40.8, 40.8, 40.8, 40.8], "power_watts_avg": 36.54, "power_watts_peak": 40.8, "energy_joules_est": 34.73, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-11T13:14:05.997324"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1200.723, "latencies_ms": [1200.723], "images_per_second": 0.833, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A purple bus labeled \"South Tyne\" is driving down a city street, passing a pedestrian. A man is visible inside the bus, seemingly waiting or preparing to board. The scene suggests a typical urban environment with buildings, trees, and street infrastructure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.8, 41.4, 41.4, 41.4, 41.4, 41.4, 41.09, 41.09, 41.09, 41.09, 41.09, 38.52], "power_watts_avg": 40.98, "power_watts_peak": 41.4, "energy_joules_est": 49.23, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-11T13:14:07.210210"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 838.03, "latencies_ms": [838.03], "images_per_second": 1.193, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The bus is purple and features bright orange numbers. The bus has a windshield and side windows. The bus is driving on a road with a sidewalk nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.52, 38.52, 38.52, 38.52, 42.0, 42.0, 42.0, 42.0, 42.0], "power_watts_avg": 40.46, "power_watts_peak": 42.0, "energy_joules_est": 33.92, "sample_count": 9, "duration_seconds": 0.839}, "timestamp": "2026-01-11T13:14:08.119502"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 601.198, "latencies_ms": [601.198], "images_per_second": 1.663, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A white bowl filled with shiny green apples sits on a table, displaying their natural shape and vibrant color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.3, 41.3, 41.3, 41.3, 41.3, 40.75], "power_watts_avg": 41.21, "power_watts_peak": 41.3, "energy_joules_est": 24.8, "sample_count": 6, "duration_seconds": 0.602}, "timestamp": "2026-01-11T13:14:08.728501"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1230.981, "latencies_ms": [1230.981], "images_per_second": 0.812, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.75, 40.75, 40.75, 40.75, 51.86, 51.86, 51.86, 51.86, 51.86, 42.15, 42.15, 42.15, 42.15], "power_watts_avg": 45.46, "power_watts_peak": 51.86, "energy_joules_est": 55.98, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-11T13:14:10.042291"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 784.038, "latencies_ms": [784.038], "images_per_second": 1.275, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main objects are positioned close together, creating a sense of proximity and shared space. The apples are situated in the foreground, while the background is dark and out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.15, 31.45, 31.45, 31.45, 31.45, 31.45, 40.5, 40.5], "power_watts_avg": 35.05, "power_watts_peak": 42.15, "energy_joules_est": 27.49, "sample_count": 8, "duration_seconds": 0.784}, "timestamp": "2026-01-11T13:14:10.853508"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 830.696, "latencies_ms": [830.696], "images_per_second": 1.204, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A white bowl filled with green apples sits on a dark surface, possibly a table. The apples are piled together, showcasing their vibrant green color and smooth skin.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.9, "ram_available_mb": 109417.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.5, 40.5, 40.5, 51.11, 51.11, 51.11, 51.11, 51.11, 41.98], "power_watts_avg": 46.56, "power_watts_peak": 51.11, "energy_joules_est": 38.69, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-11T13:14:11.764403"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 798.918, "latencies_ms": [798.918], "images_per_second": 1.252, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The apples are bright green, indicating they are likely freshly picked. The lighting in the image is soft and warm, enhancing the vibrant green color of the apples.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.98, 41.98, 41.98, 41.98, 40.85, 40.85, 40.85, 40.85], "power_watts_avg": 41.41, "power_watts_peak": 41.98, "energy_joules_est": 33.1, "sample_count": 8, "duration_seconds": 0.799}, "timestamp": "2026-01-11T13:14:12.573710"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 756.545, "latencies_ms": [756.545], "images_per_second": 1.322, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A baseball game is in progress, with a batter mid-swing, a pitcher preparing to throw, and a catcher crouched behind home plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [40.85, 40.34, 40.34, 40.34, 40.34, 40.34, 42.1, 42.1], "power_watts_avg": 40.84, "power_watts_peak": 42.1, "energy_joules_est": 30.92, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:14:13.384390"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1607.624, "latencies_ms": [1607.624], "images_per_second": 0.622, "prompt_tokens": 21, "response_tokens_est": 52, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball: 1\nbaseball glove: 1\nbaseball: 1\nbaseball field: 1\nbaseball diamond: 1\nbaseball pitcher: 1\nbaseball umpire: 1\nbaseball catcher: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.1, 42.1, 42.1, 50.66, 50.66, 50.66, 50.66, 50.66, 41.46, 41.46, 41.46, 41.46, 41.46, 34.28, 34.28, 34.28], "power_watts_avg": 43.11, "power_watts_peak": 50.66, "energy_joules_est": 69.33, "sample_count": 16, "duration_seconds": 1.608}, "timestamp": "2026-01-11T13:14:14.998757"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 709.973, "latencies_ms": [709.973], "images_per_second": 1.409, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The pitcher is on the left side of the image, while the batter is in the foreground. The background is filled with green grass, indicating a baseball field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.28, 35.41, 35.41, 35.41, 35.41, 35.41, 42.03, 42.03], "power_watts_avg": 36.92, "power_watts_peak": 42.03, "energy_joules_est": 26.23, "sample_count": 8, "duration_seconds": 0.71}, "timestamp": "2026-01-11T13:14:15.807943"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1122.607, "latencies_ms": [1122.607], "images_per_second": 0.891, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A baseball game is in progress, with a batter mid-swing, a pitcher preparing to throw, and a catcher crouched behind home plate. The scene takes place on a well-maintained baseball field with green grass and a brown dirt infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.8, "ram_available_mb": 109417.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.03, 42.03, 42.03, 47.93, 47.93, 47.93, 47.93, 47.93, 40.37, 40.37, 40.37, 40.37], "power_watts_avg": 43.94, "power_watts_peak": 47.93, "energy_joules_est": 49.34, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:14:17.020346"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1332.016, "latencies_ms": [1332.016], "images_per_second": 0.751, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The baseball field is bathed in bright sunlight, creating a vibrant and dynamic atmosphere. The grass appears well-maintained and evenly cut, enhancing the overall visual appeal of the scene. The lighting conditions suggest a sunny day, which contributes to the overall brightness and vibrancy of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.37, 32.44, 32.44, 32.44, 32.44, 32.44, 40.56, 40.56, 40.56, 40.56, 40.56, 39.95, 39.95, 39.95], "power_watts_avg": 37.52, "power_watts_peak": 40.56, "energy_joules_est": 50.0, "sample_count": 14, "duration_seconds": 1.333}, "timestamp": "2026-01-11T13:14:18.434751"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 910.775, "latencies_ms": [910.775], "images_per_second": 1.098, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A table is set with an assortment of desserts, meats, and fruits, including a large fruit-topped cake, cheese and crackers, grapes, bread, and wine glasses.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [39.95, 39.95, 37.24, 37.24, 37.24, 37.24, 37.24, 40.59, 40.59, 40.59], "power_watts_avg": 38.79, "power_watts_peak": 40.59, "energy_joules_est": 35.34, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:14:19.448690"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1550.405, "latencies_ms": [1550.405], "images_per_second": 0.645, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "cake: 1\nraspberry: 1\nblueberry: 1\nwine glass: 2\nwater glass: 1\nbread: 2\ncheese: 2\ngrapes: 2\nbutter knife: 1\nserving spatula: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.59, 40.59, 39.64, 39.64, 39.64, 39.64, 39.64, 40.49, 40.49, 40.49, 40.49, 40.49, 36.11, 36.11, 36.11, 36.11], "power_watts_avg": 39.14, "power_watts_peak": 40.59, "energy_joules_est": 60.7, "sample_count": 16, "duration_seconds": 1.551}, "timestamp": "2026-01-11T13:14:21.063775"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1049.282, "latencies_ms": [1049.282], "images_per_second": 0.953, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and visually appealing manner. The cake and fruit platter are in the foreground, while the table setting with plates, glasses, and cutlery extends to the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.11, 31.0, 31.0, 31.0, 31.0, 31.0, 41.45, 41.45, 41.45, 41.45, 41.45], "power_watts_avg": 36.21, "power_watts_peak": 41.45, "energy_joules_est": 38.01, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-11T13:14:22.174732"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1135.208, "latencies_ms": [1135.208], "images_per_second": 0.881, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts an outdoor gathering with a table laden with food and drinks. A large cake with fresh berries is prominently displayed, surrounded by various plates, glasses, and serving utensils. The setting suggests a casual, festive atmosphere, possibly a celebration or party.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.57, 42.57, 42.57, 42.57, 42.57, 41.04, 41.04, 41.04, 41.04, 41.04, 41.03, 41.03], "power_watts_avg": 41.67, "power_watts_peak": 42.57, "energy_joules_est": 47.32, "sample_count": 12, "duration_seconds": 1.136}, "timestamp": "2026-01-11T13:14:23.386628"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 847.396, "latencies_ms": [847.396], "images_per_second": 1.18, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The table is covered with a red tablecloth. The food items are brightly colored and appear fresh. The lighting is soft and diffused, creating a pleasant ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.03, 41.03, 41.03, 39.98, 39.98, 39.98, 39.98, 39.98, 40.84], "power_watts_avg": 40.42, "power_watts_peak": 41.03, "energy_joules_est": 34.28, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-11T13:14:24.297855"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 590.95, "latencies_ms": [590.95], "images_per_second": 1.692, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man wearing a black shirt is riding a wave on a blue boogie board in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [40.84, 40.84, 40.84, 41.95, 41.95, 41.95], "power_watts_avg": 41.39, "power_watts_peak": 41.95, "energy_joules_est": 24.48, "sample_count": 6, "duration_seconds": 0.591}, "timestamp": "2026-01-11T13:14:24.908015"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 908.369, "latencies_ms": [908.369], "images_per_second": 1.101, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "person: 1\nbodyboard: 1\nwave: 1\nwater: 1\nshore: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.2, "ram_available_mb": 109417.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.95, 41.95, 48.27, 48.27, 48.27, 48.27, 48.27, 41.57, 41.57, 41.57], "power_watts_avg": 45.0, "power_watts_peak": 48.27, "energy_joules_est": 40.89, "sample_count": 10, "duration_seconds": 0.909}, "timestamp": "2026-01-11T13:14:25.919711"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 831.853, "latencies_ms": [831.853], "images_per_second": 1.202, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The man is positioned near the center of the image, riding a wave in the ocean. The wave is breaking towards the right side of the image, creating a dynamic and energetic scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.57, 41.57, 39.61, 39.61, 39.61, 39.61, 39.61, 40.09, 40.09], "power_watts_avg": 40.15, "power_watts_peak": 41.57, "energy_joules_est": 33.42, "sample_count": 9, "duration_seconds": 0.832}, "timestamp": "2026-01-11T13:14:26.830731"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 844.419, "latencies_ms": [844.419], "images_per_second": 1.184, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is riding a wave on a blue boogie board in the ocean. He is surrounded by green water and white foam. The scene suggests a sunny day at the beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.09, 40.09, 40.09, 43.73, 43.73, 43.73, 43.73, 43.73, 40.84], "power_watts_avg": 42.2, "power_watts_peak": 43.73, "energy_joules_est": 35.65, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-11T13:14:27.742125"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 820.528, "latencies_ms": [820.528], "images_per_second": 1.219, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The water is a vibrant green color, creating a striking contrast with the man's black shirt. The lighting appears to be natural and bright, suggesting an outdoor setting on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [40.84, 40.84, 40.84, 40.84, 40.89, 40.89, 40.89, 40.89, 40.89], "power_watts_avg": 40.87, "power_watts_peak": 40.89, "energy_joules_est": 33.55, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:14:28.654096"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 470.697, "latencies_ms": [470.697], "images_per_second": 2.125, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The black and white photograph shows a group of children gathered in front of a brick building, posing for a group photograph.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13089.1, "ram_available_mb": 109417.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13086.5, "ram_available_mb": 109419.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [40.69, 40.69, 40.69, 40.69, 40.69], "power_watts_avg": 40.69, "power_watts_peak": 40.69, "energy_joules_est": 19.18, "sample_count": 5, "duration_seconds": 0.471}, "timestamp": "2026-01-11T13:14:29.162744"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1175.049, "latencies_ms": [1175.049], "images_per_second": 0.851, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "child: 12\nboy: 8\ngirl: 8\nman: 2\nwoman: 1\nbuilding: 1\nsweater: 1\njacket: 1\ndress: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13086.5, "ram_available_mb": 109419.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13086.9, "ram_available_mb": 109419.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.37, 35.37, 35.37, 35.37, 35.37, 39.82, 39.82, 39.82, 39.82, 39.82, 36.13, 36.13], "power_watts_avg": 37.35, "power_watts_peak": 39.82, "energy_joules_est": 43.9, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-11T13:14:30.373888"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 694.372, "latencies_ms": [694.372], "images_per_second": 1.44, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are arranged in a symmetrical and organized manner, creating a sense of balance and order. The children are positioned both in the foreground and background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13086.9, "ram_available_mb": 109419.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13086.9, "ram_available_mb": 109419.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [36.13, 36.13, 36.13, 36.27, 36.27, 36.27, 36.27], "power_watts_avg": 36.21, "power_watts_peak": 36.27, "energy_joules_est": 25.15, "sample_count": 7, "duration_seconds": 0.695}, "timestamp": "2026-01-11T13:14:31.083176"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 764.75, "latencies_ms": [764.75], "images_per_second": 1.308, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The black and white photo depicts a group of children gathered together, possibly for a school photo session. The children are dressed in formal attire and appear to be posing for a group photo in front of a brick wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13086.9, "ram_available_mb": 109419.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13086.8, "ram_available_mb": 109419.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.27, 36.05, 36.05, 36.05, 36.05, 36.05, 36.44, 36.44], "power_watts_avg": 36.17, "power_watts_peak": 36.44, "energy_joules_est": 27.68, "sample_count": 8, "duration_seconds": 0.765}, "timestamp": "2026-01-11T13:14:31.893723"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1153.471, "latencies_ms": [1153.471], "images_per_second": 0.867, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The black and white photograph shows children dressed in formal attire, posing in front of a brick wall. The lighting is soft and diffused, suggesting an indoor setting. The clothing appears well-fitted and suitable for the era. The brick wall adds a historical context to the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13086.8, "ram_available_mb": 109419.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13086.8, "ram_available_mb": 109419.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.44, 36.44, 39.79, 39.79, 39.79, 39.79, 39.79, 35.19, 35.19, 35.19, 35.19, 35.19], "power_watts_avg": 37.31, "power_watts_peak": 39.79, "energy_joules_est": 43.05, "sample_count": 12, "duration_seconds": 1.154}, "timestamp": "2026-01-11T13:14:33.105718"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 732.961, "latencies_ms": [732.961], "images_per_second": 1.364, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A white rectangular platter holds a selection of grilled bread pieces, accompanied by a small white bowl and a wrapped piece of bread.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13086.8, "ram_available_mb": 109419.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13086.8, "ram_available_mb": 109419.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [31.14, 31.14, 31.14, 31.14, 31.14, 41.24, 41.24, 41.24], "power_watts_avg": 34.93, "power_watts_peak": 41.24, "energy_joules_est": 25.62, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:14:33.915545"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1289.465, "latencies_ms": [1289.465], "images_per_second": 0.776, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "toast: 6\nbread: 6\nbutter: 1\nvinegar: 1\nspoon: 1\ngrater: 1\nglass: 1\nplate: 1\ncup: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13086.8, "ram_available_mb": 109419.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13087.7, "ram_available_mb": 109418.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.24, 41.24, 48.12, 48.12, 48.12, 48.12, 48.12, 40.77, 40.77, 40.77, 40.77, 40.77, 34.85], "power_watts_avg": 43.22, "power_watts_peak": 48.12, "energy_joules_est": 55.74, "sample_count": 13, "duration_seconds": 1.29}, "timestamp": "2026-01-11T13:14:35.226287"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1088.666, "latencies_ms": [1088.666], "images_per_second": 0.919, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The foreground features the bread, butter, and sauce arranged on a white platter. The background includes a wooden table, a wine glass, and a knife. The bread and sauce are placed close to the viewer, while the butter and sauce are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13087.7, "ram_available_mb": 109418.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.0, "ram_available_mb": 109418.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 34.85, 41.99, 41.99, 41.99, 41.99, 41.99, 41.75, 41.75], "power_watts_avg": 39.35, "power_watts_peak": 41.99, "energy_joules_est": 42.85, "sample_count": 11, "duration_seconds": 1.089}, "timestamp": "2026-01-11T13:14:36.336391"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1144.656, "latencies_ms": [1144.656], "images_per_second": 0.874, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene is set on a wooden table with a white rectangular platter containing various food items, including toasted bread, a small white bowl, and a wrapped item. A glass of red wine and a knife are also present on the table, suggesting a casual dining setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.0, "ram_available_mb": 109418.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13088.3, "ram_available_mb": 109418.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [41.75, 41.75, 41.75, 41.77, 41.77, 41.77, 41.77, 41.77, 41.62, 41.62, 41.62, 41.62], "power_watts_avg": 41.72, "power_watts_peak": 41.77, "energy_joules_est": 47.77, "sample_count": 12, "duration_seconds": 1.145}, "timestamp": "2026-01-11T13:14:37.548006"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 996.226, "latencies_ms": [996.226], "images_per_second": 1.004, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The bread appears golden-brown, indicating it has been toasted. The cheese appears white and creamy. The wooden table provides a warm, rustic ambiance. The wine glass adds a touch of elegance to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.3, "ram_available_mb": 109418.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 20.0}, "power_stats": {"power_watts_samples": [41.62, 31.36, 31.36, 31.36, 31.36, 31.36, 41.03, 41.03, 41.03, 41.03], "power_watts_avg": 36.26, "power_watts_peak": 41.62, "energy_joules_est": 36.14, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-11T13:14:38.557301"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 889.657, "latencies_ms": [889.657], "images_per_second": 1.124, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A skier in a colorful jacket and pants is captured mid-air, performing a trick with ski poles, while other skiers and snowboarders are visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [41.03, 42.26, 42.26, 42.26, 42.26, 42.26, 42.31, 42.31, 42.31], "power_watts_avg": 42.14, "power_watts_peak": 42.31, "energy_joules_est": 37.5, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:14:39.468206"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1116.836, "latencies_ms": [1116.836], "images_per_second": 0.895, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "skier: 1\nski poles: 2\nskis: 2\nsnowboard: 1\ntree: 4\nsnow: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.7, "ram_available_mb": 109416.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13088.5, "ram_available_mb": 109417.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.31, 42.31, 46.91, 46.91, 46.91, 46.91, 46.91, 41.59, 41.59, 41.59, 41.59, 41.59], "power_watts_avg": 43.92, "power_watts_peak": 46.91, "energy_joules_est": 49.07, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-11T13:14:40.679841"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1305.716, "latencies_ms": [1305.716], "images_per_second": 0.766, "prompt_tokens": 25, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, mid-jump, against a backdrop of snow-covered trees and a clear blue sky. The foreground features the skier's skis and poles, while the background includes more trees and a clear sky. The skier is relatively close to the viewer, suggesting they are in close proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13088.5, "ram_available_mb": 109417.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13089.3, "ram_available_mb": 109417.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.07, 38.07, 38.07, 38.07, 38.07, 40.45, 40.45, 40.45, 40.45, 40.45, 40.82, 40.82, 40.82, 40.82], "power_watts_avg": 39.7, "power_watts_peak": 40.82, "energy_joules_est": 51.86, "sample_count": 14, "duration_seconds": 1.306}, "timestamp": "2026-01-11T13:14:42.091009"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 999.359, "latencies_ms": [999.359], "images_per_second": 1.001, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A skier is performing a jump off a snow ramp in a snowy mountain area, with other skiers visible in the background. The scene captures the excitement and athleticism of winter sports.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.3, "ram_available_mb": 109417.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13089.3, "ram_available_mb": 109417.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.82, 30.51, 30.51, 30.51, 30.51, 30.51, 39.95, 39.95, 39.95, 39.95], "power_watts_avg": 35.32, "power_watts_peak": 40.82, "energy_joules_est": 35.31, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:14:43.100681"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 691.165, "latencies_ms": [691.165], "images_per_second": 1.447, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The skier is wearing a multicolored jacket and beige pants. The scene is brightly lit by the clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13089.3, "ram_available_mb": 109417.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.6, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.69, 41.69, 41.69, 41.69, 41.69, 42.26, 42.26], "power_watts_avg": 41.85, "power_watts_peak": 42.26, "energy_joules_est": 28.94, "sample_count": 7, "duration_seconds": 0.692}, "timestamp": "2026-01-11T13:14:43.808203"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 858.147, "latencies_ms": [858.147], "images_per_second": 1.165, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A person in winter clothing, equipped with ski poles, stands on snow-covered ground, facing a vast snowy mountain landscape under a blue sky dotted with clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.26, 42.26, 42.26, 52.08, 52.08, 52.08, 52.08, 52.08, 42.3], "power_watts_avg": 47.72, "power_watts_peak": 52.08, "energy_joules_est": 40.97, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:14:44.719547"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1173.19, "latencies_ms": [1173.19], "images_per_second": 0.852, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "sky: 2\nclouds: 3\nsnow: 6\nperson: 1\nskis: 1\ntree: 1\nrocks: 2\nmountain: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.3, 42.3, 42.3, 42.3, 41.53, 41.53, 41.53, 41.53, 41.53, 41.58, 41.58, 41.58], "power_watts_avg": 41.8, "power_watts_peak": 42.3, "energy_joules_est": 49.06, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-11T13:14:45.931323"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1127.663, "latencies_ms": [1127.663], "images_per_second": 0.887, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, facing the snowy mountain landscape. The foreground is relatively clear of snow, while the background features snow-covered mountains. The skier is relatively close to the foreground, implying they are in a relatively close proximity to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.58, 41.58, 38.91, 38.91, 38.91, 38.91, 38.91, 42.09, 42.09, 42.09, 42.09, 42.09], "power_watts_avg": 40.68, "power_watts_peak": 42.09, "energy_joules_est": 45.89, "sample_count": 12, "duration_seconds": 1.128}, "timestamp": "2026-01-11T13:14:47.138131"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 873.791, "latencies_ms": [873.791], "images_per_second": 1.144, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A person is cross-country skiing across a snowy mountain landscape under a bright blue sky with fluffy white clouds. The scene captures the beauty and tranquility of winter sports.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 35.03, 35.03, 41.0, 41.0, 41.0, 41.0], "power_watts_avg": 37.68, "power_watts_peak": 41.0, "energy_joules_est": 32.94, "sample_count": 9, "duration_seconds": 0.874}, "timestamp": "2026-01-11T13:14:48.046979"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1033.804, "latencies_ms": [1033.804], "images_per_second": 0.967, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The sky is a vibrant blue with fluffy white clouds. The snow on the ground is bright white, contrasting with the darker tones of the mountains and trees. The lighting suggests a sunny day, with shadows cast by the snow-covered landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.0, 41.08, 41.08, 41.08, 41.08, 41.08, 41.97, 41.97, 41.97, 41.97, 41.97], "power_watts_avg": 41.48, "power_watts_peak": 41.97, "energy_joules_est": 42.9, "sample_count": 11, "duration_seconds": 1.034}, "timestamp": "2026-01-11T13:14:49.156748"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 526.361, "latencies_ms": [526.361], "images_per_second": 1.9, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A chocolate-glazed donut and a ripe banana are placed together on a brown surface.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.09, 42.09, 42.09, 42.09, 42.09, 35.22], "power_watts_avg": 40.94, "power_watts_peak": 42.09, "energy_joules_est": 21.58, "sample_count": 6, "duration_seconds": 0.527}, "timestamp": "2026-01-11T13:14:49.765903"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 611.18, "latencies_ms": [611.18], "images_per_second": 1.636, "prompt_tokens": 21, "response_tokens_est": 20, "n_tiles": 1, "output_text": "donut: 1\nbanana: 1\nplastic bag: 1\nbrown surface: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.22, 35.22, 35.22, 35.22, 38.64, 38.64, 38.64], "power_watts_avg": 36.69, "power_watts_peak": 38.64, "energy_joules_est": 22.44, "sample_count": 7, "duration_seconds": 0.612}, "timestamp": "2026-01-11T13:14:50.473741"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 665.181, "latencies_ms": [665.181], "images_per_second": 1.503, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The banana is positioned in the foreground, partially obscuring the donut. The donut is situated in the background, partially obscured by the banana.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [38.64, 38.64, 38.14, 38.14, 38.14, 38.14, 38.14], "power_watts_avg": 38.28, "power_watts_peak": 38.64, "energy_joules_est": 25.48, "sample_count": 7, "duration_seconds": 0.665}, "timestamp": "2026-01-11T13:14:51.183391"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 787.141, "latencies_ms": [787.141], "images_per_second": 1.27, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A chocolate-glazed donut and a ripe banana are placed together on a brown surface, possibly a table or countertop. The scene suggests a casual snack or treat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 34.97, 34.97, 36.75, 36.75, 36.75], "power_watts_avg": 35.63, "power_watts_peak": 36.75, "energy_joules_est": 28.06, "sample_count": 8, "duration_seconds": 0.787}, "timestamp": "2026-01-11T13:14:51.990376"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 720.257, "latencies_ms": [720.257], "images_per_second": 1.388, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The donut is brown and appears glazed. The banana is yellow and has a slight bruise. The bag appears to be made of a clear plastic material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.75, 36.75, 39.69, 39.69, 39.69, 39.69, 39.69, 36.59], "power_watts_avg": 38.57, "power_watts_peak": 39.69, "energy_joules_est": 27.79, "sample_count": 8, "duration_seconds": 0.721}, "timestamp": "2026-01-11T13:14:52.799576"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 546.916, "latencies_ms": [546.916], "images_per_second": 1.828, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A white mug with a skull and crossbones design sits on a glass countertop, accompanied by a serrated knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.59, 36.59, 36.59, 37.32, 37.32, 37.32], "power_watts_avg": 36.95, "power_watts_peak": 37.32, "energy_joules_est": 20.24, "sample_count": 6, "duration_seconds": 0.548}, "timestamp": "2026-01-11T13:14:53.410102"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1064.497, "latencies_ms": [1064.497], "images_per_second": 0.939, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "mug: 1\nskull: 1\nknife: 1\nhandle: 1\ncrossbones: 2\ntext: 2\nplate: 1\ncountertop: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [37.32, 37.32, 39.2, 39.2, 39.2, 39.2, 39.2, 36.23, 36.23, 36.23, 36.23], "power_watts_avg": 37.78, "power_watts_peak": 39.2, "energy_joules_est": 40.23, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:14:54.522692"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 515.893, "latencies_ms": [515.893], "images_per_second": 1.938, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The mug is positioned in the foreground, while the knife is placed in the background. The mug and knife are placed close together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 40.0}, "power_stats": {"power_watts_samples": [36.23, 34.13, 34.13, 34.13, 34.13, 34.13], "power_watts_avg": 34.48, "power_watts_peak": 36.23, "energy_joules_est": 17.8, "sample_count": 6, "duration_seconds": 0.516}, "timestamp": "2026-01-11T13:14:55.131939"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 794.255, "latencies_ms": [794.255], "images_per_second": 1.259, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A white mug with a skull and crossbones design sits on a light-colored surface. Next to it is a serrated knife with a black handle. The scene suggests a kitchen or dining area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.68, 35.68, 35.68, 35.68, 35.68, 38.57, 38.57, 38.57], "power_watts_avg": 36.76, "power_watts_peak": 38.57, "energy_joules_est": 29.22, "sample_count": 8, "duration_seconds": 0.795}, "timestamp": "2026-01-11T13:14:55.941469"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1083.939, "latencies_ms": [1083.939], "images_per_second": 0.923, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The mug is white and features a black skull and crossbones design. The knife has a black handle and a silver blade. The scene is set on a light-colored surface, possibly a countertop or table. The lighting appears to be artificial, illuminating the mug and knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.57, 38.57, 40.41, 40.41, 40.41, 40.41, 40.41, 36.49, 36.49, 36.49, 36.49], "power_watts_avg": 38.65, "power_watts_peak": 40.41, "energy_joules_est": 41.92, "sample_count": 11, "duration_seconds": 1.084}, "timestamp": "2026-01-11T13:14:57.052943"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 594.827, "latencies_ms": [594.827], "images_per_second": 1.681, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A group of people are gathered around a wooden bar, discussing and sampling various bottles of wine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.49, 32.92, 32.92, 32.92, 32.92, 32.92], "power_watts_avg": 33.52, "power_watts_peak": 36.49, "energy_joules_est": 19.95, "sample_count": 6, "duration_seconds": 0.595}, "timestamp": "2026-01-11T13:14:57.665081"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1294.368, "latencies_ms": [1294.368], "images_per_second": 0.773, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "bottle: 5\ntable: 1\nwine bottle: 4\nglasses: 2\nman: 2\nwoman: 2\nman: 1\nman: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.07, 43.07, 43.07, 43.07, 43.07, 53.58, 53.58, 53.58, 53.58, 53.58, 43.3, 43.3, 43.3], "power_watts_avg": 47.17, "power_watts_peak": 53.58, "energy_joules_est": 61.07, "sample_count": 13, "duration_seconds": 1.295}, "timestamp": "2026-01-11T13:14:58.979328"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1096.07, "latencies_ms": [1096.07], "images_per_second": 0.912, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The wine bottles are placed in the foreground, while the people are gathered around them, interacting with the display. The background includes additional elements like a wooden cabinet and a partially visible wine barrel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.3, 43.3, 37.63, 37.63, 37.63, 37.63, 37.63, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 40.71, "power_watts_peak": 43.3, "energy_joules_est": 44.64, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:15:00.092030"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1157.368, "latencies_ms": [1157.368], "images_per_second": 0.864, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "A group of people are gathered around a wooden bar, seemingly in a wine tasting event or similar social gathering. The bar features various wine bottles and glasses, indicating a focus on wine tasting.  The setting appears to be indoors, with a wooden barrel visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.28, 38.69, 38.69, 38.69, 38.69, 38.69, 43.61, 43.61, 43.61, 43.61, 43.96, 43.96], "power_watts_avg": 41.59, "power_watts_peak": 43.96, "energy_joules_est": 48.15, "sample_count": 12, "duration_seconds": 1.158}, "timestamp": "2026-01-11T13:15:01.306039"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1039.374, "latencies_ms": [1039.374], "images_per_second": 0.962, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The room has a warm color scheme with teal walls and wooden elements. The lighting is soft and diffused, creating a pleasant atmosphere. The materials appear to be natural wood and glass, contributing to the overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [43.96, 43.96, 43.96, 42.63, 42.63, 42.63, 42.63, 42.63, 42.43, 42.43, 42.43], "power_watts_avg": 42.94, "power_watts_peak": 43.96, "energy_joules_est": 44.65, "sample_count": 11, "duration_seconds": 1.04}, "timestamp": "2026-01-11T13:15:02.418406"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 416.861, "latencies_ms": [416.861], "images_per_second": 2.399, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "Two white birds stand in a grassy field near a harbor filled with boats.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [42.43, 42.43, 35.66, 35.66, 35.66], "power_watts_avg": 38.37, "power_watts_peak": 42.43, "energy_joules_est": 16.01, "sample_count": 5, "duration_seconds": 0.417}, "timestamp": "2026-01-11T13:15:02.927485"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 820.214, "latencies_ms": [820.214], "images_per_second": 1.219, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "boats: 4\npiers: 2\nseagulls: 2\ngrass: 8\nsky: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.66, 35.66, 38.85, 38.85, 38.85, 38.85, 38.85, 35.51, 35.51], "power_watts_avg": 37.4, "power_watts_peak": 38.85, "energy_joules_est": 30.7, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:15:03.837521"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 683.632, "latencies_ms": [683.632], "images_per_second": 1.463, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the boats and structures in the background. The foreground is relatively open and grassy, while the background features more structures and boats.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.51, 35.51, 35.51, 35.44, 35.44, 35.44, 35.44], "power_watts_avg": 35.47, "power_watts_peak": 35.51, "energy_joules_est": 24.27, "sample_count": 7, "duration_seconds": 0.684}, "timestamp": "2026-01-11T13:15:04.547382"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 863.643, "latencies_ms": [863.643], "images_per_second": 1.158, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a marshy area with a harbor filled with fishing boats and equipment. Two white birds, possibly egrets, are visible in the foreground. The sky is cloudy, suggesting a potentially overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [35.44, 37.07, 37.07, 37.07, 37.07, 37.07, 36.57, 36.57, 36.57], "power_watts_avg": 36.72, "power_watts_peak": 37.07, "energy_joules_est": 31.74, "sample_count": 9, "duration_seconds": 0.864}, "timestamp": "2026-01-11T13:15:05.459263"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 743.86, "latencies_ms": [743.86], "images_per_second": 1.344, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The sky is cloudy and gray. The grass is tall and green. The boats are primarily white and blue. The overall scene suggests a coastal or maritime setting.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [36.57, 36.57, 39.28, 39.28, 39.28, 39.28, 39.28, 35.79], "power_watts_avg": 38.17, "power_watts_peak": 39.28, "energy_joules_est": 28.4, "sample_count": 8, "duration_seconds": 0.744}, "timestamp": "2026-01-11T13:15:06.266025"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 651.802, "latencies_ms": [651.802], "images_per_second": 1.534, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A man in work attire kneels beside a white toilet in a bathroom, appearing to inspect or repair it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.5, "ram_available_mb": 109420.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [35.79, 35.79, 35.79, 35.79, 41.28, 41.28, 41.28], "power_watts_avg": 38.14, "power_watts_peak": 41.28, "energy_joules_est": 24.89, "sample_count": 7, "duration_seconds": 0.653}, "timestamp": "2026-01-11T13:15:06.977298"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1327.467, "latencies_ms": [1327.467], "images_per_second": 0.753, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "toilet: 1\nsink: 1\nmirror: 1\ntoilet paper: 1\ngloves: 2\npipes: 1\nfloor: 1\nwall tiles: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.5, "ram_available_mb": 109420.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.28, 41.28, 45.93, 45.93, 45.93, 45.93, 45.93, 41.09, 41.09, 41.09, 41.09, 41.09, 36.25, 36.25], "power_watts_avg": 42.16, "power_watts_peak": 45.93, "energy_joules_est": 55.97, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-11T13:15:08.388192"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 965.201, "latencies_ms": [965.201], "images_per_second": 1.036, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main object is a person kneeling in front of a toilet, positioned near the toilet bowl. The background includes tiled walls and a sink, suggesting the bathroom is situated in a space with limited space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [36.25, 36.25, 36.25, 39.15, 39.15, 39.15, 39.15, 39.15, 39.97, 39.97], "power_watts_avg": 38.44, "power_watts_peak": 39.97, "energy_joules_est": 37.12, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-11T13:15:09.397462"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 837.736, "latencies_ms": [837.736], "images_per_second": 1.194, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A man is kneeling beside a white toilet in a bathroom, appearing to be cleaning or inspecting the toilet. The bathroom features black and white checkered tiles on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [39.97, 39.97, 40.77, 40.77, 40.77, 40.77, 40.77, 41.53, 41.53], "power_watts_avg": 40.76, "power_watts_peak": 41.53, "energy_joules_est": 34.17, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:15:10.306983"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 739.776, "latencies_ms": [739.776], "images_per_second": 1.352, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The bathroom is black and white. The lighting appears to be artificial, likely from overhead fixtures. The materials appear to be standard bathroom fixtures. The floor is tiled.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [41.53, 41.53, 41.53, 43.19, 43.19, 43.19, 43.19, 43.19], "power_watts_avg": 42.56, "power_watts_peak": 43.19, "energy_joules_est": 31.49, "sample_count": 8, "duration_seconds": 0.74}, "timestamp": "2026-01-11T13:15:11.115733"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 519.681, "latencies_ms": [519.681], "images_per_second": 1.924, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A group of six people stand on a snowy mountain slope, preparing to ski down the snow-covered trail.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.06, 40.06, 40.06, 40.06, 40.06, 35.37], "power_watts_avg": 39.28, "power_watts_peak": 40.06, "energy_joules_est": 20.43, "sample_count": 6, "duration_seconds": 0.52}, "timestamp": "2026-01-11T13:15:11.724388"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 907.846, "latencies_ms": [907.846], "images_per_second": 1.102, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "mountains: 5\nsnow: 5\nskiers: 4\nsnowboarders: 2\ntracks: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 109421.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13074.9, "ram_available_mb": 109431.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.37, 35.37, 35.37, 35.37, 39.7, 39.7, 39.7, 39.7, 39.7, 35.53], "power_watts_avg": 37.55, "power_watts_peak": 39.7, "energy_joules_est": 34.1, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:15:12.734364"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 691.832, "latencies_ms": [691.832], "images_per_second": 1.445, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the snow-covered mountain in the background. The group is situated near the base of the mountain, suggesting they are at a relatively low elevation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.9, "ram_available_mb": 109431.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.53, 35.53, 35.53, 35.53, 35.01, 35.01, 35.01], "power_watts_avg": 35.3, "power_watts_peak": 35.53, "energy_joules_est": 24.44, "sample_count": 7, "duration_seconds": 0.692}, "timestamp": "2026-01-11T13:15:13.442768"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1014.395, "latencies_ms": [1014.395], "images_per_second": 0.986, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A group of people are gathered on a snowy mountain, preparing for a skiing trip. They are surrounded by tracks in the snow, indicating recent activity. The scene is set against a clear, bright blue sky, highlighting the pristine beauty of the snow-covered landscape.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 39.31, 39.31, 39.31, 39.31, 39.31, 36.5, 36.5, 36.5, 36.5], "power_watts_avg": 37.5, "power_watts_peak": 39.31, "energy_joules_est": 38.05, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-11T13:15:14.552517"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 667.842, "latencies_ms": [667.842], "images_per_second": 1.497, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The snow is bright white, reflecting sunlight, creating a striking contrast against the dark rock formations. The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 16.0}, "power_stats": {"power_watts_samples": [36.5, 32.24, 32.24, 32.24, 32.24, 32.24, 35.0], "power_watts_avg": 33.25, "power_watts_peak": 36.5, "energy_joules_est": 22.21, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:15:15.260651"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 736.673, "latencies_ms": [736.673], "images_per_second": 1.357, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white bowl contains a serving of white rice topped with a vibrant red and orange chili mixture, accompanied by steamed broccoli.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 35.0, 45.22, 45.22, 45.22, 45.22], "power_watts_avg": 40.11, "power_watts_peak": 45.22, "energy_joules_est": 29.56, "sample_count": 8, "duration_seconds": 0.737}, "timestamp": "2026-01-11T13:15:16.069443"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1243.031, "latencies_ms": [1243.031], "images_per_second": 0.804, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "chili: 2\nbroccoli: 2\nrice: 1\nbeans: 1\ncarrots: 1\nonions: 1\ntomatoes: 1\npeppers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.22, 41.88, 41.88, 41.88, 41.88, 41.88, 42.25, 42.25, 42.25, 42.25, 42.25, 43.53, 43.53], "power_watts_avg": 42.53, "power_watts_peak": 45.22, "energy_joules_est": 52.88, "sample_count": 13, "duration_seconds": 1.243}, "timestamp": "2026-01-11T13:15:17.381971"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 797.528, "latencies_ms": [797.528], "images_per_second": 1.254, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The bowl is positioned in the foreground, with the broccoli to the left and the chili to the right. The rice is situated in the background, partially obscured by the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 43.53, 40.63, 40.63, 40.63, 40.63, 40.63], "power_watts_avg": 41.72, "power_watts_peak": 43.53, "energy_joules_est": 33.29, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:15:18.191073"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 646.922, "latencies_ms": [646.922], "images_per_second": 1.546, "prompt_tokens": 19, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A white bowl contains a meal of rice, beans, and broccoli. The dish is served on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.98, 41.98, 41.98, 41.98, 41.98, 44.71, 44.71], "power_watts_avg": 42.76, "power_watts_peak": 44.71, "energy_joules_est": 27.68, "sample_count": 7, "duration_seconds": 0.647}, "timestamp": "2026-01-11T13:15:18.899611"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 832.26, "latencies_ms": [832.26], "images_per_second": 1.202, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The dish features a vibrant red sauce, contrasting with the bright green broccoli and white rice. The lighting is soft and warm, creating a pleasant and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.71, 44.71, 51.09, 51.09, 51.09, 51.09, 51.09, 42.17, 42.17], "power_watts_avg": 47.69, "power_watts_peak": 51.09, "energy_joules_est": 39.7, "sample_count": 9, "duration_seconds": 0.833}, "timestamp": "2026-01-11T13:15:19.808582"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 756.189, "latencies_ms": [756.189], "images_per_second": 1.322, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A person in black pants and black and white Vans sneakers is riding a skateboard on a small wooden ramp in a grassy area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [42.17, 42.17, 42.17, 43.06, 43.06, 43.06, 43.06, 43.06], "power_watts_avg": 42.73, "power_watts_peak": 43.06, "energy_joules_est": 32.33, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:15:20.618093"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1052.554, "latencies_ms": [1052.554], "images_per_second": 0.95, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "shoe: 2\nskateboard: 1\nboard: 1\ngrass: 2\nwood: 4\npants: 1\nground: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.51, 40.51, 40.51, 40.51, 40.51, 41.74, 41.74, 41.74, 41.74, 41.74, 42.42], "power_watts_avg": 41.24, "power_watts_peak": 42.42, "energy_joules_est": 43.42, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:15:21.731798"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 903.303, "latencies_ms": [903.303], "images_per_second": 1.107, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, moving towards the background. The wooden planks and grass create a sense of depth and distance between the skateboarder and the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.42, 42.42, 42.42, 42.42, 41.58, 41.58, 41.58, 41.58, 41.58], "power_watts_avg": 41.96, "power_watts_peak": 42.42, "energy_joules_est": 37.92, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:15:22.640858"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1103.667, "latencies_ms": [1103.667], "images_per_second": 0.906, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A person is skateboarding on a wooden platform in a grassy area. They are wearing Vans sneakers and appear to be performing a trick or maneuver. The setting suggests an outdoor recreational space, possibly a park or a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.57, 41.57, 41.57, 41.57, 41.57, 42.26, 42.26, 42.26, 42.26, 42.26, 41.99], "power_watts_avg": 41.92, "power_watts_peak": 42.26, "energy_joules_est": 46.28, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-11T13:15:23.749549"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 912.837, "latencies_ms": [912.837], "images_per_second": 1.095, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skateboarder is wearing black and white sneakers. The scene is lit by natural sunlight, creating a bright and airy atmosphere. The skateboard appears to be made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 41.99, 42.52, 42.52, 42.52, 42.52, 42.52, 42.38], "power_watts_avg": 42.29, "power_watts_peak": 42.52, "energy_joules_est": 38.61, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-11T13:15:24.758450"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 635.707, "latencies_ms": [635.707], "images_per_second": 1.573, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A bunch of ripe yellow bananas is arranged on a wooden table, partially obscuring a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 40.6, 40.6, 40.6], "power_watts_avg": 41.62, "power_watts_peak": 42.38, "energy_joules_est": 26.49, "sample_count": 7, "duration_seconds": 0.636}, "timestamp": "2026-01-11T13:15:25.466110"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 961.841, "latencies_ms": [961.841], "images_per_second": 1.04, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "bananas: 4\nkeyboard: 1\nlaptop: 1\ncup: 1\ntable: 1\npaper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [40.6, 40.6, 45.82, 45.82, 45.82, 45.82, 45.82, 41.27, 41.27, 41.27], "power_watts_avg": 43.41, "power_watts_peak": 45.82, "energy_joules_est": 41.77, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-11T13:15:26.477774"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 826.049, "latencies_ms": [826.049], "images_per_second": 1.211, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a computer keyboard and monitor visible in the background. The bananas are situated near the center, partially obscuring the keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.27, 41.27, 41.16, 41.16, 41.16, 41.16, 41.16, 41.71, 41.71], "power_watts_avg": 41.31, "power_watts_peak": 41.71, "energy_joules_est": 34.14, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:15:27.387638"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 730.26, "latencies_ms": [730.26], "images_per_second": 1.369, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene is set on a wooden desk with a computer keyboard and a computer monitor in the background. A bunch of ripe bananas is prominently featured in the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.71, 41.71, 41.71, 46.61, 46.61, 46.61, 46.61, 46.61], "power_watts_avg": 44.78, "power_watts_peak": 46.61, "energy_joules_est": 32.71, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:15:28.195993"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 905.614, "latencies_ms": [905.614], "images_per_second": 1.104, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bananas are yellow, indicating they are ripe. The lighting appears to be natural, possibly from daylight, creating a warm ambiance. The bananas appear to be made of natural materials like fruit and possibly plant matter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.06, 41.06, 41.06, 41.06, 41.06, 41.39, 41.39, 41.39, 41.39, 41.32], "power_watts_avg": 41.22, "power_watts_peak": 41.39, "energy_joules_est": 37.36, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-11T13:15:29.206832"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 713.547, "latencies_ms": [713.547], "images_per_second": 1.401, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A plate of stir-fried chicken, cauliflower, broccoli, carrots, and rice is presented on a wooden table, accompanied by a fork and a glass of water.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.32, 41.32, 41.32, 41.32, 35.22, 35.22, 35.22, 35.22], "power_watts_avg": 38.27, "power_watts_peak": 41.32, "energy_joules_est": 27.33, "sample_count": 8, "duration_seconds": 0.714}, "timestamp": "2026-01-11T13:15:30.017175"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1307.914, "latencies_ms": [1307.914], "images_per_second": 0.765, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "chicken: 6\nrice: 1\ncarrots: 3\nbroccoli: 2\ncauliflower: 2\ncorn: 1\nsauce: 1\nfork: 1\nglass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.22, 36.69, 36.69, 36.69, 36.69, 36.69, 34.94, 34.94, 34.94, 34.94, 34.94, 33.42, 33.42, 33.42], "power_watts_avg": 35.26, "power_watts_peak": 36.69, "energy_joules_est": 46.12, "sample_count": 14, "duration_seconds": 1.308}, "timestamp": "2026-01-11T13:15:31.427937"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 837.633, "latencies_ms": [837.633], "images_per_second": 1.194, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The plate is positioned in the foreground of the image, with the main dish (rice and vegetables) occupying the central area. The table occupies the background, and the glass of water is situated near the top left corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [33.42, 33.42, 35.38, 35.38, 35.38, 35.38, 35.38, 35.41, 35.41], "power_watts_avg": 34.95, "power_watts_peak": 35.41, "energy_joules_est": 29.3, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:15:32.340372"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 912.495, "latencies_ms": [912.495], "images_per_second": 1.096, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a plate of Asian cuisine featuring white rice, chicken, broccoli, carrots, and cauliflower, served on a colorful plate. A glass of water and a fork are also present on the wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.41, 35.41, 35.41, 36.12, 36.12, 36.12, 36.12, 36.12, 36.06, 36.06], "power_watts_avg": 35.89, "power_watts_peak": 36.12, "energy_joules_est": 32.77, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-11T13:15:33.351377"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1047.45, "latencies_ms": [1047.45], "images_per_second": 0.955, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The plate features a vibrant mix of colors, including orange, green, and white. The lighting is soft and warm, creating a pleasant atmosphere. The food appears to be made of high-quality ingredients, enhancing its visual appeal. The plate rests on a wooden table, suggesting it's ready to be enjoyed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.06, 36.06, 36.06, 35.4, 35.4, 35.4, 35.4, 35.4, 35.47, 35.47, 35.47], "power_watts_avg": 35.6, "power_watts_peak": 36.06, "energy_joules_est": 37.3, "sample_count": 11, "duration_seconds": 1.048}, "timestamp": "2026-01-11T13:15:34.463005"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 665.956, "latencies_ms": [665.956], "images_per_second": 1.502, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A young girl in a white dress and colorful skirt is playing with a Wii remote while several people socialize and enjoy themselves in a cozy living room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [35.47, 35.47, 36.03, 36.03, 36.03, 36.03, 36.03], "power_watts_avg": 35.87, "power_watts_peak": 36.03, "energy_joules_est": 23.91, "sample_count": 7, "duration_seconds": 0.667}, "timestamp": "2026-01-11T13:15:35.174409"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1129.123, "latencies_ms": [1129.123], "images_per_second": 0.886, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "woman: 2\ngirl: 1\ndress: 1\nskirt: 1\ngirl: 1\ntable: 1\nchair: 1\nrug: 1\nstairs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.01, 36.01, 36.01, 36.01, 36.01, 36.48, 36.48, 36.48, 36.48, 36.48, 36.68, 36.68], "power_watts_avg": 36.32, "power_watts_peak": 36.68, "energy_joules_est": 41.02, "sample_count": 12, "duration_seconds": 1.13}, "timestamp": "2026-01-11T13:15:36.386948"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 596.991, "latencies_ms": [596.991], "images_per_second": 1.675, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The girl is positioned in the foreground, interacting with the partygoers. The living room extends in the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [36.68, 36.68, 36.68, 35.62, 35.62, 35.62], "power_watts_avg": 36.15, "power_watts_peak": 36.68, "energy_joules_est": 21.6, "sample_count": 6, "duration_seconds": 0.597}, "timestamp": "2026-01-11T13:15:36.995972"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 986.929, "latencies_ms": [986.929], "images_per_second": 1.013, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "A group of people are gathered in a living room, enjoying a casual social gathering. A young girl is actively playing a game, possibly wii, while others watch and engage in conversation. The room features a couch, a coffee table, and a dining area in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.62, 35.62, 38.79, 38.79, 38.79, 38.79, 38.79, 36.75, 36.75, 36.75], "power_watts_avg": 37.54, "power_watts_peak": 38.79, "energy_joules_est": 37.07, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-11T13:15:38.005382"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 838.012, "latencies_ms": [838.012], "images_per_second": 1.193, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The room is lit by natural light from skylights, creating a warm and inviting atmosphere. The walls are painted white, and the floor is made of polished wood, complementing the overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 13077.8, "ram_available_mb": 109428.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.75, 37.03, 37.03, 37.03, 37.03, 37.03, 36.54, 36.54, 36.54], "power_watts_avg": 36.83, "power_watts_peak": 37.03, "energy_joules_est": 30.88, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:15:38.912826"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 666.681, "latencies_ms": [666.681], "images_per_second": 1.5, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two men in formal attire are shaking hands at a banquet, engaging in a business or professional interaction.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.54, 36.54, 40.57, 40.57, 40.57, 40.57, 40.57], "power_watts_avg": 39.42, "power_watts_peak": 40.57, "energy_joules_est": 26.3, "sample_count": 7, "duration_seconds": 0.667}, "timestamp": "2026-01-11T13:15:39.623957"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1118.427, "latencies_ms": [1118.427], "images_per_second": 0.894, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "man: 2\ntie: 1\nglasses: 1\nsuit: 2\ntable: 2\nplate: 2\nwater: 1\nfood: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.83, 40.83, 40.83, 40.83, 40.83, 43.76, 43.76, 43.76, 43.76, 43.76, 42.38, 42.38], "power_watts_avg": 42.31, "power_watts_peak": 43.76, "energy_joules_est": 47.34, "sample_count": 12, "duration_seconds": 1.119}, "timestamp": "2026-01-11T13:15:40.832129"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 861.006, "latencies_ms": [861.006], "images_per_second": 1.161, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the man on the left shaking hands with the man on the right. The background features other individuals and tables, suggesting a larger event or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 41.0, 41.0, 41.0, 41.0, 41.0, 40.77], "power_watts_avg": 41.43, "power_watts_peak": 42.38, "energy_joules_est": 35.7, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:15:41.740001"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1037.312, "latencies_ms": [1037.312], "images_per_second": 0.964, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a formal event or conference taking place in a large, well-lit room.  Two men in suits are shaking hands and engaging in a conversation amidst other attendees and tables filled with food and beverages.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.77, 40.77, 40.77, 40.77, 41.26, 41.26, 41.26, 41.26, 41.26, 41.32, 41.32], "power_watts_avg": 41.09, "power_watts_peak": 41.32, "energy_joules_est": 42.64, "sample_count": 11, "duration_seconds": 1.038}, "timestamp": "2026-01-11T13:15:42.850387"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1111.356, "latencies_ms": [1111.356], "images_per_second": 0.9, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The room is lit with warm yellow lighting, creating a welcoming atmosphere. The walls are made of wood, and the tables are covered with white tablecloths. The men are dressed in formal attire, further emphasizing the event's formality.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.32, 41.32, 41.32, 41.06, 41.06, 41.06, 41.06, 41.06, 41.07, 41.07, 41.07, 41.07], "power_watts_avg": 41.13, "power_watts_peak": 41.32, "energy_joules_est": 45.72, "sample_count": 12, "duration_seconds": 1.112}, "timestamp": "2026-01-11T13:15:44.060272"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 685.597, "latencies_ms": [685.597], "images_per_second": 1.459, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man in a white dress shirt and striped tie stands in front of a dark background, looking off to the side with a thoughtful expression.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.07, 31.52, 31.52, 31.52, 31.52, 31.52, 40.67], "power_watts_avg": 34.19, "power_watts_peak": 41.07, "energy_joules_est": 23.47, "sample_count": 7, "duration_seconds": 0.687}, "timestamp": "2026-01-11T13:15:44.767543"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1043.573, "latencies_ms": [1043.573], "images_per_second": 0.958, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "shirt: 1\ntie: 1\npocket: 1\nhand: 1\nface: 1\nhair: 1\neyes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.67, 40.67, 40.67, 40.67, 52.1, 52.1, 52.1, 52.1, 52.1, 42.13, 42.13], "power_watts_avg": 46.13, "power_watts_peak": 52.1, "energy_joules_est": 48.16, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-11T13:15:45.876833"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 887.825, "latencies_ms": [887.825], "images_per_second": 1.126, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the background blurred and out of focus. The man is standing near a dark object, possibly a window or door, which suggests he is indoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.13, 42.13, 42.13, 40.98, 40.98, 40.98, 40.98, 40.98, 41.4], "power_watts_avg": 41.41, "power_watts_peak": 42.13, "energy_joules_est": 36.78, "sample_count": 9, "duration_seconds": 0.888}, "timestamp": "2026-01-11T13:15:46.787471"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 786.538, "latencies_ms": [786.538], "images_per_second": 1.271, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A man is standing indoors, wearing a white dress shirt and a striped tie. He appears to be in a professional or business setting, possibly a meeting or office.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.4, 41.4, 41.4, 41.4, 42.78, 42.78, 42.78, 42.78], "power_watts_avg": 42.09, "power_watts_peak": 42.78, "energy_joules_est": 33.13, "sample_count": 8, "duration_seconds": 0.787}, "timestamp": "2026-01-11T13:15:47.596863"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1081.054, "latencies_ms": [1081.054], "images_per_second": 0.925, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is wearing a light yellow dress shirt and a dark-colored tie with thin, light-colored stripes. His hair is dark and neatly styled. The lighting in the image is soft and somewhat dim, creating a subdued atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.78, 41.68, 41.68, 41.68, 41.68, 41.68, 42.01, 42.01, 42.01, 42.01, 42.01], "power_watts_avg": 41.93, "power_watts_peak": 42.78, "energy_joules_est": 45.35, "sample_count": 11, "duration_seconds": 1.082}, "timestamp": "2026-01-11T13:15:48.708311"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 623.964, "latencies_ms": [623.964], "images_per_second": 1.603, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The living room features a plaid couch, a wooden TV stand with a TV, a red plaid chair, and a whiteboard with writing on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 42.46, 42.46, 36.34, 36.34, 36.34], "power_watts_avg": 39.84, "power_watts_peak": 42.46, "energy_joules_est": 24.87, "sample_count": 7, "duration_seconds": 0.624}, "timestamp": "2026-01-11T13:15:49.417955"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1008.485, "latencies_ms": [1008.485], "images_per_second": 0.992, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "chair: 2\ncouch: 2\ntv: 1\ncabinet: 1\nwhiteboard: 1\npicture: 1\nspeakers: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [36.34, 36.34, 39.48, 39.48, 39.48, 39.48, 39.48, 35.57, 35.57, 35.57, 35.57], "power_watts_avg": 37.49, "power_watts_peak": 39.48, "energy_joules_est": 37.83, "sample_count": 11, "duration_seconds": 1.009}, "timestamp": "2026-01-11T13:15:50.530000"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 604.449, "latencies_ms": [604.449], "images_per_second": 1.654, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The chair is positioned to the left of the couch, closer to the viewer. The couch is situated further back in the room, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [35.57, 33.64, 33.64, 33.64, 33.64, 33.64, 35.53], "power_watts_avg": 34.19, "power_watts_peak": 35.57, "energy_joules_est": 20.68, "sample_count": 7, "duration_seconds": 0.605}, "timestamp": "2026-01-11T13:15:51.238697"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1086.613, "latencies_ms": [1086.613], "images_per_second": 0.92, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The scene depicts a cozy living room or common area with comfortable seating arrangements, including a plaid couch and a plaid armchair. A television set is positioned nearby, offering entertainment options. The room features a whiteboard with notes, a framed black and white photo, and a small wooden cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.53, 35.53, 35.53, 35.53, 38.45, 38.45, 38.45, 38.45, 38.45, 35.53, 35.53], "power_watts_avg": 36.86, "power_watts_peak": 38.45, "energy_joules_est": 40.07, "sample_count": 11, "duration_seconds": 1.087}, "timestamp": "2026-01-11T13:15:52.350568"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1109.551, "latencies_ms": [1109.551], "images_per_second": 0.901, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The room features a plaid couch in blue and red hues, complemented by a plaid armchair in red and brown tones. The lighting is soft and warm, creating a cozy atmosphere. The walls are painted a pale yellow, and the floor is carpeted in a neutral tone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.53, 35.53, 35.53, 36.86, 36.86, 36.86, 36.86, 36.86, 36.9, 36.9, 36.9, 36.9], "power_watts_avg": 36.54, "power_watts_peak": 36.9, "energy_joules_est": 40.56, "sample_count": 12, "duration_seconds": 1.11}, "timestamp": "2026-01-11T13:15:53.563926"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 790.426, "latencies_ms": [790.426], "images_per_second": 1.265, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A surfer in a yellow wetsuit rides a wave on a white surfboard with orange fins, skillfully carving through the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [36.9, 31.25, 31.25, 31.25, 31.25, 31.25, 41.81, 41.81], "power_watts_avg": 34.59, "power_watts_peak": 41.81, "energy_joules_est": 27.36, "sample_count": 8, "duration_seconds": 0.791}, "timestamp": "2026-01-11T13:15:54.375617"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1308.862, "latencies_ms": [1308.862], "images_per_second": 0.764, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "surfboard: 1\nwetsuit: 1\nwater: 1\nwaves: 1\nsurfer: 1\nsurfboard: 1\nwetsuit: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.81, 41.81, 41.81, 54.07, 54.07, 54.07, 54.07, 54.07, 43.68, 43.68, 43.68, 43.68, 43.68, 33.11], "power_watts_avg": 46.23, "power_watts_peak": 54.07, "energy_joules_est": 60.54, "sample_count": 14, "duration_seconds": 1.309}, "timestamp": "2026-01-11T13:15:55.789132"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 765.8, "latencies_ms": [765.8], "images_per_second": 1.306, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The wave is further in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.11, 33.11, 33.11, 33.11, 41.9, 41.9, 41.9, 41.9], "power_watts_avg": 37.5, "power_watts_peak": 41.9, "energy_joules_est": 28.74, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-11T13:15:56.599249"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 848.632, "latencies_ms": [848.632], "images_per_second": 1.178, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A surfer in a yellow wetsuit skillfully rides a wave on a white surfboard. The setting appears to be a river or ocean with choppy water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [41.9, 41.03, 41.03, 41.03, 41.03, 41.03, 42.98, 42.98, 42.98], "power_watts_avg": 41.78, "power_watts_peak": 42.98, "energy_joules_est": 35.48, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:15:57.509922"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1121.899, "latencies_ms": [1121.899], "images_per_second": 0.891, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The surfer is wearing a yellow top and dark shorts. The wave is teal and white, indicating a likely cloudy or overcast day. The surfboard appears to be made of a light-colored material, possibly fiberglass or foam.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.98, 46.05, 46.05, 46.05, 46.05, 46.05, 42.39, 42.39, 42.39, 42.39, 42.39, 39.73], "power_watts_avg": 43.74, "power_watts_peak": 46.05, "energy_joules_est": 49.1, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-11T13:15:58.723143"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 637.903, "latencies_ms": [637.903], "images_per_second": 1.568, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A long-haired black cat is sitting in front of a computer monitor, attentively gazing at the content displayed.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.73, 39.73, 39.73, 39.73, 40.78, 40.78, 40.78], "power_watts_avg": 40.18, "power_watts_peak": 40.78, "energy_joules_est": 25.65, "sample_count": 7, "duration_seconds": 0.638}, "timestamp": "2026-01-11T13:15:59.434099"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1218.106, "latencies_ms": [1218.106], "images_per_second": 0.821, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "laptop: 2\nmouse: 1\nkeyboard: 1\nmousepad: 1\ncat: 1\ntelephone: 1\nmousepad: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.78, 40.78, 47.23, 47.23, 47.23, 47.23, 47.23, 41.45, 41.45, 41.45, 41.45, 41.45, 35.28], "power_watts_avg": 43.09, "power_watts_peak": 47.23, "energy_joules_est": 52.52, "sample_count": 13, "duration_seconds": 1.219}, "timestamp": "2026-01-11T13:16:00.744154"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 780.839, "latencies_ms": [780.839], "images_per_second": 1.281, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, partially obscuring the laptop screen. The laptop is situated near the cat, and the cat is situated near the monitor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.28, 35.28, 35.28, 35.28, 41.03, 41.03, 41.03, 41.03], "power_watts_avg": 38.16, "power_watts_peak": 41.03, "energy_joules_est": 29.8, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:16:01.554563"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 761.225, "latencies_ms": [761.225], "images_per_second": 1.314, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A cat is sitting in front of a computer monitor, seemingly observing the screen. The computer is situated on a desk alongside a laptop and a telephone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [41.03, 42.07, 42.07, 42.07, 42.07, 42.07, 42.2, 42.2], "power_watts_avg": 41.97, "power_watts_peak": 42.2, "energy_joules_est": 31.96, "sample_count": 8, "duration_seconds": 0.762}, "timestamp": "2026-01-11T13:16:02.362598"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1060.087, "latencies_ms": [1060.087], "images_per_second": 0.943, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The cat is primarily black with gray fur. The lighting in the image appears to be soft and warm, likely from natural light coming in from the window. The desk surface appears to be made of a light-colored material, possibly wood or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.2, 42.2, 42.2, 51.69, 51.69, 51.69, 51.69, 51.69, 41.84, 41.84, 41.84], "power_watts_avg": 46.42, "power_watts_peak": 51.69, "energy_joules_est": 49.27, "sample_count": 11, "duration_seconds": 1.061}, "timestamp": "2026-01-11T13:16:03.476313"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 601.46, "latencies_ms": [601.46], "images_per_second": 1.663, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A man and a child are cutting a red ribbon together in front of a building, accompanied by a crowd of people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.84, 41.84, 37.1, 37.1, 37.1, 37.1], "power_watts_avg": 38.68, "power_watts_peak": 41.84, "energy_joules_est": 23.29, "sample_count": 6, "duration_seconds": 0.602}, "timestamp": "2026-01-11T13:16:04.085631"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1085.272, "latencies_ms": [1085.272], "images_per_second": 0.921, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "red ribbon: 2\nscissors: 2\nballoon: 1\nhelmet: 1\nchild: 1\nman: 3\nwoman: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.1, 41.14, 41.14, 41.14, 41.14, 41.14, 47.63, 47.63, 47.63, 47.63, 47.63], "power_watts_avg": 43.72, "power_watts_peak": 47.63, "energy_joules_est": 47.47, "sample_count": 11, "duration_seconds": 1.086}, "timestamp": "2026-01-11T13:16:05.195860"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 946.054, "latencies_ms": [946.054], "images_per_second": 1.057, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scissors are positioned in the foreground, cutting the red ribbon. The crowd surrounds the scissors, observing the event. The scene appears to be taking place on a street or sidewalk, with a building visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.25, 42.25, 42.25, 42.25, 42.25, 42.19, 42.19, 42.19, 42.19, 42.19], "power_watts_avg": 42.22, "power_watts_peak": 42.25, "energy_joules_est": 39.97, "sample_count": 10, "duration_seconds": 0.947}, "timestamp": "2026-01-11T13:16:06.204513"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1260.988, "latencies_ms": [1260.988], "images_per_second": 0.793, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The scene depicts a lively outdoor event, possibly a ribbon-cutting ceremony, where a young child is cutting a red ribbon with a pair of scissors. Several adults and children surround the child, observing and participating in the event. A blue balloon adds a festive touch to the atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.8, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 42.28, 42.28, 42.28, 41.3, 41.3, 41.3, 41.3, 41.3, 41.35, 41.35, 41.35], "power_watts_avg": 41.69, "power_watts_peak": 42.28, "energy_joules_est": 52.6, "sample_count": 13, "duration_seconds": 1.262}, "timestamp": "2026-01-11T13:16:07.516093"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 925.94, "latencies_ms": [925.94], "images_per_second": 1.08, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The red ribbon cutting is bright and vibrant, contrasting with the dark clothing of the adults and the light-colored clothing of the children. The lighting appears to be natural daylight, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.8, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 47.0}, "power_stats": {"power_watts_samples": [41.35, 35.05, 35.05, 35.05, 35.05, 35.05, 41.69, 41.69, 41.69, 41.69], "power_watts_avg": 38.34, "power_watts_peak": 41.69, "energy_joules_est": 35.52, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-11T13:16:08.525164"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 801.169, "latencies_ms": [801.169], "images_per_second": 1.248, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A First Group bus numbered 65745 is parked on the side of the road, displaying its free Wi-Fi and board signage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 37.0}, "power_stats": {"power_watts_samples": [41.69, 41.35, 41.35, 41.35, 41.35, 41.35, 40.72, 40.72], "power_watts_avg": 41.23, "power_watts_peak": 41.69, "energy_joules_est": 33.06, "sample_count": 8, "duration_seconds": 0.802}, "timestamp": "2026-01-11T13:16:09.333283"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1439.783, "latencies_ms": [1439.783], "images_per_second": 0.695, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bus: 1\nwindshield wipers: 2\nheadlights: 4\nbumper: 1\nside mirror: 1\ndoor: 1\nlicense plate: 1\nstreet: 1\nbuildings: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.72, 40.72, 40.72, 49.81, 49.81, 49.81, 49.81, 49.81, 42.49, 42.49, 42.49, 42.49, 42.49, 32.41, 32.41], "power_watts_avg": 43.23, "power_watts_peak": 49.81, "energy_joules_est": 62.26, "sample_count": 15, "duration_seconds": 1.44}, "timestamp": "2026-01-11T13:16:10.845762"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 828.973, "latencies_ms": [828.973], "images_per_second": 1.206, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving towards the left side of the image. The background features buildings and a street with pedestrians, creating a sense of a typical urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.41, 32.41, 32.41, 41.33, 41.33, 41.33, 41.33, 41.33, 41.19], "power_watts_avg": 38.34, "power_watts_peak": 41.33, "energy_joules_est": 31.8, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-11T13:16:11.752175"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1255.985, "latencies_ms": [1255.985], "images_per_second": 0.796, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a city street with a First Group bus parked at the curb. The bus is labeled \"First Group\" and has a \"Free Wi-Fi on Board\" sign displayed. The street is lined with buildings, and pedestrians can be seen walking nearby.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.19, 41.19, 41.19, 41.19, 40.12, 40.12, 40.12, 40.12, 40.12, 40.38, 40.38, 40.38, 40.38], "power_watts_avg": 40.53, "power_watts_peak": 41.19, "energy_joules_est": 50.94, "sample_count": 13, "duration_seconds": 1.257}, "timestamp": "2026-01-11T13:16:13.063244"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 814.592, "latencies_ms": [814.592], "images_per_second": 1.228, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The bus is primarily white with pink and blue accents. The bus has multiple headlights and fog lights. The sky is overcast, suggesting cloudy weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.38, 32.2, 32.2, 32.2, 32.2, 32.2, 41.46, 41.46, 41.46], "power_watts_avg": 36.2, "power_watts_peak": 41.46, "energy_joules_est": 29.49, "sample_count": 9, "duration_seconds": 0.815}, "timestamp": "2026-01-11T13:16:13.971861"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 640.875, "latencies_ms": [640.875], "images_per_second": 1.56, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man is sitting cross-legged on a wooden floor in front of a large mirror, capturing his reflection while holding a phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.6, "ram_available_mb": 109431.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.46, 41.46, 46.78, 46.78, 46.78, 46.78, 46.78], "power_watts_avg": 45.26, "power_watts_peak": 46.78, "energy_joules_est": 29.04, "sample_count": 7, "duration_seconds": 0.642}, "timestamp": "2026-01-11T13:16:14.683483"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1505.038, "latencies_ms": [1505.038], "images_per_second": 0.664, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "mirror: 1\nwooden frame: 1\nman's reflection: 1\ngreen shirt: 1\nslippers: 1\nwindow: 1\nbed: 1\ntoys: 1\ncabinet: 1\nrug: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.85, 40.85, 40.85, 40.85, 40.85, 45.97, 45.97, 45.97, 45.97, 45.97, 41.56, 41.56, 41.56, 41.56, 41.56], "power_watts_avg": 42.79, "power_watts_peak": 45.97, "energy_joules_est": 64.43, "sample_count": 15, "duration_seconds": 1.506}, "timestamp": "2026-01-11T13:16:16.196125"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 775.231, "latencies_ms": [775.231], "images_per_second": 1.29, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The man is sitting in front of the mirror, which reflects his image. The mirror is positioned between the man and the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [32.68, 32.68, 32.68, 32.68, 32.68, 42.76, 42.76, 42.76], "power_watts_avg": 36.46, "power_watts_peak": 42.76, "energy_joules_est": 28.28, "sample_count": 8, "duration_seconds": 0.776}, "timestamp": "2026-01-11T13:16:17.005837"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 879.634, "latencies_ms": [879.634], "images_per_second": 1.137, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A man is sitting cross-legged in front of a large mirror, taking a selfie. He appears to be in a living room with hardwood floors, a green chair, and a wooden dresser visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.76, 42.76, 45.94, 45.94, 45.94, 45.94, 45.94, 42.29, 42.29], "power_watts_avg": 44.42, "power_watts_peak": 45.94, "energy_joules_est": 39.09, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-11T13:16:17.914995"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1097.643, "latencies_ms": [1097.643], "images_per_second": 0.911, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The room has light-colored wood flooring and walls painted in a muted green hue. The lighting appears to be soft and diffused, creating a calm atmosphere. A wooden ornate mirror is prominently featured, reflecting the room's interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.7, "ram_available_mb": 109431.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.1, "ram_available_mb": 109434.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.29, 42.29, 47.92, 47.92, 47.92, 47.92, 47.92, 42.27, 42.27, 42.27, 42.27], "power_watts_avg": 44.84, "power_watts_peak": 47.92, "energy_joules_est": 49.26, "sample_count": 11, "duration_seconds": 1.099}, "timestamp": "2026-01-11T13:16:19.026622"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 689.681, "latencies_ms": [689.681], "images_per_second": 1.45, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of young men are standing next to surfboards, posing for a photo while a man captures the moment on his camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13072.1, "ram_available_mb": 109434.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13072.1, "ram_available_mb": 109434.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.27, 37.14, 37.14, 37.14, 37.14, 37.14, 42.67], "power_watts_avg": 38.66, "power_watts_peak": 42.67, "energy_joules_est": 26.67, "sample_count": 7, "duration_seconds": 0.69}, "timestamp": "2026-01-11T13:16:19.734761"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1331.527, "latencies_ms": [1331.527], "images_per_second": 0.751, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "surfboard: 2\nman: 3\nman in red jacket: 1\nboy: 2\nman in black: 1\nwoman: 1\nman in black: 1\nman in gray: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.1, "ram_available_mb": 109434.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 42.67, 50.92, 50.92, 50.92, 50.92, 50.92, 42.53, 42.53, 42.53, 42.53, 42.53], "power_watts_avg": 45.57, "power_watts_peak": 50.92, "energy_joules_est": 60.7, "sample_count": 14, "duration_seconds": 1.332}, "timestamp": "2026-01-11T13:16:21.147391"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1041.354, "latencies_ms": [1041.354], "images_per_second": 0.96, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The man is on the left side of the image, taking a picture of the group of young boys. The boys are standing close together in the foreground, while the man is positioned in the background. The scene appears to be set in a room or garage-like environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [31.81, 31.81, 31.81, 31.81, 31.81, 41.24, 41.24, 41.24, 41.24, 41.24, 41.69], "power_watts_avg": 37.0, "power_watts_peak": 41.69, "energy_joules_est": 38.55, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:16:22.255096"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 754.475, "latencies_ms": [754.475], "images_per_second": 1.325, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of young men are gathered in a room with surfboards, posing for a photo. A person is taking a picture of them with a digital camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.8, "ram_available_mb": 109432.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [41.69, 41.69, 41.69, 41.69, 41.26, 41.26, 41.26, 41.26], "power_watts_avg": 41.47, "power_watts_peak": 41.69, "energy_joules_est": 31.31, "sample_count": 8, "duration_seconds": 0.755}, "timestamp": "2026-01-11T13:16:23.063255"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1096.378, "latencies_ms": [1096.378], "images_per_second": 0.912, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The surfboards are brightly colored, featuring yellow, red, and blue. The lighting in the room is bright, likely from overhead fluorescent fixtures, creating a well-lit atmosphere. The surfboards appear to be made of durable materials like fiberglass or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.8, "ram_available_mb": 109432.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.26, 41.19, 41.19, 41.19, 41.19, 41.19, 41.65, 41.65, 41.65, 41.65, 41.65], "power_watts_avg": 41.4, "power_watts_peak": 41.65, "energy_joules_est": 45.4, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:16:24.175108"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 748.493, "latencies_ms": [748.493], "images_per_second": 1.336, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A gold-colored Polish Airlines Boeing 737-800, marked with the LOT logo and Polish text, is taxiing on the tarmac.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13072.7, "ram_available_mb": 109433.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.63, 41.63, 41.63, 41.63, 41.63, 36.33, 36.33, 36.33], "power_watts_avg": 39.64, "power_watts_peak": 41.63, "energy_joules_est": 29.68, "sample_count": 8, "duration_seconds": 0.749}, "timestamp": "2026-01-11T13:16:24.985976"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1112.991, "latencies_ms": [1112.991], "images_per_second": 0.898, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "airplane: 1\ntwin-engine: 2\nwings: 2\ntail: 1\nwindow: 8\ndoor: 2\ncockpit: 1\nengine: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.7, "ram_available_mb": 109433.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.33, 36.33, 40.69, 40.69, 40.69, 40.69, 40.69, 36.59, 36.59, 36.59, 36.59, 36.59], "power_watts_avg": 38.25, "power_watts_peak": 40.69, "energy_joules_est": 42.6, "sample_count": 12, "duration_seconds": 1.114}, "timestamp": "2026-01-11T13:16:26.199843"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 908.291, "latencies_ms": [908.291], "images_per_second": 1.101, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main object is a large passenger airplane positioned in the foreground of the image. The airplane is situated on a runway or tarmac, facing towards the right side of the image.  In the background, other aircraft and airport infrastructure are visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [33.3, 33.3, 33.3, 33.3, 33.3, 35.73, 35.73, 35.73, 35.73, 35.73], "power_watts_avg": 34.51, "power_watts_peak": 35.73, "energy_joules_est": 31.36, "sample_count": 10, "duration_seconds": 0.909}, "timestamp": "2026-01-11T13:16:27.210852"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 858.827, "latencies_ms": [858.827], "images_per_second": 1.164, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "An LOT Polish Airlines Boeing 737-800 aircraft is parked on the tarmac at an airport, facing right. The sky is partly cloudy, and there are other aircraft visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.64, 35.64, 35.64, 35.64, 35.64, 35.56, 35.56, 35.56, 35.56], "power_watts_avg": 35.6, "power_watts_peak": 35.64, "energy_joules_est": 30.6, "sample_count": 9, "duration_seconds": 0.859}, "timestamp": "2026-01-11T13:16:28.117860"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 788.628, "latencies_ms": [788.628], "images_per_second": 1.268, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The plane is primarily gold in color. The lighting appears to be natural daylight, illuminating the scene. The plane appears to be made of metal and has a polished finish. The sky is partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.08, 35.08, 35.08, 35.08, 35.08, 36.72, 36.72, 36.72], "power_watts_avg": 35.69, "power_watts_peak": 36.72, "energy_joules_est": 28.16, "sample_count": 8, "duration_seconds": 0.789}, "timestamp": "2026-01-11T13:16:28.926537"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 457.979, "latencies_ms": [457.979], "images_per_second": 2.184, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A person is standing in front of a white toilet with a raised lid, releasing water into the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.72, 36.72, 41.85, 41.85, 41.85], "power_watts_avg": 39.8, "power_watts_peak": 41.85, "energy_joules_est": 18.25, "sample_count": 5, "duration_seconds": 0.459}, "timestamp": "2026-01-11T13:16:29.434994"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1943.832, "latencies_ms": [1943.832], "images_per_second": 0.514, "prompt_tokens": 21, "response_tokens_est": 64, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper: 1\ntoilet seat: 1\ntoilet seat cover: 1\ntoilet seat lid: 1\ntoilet seat handle: 1\ntoilet flushing handle: 1\ntoilet lid: 1\ntoilet paper holder: 1\ntoilet paper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.85, 41.85, 40.66, 40.66, 40.66, 40.66, 40.66, 36.16, 36.16, 36.16, 36.16, 36.16, 32.53, 32.53, 32.53, 32.53, 32.53, 32.78, 32.78, 32.78], "power_watts_avg": 36.44, "power_watts_peak": 41.85, "energy_joules_est": 70.84, "sample_count": 20, "duration_seconds": 1.944}, "timestamp": "2026-01-11T13:16:31.450476"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 879.496, "latencies_ms": [879.496], "images_per_second": 1.137, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, close to the person's feet. The toilet is situated next to a wall, suggesting it is in a bathroom setting. The person's feet are visible at the bottom of the image, indicating they are standing close to the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [32.78, 32.78, 34.81, 34.81, 34.81, 34.81, 34.81, 35.37, 35.37], "power_watts_avg": 34.48, "power_watts_peak": 35.37, "energy_joules_est": 30.34, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-11T13:16:32.409288"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 728.873, "latencies_ms": [728.873], "images_per_second": 1.372, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a person using a toilet in a bathroom. The toilet seat is up, and the person is urinating into the bowl. The bathroom appears to be simple and uncluttered.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [35.37, 35.37, 35.37, 37.77, 37.77, 37.77, 37.77, 37.77], "power_watts_avg": 36.87, "power_watts_peak": 37.77, "energy_joules_est": 26.89, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-11T13:16:33.218242"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 884.748, "latencies_ms": [884.748], "images_per_second": 1.13, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The toilet is white and appears to be made of porcelain or ceramic. The lighting in the image is dim, creating a somewhat shadowy atmosphere. The materials visible include metal for the toilet and possibly the toilet seat cover.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.04, 37.04, 37.04, 37.04, 35.92, 35.92, 35.92, 35.92, 35.92], "power_watts_avg": 36.42, "power_watts_peak": 37.04, "energy_joules_est": 32.23, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-11T13:16:34.125759"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 863.686, "latencies_ms": [863.686], "images_per_second": 1.158, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A skier dressed in blue and black, wearing a white helmet and goggles, skillfully navigates a snowy mountain slope using ski poles.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13072.8, "ram_available_mb": 109433.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.91, 35.91, 35.91, 35.91, 35.91, 41.88, 41.88, 41.88, 41.88], "power_watts_avg": 38.57, "power_watts_peak": 41.88, "energy_joules_est": 33.33, "sample_count": 9, "duration_seconds": 0.864}, "timestamp": "2026-01-11T13:16:35.036105"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1201.316, "latencies_ms": [1201.316], "images_per_second": 0.832, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "person: 1\nhelmet: 1\ngloves: 1\nski poles: 2\nskis: 2\nsnow: 6\ntrees: 4\nsnow: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.8, "ram_available_mb": 109433.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.8, "ram_available_mb": 109433.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.88, 43.45, 43.45, 43.45, 43.45, 43.45, 41.98, 41.98, 41.98, 41.98, 41.98, 41.65], "power_watts_avg": 42.55, "power_watts_peak": 43.45, "energy_joules_est": 51.15, "sample_count": 12, "duration_seconds": 1.202}, "timestamp": "2026-01-11T13:16:36.248687"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 803.515, "latencies_ms": [803.515], "images_per_second": 1.245, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skier is positioned in the foreground of the image, moving towards the left side of the frame. The snowy landscape and trees in the background create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.8, "ram_available_mb": 109433.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.8, "ram_available_mb": 109433.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.65, 41.65, 41.65, 41.65, 42.89, 42.89, 42.89, 42.89], "power_watts_avg": 42.27, "power_watts_peak": 42.89, "energy_joules_est": 33.99, "sample_count": 8, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:16:37.058101"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 945.256, "latencies_ms": [945.256], "images_per_second": 1.058, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A skier is captured mid-turn on a snowy slope, surrounded by snow-covered trees. The skier is wearing a blue jacket and helmet, holding ski poles and navigating the terrain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.8, "ram_available_mb": 109433.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.89, 44.03, 44.03, 44.03, 44.03, 44.03, 42.84, 42.84, 42.84, 42.84], "power_watts_avg": 43.44, "power_watts_peak": 44.03, "energy_joules_est": 41.08, "sample_count": 10, "duration_seconds": 0.946}, "timestamp": "2026-01-11T13:16:38.067569"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1029.844, "latencies_ms": [1029.844], "images_per_second": 0.971, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The skier is wearing a blue jacket and dark pants. The lighting is soft and diffused, suggesting overcast conditions. The snow appears to be fresh and undisturbed, contributing to the overall wintery atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.84, 40.94, 40.94, 40.94, 40.94, 40.94, 40.89, 40.89, 40.89, 40.89, 40.89], "power_watts_avg": 41.09, "power_watts_peak": 42.84, "energy_joules_est": 42.34, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-11T13:16:39.179580"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 696.35, "latencies_ms": [696.35], "images_per_second": 1.436, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A female tennis player in a yellow shirt and black shorts is poised to hit the ball during a match on a blue court, surrounded by spectators and advertisements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13071.7, "ram_available_mb": 109434.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.72, 41.72, 41.72, 41.72, 41.72, 35.66, 35.66], "power_watts_avg": 39.99, "power_watts_peak": 41.72, "energy_joules_est": 27.87, "sample_count": 7, "duration_seconds": 0.697}, "timestamp": "2026-01-11T13:16:39.889003"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1323.381, "latencies_ms": [1323.381], "images_per_second": 0.756, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "Tennis player: 1\nTennis racket: 1\nTennis ball: 1\nTennis court: 1\nSpectators: 1\nReferee: 1\nCourt markings: 2\nAdvertising boards: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13071.7, "ram_available_mb": 109434.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13071.9, "ram_available_mb": 109434.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.66, 35.66, 35.66, 40.17, 40.17, 40.17, 40.17, 40.17, 37.24, 37.24, 37.24, 37.24, 37.24, 32.77], "power_watts_avg": 37.63, "power_watts_peak": 40.17, "energy_joules_est": 49.82, "sample_count": 14, "duration_seconds": 1.324}, "timestamp": "2026-01-11T13:16:41.300230"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 726.959, "latencies_ms": [726.959], "images_per_second": 1.376, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the court, facing the audience. The ball court is situated in the background, extending beyond the immediate foreground of the player and spectators.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13071.9, "ram_available_mb": 109434.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13071.9, "ram_available_mb": 109434.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.77, 32.77, 32.77, 32.77, 36.13, 36.13, 36.13, 36.13], "power_watts_avg": 34.45, "power_watts_peak": 36.13, "energy_joules_est": 25.06, "sample_count": 8, "duration_seconds": 0.727}, "timestamp": "2026-01-11T13:16:42.108571"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 700.263, "latencies_ms": [700.263], "images_per_second": 1.428, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A tennis match is taking place on a blue court, with players in action and spectators in the stands. The stands are filled with people, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13071.9, "ram_available_mb": 109434.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13072.3, "ram_available_mb": 109434.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.13, 34.82, 34.82, 34.82, 34.82, 34.82, 35.54], "power_watts_avg": 35.11, "power_watts_peak": 36.13, "energy_joules_est": 24.61, "sample_count": 7, "duration_seconds": 0.701}, "timestamp": "2026-01-11T13:16:42.817993"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 764.772, "latencies_ms": [764.772], "images_per_second": 1.308, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The tennis court is predominantly blue. The lighting appears to be artificial, likely from spotlights. The court surface appears to be made of a synthetic material like rubber or synthetic turf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.54, 35.54, 35.54, 41.02, 41.02, 41.02, 41.02, 41.02], "power_watts_avg": 38.97, "power_watts_peak": 41.02, "energy_joules_est": 29.81, "sample_count": 8, "duration_seconds": 0.765}, "timestamp": "2026-01-11T13:16:43.627171"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 559.565, "latencies_ms": [559.565], "images_per_second": 1.787, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A metal bowl on a plate contains cubed orange-colored vegetables, accompanied by a spoon and a bowl of brown stew.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.61, 36.61, 36.61, 36.61, 36.61, 36.34], "power_watts_avg": 36.56, "power_watts_peak": 36.61, "energy_joules_est": 20.48, "sample_count": 6, "duration_seconds": 0.56}, "timestamp": "2026-01-11T13:16:44.236701"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1302.682, "latencies_ms": [1302.682], "images_per_second": 0.768, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bowl: 2\nspoon: 1\nplate: 1\nnapkin: 1\nbowl: 4\nonion: 4\nred onion: 4\nsauce: 1\ntablecloth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.34, 36.34, 36.34, 36.34, 40.34, 40.34, 40.34, 40.34, 40.34, 36.46, 36.46, 36.46, 36.46], "power_watts_avg": 37.91, "power_watts_peak": 40.34, "energy_joules_est": 49.41, "sample_count": 13, "duration_seconds": 1.303}, "timestamp": "2026-01-11T13:16:45.550765"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 984.665, "latencies_ms": [984.665], "images_per_second": 1.016, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned close together, with the bowl of chutney slightly behind and to the left of the bowl of pickled onions. The foreground is dominated by the plate and utensils, while the background features the dark tablecloth and additional utensils.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [36.46, 35.41, 35.41, 35.41, 35.41, 35.41, 37.16, 37.16, 37.16, 37.16], "power_watts_avg": 36.22, "power_watts_peak": 37.16, "energy_joules_est": 35.68, "sample_count": 10, "duration_seconds": 0.985}, "timestamp": "2026-01-11T13:16:46.562797"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1101.381, "latencies_ms": [1101.381], "images_per_second": 0.908, "prompt_tokens": 19, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The scene depicts a meal served on a dark table with a white plate and a metal bowl containing two distinct dishes: one with a chunky, reddish-brown meat dish and the other with sliced, orange-colored vegetables. A spoon rests on the plate, ready for use.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.16, 36.96, 36.96, 36.96, 36.96, 36.96, 36.52, 36.52, 36.52, 36.52, 36.52], "power_watts_avg": 36.78, "power_watts_peak": 37.16, "energy_joules_est": 40.53, "sample_count": 11, "duration_seconds": 1.102}, "timestamp": "2026-01-11T13:16:47.674111"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1130.423, "latencies_ms": [1130.423], "images_per_second": 0.885, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The food in the bowls has a vibrant orange color. The lighting in the image is soft and warm, creating a pleasant ambiance. The bowls appear to be made of metal and have a shiny surface, suggesting they are made of high-quality materials. The food is presented on a plate with a napkin underneath.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 34.88, 37.2, 37.2, 37.2, 37.2, 37.2, 37.04, 37.04], "power_watts_avg": 36.21, "power_watts_peak": 37.2, "energy_joules_est": 40.95, "sample_count": 12, "duration_seconds": 1.131}, "timestamp": "2026-01-11T13:16:48.886329"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 658.477, "latencies_ms": [658.477], "images_per_second": 1.519, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of sheep, including one with a distinctive black face, are standing together near a brick building in a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.04, 37.04, 37.04, 41.16, 41.16, 41.16, 41.16], "power_watts_avg": 39.39, "power_watts_peak": 41.16, "energy_joules_est": 25.97, "sample_count": 7, "duration_seconds": 0.659}, "timestamp": "2026-01-11T13:16:49.595900"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1154.238, "latencies_ms": [1154.238], "images_per_second": 0.866, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "sheep: 5\nbrick wall: 1\ngrass: 2\nslide: 1\nwooden structure: 1\nfence: 1\nwooden beams: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.16, 40.55, 40.55, 40.55, 40.55, 40.55, 42.16, 42.16, 42.16, 42.16, 42.16, 43.16], "power_watts_avg": 41.49, "power_watts_peak": 43.16, "energy_joules_est": 47.9, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:16:50.807604"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 760.136, "latencies_ms": [760.136], "images_per_second": 1.316, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, slightly to the left of the image. The brick wall and wooden structure are in the background, further back from the sheep.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.16, 43.16, 43.16, 43.16, 41.85, 41.85, 41.85, 41.85], "power_watts_avg": 42.51, "power_watts_peak": 43.16, "energy_joules_est": 32.32, "sample_count": 8, "duration_seconds": 0.76}, "timestamp": "2026-01-11T13:16:51.616595"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 893.143, "latencies_ms": [893.143], "images_per_second": 1.12, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A group of sheep, including two prominent ones, are gathered in a grassy area near a brick building. The scene suggests a farm or rural setting, possibly during a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.94, 40.94, 40.94, 40.94, 40.94, 41.37, 41.37, 41.37, 41.37], "power_watts_avg": 41.13, "power_watts_peak": 41.37, "energy_joules_est": 36.76, "sample_count": 9, "duration_seconds": 0.894}, "timestamp": "2026-01-11T13:16:52.527100"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 994.412, "latencies_ms": [994.412], "images_per_second": 1.006, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The sheep have thick, brown wool that appears slightly damp or dirty. The lighting suggests a sunny day, with shadows cast on the grass. The brick wall in the background adds a rustic touch to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.5, "ram_available_mb": 109433.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.7, "ram_available_mb": 109433.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [41.37, 46.05, 46.05, 46.05, 46.05, 46.05, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 44.2, "power_watts_peak": 46.05, "energy_joules_est": 43.97, "sample_count": 10, "duration_seconds": 0.995}, "timestamp": "2026-01-11T13:16:53.538148"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 653.261, "latencies_ms": [653.261], "images_per_second": 1.531, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A bunch of ripe bananas is arranged in a circular pattern, partially overlapping a vibrant red and yellow fruit in the center.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.7, "ram_available_mb": 109433.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13072.7, "ram_available_mb": 109433.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [42.61, 42.8, 42.8, 42.8, 42.8, 42.8, 43.93], "power_watts_avg": 42.93, "power_watts_peak": 43.93, "energy_joules_est": 28.07, "sample_count": 7, "duration_seconds": 0.654}, "timestamp": "2026-01-11T13:16:54.249394"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1459.994, "latencies_ms": [1459.994], "images_per_second": 0.685, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Banana: 5\nMango: 1\nPomegranate: 1\nBanana: 5\nPomegranate: 1\nBanana: 5\nPomegranate: 1\nBanana: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.7, "ram_available_mb": 109433.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.93, 43.93, 43.93, 43.93, 51.75, 51.75, 51.75, 51.75, 51.75, 42.52, 42.52, 42.52, 42.52, 42.52, 32.43], "power_watts_avg": 45.3, "power_watts_peak": 51.75, "energy_joules_est": 66.17, "sample_count": 15, "duration_seconds": 1.461}, "timestamp": "2026-01-11T13:16:55.760985"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 920.41, "latencies_ms": [920.41], "images_per_second": 1.086, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The bananas are positioned in the foreground, partially overlapping the pomegranate. The pomegranate is situated near the center of the image, slightly behind and to the right of the bananas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [32.43, 32.43, 32.43, 32.43, 43.13, 43.13, 43.13, 43.13, 43.13, 43.31], "power_watts_avg": 38.87, "power_watts_peak": 43.31, "energy_joules_est": 35.79, "sample_count": 10, "duration_seconds": 0.921}, "timestamp": "2026-01-11T13:16:56.771100"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 982.533, "latencies_ms": [982.533], "images_per_second": 1.018, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set against a textured, teal background with leaf-like patterns. A bunch of green bananas is arranged around a partially peeled, red and yellow apple, creating a visually striking and artistic composition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.31, 43.31, 43.31, 43.31, 42.63, 42.63, 42.63, 42.63, 42.63, 42.19], "power_watts_avg": 42.86, "power_watts_peak": 43.31, "energy_joules_est": 42.14, "sample_count": 10, "duration_seconds": 0.983}, "timestamp": "2026-01-11T13:16:57.782630"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1312.953, "latencies_ms": [1312.953], "images_per_second": 0.762, "prompt_tokens": 18, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The fruits are predominantly green and have a vibrant red-yellow color. The lighting is soft and diffused, creating a gentle glow on the fruits. The materials appear to be natural, potentially fruits or plant matter. The background has a textured, light blue-green pattern, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.19, 42.19, 42.19, 42.19, 43.38, 43.38, 43.38, 43.38, 43.38, 43.76, 43.76, 43.76, 43.76, 43.76], "power_watts_avg": 43.17, "power_watts_peak": 43.76, "energy_joules_est": 56.71, "sample_count": 14, "duration_seconds": 1.314}, "timestamp": "2026-01-11T13:16:59.195886"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 482.274, "latencies_ms": [482.274], "images_per_second": 2.074, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A blue and white tram numbered 2 is traveling down a street lined with trees and buildings.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [32.3, 32.3, 32.3, 32.3, 32.3], "power_watts_avg": 32.3, "power_watts_peak": 32.3, "energy_joules_est": 15.59, "sample_count": 5, "duration_seconds": 0.483}, "timestamp": "2026-01-11T13:16:59.704941"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1020.043, "latencies_ms": [1020.043], "images_per_second": 0.98, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Train: 8\nTrees: 2\nSky: 1\nWires: 6\nBuildings: 1\nCars: 1\nTram tracks: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.6, "ram_available_mb": 109433.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.4, "ram_available_mb": 109439.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [35.66, 35.66, 35.66, 35.66, 35.66, 40.2, 40.2, 40.2, 40.2, 40.2, 37.42], "power_watts_avg": 37.88, "power_watts_peak": 40.2, "energy_joules_est": 38.66, "sample_count": 11, "duration_seconds": 1.021}, "timestamp": "2026-01-11T13:17:00.816956"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 839.202, "latencies_ms": [839.202], "images_per_second": 1.192, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object is a blue and white tram moving from left to right in the foreground. The background features trees, a building, and a parked car. The tram is positioned near the center of the image, moving towards the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.4, "ram_available_mb": 109439.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13066.4, "ram_available_mb": 109439.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.42, 37.42, 37.42, 36.06, 36.06, 36.06, 36.06, 36.06, 35.93], "power_watts_avg": 36.5, "power_watts_peak": 37.42, "energy_joules_est": 30.65, "sample_count": 9, "duration_seconds": 0.84}, "timestamp": "2026-01-11T13:17:01.727224"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 691.216, "latencies_ms": [691.216], "images_per_second": 1.447, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A blue and white tram is traveling down a street, carrying passengers and passing by trees and a building. The scene suggests a modern, urban transit system.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.4, "ram_available_mb": 109439.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.93, 35.93, 35.93, 35.93, 36.41, 36.41, 36.41], "power_watts_avg": 36.13, "power_watts_peak": 36.41, "energy_joules_est": 25.0, "sample_count": 7, "duration_seconds": 0.692}, "timestamp": "2026-01-11T13:17:02.434995"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 753.212, "latencies_ms": [753.212], "images_per_second": 1.328, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The tram is primarily blue and white. The lighting is bright, illuminating the scene clearly. The tram appears to be made of metal and plastic. The weather is sunny and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [36.41, 36.41, 41.09, 41.09, 41.09, 41.09, 41.09, 37.21], "power_watts_avg": 39.43, "power_watts_peak": 41.09, "energy_joules_est": 29.72, "sample_count": 8, "duration_seconds": 0.754}, "timestamp": "2026-01-11T13:17:03.244805"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 808.822, "latencies_ms": [808.822], "images_per_second": 1.236, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The bathroom features a white bathtub, a glass shower enclosure, a red shower curtain, and two sinks with dark wood cabinets and marble countertops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [37.21, 37.21, 37.21, 37.21, 41.6, 41.6, 41.6, 41.6, 41.6], "power_watts_avg": 39.65, "power_watts_peak": 41.6, "energy_joules_est": 32.09, "sample_count": 9, "duration_seconds": 0.809}, "timestamp": "2026-01-11T13:17:04.154477"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1560.931, "latencies_ms": [1560.931], "images_per_second": 0.641, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "shower curtain: 1\nbathtub: 1\nshower head: 1\ntoilet paper holder: 1\nmirrors: 2\nvanity: 2\nsink: 2\ncountertop: 2\nfloor: 1\nrug: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.59, 40.59, 40.59, 40.59, 40.59, 41.31, 41.31, 41.31, 41.31, 41.31, 42.48, 42.48, 42.48, 42.48, 42.48, 32.83], "power_watts_avg": 40.92, "power_watts_peak": 42.48, "energy_joules_est": 63.9, "sample_count": 16, "duration_seconds": 1.561}, "timestamp": "2026-01-11T13:17:05.768341"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 905.311, "latencies_ms": [905.311], "images_per_second": 1.105, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The bathtub is positioned to the left of the shower and partially behind the shower curtain. The sink is located in the foreground, near the mirrors. The tiled floor extends from the foreground towards the shower.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [32.83, 32.83, 32.83, 32.83, 41.63, 41.63, 41.63, 41.63, 41.63, 41.38], "power_watts_avg": 38.08, "power_watts_peak": 41.63, "energy_joules_est": 34.49, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-11T13:17:06.778456"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1091.15, "latencies_ms": [1091.15], "images_per_second": 0.916, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The bathroom features a double vanity with dark wood cabinets, a white countertop, and marble-like backsplash. A bathtub with a shower curtain is situated next to the vanity, complete with a glass enclosure and a red bathmat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.38, 41.38, 41.38, 41.38, 41.06, 41.06, 41.06, 41.06, 41.06, 41.07, 41.07], "power_watts_avg": 41.18, "power_watts_peak": 41.38, "energy_joules_est": 44.94, "sample_count": 11, "duration_seconds": 1.091}, "timestamp": "2026-01-11T13:17:07.888330"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1275.474, "latencies_ms": [1275.474], "images_per_second": 0.784, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The bathroom features a beige color scheme, accented by red shower curtains and dark wood cabinets. The lighting is warm and ambient, contributing to the overall ambiance. The bathroom includes a glass shower enclosure, a bathtub, and a double vanity with dark wood cabinets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.07, 41.07, 41.07, 41.7, 41.7, 41.7, 41.7, 41.7, 41.79, 41.79, 41.79, 41.79, 41.79], "power_watts_avg": 41.59, "power_watts_peak": 41.79, "energy_joules_est": 53.07, "sample_count": 13, "duration_seconds": 1.276}, "timestamp": "2026-01-11T13:17:09.196273"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 726.996, "latencies_ms": [726.996], "images_per_second": 1.376, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A surfer in a wetsuit rides a wave on a surfboard, skillfully carving through the water as it crashes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [32.81, 32.81, 32.81, 32.81, 32.81, 42.48, 42.48, 42.48], "power_watts_avg": 36.43, "power_watts_peak": 42.48, "energy_joules_est": 26.51, "sample_count": 8, "duration_seconds": 0.728}, "timestamp": "2026-01-11T13:17:10.002921"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1143.074, "latencies_ms": [1143.074], "images_per_second": 0.875, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "surfboard: 1\nwetsuit: 1\nwater: 1\nwave: 1\ncable: 1\nperson: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 46.09, 46.09, 46.09, 46.09, 46.09, 40.6, 40.6, 40.6, 40.6, 40.6], "power_watts_avg": 43.2, "power_watts_peak": 46.09, "energy_joules_est": 49.39, "sample_count": 12, "duration_seconds": 1.143}, "timestamp": "2026-01-11T13:17:11.215772"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 928.137, "latencies_ms": [928.137], "images_per_second": 1.077, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The surfer is positioned near the center of the image, riding a wave that extends towards the background. The wave is relatively large compared to the surfer, emphasizing the dynamic nature of the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.63, 36.63, 36.63, 36.63, 36.63, 41.37, 41.37, 41.37, 41.37, 41.39], "power_watts_avg": 39.0, "power_watts_peak": 41.39, "energy_joules_est": 36.21, "sample_count": 10, "duration_seconds": 0.928}, "timestamp": "2026-01-11T13:17:12.225799"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1197.373, "latencies_ms": [1197.373], "images_per_second": 0.835, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "A surfer in a wetsuit is skillfully riding a wave in the ocean. The wave is breaking, creating a dynamic scene with splashing water. The image is captured in black and white, emphasizing the contrast and texture of the ocean and wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.39, 41.39, 41.39, 41.39, 41.23, 41.23, 41.23, 41.23, 41.23, 41.17, 41.17, 41.17], "power_watts_avg": 41.27, "power_watts_peak": 41.39, "energy_joules_est": 49.44, "sample_count": 12, "duration_seconds": 1.198}, "timestamp": "2026-01-11T13:17:13.437485"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1457.634, "latencies_ms": [1457.634], "images_per_second": 0.686, "prompt_tokens": 18, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The black and white image captures a dynamic moment of action in the ocean. The lighting is dramatic, with strong contrasts between light and shadow, enhancing the visual impact of the surfer and the wave. The wave appears to be breaking, creating a powerful visual effect. The surfer is wearing a wetsuit, which suggests the presence of cold water conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.17, 41.17, 39.92, 39.92, 39.92, 39.92, 39.92, 42.21, 42.21, 42.21, 42.21, 42.21, 34.53, 34.53, 34.53], "power_watts_avg": 39.77, "power_watts_peak": 42.21, "energy_joules_est": 57.98, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-11T13:17:14.950538"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 855.651, "latencies_ms": [855.651], "images_per_second": 1.169, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A baseball player in a white uniform with orange and black accents is poised at home plate, ready to swing the bat, while a catcher in black and red gear crouches behind him.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.53, 34.53, 36.18, 36.18, 36.18, 36.18, 36.18, 36.24, 36.24], "power_watts_avg": 35.83, "power_watts_peak": 36.24, "energy_joules_est": 30.66, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-11T13:17:15.859863"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1240.943, "latencies_ms": [1240.943], "images_per_second": 0.806, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball mitt: 1\nbaseball: 1\ncatcher: 2\numpire: 1\nbaseball field: 1\nspectators: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.24, 36.24, 36.24, 36.58, 36.58, 36.58, 36.58, 36.58, 36.88, 36.88, 36.88, 36.88, 36.88], "power_watts_avg": 36.62, "power_watts_peak": 36.88, "energy_joules_est": 45.46, "sample_count": 13, "duration_seconds": 1.242}, "timestamp": "2026-01-11T13:17:17.170115"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1052.549, "latencies_ms": [1052.549], "images_per_second": 0.95, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a spatial arrangement that suggests a game in progress. The batter is in the foreground, preparing to swing, while the catcher and umpire are in the background, observing the play. The spectators are situated in the background, watching the game unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.61, 32.61, 32.61, 32.61, 32.61, 36.51, 36.51, 36.51, 36.51, 36.51, 36.74], "power_watts_avg": 34.76, "power_watts_peak": 36.74, "energy_joules_est": 36.59, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:17:18.279687"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1546.485, "latencies_ms": [1546.485], "images_per_second": 0.647, "prompt_tokens": 19, "response_tokens_est": 73, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter in a white uniform with orange accents is swinging at a pitch, while a catcher in a black uniform with red accents is crouched behind home plate. An umpire in a blue uniform is positioned behind the catcher, observing the play. Spectators are seated in the stands, watching the game unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13067.2, "ram_available_mb": 109439.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.74, 36.74, 36.74, 36.74, 35.55, 35.55, 35.55, 35.55, 35.55, 35.47, 35.47, 35.47, 35.47, 35.47, 32.41, 32.41], "power_watts_avg": 35.43, "power_watts_peak": 36.74, "energy_joules_est": 54.8, "sample_count": 16, "duration_seconds": 1.547}, "timestamp": "2026-01-11T13:17:19.887644"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 752.157, "latencies_ms": [752.157], "images_per_second": 1.33, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The batter is wearing white pants and an orange jersey. The catcher is wearing a black jersey and protective gear. The field is green, and the lighting appears to be natural daylight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.2, "ram_available_mb": 109439.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.2, "ram_available_mb": 109439.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [32.41, 32.41, 32.41, 36.21, 36.21, 36.21, 36.21, 36.21], "power_watts_avg": 34.78, "power_watts_peak": 36.21, "energy_joules_est": 26.18, "sample_count": 8, "duration_seconds": 0.753}, "timestamp": "2026-01-11T13:17:20.694933"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 725.022, "latencies_ms": [725.022], "images_per_second": 1.379, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A black and white drawing features an assortment of fruits and vegetables, including apples, oranges, grapes, and peanuts, arranged in a visually appealing composition.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13067.2, "ram_available_mb": 109439.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.18, 36.18, 36.18, 36.18, 36.18, 41.26, 41.26, 41.26], "power_watts_avg": 38.08, "power_watts_peak": 41.26, "energy_joules_est": 27.64, "sample_count": 8, "duration_seconds": 0.726}, "timestamp": "2026-01-11T13:17:21.504353"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 990.065, "latencies_ms": [990.065], "images_per_second": 1.01, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "apple: 2\norange: 1\ngrapes: 4\npeanuts: 8\nfruit: 3\nfruit: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [41.26, 41.26, 45.54, 45.54, 45.54, 45.54, 45.54, 41.2, 41.2, 41.2], "power_watts_avg": 43.38, "power_watts_peak": 45.54, "energy_joules_est": 42.98, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-11T13:17:22.513550"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 926.674, "latencies_ms": [926.674], "images_per_second": 1.079, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The left side of the image features the fruits and nuts, while the right side shows the apple and grapes. The fruits and nuts are positioned in the foreground, while the apple and grapes are situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [41.2, 41.2, 42.59, 42.59, 42.59, 42.59, 42.59, 42.28, 42.28, 42.28], "power_watts_avg": 42.22, "power_watts_peak": 42.59, "energy_joules_est": 39.15, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-11T13:17:23.526203"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1192.777, "latencies_ms": [1192.777], "images_per_second": 0.838, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a still life arrangement featuring various fruits, including apples, grapes, and a citrus fruit, alongside scattered peanuts. The arrangement is presented in a monochromatic palette, emphasizing the textures and shapes of the fruits and the contrasting textures of the peanuts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.28, 40.56, 40.56, 40.56, 40.56, 40.56, 41.41, 41.41, 41.41, 41.41, 41.41, 38.76], "power_watts_avg": 40.91, "power_watts_peak": 42.28, "energy_joules_est": 48.82, "sample_count": 12, "duration_seconds": 1.193}, "timestamp": "2026-01-11T13:17:24.739838"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 961.382, "latencies_ms": [961.382], "images_per_second": 1.04, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The fruits are depicted in shades of white and gray, creating a monochromatic effect. The lighting in the image appears to be soft and diffused, enhancing the textures and details of the fruits and nuts.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.76, 38.76, 38.76, 38.76, 42.58, 42.58, 42.58, 42.58, 42.58, 42.78], "power_watts_avg": 41.07, "power_watts_peak": 42.78, "energy_joules_est": 39.5, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-11T13:17:25.751456"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 558.461, "latencies_ms": [558.461], "images_per_second": 1.791, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A city street scene features modern buildings, a bike path, parked cars, and a bus traveling down the road.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.78, 42.78, 42.78, 42.78, 36.52, 36.52], "power_watts_avg": 40.69, "power_watts_peak": 42.78, "energy_joules_est": 22.75, "sample_count": 6, "duration_seconds": 0.559}, "timestamp": "2026-01-11T13:17:26.360918"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1103.703, "latencies_ms": [1103.703], "images_per_second": 0.906, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "building: 5\ncar: 2\nbus: 1\nstreet light: 2\npedestrian path: 1\nbus stop: 1\ntrees: 2\npower lines: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [36.52, 36.52, 36.52, 40.43, 40.43, 40.43, 40.43, 40.43, 36.64, 36.64, 36.64], "power_watts_avg": 38.33, "power_watts_peak": 40.43, "energy_joules_est": 42.32, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-11T13:17:27.472836"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 925.043, "latencies_ms": [925.043], "images_per_second": 1.081, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The foreground features a paved road with a bike path running alongside it.  The background includes buildings, parked cars, and a bus, indicating a developed urban area. The bike path appears relatively narrow compared to the road and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [36.64, 36.64, 37.55, 37.55, 37.55, 37.55, 37.55, 37.5, 37.5, 37.5], "power_watts_avg": 37.35, "power_watts_peak": 37.55, "energy_joules_est": 34.57, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-11T13:17:28.483998"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 939.021, "latencies_ms": [939.021], "images_per_second": 1.065, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a modern urban street with modern buildings lining both sides. A bike path runs alongside the road, providing a green space for cyclists. The street is relatively quiet, with only a few cars and a bus visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [37.5, 37.5, 36.22, 36.22, 36.22, 36.22, 36.22, 36.22, 36.22, 36.22], "power_watts_avg": 36.47, "power_watts_peak": 37.5, "energy_joules_est": 34.26, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-11T13:17:29.492867"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 892.605, "latencies_ms": [892.605], "images_per_second": 1.12, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The buildings exhibit a mix of colors, including white, red, and brown. The lighting is bright, likely from streetlights and building windows. The materials appear to be primarily concrete and metal. The weather appears to be partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [36.22, 36.22, 36.19, 36.19, 36.19, 36.19, 36.19, 36.13, 36.13], "power_watts_avg": 36.19, "power_watts_peak": 36.22, "energy_joules_est": 32.32, "sample_count": 9, "duration_seconds": 0.893}, "timestamp": "2026-01-11T13:17:30.402613"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 491.528, "latencies_ms": [491.528], "images_per_second": 2.034, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A man and a woman are seated at a wooden table in a cozy pub, smiling and embracing each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.13, 36.13, 36.13, 37.36, 37.36], "power_watts_avg": 36.62, "power_watts_peak": 37.36, "energy_joules_est": 18.02, "sample_count": 5, "duration_seconds": 0.492}, "timestamp": "2026-01-11T13:17:30.910108"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1001.647, "latencies_ms": [1001.647], "images_per_second": 0.998, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "man: 2\nwoman: 2\ntie: 1\ntable: 1\nphone: 1\nscreen: 1\nchair: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.36, 37.36, 37.36, 42.04, 42.04, 42.04, 42.04, 42.04, 37.25, 37.25], "power_watts_avg": 39.68, "power_watts_peak": 42.04, "energy_joules_est": 39.77, "sample_count": 10, "duration_seconds": 1.002}, "timestamp": "2026-01-11T13:17:31.920467"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 719.778, "latencies_ms": [719.778], "images_per_second": 1.389, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a man and woman seated at a table in the background. The man is on the left side of the image, and the woman is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.25, 37.25, 37.46, 37.46, 37.46, 37.46, 37.46, 37.49], "power_watts_avg": 37.41, "power_watts_peak": 37.49, "energy_joules_est": 26.94, "sample_count": 8, "duration_seconds": 0.72}, "timestamp": "2026-01-11T13:17:32.732265"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 845.514, "latencies_ms": [845.514], "images_per_second": 1.183, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A man and a woman are seated at a table in a dimly lit pub, smiling and embracing. The pub's decor includes framed pictures and wall sconces, and a television is visible in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.49, 37.49, 37.49, 37.49, 35.92, 35.92, 35.92, 35.92, 35.92], "power_watts_avg": 36.62, "power_watts_peak": 37.49, "energy_joules_est": 30.97, "sample_count": 9, "duration_seconds": 0.846}, "timestamp": "2026-01-11T13:17:33.641772"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 917.703, "latencies_ms": [917.703], "images_per_second": 1.09, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The man is wearing a purple striped shirt and a patterned tie. The lighting in the pub is warm and dim, creating a cozy atmosphere. The walls are painted a muted green, and there are framed pictures and signs visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [35.16, 35.16, 35.16, 35.16, 35.16, 36.59, 36.59, 36.59, 36.59, 36.59], "power_watts_avg": 35.88, "power_watts_peak": 36.59, "energy_joules_est": 32.93, "sample_count": 10, "duration_seconds": 0.918}, "timestamp": "2026-01-11T13:17:34.652723"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 638.824, "latencies_ms": [638.824], "images_per_second": 1.565, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A woman dressed in a costume and wearing a golden helmet is talking on her cell phone amidst a crowd of people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [36.27, 36.27, 36.27, 36.27, 36.27, 41.16, 41.16], "power_watts_avg": 37.67, "power_watts_peak": 41.16, "energy_joules_est": 24.08, "sample_count": 7, "duration_seconds": 0.639}, "timestamp": "2026-01-11T13:17:35.361824"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1233.882, "latencies_ms": [1233.882], "images_per_second": 0.81, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "woman: 1\nhelmet: 1\nman: 2\nman: 3\nman: 4\nman: 5\nman: 6\nman: 7\nman: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.16, 41.16, 41.16, 51.34, 51.34, 51.34, 51.34, 51.34, 41.59, 41.59, 41.59, 41.59, 41.59], "power_watts_avg": 45.24, "power_watts_peak": 51.34, "energy_joules_est": 55.84, "sample_count": 13, "duration_seconds": 1.234}, "timestamp": "2026-01-11T13:17:36.674659"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 797.502, "latencies_ms": [797.502], "images_per_second": 1.254, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The man on the left is partially visible in the foreground, while the woman is centrally positioned in the foreground. The background features other individuals, suggesting a crowd or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [32.14, 32.14, 32.14, 32.14, 32.14, 40.93, 40.93, 40.93], "power_watts_avg": 35.44, "power_watts_peak": 40.93, "energy_joules_est": 28.28, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:17:37.485425"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 827.724, "latencies_ms": [827.724], "images_per_second": 1.208, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The scene takes place outdoors, possibly during a festival or event. A woman dressed in medieval-inspired attire is talking on her cell phone amidst a crowd of people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [40.93, 40.93, 47.69, 47.69, 47.69, 47.69, 47.69, 42.84, 42.84], "power_watts_avg": 45.11, "power_watts_peak": 47.69, "energy_joules_est": 37.36, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:17:38.397045"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 949.076, "latencies_ms": [949.076], "images_per_second": 1.054, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The woman is wearing a gold and black costume with a helmet-like headpiece. Her hair is dark and appears to be styled in loose waves. The lighting suggests an outdoor setting, possibly in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 42.84, 46.56, 46.56, 46.56, 46.56, 46.56, 41.66, 41.66], "power_watts_avg": 44.46, "power_watts_peak": 46.56, "energy_joules_est": 42.22, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-11T13:17:39.409272"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 563.972, "latencies_ms": [563.972], "images_per_second": 1.773, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "The bathroom features a white toilet situated beneath a window, with two buckets placed nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [41.66, 41.66, 41.66, 41.48, 41.48, 41.48], "power_watts_avg": 41.57, "power_watts_peak": 41.66, "energy_joules_est": 23.47, "sample_count": 6, "duration_seconds": 0.565}, "timestamp": "2026-01-11T13:17:40.018508"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1427.542, "latencies_ms": [1427.542], "images_per_second": 0.701, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "Shower head: 1\nPipe: 2\nToilet: 1\nToilet paper holder: 1\nBucket: 2\nFloor tiles: 8\nShelf: 1\nCleaning supplies: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.48, 41.48, 45.7, 45.7, 45.7, 45.7, 45.7, 42.99, 42.99, 42.99, 42.99, 42.99, 38.56, 38.56, 38.56], "power_watts_avg": 42.81, "power_watts_peak": 45.7, "energy_joules_est": 61.14, "sample_count": 15, "duration_seconds": 1.428}, "timestamp": "2026-01-11T13:17:41.534015"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 730.309, "latencies_ms": [730.309], "images_per_second": 1.369, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The toilet is located in the foreground, close to the shower and bucket. The shower and bucket are situated in the background, further away from the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 29.0}, "power_stats": {"power_watts_samples": [38.56, 35.0, 35.0, 35.0, 35.0, 35.0, 41.23, 41.23], "power_watts_avg": 37.01, "power_watts_peak": 41.23, "energy_joules_est": 27.04, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:17:42.344594"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 805.056, "latencies_ms": [805.056], "images_per_second": 1.242, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The bathroom features a toilet, a shower stall, and several buckets. The scene suggests a functional and possibly temporary space for personal hygiene and cleaning.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [41.23, 41.23, 41.23, 48.48, 48.48, 48.48, 48.48, 48.48, 41.1], "power_watts_avg": 45.25, "power_watts_peak": 48.48, "energy_joules_est": 36.45, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-11T13:17:43.255072"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 922.341, "latencies_ms": [922.341], "images_per_second": 1.084, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bathroom is predominantly white, with gray tiled flooring. The lighting appears to be artificial, coming from overhead fixtures. The materials include white tiles, plastic pipes, and metal fixtures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [41.1, 41.1, 41.1, 41.1, 41.0, 41.0, 41.0, 41.0, 41.0, 40.87], "power_watts_avg": 41.03, "power_watts_peak": 41.1, "energy_joules_est": 37.86, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-11T13:17:44.263955"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 603.269, "latencies_ms": [603.269], "images_per_second": 1.658, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man wearing glasses and a green shirt stands next to an elephant with its trunk touching his face.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [40.87, 40.87, 40.87, 40.87, 41.02, 41.02, 41.02], "power_watts_avg": 40.93, "power_watts_peak": 41.02, "energy_joules_est": 24.72, "sample_count": 7, "duration_seconds": 0.604}, "timestamp": "2026-01-11T13:17:44.975271"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1124.721, "latencies_ms": [1124.721], "images_per_second": 0.889, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "elephant: 2\nman: 1\nglasses: 1\nt-shirt: 1\ntrunk: 1\nhills: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.02, 41.02, 46.24, 46.24, 46.24, 46.24, 46.24, 41.01, 41.01, 41.01, 41.01, 41.01], "power_watts_avg": 43.19, "power_watts_peak": 46.24, "energy_joules_est": 48.59, "sample_count": 12, "duration_seconds": 1.125}, "timestamp": "2026-01-11T13:17:46.187742"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 910.147, "latencies_ms": [910.147], "images_per_second": 1.099, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The elephant is positioned close to the man, creating a close and intimate interaction. The elephant's trunk is partially visible, extending towards the man's face, suggesting an affectionate or playful connection.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.76, 36.76, 36.76, 36.76, 36.76, 41.47, 41.47, 41.47, 41.47, 41.47], "power_watts_avg": 39.11, "power_watts_peak": 41.47, "energy_joules_est": 35.61, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-11T13:17:47.196579"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 949.988, "latencies_ms": [949.988], "images_per_second": 1.053, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A man is standing next to an elephant, appearing to be interacting or playing with it. The setting suggests a natural environment, possibly a wildlife sanctuary or tourist attraction, where elephants are commonly found.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.14, 41.14, 41.14, 41.14, 41.14, 40.96, 40.96, 40.96, 40.96, 40.96], "power_watts_avg": 41.05, "power_watts_peak": 41.14, "energy_joules_est": 39.02, "sample_count": 10, "duration_seconds": 0.951}, "timestamp": "2026-01-11T13:17:48.208851"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1171.922, "latencies_ms": [1171.922], "images_per_second": 0.853, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The elephant's skin is a dark brown color. The lighting appears to be bright and sunny, creating a clear contrast between the elephant and the man's shirt. The materials appear to be natural and sturdy, consistent with the elephant's skin and overall structure. The weather appears to be sunny and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.87, 40.87, 40.87, 40.87, 40.87, 41.91, 41.91, 41.91, 41.91, 41.91, 41.99, 41.99], "power_watts_avg": 41.49, "power_watts_peak": 41.99, "energy_joules_est": 48.64, "sample_count": 12, "duration_seconds": 1.172}, "timestamp": "2026-01-11T13:17:49.422070"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 600.798, "latencies_ms": [600.798], "images_per_second": 1.664, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Five young children sit on the grass, each holding a white frisbee with a black design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 40.45, 40.45, 40.45], "power_watts_avg": 41.22, "power_watts_peak": 41.99, "energy_joules_est": 24.79, "sample_count": 6, "duration_seconds": 0.601}, "timestamp": "2026-01-11T13:17:50.033514"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1276.596, "latencies_ms": [1276.596], "images_per_second": 0.783, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Frisbee: 2\nT-shirt: 3\nBoy: 3\nBoy: 3\nBoy: 3\nBoy: 3\nBoy: 3\nBoy: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.45, 45.87, 45.87, 45.87, 45.87, 45.87, 44.92, 44.92, 44.92, 44.92, 44.92, 39.95, 39.95], "power_watts_avg": 44.18, "power_watts_peak": 45.87, "energy_joules_est": 56.41, "sample_count": 13, "duration_seconds": 1.277}, "timestamp": "2026-01-11T13:17:51.348061"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 803.216, "latencies_ms": [803.216], "images_per_second": 1.245, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The children's feet are positioned in the foreground, close to the frisbees. The frisbees are situated near the children, creating a sense of proximity and playfulness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [39.95, 39.95, 39.95, 42.77, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 41.72, "power_watts_peak": 42.77, "energy_joules_est": 33.53, "sample_count": 8, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:17:52.157531"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 793.154, "latencies_ms": [793.154], "images_per_second": 1.261, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A group of young children is sitting on the grass in a natural outdoor setting. They are holding frisbees, suggesting they might be playing or enjoying a game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.52, 42.52, 42.52, 42.52, 42.52, 42.96, 42.96, 42.96], "power_watts_avg": 42.69, "power_watts_peak": 42.96, "energy_joules_est": 33.87, "sample_count": 8, "duration_seconds": 0.794}, "timestamp": "2026-01-11T13:17:52.968287"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 981.289, "latencies_ms": [981.289], "images_per_second": 1.019, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The children are wearing light brown and tan clothing. The lighting appears to be natural, possibly overcast. The grass they are sitting on is green and appears well-maintained. The children seem to be barefoot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 49.79, 49.79, 49.79, 49.79, 49.79, 42.48, 42.48, 42.48], "power_watts_avg": 46.23, "power_watts_peak": 49.79, "energy_joules_est": 45.38, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-11T13:17:53.979631"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 667.643, "latencies_ms": [667.643], "images_per_second": 1.498, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A young girl in a red coat and blue jeans holds a black and pink umbrella while standing on a wet sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 41.47, 41.47, 41.47, 41.47, 41.47], "power_watts_avg": 41.75, "power_watts_peak": 42.48, "energy_joules_est": 27.9, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:17:54.690792"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1268.24, "latencies_ms": [1268.24], "images_per_second": 0.788, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Umbrella: 1\nGirl: 1\nHedge: 1\nTruck: 1\nHouse: 2\nTrees: 3\nSky: 1\nPavement: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.1, 42.1, 42.1, 42.1, 42.1, 46.98, 46.98, 46.98, 46.98, 46.98, 42.51, 42.51, 42.51], "power_watts_avg": 44.07, "power_watts_peak": 46.98, "energy_joules_est": 55.91, "sample_count": 13, "duration_seconds": 1.269}, "timestamp": "2026-01-11T13:17:56.004239"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 846.417, "latencies_ms": [846.417], "images_per_second": 1.181, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The girl is positioned in the foreground of the image, standing on a wet sidewalk near a bush and a parked truck. The background includes houses and trees, indicating a residential setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 37.26, 37.26, 37.26, 37.26, 37.26, 42.49, 42.49], "power_watts_avg": 39.59, "power_watts_peak": 42.51, "energy_joules_est": 33.53, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-11T13:17:56.914048"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.815, "latencies_ms": [1052.815], "images_per_second": 0.95, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A young girl in a red coat is standing on a wet sidewalk, holding a blue and pink umbrella to shield herself from the rain. Behind her, a green hedge separates the sidewalk from a residential area with houses and a parked truck.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 42.49, 47.74, 47.74, 47.74, 47.74, 47.74, 42.0, 42.0, 42.0], "power_watts_avg": 44.75, "power_watts_peak": 47.74, "energy_joules_est": 47.12, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:17:58.026945"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 939.783, "latencies_ms": [939.783], "images_per_second": 1.064, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The girl is wearing a bright red coat. The umbrella she's holding is dark-colored with pink accents. The scene appears to be wet, suggesting rain. The overall atmosphere is calm and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.0, 42.0, 36.39, 36.39, 36.39, 36.39, 42.27, 42.27, 42.27, 42.27], "power_watts_avg": 39.86, "power_watts_peak": 42.27, "energy_joules_est": 37.48, "sample_count": 10, "duration_seconds": 0.94}, "timestamp": "2026-01-11T13:17:59.038813"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 757.755, "latencies_ms": [757.755], "images_per_second": 1.32, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A group of elephants, including two calves, stand together near a body of water, their dusty bodies and expressive faces creating a captivating scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.27, 42.05, 42.05, 42.05, 42.05, 42.05, 41.55, 41.55], "power_watts_avg": 41.95, "power_watts_peak": 42.27, "energy_joules_est": 31.81, "sample_count": 8, "duration_seconds": 0.758}, "timestamp": "2026-01-11T13:17:59.849395"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 916.687, "latencies_ms": [916.687], "images_per_second": 1.091, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "elephant: 3\nwater: 1\ndirt: 2\ntrees: 1\nsky: 1\nground: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.55, 41.55, 41.55, 50.04, 50.04, 50.04, 50.04, 50.04, 42.22, 42.22], "power_watts_avg": 45.93, "power_watts_peak": 50.04, "energy_joules_est": 42.13, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-11T13:18:00.861937"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 852.843, "latencies_ms": [852.843], "images_per_second": 1.173, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the elephant closest to the camera appearing larger and closer to the viewer. The background includes other elephants and a body of water, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.22, 42.22, 42.22, 41.33, 41.33, 41.33, 41.33, 41.33, 41.44], "power_watts_avg": 41.64, "power_watts_peak": 42.22, "energy_joules_est": 35.53, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-11T13:18:01.772604"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1014.662, "latencies_ms": [1014.662], "images_per_second": 0.986, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A group of elephants, including two young ones, is seen near a body of water. The elephants are dusty, indicating recent activity or movement. The setting appears to be a natural environment, possibly a savanna or dry grassland.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.44, 41.44, 41.44, 41.44, 41.88, 41.88, 41.88, 41.88, 41.88, 41.83, 41.83], "power_watts_avg": 41.71, "power_watts_peak": 41.88, "energy_joules_est": 42.35, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-11T13:18:02.885431"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 968.537, "latencies_ms": [968.537], "images_per_second": 1.032, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The elephants are primarily brown in color. The lighting appears to be natural, possibly sunlight, giving the scene a warm tone. The elephants are standing on a reddish-brown dirt surface, which contrasts with their skin color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.83, 41.83, 41.83, 41.34, 41.34, 41.34, 41.34, 41.34, 41.35, 41.35], "power_watts_avg": 41.49, "power_watts_peak": 41.83, "energy_joules_est": 40.2, "sample_count": 10, "duration_seconds": 0.969}, "timestamp": "2026-01-11T13:18:03.897593"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 781.363, "latencies_ms": [781.363], "images_per_second": 1.28, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A surfer in a red and green wetsuit is skillfully riding a wave on a white surfboard, performing an impressive aerial maneuver.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.35, 41.35, 41.35, 42.59, 42.59, 42.59, 42.59, 42.59], "power_watts_avg": 42.13, "power_watts_peak": 42.59, "energy_joules_est": 32.93, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-11T13:18:04.710177"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1056.022, "latencies_ms": [1056.022], "images_per_second": 0.947, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "surfboard: 1\nsurfer: 1\nwaves: 1\nwater: 1\nsky: 1\nclouds: 1\nshore: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 42.6, 42.6, 42.6, 42.99, 42.99, 42.99, 42.99, 42.99, 42.87], "power_watts_avg": 42.8, "power_watts_peak": 42.99, "energy_joules_est": 45.21, "sample_count": 11, "duration_seconds": 1.056}, "timestamp": "2026-01-11T13:18:05.823459"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 787.153, "latencies_ms": [787.153], "images_per_second": 1.27, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The wave extends towards the right side of the image, creating a dynamic and energetic scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 42.87, 42.87, 42.44, 42.44, 42.44, 42.44], "power_watts_avg": 42.65, "power_watts_peak": 42.87, "energy_joules_est": 33.6, "sample_count": 8, "duration_seconds": 0.788}, "timestamp": "2026-01-11T13:18:06.634886"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1050.894, "latencies_ms": [1050.894], "images_per_second": 0.952, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A surfer in a red and green wetsuit is performing an aerial maneuver on a large green wave, skillfully riding the crest and creating a large spray of water. The setting appears to be a coastal area with ocean waves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.06, 42.06, 42.06, 42.06, 42.06, 42.89, 42.89, 42.89, 42.89, 42.89, 43.2], "power_watts_avg": 42.54, "power_watts_peak": 43.2, "energy_joules_est": 44.72, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-11T13:18:07.748162"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 768.166, "latencies_ms": [768.166], "images_per_second": 1.302, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The surfer is wearing a red and green wetsuit. The wave is green and white, and the lighting suggests an overcast sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.2, 43.2, 43.2, 43.2, 41.71, 41.71, 41.71, 41.71], "power_watts_avg": 42.45, "power_watts_peak": 43.2, "energy_joules_est": 32.62, "sample_count": 8, "duration_seconds": 0.768}, "timestamp": "2026-01-11T13:18:08.558233"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 606.885, "latencies_ms": [606.885], "images_per_second": 1.648, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two men in traditional white clothing are riding horses along a sandy beach, waving to onlookers as they gallop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [41.71, 43.29, 43.29, 43.29, 43.29, 43.29, 37.26], "power_watts_avg": 42.2, "power_watts_peak": 43.29, "energy_joules_est": 25.63, "sample_count": 7, "duration_seconds": 0.607}, "timestamp": "2026-01-11T13:18:09.268912"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1064.966, "latencies_ms": [1064.966], "images_per_second": 0.939, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Horse: 2\nPerson: 2\nSword: 1\nHat: 2\nSand: 2\nOcean: 1\nSky: 1\nClouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.26, 37.26, 37.26, 37.26, 38.66, 38.66, 38.66, 38.66, 38.66, 36.28, 36.28], "power_watts_avg": 37.72, "power_watts_peak": 38.66, "energy_joules_est": 40.19, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:18:10.379155"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 633.087, "latencies_ms": [633.087], "images_per_second": 1.58, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the beach and ocean in the background. The horses are moving towards the ocean, suggesting they are moving towards a body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [36.28, 36.28, 36.28, 37.18, 37.18, 37.18, 37.18], "power_watts_avg": 36.8, "power_watts_peak": 37.18, "energy_joules_est": 23.32, "sample_count": 7, "duration_seconds": 0.634}, "timestamp": "2026-01-11T13:18:11.089119"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 765.29, "latencies_ms": [765.29], "images_per_second": 1.307, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Two men are riding horses on a sandy beach near the ocean, appearing to be engaged in a game or activity. The beach is crowded with people enjoying the sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.18, 36.9, 36.9, 36.9, 36.9, 36.9, 36.35, 36.35], "power_watts_avg": 36.8, "power_watts_peak": 37.18, "energy_joules_est": 28.18, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-11T13:18:11.899518"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 802.136, "latencies_ms": [802.136], "images_per_second": 1.247, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The sky is bright blue with scattered white clouds. The beach is sandy and appears relatively empty except for a few people. The horses are light-colored and appear to be running on the sand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.35, 36.35, 36.35, 41.87, 41.87, 41.87, 41.87, 41.87], "power_watts_avg": 39.8, "power_watts_peak": 41.87, "energy_joules_est": 31.95, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-11T13:18:12.710044"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 744.686, "latencies_ms": [744.686], "images_per_second": 1.343, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A custom-built trike with a silver engine and distinctive front suspension is parked in a driveway, accompanied by a small dog.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.99, 36.99, 36.99, 36.99, 36.99, 43.04, 43.04, 43.04], "power_watts_avg": 39.26, "power_watts_peak": 43.04, "energy_joules_est": 29.25, "sample_count": 8, "duration_seconds": 0.745}, "timestamp": "2026-01-11T13:18:13.520606"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1243.942, "latencies_ms": [1243.942], "images_per_second": 0.804, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "tire: 2\nchopper: 3\nbike: 1\nbicycle: 2\ndog: 1\ngarage: 1\ntruck: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.04, 43.04, 46.27, 46.27, 46.27, 46.27, 46.27, 42.4, 42.4, 42.4, 42.4, 42.4, 39.07], "power_watts_avg": 43.73, "power_watts_peak": 46.27, "energy_joules_est": 54.42, "sample_count": 13, "duration_seconds": 1.244}, "timestamp": "2026-01-11T13:18:14.835383"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 737.462, "latencies_ms": [737.462], "images_per_second": 1.356, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The trike is positioned in the foreground, slightly to the right of the garage. The garage is situated in the background, partially obscured by trees and bushes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.07, 39.07, 39.07, 42.09, 42.09, 42.09, 42.09, 42.09], "power_watts_avg": 40.96, "power_watts_peak": 42.09, "energy_joules_est": 30.23, "sample_count": 8, "duration_seconds": 0.738}, "timestamp": "2026-01-11T13:18:15.645682"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1186.093, "latencies_ms": [1186.093], "images_per_second": 0.843, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a custom trike with a silver engine and exposed frame, parked in a driveway in front of a garage. A small dog is sitting near the trike's frame. The garage contains various items and equipment, suggesting a workspace or workshop environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.28, 41.28, 41.28, 41.28, 41.28, 42.14, 42.14, 42.14, 42.14, 42.14, 42.85, 42.85], "power_watts_avg": 41.9, "power_watts_peak": 42.85, "energy_joules_est": 49.71, "sample_count": 12, "duration_seconds": 1.186}, "timestamp": "2026-01-11T13:18:16.858749"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1053.891, "latencies_ms": [1053.891], "images_per_second": 0.949, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The motorcycle is primarily silver and chrome. The lighting appears to be natural daylight, creating a bright and clear atmosphere. The materials used appear to be metal and possibly wood, giving it a somewhat rustic look. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.85, 43.01, 43.01, 43.01, 43.01, 43.01, 43.02, 43.02, 43.02], "power_watts_avg": 42.97, "power_watts_peak": 43.02, "energy_joules_est": 45.31, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-11T13:18:17.969945"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 747.851, "latencies_ms": [747.851], "images_per_second": 1.337, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man is flying a blue and white kite high above a sandy beach, surrounded by other beachgoers and enjoying the sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 39.05, 39.05, 39.05, 39.05, 39.05, 42.25], "power_watts_avg": 40.45, "power_watts_peak": 43.02, "energy_joules_est": 30.27, "sample_count": 8, "duration_seconds": 0.748}, "timestamp": "2026-01-11T13:18:18.781128"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1148.723, "latencies_ms": [1148.723], "images_per_second": 0.871, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "kite: 1\nperson: 1\nsand: 8\nwater: 1\ntrees: 4\nbuildings: 2\nsky: 1\nclouds: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.25, 42.25, 42.25, 42.25, 46.29, 46.29, 46.29, 46.29, 46.29, 42.11, 42.11, 42.11], "power_watts_avg": 43.9, "power_watts_peak": 46.29, "energy_joules_est": 50.45, "sample_count": 12, "duration_seconds": 1.149}, "timestamp": "2026-01-11T13:18:19.995097"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 797.622, "latencies_ms": [797.622], "images_per_second": 1.254, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The man is standing on the sandy beach, facing the water.  In the background, other people are visible on the beach and near the water's edge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.11, 42.11, 37.65, 37.65, 37.65, 37.65, 37.65, 41.7], "power_watts_avg": 39.27, "power_watts_peak": 42.11, "energy_joules_est": 31.35, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:18:20.804566"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 952.842, "latencies_ms": [952.842], "images_per_second": 1.049, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene takes place on a sandy beach near a body of water, where people are enjoying various activities. A man is flying a kite high in the sky, while others are walking along the shoreline or playing in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.7, 41.7, 41.7, 41.7, 48.11, 48.11, 48.11, 48.11, 48.11, 43.02], "power_watts_avg": 45.04, "power_watts_peak": 48.11, "energy_joules_est": 42.93, "sample_count": 10, "duration_seconds": 0.953}, "timestamp": "2026-01-11T13:18:21.812885"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 669.937, "latencies_ms": [669.937], "images_per_second": 1.493, "prompt_tokens": 18, "response_tokens_est": 23, "n_tiles": 1, "output_text": "The kite is light blue and white. The beach is sandy and appears sunny. The sky is partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 42.51, 42.51, 42.51], "power_watts_avg": 42.8, "power_watts_peak": 43.02, "energy_joules_est": 28.69, "sample_count": 7, "duration_seconds": 0.67}, "timestamp": "2026-01-11T13:18:22.520846"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1423.638, "latencies_ms": [1423.638], "images_per_second": 0.702, "prompt_tokens": 8, "response_tokens_est": 73, "n_tiles": 1, "output_text": "The kitchen counter is cluttered with various items, including cleaning supplies, a green bottle, a red bow, a silver bowl, a white bowl, a wooden cutting board, a fork, a knife, a spoon, a bottle of dish soap, a cup, a bowl, a bowl, a bottle of dish soap, a red candle, and a book.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 45.97, 45.97, 45.97, 45.97, 45.97, 42.39, 42.39, 42.39, 42.39, 42.39, 40.2, 40.2, 40.2], "power_watts_avg": 43.16, "power_watts_peak": 45.97, "energy_joules_est": 61.47, "sample_count": 15, "duration_seconds": 1.424}, "timestamp": "2026-01-11T13:18:24.037541"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1838.26, "latencies_ms": [1838.26], "images_per_second": 0.544, "prompt_tokens": 21, "response_tokens_est": 65, "n_tiles": 1, "output_text": "kitchen sink: 2\nstainless steel refrigerator: 1\nwooden cabinets: 6\nmicrowave: 1\noven: 1\ncountertop: 2\nfaucet: 1\ngreen dishwashing detergent bottle: 1\nred bow: 1\nplastic cups: 2\nglass bottles: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.2, 34.76, 34.76, 34.76, 34.76, 34.76, 41.86, 41.86, 41.86, 41.86, 41.86, 41.2, 41.2, 41.2, 41.2, 41.2, 33.19, 33.19, 33.19], "power_watts_avg": 38.36, "power_watts_peak": 41.86, "energy_joules_est": 70.54, "sample_count": 19, "duration_seconds": 1.839}, "timestamp": "2026-01-11T13:18:25.950999"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 899.624, "latencies_ms": [899.624], "images_per_second": 1.112, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The stainless steel refrigerator is positioned to the left of the kitchen counter. The sink is located in the foreground, closer to the viewer. The kitchen counter extends into the background, occupying a significant portion of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.19, 33.19, 39.62, 39.62, 39.62, 39.62, 39.62, 41.53, 41.53], "power_watts_avg": 38.61, "power_watts_peak": 41.53, "energy_joules_est": 34.75, "sample_count": 9, "duration_seconds": 0.9}, "timestamp": "2026-01-11T13:18:26.860880"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 941.465, "latencies_ms": [941.465], "images_per_second": 1.062, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The kitchen is clean and organized, with light wood cabinets, a stainless steel refrigerator, and a black countertop. A sink, dishwasher, and various kitchen items are visible on the counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.1, "ram_available_mb": 109439.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.53, 41.53, 41.53, 45.27, 45.27, 45.27, 45.27, 45.27, 43.09, 43.09], "power_watts_avg": 43.71, "power_watts_peak": 45.27, "energy_joules_est": 41.19, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:18:27.872783"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1012.356, "latencies_ms": [1012.356], "images_per_second": 0.988, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The kitchen features light brown wooden cabinets and a black countertop. The lighting is bright, likely from overhead fixtures, creating a well-lit space. The materials include wood, stainless steel, and black countertop elements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 43.09, 42.26, 42.26, 42.26, 42.26, 42.26, 42.08, 42.08, 42.08], "power_watts_avg": 42.43, "power_watts_peak": 43.09, "energy_joules_est": 42.97, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:18:28.984521"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 555.49, "latencies_ms": [555.49], "images_per_second": 1.8, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A large orange and white kite soars high in the clear blue sky, tethered to the ground by multiple lines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.08, 42.08, 35.94, 35.94, 35.94, 35.94], "power_watts_avg": 37.98, "power_watts_peak": 42.08, "energy_joules_est": 21.12, "sample_count": 6, "duration_seconds": 0.556}, "timestamp": "2026-01-11T13:18:29.593430"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1159.692, "latencies_ms": [1159.692], "images_per_second": 0.862, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "kite: 1\nkite lines: 2\nkite fabric: 1\nkite shape: 1\nkite colors: 2\nkite design: 1\nkite control: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.94, 35.87, 35.87, 35.87, 35.87, 35.87, 36.46, 36.46, 36.46, 36.46, 36.46, 37.72], "power_watts_avg": 36.27, "power_watts_peak": 37.72, "energy_joules_est": 42.08, "sample_count": 12, "duration_seconds": 1.16}, "timestamp": "2026-01-11T13:18:30.806745"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 819.476, "latencies_ms": [819.476], "images_per_second": 1.22, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main object is a kite flying high in the sky, positioned near the foreground. The kite is primarily white with red and black accents. The background is a clear, bright blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.72, 37.72, 37.72, 37.72, 37.02, 37.02, 37.02, 37.02, 37.02], "power_watts_avg": 37.33, "power_watts_peak": 37.72, "energy_joules_est": 30.6, "sample_count": 9, "duration_seconds": 0.82}, "timestamp": "2026-01-11T13:18:31.717261"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 859.451, "latencies_ms": [859.451], "images_per_second": 1.164, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A large kite soars high in the clear blue sky, controlled by a person holding the lines. The kite is primarily white with red and black accents, contrasting against the vibrant blue backdrop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.99, 36.99, 36.99, 36.99, 36.99, 35.86, 35.86, 35.86, 35.86], "power_watts_avg": 36.49, "power_watts_peak": 36.99, "energy_joules_est": 31.37, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-11T13:18:32.628585"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 570.452, "latencies_ms": [570.452], "images_per_second": 1.753, "prompt_tokens": 18, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The kite is predominantly white with red accents. The lighting suggests a sunny day with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.86, 35.2, 35.2, 35.2, 35.2, 35.2], "power_watts_avg": 35.31, "power_watts_peak": 35.86, "energy_joules_est": 20.16, "sample_count": 6, "duration_seconds": 0.571}, "timestamp": "2026-01-11T13:18:33.237463"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 755.519, "latencies_ms": [755.519], "images_per_second": 1.324, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The hotel room features two twin beds with white linens and gray throw blankets, complemented by pillows and towels.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.56, 36.56, 36.56, 36.56, 47.29, 47.29, 47.29, 47.29], "power_watts_avg": 41.93, "power_watts_peak": 47.29, "energy_joules_est": 31.7, "sample_count": 8, "duration_seconds": 0.756}, "timestamp": "2026-01-11T13:18:34.050002"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1199.844, "latencies_ms": [1199.844], "images_per_second": 0.833, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "bed: 2\npillows: 4\ntowels: 2\nnightstands: 1\nlamps: 2\nartwork: 1\nwindow: 2\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [47.29, 43.93, 43.93, 43.93, 43.93, 43.93, 42.23, 42.23, 42.23, 42.23, 42.23, 40.75], "power_watts_avg": 43.24, "power_watts_peak": 47.29, "energy_joules_est": 51.9, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-11T13:18:35.264227"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1139.746, "latencies_ms": [1139.746], "images_per_second": 0.877, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the bed and towel placed between them. The bed occupies the central portion of the image, while the towel and pillows are placed on the bedsides. The window and door are located in the background, further away from the beds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [40.75, 40.75, 40.75, 40.75, 42.31, 42.31, 42.31, 42.31, 42.31, 42.33, 42.33, 42.33], "power_watts_avg": 41.79, "power_watts_peak": 42.33, "energy_joules_est": 47.65, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-11T13:18:36.476074"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1230.228, "latencies_ms": [1230.228], "images_per_second": 0.813, "prompt_tokens": 19, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The scene depicts a hotel room with two twin beds, each adorned with gray and brown bedding and towels. The room features modern decor, including artwork on the walls and warm lighting from lamps. A window offers a view of the outside, and a door is visible on the right side of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.33, 42.33, 39.13, 39.13, 39.13, 39.13, 39.13, 41.96, 41.96, 41.96, 41.96, 41.96, 35.78], "power_watts_avg": 40.45, "power_watts_peak": 42.33, "energy_joules_est": 49.78, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-11T13:18:37.787540"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 869.413, "latencies_ms": [869.413], "images_per_second": 1.15, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The room features warm lighting from lamps and a window with natural light filtering through. The walls are painted in a light green hue, and the flooring is dark wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.78, 35.78, 35.78, 35.78, 41.89, 41.89, 41.89, 41.89, 41.89], "power_watts_avg": 39.18, "power_watts_peak": 41.89, "energy_joules_est": 34.07, "sample_count": 9, "duration_seconds": 0.87}, "timestamp": "2026-01-11T13:18:38.696210"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 854.176, "latencies_ms": [854.176], "images_per_second": 1.171, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man in a white helmet and leather suit is riding a white motorcycle with green stripes down a curving road, passing spectators standing behind a wooden fence.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 13070.4, "ram_available_mb": 109435.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.69, 41.69, 41.69, 41.69, 41.69, 42.03, 42.03, 42.03, 42.03], "power_watts_avg": 41.84, "power_watts_peak": 42.03, "energy_joules_est": 35.75, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-11T13:18:39.606412"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1318.274, "latencies_ms": [1318.274], "images_per_second": 0.759, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Motorcycle: 1\nHelmet: 1\nRider: 1\nFence: 2\nGrass: 2\nRoad: 1\nSpectators: 2\nBright sunlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.4, "ram_available_mb": 109435.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.03, 41.82, 41.82, 41.82, 41.82, 41.82, 42.34, 42.34, 42.34, 42.34, 42.34, 43.44, 43.44, 43.44], "power_watts_avg": 42.37, "power_watts_peak": 43.44, "energy_joules_est": 55.88, "sample_count": 14, "duration_seconds": 1.319}, "timestamp": "2026-01-11T13:18:41.020596"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 728.925, "latencies_ms": [728.925], "images_per_second": 1.372, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The motorcycle is positioned in the foreground, moving towards the left side of the image. The spectators are in the background, observing the motorcycle's performance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 36.65, 36.65, 36.65, 36.65, 36.65, 41.58], "power_watts_avg": 38.96, "power_watts_peak": 43.44, "energy_joules_est": 28.42, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-11T13:18:41.829525"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 864.949, "latencies_ms": [864.949], "images_per_second": 1.156, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man is riding a white motorcycle on a paved road, leaning into a turn. Spectators are gathered behind a fence, watching the motorcycle performance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.58, 41.58, 41.58, 41.58, 47.25, 47.25, 47.25, 47.25, 47.25], "power_watts_avg": 44.73, "power_watts_peak": 47.25, "energy_joules_est": 38.71, "sample_count": 9, "duration_seconds": 0.866}, "timestamp": "2026-01-11T13:18:42.738656"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 941.365, "latencies_ms": [941.365], "images_per_second": 1.062, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The motorcycle is predominantly white with green accents. The lighting suggests it might be an overcast day. The motorcycle appears to be made of metal and has a sleek, aerodynamic design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.17, 41.17, 41.17, 41.17, 41.58, 41.58, 41.58, 41.58, 41.58, 41.62], "power_watts_avg": 41.42, "power_watts_peak": 41.62, "energy_joules_est": 39.01, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:18:43.749995"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 766.128, "latencies_ms": [766.128], "images_per_second": 1.305, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The table is set for a romantic dinner, featuring white plates, silverware, wine glasses, and a centerpiece of white flowers in a vase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.6, "ram_available_mb": 109435.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13070.8, "ram_available_mb": 109435.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.62, 41.62, 41.62, 41.62, 41.49, 41.49, 41.49, 41.49], "power_watts_avg": 41.55, "power_watts_peak": 41.62, "energy_joules_est": 31.88, "sample_count": 8, "duration_seconds": 0.767}, "timestamp": "2026-01-11T13:18:44.563506"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1175.932, "latencies_ms": [1175.932], "images_per_second": 0.85, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "table: 4\nglasses: 4\nflower vase: 1\nfloral arrangement: 1\nnapkins: 2\ncutlery: 2\nchairs: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.8, "ram_available_mb": 109435.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13070.8, "ram_available_mb": 109435.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.49, 44.13, 44.13, 44.13, 44.13, 44.13, 42.56, 42.56, 42.56, 42.56, 42.56, 41.2], "power_watts_avg": 43.01, "power_watts_peak": 44.13, "energy_joules_est": 50.6, "sample_count": 12, "duration_seconds": 1.176}, "timestamp": "2026-01-11T13:18:45.776695"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1063.341, "latencies_ms": [1063.341], "images_per_second": 0.94, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and symmetrical manner. The table occupies the foreground, while the background features the window and possibly other tables and chairs. The flowers are placed centrally in the vase, creating a focal point.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.8, "ram_available_mb": 109435.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13070.8, "ram_available_mb": 109435.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.2, 41.2, 41.2, 41.2, 42.34, 42.34, 42.34, 42.34, 42.34, 42.49, 42.49], "power_watts_avg": 41.95, "power_watts_peak": 42.49, "energy_joules_est": 44.63, "sample_count": 11, "duration_seconds": 1.064}, "timestamp": "2026-01-11T13:18:46.887869"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1480.576, "latencies_ms": [1480.576], "images_per_second": 0.675, "prompt_tokens": 19, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene depicts a sophisticated dining setting with a table set for a meal, featuring white tablecloths, neatly folded napkins, wine glasses, and silverware. A centerpiece of white flowers in a glass vase adds a touch of elegance and freshness to the table. The background suggests a restaurant or upscale dining establishment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13070.8, "ram_available_mb": 109435.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.6, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 42.49, 42.55, 42.55, 42.55, 42.55, 42.55, 42.7, 42.7, 42.7, 42.7, 42.7, 33.0, 33.0], "power_watts_avg": 41.31, "power_watts_peak": 42.7, "energy_joules_est": 61.18, "sample_count": 15, "duration_seconds": 1.481}, "timestamp": "2026-01-11T13:18:48.403770"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1157.578, "latencies_ms": [1157.578], "images_per_second": 0.864, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The table is covered with a pristine white tablecloth. The centerpiece is a vase filled with delicate white flowers, illuminated by a soft, warm light source. The table setting includes several wine glasses and silverware, ready for a meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.6, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.6, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.0, 33.0, 33.0, 42.58, 42.58, 42.58, 42.58, 42.58, 42.7, 42.7, 42.7, 42.7], "power_watts_avg": 40.22, "power_watts_peak": 42.7, "energy_joules_est": 46.57, "sample_count": 12, "duration_seconds": 1.158}, "timestamp": "2026-01-11T13:18:49.618376"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 637.982, "latencies_ms": [637.982], "images_per_second": 1.567, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A tall, ornate clock tower with two clock faces stands prominently against a hazy sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13066.6, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.7, 32.45, 32.45, 32.45, 32.45, 32.45, 43.15], "power_watts_avg": 35.44, "power_watts_peak": 43.15, "energy_joules_est": 22.62, "sample_count": 7, "duration_seconds": 0.638}, "timestamp": "2026-01-11T13:18:50.327297"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1394.812, "latencies_ms": [1394.812], "images_per_second": 0.717, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "clock: 2\npole: 1\nclock face: 2\nclock hands: 2\nclock numbers: 10, 11, 12, 13, 14, 15, 16, 17\nfield: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.15, 43.15, 43.15, 43.15, 54.0, 54.0, 54.0, 54.0, 54.0, 43.34, 43.34, 43.34, 43.34, 43.34], "power_watts_avg": 47.09, "power_watts_peak": 54.0, "energy_joules_est": 65.71, "sample_count": 14, "duration_seconds": 1.395}, "timestamp": "2026-01-11T13:18:51.742104"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 856.002, "latencies_ms": [856.002], "images_per_second": 1.168, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The clock is positioned in the foreground, slightly to the right of the viewer. The field in the background is further away and appears smaller, suggesting the viewer is at a distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.09, 33.09, 33.09, 33.09, 43.67, 43.67, 43.67, 43.67, 43.67], "power_watts_avg": 38.97, "power_watts_peak": 43.67, "energy_joules_est": 33.38, "sample_count": 9, "duration_seconds": 0.857}, "timestamp": "2026-01-11T13:18:52.652826"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1048.282, "latencies_ms": [1048.282], "images_per_second": 0.954, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene features a square clock mounted on a pole, displaying the time. The background is blurred, suggesting an outdoor setting, possibly a park or a field. The image is in black and white, giving it a timeless and classic feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.04, 43.04, 43.04, 43.04, 43.04, 43.65, 43.65, 43.65, 43.65, 43.65, 44.27], "power_watts_avg": 43.43, "power_watts_peak": 44.27, "energy_joules_est": 45.55, "sample_count": 11, "duration_seconds": 1.049}, "timestamp": "2026-01-11T13:18:53.762014"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1377.805, "latencies_ms": [1377.805], "images_per_second": 0.726, "prompt_tokens": 18, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The clock is primarily dark, possibly black or dark gray. The lighting appears to be soft and diffused, possibly from overcast conditions. The clock's materials appear to be metal, giving it a sturdy and durable appearance. The weather appears to be overcast, contributing to the muted and somewhat moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.27, 44.27, 44.27, 44.27, 42.98, 42.98, 42.98, 42.98, 42.98, 42.77, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 43.27, "power_watts_peak": 44.27, "energy_joules_est": 59.65, "sample_count": 14, "duration_seconds": 1.378}, "timestamp": "2026-01-11T13:18:55.178534"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 851.838, "latencies_ms": [851.838], "images_per_second": 1.174, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A young man in a black t-shirt and baseball cap skillfully maneuvers his skateboard on a concrete surface, performing a trick while surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [32.88, 32.88, 32.88, 32.88, 32.88, 42.15, 42.15, 42.15, 42.15], "power_watts_avg": 37.0, "power_watts_peak": 42.15, "energy_joules_est": 31.54, "sample_count": 9, "duration_seconds": 0.852}, "timestamp": "2026-01-11T13:18:56.091445"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1324.261, "latencies_ms": [1324.261], "images_per_second": 0.755, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "skateboard: 1\nbaseball cap: 1\nt-shirt: 1\npants: 1\nshoes: 1\nskateboard: 1\nground: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.15, 42.92, 42.92, 42.92, 42.92, 42.92, 42.08, 42.08, 42.08, 42.08, 42.08, 41.63, 41.63, 41.63], "power_watts_avg": 42.29, "power_watts_peak": 42.92, "energy_joules_est": 56.02, "sample_count": 14, "duration_seconds": 1.325}, "timestamp": "2026-01-11T13:18:57.504908"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 825.95, "latencies_ms": [825.95], "images_per_second": 1.211, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, moving towards the left side of the image. The skate park is situated in the background, extending beyond the immediate foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 57.0}, "power_stats": {"power_watts_samples": [41.63, 41.63, 38.11, 38.11, 38.11, 38.11, 38.11, 41.81, 41.81], "power_watts_avg": 39.72, "power_watts_peak": 41.81, "energy_joules_est": 32.81, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:18:58.415196"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.837, "latencies_ms": [1116.837], "images_per_second": 0.895, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A young man is skateboarding in a skate park, performing a trick on a paved surface. He wears a black t-shirt and baseball cap. The park is surrounded by trees, and there are other skateboarders visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.8, "ram_available_mb": 109439.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [41.81, 41.81, 41.81, 46.94, 46.94, 46.94, 46.94, 46.94, 41.89, 41.89, 41.89, 41.89], "power_watts_avg": 43.98, "power_watts_peak": 46.94, "energy_joules_est": 49.14, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-11T13:18:59.628570"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1018.449, "latencies_ms": [1018.449], "images_per_second": 0.982, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skateboarder is wearing a black t-shirt and gray pants. The skateboard is black and appears to be made of wood. The lighting suggests an overcast day, and the scene takes place outdoors on a paved surface.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13066.7, "ram_available_mb": 109439.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.89, 31.09, 31.09, 31.09, 31.09, 31.09, 41.72, 41.72, 41.72, 41.72, 41.72], "power_watts_avg": 36.9, "power_watts_peak": 41.89, "energy_joules_est": 37.6, "sample_count": 11, "duration_seconds": 1.019}, "timestamp": "2026-01-11T13:19:00.739482"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 631.581, "latencies_ms": [631.581], "images_per_second": 1.583, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A white plate is filled with freshly peeled and cut carrots, accompanied by a blue vegetable peeler and a small pile of beets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.0, "ram_available_mb": 109439.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.67, 43.67, 43.67, 43.67, 36.24, 36.24, 36.24], "power_watts_avg": 40.48, "power_watts_peak": 43.67, "energy_joules_est": 25.59, "sample_count": 7, "duration_seconds": 0.632}, "timestamp": "2026-01-11T13:19:01.449792"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1094.958, "latencies_ms": [1094.958], "images_per_second": 0.913, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "carrots: 20\nbeets: 3\ngreen beans: 4\ncarrot peeler: 1\nsink: 1\ncutting board: 1\nkitchen sink: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [36.24, 36.24, 39.93, 39.93, 39.93, 39.93, 39.93, 36.54, 36.54, 36.54, 36.54], "power_watts_avg": 38.03, "power_watts_peak": 39.93, "energy_joules_est": 41.65, "sample_count": 11, "duration_seconds": 1.095}, "timestamp": "2026-01-11T13:19:02.557391"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1075.861, "latencies_ms": [1075.861], "images_per_second": 0.929, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The main objects are positioned in a way that suggests they are being prepared for consumption. The carrots are in the foreground, while the beets are in the background, separated by a small gap. The plate and cutting board are placed in the background, further emphasizing the preparation process.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.54, 35.38, 35.38, 35.38, 35.38, 35.38, 36.81, 36.81, 36.81, 36.81, 36.81], "power_watts_avg": 36.14, "power_watts_peak": 36.81, "energy_joules_est": 38.9, "sample_count": 11, "duration_seconds": 1.076}, "timestamp": "2026-01-11T13:19:03.670311"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 859.499, "latencies_ms": [859.499], "images_per_second": 1.163, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts a kitchen counter with a plate of freshly peeled and cut carrots, along with some beets and a peeler. The counter also features a dish rack, a knife, and a cup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 34.77, 34.77, 37.03, 37.03, 37.03, 37.03], "power_watts_avg": 35.78, "power_watts_peak": 37.03, "energy_joules_est": 30.77, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-11T13:19:04.581637"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 825.25, "latencies_ms": [825.25], "images_per_second": 1.212, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The carrots are bright orange and appear to be freshly peeled. The plate is white and round. The vegetables are placed on a countertop. The lighting is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [37.03, 38.48, 38.48, 38.48, 38.48, 38.48, 36.52, 36.52, 36.52], "power_watts_avg": 37.67, "power_watts_peak": 38.48, "energy_joules_est": 31.11, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:19:05.491633"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 757.36, "latencies_ms": [757.36], "images_per_second": 1.32, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man is giving a presentation or lecture on a large screen, gesturing with his hands as he speaks to attentive audience members.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [36.52, 36.52, 41.38, 41.38, 41.38, 41.38, 41.38, 41.56], "power_watts_avg": 40.19, "power_watts_peak": 41.56, "energy_joules_est": 30.46, "sample_count": 8, "duration_seconds": 0.758}, "timestamp": "2026-01-11T13:19:06.303180"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1053.543, "latencies_ms": [1053.543], "images_per_second": 0.949, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "projection screen: 1\nman: 1\nsuit: 1\ntie: 1\ntable: 1\npeople: 2\nhair: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.9, "ram_available_mb": 109439.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13067.4, "ram_available_mb": 109438.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [41.56, 41.56, 41.56, 41.56, 46.32, 46.32, 46.32, 46.32, 46.32, 42.43, 42.43], "power_watts_avg": 43.88, "power_watts_peak": 46.32, "energy_joules_est": 46.25, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-11T13:19:07.416570"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1216.652, "latencies_ms": [1216.652], "images_per_second": 0.822, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main object is a man giving a presentation or lecture, positioned centrally and slightly to the right of the screen. The audience is seated in the foreground, facing the screen and likely listening intently. The screen is positioned in the background, extending beyond the audience's view.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.4, "ram_available_mb": 109438.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.43, 42.43, 42.43, 42.03, 42.03, 42.03, 42.03, 42.03, 41.96, 41.96, 41.96, 41.96, 41.96], "power_watts_avg": 42.1, "power_watts_peak": 42.43, "energy_joules_est": 51.24, "sample_count": 13, "duration_seconds": 1.217}, "timestamp": "2026-01-11T13:19:08.727886"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 985.964, "latencies_ms": [985.964], "images_per_second": 1.014, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a presentation taking place on a large screen, possibly in a conference room or auditorium. Two people are visible, seemingly attending the presentation, with one person gesturing while the other is seated.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.04, 33.04, 33.04, 33.04, 33.04, 41.41, 41.41, 41.41, 41.41, 41.41], "power_watts_avg": 37.22, "power_watts_peak": 41.41, "energy_joules_est": 36.73, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-11T13:19:09.740452"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1111.076, "latencies_ms": [1111.076], "images_per_second": 0.9, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The screen displays a vibrant teal background with geometric shapes in orange and purple. The lighting is bright, illuminating the screen and highlighting the speaker. The screen appears to be made of a flexible material, potentially fabric or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.57, 41.57, 41.57, 41.57, 42.97, 42.97, 42.97, 42.97, 42.97, 43.02, 43.02, 43.02], "power_watts_avg": 42.51, "power_watts_peak": 43.02, "energy_joules_est": 47.25, "sample_count": 12, "duration_seconds": 1.111}, "timestamp": "2026-01-11T13:19:10.952832"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 690.886, "latencies_ms": [690.886], "images_per_second": 1.447, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two workers in blue uniforms are sitting on a chair outside a building, conversing while one holds a broom.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 39.68, 39.68, 39.68, 39.68, 39.68], "power_watts_avg": 40.63, "power_watts_peak": 43.02, "energy_joules_est": 28.08, "sample_count": 7, "duration_seconds": 0.691}, "timestamp": "2026-01-11T13:19:11.664424"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1132.151, "latencies_ms": [1132.151], "images_per_second": 0.883, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "scooter: 2\nchair: 1\nman: 2\nwoman: 1\nbroom: 1\nsign: 2\nstreet: 1\nbuilding: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.51, 41.51, 41.51, 41.51, 41.51, 45.26, 45.26, 45.26, 45.26, 45.26, 43.4, 43.4], "power_watts_avg": 43.39, "power_watts_peak": 45.26, "energy_joules_est": 49.15, "sample_count": 12, "duration_seconds": 1.133}, "timestamp": "2026-01-11T13:19:12.876553"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 903.644, "latencies_ms": [903.644], "images_per_second": 1.107, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The mop is positioned in the foreground, close to the two workers. The mop is situated between the workers and the parked motorcycles. The background features the storefront and signage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.4, 43.4, 43.4, 42.06, 42.06, 42.06, 42.06, 42.06, 42.04], "power_watts_avg": 42.5, "power_watts_peak": 43.4, "energy_joules_est": 38.43, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:19:13.788043"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 855.467, "latencies_ms": [855.467], "images_per_second": 1.169, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two men in blue uniforms are sitting and standing on a city street near a building with signs and advertisements. Parked motorbikes are visible nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.6, "ram_available_mb": 109438.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.04, 42.04, 42.04, 42.04, 43.54, 43.54, 43.54, 43.54, 43.54], "power_watts_avg": 42.87, "power_watts_peak": 43.54, "energy_joules_est": 36.7, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-11T13:19:14.699989"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1235.674, "latencies_ms": [1235.674], "images_per_second": 0.809, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The street scene is dominated by blue and white colors, creating a vibrant and somewhat industrial atmosphere. The lighting appears to be natural daylight, suggesting an overcast day or possibly late afternoon. The street is paved with asphalt, contributing to the overall urban feel of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 43.52, 43.52, 43.52, 41.89, 41.89, 41.89, 41.89, 41.89, 41.62, 41.62, 41.62], "power_watts_avg": 42.45, "power_watts_peak": 43.52, "energy_joules_est": 52.48, "sample_count": 13, "duration_seconds": 1.236}, "timestamp": "2026-01-11T13:19:16.008171"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 779.369, "latencies_ms": [779.369], "images_per_second": 1.283, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A white plate holds a serving of shredded chicken and a bowl of broccoli slaw, accompanied by a fork on a beige carpeted floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.62, 41.62, 37.4, 37.4, 37.4, 37.4, 37.4, 43.01], "power_watts_avg": 39.16, "power_watts_peak": 43.01, "energy_joules_est": 30.54, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-11T13:19:16.819492"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1065.077, "latencies_ms": [1065.077], "images_per_second": 0.939, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "chicken: 2\nbroccoli: 2\ncasserole: 1\nfork: 1\nplastic plate: 1\ncarpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.01, 49.29, 49.29, 49.29, 49.29, 49.29, 43.69, 43.69], "power_watts_avg": 45.99, "power_watts_peak": 49.29, "energy_joules_est": 49.0, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:19:17.929032"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 581.166, "latencies_ms": [581.166], "images_per_second": 1.721, "prompt_tokens": 25, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The chicken and broccoli are positioned in the foreground, with the fork resting on the plate behind them.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13067.8, "ram_available_mb": 109438.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13067.8, "ram_available_mb": 109438.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.69, 41.89, 41.89, 41.89], "power_watts_avg": 42.79, "power_watts_peak": 43.69, "energy_joules_est": 24.9, "sample_count": 6, "duration_seconds": 0.582}, "timestamp": "2026-01-11T13:19:18.539255"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 888.961, "latencies_ms": [888.961], "images_per_second": 1.125, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A white plate holds a serving of shredded chicken and broccoli. A fork is placed next to the plate. The setting appears to be a casual dining environment, possibly at home or a restaurant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.8, "ram_available_mb": 109438.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.8, "ram_available_mb": 109438.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [41.89, 41.89, 47.43, 47.43, 47.43, 47.43, 45.63, 45.63, 45.63], "power_watts_avg": 45.6, "power_watts_peak": 47.43, "energy_joules_est": 40.56, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:19:19.449988"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1343.021, "latencies_ms": [1343.021], "images_per_second": 0.745, "prompt_tokens": 18, "response_tokens_est": 66, "n_tiles": 1, "output_text": "The food in the image is primarily yellow and green in color. The lighting appears to be soft and diffused, creating a warm and inviting atmosphere. The food appears to be served on a white styrofoam plate, which contrasts with the colors of the dish. The overall presentation suggests a casual, home-cooked meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13067.8, "ram_available_mb": 109438.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13067.8, "ram_available_mb": 109438.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.63, 45.63, 49.3, 49.3, 49.3, 49.3, 49.3, 43.96, 43.96, 43.96, 43.96, 43.96, 35.5, 35.5], "power_watts_avg": 44.9, "power_watts_peak": 49.3, "energy_joules_est": 60.32, "sample_count": 14, "duration_seconds": 1.344}, "timestamp": "2026-01-11T13:19:20.864392"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 694.314, "latencies_ms": [694.314], "images_per_second": 1.44, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man wearing a blue shirt, red tie, plaid cap, and round sunglasses stands in front of a building, smiling warmly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13068.0, "ram_available_mb": 109438.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13068.7, "ram_available_mb": 109437.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.5, 35.5, 35.5, 41.69, 41.69, 41.69, 41.69], "power_watts_avg": 39.04, "power_watts_peak": 41.69, "energy_joules_est": 27.12, "sample_count": 7, "duration_seconds": 0.695}, "timestamp": "2026-01-11T13:19:21.573230"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1041.442, "latencies_ms": [1041.442], "images_per_second": 0.96, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "hat: 1\nglasses: 2\nshirt: 1\ntie: 1\npool: 1\nwall: 1\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13068.7, "ram_available_mb": 109437.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13068.7, "ram_available_mb": 109437.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.69, 44.26, 44.26, 44.26, 44.26, 44.26, 42.91, 42.91, 42.91, 42.91, 42.91], "power_watts_avg": 43.42, "power_watts_peak": 44.26, "energy_joules_est": 45.24, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:19:22.686850"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 920.92, "latencies_ms": [920.92], "images_per_second": 1.086, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the background elements blurred, suggesting they are further away or out of focus. The man is standing near a wall or structure, further back from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13068.7, "ram_available_mb": 109437.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13068.7, "ram_available_mb": 109437.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.32, 41.32, 41.32, 41.32, 41.32, 42.04, 42.04, 42.04, 42.04, 42.04], "power_watts_avg": 41.68, "power_watts_peak": 42.04, "energy_joules_est": 38.41, "sample_count": 10, "duration_seconds": 0.921}, "timestamp": "2026-01-11T13:19:23.697622"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 890.378, "latencies_ms": [890.378], "images_per_second": 1.123, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A man wearing a blue shirt, red tie, and plaid cap is smiling at the camera. He appears to be outdoors, possibly near a building, with a blurred background suggesting a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13068.7, "ram_available_mb": 109437.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.48, 41.48, 41.48, 41.48, 41.48, 41.72, 41.72, 41.72, 41.72], "power_watts_avg": 41.58, "power_watts_peak": 41.72, "energy_joules_est": 37.05, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:19:24.609166"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 862.61, "latencies_ms": [862.61], "images_per_second": 1.159, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The man is wearing a blue shirt and a red tie. His hat is black and gray plaid. The lighting appears to be natural, possibly sunlight, and the background suggests an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.72, 42.57, 42.57, 42.57, 42.57, 42.57, 43.11, 43.11, 43.11], "power_watts_avg": 42.66, "power_watts_peak": 43.11, "energy_joules_est": 36.82, "sample_count": 9, "duration_seconds": 0.863}, "timestamp": "2026-01-11T13:19:25.520765"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 691.315, "latencies_ms": [691.315], "images_per_second": 1.447, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The image features six different slices of pizza arranged on white plates, showcasing a variety of toppings and sauces.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 38.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 48.05, 48.05, 48.05, 48.05, 48.05], "power_watts_avg": 46.64, "power_watts_peak": 48.05, "energy_joules_est": 32.26, "sample_count": 7, "duration_seconds": 0.692}, "timestamp": "2026-01-11T13:19:26.231989"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2070.515, "latencies_ms": [2070.515], "images_per_second": 0.483, "prompt_tokens": 21, "response_tokens_est": 75, "n_tiles": 1, "output_text": "slice of pizza: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.68, 43.68, 43.68, 43.68, 43.68, 50.56, 50.56, 50.56, 50.56, 50.56, 44.25, 44.25, 44.25, 44.25, 32.96, 32.96, 32.96, 32.96, 32.96, 32.88, 32.88], "power_watts_avg": 41.85, "power_watts_peak": 50.56, "energy_joules_est": 86.66, "sample_count": 21, "duration_seconds": 2.071}, "timestamp": "2026-01-11T13:19:28.352628"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 752.329, "latencies_ms": [752.329], "images_per_second": 1.329, "prompt_tokens": 25, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The main object, pizza slice, occupies the foreground of the image. The background includes additional pizza slices and partially visible plates.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13068.9, "ram_available_mb": 109437.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [32.88, 32.88, 32.88, 42.27, 42.27, 42.27, 42.27, 42.27], "power_watts_avg": 38.75, "power_watts_peak": 42.27, "energy_joules_est": 29.21, "sample_count": 8, "duration_seconds": 0.754}, "timestamp": "2026-01-11T13:19:29.213908"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1213.133, "latencies_ms": [1213.133], "images_per_second": 0.824, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a casual dining setting, likely in a restaurant or pizzeria, where various slices of pizza are presented on white plates. The pizza slices vary in toppings and sauces, showcasing a diverse range of flavors and styles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13068.9, "ram_available_mb": 109437.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13068.9, "ram_available_mb": 109437.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 42.46, 42.46, 42.46, 44.51, 44.51, 44.51, 44.51, 44.51, 43.46, 43.46, 43.46], "power_watts_avg": 43.48, "power_watts_peak": 44.51, "energy_joules_est": 52.76, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-11T13:19:30.528238"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1198.64, "latencies_ms": [1198.64], "images_per_second": 0.834, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The pizza slices exhibit a range of colors, including yellows, greens, and browns. The lighting in the image appears to be soft and warm, creating a pleasant ambiance. The pizza appears to be made with traditional ingredients, suggesting it might be a classic or homemade dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13068.9, "ram_available_mb": 109437.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13068.9, "ram_available_mb": 109437.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 36.15, 36.15, 36.15, 36.15, 36.15, 42.24, 42.24, 42.24, 42.24, 42.24], "power_watts_avg": 39.9, "power_watts_peak": 43.46, "energy_joules_est": 47.85, "sample_count": 12, "duration_seconds": 1.199}, "timestamp": "2026-01-11T13:19:31.742815"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 670.635, "latencies_ms": [670.635], "images_per_second": 1.491, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two young girls in colorful dresses are petting a black goat while standing behind a metal fence.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13068.9, "ram_available_mb": 109437.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.24, 40.24, 40.24, 40.24, 42.84, 42.84, 42.84], "power_watts_avg": 41.35, "power_watts_peak": 42.84, "energy_joules_est": 27.75, "sample_count": 7, "duration_seconds": 0.671}, "timestamp": "2026-01-11T13:19:32.453938"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 938.802, "latencies_ms": [938.802], "images_per_second": 1.065, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "goat: 2\ngirl: 2\nfence: 2\ngrass: 2\nman: 1\ngoat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 51.16, 51.16, 51.16, 51.16, 51.16, 43.09, 43.09, 43.09], "power_watts_avg": 47.07, "power_watts_peak": 51.16, "energy_joules_est": 44.21, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-11T13:19:33.465800"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1219.776, "latencies_ms": [1219.776], "images_per_second": 0.82, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the goat being the most prominent object. The children's interaction with the goat suggests a close relationship, potentially a petting or feeding experience. The background features additional elements like a fence and a person walking by, further emphasizing the outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 42.98, 42.98, 42.98, 42.98, 42.98, 42.58, 42.58, 42.58, 42.58, 42.58, 36.48], "power_watts_avg": 42.34, "power_watts_peak": 43.09, "energy_joules_est": 51.67, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:19:34.779616"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 983.894, "latencies_ms": [983.894], "images_per_second": 1.016, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Two young girls are petting a black goat at a petting zoo or farm. The goat is standing next to a white goat. The setting is outdoors, with a fence separating the girls from the animals.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.48, 36.48, 36.48, 36.48, 41.93, 41.93, 41.93, 41.93, 41.93, 42.07], "power_watts_avg": 39.76, "power_watts_peak": 42.07, "energy_joules_est": 39.15, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-11T13:19:35.791262"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 756.723, "latencies_ms": [756.723], "images_per_second": 1.321, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The girls are wearing colorful dresses. The goat is black, and the goat's horns are visible. The scene appears to be outdoors in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.07, 42.07, 42.07, 42.07, 43.29, 43.29, 43.29, 43.29], "power_watts_avg": 42.68, "power_watts_peak": 43.29, "energy_joules_est": 32.32, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:19:36.600017"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 751.009, "latencies_ms": [751.009], "images_per_second": 1.332, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The scene captures a busy intersection at dusk, with multiple traffic lights glowing green, cars waiting at the lights, and street signs visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [43.29, 43.3, 43.3, 43.3, 43.3, 43.3, 42.68, 42.68], "power_watts_avg": 43.14, "power_watts_peak": 43.3, "energy_joules_est": 32.41, "sample_count": 8, "duration_seconds": 0.751}, "timestamp": "2026-01-11T13:19:37.410894"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1156.871, "latencies_ms": [1156.871], "images_per_second": 0.864, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "traffic light: 2\nstreet sign: 1\npower lines: 6\nbuildings: 2\nmountains: 1\ncars: 2\nstreetlights: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [42.68, 42.68, 42.68, 52.29, 52.29, 52.29, 52.29, 52.29, 42.33, 42.33, 42.33, 42.33], "power_watts_avg": 46.57, "power_watts_peak": 52.29, "energy_joules_est": 53.9, "sample_count": 12, "duration_seconds": 1.157}, "timestamp": "2026-01-11T13:19:38.623538"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1213.099, "latencies_ms": [1213.099], "images_per_second": 0.824, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The traffic light is positioned on the left side of the image, angled towards the viewer. The street extends into the distance, disappearing into the darkness, creating a sense of depth and distance. The traffic light is situated in the foreground, contrasting with the darkened background and the distant street lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.1, "ram_available_mb": 109437.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.33, 32.36, 32.36, 32.36, 32.36, 32.36, 42.29, 42.29, 42.29, 42.29, 42.29, 43.58, 43.58], "power_watts_avg": 38.67, "power_watts_peak": 43.58, "energy_joules_est": 46.93, "sample_count": 13, "duration_seconds": 1.214}, "timestamp": "2026-01-11T13:19:39.935190"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1173.454, "latencies_ms": [1173.454], "images_per_second": 0.852, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene depicts a city intersection at dusk or dawn. The sky is a deep blue, transitioning to orange and pink hues near the horizon. Streetlights illuminate the area, and traffic lights are visible, controlling the flow of vehicles and pedestrians.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 43.58, 40.81, 40.81, 40.81, 40.81, 40.81, 41.76, 41.76, 41.76, 41.76], "power_watts_avg": 41.82, "power_watts_peak": 43.58, "energy_joules_est": 49.09, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-11T13:19:41.144275"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1027.625, "latencies_ms": [1027.625], "images_per_second": 0.973, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The sky is a deep blue, indicating it's likely dusk or early evening. The traffic lights are illuminated green, signaling that vehicles can proceed. The street is dark and appears empty, with some faint lights in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.76, 33.2, 33.2, 33.2, 33.2, 42.85, 42.85, 42.85, 42.85, 42.85, 43.69], "power_watts_avg": 39.32, "power_watts_peak": 43.69, "energy_joules_est": 40.42, "sample_count": 11, "duration_seconds": 1.028}, "timestamp": "2026-01-11T13:19:42.258209"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 555.239, "latencies_ms": [555.239], "images_per_second": 1.801, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A woman stands behind a table displaying several bunches of ripe, yellow bananas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.69, 43.69, 41.99, 41.99], "power_watts_avg": 43.12, "power_watts_peak": 43.69, "energy_joules_est": 23.96, "sample_count": 6, "duration_seconds": 0.556}, "timestamp": "2026-01-11T13:19:42.868249"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 780.456, "latencies_ms": [780.456], "images_per_second": 1.281, "prompt_tokens": 21, "response_tokens_est": 20, "n_tiles": 1, "output_text": "bananas: 5\nwoman: 1\ntable: 1\nbuilding: 2\npeople: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 51.17, 51.17, 51.17, 51.17, 51.17], "power_watts_avg": 47.73, "power_watts_peak": 51.17, "energy_joules_est": 37.26, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:19:43.679322"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 782.833, "latencies_ms": [782.833], "images_per_second": 1.277, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bananas are in the foreground, slightly blurred, while the woman stands in the background, slightly out of focus. The bananas are positioned closer to the viewer, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.64, 42.64, 42.64, 42.64, 42.64, 43.29, 43.29, 43.29], "power_watts_avg": 42.88, "power_watts_peak": 43.29, "energy_joules_est": 33.59, "sample_count": 8, "duration_seconds": 0.783}, "timestamp": "2026-01-11T13:19:44.489664"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 805.352, "latencies_ms": [805.352], "images_per_second": 1.242, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A woman stands behind a table displaying several bunches of ripe, yellow bananas. The setting appears to be an outdoor market or marketplace, with a building visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [43.29, 43.29, 50.19, 50.19, 50.19, 50.19, 50.19, 43.31, 43.31], "power_watts_avg": 47.13, "power_watts_peak": 50.19, "energy_joules_est": 37.97, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-11T13:19:45.399910"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1144.503, "latencies_ms": [1144.503], "images_per_second": 0.874, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The bananas are yellow, indicating they are ripe. The lighting appears to be natural, possibly from the sun, giving them a warm glow. The bananas appear to be made of ripe bananas and possibly a natural material like wood or bamboo. The overall scene suggests a sunny outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.31, 43.31, 43.31, 44.99, 44.99, 44.99, 44.99, 44.99, 41.63, 41.63, 41.63, 41.63], "power_watts_avg": 43.45, "power_watts_peak": 44.99, "energy_joules_est": 49.75, "sample_count": 12, "duration_seconds": 1.145}, "timestamp": "2026-01-11T13:19:46.612343"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 652.635, "latencies_ms": [652.635], "images_per_second": 1.532, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A green door with graffiti is visible in front of a red brick building with a fire escape and a green awning.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [41.63, 32.25, 32.25, 32.25, 32.25, 32.25, 43.7], "power_watts_avg": 35.23, "power_watts_peak": 43.7, "energy_joules_est": 23.01, "sample_count": 7, "duration_seconds": 0.653}, "timestamp": "2026-01-11T13:19:47.321548"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1258.75, "latencies_ms": [1258.75], "images_per_second": 0.794, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "building: 4\nfire escape: 1\ngarage doors: 2\nfire hydrant: 1\nbicycle: 1\ntree: 1\nsidewalk: 1\nstreet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.7, 43.7, 43.7, 43.7, 55.44, 55.44, 55.44, 55.44, 55.44, 43.84, 43.84, 43.84, 43.84], "power_watts_avg": 48.26, "power_watts_peak": 55.44, "energy_joules_est": 60.77, "sample_count": 13, "duration_seconds": 1.259}, "timestamp": "2026-01-11T13:19:48.636316"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 795.565, "latencies_ms": [795.565], "images_per_second": 1.257, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The building is positioned in the foreground, with the fire escape and windows located on its right side. The bicycle is situated to the left of the building, near the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13069.0, "ram_available_mb": 109437.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.84, 32.15, 32.15, 32.15, 32.15, 32.15, 44.08, 44.08], "power_watts_avg": 36.59, "power_watts_peak": 44.08, "energy_joules_est": 29.12, "sample_count": 8, "duration_seconds": 0.796}, "timestamp": "2026-01-11T13:19:49.444738"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1041.614, "latencies_ms": [1041.614], "images_per_second": 0.96, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a red brick building with green metal shutters and graffiti on its facade. A green door is visible, flanked by a fire escape. A bicycle is parked on the sidewalk in front of the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.08, 44.08, 44.08, 53.99, 53.99, 53.99, 53.99, 44.53, 44.53, 44.53, 44.53], "power_watts_avg": 47.85, "power_watts_peak": 53.99, "energy_joules_est": 49.85, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:19:50.556927"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 992.967, "latencies_ms": [992.967], "images_per_second": 1.007, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The building is primarily red brick with green metal accents, including shutters and a fire escape. The lighting appears to be natural daylight, and the overall appearance suggests a somewhat run-down or urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 15.0}, "power_stats": {"power_watts_samples": [44.53, 38.05, 38.05, 38.05, 38.05, 38.05, 43.23, 43.23, 43.23, 43.23], "power_watts_avg": 40.77, "power_watts_peak": 44.53, "energy_joules_est": 40.5, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-11T13:19:51.570641"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 892.551, "latencies_ms": [892.551], "images_per_second": 1.12, "prompt_tokens": 8, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A man with long curly hair, wearing a black shirt and a blue and white striped hat, is captured mid-throw of a yellow frisbee, drawing the attention of a crowd.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [43.23, 43.63, 43.63, 43.63, 43.63, 43.63, 43.09, 43.09, 43.09], "power_watts_avg": 43.41, "power_watts_peak": 43.63, "energy_joules_est": 38.76, "sample_count": 9, "duration_seconds": 0.893}, "timestamp": "2026-01-11T13:19:52.483480"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1254.955, "latencies_ms": [1254.955], "images_per_second": 0.797, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Frisbee: 1\nPerson: 1\nHeadband: 1\nT-shirt: 1\nGround: 1\nCeiling: 1\nLighting: 1\nAudience: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 48.82, 48.82, 48.82, 48.82, 48.82, 43.72, 43.72, 43.72, 43.72, 43.72, 36.8], "power_watts_avg": 45.05, "power_watts_peak": 48.82, "energy_joules_est": 56.57, "sample_count": 13, "duration_seconds": 1.256}, "timestamp": "2026-01-11T13:19:53.798421"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1149.026, "latencies_ms": [1149.026], "images_per_second": 0.87, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The man is positioned in the foreground, throwing the frisbee towards the right side of the image. The frisbee is relatively close to the man's hand, suggesting an active throwing motion. The background is slightly blurred, indicating a focus on the man and the frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.8, 36.8, 36.8, 36.8, 42.91, 42.91, 42.91, 42.91, 42.91, 42.84, 42.84, 42.84], "power_watts_avg": 40.86, "power_watts_peak": 42.91, "energy_joules_est": 46.97, "sample_count": 12, "duration_seconds": 1.15}, "timestamp": "2026-01-11T13:19:55.011217"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 999.046, "latencies_ms": [999.046], "images_per_second": 1.001, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A man is captured mid-throw of a yellow frisbee, seemingly in a dimly lit indoor space, possibly a park or event venue.  A crowd of people is visible in the background, observing the action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 38.3, 38.3, 38.3, 38.3, 38.3, 42.89, 42.89, 42.89], "power_watts_avg": 40.58, "power_watts_peak": 42.89, "energy_joules_est": 40.57, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:19:56.023852"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1087.999, "latencies_ms": [1087.999], "images_per_second": 0.919, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The man is wearing a black shirt and a blue and white patterned headband. His hair is long, dark, and appears to be curly or wavy. The background is dimly lit, suggesting an indoor setting. The man is holding a bright yellow frisbee.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.89, 42.89, 43.98, 43.98, 43.98, 43.98, 43.98, 43.51, 43.51, 43.51, 43.51], "power_watts_avg": 43.61, "power_watts_peak": 43.98, "energy_joules_est": 47.48, "sample_count": 11, "duration_seconds": 1.089}, "timestamp": "2026-01-11T13:19:57.136130"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 537.75, "latencies_ms": [537.75], "images_per_second": 1.86, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A group of people are sitting around a table, working on their laptops in a dimly lit restaurant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.51, 38.24, 38.24, 38.24, 38.24, 38.24], "power_watts_avg": 39.12, "power_watts_peak": 43.51, "energy_joules_est": 21.06, "sample_count": 6, "duration_seconds": 0.538}, "timestamp": "2026-01-11T13:19:57.746003"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1172.045, "latencies_ms": [1172.045], "images_per_second": 0.853, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "laptop: 4\nkeyboard: 2\nglass: 2\nmug: 1\nwater bottle: 1\nhat: 1\nman: 2\nwoman: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 43.35, 43.35, 53.29, 53.29, 53.29, 53.29, 42.79, 42.79, 42.79], "power_watts_avg": 46.53, "power_watts_peak": 53.29, "energy_joules_est": 54.56, "sample_count": 12, "duration_seconds": 1.173}, "timestamp": "2026-01-11T13:19:58.960716"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1058.925, "latencies_ms": [1058.925], "images_per_second": 0.944, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The foreground features the laptops and people, while the background includes other individuals and tables. The laptops are placed in the foreground, closer to the viewer, while the people are situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.79, 42.79, 40.79, 40.79, 40.79, 40.79, 40.79, 42.91, 42.91, 42.91, 42.91], "power_watts_avg": 41.93, "power_watts_peak": 42.91, "energy_joules_est": 44.42, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-11T13:20:00.074796"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 756.276, "latencies_ms": [756.276], "images_per_second": 1.322, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A group of people are gathered around a table in a dimly lit restaurant or bar, working on laptops and interacting with each other. The atmosphere appears casual and collaborative.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.91, 37.11, 37.11, 37.11, 37.11, 37.11, 42.93, 42.93], "power_watts_avg": 39.29, "power_watts_peak": 42.93, "energy_joules_est": 29.73, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:20:00.882927"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1013.488, "latencies_ms": [1013.488], "images_per_second": 0.987, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The room is dimly lit with warm lighting, creating a cozy atmosphere. The walls have a checkered pattern, adding a unique touch to the space. The laptops are open and active, suggesting active use or collaborative work.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 42.93, 51.72, 51.72, 51.72, 51.72, 51.72, 42.72, 42.72, 42.72], "power_watts_avg": 46.87, "power_watts_peak": 51.72, "energy_joules_est": 47.53, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-11T13:20:01.995347"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 674.875, "latencies_ms": [674.875], "images_per_second": 1.482, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A young girl in a pink jacket and blue jeans holds a blue umbrella, gazing at the camera with a serious expression.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.72, 42.72, 38.04, 38.04, 38.04, 38.04, 38.04], "power_watts_avg": 39.38, "power_watts_peak": 42.72, "energy_joules_est": 26.6, "sample_count": 7, "duration_seconds": 0.675}, "timestamp": "2026-01-11T13:20:02.706744"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1088.708, "latencies_ms": [1088.708], "images_per_second": 0.919, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Umbrella: 1\nGirl: 1\nJacket: 1\nScarf: 1\nJeans: 1\nGround: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.1, 43.1, 43.1, 43.1, 43.1, 49.14, 49.14, 49.14, 49.14, 49.14, 43.85], "power_watts_avg": 45.91, "power_watts_peak": 49.14, "energy_joules_est": 50.01, "sample_count": 11, "duration_seconds": 1.089}, "timestamp": "2026-01-11T13:20:03.816492"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1133.199, "latencies_ms": [1133.199], "images_per_second": 0.882, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The girl is positioned in the foreground, holding a blue umbrella that extends towards her right. The umbrella is partially obscuring the background, drawing attention to the girl. The girl is standing near a gravel surface, which suggests a somewhat distant location.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.85, 43.85, 43.85, 43.85, 44.16, 44.16, 44.16, 44.16, 44.16, 44.53, 44.53, 44.53], "power_watts_avg": 44.15, "power_watts_peak": 44.53, "energy_joules_est": 50.05, "sample_count": 12, "duration_seconds": 1.134}, "timestamp": "2026-01-11T13:20:05.024820"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 814.391, "latencies_ms": [814.391], "images_per_second": 1.228, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A young girl is standing under a blue umbrella on a gravel surface. She is wearing a pink jacket and jeans, and appears to be looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.53, 44.53, 37.04, 37.04, 37.04, 37.04, 37.04, 43.11, 43.11], "power_watts_avg": 40.05, "power_watts_peak": 44.53, "energy_joules_est": 32.62, "sample_count": 9, "duration_seconds": 0.815}, "timestamp": "2026-01-11T13:20:05.934351"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 883.625, "latencies_ms": [883.625], "images_per_second": 1.132, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The girl is wearing a bright pink jacket and a colorful scarf. The umbrella is blue and appears to be made of sturdy material. The lighting suggests an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 43.11, 47.48, 47.48, 47.48, 47.48, 47.48, 42.59], "power_watts_avg": 45.48, "power_watts_peak": 47.48, "energy_joules_est": 40.22, "sample_count": 9, "duration_seconds": 0.884}, "timestamp": "2026-01-11T13:20:06.845246"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 641.26, "latencies_ms": [641.26], "images_per_second": 1.559, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a suit stands in front of a large window in a room, operating a control panel with various screens and buttons.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 42.59, 42.59, 45.27, 45.27, 45.27], "power_watts_avg": 43.74, "power_watts_peak": 45.27, "energy_joules_est": 28.08, "sample_count": 7, "duration_seconds": 0.642}, "timestamp": "2026-01-11T13:20:07.554724"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1187.832, "latencies_ms": [1187.832], "images_per_second": 0.842, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "man: 1\ntable: 2\nkeyboard: 1\ncomputer: 1\nmonitor: 1\ncables: 2\nwindow: 1\nchair: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.27, 45.26, 45.26, 45.26, 45.26, 45.26, 42.16, 42.16, 42.16, 42.16, 42.16, 40.77], "power_watts_avg": 43.59, "power_watts_peak": 45.27, "energy_joules_est": 51.8, "sample_count": 12, "duration_seconds": 1.188}, "timestamp": "2026-01-11T13:20:08.764618"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 977.741, "latencies_ms": [977.741], "images_per_second": 1.023, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The man is standing to the left of the image, near the foreground. The computer setup is positioned in the foreground, near the man. The window is situated in the background, offering a view into the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.77, 40.77, 40.77, 40.77, 42.28, 42.28, 42.28, 42.28, 42.28, 42.21], "power_watts_avg": 41.67, "power_watts_peak": 42.28, "energy_joules_est": 40.76, "sample_count": 10, "duration_seconds": 0.978}, "timestamp": "2026-01-11T13:20:09.776706"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 843.757, "latencies_ms": [843.757], "images_per_second": 1.185, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is standing in a room with a desk, computer, and window, possibly in a training or educational setting. The window reflects another person, possibly a participant or instructor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.21, 42.21, 42.21, 42.21, 42.85, 42.85, 42.85, 42.85, 42.85], "power_watts_avg": 42.56, "power_watts_peak": 42.85, "energy_joules_est": 35.93, "sample_count": 9, "duration_seconds": 0.844}, "timestamp": "2026-01-11T13:20:10.688992"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 926.753, "latencies_ms": [926.753], "images_per_second": 1.079, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The room is lit by natural light coming through a window. The walls are white, and the overall atmosphere appears bright and airy. The materials used appear to be standard office furniture and equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 42.96, 42.96, 42.96, 42.61, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 42.79, "power_watts_peak": 42.96, "energy_joules_est": 39.68, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-11T13:20:11.698395"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 629.497, "latencies_ms": [629.497], "images_per_second": 1.589, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A group of five young men are gathered around a wooden table, enjoying a meal and engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.52, 42.52, 42.52, 42.52, 42.52, 42.19, 42.19], "power_watts_avg": 42.42, "power_watts_peak": 42.52, "energy_joules_est": 26.73, "sample_count": 7, "duration_seconds": 0.63}, "timestamp": "2026-01-11T13:20:12.407712"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1748.701, "latencies_ms": [1748.701], "images_per_second": 0.572, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "cup: 2\nsaucer: 1\nplate: 1\nbowl: 2\nsauce bottle: 1\nglass: 1\nserving spoon: 1\ntable: 1\nchopsticks: 0\nclock: 1\nwindow: 1\ncurtains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.19, 42.19, 42.19, 51.11, 51.11, 51.11, 51.11, 51.11, 42.55, 42.55, 42.55, 42.55, 42.55, 33.6, 33.6, 33.6, 33.6, 33.6], "power_watts_avg": 42.38, "power_watts_peak": 51.11, "energy_joules_est": 74.14, "sample_count": 18, "duration_seconds": 1.749}, "timestamp": "2026-01-11T13:20:14.222214"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1219.711, "latencies_ms": [1219.711], "images_per_second": 0.82, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The foreground is dominated by the table and chairs, while the background features the window and wooden elements. The table occupies the central portion of the image, drawing the viewer's eye towards the people seated around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.62, 33.62, 33.62, 33.62, 33.62, 42.52, 42.52, 42.52, 42.52, 42.52, 42.53, 42.53, 42.53], "power_watts_avg": 39.1, "power_watts_peak": 42.53, "energy_joules_est": 47.71, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:20:15.534159"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1348.717, "latencies_ms": [1348.717], "images_per_second": 0.741, "prompt_tokens": 19, "response_tokens_est": 64, "n_tiles": 1, "output_text": "A group of young men is gathered around a wooden table in a cozy room, enjoying a meal together. They are seated in a traditional Japanese setting with wooden floors, curtains, and a clock on the wall. Various dishes, cups, and cutlery are spread across the table, hinting at a shared meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 36.2, 36.2, 36.2, 36.2, 36.2, 41.28, 41.28, 41.28, 41.28, 41.28, 39.48, 39.48], "power_watts_avg": 39.39, "power_watts_peak": 42.53, "energy_joules_est": 53.14, "sample_count": 14, "duration_seconds": 1.349}, "timestamp": "2026-01-11T13:20:16.942687"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1008.998, "latencies_ms": [1008.998], "images_per_second": 0.991, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The room is lit by natural light coming through a large window with curtains. The wooden table and chairs add warmth to the setting. The men are gathered around a table, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.2, "ram_available_mb": 109446.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.48, 39.48, 39.48, 40.6, 40.6, 40.6, 40.6, 40.6, 42.23, 42.23, 42.23], "power_watts_avg": 40.74, "power_watts_peak": 42.23, "energy_joules_est": 41.13, "sample_count": 11, "duration_seconds": 1.009}, "timestamp": "2026-01-11T13:20:18.054305"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 605.769, "latencies_ms": [605.769], "images_per_second": 1.651, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A person is standing next to a red pickup truck parked on the side of a snow-covered residential street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.2, "ram_available_mb": 109446.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.2, "ram_available_mb": 109446.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.23, 36.16, 36.16, 36.16, 36.16, 36.16, 41.7], "power_watts_avg": 37.82, "power_watts_peak": 42.23, "energy_joules_est": 22.95, "sample_count": 7, "duration_seconds": 0.607}, "timestamp": "2026-01-11T13:20:18.765141"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1339.941, "latencies_ms": [1339.941], "images_per_second": 0.746, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Truck: 1\nSnowplow: 1\nPerson: 1\nHouses: 4\nTrees: 4\nStreet: 1\nSnow: 2\nFire hydrant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.2, "ram_available_mb": 109446.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.7, 41.7, 41.7, 41.7, 49.29, 49.29, 49.29, 49.29, 49.29, 41.17, 41.17, 41.17, 41.17, 41.17], "power_watts_avg": 44.22, "power_watts_peak": 49.29, "energy_joules_est": 59.27, "sample_count": 14, "duration_seconds": 1.34}, "timestamp": "2026-01-11T13:20:20.177896"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 842.574, "latencies_ms": [842.574], "images_per_second": 1.187, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The red snowplow truck is positioned in the foreground, facing the viewer. The snowy street and houses in the background extend into the distance, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [32.66, 32.66, 32.66, 32.66, 32.66, 42.45, 42.45, 42.45, 42.45], "power_watts_avg": 37.01, "power_watts_peak": 42.45, "energy_joules_est": 31.2, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:20:21.087750"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1114.65, "latencies_ms": [1114.65], "images_per_second": 0.897, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A red pickup truck with a snowplow attached is parked on a snow-covered residential street. A person in winter clothing is standing near the truck, possibly preparing to clear the snow. The scene depicts a typical winter day in a residential neighborhood.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.45, 43.48, 43.48, 43.48, 43.48, 43.48, 42.44, 42.44, 42.44, 42.44, 42.44, 43.18], "power_watts_avg": 42.93, "power_watts_peak": 43.48, "energy_joules_est": 47.87, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-11T13:20:22.300371"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 857.374, "latencies_ms": [857.374], "images_per_second": 1.166, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The red truck is covered in snow. The scene is lit by natural light, suggesting an overcast day. The snow is undisturbed on the truck and the surrounding area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.18, 43.18, 43.18, 43.18, 41.96, 41.96, 41.96, 41.96, 41.96], "power_watts_avg": 42.5, "power_watts_peak": 43.18, "energy_joules_est": 36.46, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:20:23.211451"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 651.2, "latencies_ms": [651.2], "images_per_second": 1.536, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A man is taking a selfie in a luxurious bathroom with a large mirror, marble countertop, and two sinks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.02, 42.02, 42.02, 42.02, 42.02, 43.8, 43.8], "power_watts_avg": 42.53, "power_watts_peak": 43.8, "energy_joules_est": 27.72, "sample_count": 7, "duration_seconds": 0.652}, "timestamp": "2026-01-11T13:20:23.922759"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1638.996, "latencies_ms": [1638.996], "images_per_second": 0.61, "prompt_tokens": 21, "response_tokens_est": 52, "n_tiles": 1, "output_text": "Bathroom: 4\nDouble vanity: 2\nSink: 2\nMirror: 2\nTowels: 2\nBathtub: 1\nFloor: 2\nWalls: 2\nLighting: 2\nTelevision: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.8, 43.8, 43.8, 52.12, 52.12, 52.12, 52.12, 52.12, 43.53, 43.53, 43.53, 43.53, 43.53, 34.87, 34.87, 34.87, 34.87], "power_watts_avg": 44.07, "power_watts_peak": 52.12, "energy_joules_est": 72.25, "sample_count": 17, "duration_seconds": 1.64}, "timestamp": "2026-01-11T13:20:25.640873"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1103.18, "latencies_ms": [1103.18], "images_per_second": 0.906, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The large mirror spans the width of the bathroom, reflecting the sink and surrounding space. The sink is located in the foreground, while the mirror is positioned in the background. The bathroom is spacious and clean, with a tiled floor and marble countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.87, 31.78, 31.78, 31.78, 31.78, 31.78, 43.33, 43.33, 43.33, 43.33, 43.33], "power_watts_avg": 37.31, "power_watts_peak": 43.33, "energy_joules_est": 41.18, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-11T13:20:26.754050"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1260.111, "latencies_ms": [1260.111], "images_per_second": 0.794, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The scene depicts a luxurious bathroom with a double vanity, marble countertop, and large mirror reflecting the room's interior. The bathroom is well-lit with recessed lighting and wall sconces, creating a warm and inviting atmosphere. A television is mounted on the wall above the vanity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.6, 44.6, 44.6, 44.6, 44.54, 44.54, 44.54, 44.54, 44.54, 44.76, 44.76, 44.76, 44.76], "power_watts_avg": 44.63, "power_watts_peak": 44.76, "energy_joules_est": 56.26, "sample_count": 13, "duration_seconds": 1.261}, "timestamp": "2026-01-11T13:20:28.065302"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1184.944, "latencies_ms": [1184.944], "images_per_second": 0.844, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The bathroom features a dark green marble countertop and beige walls with gold accents. The lighting is warm and inviting, creating a relaxing atmosphere. The marble countertop is complemented by gold fixtures and accents, enhancing the overall luxurious feel of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.76, 35.18, 35.18, 35.18, 35.18, 35.18, 44.05, 44.05, 44.05, 44.05, 44.05, 43.16], "power_watts_avg": 40.34, "power_watts_peak": 44.76, "energy_joules_est": 47.83, "sample_count": 12, "duration_seconds": 1.186}, "timestamp": "2026-01-11T13:20:29.277214"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 569.106, "latencies_ms": [569.106], "images_per_second": 1.757, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "Two men are loading luggage into a white car in a busy airport parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [43.16, 43.16, 43.16, 43.16, 43.07, 43.07], "power_watts_avg": 43.13, "power_watts_peak": 43.16, "energy_joules_est": 24.57, "sample_count": 6, "duration_seconds": 0.57}, "timestamp": "2026-01-11T13:20:29.886885"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1081.767, "latencies_ms": [1081.767], "images_per_second": 0.924, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "car: 2\nluggage: 4\nsuitcase: 2\ntrolley: 1\nperson: 2\nwindow: 1\nsign: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.07, 43.07, 43.07, 53.01, 53.01, 53.01, 53.01, 53.01, 42.96, 42.96, 42.96], "power_watts_avg": 47.56, "power_watts_peak": 53.01, "energy_joules_est": 51.47, "sample_count": 11, "duration_seconds": 1.082}, "timestamp": "2026-01-11T13:20:30.997595"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 797.357, "latencies_ms": [797.357], "images_per_second": 1.254, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The luggage cart is positioned to the left of the main objects in the image. The car is parked in the background, slightly further away than the luggage cart.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 39.65, 39.65, 39.65, 39.65, 39.65, 43.57], "power_watts_avg": 40.96, "power_watts_peak": 43.57, "energy_joules_est": 32.68, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:20:31.806493"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 776.238, "latencies_ms": [776.238], "images_per_second": 1.288, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Two men are loading luggage into a white car in a parking garage. A luggage cart is also present, ready to assist with the process.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.57, 43.57, 43.57, 43.57, 48.37, 48.37, 48.37, 48.37], "power_watts_avg": 45.97, "power_watts_peak": 48.37, "energy_joules_est": 35.7, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:20:32.614693"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 905.373, "latencies_ms": [905.373], "images_per_second": 1.105, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The car is white, and the lighting is bright, illuminating the scene. The luggage is various colors, including black and brown. The overall atmosphere appears to be clean and well-organized.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.37, 42.95, 42.95, 42.95, 42.95, 42.95, 42.92, 42.92, 42.92, 42.92], "power_watts_avg": 43.48, "power_watts_peak": 48.37, "energy_joules_est": 39.37, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-11T13:20:33.624475"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 987.368, "latencies_ms": [987.368], "images_per_second": 1.013, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The plate contains a grilled chicken sandwich with sesame seed buns, accompanied by golden brown french fries, two small bowls of ketchup, and a side of lettuce and tomato.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 38.0}, "power_stats": {"power_watts_samples": [42.92, 41.03, 41.03, 41.03, 41.03, 41.03, 41.46, 41.46, 41.46, 41.46], "power_watts_avg": 41.39, "power_watts_peak": 42.92, "energy_joules_est": 40.89, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-11T13:20:34.638231"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1192.113, "latencies_ms": [1192.113], "images_per_second": 0.839, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "bun: 2\nfries: 4\nchicken: 2\nketchup: 1\nlettuce: 1\ntomato: 1\nmayonnaise: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.46, 43.16, 43.16, 43.16, 43.16, 43.16, 43.08, 43.08, 43.08, 43.08, 43.08, 43.52], "power_watts_avg": 43.01, "power_watts_peak": 43.52, "energy_joules_est": 51.29, "sample_count": 12, "duration_seconds": 1.192}, "timestamp": "2026-01-11T13:20:35.848125"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1019.687, "latencies_ms": [1019.687], "images_per_second": 0.981, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The sandwich is in the foreground, while the fries and sauce are in the background. The plate is situated on a surface, providing a neutral backdrop for the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 43.52, 43.52, 43.06, 43.06, 43.06, 43.06, 43.06, 42.98, 42.98], "power_watts_avg": 43.22, "power_watts_peak": 43.52, "energy_joules_est": 44.08, "sample_count": 11, "duration_seconds": 1.02}, "timestamp": "2026-01-11T13:20:36.959240"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1191.112, "latencies_ms": [1191.112], "images_per_second": 0.84, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a casual dining setting with a plate containing a grilled chicken sandwich, french fries, and two small bowls of condiments. The sandwich is served on a white plate, accompanied by a knife. The overall setting suggests a relaxed and informal dining environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.98, 42.98, 40.12, 40.12, 40.12, 40.12, 40.12, 42.01, 42.01, 42.01, 42.01, 42.01], "power_watts_avg": 41.38, "power_watts_peak": 42.98, "energy_joules_est": 49.31, "sample_count": 12, "duration_seconds": 1.191}, "timestamp": "2026-01-11T13:20:38.171660"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1144.155, "latencies_ms": [1144.155], "images_per_second": 0.874, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The plate features a mix of golden-brown fries, vibrant red ketchup, and fresh green lettuce. The lighting is bright, enhancing the colors and textures of the food. The plate appears to be made of ceramic or porcelain, suitable for outdoor dining.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.55, 35.55, 35.55, 35.55, 35.55, 43.23, 43.23, 43.23, 43.23, 43.23, 43.46, 43.46], "power_watts_avg": 40.07, "power_watts_peak": 43.46, "energy_joules_est": 45.86, "sample_count": 12, "duration_seconds": 1.145}, "timestamp": "2026-01-11T13:20:39.384138"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 663.703, "latencies_ms": [663.703], "images_per_second": 1.507, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The room features a bed with a mosquito net, wooden furniture, and natural light streaming in through large windows.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 43.46, 42.46, 42.46, 42.46, 42.46], "power_watts_avg": 42.89, "power_watts_peak": 43.46, "energy_joules_est": 28.48, "sample_count": 7, "duration_seconds": 0.664}, "timestamp": "2026-01-11T13:20:40.094920"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1184.52, "latencies_ms": [1184.52], "images_per_second": 0.844, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "bed: 2\ncurtains: 3\nnightstands: 2\ncandle: 1\ntable: 1\nchair: 1\nwindow: 3\nwall: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.46, 43.99, 43.99, 43.99, 43.99, 43.99, 42.57, 42.57, 42.57, 42.57, 42.57, 42.19], "power_watts_avg": 43.12, "power_watts_peak": 43.99, "energy_joules_est": 51.09, "sample_count": 12, "duration_seconds": 1.185}, "timestamp": "2026-01-11T13:20:41.305534"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1071.669, "latencies_ms": [1071.669], "images_per_second": 0.933, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned between the viewer and the window. The window and curtains are located in the background, extending from left to right. The bed is situated between the viewer and the window, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [42.19, 42.19, 42.19, 42.19, 42.88, 42.88, 42.88, 42.88, 42.88, 42.77, 42.77], "power_watts_avg": 42.61, "power_watts_peak": 42.88, "energy_joules_est": 45.69, "sample_count": 11, "duration_seconds": 1.072}, "timestamp": "2026-01-11T13:20:42.420496"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.045, "latencies_ms": [1052.045], "images_per_second": 0.951, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a serene and cozy bedroom with a thatched roof, bathed in natural light. The room features a bed with a mosquito net, a small table with a lit candle, and several framed pictures on the walls.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13059.7, "ram_available_mb": 109446.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 42.79, 42.79, 42.79, 42.79, 42.79, 42.71, 42.71, 42.71], "power_watts_avg": 42.76, "power_watts_peak": 42.79, "energy_joules_est": 45.01, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:20:43.531661"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1099.032, "latencies_ms": [1099.032], "images_per_second": 0.91, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The room features a warm, inviting ambiance with warm yellow walls and a thatched roof. The lighting is soft and warm, creating a cozy atmosphere. The bed is covered in a green mosquito net, adding a unique touch to the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 30.0}, "power_stats": {"power_watts_samples": [42.71, 42.71, 38.54, 38.54, 38.54, 38.54, 38.54, 42.59, 42.59, 42.59, 42.59], "power_watts_avg": 40.77, "power_watts_peak": 42.71, "energy_joules_est": 44.83, "sample_count": 11, "duration_seconds": 1.1}, "timestamp": "2026-01-11T13:20:44.644873"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 588.147, "latencies_ms": [588.147], "images_per_second": 1.7, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A tabby cat with striking blue eyes is standing on the hood of a sleek black car in a garage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.59, 38.18, 38.18, 38.18, 38.18, 38.18], "power_watts_avg": 38.91, "power_watts_peak": 42.59, "energy_joules_est": 22.9, "sample_count": 6, "duration_seconds": 0.588}, "timestamp": "2026-01-11T13:20:45.254893"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1135.45, "latencies_ms": [1135.45], "images_per_second": 0.881, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "lamp: 2\nbox: 2\ncar: 1\ncat: 1\nbicycle: 1\nglove: 1\nshoe: 1\ntoolbox: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.11, 37.11, 37.11, 37.11, 41.95, 41.95, 41.95, 41.95, 41.95, 37.48, 37.48, 37.48], "power_watts_avg": 39.22, "power_watts_peak": 41.95, "energy_joules_est": 44.54, "sample_count": 12, "duration_seconds": 1.136}, "timestamp": "2026-01-11T13:20:46.466023"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 626.903, "latencies_ms": [626.903], "images_per_second": 1.595, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The black car is positioned in the foreground, slightly to the right of the cat. The garage is situated in the background, extending from left to right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [37.48, 37.48, 36.54, 36.54, 36.54, 36.54, 36.54], "power_watts_avg": 36.81, "power_watts_peak": 37.48, "energy_joules_est": 23.11, "sample_count": 7, "duration_seconds": 0.628}, "timestamp": "2026-01-11T13:20:47.176692"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 704.846, "latencies_ms": [704.846], "images_per_second": 1.419, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A tabby cat is standing on the hood of a black car in a garage. The garage contains various items like tools, boxes, and bicycles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.42, 35.42, 35.42, 35.42, 35.42, 36.51, 36.51, 36.51], "power_watts_avg": 35.83, "power_watts_peak": 36.51, "energy_joules_est": 25.27, "sample_count": 8, "duration_seconds": 0.705}, "timestamp": "2026-01-11T13:20:47.987178"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 560.574, "latencies_ms": [560.574], "images_per_second": 1.784, "prompt_tokens": 18, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The car is black. The lighting is dim. The materials appear to be metal and plastic. The weather is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.51, 36.51, 40.18, 40.18, 40.18, 40.18], "power_watts_avg": 38.95, "power_watts_peak": 40.18, "energy_joules_est": 21.86, "sample_count": 6, "duration_seconds": 0.561}, "timestamp": "2026-01-11T13:20:48.594214"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 795.864, "latencies_ms": [795.864], "images_per_second": 1.256, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The dish features a meat patty topped with gravy, onions, tomatoes, and herbs, served on a bun and accompanied by a knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [40.18, 37.34, 37.34, 37.34, 37.34, 37.34, 43.73, 43.73], "power_watts_avg": 39.29, "power_watts_peak": 43.73, "energy_joules_est": 31.29, "sample_count": 8, "duration_seconds": 0.796}, "timestamp": "2026-01-11T13:20:49.407351"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1489.378, "latencies_ms": [1489.378], "images_per_second": 0.671, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "bun: 1\ntomato: 1\nsauce: 1\nonions: 1\ngrilled tomato: 1\nmeat: 1\nbacon: 1\nbiscuit: 1\nknife: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.73, 54.45, 54.45, 54.45, 54.45, 54.45, 44.22, 44.22, 44.22, 44.22, 44.22, 34.29, 34.29], "power_watts_avg": 46.21, "power_watts_peak": 54.45, "energy_joules_est": 68.84, "sample_count": 15, "duration_seconds": 1.49}, "timestamp": "2026-01-11T13:20:50.923236"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1249.179, "latencies_ms": [1249.179], "images_per_second": 0.801, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main object, consisting of a meat patty topped with gravy, onions, and tomatoes, is positioned in the foreground of the image. The meat patty is situated on a plate that occupies the central portion of the foreground. The background features another plate of food and a partially visible beverage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.29, 34.29, 34.29, 44.14, 44.14, 44.14, 44.14, 44.14, 44.45, 44.45, 44.45, 44.45, 44.45], "power_watts_avg": 41.98, "power_watts_peak": 44.45, "energy_joules_est": 52.47, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-11T13:20:52.236885"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1115.182, "latencies_ms": [1115.182], "images_per_second": 0.897, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is set outdoors on a metal table, showcasing a plate with a hearty-looking dish topped with gravy, onions, and herbs. A knife rests on the plate, suggesting the dish is ready to be served or eaten.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [33.27, 33.27, 33.27, 33.27, 33.27, 42.72, 42.72, 42.72, 42.72, 42.72, 43.02, 43.02], "power_watts_avg": 38.83, "power_watts_peak": 43.02, "energy_joules_est": 43.32, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-11T13:20:53.449409"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1183.46, "latencies_ms": [1183.46], "images_per_second": 0.845, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The dish features a rich brown gravy drizzled over it, which adds a vibrant color. The plate is white, providing a clean backdrop for the colorful food. The lighting is soft and warm, enhancing the visual appeal of the dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 41.29, 41.29, 41.29, 41.29, 41.29, 43.03, 43.03, 43.03, 43.03], "power_watts_avg": 42.3, "power_watts_peak": 43.03, "energy_joules_est": 50.09, "sample_count": 12, "duration_seconds": 1.184}, "timestamp": "2026-01-11T13:20:54.662379"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 655.726, "latencies_ms": [655.726], "images_per_second": 1.525, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three men are gathered in a cozy living room, playing a video game together while enjoying snacks and drinks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.33, 35.33, 35.33, 35.33, 35.33, 42.58, 42.58], "power_watts_avg": 37.4, "power_watts_peak": 42.58, "energy_joules_est": 24.54, "sample_count": 7, "duration_seconds": 0.656}, "timestamp": "2026-01-11T13:20:55.372371"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1599.647, "latencies_ms": [1599.647], "images_per_second": 0.625, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "laptop: 1\ncans: 2\nbottles: 2\ncork: 1\ncan opener: 1\ntable: 1\nred couch: 1\npillow: 1\nwindow blinds: 2\nfloor lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.58, 42.58, 42.58, 52.29, 52.29, 52.29, 52.29, 52.29, 41.95, 41.95, 41.95, 41.95, 41.95, 32.78, 32.78, 32.78], "power_watts_avg": 43.58, "power_watts_peak": 52.29, "energy_joules_est": 69.74, "sample_count": 16, "duration_seconds": 1.6}, "timestamp": "2026-01-11T13:20:56.985936"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 885.922, "latencies_ms": [885.922], "images_per_second": 1.129, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a couch on the left and a red couch on the right. The foreground is dominated by the red couch, while the background features a window and a lamp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.78, 32.78, 40.53, 40.53, 40.53, 40.53, 40.53, 43.28, 43.28], "power_watts_avg": 39.42, "power_watts_peak": 43.28, "energy_joules_est": 34.95, "sample_count": 9, "duration_seconds": 0.887}, "timestamp": "2026-01-11T13:20:57.895008"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1464.885, "latencies_ms": [1464.885], "images_per_second": 0.683, "prompt_tokens": 19, "response_tokens_est": 67, "n_tiles": 1, "output_text": "Three young men are gathered in a cozy living room, playing a video game on a Nintendo Wii console. They are surrounded by various items, including a laptop, a red couch, a coffee table with drinks and snacks, and a window with blinds. The scene suggests a casual, relaxed atmosphere where friends are enjoying leisure time together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 43.28, 45.64, 45.64, 45.64, 45.64, 45.64, 42.76, 42.76, 42.76, 42.76, 42.76, 33.18, 33.18], "power_watts_avg": 42.55, "power_watts_peak": 45.64, "energy_joules_est": 62.35, "sample_count": 15, "duration_seconds": 1.465}, "timestamp": "2026-01-11T13:20:59.409251"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1152.103, "latencies_ms": [1152.103], "images_per_second": 0.868, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The room is lit by warm yellow lighting, creating a cozy atmosphere. The walls are painted a light beige color, and the furniture includes a red couch, a beige sofa, and a red coffee table. The scene suggests a casual gathering or social event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.18, 33.18, 33.18, 42.45, 42.45, 42.45, 42.45, 42.45, 42.46, 42.46, 42.46, 42.46], "power_watts_avg": 40.14, "power_watts_peak": 42.46, "energy_joules_est": 46.25, "sample_count": 12, "duration_seconds": 1.152}, "timestamp": "2026-01-11T13:21:00.621647"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 681.785, "latencies_ms": [681.785], "images_per_second": 1.467, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A baseball catcher crouches behind home plate, preparing to catch a pitch during a game.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [42.46, 33.18, 33.18, 33.18, 33.18, 33.18, 41.78], "power_watts_avg": 35.74, "power_watts_peak": 42.46, "energy_joules_est": 24.38, "sample_count": 7, "duration_seconds": 0.682}, "timestamp": "2026-01-11T13:21:01.331307"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1261.343, "latencies_ms": [1261.343], "images_per_second": 0.793, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "catcher: 1\nglove: 1\nhelmet: 1\npants: 1\nshin guards: 1\nbaseball glove: 1\nbaseball field: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [41.78, 41.78, 41.78, 41.78, 52.16, 52.16, 52.16, 52.16, 52.16, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 46.03, "power_watts_peak": 52.16, "energy_joules_est": 58.08, "sample_count": 13, "duration_seconds": 1.262}, "timestamp": "2026-01-11T13:21:02.642422"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 989.098, "latencies_ms": [989.098], "images_per_second": 1.011, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The catcher is positioned in the foreground, crouched down on the baseball field. The pitcher is further in the background, near the outfield wall. The field extends into the distance, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.61, 32.26, 32.26, 32.26, 32.26, 32.26, 42.19, 42.19, 42.19, 42.19], "power_watts_avg": 37.27, "power_watts_peak": 42.61, "energy_joules_est": 36.89, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:21:03.651084"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 972.3, "latencies_ms": [972.3], "images_per_second": 1.028, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A baseball catcher is crouched behind home plate, preparing to catch a ball during a game. The field is well-maintained, and the overall atmosphere suggests a professional or competitive setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.8, "ram_available_mb": 109446.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.19, 42.79, 42.79, 42.79, 42.79, 42.79, 43.07, 43.07, 43.07, 43.07], "power_watts_avg": 42.84, "power_watts_peak": 43.07, "energy_joules_est": 41.68, "sample_count": 10, "duration_seconds": 0.973}, "timestamp": "2026-01-11T13:21:04.662094"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 720.235, "latencies_ms": [720.235], "images_per_second": 1.388, "prompt_tokens": 18, "response_tokens_est": 23, "n_tiles": 1, "output_text": "The catcher is wearing a white uniform with black accents. The field is well-lit, suggesting sunny weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.03, 43.03, 43.03, 43.03, 43.03, 42.16, 42.16, 42.16], "power_watts_avg": 42.71, "power_watts_peak": 43.03, "energy_joules_est": 30.78, "sample_count": 8, "duration_seconds": 0.721}, "timestamp": "2026-01-11T13:21:05.470381"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 709.299, "latencies_ms": [709.299], "images_per_second": 1.41, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The bathroom features a white bathtub, a toilet, a sink with a wooden cabinet, and a shower curtain, all set against pink and light blue walls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [42.16, 42.16, 45.27, 45.27, 45.27, 45.27, 45.27, 36.08], "power_watts_avg": 43.34, "power_watts_peak": 45.27, "energy_joules_est": 30.77, "sample_count": 8, "duration_seconds": 0.71}, "timestamp": "2026-01-11T13:21:06.279533"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1665.736, "latencies_ms": [1665.736], "images_per_second": 0.6, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "Bathtub: 1\nToilet: 1\nShower curtain: 1\nBathtub surround: 1\nWindow: 1\nVanity: 1\nSink: 1\nCabinet: 1\nFloor: 1\nWalls: 2\nDoor: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.08, 36.08, 36.08, 36.08, 36.11, 36.11, 36.11, 36.11, 36.11, 36.18, 36.18, 36.18, 36.18, 36.18, 33.27, 33.27, 33.27], "power_watts_avg": 35.62, "power_watts_peak": 36.18, "energy_joules_est": 59.35, "sample_count": 17, "duration_seconds": 1.666}, "timestamp": "2026-01-11T13:21:07.992009"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 710.076, "latencies_ms": [710.076], "images_per_second": 1.408, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The toilet is positioned near the foreground, slightly to the right of the bathtub. The bathtub is situated in the background, partially obscured by the shower curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.27, 33.27, 36.87, 36.87, 36.87, 36.87, 36.87, 36.85], "power_watts_avg": 35.97, "power_watts_peak": 36.87, "energy_joules_est": 25.55, "sample_count": 8, "duration_seconds": 0.71}, "timestamp": "2026-01-11T13:21:08.799778"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 724.85, "latencies_ms": [724.85], "images_per_second": 1.38, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bathroom features a pink and white color scheme, with a white bathtub, toilet, and sink. A green bathmat is placed on the floor, and a window provides natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.85, 36.85, 36.85, 36.85, 36.26, 36.26, 36.26, 36.26], "power_watts_avg": 36.55, "power_watts_peak": 36.85, "energy_joules_est": 26.52, "sample_count": 8, "duration_seconds": 0.725}, "timestamp": "2026-01-11T13:21:09.609180"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1115.737, "latencies_ms": [1115.737], "images_per_second": 0.896, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The bathroom features a pink and white color scheme. The lighting appears to be natural or soft, contributing to a calm atmosphere. The materials include tiled walls, wood cabinets, and a white bathtub and toilet. The weather is sunny, enhancing the brightness and cleanliness of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.26, 36.7, 36.7, 36.7, 36.7, 36.7, 36.73, 36.73, 36.73, 36.73, 36.73, 37.11], "power_watts_avg": 36.71, "power_watts_peak": 37.11, "energy_joules_est": 40.97, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-11T13:21:10.820492"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 795.06, "latencies_ms": [795.06], "images_per_second": 1.258, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A bed with a yellow and white plaid comforter is situated next to a window with sheer white curtains, allowing soft natural light into the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.11, 37.11, 37.11, 37.11, 41.74, 41.74, 41.74, 41.74], "power_watts_avg": 39.43, "power_watts_peak": 41.74, "energy_joules_est": 31.37, "sample_count": 8, "duration_seconds": 0.796}, "timestamp": "2026-01-11T13:21:11.632325"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1163.922, "latencies_ms": [1163.922], "images_per_second": 0.859, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bed: 2\ncurtains: 2\nwindow: 1\nnightstand: 1\nlamp: 1\nheadboard: 1\nplaid bedspread: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.74, 41.73, 41.73, 41.73, 41.73, 41.73, 43.22, 43.22, 43.22, 43.22, 43.22, 43.5], "power_watts_avg": 42.5, "power_watts_peak": 43.5, "energy_joules_est": 49.5, "sample_count": 12, "duration_seconds": 1.165}, "timestamp": "2026-01-11T13:21:12.845235"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 731.711, "latencies_ms": [731.711], "images_per_second": 1.367, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned slightly to the right of the image. The window is situated in the background, extending from left to right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 43.5, 43.5, 42.62, 42.62, 42.62, 42.62], "power_watts_avg": 43.06, "power_watts_peak": 43.5, "energy_joules_est": 31.53, "sample_count": 8, "duration_seconds": 0.732}, "timestamp": "2026-01-11T13:21:13.654948"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 878.991, "latencies_ms": [878.991], "images_per_second": 1.138, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene depicts a dimly lit bedroom with a plaid-covered bed, a window with sheer curtains, and a small nightstand with a lamp. The room appears cozy and inviting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.62, 41.36, 41.36, 41.36, 41.36, 41.36, 42.25, 42.25, 42.25], "power_watts_avg": 41.8, "power_watts_peak": 42.62, "energy_joules_est": 36.75, "sample_count": 9, "duration_seconds": 0.879}, "timestamp": "2026-01-11T13:21:14.564561"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 896.616, "latencies_ms": [896.616], "images_per_second": 1.115, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The bed has a plaid comforter in shades of yellow and white. The walls are a muted yellow or tan color. The lighting in the room is dim, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [42.25, 47.19, 47.19, 47.19, 47.19, 47.19, 43.1, 43.1, 43.1], "power_watts_avg": 45.28, "power_watts_peak": 47.19, "energy_joules_est": 40.61, "sample_count": 9, "duration_seconds": 0.897}, "timestamp": "2026-01-11T13:21:15.473408"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 671.213, "latencies_ms": [671.213], "images_per_second": 1.49, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A young woman in a black dress is helping a young man put on a boutonniere on his lapel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.1, 43.1, 48.84, 48.84, 48.84, 48.84, 48.84], "power_watts_avg": 47.2, "power_watts_peak": 48.84, "energy_joules_est": 31.71, "sample_count": 7, "duration_seconds": 0.672}, "timestamp": "2026-01-11T13:21:16.183423"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1082.91, "latencies_ms": [1082.91], "images_per_second": 0.923, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "man: 1\nwoman: 2\nflower: 1\ntie: 1\ndress: 1\nnecklace: 1\nbelt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 44.06, 44.06, 44.06, 46.95, 46.95, 46.95, 46.95, 46.95, 44.25], "power_watts_avg": 45.39, "power_watts_peak": 46.95, "energy_joules_est": 49.18, "sample_count": 11, "duration_seconds": 1.083}, "timestamp": "2026-01-11T13:21:17.293984"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 775.284, "latencies_ms": [775.284], "images_per_second": 1.29, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The man is positioned to the left of the woman, who is positioned to the right. The woman is standing closer to the man than the man is standing to the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [44.25, 44.25, 44.25, 44.25, 44.12, 44.12, 44.12, 44.12], "power_watts_avg": 44.19, "power_watts_peak": 44.25, "energy_joules_est": 34.28, "sample_count": 8, "duration_seconds": 0.776}, "timestamp": "2026-01-11T13:21:18.103147"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.442, "latencies_ms": [1116.442], "images_per_second": 0.896, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young man and woman are dressed in formal attire, likely attending a prom or wedding. The woman is helping the man with his boutonniere. The setting appears to be indoors, possibly in a hallway or reception area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.12, 45.6, 45.6, 45.6, 45.6, 45.6, 44.06, 44.06, 44.06, 44.06, 44.06, 43.61], "power_watts_avg": 44.67, "power_watts_peak": 45.6, "energy_joules_est": 49.89, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-11T13:21:19.313197"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1040.566, "latencies_ms": [1040.566], "images_per_second": 0.961, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The man is wearing a black suit with a gold tie. The woman is wearing a black dress with a sparkly or sequined bodice. The lighting is soft and warm, enhancing the colors and details of the attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [43.61, 43.61, 43.61, 43.61, 42.65, 42.65, 42.65, 42.65, 42.65, 42.92, 42.92], "power_watts_avg": 43.05, "power_watts_peak": 43.61, "energy_joules_est": 44.8, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-11T13:21:20.423419"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 741.939, "latencies_ms": [741.939], "images_per_second": 1.348, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A stop sign is mounted on a metal post behind a chain-link fence, with trash and debris scattered around the base.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.92, 42.92, 42.92, 41.77, 41.77, 41.77, 41.77, 41.77], "power_watts_avg": 42.2, "power_watts_peak": 42.92, "energy_joules_est": 31.34, "sample_count": 8, "duration_seconds": 0.743}, "timestamp": "2026-01-11T13:21:21.236020"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1140.759, "latencies_ms": [1140.759], "images_per_second": 0.877, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "stop sign: 1\nchain link fence: 1\npalm trees: 4\ngrass: 2\ntrash: 2\nbuilding: 1\nshrubs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.11, 42.11, 42.11, 42.11, 42.11, 42.73, 42.73, 42.73, 42.73, 42.73, 42.39, 42.39], "power_watts_avg": 42.42, "power_watts_peak": 42.73, "energy_joules_est": 48.41, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-11T13:21:22.445598"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1138.066, "latencies_ms": [1138.066], "images_per_second": 0.879, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The stop sign is positioned in the foreground, slightly to the right of the chain-link fence. The background features palm trees and a building, indicating a tropical or suburban setting. The stop sign is situated between the fence and the palm trees, implying a relatively close proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.39, 42.39, 42.39, 41.77, 41.77, 41.77, 41.77, 41.77, 42.69, 42.69, 42.69, 42.69], "power_watts_avg": 42.23, "power_watts_peak": 42.69, "energy_joules_est": 48.08, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-11T13:21:23.657707"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1104.706, "latencies_ms": [1104.706], "images_per_second": 0.905, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a stop sign situated behind a chain-link fence in a grassy area with palm trees in the background. The fence appears somewhat overgrown with weeds and debris, suggesting the location might be a park or a recreational area.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.69, 32.76, 32.76, 32.76, 32.76, 32.76, 42.26, 42.26, 42.26, 42.26, 42.88], "power_watts_avg": 38.04, "power_watts_peak": 42.88, "energy_joules_est": 42.04, "sample_count": 11, "duration_seconds": 1.105}, "timestamp": "2026-01-11T13:21:24.767471"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 916.752, "latencies_ms": [916.752], "images_per_second": 1.091, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The stop sign is red and white. The scene is lit by sunlight, giving a bright and sunny appearance. The stop sign is positioned in a grassy area with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 42.88, 42.88, 43.09, 43.09, 43.09, 43.09, 43.09, 43.31], "power_watts_avg": 43.03, "power_watts_peak": 43.31, "energy_joules_est": 39.47, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-11T13:21:25.776316"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 599.0, "latencies_ms": [599.0], "images_per_second": 1.669, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A man is riding a motorcycle past two parked bicycles, one yellow and one black, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.31, 43.31, 43.31, 43.31, 35.5, 35.5], "power_watts_avg": 40.71, "power_watts_peak": 43.31, "energy_joules_est": 24.41, "sample_count": 6, "duration_seconds": 0.6}, "timestamp": "2026-01-11T13:21:26.384804"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1255.959, "latencies_ms": [1255.959], "images_per_second": 0.796, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bike: 2\nmotorcycle: 1\nbicycle: 2\nbag: 1\ntowel: 1\nperson: 1\nshorts: 1\nsocks: 1\nshoe: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.5, 35.5, 35.5, 40.42, 40.42, 40.42, 40.42, 40.42, 38.06, 38.06, 38.06, 38.06, 38.06], "power_watts_avg": 38.38, "power_watts_peak": 40.42, "energy_joules_est": 48.24, "sample_count": 13, "duration_seconds": 1.257}, "timestamp": "2026-01-11T13:21:27.695483"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 743.283, "latencies_ms": [743.283], "images_per_second": 1.345, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned relatively close to the viewer, with the motorcycle in the foreground and the bicycles further in the background. The motorcycle is closest to the viewer, while the bicycles are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.17, 33.17, 33.17, 33.17, 33.17, 37.43, 37.43, 37.43], "power_watts_avg": 34.77, "power_watts_peak": 37.43, "energy_joules_est": 25.85, "sample_count": 8, "duration_seconds": 0.744}, "timestamp": "2026-01-11T13:21:28.503904"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 853.832, "latencies_ms": [853.832], "images_per_second": 1.171, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Two bicycles, one yellow and one black, are parked on a paved path near a fence and trees. A person on a motorcycle is passing by, and another person is standing nearby, observing the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [37.43, 37.43, 41.49, 41.49, 41.49, 41.49, 41.49, 37.16, 37.16], "power_watts_avg": 39.63, "power_watts_peak": 41.49, "energy_joules_est": 33.87, "sample_count": 9, "duration_seconds": 0.855}, "timestamp": "2026-01-11T13:21:29.413509"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 552.338, "latencies_ms": [552.338], "images_per_second": 1.81, "prompt_tokens": 18, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The yellow bicycle is partially obscured by the motorcycle. The motorcycle has a bright headlight. The scene appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [37.16, 37.16, 37.16, 37.27, 37.27, 37.27], "power_watts_avg": 37.22, "power_watts_peak": 37.27, "energy_joules_est": 20.57, "sample_count": 6, "duration_seconds": 0.553}, "timestamp": "2026-01-11T13:21:30.020742"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 612.906, "latencies_ms": [612.906], "images_per_second": 1.632, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "Two pedestrians are standing on the sidewalk near a street corner, waiting to cross the road.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.27, 37.27, 42.92, 42.92, 42.92, 42.92, 42.92], "power_watts_avg": 41.31, "power_watts_peak": 42.92, "energy_joules_est": 25.33, "sample_count": 7, "duration_seconds": 0.613}, "timestamp": "2026-01-11T13:21:30.731150"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1372.138, "latencies_ms": [1372.138], "images_per_second": 0.729, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Sign: 2\nTraffic light: 2\nStreet light: 2\nCar: 1\nBicycle: 1\nPerson: 1\nTrash can: 1\nCrosswalk: 2\nBuilding: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 42.46, 42.46, 42.46, 46.67, 46.67, 46.67, 46.67, 46.67, 42.31, 42.31, 42.31, 42.31], "power_watts_avg": 43.92, "power_watts_peak": 46.67, "energy_joules_est": 60.27, "sample_count": 14, "duration_seconds": 1.372}, "timestamp": "2026-01-11T13:21:32.143187"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1030.845, "latencies_ms": [1030.845], "images_per_second": 0.97, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The foreground features a brick sidewalk and a black trash can. The background includes a street with cars, traffic lights, and buildings. The central focus is the street corner where two men are standing near a signpost.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.31, 32.47, 32.47, 32.47, 32.47, 32.47, 42.95, 42.95, 42.95, 42.95, 42.95], "power_watts_avg": 38.13, "power_watts_peak": 42.95, "energy_joules_est": 39.31, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-11T13:21:33.254655"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1174.005, "latencies_ms": [1174.005], "images_per_second": 0.852, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene depicts a busy city intersection with pedestrians, vehicles, and street signs. A man is standing near a signpost, while another person walks nearby. The setting includes buildings, traffic lights, and streetlights, typical of an urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 43.34, 43.34, 43.34, 42.16, 42.16, 42.16, 42.16, 42.16, 42.24, 42.24], "power_watts_avg": 42.67, "power_watts_peak": 43.34, "energy_joules_est": 50.1, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-11T13:21:34.466847"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1101.667, "latencies_ms": [1101.667], "images_per_second": 0.908, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is lit by streetlights, giving it a slightly dim atmosphere. The buildings in the background are primarily brick and concrete, contributing to the urban feel. The street is paved with brick and asphalt, typical of city streets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [42.24, 42.24, 41.6, 41.6, 41.6, 41.6, 41.6, 43.04, 43.04, 43.04, 43.04], "power_watts_avg": 42.24, "power_watts_peak": 43.04, "energy_joules_est": 46.55, "sample_count": 11, "duration_seconds": 1.102}, "timestamp": "2026-01-11T13:21:35.578978"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 658.478, "latencies_ms": [658.478], "images_per_second": 1.519, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two bronze statues of women sit on a stone bench, facing each other and appearing to converse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.04, 37.16, 37.16, 37.16, 37.16, 37.16, 42.15], "power_watts_avg": 38.72, "power_watts_peak": 43.04, "energy_joules_est": 25.52, "sample_count": 7, "duration_seconds": 0.659}, "timestamp": "2026-01-11T13:21:36.291079"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1227.351, "latencies_ms": [1227.351], "images_per_second": 0.815, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Bench: 2\nStatue: 2\nBag: 1\nHandbag: 1\nWoman: 2\nMan: 1\nPerson: 2\nBricks: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [42.15, 42.15, 42.15, 42.15, 49.26, 49.26, 49.26, 49.26, 49.26, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 45.08, "power_watts_peak": 49.26, "energy_joules_est": 55.34, "sample_count": 13, "duration_seconds": 1.228}, "timestamp": "2026-01-11T13:21:37.603384"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 948.387, "latencies_ms": [948.387], "images_per_second": 1.054, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The statue is positioned in the foreground, slightly to the left of the viewer. The background features people standing and walking, further away from the statue. The statue is situated on a bench, placed near the sidewalk.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 37.0}, "power_stats": {"power_watts_samples": [42.77, 33.65, 33.65, 33.65, 33.65, 33.65, 42.02, 42.02, 42.02, 42.02], "power_watts_avg": 37.91, "power_watts_peak": 42.77, "energy_joules_est": 35.97, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-11T13:21:38.615744"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1034.977, "latencies_ms": [1034.977], "images_per_second": 0.966, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a public outdoor space with a bronze statue of two women sitting on a bench, seemingly engaged in conversation. The setting appears to be a sidewalk or pedestrian area, with people casually walking by and passing by the statue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.02, 42.65, 42.65, 42.65, 42.65, 42.65, 42.4, 42.4, 42.4, 42.4, 42.4], "power_watts_avg": 42.48, "power_watts_peak": 42.65, "energy_joules_est": 43.99, "sample_count": 11, "duration_seconds": 1.036}, "timestamp": "2026-01-11T13:21:39.726996"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1012.529, "latencies_ms": [1012.529], "images_per_second": 0.988, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The statue is bronze and appears weathered, suggesting it is made of metal. The lighting in the image creates a dramatic contrast, highlighting the statue's details and casting shadows on the ground. The setting appears to be outdoors on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13061.6, "ram_available_mb": 109444.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.3, 43.3, 43.3, 43.3, 43.3, 42.3, 42.3, 42.3, 42.3, 42.3, 42.63], "power_watts_avg": 42.78, "power_watts_peak": 43.3, "energy_joules_est": 43.35, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:21:40.837701"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 591.213, "latencies_ms": [591.213], "images_per_second": 1.691, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A tall pole displays multiple directional signs in German, guiding travelers to various destinations.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 13061.6, "ram_available_mb": 109444.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.63, 42.63, 42.63, 42.63, 41.96, 41.96], "power_watts_avg": 42.41, "power_watts_peak": 42.63, "energy_joules_est": 25.09, "sample_count": 6, "duration_seconds": 0.592}, "timestamp": "2026-01-11T13:21:41.447871"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1160.108, "latencies_ms": [1160.108], "images_per_second": 0.862, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Sign: 4\nAirplane: 1\nHighway: 1\nTruck: 1\nParking sign: 1\nNo parking sign: 1\nTrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [41.96, 41.96, 41.96, 51.3, 51.3, 51.3, 51.3, 51.3, 43.35, 43.35, 43.35, 43.35], "power_watts_avg": 46.31, "power_watts_peak": 51.3, "energy_joules_est": 53.74, "sample_count": 12, "duration_seconds": 1.16}, "timestamp": "2026-01-11T13:21:42.660163"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 645.177, "latencies_ms": [645.177], "images_per_second": 1.55, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The signs are positioned in the foreground, slightly to the right of the image. The background consists of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.35, 33.02, 33.02, 33.02, 33.02, 33.02, 42.66], "power_watts_avg": 35.87, "power_watts_peak": 43.35, "energy_joules_est": 23.16, "sample_count": 7, "duration_seconds": 0.645}, "timestamp": "2026-01-11T13:21:43.369808"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1224.61, "latencies_ms": [1224.61], "images_per_second": 0.817, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a street sign post with multiple directional signs in German, guiding travelers to various locations such as an airport, bus stop, and parking area. The signs are mounted on a brown pole amidst trees, indicating a public or semi-public space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.66, 42.66, 42.66, 52.78, 52.78, 52.78, 52.78, 52.78, 42.16, 42.16, 42.16, 42.16, 42.16], "power_watts_avg": 46.36, "power_watts_peak": 52.78, "energy_joules_est": 56.79, "sample_count": 13, "duration_seconds": 1.225}, "timestamp": "2026-01-11T13:21:44.680823"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 776.977, "latencies_ms": [776.977], "images_per_second": 1.287, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The signs are brightly colored with contrasting blue and green backgrounds. The lighting appears to be overcast, giving a slightly muted appearance to the signs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [31.87, 31.87, 31.87, 31.87, 31.87, 41.79, 41.79, 41.79], "power_watts_avg": 35.59, "power_watts_peak": 41.79, "energy_joules_est": 27.66, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:21:45.490165"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 865.368, "latencies_ms": [865.368], "images_per_second": 1.156, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Two women, one in a red shirt and the other in a blue shirt, are standing next to a large black suitcase at a train station, smiling and posing for the camera.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [41.79, 41.79, 49.59, 49.59, 49.59, 49.59, 49.59, 42.77, 42.77], "power_watts_avg": 46.34, "power_watts_peak": 49.59, "energy_joules_est": 40.13, "sample_count": 9, "duration_seconds": 0.866}, "timestamp": "2026-01-11T13:21:46.400212"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1112.39, "latencies_ms": [1112.39], "images_per_second": 0.899, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "suitcase: 1\nbackpack: 2\nhandbag: 2\nwatch: 1\njeans: 1\nshirt: 2\nsmile: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 45.23, 45.23, 45.23, 45.23, 45.23, 42.6, 42.6, 42.6, 42.6], "power_watts_avg": 43.74, "power_watts_peak": 45.23, "energy_joules_est": 48.67, "sample_count": 12, "duration_seconds": 1.113}, "timestamp": "2026-01-11T13:21:47.612705"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 913.686, "latencies_ms": [913.686], "images_per_second": 1.094, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The two women are standing close together in the foreground of the image, positioned near a black suitcase and a train platform. The train is further in the background, suggesting they are at a train station.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 35.0}, "power_stats": {"power_watts_samples": [42.6, 33.12, 33.12, 33.12, 33.12, 33.12, 41.93, 41.93, 41.93, 41.93], "power_watts_avg": 37.59, "power_watts_peak": 42.6, "energy_joules_est": 34.36, "sample_count": 10, "duration_seconds": 0.914}, "timestamp": "2026-01-11T13:21:48.623687"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 876.213, "latencies_ms": [876.213], "images_per_second": 1.141, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Two women are standing at a train station, preparing for a journey. They are both smiling and posing for a photo, with one woman holding a suitcase and the other a handbag.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 47.0}, "power_stats": {"power_watts_samples": [41.93, 41.46, 41.46, 41.46, 41.46, 41.46, 41.69, 41.69, 41.69], "power_watts_avg": 41.59, "power_watts_peak": 41.93, "energy_joules_est": 36.46, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-11T13:21:49.536385"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1067.729, "latencies_ms": [1067.729], "images_per_second": 0.937, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The women are wearing bright colors. The lighting in the image is bright, likely from overhead fluorescent lights. The suitcase they are standing next to appears to be made of a sturdy material like canvas or hard-shell.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [41.69, 41.69, 48.51, 48.51, 48.51, 48.51, 48.51, 42.38, 42.38, 42.38, 42.38], "power_watts_avg": 45.04, "power_watts_peak": 48.51, "energy_joules_est": 48.1, "sample_count": 11, "duration_seconds": 1.068}, "timestamp": "2026-01-11T13:21:50.648826"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 655.173, "latencies_ms": [655.173], "images_per_second": 1.526, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Three zebras stand in a row, facing the camera, with a backdrop of purple flowers and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.38, 37.39, 37.39, 37.39, 37.39, 37.39, 42.98], "power_watts_avg": 38.9, "power_watts_peak": 42.98, "energy_joules_est": 25.52, "sample_count": 7, "duration_seconds": 0.656}, "timestamp": "2026-01-11T13:21:51.360270"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1046.335, "latencies_ms": [1046.335], "images_per_second": 0.956, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "zebra: 3\ntree: 2\nflowers: 2\nground: 2\ndirt: 1\nbranches: 2\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [42.98, 42.98, 42.98, 42.98, 53.48, 53.48, 53.48, 53.48, 53.48, 42.88, 42.88], "power_watts_avg": 47.73, "power_watts_peak": 53.48, "energy_joules_est": 49.97, "sample_count": 11, "duration_seconds": 1.047}, "timestamp": "2026-01-11T13:21:52.471216"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 857.223, "latencies_ms": [857.223], "images_per_second": 1.167, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The zebras are positioned in the foreground, with the purple flowers in the background. The zebras are relatively close to the viewer, while the flowers are further away, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 41.07, 41.07, 41.07, 41.07, 41.07, 42.55, 42.55], "power_watts_avg": 41.8, "power_watts_peak": 42.88, "energy_joules_est": 35.85, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:21:53.380917"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 806.273, "latencies_ms": [806.273], "images_per_second": 1.24, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Three zebras stand in a natural setting with trees and purple flowers in the background. The zebras appear to be in a zoo or wildlife park environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.55, 42.55, 42.55, 44.29, 44.29, 44.29, 44.29, 44.29, 42.55], "power_watts_avg": 43.52, "power_watts_peak": 44.29, "energy_joules_est": 35.11, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-11T13:21:54.291723"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 976.774, "latencies_ms": [976.774], "images_per_second": 1.024, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The zebras have black and white stripes. The lighting is bright, likely from sunlight, creating a clear contrast against the ground and vegetation. The zebras appear to be standing on a dirt path or road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [42.55, 42.55, 42.55, 42.55, 41.56, 41.56, 41.56, 41.56, 41.56, 41.61], "power_watts_avg": 41.96, "power_watts_peak": 42.55, "energy_joules_est": 41.01, "sample_count": 10, "duration_seconds": 0.977}, "timestamp": "2026-01-11T13:21:55.300465"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 640.258, "latencies_ms": [640.258], "images_per_second": 1.562, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A black tripod with a camera mounted on it is set up in a room with a table, chair, and vending machine in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [41.61, 41.61, 41.61, 41.61, 36.65, 36.65, 36.65], "power_watts_avg": 39.48, "power_watts_peak": 41.61, "energy_joules_est": 25.31, "sample_count": 7, "duration_seconds": 0.641}, "timestamp": "2026-01-11T13:21:56.009527"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1174.99, "latencies_ms": [1174.99], "images_per_second": 0.851, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "camera: 1\nlaptop: 1\ntripod: 1\nchair: 1\nvending machine: 1\ntable: 1\ncontainers: 2\nfloor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.65, 36.65, 40.6, 40.6, 40.6, 40.6, 40.6, 37.16, 37.16, 37.16, 37.16, 37.16], "power_watts_avg": 38.51, "power_watts_peak": 40.6, "energy_joules_est": 45.27, "sample_count": 12, "duration_seconds": 1.176}, "timestamp": "2026-01-11T13:21:57.220751"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 626.938, "latencies_ms": [626.938], "images_per_second": 1.595, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The camera is positioned in the foreground, slightly to the right of the laptop. The vending machine is in the background, slightly to the left of the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.21, 33.21, 33.21, 33.21, 33.21, 37.33, 37.33], "power_watts_avg": 34.39, "power_watts_peak": 37.33, "energy_joules_est": 21.58, "sample_count": 7, "duration_seconds": 0.627}, "timestamp": "2026-01-11T13:21:57.930077"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 926.93, "latencies_ms": [926.93], "images_per_second": 1.079, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a workspace with a camera mounted on a tripod, positioned near a laptop and a chair. The background includes a vending machine, suggesting an indoor setting possibly in a public or commercial space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.33, 37.33, 37.33, 40.9, 40.9, 40.9, 40.9, 40.9, 36.52, 36.52], "power_watts_avg": 38.95, "power_watts_peak": 40.9, "energy_joules_est": 36.13, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-11T13:21:58.943298"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1034.505, "latencies_ms": [1034.505], "images_per_second": 0.967, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The camera is black and has a green light. The lighting appears to be artificial, possibly from spotlights. The camera is mounted on a tripod, suggesting it is set up for photography or videography. The setting appears to be indoors, possibly a storage or event area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.52, 36.52, 36.52, 36.48, 36.48, 36.48, 36.48, 36.48, 36.76, 36.76, 36.76], "power_watts_avg": 36.57, "power_watts_peak": 36.76, "energy_joules_est": 37.84, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-11T13:22:00.053624"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 608.022, "latencies_ms": [608.022], "images_per_second": 1.645, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A white sheep stands among piles of freshly sheared wool in a fenced area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.76, 36.76, 36.52, 36.52, 36.52, 36.52, 36.52], "power_watts_avg": 36.59, "power_watts_peak": 36.76, "energy_joules_est": 22.27, "sample_count": 7, "duration_seconds": 0.609}, "timestamp": "2026-01-11T13:22:00.762763"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1302.438, "latencies_ms": [1302.438], "images_per_second": 0.768, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Sheep: 2\nFelt: 2\nWool: 2\nFence: 1\nGround: 1\nBall: 1\nSheep's wool: 2\nSheep's body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.55, 41.55, 41.55, 41.55, 41.55, 48.15, 48.15, 48.15, 48.15, 48.15, 42.19, 42.19, 42.19], "power_watts_avg": 44.23, "power_watts_peak": 48.15, "energy_joules_est": 57.62, "sample_count": 13, "duration_seconds": 1.303}, "timestamp": "2026-01-11T13:22:02.072215"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 828.891, "latencies_ms": [828.891], "images_per_second": 1.206, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, partially obscured by the pile of wool. The pile of wool is situated in the background, extending beyond the immediate foreground of the sheep.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.19, 37.38, 37.38, 37.38, 37.38, 37.38, 43.93, 43.93, 43.93], "power_watts_avg": 40.1, "power_watts_peak": 43.93, "energy_joules_est": 33.25, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:22:02.979821"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 988.287, "latencies_ms": [988.287], "images_per_second": 1.012, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A white sheep is standing behind a pile of freshly sheared wool in a fenced enclosure. The wool is piled up around its legs and body, indicating a recent shearing process.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.93, 43.93, 47.9, 47.9, 47.9, 47.9, 47.9, 42.15, 42.15, 42.15], "power_watts_avg": 45.38, "power_watts_peak": 47.9, "energy_joules_est": 44.86, "sample_count": 10, "duration_seconds": 0.989}, "timestamp": "2026-01-11T13:22:03.992442"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 735.96, "latencies_ms": [735.96], "images_per_second": 1.359, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The sheep is primarily white with patches of gray wool. The lighting appears to be natural, possibly outdoors, and the scene suggests a cold environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.15, 42.15, 42.76, 42.76, 42.76, 42.76, 42.76, 43.32], "power_watts_avg": 42.68, "power_watts_peak": 43.32, "energy_joules_est": 31.43, "sample_count": 8, "duration_seconds": 0.737}, "timestamp": "2026-01-11T13:22:04.802561"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 722.245, "latencies_ms": [722.245], "images_per_second": 1.385, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two female tennis players are engaged in a match on a blue court, with one player preparing to hit the ball and the other positioned near the net.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.32, 43.32, 43.32, 43.32, 45.41, 45.41, 45.41, 45.41], "power_watts_avg": 44.37, "power_watts_peak": 45.41, "energy_joules_est": 32.07, "sample_count": 8, "duration_seconds": 0.723}, "timestamp": "2026-01-11T13:22:05.614100"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1250.133, "latencies_ms": [1250.133], "images_per_second": 0.8, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "net: 1\nball: 1\nracket: 1\ncourt: 2\nplayers: 2\nspectators: 2\nscoreboard: 2\nadvertising boards: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.41, 42.23, 42.23, 42.23, 42.23, 42.23, 41.91, 41.91, 41.91, 41.91, 41.91, 43.26, 43.26], "power_watts_avg": 42.51, "power_watts_peak": 45.41, "energy_joules_est": 53.17, "sample_count": 13, "duration_seconds": 1.251}, "timestamp": "2026-01-11T13:22:06.927411"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 967.503, "latencies_ms": [967.503], "images_per_second": 1.034, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The foreground features a tennis court with a net, players, and spectators. The background includes spectators seated in bleachers and additional advertising boards. The players are positioned on the court, engaging in the match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.26, 43.26, 43.26, 42.78, 42.78, 42.78, 42.78, 42.78, 42.77, 42.77], "power_watts_avg": 42.92, "power_watts_peak": 43.26, "energy_joules_est": 41.54, "sample_count": 10, "duration_seconds": 0.968}, "timestamp": "2026-01-11T13:22:07.938892"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 921.851, "latencies_ms": [921.851], "images_per_second": 1.085, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A tennis match is taking place on a blue court, with players in red and pink outfits competing against each other. The audience is seated in stadium seating, watching the match unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.2, "ram_available_mb": 109446.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 43.55, 43.55, 43.55, 43.55, 43.55, 43.36, 43.36], "power_watts_avg": 43.27, "power_watts_peak": 43.55, "energy_joules_est": 39.92, "sample_count": 10, "duration_seconds": 0.922}, "timestamp": "2026-01-11T13:22:08.951136"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 731.92, "latencies_ms": [731.92], "images_per_second": 1.366, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The tennis court is predominantly blue. The lighting appears to be bright and evenly distributed, enhancing the visibility of both players and spectators.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.2, "ram_available_mb": 109446.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.36, 43.36, 43.36, 41.22, 41.22, 41.22, 41.22, 41.22], "power_watts_avg": 42.02, "power_watts_peak": 43.36, "energy_joules_est": 30.76, "sample_count": 8, "duration_seconds": 0.732}, "timestamp": "2026-01-11T13:22:09.761376"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 627.747, "latencies_ms": [627.747], "images_per_second": 1.593, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A man dressed in black is walking through a modern airport terminal, pulling a suitcase behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.15, 42.15, 42.15, 42.15, 42.15, 44.16, 44.16], "power_watts_avg": 42.73, "power_watts_peak": 44.16, "energy_joules_est": 26.84, "sample_count": 7, "duration_seconds": 0.628}, "timestamp": "2026-01-11T13:22:10.472902"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1006.219, "latencies_ms": [1006.219], "images_per_second": 0.994, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "person: 1\nsuitcase: 1\nscreen: 1\nstairs: 2\npillars: 2\nfloor: 6\nsigns: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.16, 44.16, 49.62, 49.62, 49.62, 49.62, 49.62, 42.51, 42.51, 42.51], "power_watts_avg": 46.39, "power_watts_peak": 49.62, "energy_joules_est": 46.69, "sample_count": 10, "duration_seconds": 1.006}, "timestamp": "2026-01-11T13:22:11.485511"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1109.995, "latencies_ms": [1109.995], "images_per_second": 0.901, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is walking through the airport terminal, moving from left to right. The foreground is dominated by the airport terminal entrance and the man. The background features escalators, stairs, and signage, indicating the airport's layout and accessibility.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 44.12, 44.12, 44.12, 44.12, 44.12, 43.84, 43.84, 43.84, 43.84, 43.84], "power_watts_avg": 43.74, "power_watts_peak": 44.12, "energy_joules_est": 48.57, "sample_count": 12, "duration_seconds": 1.111}, "timestamp": "2026-01-11T13:22:12.698185"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 871.635, "latencies_ms": [871.635], "images_per_second": 1.147, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man in dark clothing is walking through a modern airport terminal, pulling a rolling suitcase behind him. Large pillars and escalators are visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.38, 35.38, 35.38, 35.38, 35.38, 41.55, 41.55, 41.55, 41.55], "power_watts_avg": 38.12, "power_watts_peak": 41.55, "energy_joules_est": 33.25, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-11T13:22:13.608935"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1152.908, "latencies_ms": [1152.908], "images_per_second": 0.867, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The airport terminal features a predominantly gray color scheme, with blue and white directional signs. The lighting is bright, likely from overhead fluorescent fixtures, creating a well-lit environment. The materials appear to be modern glass and metal, contributing to the sleek and contemporary aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.55, 43.68, 43.68, 43.68, 43.68, 43.68, 42.92, 42.92, 42.92, 42.92, 42.92, 42.77], "power_watts_avg": 43.11, "power_watts_peak": 43.68, "energy_joules_est": 49.72, "sample_count": 12, "duration_seconds": 1.153}, "timestamp": "2026-01-11T13:22:14.823111"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 771.671, "latencies_ms": [771.671], "images_per_second": 1.296, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "An elderly woman is seated at a table with two pizzas, glasses of beverages, and utensils, enjoying a meal in a cozy setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 42.77, 42.28, 42.28, 42.28, 42.28], "power_watts_avg": 42.52, "power_watts_peak": 42.77, "energy_joules_est": 32.84, "sample_count": 8, "duration_seconds": 0.772}, "timestamp": "2026-01-11T13:22:15.636342"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1183.639, "latencies_ms": [1183.639], "images_per_second": 0.845, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "pizza: 2\nglass: 2\nchicken: 0\nfork: 1\nknife: 1\ntablecloth: 1\nchair: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.28, 41.95, 41.95, 41.95, 41.95, 41.95, 43.16, 43.16, 43.16, 43.16, 43.16, 43.75], "power_watts_avg": 42.63, "power_watts_peak": 43.75, "energy_joules_est": 50.48, "sample_count": 12, "duration_seconds": 1.184}, "timestamp": "2026-01-11T13:22:16.850637"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 848.444, "latencies_ms": [848.444], "images_per_second": 1.179, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the pizza boxes and glasses placed nearby. The woman in the background is situated further back, suggesting the setting is relatively open and spacious.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.75, 43.75, 43.75, 43.75, 43.27, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 43.48, "power_watts_peak": 43.75, "energy_joules_est": 36.9, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:22:17.760277"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1084.084, "latencies_ms": [1084.084], "images_per_second": 0.922, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a casual dining setting with two pizzas on white boxes placed on a table, accompanied by glasses, cutlery, and a vase of flowers. An elderly woman is seated in the background, seemingly enjoying the meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 43.28, 43.28, 43.28, 42.64, 42.64, 42.64, 42.64, 42.64, 42.6], "power_watts_avg": 42.93, "power_watts_peak": 43.28, "energy_joules_est": 46.56, "sample_count": 11, "duration_seconds": 1.085}, "timestamp": "2026-01-11T13:22:18.873540"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 928.587, "latencies_ms": [928.587], "images_per_second": 1.077, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The pizza boxes are white with red lettering. The table setting includes red wine glasses, cutlery, and plates. The lighting is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 42.6, 43.31, 43.31, 43.31, 43.31, 43.31, 43.36, 43.36], "power_watts_avg": 43.11, "power_watts_peak": 43.36, "energy_joules_est": 40.05, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-11T13:22:19.886569"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 998.118, "latencies_ms": [998.118], "images_per_second": 1.002, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A youth baseball game is in progress, with a batter in a white shirt and gray pants preparing to swing at a pitch, while a catcher in a red shirt and gray pants crouches behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.36, 43.36, 43.36, 42.26, 42.26, 42.26, 42.26, 42.26, 41.93, 41.93], "power_watts_avg": 42.52, "power_watts_peak": 43.36, "energy_joules_est": 42.47, "sample_count": 10, "duration_seconds": 0.999}, "timestamp": "2026-01-11T13:22:20.899704"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1517.919, "latencies_ms": [1517.919], "images_per_second": 0.659, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball helmet: 1\nbaseball: 1\nbaseball field: 1\nbaseball diamond: 1\nbaseball player: 2\nspectators: 4\ntree: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.93, 41.93, 41.93, 43.17, 43.17, 43.17, 43.17, 43.17, 43.33, 43.33, 43.33, 43.33, 43.33, 33.53, 33.53, 33.53], "power_watts_avg": 41.18, "power_watts_peak": 43.33, "energy_joules_est": 62.53, "sample_count": 16, "duration_seconds": 1.518}, "timestamp": "2026-01-11T13:22:22.516260"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 761.346, "latencies_ms": [761.346], "images_per_second": 1.313, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the catcher, who is positioned behind him. The spectators are situated in the background, watching the game unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.53, 33.53, 39.56, 39.56, 39.56, 39.56, 39.56, 42.11], "power_watts_avg": 38.37, "power_watts_peak": 42.11, "energy_joules_est": 29.23, "sample_count": 8, "duration_seconds": 0.762}, "timestamp": "2026-01-11T13:22:23.325165"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1100.482, "latencies_ms": [1100.482], "images_per_second": 0.909, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A youth baseball game is taking place in a park. A young batter is preparing to swing, while a catcher crouches behind home plate, ready to catch the ball. Spectators are watching the game from the sidelines.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.11, 42.11, 42.11, 42.11, 46.36, 46.36, 46.36, 46.36, 46.36, 42.83, 42.83], "power_watts_avg": 44.17, "power_watts_peak": 46.36, "energy_joules_est": 48.63, "sample_count": 11, "duration_seconds": 1.101}, "timestamp": "2026-01-11T13:22:24.437581"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1221.381, "latencies_ms": [1221.381], "images_per_second": 0.819, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene is bathed in bright sunlight, creating a vibrant atmosphere. The green grass and trees provide a natural backdrop, while the dirt field and metal fence suggest an outdoor setting. The lighting is likely natural sunlight, enhancing the overall ambiance of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [42.83, 42.83, 42.83, 43.37, 43.37, 43.37, 43.37, 43.37, 43.13, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 43.15, "power_watts_peak": 43.37, "energy_joules_est": 52.72, "sample_count": 13, "duration_seconds": 1.222}, "timestamp": "2026-01-11T13:22:25.752829"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 746.512, "latencies_ms": [746.512], "images_per_second": 1.34, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A black telephone with a banana attached to its handset is placed on a white desk, accompanied by a stapler and a piece of paper with handwritten text.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [32.99, 32.99, 32.99, 32.99, 32.99, 41.4, 41.4, 41.4], "power_watts_avg": 36.15, "power_watts_peak": 41.4, "energy_joules_est": 27.0, "sample_count": 8, "duration_seconds": 0.747}, "timestamp": "2026-01-11T13:22:26.563149"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1105.886, "latencies_ms": [1105.886], "images_per_second": 0.904, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "phone: 8\nbanana: 1\nstaple: 1\nprinter: 1\nnotepad: 1\ntable: 1\ncord: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [41.4, 41.4, 46.29, 46.29, 46.29, 46.29, 46.29, 42.65, 42.65, 42.65, 42.65], "power_watts_avg": 44.08, "power_watts_peak": 46.29, "energy_joules_est": 48.76, "sample_count": 11, "duration_seconds": 1.106}, "timestamp": "2026-01-11T13:22:27.675573"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 682.524, "latencies_ms": [682.524], "images_per_second": 1.465, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The banana is positioned in the foreground, close to the phone. The phone is situated in the background, slightly further away than the banana.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [39.23, 39.23, 39.23, 39.23, 39.23, 43.54, 43.54], "power_watts_avg": 40.47, "power_watts_peak": 43.54, "energy_joules_est": 27.64, "sample_count": 7, "duration_seconds": 0.683}, "timestamp": "2026-01-11T13:22:28.385637"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 908.092, "latencies_ms": [908.092], "images_per_second": 1.101, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a desk with a black telephone with a banana attached to its handset. A stapler is visible in the background, and a piece of paper with handwritten notes is on the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 53.44, 53.44, 53.44, 53.44, 53.44, 42.77, 42.77], "power_watts_avg": 48.34, "power_watts_peak": 53.44, "energy_joules_est": 43.9, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:22:29.397061"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 960.913, "latencies_ms": [960.913], "images_per_second": 1.041, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The phone is black and has a yellow banana attached to its handset. The phone appears to be made of plastic and has a digital display. The desk is white and appears to be clean and organized.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 41.23, 41.23, 41.23, 41.23, 41.23, 41.12, 41.12], "power_watts_avg": 41.67, "power_watts_peak": 42.77, "energy_joules_est": 40.06, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-11T13:22:30.410158"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 554.114, "latencies_ms": [554.114], "images_per_second": 1.805, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A large crowd of people is gathered in a public area, engaged in various activities and conversations.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [41.12, 41.12, 41.12, 42.6, 42.6, 42.6], "power_watts_avg": 41.86, "power_watts_peak": 42.6, "energy_joules_est": 23.23, "sample_count": 6, "duration_seconds": 0.555}, "timestamp": "2026-01-11T13:22:31.021263"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1453.546, "latencies_ms": [1453.546], "images_per_second": 0.688, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Teddy bear: 1\nBag: 1\nHandbag: 1\nGlasses: 1\nShirt: 2\nScarf: 2\nBackpack: 1\nJacket: 2\nSweater: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 49.2, 49.2, 49.2, 49.2, 49.2, 42.88, 42.88, 42.88, 42.88, 42.88, 36.95, 36.95, 36.95], "power_watts_avg": 43.76, "power_watts_peak": 49.2, "energy_joules_est": 63.63, "sample_count": 15, "duration_seconds": 1.454}, "timestamp": "2026-01-11T13:22:32.537384"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1027.899, "latencies_ms": [1027.899], "images_per_second": 0.973, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The teddy bear is positioned near the center of the image, slightly to the right of the center. The crowd surrounds the bear, with people standing close together on both sides and slightly further back, creating a sense of depth and proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [36.95, 36.95, 39.51, 39.51, 39.51, 39.51, 39.51, 42.44, 42.44, 42.44, 42.44], "power_watts_avg": 40.11, "power_watts_peak": 42.44, "energy_joules_est": 41.24, "sample_count": 11, "duration_seconds": 1.028}, "timestamp": "2026-01-11T13:22:33.648694"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1027.197, "latencies_ms": [1027.197], "images_per_second": 0.974, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts a crowded public space, possibly a busy street or plaza, with many people standing and interacting. A large teddy bear is visible among the crowd, adding a playful element to the atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.44, 36.79, 36.79, 36.79, 36.79, 36.79, 41.95, 41.95, 41.95, 41.95, 41.95], "power_watts_avg": 39.65, "power_watts_peak": 42.44, "energy_joules_est": 40.74, "sample_count": 11, "duration_seconds": 1.028}, "timestamp": "2026-01-11T13:22:34.761398"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1176.653, "latencies_ms": [1176.653], "images_per_second": 0.85, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The crowd is densely packed, showcasing a variety of colors, including red, green, and white. The lighting appears to be natural daylight, creating a bright and lively atmosphere. The materials appear to be casual clothing and bags, typical of a public setting. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 42.97, 42.97, 42.97, 42.06, 42.06, 42.06, 42.06, 42.06, 42.13, 42.13], "power_watts_avg": 42.45, "power_watts_peak": 42.97, "energy_joules_est": 49.96, "sample_count": 12, "duration_seconds": 1.177}, "timestamp": "2026-01-11T13:22:35.970536"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 565.217, "latencies_ms": [565.217], "images_per_second": 1.769, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man tenderly pets a brown horse's nose while holding a toddler on his hip.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.13, 42.13, 42.13, 42.32, 42.32, 42.32], "power_watts_avg": 42.22, "power_watts_peak": 42.32, "energy_joules_est": 23.91, "sample_count": 6, "duration_seconds": 0.566}, "timestamp": "2026-01-11T13:22:36.582323"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1324.476, "latencies_ms": [1324.476], "images_per_second": 0.755, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "horse: 1\nman: 2\nchild: 1\nred shirt: 1\njeans: 1\nstone building: 1\nporch: 1\nroof: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13060.4, "ram_available_mb": 109445.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.32, 46.61, 46.61, 46.61, 46.61, 46.61, 43.85, 43.85, 43.85, 43.85, 43.85, 39.4, 39.4, 39.4], "power_watts_avg": 43.77, "power_watts_peak": 46.61, "energy_joules_est": 58.0, "sample_count": 14, "duration_seconds": 1.325}, "timestamp": "2026-01-11T13:22:37.997076"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 906.828, "latencies_ms": [906.828], "images_per_second": 1.103, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The horse is positioned to the left of the man and baby, creating a spatial relationship that suggests proximity. The man and baby are standing close to the horse, implying a close interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.6, "ram_available_mb": 109445.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.4, 39.4, 39.47, 39.47, 39.47, 39.47, 39.47, 41.65, 41.65, 41.65], "power_watts_avg": 40.11, "power_watts_peak": 41.65, "energy_joules_est": 36.39, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-11T13:22:39.007894"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 808.531, "latencies_ms": [808.531], "images_per_second": 1.237, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A man is holding a toddler while petting a brown horse. The setting appears to be a stable or farm, with a wooden porch and stone walls visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.65, 41.65, 41.52, 41.52, 41.52, 41.52, 41.52, 41.31, 41.31], "power_watts_avg": 41.5, "power_watts_peak": 41.65, "energy_joules_est": 33.58, "sample_count": 9, "duration_seconds": 0.809}, "timestamp": "2026-01-11T13:22:39.918074"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 627.182, "latencies_ms": [627.182], "images_per_second": 1.594, "prompt_tokens": 18, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The horse is brown. The man is wearing a red shirt. The setting appears to be sunny and outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.31, 41.31, 41.31, 44.45, 44.45, 44.45, 44.45], "power_watts_avg": 43.11, "power_watts_peak": 44.45, "energy_joules_est": 27.06, "sample_count": 7, "duration_seconds": 0.628}, "timestamp": "2026-01-11T13:22:40.628081"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 580.328, "latencies_ms": [580.328], "images_per_second": 1.723, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A ripe banana with a small cup of peanut butter sits on a simple white plate with a brown rim, set against a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 31.0}, "power_stats": {"power_watts_samples": [44.45, 42.24, 42.24, 42.24, 42.24, 42.24], "power_watts_avg": 42.61, "power_watts_peak": 44.45, "energy_joules_est": 24.75, "sample_count": 6, "duration_seconds": 0.581}, "timestamp": "2026-01-11T13:22:41.239425"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 610.895, "latencies_ms": [610.895], "images_per_second": 1.637, "prompt_tokens": 21, "response_tokens_est": 18, "n_tiles": 1, "output_text": "banana: 1\npeanut butter: 1\nplate: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.81, 36.81, 36.81, 36.81, 36.81, 41.18, 41.18], "power_watts_avg": 38.06, "power_watts_peak": 41.18, "energy_joules_est": 23.27, "sample_count": 7, "duration_seconds": 0.611}, "timestamp": "2026-01-11T13:22:41.950551"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 758.027, "latencies_ms": [758.027], "images_per_second": 1.319, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The banana is positioned towards the left side of the plate, partially covering the peanut butter. The plate is situated on a table, creating a simple setting for the snack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.18, 41.18, 41.18, 40.35, 40.35, 40.35, 40.35, 40.35], "power_watts_avg": 40.66, "power_watts_peak": 41.18, "energy_joules_est": 30.83, "sample_count": 8, "duration_seconds": 0.758}, "timestamp": "2026-01-11T13:22:42.760327"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 676.231, "latencies_ms": [676.231], "images_per_second": 1.479, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A ripe banana rests on a small plate, accompanied by a dollop of peanut butter. The plate is placed on a wooden table, creating a simple, casual setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.66, 35.66, 35.66, 35.66, 35.66, 37.18, 37.18], "power_watts_avg": 36.09, "power_watts_peak": 37.18, "energy_joules_est": 24.44, "sample_count": 7, "duration_seconds": 0.677}, "timestamp": "2026-01-11T13:22:43.468885"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 890.466, "latencies_ms": [890.466], "images_per_second": 1.123, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The banana is white and appears ripe. The peanut butter is light brown and has a smooth, glossy texture. The plate is off-white with a thin orange-brown rim. The table appears to be wooden.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.18, 37.18, 37.18, 41.56, 41.56, 41.56, 41.56, 41.56, 37.66], "power_watts_avg": 39.67, "power_watts_peak": 41.56, "energy_joules_est": 35.33, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:22:44.377703"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 516.781, "latencies_ms": [516.781], "images_per_second": 1.935, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "A man in green and blue is repairing a motorcycle wheel on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [37.66, 37.66, 37.66, 43.41, 43.41, 43.41], "power_watts_avg": 40.54, "power_watts_peak": 43.41, "energy_joules_est": 20.96, "sample_count": 6, "duration_seconds": 0.517}, "timestamp": "2026-01-11T13:22:44.986923"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1273.868, "latencies_ms": [1273.868], "images_per_second": 0.785, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Motorcycle: 2\nBike wheel: 1\nMan: 1\nGlasses: 1\nFloor: 1\nBicycle: 1\nPole: 1\nShoe: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.41, 43.41, 50.25, 50.25, 50.25, 50.25, 50.25, 42.16, 42.16, 42.16, 42.16, 42.16, 35.28], "power_watts_avg": 44.93, "power_watts_peak": 50.25, "energy_joules_est": 57.25, "sample_count": 13, "duration_seconds": 1.274}, "timestamp": "2026-01-11T13:22:46.297740"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 841.528, "latencies_ms": [841.528], "images_per_second": 1.188, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The motorcycle is positioned to the left of the man, who is crouched down working on the wheel. The background includes other motorcycles and bicycles, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.28, 35.28, 35.28, 35.28, 43.26, 43.26, 43.26, 43.26, 43.26], "power_watts_avg": 39.71, "power_watts_peak": 43.26, "energy_joules_est": 33.43, "sample_count": 9, "duration_seconds": 0.842}, "timestamp": "2026-01-11T13:22:47.207078"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 693.787, "latencies_ms": [693.787], "images_per_second": 1.441, "prompt_tokens": 19, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A man is repairing a motorcycle wheel, possibly on a city street. Other motorcycles and bicycles are visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 42.67, 42.67, 42.67, 42.67], "power_watts_avg": 42.67, "power_watts_peak": 42.67, "energy_joules_est": 29.63, "sample_count": 7, "duration_seconds": 0.694}, "timestamp": "2026-01-11T13:22:47.915051"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 779.766, "latencies_ms": [779.766], "images_per_second": 1.282, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The motorcycle is primarily blue and silver. The lighting appears to be natural daylight. The motorcycle appears to be made of metal and plastic. The weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 53.3, 53.3, 53.3, 53.3, 53.3], "power_watts_avg": 49.32, "power_watts_peak": 53.3, "energy_joules_est": 38.48, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-11T13:22:48.725935"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 848.142, "latencies_ms": [848.142], "images_per_second": 1.179, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young man with dreadlocks is skillfully performing a trick on his skateboard, airborne and balanced on a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.33, 43.33, 43.33, 43.33, 43.33, 43.2, 43.2, 43.2, 43.2], "power_watts_avg": 43.28, "power_watts_peak": 43.33, "energy_joules_est": 36.73, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:22:49.635645"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1225.009, "latencies_ms": [1225.009], "images_per_second": 0.816, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "skateboard: 1\nman: 1\nfence: 1\ntrees: 1\ngrass: 1\nskate ramp: 1\ncamera: 1\nwatermark: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.2, 43.53, 43.53, 43.53, 43.53, 43.53, 42.84, 42.84, 42.84, 42.84, 42.84, 42.82, 42.82], "power_watts_avg": 43.13, "power_watts_peak": 43.53, "energy_joules_est": 52.85, "sample_count": 13, "duration_seconds": 1.225}, "timestamp": "2026-01-11T13:22:50.948041"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1249.582, "latencies_ms": [1249.582], "images_per_second": 0.8, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a ramp. The skateboard is situated near the center of the image, slightly angled towards the left. The background features a grassy area and a fence, providing a contrast to the skateboarder's action.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.42, 42.42, 42.42, 42.42, 42.42, 42.1, 42.1, 42.1, 42.1, 42.1], "power_watts_avg": 42.39, "power_watts_peak": 42.82, "energy_joules_est": 52.99, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-11T13:22:52.261117"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1047.628, "latencies_ms": [1047.628], "images_per_second": 0.955, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young man with dreadlocks is performing a skateboard trick on a concrete ramp in a skate park. He wears a black t-shirt and dark pants. The setting includes a grassy area and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.13, 33.13, 33.13, 33.13, 33.13, 42.53, 42.53, 42.53, 42.53, 42.53, 42.65], "power_watts_avg": 38.27, "power_watts_peak": 42.65, "energy_joules_est": 40.1, "sample_count": 11, "duration_seconds": 1.048}, "timestamp": "2026-01-11T13:22:53.372168"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1009.245, "latencies_ms": [1009.245], "images_per_second": 0.991, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The skateboarder is wearing black clothing and a brown baseball cap. The scene appears to be lit by natural daylight, creating a vibrant atmosphere. The skateboard itself appears to be made of metal and plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 57.0}, "power_stats": {"power_watts_samples": [42.65, 42.65, 42.65, 42.65, 42.12, 42.12, 42.12, 42.12, 42.12, 42.1, 42.1], "power_watts_avg": 42.31, "power_watts_peak": 42.65, "energy_joules_est": 42.73, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-11T13:22:54.481228"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 538.708, "latencies_ms": [538.708], "images_per_second": 1.856, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A group of four people, dressed casually, are posing for a photo on a grassy field, each holding a frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.1, 42.1, 36.65, 36.65, 36.65, 36.65], "power_watts_avg": 38.46, "power_watts_peak": 42.1, "energy_joules_est": 20.76, "sample_count": 6, "duration_seconds": 0.54}, "timestamp": "2026-01-11T13:22:55.090141"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1358.651, "latencies_ms": [1358.651], "images_per_second": 0.736, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Frisbee: 3\nFrisbee: 2\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.65, 38.45, 38.45, 38.45, 38.45, 38.45, 36.75, 36.75, 36.75, 36.75, 36.75, 35.4, 35.4, 35.4], "power_watts_avg": 37.06, "power_watts_peak": 38.45, "energy_joules_est": 50.37, "sample_count": 14, "duration_seconds": 1.359}, "timestamp": "2026-01-11T13:22:56.503207"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 630.198, "latencies_ms": [630.198], "images_per_second": 1.587, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The frisbees are positioned in the foreground, with the players standing behind them. The grassy field extends in the background, separating the main subjects from the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [35.4, 35.4, 37.37, 37.37, 37.37, 37.37, 37.37], "power_watts_avg": 36.8, "power_watts_peak": 37.37, "energy_joules_est": 23.21, "sample_count": 7, "duration_seconds": 0.631}, "timestamp": "2026-01-11T13:22:57.210462"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1029.206, "latencies_ms": [1029.206], "images_per_second": 0.972, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "A group of four people are gathered on a grassy field, enjoying a game of frisbee. They are posing for a photo, holding their frisbees, and smiling. The setting appears to be a park or recreational area, with trees in the background and a clear sky overhead.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.7, 36.7, 36.7, 36.7, 36.7, 37.05, 37.05, 37.05, 37.05, 37.05, 37.42], "power_watts_avg": 36.93, "power_watts_peak": 37.42, "energy_joules_est": 38.02, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-11T13:22:58.319523"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1046.91, "latencies_ms": [1046.91], "images_per_second": 0.955, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The people are wearing casual clothing in colors like blue, white, and red. The lighting suggests it might be either dusk or dawn, creating a warm, inviting atmosphere. The frisbees appear to be made of a durable material, likely plastic or rubber, suitable for outdoor activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.42, 37.42, 37.42, 37.42, 37.02, 37.02, 37.02, 37.02, 37.02, 37.11, 37.11], "power_watts_avg": 37.18, "power_watts_peak": 37.42, "energy_joules_est": 38.95, "sample_count": 11, "duration_seconds": 1.048}, "timestamp": "2026-01-11T13:22:59.431439"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 776.671, "latencies_ms": [776.671], "images_per_second": 1.288, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A large commercial passenger airplane, painted white with a red tail and displaying the JAL logo, is parked at an airport gate with jet bridges attached.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [37.11, 37.11, 37.11, 42.69, 42.69, 42.69, 42.69, 42.69], "power_watts_avg": 40.6, "power_watts_peak": 42.69, "energy_joules_est": 31.55, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:23:00.241721"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1119.778, "latencies_ms": [1119.778], "images_per_second": 0.893, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "airplane: 1\ntarmac: 1\njet bridge: 1\nground crew: 1\nservice vehicles: 1\nairport buildings: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.7, 42.7, 42.7, 42.7, 42.7, 43.19, 43.19, 43.19, 43.19, 43.19, 43.53, 43.53], "power_watts_avg": 43.04, "power_watts_peak": 43.53, "energy_joules_est": 48.21, "sample_count": 12, "duration_seconds": 1.12}, "timestamp": "2026-01-11T13:23:01.452526"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1026.898, "latencies_ms": [1026.898], "images_per_second": 0.974, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object is a large passenger airplane parked on the tarmac, positioned in the foreground. The airplane is facing the viewer and occupies a significant portion of the image. The background includes other aircraft, airport infrastructure, and possibly airport personnel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 43.53, 42.58, 42.58, 42.58, 42.58, 42.58, 42.37, 42.37, 42.37], "power_watts_avg": 42.78, "power_watts_peak": 43.53, "energy_joules_est": 43.95, "sample_count": 11, "duration_seconds": 1.027}, "timestamp": "2026-01-11T13:23:02.563014"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1347.612, "latencies_ms": [1347.612], "images_per_second": 0.742, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "A large Japan Airlines Boeing 777-300ER is parked at an airport gate, ready for boarding or disembarking passengers. Ground service equipment, including baggage carts and service vehicles, is present around the aircraft. The scene is set against a bright blue sky with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.37, 42.37, 37.4, 37.4, 37.4, 37.4, 37.4, 42.41, 42.41, 42.41, 42.41, 42.41, 38.37, 38.37], "power_watts_avg": 40.04, "power_watts_peak": 42.41, "energy_joules_est": 53.97, "sample_count": 14, "duration_seconds": 1.348}, "timestamp": "2026-01-11T13:23:03.975773"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 734.832, "latencies_ms": [734.832], "images_per_second": 1.361, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The airplane is predominantly white with red accents on the tail and around the engines. The sky is bright blue with scattered white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.37, 38.37, 38.37, 41.68, 41.68, 41.68, 41.68, 41.68], "power_watts_avg": 40.44, "power_watts_peak": 41.68, "energy_joules_est": 29.74, "sample_count": 8, "duration_seconds": 0.735}, "timestamp": "2026-01-11T13:23:04.783413"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 815.037, "latencies_ms": [815.037], "images_per_second": 1.227, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A young man in a yellow shirt and black pants is skillfully riding a skateboard on a concrete ramp in a skate park, surrounded by graffiti and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 23.0}, "power_stats": {"power_watts_samples": [42.68, 42.68, 42.68, 42.68, 43.57, 43.57, 43.57, 43.57, 43.57], "power_watts_avg": 43.17, "power_watts_peak": 43.57, "energy_joules_est": 35.21, "sample_count": 9, "duration_seconds": 0.816}, "timestamp": "2026-01-11T13:23:05.694896"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1156.995, "latencies_ms": [1156.995], "images_per_second": 0.864, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "trash can: 1\nbench: 2\npark bench: 2\nskateboard: 1\nskateboard ramp: 1\ncar: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.3, 41.3, 41.3, 41.3, 41.3, 42.42, 42.42, 42.42, 42.42, 42.42, 43.88, 43.88], "power_watts_avg": 42.2, "power_watts_peak": 43.88, "energy_joules_est": 48.84, "sample_count": 12, "duration_seconds": 1.157}, "timestamp": "2026-01-11T13:23:06.903965"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1073.351, "latencies_ms": [1073.351], "images_per_second": 0.932, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a concrete ramp. The park setting with benches, trees, and a bus stop in the background creates a spatial relationship between the skateboarder and the park elements.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.88, 43.88, 43.88, 43.14, 43.14, 43.14, 43.14, 43.14, 43.05, 43.05, 43.05], "power_watts_avg": 43.32, "power_watts_peak": 43.88, "energy_joules_est": 46.51, "sample_count": 11, "duration_seconds": 1.074}, "timestamp": "2026-01-11T13:23:08.015061"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 920.62, "latencies_ms": [920.62], "images_per_second": 1.086, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A young man is performing a skateboard trick on a concrete ramp in a park-like setting. The park features benches, a bus stop, and trees, creating a casual and recreational atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 40.44, 40.44, 40.44, 40.44, 40.44, 43.54, 43.54, 43.54], "power_watts_avg": 41.89, "power_watts_peak": 43.54, "energy_joules_est": 38.59, "sample_count": 10, "duration_seconds": 0.921}, "timestamp": "2026-01-11T13:23:09.027390"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 949.051, "latencies_ms": [949.051], "images_per_second": 1.054, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The skateboarder is wearing a yellow shirt and brown pants. The scene is brightly lit, suggesting sunlight. The skate park features graffiti on the concrete structures and benches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 42.21, 42.21, 42.21, 42.21, 42.21, 41.95, 41.95, 41.95], "power_watts_avg": 42.39, "power_watts_peak": 43.54, "energy_joules_est": 40.26, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-11T13:23:10.038230"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 863.126, "latencies_ms": [863.126], "images_per_second": 1.159, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A slice of decadent chocolate cake, drizzled with chocolate sauce and adorned with white chocolate drizzle, sits on a decorative white plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.95, 41.95, 42.99, 42.99, 42.99, 42.99, 42.99, 42.51, 42.51], "power_watts_avg": 42.65, "power_watts_peak": 42.99, "energy_joules_est": 36.83, "sample_count": 9, "duration_seconds": 0.863}, "timestamp": "2026-01-11T13:23:10.948937"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1445.006, "latencies_ms": [1445.006], "images_per_second": 0.692, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "slice of chocolate cake: 1\nchocolate ganache: 1\ncaramel sauce: 1\nflour: 0\nbutter: 0\nsprinkles: 0\nflour: 0\ncake: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 42.51, 45.9, 45.9, 45.9, 45.9, 45.9, 42.73, 42.73, 42.73, 42.73, 42.73, 33.57, 33.57], "power_watts_avg": 42.52, "power_watts_peak": 45.9, "energy_joules_est": 61.47, "sample_count": 15, "duration_seconds": 1.446}, "timestamp": "2026-01-11T13:23:12.464335"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 966.109, "latencies_ms": [966.109], "images_per_second": 1.035, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The chocolate cake is positioned in the foreground of the image, resting on a white plate with a gold floral pattern. The plate is situated on a surface, possibly a table, which further emphasizes the foreground placement of the cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.57, 33.57, 33.57, 42.13, 42.13, 42.13, 42.13, 42.13, 42.54, 42.54], "power_watts_avg": 39.65, "power_watts_peak": 42.54, "energy_joules_est": 38.32, "sample_count": 10, "duration_seconds": 0.967}, "timestamp": "2026-01-11T13:23:13.476018"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 837.88, "latencies_ms": [837.88], "images_per_second": 1.193, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A slice of chocolate cake with a drizzle of white chocolate sits on a decorative plate. The plate is placed on a wooden table, enhancing the warm and inviting atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 42.77, 42.77, 42.77, 42.77, 42.77, 43.35], "power_watts_avg": 42.76, "power_watts_peak": 43.35, "energy_joules_est": 35.85, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:23:14.387382"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1016.386, "latencies_ms": [1016.386], "images_per_second": 0.984, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The chocolate cake is topped with a glossy chocolate glaze. The plate has a delicate gold floral pattern. The cake appears moist and rich, enhanced by the caramel sauce drizzled on top.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 43.48, 43.48, 43.48, 43.48, 43.48, 42.31, 42.31, 42.31], "power_watts_avg": 43.12, "power_watts_peak": 43.48, "energy_joules_est": 43.85, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-11T13:23:15.498414"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 613.251, "latencies_ms": [613.251], "images_per_second": 1.631, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is working on a laptop at a cluttered desk, surrounded by various electronic devices and equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.31, 42.31, 39.24, 39.24, 39.24, 39.24, 39.24], "power_watts_avg": 40.11, "power_watts_peak": 42.31, "energy_joules_est": 24.62, "sample_count": 7, "duration_seconds": 0.614}, "timestamp": "2026-01-11T13:23:16.209547"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1489.484, "latencies_ms": [1489.484], "images_per_second": 0.671, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "laptop: 2\nkeyboard: 1\nmouse: 1\nlaptop: 2\ncord: 1\nwater bottle: 1\ncardboard box: 2\nchair: 4\ntable: 2\nperson: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.5, 40.5, 40.5, 40.5, 40.5, 44.53, 44.53, 44.53, 44.53, 44.53, 43.44, 43.44, 43.44, 43.44, 43.44], "power_watts_avg": 42.83, "power_watts_peak": 44.53, "energy_joules_est": 63.81, "sample_count": 15, "duration_seconds": 1.49}, "timestamp": "2026-01-11T13:23:17.720517"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1175.462, "latencies_ms": [1175.462], "images_per_second": 0.851, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The foreground features the laptop and keyboard, while the background includes other desks, chairs, and equipment. The laptop is situated in the foreground, closer to the viewer, while the background elements are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.64, 33.64, 33.64, 33.64, 33.64, 43.55, 43.55, 43.55, 43.55, 43.55, 43.37, 43.37], "power_watts_avg": 39.39, "power_watts_peak": 43.55, "energy_joules_est": 46.32, "sample_count": 12, "duration_seconds": 1.176}, "timestamp": "2026-01-11T13:23:18.931880"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 898.917, "latencies_ms": [898.917], "images_per_second": 1.112, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a busy workspace with multiple people working on laptops and electronic components. Various boxes, equipment, and tools are scattered throughout the room, indicating a collaborative environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.37, 43.37, 43.37, 43.02, 43.02, 43.02, 43.02, 43.02, 43.0], "power_watts_avg": 43.13, "power_watts_peak": 43.37, "energy_joules_est": 38.79, "sample_count": 9, "duration_seconds": 0.899}, "timestamp": "2026-01-11T13:23:19.840380"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1145.566, "latencies_ms": [1145.566], "images_per_second": 0.873, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The room is lit by fluorescent lighting, giving it a bright and airy atmosphere. The walls are covered with various materials, including cardboard boxes, papers, and possibly some electronic components. The floor appears to be painted in a light yellow or tan color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.0, 43.0, 43.0, 43.0, 43.38, 43.38, 43.38, 43.38, 43.38, 43.44, 43.44, 43.44], "power_watts_avg": 43.27, "power_watts_peak": 43.44, "energy_joules_est": 49.59, "sample_count": 12, "duration_seconds": 1.146}, "timestamp": "2026-01-11T13:23:21.054741"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 640.083, "latencies_ms": [640.083], "images_per_second": 1.562, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of friends is playing a video game in a cozy living room, enjoying each other's company and having a good time.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 37.8, 37.8, 37.8, 37.8, 37.8], "power_watts_avg": 39.42, "power_watts_peak": 43.44, "energy_joules_est": 25.25, "sample_count": 7, "duration_seconds": 0.641}, "timestamp": "2026-01-11T13:23:21.763177"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1142.875, "latencies_ms": [1142.875], "images_per_second": 0.875, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "woman: 2\nman: 2\nman: 2\nman: 2\nman: 2\nman: 2\nman: 2\nman: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.4, 42.4, 42.4, 42.4, 42.4, 47.58, 47.58, 47.58, 47.58, 47.58, 42.04, 42.04], "power_watts_avg": 44.5, "power_watts_peak": 47.58, "energy_joules_est": 50.87, "sample_count": 12, "duration_seconds": 1.143}, "timestamp": "2026-01-11T13:23:22.970926"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 956.512, "latencies_ms": [956.512], "images_per_second": 1.045, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a couch and table located in the background. The foreground is dominated by the woman and the man playing the game, while the background features other furniture and objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.04, 42.04, 42.04, 41.53, 41.53, 41.53, 41.53, 41.53, 42.46, 42.46], "power_watts_avg": 41.87, "power_watts_peak": 42.46, "energy_joules_est": 40.08, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:23:23.981664"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1155.611, "latencies_ms": [1155.611], "images_per_second": 0.865, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "A group of friends is playing a video game in a cozy living room. They are standing barefoot and holding Wii remotes, enjoying a fun and engaging activity together. The room features a couch, a coffee table, and various personal items, creating a comfortable and relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 42.46, 43.27, 43.27, 43.27, 43.27, 43.27, 42.74, 42.74, 42.74, 42.74], "power_watts_avg": 42.89, "power_watts_peak": 43.27, "energy_joules_est": 49.58, "sample_count": 12, "duration_seconds": 1.156}, "timestamp": "2026-01-11T13:23:25.192647"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 820.619, "latencies_ms": [820.619], "images_per_second": 1.219, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The room is lit by natural light coming through windows, creating a warm ambiance. The walls are painted white, and the carpet is a neutral color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [34.08, 34.08, 34.08, 34.08, 34.08, 42.12, 42.12, 42.12, 42.12], "power_watts_avg": 37.66, "power_watts_peak": 42.12, "energy_joules_est": 30.91, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:23:26.102411"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 665.85, "latencies_ms": [665.85], "images_per_second": 1.502, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A person is silhouetted against the setting sun, standing on a frozen surface with footprints nearby, holding an object in their hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.12, 44.44, 44.44, 44.44, 44.44, 44.44, 42.18], "power_watts_avg": 43.79, "power_watts_peak": 44.44, "energy_joules_est": 29.18, "sample_count": 7, "duration_seconds": 0.666}, "timestamp": "2026-01-11T13:23:26.813697"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1054.69, "latencies_ms": [1054.69], "images_per_second": 0.948, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "sun: 1\nperson: 1\nfrisbee: 1\nice: 2\nwater: 2\nsky: 1\nhorizon: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.18, 42.18, 42.18, 42.18, 51.21, 51.21, 51.21, 51.21, 51.21, 42.95, 42.95], "power_watts_avg": 46.43, "power_watts_peak": 51.21, "energy_joules_est": 48.99, "sample_count": 11, "duration_seconds": 1.055}, "timestamp": "2026-01-11T13:23:27.924484"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1000.869, "latencies_ms": [1000.869], "images_per_second": 0.999, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The person stands in the middle of the image, facing the setting sun. The sun is positioned behind them, partially obscured by the horizon. The person's silhouette is visible against the bright sky, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.95, 42.95, 42.95, 42.95, 42.95, 42.95, 42.95, 42.95, 42.91, 42.91], "power_watts_avg": 42.94, "power_watts_peak": 42.95, "energy_joules_est": 43.0, "sample_count": 10, "duration_seconds": 1.001}, "timestamp": "2026-01-11T13:23:28.934988"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1096.342, "latencies_ms": [1096.342], "images_per_second": 0.912, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A person is standing on a frozen surface, possibly a beach or ice floe, during sunset. The sun is setting in the distance, creating a warm glow and casting long shadows. The scene evokes a sense of solitude and tranquility.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.91, 42.91, 42.91, 43.64, 43.64, 43.64, 43.64, 43.64, 43.19, 43.19, 43.19], "power_watts_avg": 43.32, "power_watts_peak": 43.64, "energy_joules_est": 47.51, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:23:30.046147"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 949.611, "latencies_ms": [949.611], "images_per_second": 1.053, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The sky is a vibrant mix of orange and blue, indicating a sunset. The ground is partially covered with ice and snow, reflecting the warm light of the setting sun. The scene is peaceful and serene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 39.99, 39.99, 39.99, 39.99, 39.99, 43.5, 43.5, 43.5], "power_watts_avg": 41.68, "power_watts_peak": 43.5, "energy_joules_est": 39.61, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-11T13:23:31.055290"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 843.725, "latencies_ms": [843.725], "images_per_second": 1.185, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The living room features a white sofa, a coffee table, a television, a dining table with four chairs, and various decorative elements such as vases, books, and wall art.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 42.45, 42.45, 42.45, 42.45, 42.45, 43.0, 43.0], "power_watts_avg": 42.8, "power_watts_peak": 43.5, "energy_joules_est": 36.15, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-11T13:23:31.968965"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1222.746, "latencies_ms": [1222.746], "images_per_second": 0.818, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "sofa: 2\nchairs: 3\nrug: 1\ntable: 1\ntelevision: 1\nlamp: 1\nflowers: 1\nwall decor: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.0, 43.0, 43.0, 48.05, 48.05, 48.05, 48.05, 48.05, 42.81, 42.81, 42.81, 42.81, 42.81], "power_watts_avg": 44.87, "power_watts_peak": 48.05, "energy_joules_est": 54.88, "sample_count": 13, "duration_seconds": 1.223}, "timestamp": "2026-01-11T13:23:33.284253"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 919.618, "latencies_ms": [919.618], "images_per_second": 1.087, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The white sofa and wooden coffee table are positioned in the foreground, facing the window and television. The dining table and chairs are situated in the background, facing the window and television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.83, 33.83, 33.83, 33.83, 33.83, 42.27, 42.27, 42.27, 42.27, 42.26], "power_watts_avg": 38.05, "power_watts_peak": 42.27, "energy_joules_est": 35.01, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-11T13:23:34.295953"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1332.601, "latencies_ms": [1332.601], "images_per_second": 0.75, "prompt_tokens": 19, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The living room features a modern and stylish design with natural light streaming in through large windows.  The space is furnished with a white sofa, a coffee table, a television, and a dining area with a round table and chairs. Decorative elements like wall art and plants contribute to the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 48.0}, "power_stats": {"power_watts_samples": [42.26, 42.26, 42.26, 42.26, 41.95, 41.95, 41.95, 41.95, 41.95, 41.84, 41.84, 41.84, 41.84, 41.84], "power_watts_avg": 42.0, "power_watts_peak": 42.26, "energy_joules_est": 55.99, "sample_count": 14, "duration_seconds": 1.333}, "timestamp": "2026-01-11T13:23:35.711216"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1165.915, "latencies_ms": [1165.915], "images_per_second": 0.858, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The room features a warm color palette, primarily with cream, beige, and light brown tones. The lighting is soft and warm, creating a cozy atmosphere. The furniture includes white, wood, and red elements, adding contrast and visual interest to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [32.43, 32.43, 32.43, 32.43, 32.43, 42.23, 42.23, 42.23, 42.23, 42.23, 42.44, 42.44], "power_watts_avg": 38.18, "power_watts_peak": 42.44, "energy_joules_est": 44.53, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-11T13:23:36.923291"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 668.143, "latencies_ms": [668.143], "images_per_second": 1.497, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A curious tabby cat with a blue collar sits atop a blue refrigerator in a kitchen, gazing upwards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.44, 42.44, 42.44, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 42.63, "power_watts_peak": 42.77, "energy_joules_est": 28.5, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:23:37.634778"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1294.906, "latencies_ms": [1294.906], "images_per_second": 0.772, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Refrigerator: 2\nCabinet: 1\nLight fixture: 1\nCat: 1\nWall: 1\nFloor: 1\nMirror: 1\nMagnet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.77, 43.48, 43.48, 43.48, 43.48, 43.48, 43.13, 43.13, 43.13, 43.13, 43.13, 43.4, 43.4], "power_watts_avg": 43.28, "power_watts_peak": 43.48, "energy_joules_est": 56.05, "sample_count": 13, "duration_seconds": 1.295}, "timestamp": "2026-01-11T13:23:38.948221"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 922.86, "latencies_ms": [922.86], "images_per_second": 1.084, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The cat is positioned near the refrigerator, seemingly looking up at it.  The refrigerator is situated in the immediate foreground, while the cat is positioned slightly further back, near the cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.4, 43.4, 43.4, 43.39, 43.39, 43.39, 43.39, 43.39, 43.39, 43.39], "power_watts_avg": 43.39, "power_watts_peak": 43.4, "energy_joules_est": 40.07, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-11T13:23:39.959096"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 797.777, "latencies_ms": [797.777], "images_per_second": 1.253, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A tabby cat with a blue collar is perched atop a blue refrigerator in a kitchen. The kitchen features white cabinets and a light-colored ceiling.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.39, 43.39, 43.39, 42.48, 42.48, 42.48, 42.48, 42.48], "power_watts_avg": 42.82, "power_watts_peak": 43.39, "energy_joules_est": 34.19, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:23:40.767512"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 855.036, "latencies_ms": [855.036], "images_per_second": 1.17, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The cat is brown and gray, wearing a blue collar. The kitchen has light-colored cabinets and a blue refrigerator. The lighting is bright, likely from overhead fixtures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.94, 41.94, 41.94, 41.94, 41.94, 43.91, 43.91, 43.91, 43.91], "power_watts_avg": 42.82, "power_watts_peak": 43.91, "energy_joules_est": 36.63, "sample_count": 9, "duration_seconds": 0.855}, "timestamp": "2026-01-11T13:23:41.678107"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 697.376, "latencies_ms": [697.376], "images_per_second": 1.434, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The living room is decorated with colorful balloons, including a large yellow smiley face balloon, and scattered confetti on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 42.0}, "power_stats": {"power_watts_samples": [43.91, 42.61, 42.61, 42.61, 42.61, 42.61, 42.41], "power_watts_avg": 42.77, "power_watts_peak": 43.91, "energy_joules_est": 29.84, "sample_count": 7, "duration_seconds": 0.698}, "timestamp": "2026-01-11T13:23:42.390245"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1729.612, "latencies_ms": [1729.612], "images_per_second": 0.578, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "smiley face balloon: 1\nblue balloon: 1\nyellow balloon: 1\ngreen balloon: 1\nwooden shelving unit: 2\nrefrigerator: 1\nbed: 1\nrug: 1\ntable: 1\nbookshelf: 2\nlamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.41, 42.41, 42.41, 53.8, 53.8, 53.8, 53.8, 53.8, 43.64, 43.64, 43.64, 43.64, 43.64, 33.36, 33.36, 33.36, 33.36, 33.36], "power_watts_avg": 43.4, "power_watts_peak": 53.8, "energy_joules_est": 75.1, "sample_count": 18, "duration_seconds": 1.73}, "timestamp": "2026-01-11T13:23:44.209694"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 925.43, "latencies_ms": [925.43], "images_per_second": 1.081, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The refrigerator is positioned on the left side of the image, near the foreground. The bedroom is situated in the background, near the center. The living area is further back, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.41, 32.41, 32.41, 32.41, 32.41, 41.97, 41.97, 41.97, 41.97, 41.97], "power_watts_avg": 37.19, "power_watts_peak": 41.97, "energy_joules_est": 34.44, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-11T13:23:45.222077"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 911.866, "latencies_ms": [911.866], "images_per_second": 1.097, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a cozy, cluttered apartment with a small kitchen area, living room, and bedroom.  A birthday celebration is taking place, with balloons and decorations adding to the festive atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.17, 42.17, 42.17, 42.17, 42.17, 42.12, 42.12, 42.12, 42.12, 42.12], "power_watts_avg": 42.15, "power_watts_peak": 42.17, "energy_joules_est": 38.46, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-11T13:23:46.233671"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 817.541, "latencies_ms": [817.541], "images_per_second": 1.223, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The room is decorated with yellow and blue balloons, creating a cheerful atmosphere. The wooden floor and light-colored walls contribute to the overall warm and cozy feel of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.9, 41.9, 41.9, 41.9, 41.9, 42.31, 42.31, 42.31, 42.31], "power_watts_avg": 42.08, "power_watts_peak": 42.31, "energy_joules_est": 34.42, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:23:47.142685"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 690.541, "latencies_ms": [690.541], "images_per_second": 1.448, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man with red hair, wearing a green jacket and headphones, is sitting in a train seat, focused on his laptop computer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.31, 42.14, 42.14, 42.14, 42.14, 42.14, 42.44], "power_watts_avg": 42.2, "power_watts_peak": 42.44, "energy_joules_est": 29.17, "sample_count": 7, "duration_seconds": 0.691}, "timestamp": "2026-01-11T13:23:47.852589"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1159.07, "latencies_ms": [1159.07], "images_per_second": 0.863, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "laptop: 1\ntable: 1\nchair: 2\nwindow: 1\nman: 1\nheadphones: 1\njacket: 1\nshirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.44, 42.44, 42.44, 42.44, 53.64, 53.64, 53.64, 53.64, 53.64, 43.77, 43.77, 43.77], "power_watts_avg": 47.44, "power_watts_peak": 53.64, "energy_joules_est": 55.01, "sample_count": 12, "duration_seconds": 1.16}, "timestamp": "2026-01-11T13:23:49.065664"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 953.476, "latencies_ms": [953.476], "images_per_second": 1.049, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main object is a laptop positioned in the foreground, close to the viewer. The background features the train window, suggesting the train is moving. The laptop is situated near the window, implying a train travel scenario.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 37.98, 37.98, 37.98, 37.98, 37.98, 43.27, 43.27, 43.27], "power_watts_avg": 40.73, "power_watts_peak": 43.77, "energy_joules_est": 38.85, "sample_count": 10, "duration_seconds": 0.954}, "timestamp": "2026-01-11T13:23:50.075949"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 742.406, "latencies_ms": [742.406], "images_per_second": 1.347, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man is sitting in a train car, using a laptop while looking out the window. He appears to be focused on his work or browsing the internet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 42.3, 42.3, 42.3, 42.3, 42.3, 42.75], "power_watts_avg": 42.6, "power_watts_peak": 43.27, "energy_joules_est": 31.66, "sample_count": 8, "duration_seconds": 0.743}, "timestamp": "2026-01-11T13:23:50.885615"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1211.981, "latencies_ms": [1211.981], "images_per_second": 0.825, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The man is wearing a green jacket, which stands out against the neutral tones of the train's interior. The lighting is soft and diffused, suggesting natural light from the window. The train's interior appears to be made of metal and wood, contributing to the overall industrial aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.75, 42.75, 42.75, 42.75, 48.73, 48.73, 48.73, 48.73, 48.73, 42.34, 42.34, 42.34, 42.34], "power_watts_avg": 44.92, "power_watts_peak": 48.73, "energy_joules_est": 54.46, "sample_count": 13, "duration_seconds": 1.212}, "timestamp": "2026-01-11T13:23:52.196525"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 700.713, "latencies_ms": [700.713], "images_per_second": 1.427, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A silver train is traveling on a track beneath a large white metal bridge, passing through a suburban area with buildings and trees.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [31.78, 31.78, 31.78, 31.78, 31.78, 41.98, 41.98], "power_watts_avg": 34.7, "power_watts_peak": 41.98, "energy_joules_est": 24.34, "sample_count": 7, "duration_seconds": 0.701}, "timestamp": "2026-01-11T13:23:52.908295"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1028.255, "latencies_ms": [1028.255], "images_per_second": 0.973, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bridge: 2\ntrain: 2\nroad: 1\nsky: 1\nclouds: 2\nbuildings: 2\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.98, 41.98, 41.98, 53.9, 53.9, 53.9, 53.9, 53.9, 43.71, 43.71, 43.71], "power_watts_avg": 47.87, "power_watts_peak": 53.9, "energy_joules_est": 49.25, "sample_count": 11, "duration_seconds": 1.029}, "timestamp": "2026-01-11T13:23:54.019336"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 942.128, "latencies_ms": [942.128], "images_per_second": 1.061, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The train is positioned in the foreground, moving away from the viewer. The road and bridge are located in the background, extending into the distance. The bridge spans across the road and appears to connect two points.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.71, 43.71, 39.31, 39.31, 39.31, 39.31, 39.31, 42.44, 42.44, 42.44], "power_watts_avg": 41.13, "power_watts_peak": 43.71, "energy_joules_est": 38.77, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-11T13:23:55.029154"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.369, "latencies_ms": [1052.369], "images_per_second": 0.95, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a modern, elevated train station with multiple train tracks. A silver train is traveling on the tracks, passing under a distinctive white bridge. The surrounding area features residential buildings and a hilly landscape in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.44, 42.44, 42.6, 42.6, 42.6, 42.6, 42.6, 42.64, 42.64, 42.64, 42.64], "power_watts_avg": 42.59, "power_watts_peak": 42.64, "energy_joules_est": 44.84, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:23:56.139171"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1045.713, "latencies_ms": [1045.713], "images_per_second": 0.956, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The bridge is primarily white, contrasting with the blue sky and white clouds above. The lighting suggests a sunny day, with bright sunlight illuminating the scene. The materials appear to be steel and concrete, typical of infrastructure construction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.64, 37.51, 37.51, 37.51, 37.51, 37.51, 42.67, 42.67, 42.67, 42.67, 42.67], "power_watts_avg": 40.32, "power_watts_peak": 42.67, "energy_joules_est": 42.19, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-11T13:23:57.249984"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 722.618, "latencies_ms": [722.618], "images_per_second": 1.384, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A group of people are flying a colorful dragon-shaped kite in a vibrant park, surrounded by other kites and people enjoying outdoor activities.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.94, 42.94, 42.94, 42.94, 42.94, 42.79, 42.79, 42.79], "power_watts_avg": 42.89, "power_watts_peak": 42.94, "energy_joules_est": 31.01, "sample_count": 8, "duration_seconds": 0.723}, "timestamp": "2026-01-11T13:23:58.060896"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1081.944, "latencies_ms": [1081.944], "images_per_second": 0.924, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "kite: 1\nperson: 2\ngrass: 6\nfence: 1\nsoccer ball: 1\nchairs: 1\nbags: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.79, 42.79, 46.76, 46.76, 46.76, 46.76, 46.76, 42.27, 42.27, 42.27, 42.27], "power_watts_avg": 44.41, "power_watts_peak": 46.76, "energy_joules_est": 48.07, "sample_count": 11, "duration_seconds": 1.083}, "timestamp": "2026-01-11T13:23:59.169208"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 638.104, "latencies_ms": [638.104], "images_per_second": 1.567, "prompt_tokens": 25, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The kite is positioned in the foreground, close to the people. The field extends in the background, further away from the people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.27, 39.21, 39.21, 39.21, 39.21, 39.21, 43.75], "power_watts_avg": 40.3, "power_watts_peak": 43.75, "energy_joules_est": 25.74, "sample_count": 7, "duration_seconds": 0.639}, "timestamp": "2026-01-11T13:23:59.878049"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1070.187, "latencies_ms": [1070.187], "images_per_second": 0.934, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene takes place in a park on a sunny day. A group of people, including children, gathers on a grassy field, flying a large, colorful kite. The kite has a dragon-like design, adding a playful element to the atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.75, 43.75, 43.75, 43.75, 53.63, 53.63, 53.63, 53.63, 53.63, 43.05, 43.05], "power_watts_avg": 48.11, "power_watts_peak": 53.63, "energy_joules_est": 51.51, "sample_count": 11, "duration_seconds": 1.071}, "timestamp": "2026-01-11T13:24:00.988219"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1138.992, "latencies_ms": [1138.992], "images_per_second": 0.878, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The kite is predominantly blue and purple with vibrant orange and yellow accents. The scene appears to be lit by natural sunlight, giving a warm glow to the green grass and the colorful kite. The kite appears to be made of a lightweight, flexible material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 41.7, 41.7, 41.7, 41.7, 43.49, 43.49, 43.49, 43.49, 43.49], "power_watts_avg": 42.78, "power_watts_peak": 43.49, "energy_joules_est": 48.75, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-11T13:24:02.199588"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 777.821, "latencies_ms": [777.821], "images_per_second": 1.286, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A group of miniature workers in orange uniforms are standing next to a red and black Virgin train, appearing to be inspecting or preparing the train for a journey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.39, 34.39, 34.39, 34.39, 34.39, 42.64, 42.64, 42.64], "power_watts_avg": 37.49, "power_watts_peak": 42.64, "energy_joules_est": 29.18, "sample_count": 8, "duration_seconds": 0.778}, "timestamp": "2026-01-11T13:24:03.011342"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1414.4, "latencies_ms": [1414.4], "images_per_second": 0.707, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Train: 6\nTrain car: 2\nTrain tracks: 4\nTrain wires: 4\nTrain workers: 6\nTrain engine: 1\nTrain body: 1\nTrain wheels: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.64, 42.64, 50.01, 50.01, 50.01, 50.01, 50.01, 43.45, 43.45, 43.45, 43.45, 43.45, 35.3, 35.3, 35.3], "power_watts_avg": 43.9, "power_watts_peak": 50.01, "energy_joules_est": 62.11, "sample_count": 15, "duration_seconds": 1.415}, "timestamp": "2026-01-11T13:24:04.522916"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 840.7, "latencies_ms": [840.7], "images_per_second": 1.189, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The red and black train is positioned in the foreground, moving towards the left side of the image. The miniature model train track extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [35.3, 35.3, 39.03, 39.03, 39.03, 39.03, 39.03, 42.01, 42.01], "power_watts_avg": 38.86, "power_watts_peak": 42.01, "energy_joules_est": 32.7, "sample_count": 9, "duration_seconds": 0.841}, "timestamp": "2026-01-11T13:24:05.432774"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 910.019, "latencies_ms": [910.019], "images_per_second": 1.099, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A model train is traveling on tracks in a miniature model landscape. Workers in orange uniforms are seen working alongside the train, seemingly inspecting or maintaining the model.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.2, "ram_available_mb": 109445.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [42.01, 42.01, 42.01, 45.36, 45.36, 45.36, 45.36, 45.36, 42.23, 42.23], "power_watts_avg": 43.73, "power_watts_peak": 45.36, "energy_joules_est": 39.81, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:24:06.442228"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1108.714, "latencies_ms": [1108.714], "images_per_second": 0.902, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The train is primarily red and black. The lighting in the image creates a dramatic effect, highlighting the colors of the train and the workers. The materials appear to be standard model train construction, typical for miniature models. The weather is not visible in the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [42.23, 42.23, 42.23, 41.73, 41.73, 41.73, 41.73, 41.73, 42.1, 42.1, 42.1, 42.1], "power_watts_avg": 41.98, "power_watts_peak": 42.23, "energy_joules_est": 46.55, "sample_count": 12, "duration_seconds": 1.109}, "timestamp": "2026-01-11T13:24:07.650683"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 660.733, "latencies_ms": [660.733], "images_per_second": 1.513, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A brown and white cat's fur is visible, appearing soft and slightly ruffled against the textured background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 8.0}, "power_stats": {"power_watts_samples": [42.1, 33.02, 33.02, 33.02, 33.02, 33.02, 41.96], "power_watts_avg": 35.6, "power_watts_peak": 42.1, "energy_joules_est": 23.54, "sample_count": 7, "duration_seconds": 0.661}, "timestamp": "2026-01-11T13:24:08.361172"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 890.722, "latencies_ms": [890.722], "images_per_second": 1.123, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "cat: 2\nblanket: 2\nfur: 2\nhair: 2\nskin: 2\nbody: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.96, 41.96, 41.96, 41.96, 52.25, 52.25, 52.25, 52.25, 52.25], "power_watts_avg": 47.68, "power_watts_peak": 52.25, "energy_joules_est": 42.48, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:24:09.271065"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 946.746, "latencies_ms": [946.746], "images_per_second": 1.056, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the beige textured fabric. The cat's fur is primarily light brown and white, contrasting with the background. The cat's position suggests it is close to the fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.29, 43.29, 43.29, 43.29, 43.29, 43.68, 43.68, 43.68, 43.68, 43.68], "power_watts_avg": 43.49, "power_watts_peak": 43.68, "energy_joules_est": 41.18, "sample_count": 10, "duration_seconds": 0.947}, "timestamp": "2026-01-11T13:24:10.278731"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 693.546, "latencies_ms": [693.546], "images_per_second": 1.442, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A cat with brown and white fur is resting on a textured, beige blanket. The blanket has a subtle pattern of triangles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.68, 43.68, 43.68, 43.68, 43.68, 42.67, 42.67], "power_watts_avg": 43.39, "power_watts_peak": 43.68, "energy_joules_est": 30.12, "sample_count": 7, "duration_seconds": 0.694}, "timestamp": "2026-01-11T13:24:10.985875"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1049.716, "latencies_ms": [1049.716], "images_per_second": 0.953, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The cat's fur is a mix of brown and white. The lighting appears to be soft and diffused, possibly coming from a window or overhead light source. The material appears to be a soft, textured fabric, possibly a blanket or bedspread.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 51.99, 51.99, 51.99, 51.99, 51.99, 43.49, 43.49, 43.49], "power_watts_avg": 47.13, "power_watts_peak": 51.99, "energy_joules_est": 49.5, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-11T13:24:12.097299"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 701.805, "latencies_ms": [701.805], "images_per_second": 1.425, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A cow is standing in a milking parlor, receiving milk from a series of red and white tubes connected to a machine.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.49, 37.34, 37.34, 37.34, 37.34, 37.34, 42.83], "power_watts_avg": 39.01, "power_watts_peak": 43.49, "energy_joules_est": 27.39, "sample_count": 7, "duration_seconds": 0.702}, "timestamp": "2026-01-11T13:24:12.807987"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1406.861, "latencies_ms": [1406.861], "images_per_second": 0.711, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Cow: 4\nMilking machine: 3\nMilk tub: 1\nPumps: 2\nPipes: 2\nMetal: 1\nPlastic: 1\nWood: 1\nMetal: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.6, "ram_available_mb": 109444.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.83, 42.83, 42.83, 42.83, 49.99, 49.99, 49.99, 49.99, 49.99, 44.06, 44.06, 44.06, 44.06, 44.06, 33.69], "power_watts_avg": 45.02, "power_watts_peak": 49.99, "energy_joules_est": 63.36, "sample_count": 15, "duration_seconds": 1.407}, "timestamp": "2026-01-11T13:24:14.318110"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 895.208, "latencies_ms": [895.208], "images_per_second": 1.117, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The cow's legs are positioned in the foreground, partially obscuring the milking machine. The milking machine is situated in the background, partially obscured by the cow's legs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.6, "ram_available_mb": 109444.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.6, "ram_available_mb": 109444.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.69, 33.69, 33.69, 33.69, 42.22, 42.22, 42.22, 42.22, 42.22], "power_watts_avg": 38.43, "power_watts_peak": 42.22, "energy_joules_est": 34.41, "sample_count": 9, "duration_seconds": 0.896}, "timestamp": "2026-01-11T13:24:15.228553"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1081.425, "latencies_ms": [1081.425], "images_per_second": 0.925, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A cow is milking a cow in a milking parlor. The milking apparatus consists of red and white tubes connected to a machine. The parlor is filled with dirt and hay, indicating a traditional milking process.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13061.6, "ram_available_mb": 109444.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.98, 41.98, 41.98, 41.98, 41.98, 43.46, 43.46, 43.46, 43.46, 43.46, 43.54], "power_watts_avg": 42.8, "power_watts_peak": 43.54, "energy_joules_est": 46.29, "sample_count": 11, "duration_seconds": 1.082}, "timestamp": "2026-01-11T13:24:16.336231"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1013.601, "latencies_ms": [1013.601], "images_per_second": 0.987, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The cow's legs are predominantly black with white patches. The lighting in the image appears to be artificial, likely from overhead fixtures. The cow's legs are made of metal and plastic, contributing to the overall industrial aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 43.54, 43.06, 43.06, 43.06, 43.06, 43.06, 43.17, 43.17], "power_watts_avg": 43.25, "power_watts_peak": 43.54, "energy_joules_est": 43.85, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-11T13:24:17.446101"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 659.993, "latencies_ms": [659.993], "images_per_second": 1.515, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A half-eaten sandwich with red filling and scattered seeds rests on a patterned plate, accompanied by a knife.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 43.17, 41.91, 41.91, 41.91, 41.91], "power_watts_avg": 42.45, "power_watts_peak": 43.17, "energy_joules_est": 28.04, "sample_count": 7, "duration_seconds": 0.661}, "timestamp": "2026-01-11T13:24:18.157458"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1108.505, "latencies_ms": [1108.505], "images_per_second": 0.902, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "sandwich: 3\nbread: 2\njelly: 1\nbutter: 1\nplate: 1\nknife: 1\ngreen napkin: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.91, 42.54, 42.54, 42.54, 42.54, 42.54, 43.03, 43.03, 43.03, 43.03, 43.03, 43.96], "power_watts_avg": 42.81, "power_watts_peak": 43.96, "energy_joules_est": 47.47, "sample_count": 12, "duration_seconds": 1.109}, "timestamp": "2026-01-11T13:24:19.367040"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 695.28, "latencies_ms": [695.28], "images_per_second": 1.438, "prompt_tokens": 25, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The sandwich is positioned in the foreground, partially obscuring the background. The knife is placed near the sandwich, close to the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [43.96, 43.96, 43.96, 43.96, 41.9, 41.9, 41.9], "power_watts_avg": 43.08, "power_watts_peak": 43.96, "energy_joules_est": 29.98, "sample_count": 7, "duration_seconds": 0.696}, "timestamp": "2026-01-11T13:24:20.078011"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.613, "latencies_ms": [828.613], "images_per_second": 1.207, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A partially eaten sandwich with dark red filling sits on a patterned plate, accompanied by a knife. The setting appears to be a dimly lit dining table with a green napkin.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.9, 41.9, 47.11, 47.11, 47.11, 47.11, 47.11, 43.75, 43.75], "power_watts_avg": 45.21, "power_watts_peak": 47.11, "energy_joules_est": 37.47, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:24:20.988596"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1249.413, "latencies_ms": [1249.413], "images_per_second": 0.8, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The sandwich is primarily light brown in color. The bread appears soft and slightly moist. The sandwich is cut in half, revealing a dark red filling. The plate has a subtle pattern and rests on a green napkin. The lighting is dim, creating a moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.75, 43.75, 43.75, 47.69, 47.69, 47.69, 47.69, 47.69, 42.61, 42.61, 42.61, 42.61, 34.29], "power_watts_avg": 44.19, "power_watts_peak": 47.69, "energy_joules_est": 55.22, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-11T13:24:22.302393"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 780.828, "latencies_ms": [780.828], "images_per_second": 1.281, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The meal includes a variety of colorful and healthy food items, including pasta, vegetables, grapes, and carrots, arranged in four distinct containers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.29, 34.29, 34.29, 34.29, 42.58, 42.58, 42.58, 42.58], "power_watts_avg": 38.43, "power_watts_peak": 42.58, "energy_joules_est": 30.03, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:24:23.113928"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1275.148, "latencies_ms": [1275.148], "images_per_second": 0.784, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Pasta: 2\nGrapes: 6\nCarrots: 2\nQuinoa: 1\nTomato: 1\nBeans: 1\nMeat: 1\nCheese: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.58, 45.49, 45.49, 45.49, 45.49, 45.49, 43.7, 43.7, 43.7, 43.7, 43.7, 41.55, 41.55], "power_watts_avg": 43.97, "power_watts_peak": 45.49, "energy_joules_est": 56.09, "sample_count": 13, "duration_seconds": 1.276}, "timestamp": "2026-01-11T13:24:24.428698"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 935.371, "latencies_ms": [935.371], "images_per_second": 1.069, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main objects are arranged in a visually appealing manner, with the main dish (left) positioned in the foreground and the side dishes (right) in the background. The vegetables are placed near the right side of the main dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [41.55, 41.55, 41.55, 43.57, 43.57, 43.57, 43.57, 43.57, 43.33, 43.33], "power_watts_avg": 42.92, "power_watts_peak": 43.57, "energy_joules_est": 40.16, "sample_count": 10, "duration_seconds": 0.936}, "timestamp": "2026-01-11T13:24:25.441090"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 956.799, "latencies_ms": [956.799], "images_per_second": 1.045, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a colorful bento box meal on a dark surface. The meal includes a variety of food items such as pasta, vegetables, meat, and cheese, arranged in four separate containers.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [43.33, 43.33, 43.33, 42.58, 42.58, 42.58, 42.58, 42.58, 42.61, 42.61], "power_watts_avg": 42.81, "power_watts_peak": 43.33, "energy_joules_est": 40.97, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:24:26.451851"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1055.8, "latencies_ms": [1055.8], "images_per_second": 0.947, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The meal is presented in a vibrant purple lunchbox. The food items are arranged in colorful containers, highlighting the variety of textures and colors. The lighting appears to be soft and warm, enhancing the visual appeal of the meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 43.22, 43.22, 43.22, 43.22, 43.22, 42.87, 42.87, 42.87], "power_watts_avg": 42.96, "power_watts_peak": 43.22, "energy_joules_est": 45.37, "sample_count": 11, "duration_seconds": 1.056}, "timestamp": "2026-01-11T13:24:27.561148"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 683.815, "latencies_ms": [683.815], "images_per_second": 1.462, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A traffic light with red lights illuminated is mounted on a pole above a tree covered in blooming cherry blossoms.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.8, "ram_available_mb": 109444.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 38.64, 38.64, 38.64, 38.64, 38.64], "power_watts_avg": 39.85, "power_watts_peak": 42.87, "energy_joules_est": 27.28, "sample_count": 7, "duration_seconds": 0.685}, "timestamp": "2026-01-11T13:24:28.272931"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 743.273, "latencies_ms": [743.273], "images_per_second": 1.345, "prompt_tokens": 21, "response_tokens_est": 21, "n_tiles": 1, "output_text": "traffic light: 3\ncherry blossoms: 10\ntrees: 10\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.7, 42.7, 42.7, 42.7, 42.7, 47.72, 47.72, 47.72], "power_watts_avg": 44.59, "power_watts_peak": 47.72, "energy_joules_est": 33.15, "sample_count": 8, "duration_seconds": 0.744}, "timestamp": "2026-01-11T13:24:29.082871"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 765.268, "latencies_ms": [765.268], "images_per_second": 1.307, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cherry blossoms are in the foreground, partially obscuring the traffic light. The traffic light is positioned slightly above and to the right of the blossoms.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [47.72, 47.72, 47.59, 47.59, 47.59, 47.59, 47.59, 42.78], "power_watts_avg": 47.03, "power_watts_peak": 47.72, "energy_joules_est": 36.0, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-11T13:24:29.893235"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 960.857, "latencies_ms": [960.857], "images_per_second": 1.041, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a cherry blossom tree in full bloom, with its branches adorned with delicate pink flowers. A traffic light hangs above the tree, displaying a red light, indicating that vehicles must stop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.78, 42.78, 42.78, 42.78, 49.37, 49.37, 49.37, 49.37, 43.21, 43.21], "power_watts_avg": 45.51, "power_watts_peak": 49.37, "energy_joules_est": 43.74, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-11T13:24:30.905238"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 948.934, "latencies_ms": [948.934], "images_per_second": 1.054, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The traffic light is red, indicating a stop. The cherry blossoms are light pink and white, showcasing the vibrant colors of the spring season. The scene appears to be captured during daytime under natural lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.21, 43.21, 43.21, 43.04, 43.04, 43.04, 43.04, 43.04, 43.05, 43.05], "power_watts_avg": 43.1, "power_watts_peak": 43.21, "energy_joules_est": 40.91, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-11T13:24:31.917026"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 827.4, "latencies_ms": [827.4], "images_per_second": 1.209, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A white plate holds a generous serving of saut\u00e9ed broccoli, alongside a piece of grilled salmon, arranged neatly on a white tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 42.5, 42.5, 42.5, 42.5, 42.5, 42.59], "power_watts_avg": 42.69, "power_watts_peak": 43.05, "energy_joules_est": 35.35, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:24:32.830622"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1344.06, "latencies_ms": [1344.06], "images_per_second": 0.744, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "broccoli: 8\nsalmon: 1\ngarlic: 1\nred pepper flakes: 1\nonions: 1\nbutter: 1\ngarlic powder: 1\nsauce: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 42.59, 42.59, 42.5, 42.5, 42.5, 42.5, 42.5, 42.38, 42.38, 42.38, 42.38, 42.38], "power_watts_avg": 42.48, "power_watts_peak": 42.59, "energy_joules_est": 57.11, "sample_count": 14, "duration_seconds": 1.344}, "timestamp": "2026-01-11T13:24:34.245815"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 652.61, "latencies_ms": [652.61], "images_per_second": 1.532, "prompt_tokens": 25, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The broccoli is positioned in the foreground, partially overlapping the plate. The salmon is situated in the background, behind the broccoli.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.45, 33.45, 33.45, 42.87, 42.87], "power_watts_avg": 36.14, "power_watts_peak": 42.87, "energy_joules_est": 23.6, "sample_count": 7, "duration_seconds": 0.653}, "timestamp": "2026-01-11T13:24:34.954486"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1206.391, "latencies_ms": [1206.391], "images_per_second": 0.829, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a meal consisting of a piece of cooked salmon and steamed broccoli on a white plate. The broccoli appears seasoned and cooked, complementing the salmon's rich flavor. The setting suggests a home-cooked meal, possibly a family dinner or special occasion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 42.87, 52.8, 52.8, 52.8, 52.8, 52.8, 43.0, 43.0, 43.0, 43.0, 43.0], "power_watts_avg": 46.74, "power_watts_peak": 52.8, "energy_joules_est": 56.4, "sample_count": 13, "duration_seconds": 1.207}, "timestamp": "2026-01-11T13:24:36.266209"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1166.003, "latencies_ms": [1166.003], "images_per_second": 0.858, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The broccoli appears vibrant green, contrasting with the golden-brown of the salmon. The lighting is soft and warm, enhancing the colors and textures of the food. The broccoli and salmon appear to be cooked together, showcasing a well-balanced and appetizing dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.2, 33.2, 33.2, 33.2, 33.2, 42.13, 42.13, 42.13, 42.13, 42.13, 42.8, 42.8], "power_watts_avg": 38.52, "power_watts_peak": 42.8, "energy_joules_est": 44.93, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-11T13:24:37.478594"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 596.467, "latencies_ms": [596.467], "images_per_second": 1.677, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A young boy is eating something while sitting at a table with two adults in a dimly lit restaurant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.8, 42.8, 42.8, 42.94, 42.94, 42.94], "power_watts_avg": 42.87, "power_watts_peak": 42.94, "energy_joules_est": 25.59, "sample_count": 6, "duration_seconds": 0.597}, "timestamp": "2026-01-11T13:24:38.089787"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1117.763, "latencies_ms": [1117.763], "images_per_second": 0.895, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "woman: 2\nboy: 1\nman: 2\ntable: 2\nnapkin: 1\nfood: 1\nglass: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.94, 42.94, 47.85, 47.85, 47.85, 47.85, 47.85, 44.2, 44.2, 44.2, 44.2, 40.47], "power_watts_avg": 45.2, "power_watts_peak": 47.85, "energy_joules_est": 50.55, "sample_count": 12, "duration_seconds": 1.118}, "timestamp": "2026-01-11T13:24:39.303749"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 735.959, "latencies_ms": [735.959], "images_per_second": 1.359, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The man and woman are seated at a table in the foreground, with the boy seated between them. The background features other diners and a decorative wall.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [40.47, 40.47, 40.47, 40.47, 42.34, 42.34, 42.34, 42.34], "power_watts_avg": 41.4, "power_watts_peak": 42.34, "energy_joules_est": 30.49, "sample_count": 8, "duration_seconds": 0.737}, "timestamp": "2026-01-11T13:24:40.113498"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.202, "latencies_ms": [933.202], "images_per_second": 1.072, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene takes place in a restaurant, where a family is seated at a booth. A young boy is eating something, while a woman appears to be looking at a phone. The atmosphere is casual and relaxed.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [42.34, 44.72, 44.72, 44.72, 44.72, 44.72, 42.92, 42.92, 42.92, 42.92], "power_watts_avg": 43.76, "power_watts_peak": 44.72, "energy_joules_est": 40.86, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:24:41.121283"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1064.524, "latencies_ms": [1064.524], "images_per_second": 0.939, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The lighting in the restaurant is dim, creating a warm ambiance. The walls are painted a reddish-brown color, and the table is covered in white napkins. The scene suggests a casual dining experience in a restaurant setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.7, "ram_available_mb": 109442.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.92, 43.26, 43.26, 43.26, 43.26, 43.26, 42.33, 42.33, 42.33, 42.33, 42.33], "power_watts_avg": 42.81, "power_watts_peak": 43.26, "energy_joules_est": 45.59, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:24:42.234146"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 628.647, "latencies_ms": [628.647], "images_per_second": 1.591, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A yellow bus is driving down a city street, passing by a tall building and several trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.7, "ram_available_mb": 109442.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.7, "ram_available_mb": 109442.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.46, 41.46, 41.46, 41.46, 41.46, 42.64, 42.64], "power_watts_avg": 41.8, "power_watts_peak": 42.64, "energy_joules_est": 26.3, "sample_count": 7, "duration_seconds": 0.629}, "timestamp": "2026-01-11T13:24:42.945642"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1071.566, "latencies_ms": [1071.566], "images_per_second": 0.933, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "building: 10\nbus: 2\ncar: 1\ntrees: 4\nstreetlights: 2\nsidewalk: 2\nbike rack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.7, "ram_available_mb": 109442.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.64, 42.64, 42.64, 52.09, 52.09, 52.09, 52.09, 52.09, 42.61, 42.61, 42.61], "power_watts_avg": 46.92, "power_watts_peak": 52.09, "energy_joules_est": 50.31, "sample_count": 11, "duration_seconds": 1.072}, "timestamp": "2026-01-11T13:24:44.057868"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 970.278, "latencies_ms": [970.278], "images_per_second": 1.031, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The foreground features a yellow bus parked near a sidewalk, positioned to the right of the street. The background showcases a modern building with multiple windows, situated behind the bus and further away on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 39.57, 39.57, 39.57, 39.57, 39.57, 43.17, 43.17, 43.17], "power_watts_avg": 41.26, "power_watts_peak": 43.17, "energy_joules_est": 40.06, "sample_count": 10, "duration_seconds": 0.971}, "timestamp": "2026-01-11T13:24:45.069745"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 942.763, "latencies_ms": [942.763], "images_per_second": 1.061, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a city street with a yellow bus, a white bus, and a van parked near a modern building. The setting appears to be urban, with trees lining the street and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 43.34, 43.34, 43.34, 43.34, 43.34, 43.17, 43.17, 43.17], "power_watts_avg": 43.26, "power_watts_peak": 43.34, "energy_joules_est": 40.81, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-11T13:24:46.082565"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 872.992, "latencies_ms": [872.992], "images_per_second": 1.145, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The building is primarily gray and has a modern architectural style. The street is paved with asphalt and features streetlights. The scene is well-lit, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 42.1, 42.1, 42.1, 42.1, 42.1, 42.66, 42.66], "power_watts_avg": 42.46, "power_watts_peak": 43.17, "energy_joules_est": 37.09, "sample_count": 9, "duration_seconds": 0.874}, "timestamp": "2026-01-11T13:24:46.993277"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 616.182, "latencies_ms": [616.182], "images_per_second": 1.623, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A stop sign is mounted on a metal pole at the corner of a street, with a bus visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 33.0}, "power_stats": {"power_watts_samples": [42.66, 42.66, 42.66, 48.48, 48.48, 48.48, 48.48], "power_watts_avg": 45.99, "power_watts_peak": 48.48, "energy_joules_est": 28.37, "sample_count": 7, "duration_seconds": 0.617}, "timestamp": "2026-01-11T13:24:47.705281"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1242.807, "latencies_ms": [1242.807], "images_per_second": 0.805, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "stop sign: 1\npole: 1\nbus: 1\nbuildings: 2\ncars: 1\nbus stop sign: 1\nmetal railing: 1\ngrass: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.76, 41.76, 41.76, 41.76, 41.76, 43.48, 43.48, 43.48, 43.48, 43.48, 43.7, 43.7, 43.7], "power_watts_avg": 42.87, "power_watts_peak": 43.7, "energy_joules_est": 53.3, "sample_count": 13, "duration_seconds": 1.243}, "timestamp": "2026-01-11T13:24:49.019810"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1139.263, "latencies_ms": [1139.263], "images_per_second": 0.878, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The stop sign is positioned in the foreground, slightly to the left of the image. The background features a street scene with a bus and buildings, suggesting an urban setting. The stop sign is situated near the center of the image, drawing the viewer's attention to its presence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.7, 43.7, 40.73, 40.73, 40.73, 40.73, 40.73, 42.69, 42.69, 42.69, 42.69, 42.69], "power_watts_avg": 42.04, "power_watts_peak": 43.7, "energy_joules_est": 47.91, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-11T13:24:50.233702"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 870.166, "latencies_ms": [870.166], "images_per_second": 1.149, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene is set in an urban area, with a stop sign prominently displayed in the foreground. The sun is shining brightly, casting a warm glow on the street and buildings, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.06, 35.06, 35.06, 35.06, 35.06, 42.64, 42.64, 42.64, 42.64], "power_watts_avg": 38.43, "power_watts_peak": 42.64, "energy_joules_est": 33.46, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:24:51.146123"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 883.454, "latencies_ms": [883.454], "images_per_second": 1.132, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The stop sign is red and white. The lighting suggests it might be near sunset or sunrise, creating a warm, golden glow. The stop sign appears to be made of metal and has a weathered appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.64, 44.43, 44.43, 44.43, 44.43, 44.43, 43.56, 43.56, 43.56], "power_watts_avg": 43.94, "power_watts_peak": 44.43, "energy_joules_est": 38.84, "sample_count": 9, "duration_seconds": 0.884}, "timestamp": "2026-01-11T13:24:52.057690"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 703.364, "latencies_ms": [703.364], "images_per_second": 1.422, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A white and brown cat with green eyes lies on a black surface, gazing at the camera with its paws stretched out.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 49.46, 49.46, 49.46, 49.46, 49.46], "power_watts_avg": 47.77, "power_watts_peak": 49.46, "energy_joules_est": 33.63, "sample_count": 7, "duration_seconds": 0.704}, "timestamp": "2026-01-11T13:24:52.769118"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1060.11, "latencies_ms": [1060.11], "images_per_second": 0.943, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cat: 2\nmouse: 1\ncord: 1\ncouch: 1\npaw: 2\nfur: 2\neyes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.48, 43.48, 43.48, 48.73, 48.73, 48.73, 48.73, 48.73, 44.23], "power_watts_avg": 45.93, "power_watts_peak": 48.73, "energy_joules_est": 48.72, "sample_count": 11, "duration_seconds": 1.061}, "timestamp": "2026-01-11T13:24:53.880945"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 842.27, "latencies_ms": [842.27], "images_per_second": 1.187, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, slightly to the right of the mouse. The mouse is located near the cat, closer to the viewer's perspective. The background is dark and out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.1, "ram_available_mb": 109442.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.23, 44.23, 44.23, 44.23, 43.49, 43.49, 43.49, 43.49, 43.49], "power_watts_avg": 43.82, "power_watts_peak": 44.23, "energy_joules_est": 36.93, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:24:54.792971"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 833.063, "latencies_ms": [833.063], "images_per_second": 1.2, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A brown and white cat with bright green eyes is lying on a dark surface, seemingly playing with a computer mouse. The scene takes place in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13064.1, "ram_available_mb": 109442.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 43.46, 43.46, 43.46, 42.8, 42.8, 42.8, 42.8], "power_watts_avg": 43.17, "power_watts_peak": 43.46, "energy_joules_est": 35.99, "sample_count": 9, "duration_seconds": 0.834}, "timestamp": "2026-01-11T13:24:55.704245"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 904.594, "latencies_ms": [904.594], "images_per_second": 1.105, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The cat has striking green eyes and a coat of brown and white fur. The lighting is dim, creating a moody atmosphere. A beige computer mouse lies nearby on the dark surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 45.0}, "power_stats": {"power_watts_samples": [41.39, 41.39, 41.39, 41.39, 41.39, 42.42, 42.42, 42.42, 42.42], "power_watts_avg": 41.85, "power_watts_peak": 42.42, "energy_joules_est": 37.87, "sample_count": 9, "duration_seconds": 0.905}, "timestamp": "2026-01-11T13:24:56.615399"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 745.005, "latencies_ms": [745.005], "images_per_second": 1.342, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A bustling city bus depot, filled with various colored buses, is situated amidst a cityscape with tall buildings and power lines overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.42, 46.94, 46.94, 46.94, 46.94, 46.94, 43.95, 43.95], "power_watts_avg": 45.62, "power_watts_peak": 46.94, "energy_joules_est": 34.02, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-11T13:24:57.426774"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 963.851, "latencies_ms": [963.851], "images_per_second": 1.038, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "bus: 5\nbuses: 6\ntram: 1\nhighway: 2\nbuildings: 8\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 50.98, 50.98, 50.98, 50.98, 50.98, 42.82, 42.82], "power_watts_avg": 47.24, "power_watts_peak": 50.98, "energy_joules_est": 45.55, "sample_count": 10, "duration_seconds": 0.964}, "timestamp": "2026-01-11T13:24:58.438463"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1433.656, "latencies_ms": [1433.656], "images_per_second": 0.698, "prompt_tokens": 25, "response_tokens_est": 69, "n_tiles": 1, "output_text": "The main objects in the image are positioned in a spatial arrangement that suggests a city or urban setting. The foreground features the buses and roadway, while the background showcases a cityscape with buildings, power lines, and possibly a tower in the distance. The buses are situated near the foreground, implying they are part of the transportation system within the city.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.89, 42.89, 42.89, 42.89, 42.89, 42.83, 42.83, 42.83, 42.83, 42.83, 33.44, 33.44], "power_watts_avg": 41.6, "power_watts_peak": 42.89, "energy_joules_est": 59.66, "sample_count": 15, "duration_seconds": 1.434}, "timestamp": "2026-01-11T13:24:59.950427"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 935.181, "latencies_ms": [935.181], "images_per_second": 1.069, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a busy city bus station with multiple buses parked and moving around. The setting includes tall buildings, power lines, and a clear blue sky, indicating a daytime urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.44, 33.44, 33.44, 42.4, 42.4, 42.4, 42.4, 42.4, 42.17, 42.17], "power_watts_avg": 39.66, "power_watts_peak": 42.4, "energy_joules_est": 37.11, "sample_count": 10, "duration_seconds": 0.936}, "timestamp": "2026-01-11T13:25:00.960606"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1172.734, "latencies_ms": [1172.734], "images_per_second": 0.853, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The sky is partly cloudy with blue and white clouds. The lighting appears to be natural daylight, creating a bright and airy atmosphere. The buildings in the background are primarily white and gray, contributing to the urban setting. The overall scene suggests a bustling city environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.17, 42.17, 42.17, 42.44, 42.44, 42.44, 42.44, 42.44, 42.19, 42.19, 42.19, 42.19], "power_watts_avg": 42.29, "power_watts_peak": 42.44, "energy_joules_est": 49.6, "sample_count": 12, "duration_seconds": 1.173}, "timestamp": "2026-01-11T13:25:02.169466"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 730.927, "latencies_ms": [730.927], "images_per_second": 1.368, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A shirtless man wearing a straw hat is skillfully riding a skateboard up a ramp in a desert-like environment.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.19, 33.86, 33.86, 33.86, 33.86, 33.86, 43.14, 43.14], "power_watts_avg": 37.22, "power_watts_peak": 43.14, "energy_joules_est": 27.22, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:25:02.981915"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1339.252, "latencies_ms": [1339.252], "images_per_second": 0.747, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Skateboard: 1\nHat: 1\nShorts: 1\nSkateboard: 1\nRamp: 1\nGround: 1\nTent: 2\nBicycle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 43.14, 51.01, 51.01, 51.01, 51.01, 51.01, 42.1, 42.1, 42.1, 42.1, 42.1, 34.83], "power_watts_avg": 44.99, "power_watts_peak": 51.01, "energy_joules_est": 60.26, "sample_count": 14, "duration_seconds": 1.34}, "timestamp": "2026-01-11T13:25:04.393609"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1169.778, "latencies_ms": [1169.778], "images_per_second": 0.855, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a ramp. The background features large tents, suggesting an outdoor event or gathering. The skateboarder's shadow is cast on the ground, indicating a relatively low sun angle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 34.83, 42.24, 42.24, 42.24, 42.24, 42.24, 42.05, 42.05, 42.05], "power_watts_avg": 39.72, "power_watts_peak": 42.24, "energy_joules_est": 46.48, "sample_count": 12, "duration_seconds": 1.17}, "timestamp": "2026-01-11T13:25:05.601920"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 900.691, "latencies_ms": [900.691], "images_per_second": 1.11, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The scene depicts a skateboarder performing a trick on a ramp in a desert-like environment. The backdrop features large tents, suggesting an outdoor event or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [42.05, 42.05, 36.92, 36.92, 36.92, 36.92, 36.92, 42.95, 42.95], "power_watts_avg": 39.4, "power_watts_peak": 42.95, "energy_joules_est": 35.5, "sample_count": 9, "duration_seconds": 0.901}, "timestamp": "2026-01-11T13:25:06.512247"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1149.411, "latencies_ms": [1149.411], "images_per_second": 0.87, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skateboarder is wearing light brown shorts and a straw hat. The scene appears to be outdoors in bright sunlight. The skateboard is red and white. The background includes large green fabric structures, suggesting an outdoor event or festival.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.2, "ram_available_mb": 109444.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.95, 42.95, 48.47, 48.47, 48.47, 48.47, 48.47, 43.37, 43.37, 43.37, 43.37, 43.37], "power_watts_avg": 45.42, "power_watts_peak": 48.47, "energy_joules_est": 52.24, "sample_count": 12, "duration_seconds": 1.15}, "timestamp": "2026-01-11T13:25:07.723248"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 507.034, "latencies_ms": [507.034], "images_per_second": 1.972, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is windsurfing in the ocean, surrounded by several colorful kites flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [35.68, 35.68, 35.68, 35.68, 35.68, 37.24], "power_watts_avg": 35.94, "power_watts_peak": 37.24, "energy_joules_est": 18.25, "sample_count": 6, "duration_seconds": 0.508}, "timestamp": "2026-01-11T13:25:08.332478"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1197.793, "latencies_ms": [1197.793], "images_per_second": 0.835, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "kite: 5\nwindsurfboard: 1\nkite: 2\nkite: 1\nkite: 1\nkite: 1\nkite: 1\nkite: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.24, 37.24, 37.24, 37.24, 41.19, 41.19, 41.19, 41.19, 41.19, 36.89, 36.89, 36.89], "power_watts_avg": 38.8, "power_watts_peak": 41.19, "energy_joules_est": 46.49, "sample_count": 12, "duration_seconds": 1.198}, "timestamp": "2026-01-11T13:25:09.543451"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 655.763, "latencies_ms": [655.763], "images_per_second": 1.525, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The windsurfer is positioned in the foreground, close to the water's edge. The kites are located in the background, further out from the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [36.89, 36.89, 38.38, 38.38, 38.38, 38.38, 38.38], "power_watts_avg": 37.95, "power_watts_peak": 38.38, "energy_joules_est": 24.91, "sample_count": 7, "duration_seconds": 0.656}, "timestamp": "2026-01-11T13:25:10.253276"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 808.858, "latencies_ms": [808.858], "images_per_second": 1.236, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a windsurfer preparing to enter the ocean, alongside several other kite surfers. The setting is a sunny beach with waves crashing against the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.37, 38.37, 38.37, 38.37, 38.37, 37.16, 37.16, 37.16, 37.16], "power_watts_avg": 37.83, "power_watts_peak": 38.37, "energy_joules_est": 30.62, "sample_count": 9, "duration_seconds": 0.809}, "timestamp": "2026-01-11T13:25:11.163736"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 749.414, "latencies_ms": [749.414], "images_per_second": 1.334, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The windsurfing equipment is primarily white and blue. The sky is bright blue with a few scattered clouds. The ocean appears dark blue with white waves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.16, 36.7, 36.7, 36.7, 36.7, 36.7, 36.36, 36.36], "power_watts_avg": 36.67, "power_watts_peak": 37.16, "energy_joules_est": 27.5, "sample_count": 8, "duration_seconds": 0.75}, "timestamp": "2026-01-11T13:25:11.970194"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 717.438, "latencies_ms": [717.438], "images_per_second": 1.394, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "An old, rusted fire hydrant with black caps stands on a lush green lawn, partially obscured by dandelions.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.36, 36.36, 36.36, 46.29, 46.29, 46.29, 46.29, 46.29], "power_watts_avg": 42.57, "power_watts_peak": 46.29, "energy_joules_est": 30.56, "sample_count": 8, "duration_seconds": 0.718}, "timestamp": "2026-01-11T13:25:12.781590"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 957.501, "latencies_ms": [957.501], "images_per_second": 1.044, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "fire hydrant: 1\nhouse: 1\ntrees: 1\nflowers: 2\ngrass: 4\ndandelions: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.85, 42.85, 42.85, 42.43, 42.43, 42.43, 42.43, 42.43], "power_watts_avg": 42.64, "power_watts_peak": 42.85, "energy_joules_est": 40.84, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-11T13:25:13.791468"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 829.536, "latencies_ms": [829.536], "images_per_second": 1.205, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The red fire hydrant is positioned in the foreground, slightly to the right of the viewer. The house and trees in the background are further back, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 42.59, 42.59, 42.59, 43.26, 43.26, 43.26, 43.26], "power_watts_avg": 42.89, "power_watts_peak": 43.26, "energy_joules_est": 35.6, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-11T13:25:14.700199"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1109.578, "latencies_ms": [1109.578], "images_per_second": 0.901, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene is set in a residential area with a vibrant red fire hydrant in the foreground, situated on a grassy lawn. Behind the hydrant, a white house with purple flowers is partially visible, enhancing the peaceful and picturesque atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.26, 41.73, 41.73, 41.73, 41.73, 41.73, 42.57, 42.57, 42.57, 42.57, 42.57, 44.0], "power_watts_avg": 42.4, "power_watts_peak": 44.0, "energy_joules_est": 47.06, "sample_count": 12, "duration_seconds": 1.11}, "timestamp": "2026-01-11T13:25:15.911069"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 763.428, "latencies_ms": [763.428], "images_per_second": 1.31, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The fire hydrant is predominantly red with black accents. The lighting suggests a sunny day, and the materials appear to be metal and painted paint.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.4, "ram_available_mb": 109443.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.0, 44.0, 44.0, 42.23, 42.23, 42.23, 42.23, 42.23], "power_watts_avg": 42.9, "power_watts_peak": 44.0, "energy_joules_est": 32.77, "sample_count": 8, "duration_seconds": 0.764}, "timestamp": "2026-01-11T13:25:16.719801"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 791.324, "latencies_ms": [791.324], "images_per_second": 1.264, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A small bird with black and brown feathers is captured in mid-flight, approaching a wooden structure where several other birds are perched.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.4, "ram_available_mb": 109443.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.71, 41.71, 41.71, 41.71, 41.71, 42.88, 42.88, 42.88], "power_watts_avg": 42.15, "power_watts_peak": 42.88, "energy_joules_est": 33.38, "sample_count": 8, "duration_seconds": 0.792}, "timestamp": "2026-01-11T13:25:17.531208"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 927.319, "latencies_ms": [927.319], "images_per_second": 1.078, "prompt_tokens": 21, "response_tokens_est": 25, "n_tiles": 1, "output_text": "bird: 3\nroof: 2\nwood: 2\nbuilding: 1\nleaf: 1\ntwig: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 50.91, 50.91, 50.91, 50.91, 50.91, 43.41, 43.41, 43.41], "power_watts_avg": 47.06, "power_watts_peak": 50.91, "energy_joules_est": 43.66, "sample_count": 10, "duration_seconds": 0.928}, "timestamp": "2026-01-11T13:25:18.541139"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 987.413, "latencies_ms": [987.413], "images_per_second": 1.013, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main object, a bird, is positioned in the foreground, close to the viewer. The background features the blue wooden surface, which extends into the distance. The bird is relatively close to the viewer, suggesting it is close to the viewer as well.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.41, 43.41, 42.63, 42.63, 42.63, 42.63, 42.63, 42.29, 42.29, 42.29], "power_watts_avg": 42.68, "power_watts_peak": 43.41, "energy_joules_est": 42.16, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-11T13:25:19.551554"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1138.546, "latencies_ms": [1138.546], "images_per_second": 0.878, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A bird is captured in mid-flight, seemingly preparing to land on a weathered wooden surface. Several other birds are perched nearby, possibly observing the incoming creature. The scene is set outdoors, with a blue wooden wall or roof providing the backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.29, 42.29, 43.11, 43.11, 43.11, 43.11, 43.11, 43.48, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 43.13, "power_watts_peak": 43.48, "energy_joules_est": 49.13, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-11T13:25:20.766479"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 813.612, "latencies_ms": [813.612], "images_per_second": 1.229, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The building's exterior is painted in a faded teal color. The lighting suggests an overcast day, giving the image a soft, diffused quality.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13062.7, "ram_available_mb": 109443.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.82, 37.82, 37.82, 37.82, 37.82, 42.88, 42.88, 42.88, 42.88], "power_watts_avg": 40.07, "power_watts_peak": 42.88, "energy_joules_est": 32.62, "sample_count": 9, "duration_seconds": 0.814}, "timestamp": "2026-01-11T13:25:21.678010"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 721.61, "latencies_ms": [721.61], "images_per_second": 1.386, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman in blue jeans is leading a brown horse with a saddle in a rustic barn, guiding it with its front legs extended.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.7, "ram_available_mb": 109443.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 7.0}, "power_stats": {"power_watts_samples": [42.88, 40.74, 40.74, 40.74, 40.74, 40.74, 42.24, 42.24], "power_watts_avg": 41.38, "power_watts_peak": 42.88, "energy_joules_est": 29.89, "sample_count": 8, "duration_seconds": 0.722}, "timestamp": "2026-01-11T13:25:22.489624"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1171.971, "latencies_ms": [1171.971], "images_per_second": 0.853, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "door: 1\nladder: 1\nhorse: 1\nwoman: 1\ntable: 1\nbucket: 1\nchair: 1\nwheelbarrow: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.24, 42.24, 42.24, 52.16, 52.16, 52.16, 52.16, 52.16, 42.56, 42.56, 42.56, 42.56], "power_watts_avg": 46.48, "power_watts_peak": 52.16, "energy_joules_est": 54.5, "sample_count": 12, "duration_seconds": 1.173}, "timestamp": "2026-01-11T13:25:23.702920"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 742.547, "latencies_ms": [742.547], "images_per_second": 1.347, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The horse is positioned in the foreground, moving towards the left side of the image. The woman is standing near the horse, seemingly observing or guiding it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [42.56, 35.17, 35.17, 35.17, 35.17, 35.17, 43.38, 43.38], "power_watts_avg": 38.14, "power_watts_peak": 43.38, "energy_joules_est": 28.34, "sample_count": 8, "duration_seconds": 0.743}, "timestamp": "2026-01-11T13:25:24.513230"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 998.89, "latencies_ms": [998.89], "images_per_second": 1.001, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A woman is leading a brown horse in a rustic barn. The horse is wearing a saddle and appears to be in motion, moving towards the woman. The barn has a wooden interior, with various items and equipment scattered around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 51.46, 51.46, 51.46, 51.46, 51.46, 42.75, 42.75, 42.75], "power_watts_avg": 47.23, "power_watts_peak": 51.46, "energy_joules_est": 47.21, "sample_count": 10, "duration_seconds": 0.999}, "timestamp": "2026-01-11T13:25:25.525284"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 871.729, "latencies_ms": [871.729], "images_per_second": 1.147, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The horse is brown and white. The lighting is natural, likely from sunlight entering through the open door. The barn's interior is constructed of wood and has a dirt floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.75, 42.75, 44.27, 44.27, 44.27, 44.27, 44.27, 43.99, 43.99], "power_watts_avg": 43.87, "power_watts_peak": 44.27, "energy_joules_est": 38.27, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-11T13:25:26.436860"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 660.66, "latencies_ms": [660.66], "images_per_second": 1.514, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A group of zebras and rhinoceroses are grazing peacefully in a lush, green field enclosed by a wooden fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.99, 43.99, 43.99, 45.98, 45.98, 45.98, 45.98], "power_watts_avg": 45.13, "power_watts_peak": 45.98, "energy_joules_est": 29.84, "sample_count": 7, "duration_seconds": 0.661}, "timestamp": "2026-01-11T13:25:27.148034"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1111.897, "latencies_ms": [1111.897], "images_per_second": 0.899, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "rhino: 2\nzebra: 2\nhorse: 1\nwildebeest: 3\ntree: 1\nrocks: 2\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.98, 44.24, 44.24, 44.24, 44.24, 44.24, 43.39, 43.39, 43.39, 43.39, 43.39, 42.62], "power_watts_avg": 43.89, "power_watts_peak": 45.98, "energy_joules_est": 48.83, "sample_count": 12, "duration_seconds": 1.112}, "timestamp": "2026-01-11T13:25:28.361264"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1009.656, "latencies_ms": [1009.656], "images_per_second": 0.99, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The rhinoceros is positioned to the left of the zebra, occupying the foreground. The zebra is situated near the center, slightly to the right of the rhinoceros. The background features trees and a partially visible body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [42.62, 42.62, 42.62, 42.62, 42.19, 42.19, 42.19, 42.19, 42.19, 42.05, 42.05], "power_watts_avg": 42.32, "power_watts_peak": 42.62, "energy_joules_est": 42.74, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-11T13:25:29.474277"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1097.881, "latencies_ms": [1097.881], "images_per_second": 0.911, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a grassy field with various animals, including zebras, rhinos, and possibly other wildlife. The animals are grazing and roaming freely within the enclosure, which is surrounded by a naturalistic setting with trees and a small body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.05, 42.05, 42.05, 41.94, 41.94, 41.94, 41.94, 41.94, 42.06, 42.06, 42.06], "power_watts_avg": 42.0, "power_watts_peak": 42.06, "energy_joules_est": 46.14, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-11T13:25:30.588593"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1179.43, "latencies_ms": [1179.43], "images_per_second": 0.848, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The grass is a vibrant green, illuminated by sunlight, creating a bright and lively atmosphere. The sky is partly cloudy, casting a soft, diffused light over the scene. The overall setting suggests a naturalistic enclosure, possibly within a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.06, 42.06, 38.47, 38.47, 38.47, 38.47, 38.47, 44.05, 44.05, 44.05, 44.05, 44.05], "power_watts_avg": 41.39, "power_watts_peak": 44.05, "energy_joules_est": 48.84, "sample_count": 12, "duration_seconds": 1.18}, "timestamp": "2026-01-11T13:25:31.802246"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 773.422, "latencies_ms": [773.422], "images_per_second": 1.293, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A horse-drawn trolley car, decorated with green and gold accents, travels down a street lined with trees and people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.36, 40.36, 40.36, 40.36, 40.36, 43.45, 43.45, 43.45], "power_watts_avg": 41.52, "power_watts_peak": 43.45, "energy_joules_est": 32.14, "sample_count": 8, "duration_seconds": 0.774}, "timestamp": "2026-01-11T13:25:32.614760"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1178.03, "latencies_ms": [1178.03], "images_per_second": 0.849, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "horse: 1\ncarriage: 1\nperson: 2\nbench: 1\ntree: 1\nstreet: 1\numbrella: 1\npeople: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.45, 46.38, 46.38, 46.38, 46.38, 46.38, 43.36, 43.36, 43.36, 43.36, 43.36, 41.55], "power_watts_avg": 44.48, "power_watts_peak": 46.38, "energy_joules_est": 52.42, "sample_count": 12, "duration_seconds": 1.179}, "timestamp": "2026-01-11T13:25:33.825777"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1410.362, "latencies_ms": [1410.362], "images_per_second": 0.709, "prompt_tokens": 25, "response_tokens_est": 74, "n_tiles": 1, "output_text": "The main object is a trolley car moving down the street, positioned in the foreground and slightly to the left of the horse and carriage. The trolley car is closer to the viewer, while the horse and carriage are further away in the background. The trolley car appears to be traveling on a paved road, while the horse and carriage are situated on a sidewalk.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.55, 41.55, 41.55, 41.55, 43.43, 43.43, 43.43, 43.43, 43.43, 43.52, 43.52, 43.52, 43.52, 43.52], "power_watts_avg": 42.93, "power_watts_peak": 43.52, "energy_joules_est": 60.56, "sample_count": 14, "duration_seconds": 1.411}, "timestamp": "2026-01-11T13:25:35.241941"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 922.707, "latencies_ms": [922.707], "images_per_second": 1.084, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene depicts a horse-drawn carriage traveling down a street, possibly at a theme park or fair. The carriage is decorated and carries passengers, blending traditional transportation with modern attractions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.01, 34.01, 34.01, 34.01, 34.01, 44.37, 44.37, 44.37, 44.37, 44.37], "power_watts_avg": 39.19, "power_watts_peak": 44.37, "energy_joules_est": 36.17, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-11T13:25:36.255199"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1062.599, "latencies_ms": [1062.599], "images_per_second": 0.941, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The trolley is painted in vibrant colors, including red, green, and gold. The lighting is bright, likely from sunlight, creating a pleasant atmosphere. The trolley appears to be made of sturdy materials like wood and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 43.6, 43.6, 42.41, 42.41, 42.41, 42.41, 42.41, 42.69], "power_watts_avg": 42.97, "power_watts_peak": 43.6, "energy_joules_est": 45.69, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:25:37.365747"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 421.413, "latencies_ms": [421.413], "images_per_second": 2.373, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A man wearing glasses is reading a newspaper while sitting on a green park bench.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.69, 42.69, 42.69, 42.69, 37.53], "power_watts_avg": 41.66, "power_watts_peak": 42.69, "energy_joules_est": 17.57, "sample_count": 5, "duration_seconds": 0.422}, "timestamp": "2026-01-11T13:25:37.874791"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1425.148, "latencies_ms": [1425.148], "images_per_second": 0.702, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "Bench: 4\nTrash can: 3\nNewspaper: 1\nMan: 2\nMan in red shirt: 1\nMan in blue shirt: 1\nMan in brown shirt: 1\nBuilding: 1\nStairs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.53, 37.53, 37.53, 37.53, 40.84, 40.84, 40.84, 40.84, 40.84, 36.88, 36.88, 36.88, 36.88, 36.88, 33.53], "power_watts_avg": 38.15, "power_watts_peak": 40.84, "energy_joules_est": 54.39, "sample_count": 15, "duration_seconds": 1.426}, "timestamp": "2026-01-11T13:25:39.390431"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1074.683, "latencies_ms": [1074.683], "images_per_second": 0.931, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a line or row, creating a sense of proximity and order. The foreground features the man reading, while other individuals are further back, occupying the background. The setting appears to be outdoors, possibly in a public space like a sidewalk or plaza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.53, 33.53, 33.53, 33.53, 36.72, 36.72, 36.72, 36.72, 36.72, 36.77, 36.77], "power_watts_avg": 35.57, "power_watts_peak": 36.77, "energy_joules_est": 38.25, "sample_count": 11, "duration_seconds": 1.075}, "timestamp": "2026-01-11T13:25:40.501111"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 914.29, "latencies_ms": [914.29], "images_per_second": 1.094, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene takes place on a sidewalk in front of a building with several people sitting on benches, reading newspapers and engaging in conversation. The setting suggests a public space, possibly a shopping district or a popular tourist area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [36.77, 36.77, 36.77, 37.84, 37.84, 37.84, 37.84, 37.84, 38.0, 38.0], "power_watts_avg": 37.55, "power_watts_peak": 38.0, "energy_joules_est": 34.35, "sample_count": 10, "duration_seconds": 0.915}, "timestamp": "2026-01-11T13:25:41.511977"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 766.977, "latencies_ms": [766.977], "images_per_second": 1.304, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The chairs are dark green, and the floor appears to be paved with light-colored stone or concrete. The lighting suggests it's daytime, and the overall atmosphere is calm and quiet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [38.0, 38.0, 36.39, 36.39, 36.39, 36.39, 36.39, 36.2], "power_watts_avg": 36.77, "power_watts_peak": 38.0, "energy_joules_est": 28.22, "sample_count": 8, "duration_seconds": 0.767}, "timestamp": "2026-01-11T13:25:42.322405"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 768.387, "latencies_ms": [768.387], "images_per_second": 1.301, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A wooden desk with a laptop, phone, lamp, and glass of orange juice is situated against a white wall, accompanied by a painting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.2, 36.2, 36.2, 36.2, 42.7, 42.7, 42.7, 42.7], "power_watts_avg": 39.45, "power_watts_peak": 42.7, "energy_joules_est": 30.33, "sample_count": 8, "duration_seconds": 0.769}, "timestamp": "2026-01-11T13:25:43.132280"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1392.997, "latencies_ms": [1392.997], "images_per_second": 0.718, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "laptop: 1\ntelephone: 1\ndesk: 1\nlamp: 1\nglass: 1\npicture frame: 1\npapers: 1\ncup: 1\ntray: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.7, 44.47, 44.47, 44.47, 44.47, 44.47, 42.93, 42.93, 42.93, 42.93, 42.93, 42.33, 42.33, 42.33], "power_watts_avg": 43.34, "power_watts_peak": 44.47, "energy_joules_est": 60.39, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-11T13:25:44.543857"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 998.073, "latencies_ms": [998.073], "images_per_second": 1.002, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The laptop is positioned in the foreground, slightly to the left of the image. The desk is situated in the background, extending from the left edge to the right edge of the image. The picture hangs on the wall behind the desk, providing a backdrop for the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.33, 42.33, 40.47, 40.47, 40.47, 40.47, 40.47, 43.61, 43.61, 43.61], "power_watts_avg": 41.79, "power_watts_peak": 43.61, "energy_joules_est": 41.74, "sample_count": 10, "duration_seconds": 0.999}, "timestamp": "2026-01-11T13:25:45.557806"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1179.736, "latencies_ms": [1179.736], "images_per_second": 0.848, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The scene depicts a home office setup with a wooden desk, a laptop, a telephone, a lamp, a glass of orange juice, and a picture on the wall. The desk is positioned against a wall, illuminated by the lamp and the orange juice, creating a cozy and functional workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.61, 43.61, 44.28, 44.28, 44.28, 44.28, 44.28, 44.06, 44.06, 44.06, 44.06, 44.06], "power_watts_avg": 44.08, "power_watts_peak": 44.28, "energy_joules_est": 52.02, "sample_count": 12, "duration_seconds": 1.18}, "timestamp": "2026-01-11T13:25:46.771054"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1130.066, "latencies_ms": [1130.066], "images_per_second": 0.885, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The room is lit by warm yellow light from a lamp with a black shade. The desk is made of dark wood and has a laptop, papers, a glass, and a telephone on it. The walls are painted a light color, and the overall atmosphere is cozy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.63, 37.63, 37.63, 37.63, 37.63, 43.56, 43.56, 43.56, 43.56, 43.56, 43.78, 43.78], "power_watts_avg": 41.13, "power_watts_peak": 43.78, "energy_joules_est": 46.49, "sample_count": 12, "duration_seconds": 1.13}, "timestamp": "2026-01-11T13:25:47.985535"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 828.297, "latencies_ms": [828.297], "images_per_second": 1.207, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two surfboards lean against the sand near a beach umbrella, accompanied by beach chairs, towels, and a cooler, with people enjoying the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 42.55, 42.55, 42.55, 42.55, 42.55, 43.56], "power_watts_avg": 43.07, "power_watts_peak": 43.78, "energy_joules_est": 35.7, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:25:48.898004"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1326.48, "latencies_ms": [1326.48], "images_per_second": 0.754, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "beach towel: 2\nsurfboard: 2\numbrella: 1\nchair: 2\ncooler: 1\nbags: 2\nsandals: 1\nfrisbee: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 43.56, 43.56, 43.93, 43.93, 43.93, 43.93, 43.93, 43.61, 43.61, 43.61, 43.61, 43.61], "power_watts_avg": 43.71, "power_watts_peak": 43.93, "energy_joules_est": 58.0, "sample_count": 14, "duration_seconds": 1.327}, "timestamp": "2026-01-11T13:25:50.311714"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1026.809, "latencies_ms": [1026.809], "images_per_second": 0.974, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The foreground features the beach setup with towels, surfboards, and a cooler, positioned near the water's edge. The background showcases the ocean with waves and a clear sky, extending to the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.1, "ram_available_mb": 109442.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.54, 33.54, 33.54, 33.54, 43.72, 43.72, 43.72, 43.72, 43.72, 43.42, 43.42], "power_watts_avg": 39.96, "power_watts_peak": 43.72, "energy_joules_est": 41.05, "sample_count": 11, "duration_seconds": 1.027}, "timestamp": "2026-01-11T13:25:51.424187"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1212.97, "latencies_ms": [1212.97], "images_per_second": 0.824, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene is set on a sandy beach with clear skies and calm ocean waves. A green umbrella provides shade, while two surfboards rest on the sand, indicating recent surfing activity. Beach chairs and towels are also present, suggesting a relaxing day at the beach.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13064.1, "ram_available_mb": 109442.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [43.42, 43.42, 43.42, 43.75, 43.75, 43.75, 43.75, 43.75, 43.78, 43.78, 43.78, 43.78, 43.78], "power_watts_avg": 43.68, "power_watts_peak": 43.78, "energy_joules_est": 53.01, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-11T13:25:52.738937"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1308.858, "latencies_ms": [1308.858], "images_per_second": 0.764, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The beach scene features a sunny day with clear blue skies and bright sunlight. The sand is a light beige color, complementing the blue and white striped beach towel and surfboards. The beach setup includes beach chairs, a green umbrella, and several bags, suggesting an organized and relaxing atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.07, 32.07, 32.07, 32.07, 32.07, 43.17, 43.17, 43.17, 43.17, 43.17, 44.75, 44.75, 44.75], "power_watts_avg": 39.26, "power_watts_peak": 44.75, "energy_joules_est": 51.4, "sample_count": 13, "duration_seconds": 1.309}, "timestamp": "2026-01-11T13:25:54.052687"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 640.935, "latencies_ms": [640.935], "images_per_second": 1.56, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A white sheep with black markings on its face and legs stands confidently atop a large, rugged rock formation, gazing towards the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.75, 44.75, 37.76, 37.76, 37.76, 37.76, 37.76], "power_watts_avg": 39.76, "power_watts_peak": 44.75, "energy_joules_est": 25.5, "sample_count": 7, "duration_seconds": 0.641}, "timestamp": "2026-01-11T13:25:54.762803"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 997.25, "latencies_ms": [997.25], "images_per_second": 1.003, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "rock: 10\nsheep: 1\nsky: 10\nclouds: 10\ngrass: 10\nhills: 1\nstaircase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.52, 37.52, 37.52, 37.52, 37.52, 37.02, 37.02, 37.02, 37.02, 37.02], "power_watts_avg": 37.27, "power_watts_peak": 37.52, "energy_joules_est": 37.19, "sample_count": 10, "duration_seconds": 0.998}, "timestamp": "2026-01-11T13:25:55.772578"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 693.072, "latencies_ms": [693.072], "images_per_second": 1.443, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The sheep is positioned prominently in the foreground, contrasting with the rocky terrain in the background. The sheep appears to be standing relatively close to the viewer, emphasizing its prominence in the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.52, 37.52, 37.52, 37.52, 37.52, 38.63, 38.63], "power_watts_avg": 37.84, "power_watts_peak": 38.63, "energy_joules_est": 26.24, "sample_count": 7, "duration_seconds": 0.694}, "timestamp": "2026-01-11T13:25:56.482026"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 609.782, "latencies_ms": [609.782], "images_per_second": 1.64, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A white sheep stands on a rocky outcrop, gazing towards the horizon. The scene is set against a clear blue sky with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [38.63, 38.63, 38.63, 42.95, 42.95, 42.95, 42.95], "power_watts_avg": 41.1, "power_watts_peak": 42.95, "energy_joules_est": 25.08, "sample_count": 7, "duration_seconds": 0.61}, "timestamp": "2026-01-11T13:25:57.190742"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 912.598, "latencies_ms": [912.598], "images_per_second": 1.096, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The sky is a bright blue with scattered white clouds. The rocky terrain is dark gray and appears to be made of granite or similar rock. The lighting suggests a sunny day, with some shadows cast by the sheep.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.6, "ram_available_mb": 109441.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.95, 37.17, 37.17, 37.17, 37.17, 37.17, 36.42, 36.42, 36.42, 36.42], "power_watts_avg": 37.45, "power_watts_peak": 42.95, "energy_joules_est": 34.19, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-11T13:25:58.198473"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 732.431, "latencies_ms": [732.431], "images_per_second": 1.365, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A woman with vibrant blue hair and a blue collared shirt takes a selfie while holding a colorful phone in her right hand.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.42, 35.2, 35.2, 35.2, 35.2, 35.2, 41.6, 41.6], "power_watts_avg": 36.96, "power_watts_peak": 41.6, "energy_joules_est": 27.09, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:25:59.009404"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1020.135, "latencies_ms": [1020.135], "images_per_second": 0.98, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "phone: 1\ntie: 1\nshirt: 2\nmirror: 1\nwoman: 1\nhair: 1\nring: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.6, 41.6, 41.6, 51.7, 51.7, 51.7, 51.7, 42.84, 42.84, 42.84, 42.84], "power_watts_avg": 45.73, "power_watts_peak": 51.7, "energy_joules_est": 46.67, "sample_count": 11, "duration_seconds": 1.021}, "timestamp": "2026-01-11T13:26:00.122588"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 930.384, "latencies_ms": [930.384], "images_per_second": 1.075, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The woman is taking a selfie with her phone held close to her face, capturing the blue hair and clothing. The phone is positioned in the foreground, while the woman's reflection is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.84, 37.56, 37.56, 37.56, 37.56, 37.56, 42.47, 42.47, 42.47, 42.47], "power_watts_avg": 40.05, "power_watts_peak": 42.84, "energy_joules_est": 37.28, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-11T13:26:01.133095"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 954.318, "latencies_ms": [954.318], "images_per_second": 1.048, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A woman with vibrant blue hair is taking a selfie in a bathroom mirror, wearing a gray button-down shirt and tie. The mirror reflects her image, showcasing her colorful hair and outfit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.8, "ram_available_mb": 109441.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.47, 42.27, 42.27, 42.27, 42.27, 42.27, 42.75, 42.75, 42.75, 42.75], "power_watts_avg": 42.48, "power_watts_peak": 42.75, "energy_joules_est": 40.57, "sample_count": 10, "duration_seconds": 0.955}, "timestamp": "2026-01-11T13:26:02.141794"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1105.681, "latencies_ms": [1105.681], "images_per_second": 0.904, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The woman's hair is a vibrant shade of blue. The lighting appears to be natural, possibly from a window, casting a soft glow on her face and hair. The shirt appears to be made of a sturdy, textured material, possibly denim or a similar fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.8, "ram_available_mb": 109441.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.8, "ram_available_mb": 109441.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.75, 42.56, 42.56, 42.56, 42.56, 42.56, 42.94, 42.94, 42.94, 42.94, 42.94, 41.99], "power_watts_avg": 42.69, "power_watts_peak": 42.94, "energy_joules_est": 47.21, "sample_count": 12, "duration_seconds": 1.106}, "timestamp": "2026-01-11T13:26:03.353237"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 848.42, "latencies_ms": [848.42], "images_per_second": 1.179, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The room features a fireplace with a black mantelpiece, a wooden cabinet with two doors, a wooden table with a book, and two chairs, one of which is a rolling office chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 41.99, 41.84, 41.84, 41.84, 41.84, 41.84], "power_watts_avg": 41.91, "power_watts_peak": 41.99, "energy_joules_est": 35.57, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:26:04.264982"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1236.085, "latencies_ms": [1236.085], "images_per_second": 0.809, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "fireplace: 2\nvases: 2\noil lamp: 1\npicture frame: 2\nwooden cabinet: 2\ndesk: 2\nchair: 2\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.79, 41.79, 41.79, 41.79, 41.79, 42.99, 42.99, 42.99, 42.99, 42.99, 43.25, 43.25, 43.25], "power_watts_avg": 42.59, "power_watts_peak": 43.25, "energy_joules_est": 52.65, "sample_count": 13, "duration_seconds": 1.236}, "timestamp": "2026-01-11T13:26:05.573392"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 956.216, "latencies_ms": [956.216], "images_per_second": 1.046, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The fireplace is positioned to the left of the wooden table and chairs, creating a sense of spatial proximity. The table and chairs are situated in the foreground, closer to the viewer, while the fireplace occupies the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.25, 43.25, 39.47, 39.47, 39.47, 39.47, 39.47, 42.37, 42.37, 42.37], "power_watts_avg": 41.09, "power_watts_peak": 43.25, "energy_joules_est": 39.32, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:26:06.583547"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 934.423, "latencies_ms": [934.423], "images_per_second": 1.07, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a cozy, antique room with a fireplace, wooden furniture, and paintings on the walls. The room appears to be part of a museum or historical setting, possibly showcasing a historical home or period.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.37, 42.37, 43.12, 43.12, 43.12, 43.12, 43.12, 43.16, 43.16, 43.16], "power_watts_avg": 42.98, "power_watts_peak": 43.16, "energy_joules_est": 40.18, "sample_count": 10, "duration_seconds": 0.935}, "timestamp": "2026-01-11T13:26:07.595306"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1061.184, "latencies_ms": [1061.184], "images_per_second": 0.942, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The room features a warm color palette, primarily due to the fireplace and wooden furniture. The lighting is soft and diffused, creating a cozy atmosphere. The materials include dark wood, metal, and fabric, adding to the antique ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.9, "ram_available_mb": 109441.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [43.16, 43.16, 42.23, 42.23, 42.23, 42.23, 42.23, 42.74, 42.74, 42.74, 42.74], "power_watts_avg": 42.58, "power_watts_peak": 43.16, "energy_joules_est": 45.2, "sample_count": 11, "duration_seconds": 1.061}, "timestamp": "2026-01-11T13:26:08.706413"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 686.923, "latencies_ms": [686.923], "images_per_second": 1.456, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A brown dog jumps to catch a red frisbee in a green yard with a black car parked in the background.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13064.9, "ram_available_mb": 109441.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13064.9, "ram_available_mb": 109441.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.74, 37.34, 37.34, 37.34, 37.34, 37.34, 43.77], "power_watts_avg": 39.03, "power_watts_peak": 43.77, "energy_joules_est": 26.83, "sample_count": 7, "duration_seconds": 0.687}, "timestamp": "2026-01-11T13:26:09.419465"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1091.013, "latencies_ms": [1091.013], "images_per_second": 0.917, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "tree: 1\nfrisbee: 1\ndog: 1\ngrass: 1\ncar: 1\nshrubs: 2\nmulch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.9, "ram_available_mb": 109441.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.9, "ram_available_mb": 109441.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 43.77, 56.47, 56.47, 56.47, 56.47, 56.47, 45.04, 45.04, 45.04], "power_watts_avg": 49.89, "power_watts_peak": 56.47, "energy_joules_est": 54.44, "sample_count": 11, "duration_seconds": 1.091}, "timestamp": "2026-01-11T13:26:10.527022"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 836.974, "latencies_ms": [836.974], "images_per_second": 1.195, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The black car is positioned in the background, slightly further away than the dog. The dog is positioned in the foreground, jumping to catch a red frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.9, "ram_available_mb": 109441.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13065.2, "ram_available_mb": 109441.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.04, 45.04, 42.09, 42.09, 42.09, 42.09, 42.09, 44.86, 44.86], "power_watts_avg": 43.36, "power_watts_peak": 45.04, "energy_joules_est": 36.31, "sample_count": 9, "duration_seconds": 0.837}, "timestamp": "2026-01-11T13:26:11.436570"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 723.832, "latencies_ms": [723.832], "images_per_second": 1.382, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A brown dog is jumping to catch a red frisbee in a grassy yard. A black car is parked nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.2, "ram_available_mb": 109441.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.2, "ram_available_mb": 109441.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [44.86, 44.86, 44.86, 46.85, 46.85, 46.85, 46.85, 46.85], "power_watts_avg": 46.1, "power_watts_peak": 46.85, "energy_joules_est": 33.4, "sample_count": 8, "duration_seconds": 0.724}, "timestamp": "2026-01-11T13:26:12.244701"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1000.071, "latencies_ms": [1000.071], "images_per_second": 1.0, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The dog is dark brown, appears to be mid-leap, and has a red frisbee in its mouth. The scene is brightly lit, suggesting sunny weather. The dog's fur looks soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.2, "ram_available_mb": 109441.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.85, 42.85, 42.85, 43.85, 43.85, 43.85, 43.85, 43.85], "power_watts_avg": 43.35, "power_watts_peak": 43.85, "energy_joules_est": 43.37, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:26:13.256002"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 575.246, "latencies_ms": [575.246], "images_per_second": 1.738, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A giraffe with brown and white spots and large, expressive eyes gazes directly at the camera in a lush, green environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.76, 44.76, 44.76, 44.76, 44.76, 38.34], "power_watts_avg": 43.69, "power_watts_peak": 44.76, "energy_joules_est": 25.14, "sample_count": 6, "duration_seconds": 0.576}, "timestamp": "2026-01-11T13:26:13.865757"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1264.238, "latencies_ms": [1264.238], "images_per_second": 0.791, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "giraffe: 1\ntree: 1\nleaves: 1\ngiraffe's head: 1\ngiraffe's neck: 1\ngiraffe's ears: 2\ngiraffe's mouth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.34, 38.34, 38.34, 38.34, 42.69, 42.69, 42.69, 42.69, 42.69, 37.98, 37.98, 37.98, 37.98], "power_watts_avg": 39.9, "power_watts_peak": 42.69, "energy_joules_est": 50.46, "sample_count": 13, "duration_seconds": 1.265}, "timestamp": "2026-01-11T13:26:15.178352"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 715.196, "latencies_ms": [715.196], "images_per_second": 1.398, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The giraffe is positioned in the foreground, with its head and neck dominating the left side of the image. The background consists of blurred green foliage, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.98, 34.81, 34.81, 34.81, 34.81, 34.81, 37.72, 37.72], "power_watts_avg": 35.94, "power_watts_peak": 37.98, "energy_joules_est": 25.72, "sample_count": 8, "duration_seconds": 0.716}, "timestamp": "2026-01-11T13:26:15.987958"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1125.536, "latencies_ms": [1125.536], "images_per_second": 0.888, "prompt_tokens": 19, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene is set in a lush, green environment, possibly a zoo or wildlife park. The focus is on a giraffe's head and neck, with its distinctive spotted pattern and large, expressive eyes. The giraffe appears to be looking directly at the camera, creating a sense of connection between the viewer and the subject.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.72, 37.72, 37.72, 40.74, 40.74, 40.74, 40.74, 40.74, 36.46, 36.46, 36.46, 36.46], "power_watts_avg": 38.56, "power_watts_peak": 40.74, "energy_joules_est": 43.42, "sample_count": 12, "duration_seconds": 1.126}, "timestamp": "2026-01-11T13:26:17.199319"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 646.062, "latencies_ms": [646.062], "images_per_second": 1.548, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The giraffe's coat is predominantly brown and white. The lighting suggests a sunny day with bright, natural light filtering through the trees.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.46, 32.55, 32.55, 32.55, 32.55, 32.55, 37.28], "power_watts_avg": 33.78, "power_watts_peak": 37.28, "energy_joules_est": 21.84, "sample_count": 7, "duration_seconds": 0.646}, "timestamp": "2026-01-11T13:26:17.905651"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 670.124, "latencies_ms": [670.124], "images_per_second": 1.492, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Two zebras stand side by side, facing away from the camera, showcasing their distinct black and white striped patterns.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.28, 37.28, 37.28, 37.28, 47.82, 47.82, 47.82], "power_watts_avg": 41.79, "power_watts_peak": 47.82, "energy_joules_est": 28.05, "sample_count": 7, "duration_seconds": 0.671}, "timestamp": "2026-01-11T13:26:18.619821"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 927.661, "latencies_ms": [927.661], "images_per_second": 1.078, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "zebra: 2\nfence: 1\nground: 1\nleaves: 1\nrocks: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [47.82, 46.57, 46.57, 46.57, 46.57, 46.57, 43.54, 43.54, 43.54, 43.54], "power_watts_avg": 45.48, "power_watts_peak": 47.82, "energy_joules_est": 42.21, "sample_count": 10, "duration_seconds": 0.928}, "timestamp": "2026-01-11T13:26:19.628559"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 902.254, "latencies_ms": [902.254], "images_per_second": 1.108, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the zebra on the left appearing slightly further away. The background is relatively open and features trees and a fence, suggesting an enclosure or open area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [43.54, 43.49, 43.49, 43.49, 43.49, 43.49, 42.78, 42.78, 42.78], "power_watts_avg": 43.26, "power_watts_peak": 43.54, "energy_joules_est": 39.06, "sample_count": 9, "duration_seconds": 0.903}, "timestamp": "2026-01-11T13:26:20.540470"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 923.909, "latencies_ms": [923.909], "images_per_second": 1.082, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Two zebras stand side by side in a fenced enclosure, facing away from the camera. The ground is covered with grass and scattered leaves, indicating a natural habitat setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.78, 42.78, 48.47, 48.47, 48.47, 48.47, 48.47, 43.49, 43.49, 43.49], "power_watts_avg": 45.84, "power_watts_peak": 48.47, "energy_joules_est": 42.37, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-11T13:26:21.552270"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 759.363, "latencies_ms": [759.363], "images_per_second": 1.317, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The zebras have distinct black and white stripes. The lighting in the image suggests a sunny day, and the ground appears to be dry and grassy.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.49, 43.49, 41.65, 41.65, 41.65, 41.65, 41.65, 42.27], "power_watts_avg": 42.19, "power_watts_peak": 43.49, "energy_joules_est": 32.06, "sample_count": 8, "duration_seconds": 0.76}, "timestamp": "2026-01-11T13:26:22.359042"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 809.348, "latencies_ms": [809.348], "images_per_second": 1.236, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A silver car is parked on the side of the road, while a group of horses, including brown, black, and white ones, stand nearby, seemingly curious about the vehicle.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13065.1, "ram_available_mb": 109441.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.27, 42.27, 42.27, 42.27, 46.05, 46.05, 46.05, 46.05, 46.05], "power_watts_avg": 44.37, "power_watts_peak": 46.05, "energy_joules_est": 35.94, "sample_count": 9, "duration_seconds": 0.81}, "timestamp": "2026-01-11T13:26:23.270299"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 922.272, "latencies_ms": [922.272], "images_per_second": 1.084, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "horse: 3\ncar: 1\nfence: 1\ntrees: 4\nroad: 2\nhorse droppings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.26, 42.26, 42.26, 42.26, 42.26, 42.33, 42.33, 42.33, 42.33, 42.33], "power_watts_avg": 42.29, "power_watts_peak": 42.33, "energy_joules_est": 39.02, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-11T13:26:24.279279"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 654.002, "latencies_ms": [654.002], "images_per_second": 1.529, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The car is positioned in the foreground, slightly to the right of the horses. The horses are situated in the background, closer to the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.06, 43.06, 43.06, 43.06, 43.06, 42.84, 42.84], "power_watts_avg": 43.0, "power_watts_peak": 43.06, "energy_joules_est": 28.13, "sample_count": 7, "duration_seconds": 0.654}, "timestamp": "2026-01-11T13:26:24.988706"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 915.555, "latencies_ms": [915.555], "images_per_second": 1.092, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A group of horses is gathered on a paved road near a wooden fence, with some standing close together and others further away. A car is parked on the side of the road, observing the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.0, "ram_available_mb": 109441.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 42.84, 52.56, 52.56, 52.56, 52.56, 52.56, 42.93, 42.93], "power_watts_avg": 47.72, "power_watts_peak": 52.56, "energy_joules_est": 43.7, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-11T13:26:25.999276"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1116.136, "latencies_ms": [1116.136], "images_per_second": 0.896, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene is bathed in bright sunlight, creating a warm and inviting atmosphere. The road is paved and appears to be well-maintained, suitable for driving. The horses are dark brown or black, contrasting with the lighter colors of the surrounding environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 42.93, 42.55, 42.55, 42.55, 42.55, 42.55, 42.3, 42.3, 42.3, 42.3], "power_watts_avg": 42.56, "power_watts_peak": 42.93, "energy_joules_est": 47.52, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-11T13:26:27.210735"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 700.67, "latencies_ms": [700.67], "images_per_second": 1.427, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A wooden desk with a stack of blue books, a red apple, and a bell sits in front of a chalkboard in a classroom setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.3, 32.21, 32.21, 32.21, 32.21, 32.21, 42.3], "power_watts_avg": 35.09, "power_watts_peak": 42.3, "energy_joules_est": 24.61, "sample_count": 7, "duration_seconds": 0.701}, "timestamp": "2026-01-11T13:26:27.920934"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1274.463, "latencies_ms": [1274.463], "images_per_second": 0.785, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Chalkboard: 10\nBooks: 5\nWooden desk: 2\nWooden chair: 1\nBell: 1\nApple: 1\nWooden floor: 1\nWhite door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.3, 42.3, 42.3, 54.47, 54.47, 54.47, 54.47, 54.47, 43.92, 43.92, 43.92, 43.92, 43.92], "power_watts_avg": 47.6, "power_watts_peak": 54.47, "energy_joules_est": 60.68, "sample_count": 13, "duration_seconds": 1.275}, "timestamp": "2026-01-11T13:26:29.232485"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1124.063, "latencies_ms": [1124.063], "images_per_second": 0.89, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a spatial arrangement that suggests a classroom setting. The books are placed on the desk in the foreground, while the bell and apple are situated near the back of the desk. The chalkboard is positioned in the background, further emphasizing the classroom setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.69, 33.69, 33.69, 33.69, 33.69, 43.73, 43.73, 43.73, 43.73, 43.73, 43.89, 43.89], "power_watts_avg": 39.57, "power_watts_peak": 43.89, "energy_joules_est": 44.5, "sample_count": 12, "duration_seconds": 1.125}, "timestamp": "2026-01-11T13:26:30.444124"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1007.722, "latencies_ms": [1007.722], "images_per_second": 0.992, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a vintage classroom setting. A wooden desk with a stack of books and a bell sits in front of a chalkboard, evoking a sense of history and learning. The overall atmosphere is calm and studious.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [43.89, 43.89, 43.89, 42.49, 42.49, 42.49, 42.49, 42.49, 42.34, 42.34, 42.34], "power_watts_avg": 42.83, "power_watts_peak": 43.89, "energy_joules_est": 43.18, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-11T13:26:31.553863"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1365.478, "latencies_ms": [1365.478], "images_per_second": 0.732, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The room features a dark green chalkboard, illuminated by a soft, natural light source. The wooden desk and chair are crafted from warm-toned wood, complementing the overall ambiance of the classroom. The walls are painted in a muted brown color, contributing to the calm atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.34, 42.34, 39.21, 39.21, 39.21, 39.21, 39.21, 42.11, 42.11, 42.11, 42.11, 42.11, 36.41, 36.41], "power_watts_avg": 40.29, "power_watts_peak": 42.34, "energy_joules_est": 55.03, "sample_count": 14, "duration_seconds": 1.366}, "timestamp": "2026-01-11T13:26:32.966520"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 760.824, "latencies_ms": [760.824], "images_per_second": 1.314, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A yellow bus with the number 475 and text in Hindi is driving down a busy city street, passing a silver SUV.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.41, 36.41, 36.41, 42.71, 42.71, 42.71, 42.71, 42.71], "power_watts_avg": 40.35, "power_watts_peak": 42.71, "energy_joules_est": 30.72, "sample_count": 8, "duration_seconds": 0.761}, "timestamp": "2026-01-11T13:26:33.777744"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1043.753, "latencies_ms": [1043.753], "images_per_second": 0.958, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bus: 475\nvan: 1\ncar: 1\nmotorcycle: 1\nman: 1\nroad: 2\nbuildings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.69, 42.69, 42.69, 42.69, 42.69, 43.0, 43.0, 43.0, 43.0, 43.0, 42.85], "power_watts_avg": 42.84, "power_watts_peak": 43.0, "energy_joules_est": 44.73, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-11T13:26:34.887935"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 815.218, "latencies_ms": [815.218], "images_per_second": 1.227, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving away from the viewer. The van is parked in the background, slightly further away. The bus is closer to the viewer than the van.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.85, 42.85, 42.84, 42.84, 42.84, 42.84, 42.84], "power_watts_avg": 42.84, "power_watts_peak": 42.85, "energy_joules_est": 34.95, "sample_count": 9, "duration_seconds": 0.816}, "timestamp": "2026-01-11T13:26:35.797659"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1232.43, "latencies_ms": [1232.43], "images_per_second": 0.811, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a busy urban street with a yellow bus driving down the road, alongside a white van and a motorcycle. The bus displays the number 475 and text in multiple languages, indicating its origin or destination. The overall setting suggests a bustling city environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.68, 42.68, 42.68, 42.68, 42.68, 41.91, 41.91, 41.91, 41.91, 41.91, 42.31, 42.31, 42.31], "power_watts_avg": 42.3, "power_watts_peak": 42.68, "energy_joules_est": 52.15, "sample_count": 13, "duration_seconds": 1.233}, "timestamp": "2026-01-11T13:26:37.110582"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 959.021, "latencies_ms": [959.021], "images_per_second": 1.043, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bus is predominantly yellow with white and green accents. Its rear lights are visible and appear to be older. The lighting suggests it might be daytime. The bus appears to be somewhat weathered or worn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.31, 42.31, 36.88, 36.88, 36.88, 36.88, 36.88, 41.69, 41.69, 41.69], "power_watts_avg": 39.41, "power_watts_peak": 42.31, "energy_joules_est": 37.81, "sample_count": 10, "duration_seconds": 0.96}, "timestamp": "2026-01-11T13:26:38.120698"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 622.964, "latencies_ms": [622.964], "images_per_second": 1.605, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A bathroom features a flat-screen TV mounted on the wall, displaying a sports game between two teams.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.69, 42.36, 42.36, 42.36, 42.36, 42.36, 42.93], "power_watts_avg": 42.35, "power_watts_peak": 42.93, "energy_joules_est": 26.42, "sample_count": 7, "duration_seconds": 0.624}, "timestamp": "2026-01-11T13:26:38.831860"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1219.268, "latencies_ms": [1219.268], "images_per_second": 0.82, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "sink: 2\ntoilet paper dispenser: 1\nhand dryer: 1\nmirror: 1\ntile: 6\ndoor: 1\nwall: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 42.93, 42.93, 49.48, 49.48, 49.48, 49.48, 49.48, 42.21, 42.21, 42.21, 42.21], "power_watts_avg": 45.23, "power_watts_peak": 49.48, "energy_joules_est": 55.16, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:26:40.143661"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 703.048, "latencies_ms": [703.048], "images_per_second": 1.422, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The sink is located in the foreground, while the mirror reflects the sink and door in the background. The sink is situated closer to the viewer than the mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.21, 34.99, 34.99, 34.99, 34.99, 34.99, 42.25], "power_watts_avg": 37.06, "power_watts_peak": 42.25, "energy_joules_est": 26.06, "sample_count": 7, "duration_seconds": 0.703}, "timestamp": "2026-01-11T13:26:40.851737"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.769, "latencies_ms": [933.769], "images_per_second": 1.071, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene depicts a public restroom with a flat-screen TV mounted on the wall, displaying a sports game. Two sinks are visible in the mirror, reflecting the room's features.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.25, 42.25, 42.25, 42.25, 52.38, 52.38, 52.38, 52.38, 52.38, 43.94], "power_watts_avg": 47.49, "power_watts_peak": 52.38, "energy_joules_est": 44.37, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:26:41.862277"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 933.267, "latencies_ms": [933.267], "images_per_second": 1.072, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The bathroom features a beige tiled wall with brown accents, creating a warm and neutral ambiance. The lighting is bright, likely from overhead fixtures, enhancing the visibility of the sink and mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.94, 43.94, 43.94, 43.94, 42.74, 42.74, 42.74, 42.74, 42.74, 42.66], "power_watts_avg": 43.21, "power_watts_peak": 43.94, "energy_joules_est": 40.35, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:26:42.871524"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 721.14, "latencies_ms": [721.14], "images_per_second": 1.387, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man sits on a park bench, gazing thoughtfully at the surrounding trees and buildings, including a tall church with a pointed steeple.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.66, 42.66, 42.66, 42.66, 42.83, 42.83, 42.83, 42.83], "power_watts_avg": 42.74, "power_watts_peak": 42.83, "energy_joules_est": 30.85, "sample_count": 8, "duration_seconds": 0.722}, "timestamp": "2026-01-11T13:26:43.683115"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1244.873, "latencies_ms": [1244.873], "images_per_second": 0.803, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Bench: 1\nPerson: 1\nTrees: 2\nFlowers: 2\nBuildings: 2\nChurch: 1\nStreetlights: 2\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.83, 41.91, 41.91, 41.91, 41.91, 41.91, 42.68, 42.68, 42.68, 42.68, 42.68, 44.48, 44.48], "power_watts_avg": 42.67, "power_watts_peak": 44.48, "energy_joules_est": 53.15, "sample_count": 13, "duration_seconds": 1.245}, "timestamp": "2026-01-11T13:26:44.993723"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 846.875, "latencies_ms": [846.875], "images_per_second": 1.181, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The man is positioned in the foreground, facing the church tower and trees in the background. The church tower is situated near the man, creating a sense of proximity between the man and the church.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.48, 44.48, 44.48, 43.13, 43.13, 43.13, 43.13, 43.13, 43.0], "power_watts_avg": 43.56, "power_watts_peak": 44.48, "energy_joules_est": 36.9, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-11T13:26:45.902400"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 888.244, "latencies_ms": [888.244], "images_per_second": 1.126, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A man sits on a park bench, appearing contemplative or relaxed. In the background, a church with a tall steeple stands amidst trees and bushes, creating a serene and peaceful atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.0, 43.0, 43.0, 43.0, 43.18, 43.18, 43.18, 43.18, 43.18], "power_watts_avg": 43.1, "power_watts_peak": 43.18, "energy_joules_est": 38.3, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:26:46.810763"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1253.652, "latencies_ms": [1253.652], "images_per_second": 0.798, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The photograph is in black and white, showcasing a calm and peaceful atmosphere. The lighting is soft and diffused, creating a serene ambiance. In the foreground, a man sits on a bench, appearing relaxed and contemplative. The image captures a moment of quiet reflection in a garden setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 43.14, 43.14, 43.14, 43.74, 43.74, 43.74, 43.74, 43.9, 43.9, 43.9, 43.9], "power_watts_avg": 43.56, "power_watts_peak": 43.9, "energy_joules_est": 54.64, "sample_count": 13, "duration_seconds": 1.254}, "timestamp": "2026-01-11T13:26:48.127716"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 671.076, "latencies_ms": [671.076], "images_per_second": 1.49, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A bustling city street scene features various vehicles, including cars, buses, and vans, navigating through the traffic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.9, 36.19, 36.19, 36.19, 36.19, 36.19, 42.91], "power_watts_avg": 38.25, "power_watts_peak": 43.9, "energy_joules_est": 25.69, "sample_count": 7, "duration_seconds": 0.672}, "timestamp": "2026-01-11T13:26:48.839256"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1149.894, "latencies_ms": [1149.894], "images_per_second": 0.87, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "bus: 2\nvan: 2\ncar: 4\nminivan: 2\ncar: 4\nstreet: 6\nbuildings: 2\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.91, 42.91, 42.91, 42.91, 50.97, 50.97, 50.97, 50.97, 50.97, 43.35, 43.35, 43.35], "power_watts_avg": 46.38, "power_watts_peak": 50.97, "energy_joules_est": 53.34, "sample_count": 12, "duration_seconds": 1.15}, "timestamp": "2026-01-11T13:26:50.052894"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1145.335, "latencies_ms": [1145.335], "images_per_second": 0.873, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The foreground features a green bus parked on the left side of the street, partially obscuring the view of the background. The background includes various parked cars and a building, which appears to be situated further back from the bus. The bus is positioned near the center-left of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 40.36, 40.36, 40.36, 40.36, 40.36, 42.92, 42.92, 42.92, 42.92, 42.92], "power_watts_avg": 41.93, "power_watts_peak": 43.35, "energy_joules_est": 48.04, "sample_count": 12, "duration_seconds": 1.146}, "timestamp": "2026-01-11T13:26:51.267217"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1183.86, "latencies_ms": [1183.86], "images_per_second": 0.845, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a busy street intersection, likely in Jerusalem, with various vehicles, including cars, buses, and vans, navigating the road. A person is seen walking on the sidewalk near the bus stop. The buildings in the background suggest a historical or religious setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.29, 36.29, 36.29, 36.29, 36.29, 42.96, 42.96, 42.96, 42.96, 42.96, 43.01, 43.01], "power_watts_avg": 40.19, "power_watts_peak": 43.01, "energy_joules_est": 47.59, "sample_count": 12, "duration_seconds": 1.184}, "timestamp": "2026-01-11T13:26:52.480629"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1033.344, "latencies_ms": [1033.344], "images_per_second": 0.968, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene is dominated by bright sunlight, creating a clear and blue sky. The buildings in the background appear to be a mix of stone and concrete, giving a historical or architectural feel to the setting. The overall atmosphere is sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.3, 43.3, 43.3, 43.3, 43.3, 43.45, 43.45, 43.45], "power_watts_avg": 43.26, "power_watts_peak": 43.45, "energy_joules_est": 44.73, "sample_count": 11, "duration_seconds": 1.034}, "timestamp": "2026-01-11T13:26:53.593963"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1032.003, "latencies_ms": [1032.003], "images_per_second": 0.969, "prompt_tokens": 8, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A wooden table holds a plate with a slice of pancake topped with banana slices, a small bowl with sugar, a plate of fruit including watermelon, pineapple, and bananas, and a cup of coffee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 37.59, 37.59, 37.59, 37.59, 37.59, 42.35, 42.35, 42.35, 42.35], "power_watts_avg": 40.39, "power_watts_peak": 43.45, "energy_joules_est": 41.7, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-11T13:26:54.708884"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1576.151, "latencies_ms": [1576.151], "images_per_second": 0.634, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Omelet: 1\nBanana slices: 2\nWatermelon: 1\nFruit: 2\nFruit salad: 1\nTea: 1\nSugar: 1\nSpoon: 1\nFork: 1\nTable: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.35, 37.79, 37.79, 37.79, 37.79, 37.79, 42.45, 42.45, 42.45, 42.45, 42.45, 44.21, 44.21, 44.21, 44.21, 44.21], "power_watts_avg": 41.54, "power_watts_peak": 44.21, "energy_joules_est": 65.48, "sample_count": 16, "duration_seconds": 1.576}, "timestamp": "2026-01-11T13:26:56.324637"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 881.531, "latencies_ms": [881.531], "images_per_second": 1.134, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The breakfast is arranged on a table with a wooden surface, positioned near a window that casts shadows. The table occupies the foreground, while the window and table are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.55, 33.55, 33.55, 33.55, 43.09, 43.09, 43.09, 43.09, 43.09], "power_watts_avg": 38.85, "power_watts_peak": 43.09, "energy_joules_est": 34.26, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-11T13:26:57.233826"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 960.936, "latencies_ms": [960.936], "images_per_second": 1.041, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a breakfast setting on a tiled floor, featuring a plate with a partially eaten omelet, a fruit platter with bananas, watermelon, and pineapple, and two cups of tea.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 43.05, 43.05, 43.73, 43.73, 43.73, 43.73, 43.73], "power_watts_avg": 43.39, "power_watts_peak": 43.73, "energy_joules_est": 41.75, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-11T13:26:58.247645"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 974.372, "latencies_ms": [974.372], "images_per_second": 1.026, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The table is brown wood, contrasting with the white tiles. The food is colorful, featuring yellow bananas, sliced watermelon, and pineapple. The table is well-lit, suggesting sunlight from the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 43.14, 43.14, 43.14, 43.22, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 43.18, "power_watts_peak": 43.22, "energy_joules_est": 42.09, "sample_count": 10, "duration_seconds": 0.975}, "timestamp": "2026-01-11T13:26:59.256586"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 857.202, "latencies_ms": [857.202], "images_per_second": 1.167, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "An elderly woman in a green and white striped shirt and pink apron is carefully arranging various baked goods, including bread rolls, biscuits, and cookies, on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.67, 43.67, 43.67, 43.67, 43.67, 43.53, 43.53, 43.53, 43.53], "power_watts_avg": 43.61, "power_watts_peak": 43.67, "energy_joules_est": 37.42, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:27:00.170434"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1460.542, "latencies_ms": [1460.542], "images_per_second": 0.685, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "bread: 8\ncookies: 8\nbuns: 2\nglazed cookies: 8\nbread pan: 1\nbaking sheet: 1\ntablecloth: 2\nglasses: 2\ntoys: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.53, 44.34, 44.34, 44.34, 44.34, 44.34, 43.24, 43.24, 43.24, 43.24, 43.24, 43.67, 43.67, 43.67, 43.67], "power_watts_avg": 43.74, "power_watts_peak": 44.34, "energy_joules_est": 63.91, "sample_count": 15, "duration_seconds": 1.461}, "timestamp": "2026-01-11T13:27:01.685750"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1121.913, "latencies_ms": [1121.913], "images_per_second": 0.891, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The woman is positioned on the left side of the image, preparing food on a table. The table occupies the foreground, displaying various baked goods and cooking utensils. The background features a living room with a couch and a window, providing a glimpse of the surrounding space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.67, 33.19, 33.19, 33.19, 33.19, 33.19, 42.87, 42.87, 42.87, 42.87, 42.87, 43.38], "power_watts_avg": 38.94, "power_watts_peak": 43.67, "energy_joules_est": 43.7, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-11T13:27:02.898506"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 785.705, "latencies_ms": [785.705], "images_per_second": 1.273, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A woman is preparing baked goods at a wooden table in a cozy living room. She is using a metal utensil to spread something on a baking sheet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 43.38, 42.11, 42.11, 42.11, 42.11], "power_watts_avg": 42.74, "power_watts_peak": 43.38, "energy_joules_est": 33.6, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:27:03.707211"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1052.817, "latencies_ms": [1052.817], "images_per_second": 0.95, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The table is covered with a patterned tablecloth in shades of red, pink, and cream. The woman is wearing glasses and a green and white striped shirt. The table is equipped with several baking trays and ingredients.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.11, 41.42, 41.42, 41.42, 41.42, 41.42, 43.39, 43.39, 43.39, 43.39, 43.39], "power_watts_avg": 42.38, "power_watts_peak": 43.39, "energy_joules_est": 44.63, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:27:04.819116"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 882.294, "latencies_ms": [882.294], "images_per_second": 1.133, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A man in a white t-shirt and shorts stands next to a traffic light pole with a \"AUSTRALIA TRAFFIC LIGHT\" sign, smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.16, 44.16, 44.16, 44.16, 44.16, 42.8, 42.8, 42.8, 42.8], "power_watts_avg": 43.55, "power_watts_peak": 44.16, "energy_joules_est": 38.45, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-11T13:27:05.731647"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1135.443, "latencies_ms": [1135.443], "images_per_second": 0.881, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "traffic light: 3\nsign: 1\nman: 1\ntrees: 2\nflowers: 2\nground: 2\nrocks: 2\nsand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.52, 42.52, 42.52, 42.52, 42.52, 43.85, 43.85, 43.85, 43.85, 43.85, 44.21, 44.21], "power_watts_avg": 43.35, "power_watts_peak": 44.21, "energy_joules_est": 49.25, "sample_count": 12, "duration_seconds": 1.136}, "timestamp": "2026-01-11T13:27:06.943936"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1154.164, "latencies_ms": [1154.164], "images_per_second": 0.866, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The man is standing in the foreground of the image, positioned to the left of the traffic light. The traffic light is situated in the background, slightly further away than the man. The setting appears to be outdoors, with vegetation and a gravel or dirt area around the man and the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.21, 44.21, 44.21, 42.66, 42.66, 42.66, 42.66, 42.66, 42.59, 42.59, 42.59, 42.59], "power_watts_avg": 43.02, "power_watts_peak": 44.21, "energy_joules_est": 49.67, "sample_count": 12, "duration_seconds": 1.154}, "timestamp": "2026-01-11T13:27:08.158843"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 847.022, "latencies_ms": [847.022], "images_per_second": 1.181, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A young man stands next to a traffic light in Australia. He is wearing a white t-shirt and shorts and appears to be smiling. The traffic light is red, indicating a stop for vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.59, 34.89, 34.89, 34.89, 34.89, 34.89, 43.17, 43.17, 43.17], "power_watts_avg": 38.5, "power_watts_peak": 43.17, "energy_joules_est": 32.62, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-11T13:27:09.068851"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 780.572, "latencies_ms": [780.572], "images_per_second": 1.281, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The traffic light is red and glowing. The man is wearing sandals. The setting appears to be outdoors, possibly in Australia, given the Australian signage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 48.24, 48.24, 48.24, 48.24, 48.24, 43.19], "power_watts_avg": 46.34, "power_watts_peak": 48.24, "energy_joules_est": 36.2, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:27:09.878328"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 807.858, "latencies_ms": [807.858], "images_per_second": 1.238, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A lively kite festival is taking place in a park, with numerous vibrant kites soaring in the sky, including three clownfish-shaped kites.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 43.19, 43.19, 46.81, 46.81, 46.81, 46.81, 46.81], "power_watts_avg": 45.2, "power_watts_peak": 46.81, "energy_joules_est": 36.53, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:27:10.790602"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1234.336, "latencies_ms": [1234.336], "images_per_second": 0.81, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "kite: 4\nflag: 4\nkite: 4\nkite: 4\nkite: 4\nkite: 4\nkite: 4\nkite: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.0, 43.0, 43.0, 43.0, 43.0, 42.33, 42.33, 42.33, 42.33, 42.33, 42.89, 42.89, 42.89], "power_watts_avg": 42.72, "power_watts_peak": 43.0, "energy_joules_est": 52.75, "sample_count": 13, "duration_seconds": 1.235}, "timestamp": "2026-01-11T13:27:12.103121"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 852.355, "latencies_ms": [852.355], "images_per_second": 1.173, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the red and black kites extending towards the background. The kites are spread out across the grassy field, creating a dynamic and colorful display.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.89, 42.89, 37.61, 37.61, 37.61, 37.61, 37.61, 42.61, 42.61], "power_watts_avg": 39.9, "power_watts_peak": 42.89, "energy_joules_est": 34.03, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-11T13:27:13.014239"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1150.969, "latencies_ms": [1150.969], "images_per_second": 0.869, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a lively kite festival in a park with several large, colorful fish-shaped kites soaring in the sky. The park is filled with people enjoying the event, with some standing near the kites and others scattered across the grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 49.07, 49.07, 49.07, 49.07, 49.07, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 45.5, "power_watts_peak": 49.07, "energy_joules_est": 52.4, "sample_count": 12, "duration_seconds": 1.151}, "timestamp": "2026-01-11T13:27:14.227498"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 808.209, "latencies_ms": [808.209], "images_per_second": 1.237, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The kites are predominantly red, orange, and purple, contrasting against the light blue sky. The lighting suggests a sunny day with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.22, 32.91, 32.91, 32.91, 32.91, 43.01, 43.01, 43.01, 43.01], "power_watts_avg": 38.54, "power_watts_peak": 43.22, "energy_joules_est": 31.17, "sample_count": 9, "duration_seconds": 0.809}, "timestamp": "2026-01-11T13:27:15.137825"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 622.194, "latencies_ms": [622.194], "images_per_second": 1.607, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is sharing a slice of pizza with a young boy, who appears excited and eager to eat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.01, 45.26, 45.26, 45.26, 45.26, 45.26, 41.96], "power_watts_avg": 44.46, "power_watts_peak": 45.26, "energy_joules_est": 27.68, "sample_count": 7, "duration_seconds": 0.622}, "timestamp": "2026-01-11T13:27:15.850052"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1425.502, "latencies_ms": [1425.502], "images_per_second": 0.702, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Pizza: 2\nPizza box: 1\nPizza slice: 1\nMan: 1\nChild: 1\nBoy: 1\nSlippers: 1\nWater bottle: 1\nCouch: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.96, 41.96, 41.96, 41.96, 50.53, 50.53, 50.53, 50.53, 50.53, 42.35, 42.35, 42.35, 42.35, 42.35, 33.61], "power_watts_avg": 44.39, "power_watts_peak": 50.53, "energy_joules_est": 63.3, "sample_count": 15, "duration_seconds": 1.426}, "timestamp": "2026-01-11T13:27:17.364288"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 949.456, "latencies_ms": [949.456], "images_per_second": 1.053, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The man is on the left side of the image, holding the pizza slice. The child is on the right side of the image, looking at the pizza slice. The pizza is positioned between the man and the child, suggesting a close interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.61, 33.61, 33.61, 33.61, 42.38, 42.38, 42.38, 42.38, 42.38, 42.47], "power_watts_avg": 38.88, "power_watts_peak": 42.47, "energy_joules_est": 36.94, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-11T13:27:18.375963"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 739.724, "latencies_ms": [739.724], "images_per_second": 1.352, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man and a young boy are sharing a slice of pizza together. The setting appears to be a casual indoor space, possibly a living room or bedroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.47, 42.47, 42.47, 42.47, 42.93, 42.93, 42.93, 42.93], "power_watts_avg": 42.7, "power_watts_peak": 42.93, "energy_joules_est": 31.61, "sample_count": 8, "duration_seconds": 0.74}, "timestamp": "2026-01-11T13:27:19.185414"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 725.614, "latencies_ms": [725.614], "images_per_second": 1.378, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The room is lit by natural light coming in through a window. The walls are a warm orange color. The floor appears to be tiled.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.9, "ram_available_mb": 109442.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.93, 42.28, 42.28, 42.28, 42.28, 42.28, 42.96, 42.96], "power_watts_avg": 42.53, "power_watts_peak": 42.96, "energy_joules_est": 30.88, "sample_count": 8, "duration_seconds": 0.726}, "timestamp": "2026-01-11T13:27:19.996119"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 609.656, "latencies_ms": [609.656], "images_per_second": 1.64, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A woman is sitting in a camping chair outdoors, eating a sandwich and enjoying a plate of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 42.96, 52.48, 52.48, 52.48, 52.48], "power_watts_avg": 48.4, "power_watts_peak": 52.48, "energy_joules_est": 29.53, "sample_count": 7, "duration_seconds": 0.61}, "timestamp": "2026-01-11T13:27:20.708562"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1145.397, "latencies_ms": [1145.397], "images_per_second": 0.873, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "woman: 2\nchair: 1\nplate: 1\nfood: 1\nsandwich: 1\nrocks: 2\nground: 1\nlog: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.48, 40.62, 40.62, 40.62, 40.62, 40.62, 42.23, 42.23, 42.23, 42.23, 42.23, 44.11], "power_watts_avg": 42.57, "power_watts_peak": 52.48, "energy_joules_est": 48.77, "sample_count": 12, "duration_seconds": 1.146}, "timestamp": "2026-01-11T13:27:21.921154"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1030.735, "latencies_ms": [1030.735], "images_per_second": 0.97, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The woman is seated in a chair, eating a sandwich. The sandwich is positioned in the foreground, close to the woman. The chair is situated in the background, slightly out of focus. The scene appears to be outdoors, near a fire pit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.11, 44.11, 44.11, 44.11, 43.05, 43.05, 43.05, 43.05, 43.05, 42.95, 42.95], "power_watts_avg": 43.42, "power_watts_peak": 44.11, "energy_joules_est": 44.77, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-11T13:27:23.028528"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 815.978, "latencies_ms": [815.978], "images_per_second": 1.226, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A woman is sitting outdoors, eating a sandwich and chips. She is surrounded by rocks and a dark area, suggesting an outdoor camping or picnic setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.95, 42.95, 40.91, 40.91, 40.91, 40.91, 40.91, 42.65, 42.65], "power_watts_avg": 41.75, "power_watts_peak": 42.95, "energy_joules_est": 34.1, "sample_count": 9, "duration_seconds": 0.817}, "timestamp": "2026-01-11T13:27:23.938054"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 993.47, "latencies_ms": [993.47], "images_per_second": 1.007, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The woman is wearing a green and white striped shirt. The scene is dimly lit, suggesting nighttime. The food appears to be fried and possibly served on a paper plate. The ground is dark and appears to be dirt or soil.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.65, 42.65, 42.65, 44.07, 44.07, 44.07, 44.07, 44.07, 42.47, 42.47], "power_watts_avg": 43.32, "power_watts_peak": 44.07, "energy_joules_est": 43.05, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-11T13:27:24.948514"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 766.738, "latencies_ms": [766.738], "images_per_second": 1.304, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A large family is gathered around a dining table, sharing a meal of roasted vegetables, bread, and wine in a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13064.0, "ram_available_mb": 109442.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.47, 42.47, 42.47, 43.68, 43.68, 43.68, 43.68, 43.68], "power_watts_avg": 43.22, "power_watts_peak": 43.68, "energy_joules_est": 33.15, "sample_count": 8, "duration_seconds": 0.767}, "timestamp": "2026-01-11T13:27:25.759716"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1425.267, "latencies_ms": [1425.267], "images_per_second": 0.702, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "table: 8\nplates: 8\nserving dishes: 8\nglasses: 4\nwine glasses: 2\ncutlery: 2\nchairs: 2\npeople: 10\npictures: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.6, "ram_available_mb": 109442.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 43.34, 43.34, 43.34, 43.07, 43.07, 43.07, 43.07, 43.07, 43.06, 43.06, 43.06, 43.06, 43.06], "power_watts_avg": 43.16, "power_watts_peak": 43.34, "energy_joules_est": 61.53, "sample_count": 15, "duration_seconds": 1.426}, "timestamp": "2026-01-11T13:27:27.272843"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1273.753, "latencies_ms": [1273.753], "images_per_second": 0.785, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal line across the image, creating a sense of depth and perspective. The foreground is dominated by the table and plates, while the background features the dining room and additional people. The table occupies the central portion of the image, drawing the viewer's eye towards the gathering.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.04, 33.04, 33.04, 33.04, 33.04, 42.41, 42.41, 42.41, 42.41, 42.41, 42.88, 42.88, 42.88], "power_watts_avg": 38.91, "power_watts_peak": 42.88, "energy_joules_est": 49.59, "sample_count": 13, "duration_seconds": 1.274}, "timestamp": "2026-01-11T13:27:28.585640"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1041.453, "latencies_ms": [1041.453], "images_per_second": 0.96, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A large family is gathered around a dining table, enjoying a meal together. The setting appears to be a home, with various dishes, glasses, and utensils spread across the table. The atmosphere is warm and inviting, typical of a family gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 38.83, 38.83, 38.83, 38.83, 38.83, 43.32, 43.32, 43.32, 43.32], "power_watts_avg": 41.2, "power_watts_peak": 43.32, "energy_joules_est": 42.93, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:27:29.696529"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1426.266, "latencies_ms": [1426.266], "images_per_second": 0.701, "prompt_tokens": 18, "response_tokens_est": 70, "n_tiles": 1, "output_text": "The table is covered with a purple tablecloth. The lighting is warm and inviting, creating a cozy atmosphere. The table is adorned with plates, bowls, cups, wine glasses, and cutlery, showcasing a variety of colors and materials. The scene appears to be set during a festive gathering, with people seated around the table enjoying a meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.5, "ram_available_mb": 109442.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.32, 36.67, 36.67, 36.67, 36.67, 36.67, 42.92, 42.92, 42.92, 42.92, 42.92, 44.23, 44.23, 44.23, 44.23], "power_watts_avg": 41.21, "power_watts_peak": 44.23, "energy_joules_est": 58.79, "sample_count": 15, "duration_seconds": 1.427}, "timestamp": "2026-01-11T13:27:31.209410"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 690.141, "latencies_ms": [690.141], "images_per_second": 1.449, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A baseball player slides into home plate, attempting to reach a base while another player attempts to tag him out.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.23, 31.96, 31.96, 31.96, 31.96, 31.96, 42.17], "power_watts_avg": 35.17, "power_watts_peak": 44.23, "energy_joules_est": 24.29, "sample_count": 7, "duration_seconds": 0.691}, "timestamp": "2026-01-11T13:27:31.918013"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1952.569, "latencies_ms": [1952.569], "images_per_second": 0.512, "prompt_tokens": 21, "response_tokens_est": 62, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball: 1\nbaseball diamond: 4\nbaseball field: 4\nbaseball player: 2\nbaseball umpire: 1\nbaseball umpire: 1\nbaseball umpire: 1\nbaseball umpire: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.17, 42.17, 42.17, 42.17, 52.79, 52.79, 52.79, 52.79, 52.79, 43.05, 43.05, 43.05, 43.05, 43.05, 33.75, 33.75, 33.75, 33.75, 33.75, 33.74], "power_watts_avg": 42.52, "power_watts_peak": 52.79, "energy_joules_est": 83.03, "sample_count": 20, "duration_seconds": 1.953}, "timestamp": "2026-01-11T13:27:33.931671"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 919.403, "latencies_ms": [919.403], "images_per_second": 1.088, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, sliding into the base. The catcher is standing in the background, watching the play. The field extends beyond the immediate action, appearing distant and open.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.74, 33.74, 33.74, 41.91, 41.91, 41.91, 41.91, 41.91, 41.87, 41.87], "power_watts_avg": 39.45, "power_watts_peak": 41.91, "energy_joules_est": 36.29, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-11T13:27:34.992068"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1038.191, "latencies_ms": [1038.191], "images_per_second": 0.963, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter is sliding into home plate, while a catcher and other players are positioned around the field. Spectators are visible in the stands, watching the game unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.87, 41.87, 41.87, 42.64, 42.64, 42.64, 42.64, 42.64, 42.47, 42.47, 42.47], "power_watts_avg": 42.38, "power_watts_peak": 42.64, "energy_joules_est": 44.03, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-11T13:27:36.103665"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1055.532, "latencies_ms": [1055.532], "images_per_second": 0.947, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The field is predominantly green, lit by sunlight, giving it a vibrant appearance. The infield dirt is reddish-brown, contrasting with the green outfield grass. The scene captures a dynamic moment during a baseball game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.47, 42.47, 38.55, 38.55, 38.55, 38.55, 38.55, 42.7, 42.7, 42.7, 42.7], "power_watts_avg": 40.77, "power_watts_peak": 42.7, "energy_joules_est": 43.06, "sample_count": 11, "duration_seconds": 1.056}, "timestamp": "2026-01-11T13:27:37.214474"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 767.413, "latencies_ms": [767.413], "images_per_second": 1.303, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A skateboarder in black attire and helmet is performing a trick mid-air on a concrete ramp, surrounded by trees and grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.7, 37.82, 37.82, 37.82, 37.82, 37.82, 44.05, 44.05], "power_watts_avg": 39.99, "power_watts_peak": 44.05, "energy_joules_est": 30.71, "sample_count": 8, "duration_seconds": 0.768}, "timestamp": "2026-01-11T13:27:38.025600"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1492.11, "latencies_ms": [1492.11], "images_per_second": 0.67, "prompt_tokens": 21, "response_tokens_est": 48, "n_tiles": 1, "output_text": "helmet: 1\nknee pads: 2\nelbow pads: 1\nshin guards: 1\nskateboard: 1\nfence: 1\nconcrete ramp: 1\ntrees: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13063.4, "ram_available_mb": 109442.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.05, 44.05, 44.05, 53.36, 53.36, 53.36, 53.36, 53.36, 44.47, 44.47, 44.47, 44.47, 36.4, 36.4, 36.4], "power_watts_avg": 45.73, "power_watts_peak": 53.36, "energy_joules_est": 68.26, "sample_count": 15, "duration_seconds": 1.493}, "timestamp": "2026-01-11T13:27:39.538848"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1155.74, "latencies_ms": [1155.74], "images_per_second": 0.865, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a concrete ramp. The skateboarder's shadow is cast onto the ramp's surface. The background features a grassy area and trees, suggesting an outdoor skatepark setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13063.3, "ram_available_mb": 109443.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.4, 36.4, 41.75, 41.75, 41.75, 41.75, 41.75, 44.74, 44.74, 44.74, 44.74, 44.74], "power_watts_avg": 42.1, "power_watts_peak": 44.74, "energy_joules_est": 48.68, "sample_count": 12, "duration_seconds": 1.156}, "timestamp": "2026-01-11T13:27:40.750245"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 903.558, "latencies_ms": [903.558], "images_per_second": 1.107, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A skateboarder is performing a trick on a concrete ramp in a skate park. The skate park is surrounded by trees and grass, creating a natural and urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.8, "ram_available_mb": 109442.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.44, 37.44, 37.44, 37.44, 37.44, 44.38, 44.38, 44.38, 44.38], "power_watts_avg": 40.53, "power_watts_peak": 44.38, "energy_joules_est": 36.63, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:27:41.658326"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1026.291, "latencies_ms": [1026.291], "images_per_second": 0.974, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The skateboarder is wearing a black helmet, black shirt, and black knee pads. The scene appears to be outdoors on a sunny day, with natural lighting illuminating the skateboarder's shadow on the concrete ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.6, "ram_available_mb": 109440.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.0, "ram_available_mb": 109440.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.38, 46.82, 46.82, 46.82, 46.82, 46.82, 45.26, 45.26, 45.26, 45.26, 45.26], "power_watts_avg": 45.89, "power_watts_peak": 46.82, "energy_joules_est": 47.11, "sample_count": 11, "duration_seconds": 1.027}, "timestamp": "2026-01-11T13:27:42.769634"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1216.487, "latencies_ms": [1216.487], "images_per_second": 0.822, "prompt_tokens": 8, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A neatly arranged meal consisting of french fries, a burger, tomato, pickle, coleslaw, lemon wedges, and condiments is presented on two white plates, accompanied by a glass of soda and a salt and pepper shaker.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13066.0, "ram_available_mb": 109440.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.9, 42.9, 42.9, 42.9, 42.9, 42.64, 42.64, 42.64, 42.64, 42.64, 43.24, 43.24, 43.24], "power_watts_avg": 42.88, "power_watts_peak": 43.24, "energy_joules_est": 52.19, "sample_count": 13, "duration_seconds": 1.217}, "timestamp": "2026-01-11T13:27:44.083140"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1516.241, "latencies_ms": [1516.241], "images_per_second": 0.66, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "fries: 10\nbun: 2\nham patty: 1\ntomato: 2\npickle: 1\ncoleslaw: 1\nmayo: 1\nlemon: 1\nsalt and pepper shakers: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 38.03, 38.03, 38.03, 38.03, 38.03, 42.17, 42.17, 42.17, 42.17, 42.17, 37.6, 37.6, 37.6, 37.6], "power_watts_avg": 39.87, "power_watts_peak": 43.24, "energy_joules_est": 60.46, "sample_count": 16, "duration_seconds": 1.517}, "timestamp": "2026-01-11T13:27:45.698391"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1147.229, "latencies_ms": [1147.229], "images_per_second": 0.872, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of balance and visual flow. The foreground features the burger, fries, and pickle, while the background includes additional plates and condiments. The arrangement suggests a well-planned and organized meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13066.5, "ram_available_mb": 109439.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.6, 32.79, 32.79, 32.79, 32.79, 32.79, 42.01, 42.01, 42.01, 42.01, 42.01, 44.02], "power_watts_avg": 37.97, "power_watts_peak": 44.02, "energy_joules_est": 43.58, "sample_count": 12, "duration_seconds": 1.148}, "timestamp": "2026-01-11T13:27:46.908774"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1000.958, "latencies_ms": [1000.958], "images_per_second": 0.999, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a hotel room meal featuring a burger, fries, tomato salad, pickle, coleslaw, lemon wedges, and condiments on a tray. A glass of beer is also present.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.02, 44.02, 44.02, 44.02, 42.91, 42.91, 42.91, 42.91, 42.91, 43.34], "power_watts_avg": 43.4, "power_watts_peak": 44.02, "energy_joules_est": 43.46, "sample_count": 10, "duration_seconds": 1.001}, "timestamp": "2026-01-11T13:27:47.919494"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1478.998, "latencies_ms": [1478.998], "images_per_second": 0.676, "prompt_tokens": 18, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The food items display vibrant colors, including golden french fries, fresh tomatoes, and creamy coleslaw. The lighting is soft and warm, enhancing the visual appeal of the meal. The food appears to be served on white plates, placed on a gray tablecloth. The overall presentation suggests a well-prepared and appetizing meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 43.34, 43.34, 44.33, 44.33, 44.33, 44.33, 44.33, 44.27, 44.27, 44.27, 44.27, 44.27, 33.88], "power_watts_avg": 43.35, "power_watts_peak": 44.33, "energy_joules_est": 64.14, "sample_count": 15, "duration_seconds": 1.48}, "timestamp": "2026-01-11T13:27:49.433540"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 587.344, "latencies_ms": [587.344], "images_per_second": 1.703, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A red motorcycle is parked on the side of a road near a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [33.88, 33.88, 33.88, 43.54, 43.54, 43.54], "power_watts_avg": 38.71, "power_watts_peak": 43.54, "energy_joules_est": 22.75, "sample_count": 6, "duration_seconds": 0.588}, "timestamp": "2026-01-11T13:27:50.044008"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1069.877, "latencies_ms": [1069.877], "images_per_second": 0.935, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "motorcycle: 1\npalm trees: 3\nbeach: 2\nsand: 2\nfence: 1\nsky: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.4, "ram_available_mb": 109441.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 52.43, 52.43, 52.43, 52.43, 52.43, 44.27, 44.27, 44.27, 44.27], "power_watts_avg": 47.84, "power_watts_peak": 52.43, "energy_joules_est": 51.2, "sample_count": 11, "duration_seconds": 1.07}, "timestamp": "2026-01-11T13:27:51.155498"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1039.47, "latencies_ms": [1039.47], "images_per_second": 0.962, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The motorcycle is positioned in the foreground, facing the left side of the image. The beach and palm trees are in the background, extending from the left to the right of the motorcycle. The motorcycle is parked near the edge of the road, suggesting it is relatively close to the beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.27, 38.28, 38.28, 38.28, 38.28, 38.28, 43.71, 43.71, 43.71, 43.71, 43.71], "power_watts_avg": 41.29, "power_watts_peak": 44.27, "energy_joules_est": 42.95, "sample_count": 11, "duration_seconds": 1.04}, "timestamp": "2026-01-11T13:27:52.265528"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 900.009, "latencies_ms": [900.009], "images_per_second": 1.111, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A red Harley Davidson motorcycle is parked on a paved area near a beach with palm trees and a wooden fence in the background. The scene suggests a sunny, tropical beach setting.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.3, 41.3, 41.3, 41.3, 41.3, 42.49, 42.49, 42.49, 42.49], "power_watts_avg": 41.83, "power_watts_peak": 42.49, "energy_joules_est": 37.66, "sample_count": 9, "duration_seconds": 0.9}, "timestamp": "2026-01-11T13:27:53.173941"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 850.922, "latencies_ms": [850.922], "images_per_second": 1.175, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The motorcycle is red and appears to be made of chrome or stainless steel. The lighting suggests a sunny day, and the sandy beach and palm trees create a tropical ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.49, 45.5, 45.5, 45.5, 45.5, 45.5, 43.98, 43.98, 43.98], "power_watts_avg": 44.66, "power_watts_peak": 45.5, "energy_joules_est": 38.01, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-11T13:27:54.083635"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 594.248, "latencies_ms": [594.248], "images_per_second": 1.683, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is elegantly dressed in a black suit with a white shirt and a patterned black tie.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13064.3, "ram_available_mb": 109442.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13064.6, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.98, 43.98, 48.0, 48.0, 48.0, 48.0], "power_watts_avg": 46.66, "power_watts_peak": 48.0, "energy_joules_est": 27.76, "sample_count": 6, "duration_seconds": 0.595}, "timestamp": "2026-01-11T13:27:54.693926"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1056.314, "latencies_ms": [1056.314], "images_per_second": 0.947, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "suit: 2\ntie: 1\nshirt: 1\njacket: 1\nvest: 1\npocket: 1\nlight switch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13064.5, "ram_available_mb": 109441.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [48.0, 43.81, 43.81, 43.81, 43.81, 43.81, 47.39, 47.39, 47.39, 47.39, 47.39], "power_watts_avg": 45.82, "power_watts_peak": 48.0, "energy_joules_est": 48.42, "sample_count": 11, "duration_seconds": 1.057}, "timestamp": "2026-01-11T13:27:55.806843"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 797.942, "latencies_ms": [797.942], "images_per_second": 1.253, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the suit and tie slightly behind him. The background is dark and out of focus, drawing attention to the man's attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.33, 44.33, 44.33, 44.33, 44.33, 43.29, 43.29, 43.29], "power_watts_avg": 43.94, "power_watts_peak": 44.33, "energy_joules_est": 35.08, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:27:56.616964"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 876.235, "latencies_ms": [876.235], "images_per_second": 1.141, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is dressed in a formal black suit and tie, standing in a dimly lit room, possibly a hotel or event venue. The setting suggests a professional or formal occasion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [43.29, 43.29, 48.27, 48.27, 48.27, 48.27, 48.27, 43.78, 43.78], "power_watts_avg": 46.17, "power_watts_peak": 48.27, "energy_joules_est": 40.48, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-11T13:27:57.525609"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1023.558, "latencies_ms": [1023.558], "images_per_second": 0.977, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The suit is primarily dark gray or black. The lighting in the image is soft and subdued, creating a calm atmosphere. The material appears to be smooth, possibly silk or a similar fabric. The weather is not explicitly visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 47.73, 47.73, 47.73, 47.73, 47.73, 43.38, 43.38, 43.38], "power_watts_avg": 45.47, "power_watts_peak": 47.73, "energy_joules_est": 46.57, "sample_count": 11, "duration_seconds": 1.024}, "timestamp": "2026-01-11T13:27:58.637718"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 658.786, "latencies_ms": [658.786], "images_per_second": 1.518, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A gray and white cat is peacefully sleeping on a pair of sneakers, curled up with its eyes closed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 21.0}, "power_stats": {"power_watts_samples": [43.38, 37.33, 37.33, 37.33, 37.33, 37.33, 42.46], "power_watts_avg": 38.93, "power_watts_peak": 43.38, "energy_joules_est": 25.67, "sample_count": 7, "duration_seconds": 0.659}, "timestamp": "2026-01-11T13:27:59.346626"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1177.07, "latencies_ms": [1177.07], "images_per_second": 0.85, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "shoe: 2\ncat: 1\nwall: 1\nsneaker: 1\nshoe laces: 1\nshoe sole: 1\nconverse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 42.46, 42.46, 50.15, 50.15, 50.15, 50.15, 50.15, 43.28, 43.28, 43.28], "power_watts_avg": 45.87, "power_watts_peak": 50.15, "energy_joules_est": 54.02, "sample_count": 12, "duration_seconds": 1.178}, "timestamp": "2026-01-11T13:28:00.557924"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 775.137, "latencies_ms": [775.137], "images_per_second": 1.29, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cat is positioned close to the foreground shoe, partially covering it. The shoe is situated near the background wall, providing a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13065.3, "ram_available_mb": 109441.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 40.79, 40.79, 40.79, 40.79, 40.79, 43.27], "power_watts_avg": 41.72, "power_watts_peak": 43.28, "energy_joules_est": 32.36, "sample_count": 8, "duration_seconds": 0.776}, "timestamp": "2026-01-11T13:28:01.366323"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 745.05, "latencies_ms": [745.05], "images_per_second": 1.342, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A cat is sleeping peacefully on a pair of sneakers placed against a textured wall. The scene takes place indoors, likely on a hardwood floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 43.27, 43.27, 45.99, 45.99, 45.99, 45.99], "power_watts_avg": 44.63, "power_watts_peak": 45.99, "energy_joules_est": 33.29, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-11T13:28:02.176639"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1306.519, "latencies_ms": [1306.519], "images_per_second": 0.765, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The cat is sleeping next to a pair of sneakers. The sneakers are primarily light blue and white. The lighting appears to be soft and diffused, suggesting an indoor setting. The cat's fur is predominantly gray and white, and the sneakers appear to be made of canvas or a similar material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13060.3, "ram_available_mb": 109446.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.99, 44.78, 44.78, 44.78, 44.78, 44.78, 42.05, 42.05, 42.05, 42.05, 42.05, 41.89, 41.89], "power_watts_avg": 43.38, "power_watts_peak": 45.99, "energy_joules_est": 56.7, "sample_count": 13, "duration_seconds": 1.307}, "timestamp": "2026-01-11T13:28:03.489610"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 805.372, "latencies_ms": [805.372], "images_per_second": 1.242, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two workers in safety vests and hard hats are standing on top of a green Isuzu dump truck parked on the side of a city street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.3, "ram_available_mb": 109446.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.89, 41.89, 41.89, 43.99, 43.99, 43.99, 43.99, 43.99, 44.1], "power_watts_avg": 43.3, "power_watts_peak": 44.1, "energy_joules_est": 34.89, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-11T13:28:04.400447"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1208.668, "latencies_ms": [1208.668], "images_per_second": 0.827, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Truck: 2\nMan: 2\nWoman: 1\nHat: 1\nVest: 1\nBus: 1\nBuilding: 1\nTrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.5, "ram_available_mb": 109445.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.8, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [44.1, 44.1, 44.1, 44.1, 42.08, 42.08, 42.08, 42.08, 42.08, 42.48, 42.48, 42.48, 42.48], "power_watts_avg": 42.83, "power_watts_peak": 44.1, "energy_joules_est": 51.79, "sample_count": 13, "duration_seconds": 1.209}, "timestamp": "2026-01-11T13:28:05.709736"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1078.539, "latencies_ms": [1078.539], "images_per_second": 0.927, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object is a green Isuzu dump truck parked on the street. The truck is positioned in the foreground, with a person standing near its front. The background includes other vehicles, buildings, and trees, indicating an urban setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.48, 32.3, 32.3, 32.3, 32.3, 32.3, 42.12, 42.12, 42.12, 42.12, 42.12], "power_watts_avg": 37.69, "power_watts_peak": 42.48, "energy_joules_est": 40.67, "sample_count": 11, "duration_seconds": 1.079}, "timestamp": "2026-01-11T13:28:06.820303"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1197.005, "latencies_ms": [1197.005], "images_per_second": 0.835, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a green Isuzu dump truck driving down a city street. Two workers in green uniforms are visible on the truck, one sitting on the back and the other standing near the front. The truck has various signs and markings, including one in Thai script.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.7, "ram_available_mb": 109445.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.64, 43.64, 43.64, 43.64, 43.64, 43.45, 43.45, 43.45, 43.45, 43.45, 43.67, 43.67], "power_watts_avg": 43.57, "power_watts_peak": 43.67, "energy_joules_est": 52.17, "sample_count": 12, "duration_seconds": 1.198}, "timestamp": "2026-01-11T13:28:08.031201"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 992.609, "latencies_ms": [992.609], "images_per_second": 1.007, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The truck is predominantly green with red and white stripes on the front. The truck has blue headlights and orange reflective stripes on the sides. The truck is parked on a city street with buildings in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.67, 43.67, 43.67, 42.49, 42.49, 42.49, 42.49, 43.77, 43.77, 43.77], "power_watts_avg": 43.23, "power_watts_peak": 43.77, "energy_joules_est": 42.93, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-11T13:28:09.043579"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 588.918, "latencies_ms": [588.918], "images_per_second": 1.698, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A large bird, possibly a crane or heron, stands prominently in the shallow waters of a river, surrounded by rocks and vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 39.91, 39.91, 39.91, 39.91], "power_watts_avg": 41.2, "power_watts_peak": 43.77, "energy_joules_est": 24.27, "sample_count": 6, "duration_seconds": 0.589}, "timestamp": "2026-01-11T13:28:09.654704"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1130.816, "latencies_ms": [1130.816], "images_per_second": 0.884, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "River: 10\nRocks: 20\nBird: 1\nBridge: 2\nTrees: 3\nVegetation: 4\nWater: 5\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.91, 40.7, 40.7, 40.7, 40.7, 40.7, 38.49, 38.49, 38.49, 38.49, 38.49, 35.73], "power_watts_avg": 39.3, "power_watts_peak": 40.7, "energy_joules_est": 44.45, "sample_count": 12, "duration_seconds": 1.131}, "timestamp": "2026-01-11T13:28:10.864496"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 662.665, "latencies_ms": [662.665], "images_per_second": 1.509, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The large rock formation is positioned in the foreground, partially obscuring the view of the river. The river extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.73, 35.73, 35.73, 35.73, 37.47, 37.47, 37.47], "power_watts_avg": 36.47, "power_watts_peak": 37.47, "energy_joules_est": 24.19, "sample_count": 7, "duration_seconds": 0.663}, "timestamp": "2026-01-11T13:28:11.572563"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1030.719, "latencies_ms": [1030.719], "images_per_second": 0.97, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a riverbank with scattered rocks and patches of green vegetation. A bird, possibly a heron, is standing on the rocks near the water's edge. A bridge is visible in the background, suggesting the river is near a populated area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [37.47, 37.47, 41.66, 41.66, 41.66, 41.66, 41.66, 38.11, 38.11, 38.11, 38.11], "power_watts_avg": 39.61, "power_watts_peak": 41.66, "energy_joules_est": 40.84, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-11T13:28:12.682751"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 538.718, "latencies_ms": [538.718], "images_per_second": 1.856, "prompt_tokens": 18, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The river is clear and blue. The lighting suggests a sunny day. The riverbed is rocky and uneven.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 28.0}, "power_stats": {"power_watts_samples": [38.11, 34.43, 34.43, 34.43, 34.43, 34.43], "power_watts_avg": 35.04, "power_watts_peak": 38.11, "energy_joules_est": 18.89, "sample_count": 6, "duration_seconds": 0.539}, "timestamp": "2026-01-11T13:28:13.290032"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 756.252, "latencies_ms": [756.252], "images_per_second": 1.322, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A row of parked motor scooters in various colors lines the sidewalk in front of a red-awning bar and restaurant, with people walking by.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.21, 37.21, 37.21, 37.21, 37.21, 46.06, 46.06, 46.06], "power_watts_avg": 40.53, "power_watts_peak": 46.06, "energy_joules_est": 30.69, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:28:14.102295"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1015.17, "latencies_ms": [1015.17], "images_per_second": 0.985, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "building: 5\nscooters: 10\nbar: 1\nstreet: 2\nsigns: 3\npeople: 2\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13061.6, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.06, 46.06, 48.78, 48.78, 48.78, 48.78, 48.78, 43.3, 43.3, 43.3, 43.3], "power_watts_avg": 46.29, "power_watts_peak": 48.78, "energy_joules_est": 47.01, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-11T13:28:15.213517"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1133.717, "latencies_ms": [1133.717], "images_per_second": 0.882, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scooters are parked along the left side of the image, occupying the foreground. The background features buildings with storefronts and awnings, extending into the distance. The scooters appear relatively close together, suggesting they are parked in a designated area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13061.6, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.3, 36.25, 36.25, 36.25, 36.25, 36.25, 42.67, 42.67, 42.67, 42.67, 42.67, 44.31], "power_watts_avg": 40.18, "power_watts_peak": 44.31, "energy_joules_est": 45.58, "sample_count": 12, "duration_seconds": 1.134}, "timestamp": "2026-01-11T13:28:16.426443"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1042.494, "latencies_ms": [1042.494], "images_per_second": 0.959, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene is set on a busy street in Paris, France, showcasing a row of parked motor scooters lined up in front of a bar with a red awning. The atmosphere is vibrant, with people walking around and engaging in various activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [44.31, 44.31, 44.31, 44.31, 42.96, 42.96, 42.96, 42.96, 42.96, 42.63, 42.63], "power_watts_avg": 43.39, "power_watts_peak": 44.31, "energy_joules_est": 45.26, "sample_count": 11, "duration_seconds": 1.043}, "timestamp": "2026-01-11T13:28:17.539266"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1176.84, "latencies_ms": [1176.84], "images_per_second": 0.85, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene is dominated by vibrant colors, particularly red and green from the storefront awnings and parked motorcycles. The lighting appears to be natural daylight, creating a pleasant atmosphere. The buildings are constructed of stone, giving a classic and timeless feel to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.63, 42.63, 41.77, 41.77, 41.77, 41.77, 41.77, 42.98, 42.98, 42.98, 42.98, 42.98], "power_watts_avg": 42.42, "power_watts_peak": 42.98, "energy_joules_est": 49.93, "sample_count": 12, "duration_seconds": 1.177}, "timestamp": "2026-01-11T13:28:18.748855"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 571.516, "latencies_ms": [571.516], "images_per_second": 1.75, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A person's hand is holding a piece of broccoli with a brown, dried insect perched on top.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.32, 35.32, 35.32, 35.32, 35.32, 43.45], "power_watts_avg": 36.67, "power_watts_peak": 43.45, "energy_joules_est": 20.98, "sample_count": 6, "duration_seconds": 0.572}, "timestamp": "2026-01-11T13:28:19.358955"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1236.585, "latencies_ms": [1236.585], "images_per_second": 0.809, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Broccoli: 2\nCaterpillar: 1\nBroccoli florets: 10\nHuman finger: 2\nCountertop: 1\nWall: 1\nStove top: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 43.45, 43.45, 53.21, 53.21, 53.21, 53.21, 53.21, 43.51, 43.51, 43.51, 43.51], "power_watts_avg": 47.22, "power_watts_peak": 53.21, "energy_joules_est": 58.4, "sample_count": 13, "duration_seconds": 1.237}, "timestamp": "2026-01-11T13:28:20.671851"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 876.029, "latencies_ms": [876.029], "images_per_second": 1.142, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The broccoli is held in the foreground, partially obscuring the background. The hand holding the broccoli is positioned near the center, suggesting the photo was taken from a relatively close distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 19.0}, "power_stats": {"power_watts_samples": [43.51, 34.85, 34.85, 34.85, 34.85, 34.85, 42.75, 42.75, 42.75], "power_watts_avg": 38.44, "power_watts_peak": 43.51, "energy_joules_est": 33.7, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-11T13:28:21.580394"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 890.082, "latencies_ms": [890.082], "images_per_second": 1.123, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A person is holding a piece of broccoli with a brown insect, possibly a caterpillar, perched on it. The scene appears to be set in a kitchen or dining area, with a tiled wall visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.1, "ram_available_mb": 109444.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [42.75, 42.75, 49.37, 49.37, 49.37, 49.37, 49.37, 43.29, 43.29], "power_watts_avg": 46.55, "power_watts_peak": 49.37, "energy_joules_est": 41.44, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:28:22.488779"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 848.343, "latencies_ms": [848.343], "images_per_second": 1.179, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The broccoli is predominantly green and has a slightly browned stem. The lighting appears to be natural, possibly from sunlight, and the material appears to be fresh and likely a leafy vegetable.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.29, 43.29, 43.29, 46.76, 46.76, 46.76, 46.76, 46.76, 43.65], "power_watts_avg": 45.26, "power_watts_peak": 46.76, "energy_joules_est": 38.44, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:28:23.396103"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 700.267, "latencies_ms": [700.267], "images_per_second": 1.428, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two people are standing close together, one wearing a black hooded jacket and the other wearing a black jacket with a fur hood, both with their faces partially covered.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 43.65, 43.65, 42.88, 42.88, 42.88], "power_watts_avg": 43.32, "power_watts_peak": 43.65, "energy_joules_est": 30.36, "sample_count": 7, "duration_seconds": 0.701}, "timestamp": "2026-01-11T13:28:24.107148"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1025.607, "latencies_ms": [1025.607], "images_per_second": 0.975, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "woman: 2\nman: 2\nhood: 2\njacket: 2\nhair: 2\nface: 2\nfood: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 49.17, 49.17, 49.17, 49.17, 49.17, 43.75, 43.75, 43.75, 43.75], "power_watts_avg": 46.06, "power_watts_peak": 49.17, "energy_joules_est": 47.26, "sample_count": 11, "duration_seconds": 1.026}, "timestamp": "2026-01-11T13:28:25.218950"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 734.398, "latencies_ms": [734.398], "images_per_second": 1.362, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, partially obscured by the man's hood. The man is situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.75, 36.04, 36.04, 36.04, 36.04, 36.04, 42.36, 42.36], "power_watts_avg": 38.59, "power_watts_peak": 43.75, "energy_joules_est": 28.37, "sample_count": 8, "duration_seconds": 0.735}, "timestamp": "2026-01-11T13:28:26.028494"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1029.161, "latencies_ms": [1029.161], "images_per_second": 0.972, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "Two people are in a dimly lit setting, possibly a cafe or restaurant. They are wearing warm clothing and appear to be enjoying themselves, with one person making a surprised or excited facial expression while the other is partially obscured by the hood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.36, 42.36, 42.36, 51.65, 51.65, 51.65, 51.65, 51.65, 42.52, 42.52, 42.52], "power_watts_avg": 46.63, "power_watts_peak": 51.65, "energy_joules_est": 48.01, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-11T13:28:27.141916"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 992.108, "latencies_ms": [992.108], "images_per_second": 1.008, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The woman is wearing a black hooded coat, and the lighting is bright, likely from artificial sources. The coat appears to be made of a thick, possibly waterproof material. The background is blurry, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.52, 36.99, 36.99, 36.99, 36.99, 36.99, 42.31, 42.31, 42.31, 42.31], "power_watts_avg": 39.67, "power_watts_peak": 42.52, "energy_joules_est": 39.38, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-11T13:28:28.153867"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 803.248, "latencies_ms": [803.248], "images_per_second": 1.245, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A male tennis player, dressed in white and black, is poised to strike a yellow tennis ball with a racket on a blue tennis court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.31, 43.72, 43.72, 43.72, 43.72, 43.72, 43.84, 43.84], "power_watts_avg": 43.57, "power_watts_peak": 43.84, "energy_joules_est": 35.02, "sample_count": 8, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:28:28.965918"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1242.509, "latencies_ms": [1242.509], "images_per_second": 0.805, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "man: 1\ntennis racket: 1\ntennis ball: 1\ntennis shoes: 2\ntennis court: 2\nchairs: 10\ngreen surface: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.84, 43.84, 43.84, 51.11, 51.11, 51.11, 51.11, 51.11, 43.71, 43.71, 43.71, 43.71, 43.71], "power_watts_avg": 46.58, "power_watts_peak": 51.11, "energy_joules_est": 57.9, "sample_count": 13, "duration_seconds": 1.243}, "timestamp": "2026-01-11T13:28:30.280434"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1018.497, "latencies_ms": [1018.497], "images_per_second": 0.982, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The tennis player is positioned on the left side of the image, facing towards the right. The tennis ball is in the foreground, slightly to the right of the player. The tennis court is situated in the background, extending beyond the player and ball.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13062.0, "ram_available_mb": 109444.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.21, 33.21, 33.21, 33.21, 33.21, 42.58, 42.58, 42.58, 42.58, 42.58, 43.14], "power_watts_avg": 38.38, "power_watts_peak": 43.14, "energy_joules_est": 39.11, "sample_count": 11, "duration_seconds": 1.019}, "timestamp": "2026-01-11T13:28:31.393941"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1005.344, "latencies_ms": [1005.344], "images_per_second": 0.995, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A man is playing tennis on a blue court, poised to hit a yellow tennis ball. He is wearing a white shirt, black shorts, and white shoes. Empty white folding chairs are visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 43.14, 43.14, 42.07, 42.07, 42.07, 42.07, 42.07, 41.88, 41.88], "power_watts_avg": 42.42, "power_watts_peak": 43.14, "energy_joules_est": 42.66, "sample_count": 11, "duration_seconds": 1.006}, "timestamp": "2026-01-11T13:28:32.503456"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 956.315, "latencies_ms": [956.315], "images_per_second": 1.046, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The tennis court is painted in vibrant blue. The lighting appears to be bright and sunny, illuminating the scene effectively. The materials used are likely durable and suitable for the outdoor tennis setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.9, "ram_available_mb": 109444.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.88, 41.88, 41.88, 42.08, 42.08, 42.08, 42.08, 42.08, 41.99, 41.99], "power_watts_avg": 42.0, "power_watts_peak": 42.08, "energy_joules_est": 40.18, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:28:33.513276"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 668.762, "latencies_ms": [668.762], "images_per_second": 1.495, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A tall, ornate vase with an etched design of a woman is prominently displayed on a reflective surface, accompanied by a lit candle and string lights in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 38.26, 38.26, 38.26, 38.26], "power_watts_avg": 39.86, "power_watts_peak": 41.99, "energy_joules_est": 26.69, "sample_count": 7, "duration_seconds": 0.67}, "timestamp": "2026-01-11T13:28:34.224800"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1073.894, "latencies_ms": [1073.894], "images_per_second": 0.931, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Vase: 1\nCandle: 1\nString lights: 4\nMirror: 1\nWooden frame: 1\nGlass: 1\nFlower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.26, 36.84, 36.84, 36.84, 36.84, 36.84, 38.28, 38.28, 38.28, 38.28, 38.28], "power_watts_avg": 37.62, "power_watts_peak": 38.28, "energy_joules_est": 40.42, "sample_count": 11, "duration_seconds": 1.074}, "timestamp": "2026-01-11T13:28:35.335762"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 762.863, "latencies_ms": [762.863], "images_per_second": 1.311, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The vase is positioned in the foreground, slightly to the right of the candle. The candle is placed in the background, closer to the viewer. The vase and candle are situated close together, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [39.18, 39.18, 39.18, 39.18, 38.11, 38.11, 38.11, 38.11], "power_watts_avg": 38.64, "power_watts_peak": 39.18, "energy_joules_est": 29.52, "sample_count": 8, "duration_seconds": 0.764}, "timestamp": "2026-01-11T13:28:36.147794"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 823.621, "latencies_ms": [823.621], "images_per_second": 1.214, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene is set on a wooden shelf with a decorative vase containing a painted figure, illuminated by string lights. A white candle is placed next to the vase, enhancing the cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.11, 40.47, 40.47, 40.47, 40.47, 40.47, 37.19, 37.19, 37.19], "power_watts_avg": 39.11, "power_watts_peak": 40.47, "energy_joules_est": 32.24, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-11T13:28:37.059041"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 960.517, "latencies_ms": [960.517], "images_per_second": 1.041, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The vase is primarily a reddish-orange color. The lighting in the scene is warm and inviting, illuminating the vase and the surrounding area. String lights are draped around the shelf, adding a cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.19, 37.19, 38.01, 38.01, 38.01, 38.01, 38.01, 36.97, 36.97, 36.97], "power_watts_avg": 37.53, "power_watts_peak": 38.01, "energy_joules_est": 36.07, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-11T13:28:38.071162"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 666.964, "latencies_ms": [666.964], "images_per_second": 1.499, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man is standing in a room, smiling and leaning forward, while another man stands behind him, holding a camera and possibly directing the photo shoot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.1, "ram_available_mb": 109446.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.97, 36.97, 37.77, 37.77, 37.77, 37.77, 37.77], "power_watts_avg": 37.54, "power_watts_peak": 37.77, "energy_joules_est": 25.06, "sample_count": 7, "duration_seconds": 0.667}, "timestamp": "2026-01-11T13:28:38.782186"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1106.308, "latencies_ms": [1106.308], "images_per_second": 0.904, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "suitcase: 1\ncamera: 1\nlighting stand: 1\nman: 2\ncouch: 1\njacket: 1\nshirt: 1\njeans: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.88, 37.88, 37.88, 37.88, 37.88, 38.1, 38.1, 38.1, 38.1, 38.1, 38.23], "power_watts_avg": 38.01, "power_watts_peak": 38.23, "energy_joules_est": 42.07, "sample_count": 11, "duration_seconds": 1.107}, "timestamp": "2026-01-11T13:28:39.894396"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 542.11, "latencies_ms": [542.11], "images_per_second": 1.845, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The suitcase is positioned in the foreground, close to the camera. The man is standing in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.23, 38.23, 38.23, 38.23, 38.88, 38.88], "power_watts_avg": 38.44, "power_watts_peak": 38.88, "energy_joules_est": 20.85, "sample_count": 6, "duration_seconds": 0.542}, "timestamp": "2026-01-11T13:28:40.501486"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 976.9, "latencies_ms": [976.9], "images_per_second": 1.024, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A man is standing in a room, possibly a studio, preparing for a photoshoot. He is positioned near a tripod and a suitcase, suggesting he might be working on lighting or composition. Another person is visible in the background, possibly a colleague or assistant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [38.88, 38.88, 38.88, 42.83, 42.83, 42.83, 42.83, 42.83, 37.74, 37.74], "power_watts_avg": 40.63, "power_watts_peak": 42.83, "energy_joules_est": 39.7, "sample_count": 10, "duration_seconds": 0.977}, "timestamp": "2026-01-11T13:28:41.511949"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 902.494, "latencies_ms": [902.494], "images_per_second": 1.108, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The room is lit by natural light from a window, creating a warm ambiance. The walls are painted a light color, complementing the wooden floor. The man is wearing a gray sweater and jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [37.74, 37.74, 37.74, 37.75, 37.75, 37.75, 37.75, 37.75, 37.63], "power_watts_avg": 37.73, "power_watts_peak": 37.75, "energy_joules_est": 34.06, "sample_count": 9, "duration_seconds": 0.903}, "timestamp": "2026-01-11T13:28:42.422798"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 747.311, "latencies_ms": [747.311], "images_per_second": 1.338, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a hat and striped tank top smokes a cigarette, smiling warmly as she looks off to the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [37.63, 37.63, 37.63, 37.63, 44.68, 44.68, 44.68, 44.68], "power_watts_avg": 41.16, "power_watts_peak": 44.68, "energy_joules_est": 30.78, "sample_count": 8, "duration_seconds": 0.748}, "timestamp": "2026-01-11T13:28:43.229754"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1127.953, "latencies_ms": [1127.953], "images_per_second": 0.887, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "hat: 1\nwoman: 1\ncigarette: 1\ntie: 1\ntank top: 1\nbracelet: 1\nearrings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.68, 43.46, 43.46, 43.46, 43.46, 43.46, 44.15, 44.15, 44.15, 44.15, 44.15, 45.57], "power_watts_avg": 44.03, "power_watts_peak": 45.57, "energy_joules_est": 49.68, "sample_count": 12, "duration_seconds": 1.128}, "timestamp": "2026-01-11T13:28:44.440656"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 978.87, "latencies_ms": [978.87], "images_per_second": 1.022, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, wearing a hat and tie, which suggests a close proximity to the viewer. The background is relatively plain and distant, further emphasizing the woman's presence in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.57, 45.57, 45.57, 45.57, 43.85, 43.85, 43.85, 43.85, 43.77, 43.77], "power_watts_avg": 44.52, "power_watts_peak": 45.57, "energy_joules_est": 43.61, "sample_count": 10, "duration_seconds": 0.98}, "timestamp": "2026-01-11T13:28:45.451145"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 921.07, "latencies_ms": [921.07], "images_per_second": 1.086, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The black and white image shows a woman wearing a wide-brimmed hat and a striped tank top. She is smiling and holding a cigarette in her mouth, appearing relaxed and enjoying herself.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13054.7, "ram_available_mb": 109451.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 43.77, 44.87, 44.87, 44.87, 44.87, 44.87, 44.78, 44.78], "power_watts_avg": 44.52, "power_watts_peak": 44.87, "energy_joules_est": 41.02, "sample_count": 10, "duration_seconds": 0.921}, "timestamp": "2026-01-11T13:28:46.460483"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1404.059, "latencies_ms": [1404.059], "images_per_second": 0.712, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The woman is wearing a wide-brimmed hat in dark colors. The lighting appears to be soft and diffused, possibly from a natural light source. The hat appears to be made of a lightweight material like felt or linen. The woman is smiling and holding a cigarette, which suggests a relaxed and casual atmosphere.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13054.7, "ram_available_mb": 109451.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13054.7, "ram_available_mb": 109451.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.78, 44.78, 44.78, 43.1, 43.1, 43.1, 43.1, 43.1, 42.65, 42.65, 42.65, 42.65, 42.65, 33.06], "power_watts_avg": 42.59, "power_watts_peak": 44.78, "energy_joules_est": 59.81, "sample_count": 14, "duration_seconds": 1.404}, "timestamp": "2026-01-11T13:28:47.872329"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 595.341, "latencies_ms": [595.341], "images_per_second": 1.68, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a zoo enclosure, surrounded by trees and rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.7, "ram_available_mb": 109451.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.06, 33.06, 33.06, 33.06, 43.72, 43.72], "power_watts_avg": 36.62, "power_watts_peak": 43.72, "energy_joules_est": 21.81, "sample_count": 6, "duration_seconds": 0.596}, "timestamp": "2026-01-11T13:28:48.482037"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1052.187, "latencies_ms": [1052.187], "images_per_second": 0.95, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "zebra: 2\ngrass: 2\nrocks: 2\ntree: 2\nbush: 1\npath: 1\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.72, 43.72, 43.72, 54.22, 54.22, 54.22, 54.22, 54.22, 43.7, 43.7, 43.7], "power_watts_avg": 48.49, "power_watts_peak": 54.22, "energy_joules_est": 51.03, "sample_count": 11, "duration_seconds": 1.052}, "timestamp": "2026-01-11T13:28:49.593616"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 944.095, "latencies_ms": [944.095], "images_per_second": 1.059, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The zebra on the left is positioned closer to the viewer, while the zebra on the right is further away, occupying the foreground. The zebras are situated in a grassy area with a rocky wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [43.7, 43.7, 39.49, 39.49, 39.49, 39.49, 39.49, 42.7, 42.7, 42.7], "power_watts_avg": 41.3, "power_watts_peak": 43.7, "energy_joules_est": 39.0, "sample_count": 10, "duration_seconds": 0.944}, "timestamp": "2026-01-11T13:28:50.603814"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 890.995, "latencies_ms": [890.995], "images_per_second": 1.122, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a zoo enclosure. The enclosure features a rocky wall, trees, and a grassy area, providing a natural habitat for the animals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [42.7, 42.7, 42.15, 42.15, 42.15, 42.15, 42.15, 42.56, 42.56], "power_watts_avg": 42.36, "power_watts_peak": 42.7, "energy_joules_est": 37.76, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:28:51.512971"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 828.812, "latencies_ms": [828.812], "images_per_second": 1.207, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The zebras are black and white, contrasting with the green grass and brown dirt. The lighting suggests a sunny day, creating a bright and open environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [42.56, 42.56, 42.56, 47.18, 47.18, 47.18, 47.18, 47.18, 43.58], "power_watts_avg": 45.24, "power_watts_peak": 47.18, "energy_joules_est": 37.52, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:28:52.422092"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 619.386, "latencies_ms": [619.386], "images_per_second": 1.615, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A rusted fire hydrant, adorned with a chain, sits on a sidewalk next to a stone wall with a painted design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 43.58, 43.58, 38.14, 38.14, 38.14], "power_watts_avg": 41.25, "power_watts_peak": 43.58, "energy_joules_est": 25.56, "sample_count": 7, "duration_seconds": 0.62}, "timestamp": "2026-01-11T13:28:53.132555"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1173.984, "latencies_ms": [1173.984], "images_per_second": 0.852, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "fire hydrant: 1\nchain: 1\nbolts: 4\ncap: 1\nhandle: 1\npipes: 1\nground: 1\nwall: 1\nplants: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.14, 38.14, 40.13, 40.13, 40.13, 40.13, 40.13, 37.3, 37.3, 37.3, 37.3, 37.3], "power_watts_avg": 38.62, "power_watts_peak": 40.13, "energy_joules_est": 45.36, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-11T13:28:54.344737"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 731.552, "latencies_ms": [731.552], "images_per_second": 1.367, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The fire hydrant is positioned in the foreground, slightly to the right of the image. The background features a stone wall with a painted design and a small flower bed with pink flowers.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.27, 34.27, 34.27, 34.27, 38.45, 38.45, 38.45, 38.45], "power_watts_avg": 36.36, "power_watts_peak": 38.45, "energy_joules_est": 26.62, "sample_count": 8, "duration_seconds": 0.732}, "timestamp": "2026-01-11T13:28:55.153704"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 890.714, "latencies_ms": [890.714], "images_per_second": 1.123, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a weathered fire hydrant situated on a sidewalk next to a stone wall with a painted design. Pink flowers are visible in the background, adding a touch of color to the otherwise muted tones.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.45, 40.36, 40.36, 40.36, 40.36, 40.36, 37.16, 37.16, 37.16], "power_watts_avg": 39.08, "power_watts_peak": 40.36, "energy_joules_est": 34.82, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:28:56.063833"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1043.075, "latencies_ms": [1043.075], "images_per_second": 0.959, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The fire hydrant is primarily a light brown color with dark gray or black accents. The lighting appears to be natural, possibly from sunlight, giving the hydrant a slightly aged look. The hydrant is made of metal and has a decorative top.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.16, 37.16, 39.73, 39.73, 39.73, 39.73, 39.73, 38.23, 38.23, 38.23, 38.23], "power_watts_avg": 38.72, "power_watts_peak": 39.73, "energy_joules_est": 40.41, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-11T13:28:57.173800"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 540.046, "latencies_ms": [540.046], "images_per_second": 1.852, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "Two brown bears are captured running along a dirt road in a wilderness setting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.23, 34.55, 34.55, 34.55, 34.55, 34.55], "power_watts_avg": 35.16, "power_watts_peak": 38.23, "energy_joules_est": 19.01, "sample_count": 6, "duration_seconds": 0.541}, "timestamp": "2026-01-11T13:28:57.784638"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1232.826, "latencies_ms": [1232.826], "images_per_second": 0.811, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Bear: 2\nGround: 5\nRocks: 2\nBushes: 2\nBear fur: 2\nBear paws: 2\nBear head: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.27, 42.27, 42.27, 42.27, 42.27, 51.73, 51.73, 51.73, 51.73, 51.73, 43.1, 43.1, 43.1], "power_watts_avg": 46.1, "power_watts_peak": 51.73, "energy_joules_est": 56.86, "sample_count": 13, "duration_seconds": 1.233}, "timestamp": "2026-01-11T13:28:59.096610"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 964.142, "latencies_ms": [964.142], "images_per_second": 1.037, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and distance. The foreground bear is closer and larger, while the other bear is further away and smaller, emphasizing the vastness of the environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.1, 43.1, 38.7, 38.7, 38.7, 38.7, 38.7, 42.69, 42.69, 42.69], "power_watts_avg": 40.77, "power_watts_peak": 43.1, "energy_joules_est": 39.33, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-11T13:29:00.105516"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 883.105, "latencies_ms": [883.105], "images_per_second": 1.132, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two brown bears are seen in a dry, rocky landscape. One bear is walking, while the other is standing, appearing alert and possibly observing its surroundings.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.69, 42.69, 42.83, 42.83, 42.83, 42.83, 42.83, 42.35, 42.35], "power_watts_avg": 42.69, "power_watts_peak": 42.83, "energy_joules_est": 37.72, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-11T13:29:01.011702"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 793.25, "latencies_ms": [793.25], "images_per_second": 1.261, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The bears are brown and appear to be running on a dirt road. The lighting suggests a sunny day, and the material is dirt, gravel, and rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.35, 42.35, 42.35, 47.32, 47.32, 47.32, 47.32, 47.32], "power_watts_avg": 45.46, "power_watts_peak": 47.32, "energy_joules_est": 36.1, "sample_count": 8, "duration_seconds": 0.794}, "timestamp": "2026-01-11T13:29:01.821551"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 807.545, "latencies_ms": [807.545], "images_per_second": 1.238, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A young child, dressed in a white shirt and tie, crouches down next to a metal bowl filled with dirt, appearing to be playing or exploring.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.8, "ram_available_mb": 109451.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 43.45, 43.45, 43.45, 44.32, 44.32, 44.32, 44.32], "power_watts_avg": 43.83, "power_watts_peak": 44.32, "energy_joules_est": 35.41, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:29:02.731753"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1383.679, "latencies_ms": [1383.679], "images_per_second": 0.723, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Bucket: 1\nGround: 1\nBoy: 1\nTie: 1\nShirt: 1\nPants: 1\nShoes: 1\nGround: 1\nPlants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.8, "ram_available_mb": 109451.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.32, 41.84, 41.84, 41.84, 41.84, 41.84, 42.57, 42.57, 42.57, 42.57, 42.57, 44.44, 44.44, 44.44], "power_watts_avg": 42.83, "power_watts_peak": 44.44, "energy_joules_est": 59.28, "sample_count": 14, "duration_seconds": 1.384}, "timestamp": "2026-01-11T13:29:04.144394"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 849.563, "latencies_ms": [849.563], "images_per_second": 1.177, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The child is positioned near the foreground, interacting with a metal bowl on the ground. The background is primarily composed of dark foliage, creating a contrast with the child's lighter clothing and the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.44, 37.26, 37.26, 37.26, 37.26, 37.26, 43.89, 43.89, 43.89], "power_watts_avg": 40.27, "power_watts_peak": 44.44, "energy_joules_est": 34.22, "sample_count": 9, "duration_seconds": 0.85}, "timestamp": "2026-01-11T13:29:05.055088"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1049.075, "latencies_ms": [1049.075], "images_per_second": 0.953, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young child, dressed in a white shirt and tie, is crouched down near a metal bowl filled with dirt, appearing to be digging or playing in the ground. The setting is outdoors, with a dark background of foliage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.89, 43.89, 48.11, 48.11, 48.11, 48.11, 48.11, 42.9, 42.9, 42.9, 42.9], "power_watts_avg": 45.45, "power_watts_peak": 48.11, "energy_joules_est": 47.69, "sample_count": 11, "duration_seconds": 1.049}, "timestamp": "2026-01-11T13:29:06.166104"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1064.557, "latencies_ms": [1064.557], "images_per_second": 0.939, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The child is wearing a white shirt and a colorful tie. The lighting is natural and soft, creating a pleasant atmosphere. The child is playing in a dirt area, which suggests an outdoor setting. The child appears to be young, possibly a toddler.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.9, 37.55, 37.55, 37.55, 37.55, 37.55, 42.91, 42.91, 42.91, 42.91, 42.91], "power_watts_avg": 40.47, "power_watts_peak": 42.91, "energy_joules_est": 43.1, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:29:07.276996"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 696.018, "latencies_ms": [696.018], "images_per_second": 1.437, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A large stuffed teddy bear, wearing a hat, sits on a chair amidst a barren, desert-like landscape, accompanied by various objects and flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.37, 42.37, 42.37, 42.37, 42.37, 37.87, 37.87], "power_watts_avg": 41.08, "power_watts_peak": 42.37, "energy_joules_est": 28.62, "sample_count": 7, "duration_seconds": 0.697}, "timestamp": "2026-01-11T13:29:07.988113"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1564.333, "latencies_ms": [1564.333], "images_per_second": 0.639, "prompt_tokens": 21, "response_tokens_est": 56, "n_tiles": 1, "output_text": "teddy bear: 2\nblanket: 1\npillow: 1\nhat: 1\nsitting chair: 1\nred cross: 1\nstuffed animal: 2\nflowers: 1\nbeer bottles: 2\nsoda cans: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.87, 37.87, 37.87, 42.55, 42.55, 42.55, 42.55, 42.55, 38.62, 38.62, 38.62, 38.62, 38.62, 34.02, 34.02, 34.02], "power_watts_avg": 38.84, "power_watts_peak": 42.55, "energy_joules_est": 60.78, "sample_count": 16, "duration_seconds": 1.565}, "timestamp": "2026-01-11T13:29:09.601037"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 974.363, "latencies_ms": [974.363], "images_per_second": 1.026, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The stuffed animal is positioned in the foreground, slightly to the right of the chair. The chair and stuffed animal are situated in the middle ground, separated by a small table with bottles and flowers. The background consists of sparse, dry grass and dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 47.0}, "power_stats": {"power_watts_samples": [34.02, 34.02, 38.17, 38.17, 38.17, 38.17, 38.17, 37.99, 37.99, 37.99], "power_watts_avg": 37.28, "power_watts_peak": 38.17, "energy_joules_est": 36.34, "sample_count": 10, "duration_seconds": 0.975}, "timestamp": "2026-01-11T13:29:10.612378"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1063.034, "latencies_ms": [1063.034], "images_per_second": 0.941, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene is set in a barren, desert-like environment. A teddy bear is lying on a makeshift chair amidst various items, including clothes, flowers, and bottles. The chair appears to be repurposed as a makeshift table or bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [37.99, 37.99, 38.12, 38.12, 38.12, 38.12, 38.12, 38.13, 38.13, 38.13, 38.13], "power_watts_avg": 38.1, "power_watts_peak": 38.13, "energy_joules_est": 40.51, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:29:11.723475"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1083.746, "latencies_ms": [1083.746], "images_per_second": 0.923, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The scene is dominated by earthy tones of brown and reddish-brown. The lighting appears to be natural sunlight, creating a warm and inviting atmosphere. The materials include fabric, wood, and metal, contributing to the rustic aesthetic. The setting suggests a dry, arid environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.13, 32.97, 32.97, 32.97, 32.97, 32.97, 37.73, 37.73, 37.73, 37.73, 37.73], "power_watts_avg": 35.6, "power_watts_peak": 38.13, "energy_joules_est": 38.6, "sample_count": 11, "duration_seconds": 1.084}, "timestamp": "2026-01-11T13:29:12.834712"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 622.417, "latencies_ms": [622.417], "images_per_second": 1.607, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "Two green fishing boats are docked at a wooden pier, ready for their next voyage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.81, 38.81, 38.81, 38.81, 38.81, 44.46, 44.46], "power_watts_avg": 40.43, "power_watts_peak": 44.46, "energy_joules_est": 25.19, "sample_count": 7, "duration_seconds": 0.623}, "timestamp": "2026-01-11T13:29:13.546005"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1550.838, "latencies_ms": [1550.838], "images_per_second": 0.645, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "Boat: 3\nFishing boat: 2\nDock: 2\nPier: 1\nSailboats: 2\nBuoys: 2\nPaint cans: 1\nWooden planks: 1\nMetal railing: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.46, 44.46, 51.61, 51.61, 51.61, 51.61, 51.61, 43.92, 43.92, 43.92, 43.92, 43.92, 36.8, 36.8, 36.8, 36.8], "power_watts_avg": 44.61, "power_watts_peak": 51.61, "energy_joules_est": 69.19, "sample_count": 16, "duration_seconds": 1.551}, "timestamp": "2026-01-11T13:29:15.160949"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 725.411, "latencies_ms": [725.411], "images_per_second": 1.379, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the boats docked further back. The water extends into the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [36.8, 35.71, 35.71, 35.71, 35.71, 35.71, 44.04, 44.04], "power_watts_avg": 37.93, "power_watts_peak": 44.04, "energy_joules_est": 27.53, "sample_count": 8, "duration_seconds": 0.726}, "timestamp": "2026-01-11T13:29:15.972496"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1089.393, "latencies_ms": [1089.393], "images_per_second": 0.918, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a harbor with several fishing boats docked near a pier. The boats are equipped with fishing gear and appear to be ready for work. The setting is surrounded by hills and mountains, creating a picturesque backdrop for the harbor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.04, 44.04, 44.04, 53.09, 53.09, 53.09, 53.09, 53.09, 43.93, 43.93, 43.93], "power_watts_avg": 48.12, "power_watts_peak": 53.09, "energy_joules_est": 52.44, "sample_count": 11, "duration_seconds": 1.09}, "timestamp": "2026-01-11T13:29:17.083203"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1083.913, "latencies_ms": [1083.913], "images_per_second": 0.923, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The boats are primarily green and white. The lighting is soft and diffused, suggesting an overcast sky. The boats appear to be made of sturdy materials like metal and wood. The overall scene conveys a peaceful and tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.93, 43.93, 41.09, 41.09, 41.09, 41.09, 41.09, 45.19, 45.19, 45.19, 45.19], "power_watts_avg": 43.09, "power_watts_peak": 45.19, "energy_joules_est": 46.72, "sample_count": 11, "duration_seconds": 1.084}, "timestamp": "2026-01-11T13:29:18.194172"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 606.0, "latencies_ms": [606.0], "images_per_second": 1.65, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman with short brown hair bites into a hot dog, wearing a dark jacket and scarf, with a blurred background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [45.19, 40.32, 40.32, 40.32, 40.32, 40.32, 37.29], "power_watts_avg": 40.58, "power_watts_peak": 45.19, "energy_joules_est": 24.62, "sample_count": 7, "duration_seconds": 0.607}, "timestamp": "2026-01-11T13:29:18.903790"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1103.453, "latencies_ms": [1103.453], "images_per_second": 0.906, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "hot dog: 1\nwoman: 1\nfood: 1\nnapkin: 1\nface: 1\nhair: 1\neyes: 1\ntongue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.29, 37.29, 37.29, 37.29, 39.09, 39.09, 39.09, 39.09, 39.09, 36.89, 36.89], "power_watts_avg": 38.04, "power_watts_peak": 39.09, "energy_joules_est": 42.0, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-11T13:29:20.016797"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 945.307, "latencies_ms": [945.307], "images_per_second": 1.058, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, eating a hot dog. The background is blurred, suggesting an outdoor setting at night. The hot dog is held in her right hand, while the woman's face and upper body are visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13055.6, "ram_available_mb": 109450.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.89, 36.89, 36.89, 38.76, 38.76, 38.76, 38.76, 38.76, 38.6, 38.6], "power_watts_avg": 38.17, "power_watts_peak": 38.76, "energy_joules_est": 36.09, "sample_count": 10, "duration_seconds": 0.946}, "timestamp": "2026-01-11T13:29:21.028190"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 704.693, "latencies_ms": [704.693], "images_per_second": 1.419, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A woman is eating a hot dog at night in a dimly lit setting, possibly outdoors. The background is blurred, drawing focus to the woman and her food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.6, 38.6, 38.6, 37.05, 37.05, 37.05, 37.05, 37.05], "power_watts_avg": 37.63, "power_watts_peak": 38.6, "energy_joules_est": 26.54, "sample_count": 8, "duration_seconds": 0.705}, "timestamp": "2026-01-11T13:29:21.839071"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 704.418, "latencies_ms": [704.418], "images_per_second": 1.42, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The woman is wearing a dark-colored jacket. The background is dimly lit, suggesting an outdoor setting at night. The food she's eating appears to be a hot dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.96, 36.96, 36.96, 36.96, 36.96, 36.54, 36.54, 36.54], "power_watts_avg": 36.8, "power_watts_peak": 36.96, "energy_joules_est": 25.94, "sample_count": 8, "duration_seconds": 0.705}, "timestamp": "2026-01-11T13:29:22.648544"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 707.384, "latencies_ms": [707.384], "images_per_second": 1.414, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a black suit and bow tie holds a martini glass while standing next to a woman in a long black dress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 11.0}, "power_stats": {"power_watts_samples": [36.54, 38.44, 38.44, 38.44, 38.44, 38.44, 41.99, 41.99], "power_watts_avg": 39.09, "power_watts_peak": 41.99, "energy_joules_est": 27.66, "sample_count": 8, "duration_seconds": 0.708}, "timestamp": "2026-01-11T13:29:23.460290"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1324.614, "latencies_ms": [1324.614], "images_per_second": 0.755, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "woman: 2\nman: 1\ndress: 1\ngloves: 1\nbow tie: 1\ncocktail glass: 1\nfloor: 1\ndoor: 1\ncurtains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 48.75, 48.75, 48.75, 48.75, 48.75, 42.14, 42.14, 42.14, 42.14, 42.14, 33.8], "power_watts_avg": 43.87, "power_watts_peak": 48.75, "energy_joules_est": 58.13, "sample_count": 14, "duration_seconds": 1.325}, "timestamp": "2026-01-11T13:29:24.875311"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 779.014, "latencies_ms": [779.014], "images_per_second": 1.284, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The woman is positioned to the left of the man, who is standing further back in the image. The man is standing in the foreground, while the woman is positioned behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.8, 33.8, 33.8, 33.8, 42.52, 42.52, 42.52, 42.52], "power_watts_avg": 38.16, "power_watts_peak": 42.52, "energy_joules_est": 29.74, "sample_count": 8, "duration_seconds": 0.779}, "timestamp": "2026-01-11T13:29:25.686313"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1020.329, "latencies_ms": [1020.329], "images_per_second": 0.98, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A man and a woman are standing in a doorway, holding a martini glass. The woman is wearing a long dark dress, and the man is wearing a dark suit with a bow tie. They are likely attending a formal event or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.52, 43.75, 43.75, 43.75, 43.75, 43.75, 43.72, 43.72, 43.72, 43.72, 43.72], "power_watts_avg": 43.63, "power_watts_peak": 43.75, "energy_joules_est": 44.53, "sample_count": 11, "duration_seconds": 1.021}, "timestamp": "2026-01-11T13:29:26.799044"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1282.037, "latencies_ms": [1282.037], "images_per_second": 0.78, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The woman is wearing a dark green dress, and the man is wearing a dark suit with a bow tie. The lighting is soft and diffused, suggesting an indoor setting. The materials appear to be standard clothing, potentially silk or satin, contributing to the overall elegance of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 43.09, 43.09, 43.09, 41.77, 41.77, 41.77, 41.77, 41.77, 42.28, 42.28, 42.28], "power_watts_avg": 42.39, "power_watts_peak": 43.09, "energy_joules_est": 54.36, "sample_count": 13, "duration_seconds": 1.282}, "timestamp": "2026-01-11T13:29:28.111291"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 754.336, "latencies_ms": [754.336], "images_per_second": 1.326, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A blue wooden shelf holds various items, including several small metal cups, a silver teapot, a vase, and several small orange price tags.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 37.38, 37.38, 37.38, 37.38, 37.38, 37.23], "power_watts_avg": 38.59, "power_watts_peak": 42.28, "energy_joules_est": 29.12, "sample_count": 8, "duration_seconds": 0.755}, "timestamp": "2026-01-11T13:29:28.920384"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1830.838, "latencies_ms": [1830.838], "images_per_second": 0.546, "prompt_tokens": 21, "response_tokens_est": 68, "n_tiles": 1, "output_text": "vase: 1\nteapot: 1\nsmall metal container: 1\nsmall metal cup: 2\nsmall metal teapot: 1\nbook: 1\nsmall metal container: 1\nsmall metal teapot: 1\nsmall metal cup: 2\nsmall metal teapot: 1\nsmall metal container: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.23, 37.23, 37.23, 37.23, 37.52, 37.52, 37.52, 37.52, 37.52, 37.63, 37.63, 37.63, 37.63, 37.63, 33.78, 33.78, 33.78, 33.78, 33.78], "power_watts_avg": 36.5, "power_watts_peak": 37.63, "energy_joules_est": 66.85, "sample_count": 19, "duration_seconds": 1.831}, "timestamp": "2026-01-11T13:29:30.833921"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1040.14, "latencies_ms": [1040.14], "images_per_second": 0.961, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The silver teapot and cups are placed on the blue shelf in the foreground, while the silver vase and candlesticks are positioned on the wooden table in the background. The arrangement suggests a casual, informal setting, possibly a home or personal collection.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.76, 33.76, 33.76, 33.76, 36.3, 36.3, 36.3, 36.3, 36.3, 36.27, 36.27], "power_watts_avg": 35.37, "power_watts_peak": 36.3, "energy_joules_est": 36.81, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-11T13:29:31.994586"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1497.848, "latencies_ms": [1497.848], "images_per_second": 0.668, "prompt_tokens": 19, "response_tokens_est": 73, "n_tiles": 1, "output_text": "The scene depicts a cluttered outdoor setting, possibly a yard sale or flea market. A blue shelf holds various items, including vases, cups, and a book with price tags. The items are arranged haphazardly, with some items stacked on top of others. The overall atmosphere suggests a casual, informal gathering where items are being offered for sale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.27, 36.27, 36.27, 37.27, 37.27, 37.27, 37.27, 37.27, 37.16, 37.16, 37.16, 37.16, 37.16, 33.42, 33.42], "power_watts_avg": 36.52, "power_watts_peak": 37.27, "energy_joules_est": 54.73, "sample_count": 15, "duration_seconds": 1.499}, "timestamp": "2026-01-11T13:29:33.506928"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 886.427, "latencies_ms": [886.427], "images_per_second": 1.128, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The blue shelf stands out against the surrounding furniture and objects. The lighting in the image is soft and diffused, creating a calm atmosphere. The shelf appears to be made of metal and has a slightly worn or weathered appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [33.42, 33.42, 33.42, 38.24, 38.24, 38.24, 38.24, 38.24, 38.39], "power_watts_avg": 36.65, "power_watts_peak": 38.39, "energy_joules_est": 32.5, "sample_count": 9, "duration_seconds": 0.887}, "timestamp": "2026-01-11T13:29:34.415125"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 854.561, "latencies_ms": [854.561], "images_per_second": 1.17, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A white plate holds four square crackers topped with a white substance, likely butter or cream cheese, accompanied by a black computer keyboard and a computer mouse in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [38.39, 38.39, 38.39, 38.39, 42.77, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 40.82, "power_watts_peak": 42.77, "energy_joules_est": 34.91, "sample_count": 9, "duration_seconds": 0.855}, "timestamp": "2026-01-11T13:29:35.324436"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 848.766, "latencies_ms": [848.766], "images_per_second": 1.178, "prompt_tokens": 21, "response_tokens_est": 22, "n_tiles": 1, "output_text": "keyboard: 2\nmouse: 1\nplate: 4\ntoast: 4\nbutter: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.0, 43.0, 43.0, 43.0, 43.0, 43.01, 43.01, 43.01, 43.01], "power_watts_avg": 43.01, "power_watts_peak": 43.01, "energy_joules_est": 36.51, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:29:36.234675"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 923.865, "latencies_ms": [923.865], "images_per_second": 1.082, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the plate of crackers slightly behind them. The background includes a keyboard, a mouse, and a partially visible cup, suggesting an office or workspace setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.01, 41.73, 41.73, 41.73, 41.73, 41.73, 42.74, 42.74, 42.74, 42.74], "power_watts_avg": 42.26, "power_watts_peak": 43.01, "energy_joules_est": 39.07, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-11T13:29:37.244403"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 906.713, "latencies_ms": [906.713], "images_per_second": 1.103, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A white plate with several square crackers topped with a white substance sits on a desk. A black computer keyboard and a computer mouse are visible in the background, along with a partially visible yellow object.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.74, 42.7, 42.7, 42.7, 42.7, 42.7, 42.22, 42.22, 42.22, 42.22], "power_watts_avg": 42.51, "power_watts_peak": 42.74, "energy_joules_est": 38.57, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-11T13:29:38.254937"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 978.28, "latencies_ms": [978.28], "images_per_second": 1.022, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The plate is white and appears to be made of ceramic or porcelain. The butter on the crackers is a pale yellow color. The lighting in the image is soft and diffused, creating a gentle ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.16, 42.16, 42.16, 42.16, 42.16, 41.98, 41.98, 41.98, 41.98, 41.98], "power_watts_avg": 42.07, "power_watts_peak": 42.16, "energy_joules_est": 41.19, "sample_count": 10, "duration_seconds": 0.979}, "timestamp": "2026-01-11T13:29:39.265623"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 589.658, "latencies_ms": [589.658], "images_per_second": 1.696, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man in a black suit and tie adjusts his colorful tie against a dark gray background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 43.35, 43.35, 44.06], "power_watts_avg": 43.47, "power_watts_peak": 44.06, "energy_joules_est": 25.67, "sample_count": 6, "duration_seconds": 0.591}, "timestamp": "2026-01-11T13:29:39.876260"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1029.834, "latencies_ms": [1029.834], "images_per_second": 0.971, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "man: 2\nglasses: 1\nsuit: 1\ntie: 1\nring: 1\nbelt: 1\nbackground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 44.06, 44.06, 55.94, 55.94, 55.94, 55.94, 55.94, 45.38, 45.38], "power_watts_avg": 49.7, "power_watts_peak": 55.94, "energy_joules_est": 51.2, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-11T13:29:40.988564"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 989.196, "latencies_ms": [989.196], "images_per_second": 1.011, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main object, the man, is positioned in the foreground, facing the camera. The tie, located near the center, is further back, creating a sense of depth. The dark background further emphasizes the man and his tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.38, 45.38, 45.38, 43.98, 43.98, 43.98, 43.98, 43.98, 43.67, 43.67], "power_watts_avg": 44.34, "power_watts_peak": 45.38, "energy_joules_est": 43.88, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:29:41.998526"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 647.435, "latencies_ms": [647.435], "images_per_second": 1.545, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a suit is adjusting a glowing tie against a dark background. He appears to be in a professional or formal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.67, 43.67, 43.67, 44.57, 44.57, 44.57, 44.57], "power_watts_avg": 44.19, "power_watts_peak": 44.57, "energy_joules_est": 28.63, "sample_count": 7, "duration_seconds": 0.648}, "timestamp": "2026-01-11T13:29:42.707181"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1160.405, "latencies_ms": [1160.405], "images_per_second": 0.862, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The tie features a vibrant array of colors, primarily red and green, creating a striking visual effect. The lighting highlights the colors and creates a dynamic effect. The tie appears to be made of a smooth, potentially synthetic material. The man is wearing a suit, suggesting formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.57, 45.18, 45.18, 45.18, 45.18, 45.18, 44.27, 44.27, 44.27, 44.27, 44.27, 45.02], "power_watts_avg": 44.74, "power_watts_peak": 45.18, "energy_joules_est": 51.94, "sample_count": 12, "duration_seconds": 1.161}, "timestamp": "2026-01-11T13:29:43.915412"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 731.446, "latencies_ms": [731.446], "images_per_second": 1.367, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman is crossing the street in front of a white building with a \"TADURIA\" sign, carrying a black purse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [45.02, 45.02, 45.02, 45.02, 43.06, 43.06, 43.06, 43.06], "power_watts_avg": 44.04, "power_watts_peak": 45.02, "energy_joules_est": 32.24, "sample_count": 8, "duration_seconds": 0.732}, "timestamp": "2026-01-11T13:29:44.725771"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1139.52, "latencies_ms": [1139.52], "images_per_second": 0.878, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "building: 4\nstreetlight: 1\nperson: 1\ncar: 1\ntraffic light: 1\nshop: 1\nsign: 1\npeople: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.06, 41.95, 41.95, 41.95, 41.95, 41.95, 42.9, 42.9, 42.9, 42.9, 42.9, 44.06], "power_watts_avg": 42.61, "power_watts_peak": 44.06, "energy_joules_est": 48.59, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-11T13:29:45.937889"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 946.937, "latencies_ms": [946.937], "images_per_second": 1.056, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The woman is standing in the foreground of the image, facing the camera. The building is situated in the background, slightly to the right of the woman. The street and traffic lights are located further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 44.06, 44.06, 43.01, 43.01, 43.01, 43.01, 43.01, 43.01], "power_watts_avg": 43.43, "power_watts_peak": 44.06, "energy_joules_est": 41.15, "sample_count": 10, "duration_seconds": 0.947}, "timestamp": "2026-01-11T13:29:46.949758"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1220.055, "latencies_ms": [1220.055], "images_per_second": 0.82, "prompt_tokens": 19, "response_tokens_est": 61, "n_tiles": 1, "output_text": "A woman is walking across a street corner in front of a white building with a \"TADURIA\" sign. A traffic light is visible, signaling pedestrians to stop. Several other people are walking or standing near the building. The scene is illuminated by streetlights, creating a calm and nighttime atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.01, 43.07, 43.07, 43.07, 43.07, 43.26, 43.26, 43.26, 43.26, 43.26], "power_watts_avg": 43.12, "power_watts_peak": 43.26, "energy_joules_est": 52.63, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:29:48.260709"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 901.439, "latencies_ms": [901.439], "images_per_second": 1.109, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The building is primarily white with light-colored trim and features warm lighting from street lamps and building lights. The sky is a deep blue, suggesting it's either dusk or dawn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [32.56, 32.56, 32.56, 32.56, 32.56, 42.68, 42.68, 42.68, 42.68], "power_watts_avg": 37.06, "power_watts_peak": 42.68, "energy_joules_est": 33.43, "sample_count": 9, "duration_seconds": 0.902}, "timestamp": "2026-01-11T13:29:49.170712"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 774.409, "latencies_ms": [774.409], "images_per_second": 1.291, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A young girl in a purple bikini skillfully surfs a wave on a blue surfboard, surrounded by other surfers in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.68, 47.83, 47.83, 47.83, 47.83, 47.83, 44.09, 44.09], "power_watts_avg": 46.25, "power_watts_peak": 47.83, "energy_joules_est": 35.83, "sample_count": 8, "duration_seconds": 0.775}, "timestamp": "2026-01-11T13:29:49.981290"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1144.183, "latencies_ms": [1144.183], "images_per_second": 0.874, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "surfboard: 2\nwoman: 1\nwoman: 1\nman: 1\nman: 1\nwoman: 1\nman: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.09, 44.09, 44.09, 51.03, 51.03, 51.03, 51.03, 51.03, 43.34, 43.34, 43.34, 43.34], "power_watts_avg": 46.73, "power_watts_peak": 51.03, "energy_joules_est": 53.48, "sample_count": 12, "duration_seconds": 1.144}, "timestamp": "2026-01-11T13:29:51.193716"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1132.354, "latencies_ms": [1132.354], "images_per_second": 0.883, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The main object, the girl surfing, is positioned in the foreground of the image. The background is filled with water, suggesting the setting is a beach or ocean. The girl is riding a wave near the foreground, drawing the viewer's attention to her action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.3, "ram_available_mb": 109450.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.34, 34.87, 34.87, 34.87, 34.87, 34.87, 42.72, 42.72, 42.72, 42.72, 42.72, 42.51], "power_watts_avg": 39.49, "power_watts_peak": 43.34, "energy_joules_est": 44.75, "sample_count": 12, "duration_seconds": 1.133}, "timestamp": "2026-01-11T13:29:52.405116"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1149.739, "latencies_ms": [1149.739], "images_per_second": 0.87, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a sunny day at the beach with several people enjoying surfing. A young girl in a purple bikini is skillfully riding a wave on a blue surfboard, while two other surfers are paddling in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 42.51, 42.51, 42.35, 42.35, 42.35, 42.35, 42.35, 42.28, 42.28, 42.28], "power_watts_avg": 42.39, "power_watts_peak": 42.51, "energy_joules_est": 48.75, "sample_count": 12, "duration_seconds": 1.15}, "timestamp": "2026-01-11T13:29:53.614625"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 963.669, "latencies_ms": [963.669], "images_per_second": 1.038, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The water is a greenish-blue color. The lighting is bright, likely from sunlight. The surfboards appear to be made of fiberglass or similar lightweight materials. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 39.2, 39.2, 39.2, 39.2, 39.2, 42.79, 42.79, 42.79], "power_watts_avg": 40.89, "power_watts_peak": 42.79, "energy_joules_est": 39.42, "sample_count": 10, "duration_seconds": 0.964}, "timestamp": "2026-01-11T13:29:54.622503"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 648.904, "latencies_ms": [648.904], "images_per_second": 1.541, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A man in a white shirt and khaki pants is feeding a gray elephant over a fence in a zoo enclosure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 39.0}, "power_stats": {"power_watts_samples": [42.79, 42.79, 42.46, 42.46, 42.46, 42.46, 42.46], "power_watts_avg": 42.55, "power_watts_peak": 42.79, "energy_joules_est": 27.64, "sample_count": 7, "duration_seconds": 0.65}, "timestamp": "2026-01-11T13:29:55.333853"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1016.121, "latencies_ms": [1016.121], "images_per_second": 0.984, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "elephant: 1\nman: 1\nfence: 2\ngrass: 2\ntree: 2\nman: 1\nhat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 43.09, 43.09, 43.09, 48.08, 48.08, 48.08, 48.08, 48.08, 43.32], "power_watts_avg": 45.38, "power_watts_peak": 48.08, "energy_joules_est": 46.14, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-11T13:29:56.445923"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 848.799, "latencies_ms": [848.799], "images_per_second": 1.178, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The elephant is positioned to the left of the man, who is positioned to the right of the elephant. The man is standing in the foreground, while the elephant is further back, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [43.32, 43.32, 43.32, 43.32, 42.69, 42.69, 42.69, 42.69, 42.69], "power_watts_avg": 42.97, "power_watts_peak": 43.32, "energy_joules_est": 36.48, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:29:57.354407"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 953.851, "latencies_ms": [953.851], "images_per_second": 1.048, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "An elephant is standing in a fenced enclosure, reaching over a metal railing to interact with a man. The man is feeding the elephant, seemingly in a zoo or wildlife sanctuary setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 42.51, 42.51, 43.05, 43.05, 43.05, 43.05, 43.05, 43.19], "power_watts_avg": 42.85, "power_watts_peak": 43.19, "energy_joules_est": 40.89, "sample_count": 10, "duration_seconds": 0.954}, "timestamp": "2026-01-11T13:29:58.364561"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1034.617, "latencies_ms": [1034.617], "images_per_second": 0.967, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The elephant is gray and appears to have some grayish-brown skin. Its trunk is extended towards the man, seemingly reaching for something. The lighting in the image suggests it might be daytime, with natural light illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 43.19, 43.19, 43.35, 43.35, 43.35, 43.35, 43.35, 43.18, 43.18], "power_watts_avg": 43.26, "power_watts_peak": 43.35, "energy_joules_est": 44.77, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-11T13:29:59.475156"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 809.251, "latencies_ms": [809.251], "images_per_second": 1.236, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A brown dog sits on a bed amidst a pile of clothes, bags, and boxes, appearing curious and possibly intrigued by the clutter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.18, 43.18, 43.18, 42.82, 42.82, 42.82, 42.82, 42.82, 42.83], "power_watts_avg": 42.94, "power_watts_peak": 43.18, "energy_joules_est": 34.78, "sample_count": 9, "duration_seconds": 0.81}, "timestamp": "2026-01-11T13:30:00.386774"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1071.333, "latencies_ms": [1071.333], "images_per_second": 0.933, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\nblankets: 2\nbags: 1\nbox: 1\nclothes: 2\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [42.83, 42.83, 42.83, 42.83, 42.34, 42.34, 42.34, 42.34, 42.34, 42.31, 42.31], "power_watts_avg": 42.51, "power_watts_peak": 42.83, "energy_joules_est": 45.56, "sample_count": 11, "duration_seconds": 1.072}, "timestamp": "2026-01-11T13:30:01.497945"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 989.601, "latencies_ms": [989.601], "images_per_second": 1.011, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The dog is positioned on the left side of the image, near the foreground. The bed occupies the foreground and background, extending from the left to the right side of the image. The dog is situated on the bed amidst the clutter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.4, "ram_available_mb": 109449.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [42.31, 42.31, 42.31, 43.7, 43.7, 43.7, 43.7, 43.7, 43.73, 43.73], "power_watts_avg": 43.29, "power_watts_peak": 43.73, "energy_joules_est": 42.85, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:30:02.507883"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 742.633, "latencies_ms": [742.633], "images_per_second": 1.347, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A brown dog sits on a bed surrounded by various items, including clothes, a backpack, and a box. The bed appears to be messy and cluttered.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.73, 43.75, 43.75, 43.75, 43.75, 43.75], "power_watts_avg": 43.74, "power_watts_peak": 43.75, "energy_joules_est": 32.51, "sample_count": 8, "duration_seconds": 0.743}, "timestamp": "2026-01-11T13:30:03.318210"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 805.09, "latencies_ms": [805.09], "images_per_second": 1.242, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The dog is brown and white. The bed is covered in white sheets and blankets. The lighting is soft and diffused, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 43.78, 43.78, 42.85, 42.85, 42.85, 42.85], "power_watts_avg": 43.37, "power_watts_peak": 43.78, "energy_joules_est": 34.95, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-11T13:30:04.230247"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 684.314, "latencies_ms": [684.314], "images_per_second": 1.461, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A man, dressed professionally in a blue shirt and tie, sits at a desk with a laptop, pen in hand, appearing deep in thought.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.85, 41.95, 41.95, 41.95, 41.95, 41.95, 36.73], "power_watts_avg": 41.33, "power_watts_peak": 42.85, "energy_joules_est": 28.31, "sample_count": 7, "duration_seconds": 0.685}, "timestamp": "2026-01-11T13:30:04.940248"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1119.905, "latencies_ms": [1119.905], "images_per_second": 0.893, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "laptop: 1\nglasses: 1\nnotebook: 1\npen: 1\ntie: 1\nman: 1\ntable: 1\nclipboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.73, 36.73, 36.73, 36.73, 43.18, 43.18, 43.18, 43.18, 43.18, 38.48, 38.48, 38.48], "power_watts_avg": 39.86, "power_watts_peak": 43.18, "energy_joules_est": 44.66, "sample_count": 12, "duration_seconds": 1.121}, "timestamp": "2026-01-11T13:30:06.150659"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 769.671, "latencies_ms": [769.671], "images_per_second": 1.299, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The man is seated at a desk with a laptop and papers, indicating a workspace. The background is blurred, suggesting the setting is likely an office or professional environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.48, 38.48, 36.89, 36.89, 36.89, 36.89, 36.94, 36.94], "power_watts_avg": 37.3, "power_watts_peak": 38.48, "energy_joules_est": 28.74, "sample_count": 8, "duration_seconds": 0.77}, "timestamp": "2026-01-11T13:30:06.962534"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 729.094, "latencies_ms": [729.094], "images_per_second": 1.372, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A man is sitting at a desk in an office, appearing thoughtful as he looks up from his laptop. He is surrounded by office supplies, including a pen and papers, suggesting a professional environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [36.94, 36.94, 36.94, 38.2, 38.2, 38.2, 38.2, 38.2], "power_watts_avg": 37.72, "power_watts_peak": 38.2, "energy_joules_est": 27.51, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-11T13:30:07.771452"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 807.004, "latencies_ms": [807.004], "images_per_second": 1.239, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is wearing a light blue shirt and a blue tie. His hair is gray and short. The lighting is bright, likely from overhead fluorescent lights, creating a well-lit workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [36.65, 36.65, 36.65, 36.65, 36.65, 37.0, 37.0, 37.0, 37.0], "power_watts_avg": 36.8, "power_watts_peak": 37.0, "energy_joules_est": 29.72, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:30:08.679878"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 657.45, "latencies_ms": [657.45], "images_per_second": 1.521, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A large commercial airplane with red accents is captured in mid-flight, passing a full moon in the sky.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 5.0}, "power_stats": {"power_watts_samples": [37.0, 39.34, 39.34, 39.34, 39.34, 39.34, 42.02], "power_watts_avg": 39.38, "power_watts_peak": 42.02, "energy_joules_est": 25.91, "sample_count": 7, "duration_seconds": 0.658}, "timestamp": "2026-01-11T13:30:09.391092"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 722.802, "latencies_ms": [722.802], "images_per_second": 1.384, "prompt_tokens": 21, "response_tokens_est": 17, "n_tiles": 1, "output_text": "airplane: 1\nmoon: 1\nsky: 1\nclouds: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [42.02, 42.02, 42.02, 42.02, 51.38, 51.38, 51.38, 51.38], "power_watts_avg": 46.7, "power_watts_peak": 51.38, "energy_joules_est": 33.77, "sample_count": 8, "duration_seconds": 0.723}, "timestamp": "2026-01-11T13:30:10.198782"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 732.205, "latencies_ms": [732.205], "images_per_second": 1.366, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The airplane is flying towards the right side of the image, while the moon is positioned in the lower left corner, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [51.38, 43.48, 43.48, 43.48, 43.48, 43.48, 42.36, 42.36], "power_watts_avg": 44.19, "power_watts_peak": 51.38, "energy_joules_est": 32.38, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:30:11.007809"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 839.535, "latencies_ms": [839.535], "images_per_second": 1.191, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A large commercial airplane is captured in mid-flight against a clear, light blue sky. A large, full moon is visible in the lower left corner of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.36, 42.36, 42.36, 51.17, 51.17, 51.17, 51.17, 51.17, 42.61], "power_watts_avg": 47.28, "power_watts_peak": 51.17, "energy_joules_est": 39.73, "sample_count": 9, "duration_seconds": 0.84}, "timestamp": "2026-01-11T13:30:11.921347"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1031.017, "latencies_ms": [1031.017], "images_per_second": 0.97, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The moon is a pale orange-yellow color, illuminated by the sun's light. The airplane is primarily gray with red accents on the tail and wings. The sky is a light blue, suggesting fair weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 42.61, 42.34, 42.34, 42.34, 42.34, 42.34, 42.73, 42.73], "power_watts_avg": 42.51, "power_watts_peak": 42.73, "energy_joules_est": 43.85, "sample_count": 11, "duration_seconds": 1.032}, "timestamp": "2026-01-11T13:30:13.033003"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 938.569, "latencies_ms": [938.569], "images_per_second": 1.065, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young man in a purple tie-dye shirt and black pants is skillfully performing a trick on his skateboard, airborne above a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 42.92, 42.92, 42.92, 42.92, 42.92, 43.84, 43.84], "power_watts_avg": 43.05, "power_watts_peak": 43.84, "energy_joules_est": 40.42, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-11T13:30:14.045681"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1453.408, "latencies_ms": [1453.408], "images_per_second": 0.688, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "Skateboard: 2\nTie-dye shirt: 1\nSkateboard wheels: 4\nSkateboard deck: 1\nGround: 1\nTrees: 2\nBuildings: 2\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.84, 43.84, 43.84, 43.77, 43.77, 43.77, 43.77, 43.77, 43.88, 43.88, 43.88, 43.88, 43.88, 36.72, 36.72], "power_watts_avg": 42.88, "power_watts_peak": 43.88, "energy_joules_est": 62.35, "sample_count": 15, "duration_seconds": 1.454}, "timestamp": "2026-01-11T13:30:15.560084"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 912.399, "latencies_ms": [912.399], "images_per_second": 1.096, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, mid-air, performing a trick. The skate park is situated in the background, partially obscured by palm trees and other structures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [36.72, 36.72, 42.19, 42.19, 42.19, 42.19, 42.19, 44.41, 44.41, 44.41], "power_watts_avg": 41.76, "power_watts_peak": 44.41, "energy_joules_est": 38.13, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-11T13:30:16.569501"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1125.587, "latencies_ms": [1125.587], "images_per_second": 0.888, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A young man is performing a skateboard trick in a skate park. He is mid-air, executing a trick while wearing a tie-dye shirt and jeans. The park is surrounded by palm trees and other greenery, with buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.41, 44.41, 43.01, 43.01, 43.01, 43.01, 43.01, 43.48, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 43.44, "power_watts_peak": 44.41, "energy_joules_est": 48.94, "sample_count": 12, "duration_seconds": 1.126}, "timestamp": "2026-01-11T13:30:17.783487"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1220.109, "latencies_ms": [1220.109], "images_per_second": 0.82, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The skateboarder is wearing a tie-dye shirt in shades of purple and blue. The lighting appears to be natural daylight, creating a bright and clear atmosphere. The skateboard itself appears to be made of wood and metal, typical for skateboarding equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.21, 36.21, 36.21, 36.21, 36.21, 43.64, 43.64, 43.64, 43.64, 43.64, 44.09, 44.09, 44.09], "power_watts_avg": 40.89, "power_watts_peak": 44.09, "energy_joules_est": 49.9, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:30:19.098748"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 630.148, "latencies_ms": [630.148], "images_per_second": 1.587, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A curious sheep gazes through the wire fence, its fluffy white coat contrasting with the rusty metal.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.09, 44.09, 39.25, 39.25, 39.25, 39.25, 39.25], "power_watts_avg": 40.63, "power_watts_peak": 44.09, "energy_joules_est": 25.63, "sample_count": 7, "duration_seconds": 0.631}, "timestamp": "2026-01-11T13:30:19.810539"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 926.105, "latencies_ms": [926.105], "images_per_second": 1.08, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "sheep: 2\nwire fence: 1\ngrass: 1\ntrees: 4\nbush: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.22, 42.22, 42.22, 42.22, 42.22, 46.11, 46.11, 46.11, 46.11, 46.11], "power_watts_avg": 44.16, "power_watts_peak": 46.11, "energy_joules_est": 40.91, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-11T13:30:20.823423"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 718.139, "latencies_ms": [718.139], "images_per_second": 1.392, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, partially obscured by the wire fence. The background features trees and a grassy area, creating a natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.66, 42.66, 42.66, 42.66, 42.66, 42.97, 42.97, 42.97], "power_watts_avg": 42.78, "power_watts_peak": 42.97, "energy_joules_est": 30.74, "sample_count": 8, "duration_seconds": 0.719}, "timestamp": "2026-01-11T13:30:21.634614"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 718.973, "latencies_ms": [718.973], "images_per_second": 1.391, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A sheep is standing behind a wire fence in a grassy field with trees in the background. The sheep appears to be looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 24.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 46.6, 46.6, 46.6, 46.6, 46.6, 42.58], "power_watts_avg": 45.19, "power_watts_peak": 46.6, "energy_joules_est": 32.52, "sample_count": 8, "duration_seconds": 0.72}, "timestamp": "2026-01-11T13:30:22.445583"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1009.625, "latencies_ms": [1009.625], "images_per_second": 0.99, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The sheep's wool is a light beige color. The lighting in the image appears to be natural, possibly from the sun, creating a soft, warm glow. The scene is set against a backdrop of lush green trees, suggesting a pleasant, outdoor environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [42.58, 42.58, 42.58, 42.58, 48.02, 48.02, 48.02, 48.02, 48.02, 42.4, 42.4], "power_watts_avg": 45.02, "power_watts_peak": 48.02, "energy_joules_est": 45.47, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-11T13:30:23.559036"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 616.046, "latencies_ms": [616.046], "images_per_second": 1.623, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A close-up shot reveals the illuminated buttons and screen of a silver Sony Walkman phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.4, 42.4, 40.44, 40.44, 40.44, 40.44, 40.44], "power_watts_avg": 41.0, "power_watts_peak": 42.4, "energy_joules_est": 25.27, "sample_count": 7, "duration_seconds": 0.616}, "timestamp": "2026-01-11T13:30:24.266199"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1134.673, "latencies_ms": [1134.673], "images_per_second": 0.881, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "button: 2\nscreen: 1\nvolume knob: 1\nplay button: 1\nwalkman button: 1\nback button: 1\nup arrow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.45, 40.45, 40.45, 40.45, 40.45, 43.95, 43.95, 43.95, 43.95, 43.95, 44.1, 44.1], "power_watts_avg": 42.52, "power_watts_peak": 44.1, "energy_joules_est": 48.26, "sample_count": 12, "duration_seconds": 1.135}, "timestamp": "2026-01-11T13:30:25.477093"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 792.314, "latencies_ms": [792.314], "images_per_second": 1.262, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The left object is positioned in the foreground, while the right object is further away in the background. The device is angled towards the viewer, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [44.1, 44.1, 44.1, 42.58, 42.58, 42.58, 42.58, 42.58], "power_watts_avg": 43.15, "power_watts_peak": 44.1, "energy_joules_est": 34.22, "sample_count": 8, "duration_seconds": 0.793}, "timestamp": "2026-01-11T13:30:26.288782"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 995.371, "latencies_ms": [995.371], "images_per_second": 1.005, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Close-up view of a silver Sony Walkman phone, showcasing its illuminated buttons and screen. The phone rests on a dark surface, emphasizing its metallic finish and the orange lights that illuminate the buttons.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 42.38, 44.01, 44.01, 44.01, 44.01, 44.01], "power_watts_avg": 43.19, "power_watts_peak": 44.01, "energy_joules_est": 43.01, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-11T13:30:27.299032"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1258.792, "latencies_ms": [1258.792], "images_per_second": 0.794, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The phone's metallic silver casing is illuminated by warm orange light, giving it a sleek and modern appearance. The buttons and screen are also illuminated, enhancing the phone's visual appeal. The phone rests on a dark surface, suggesting it might be in a dimly lit environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.1, 44.1, 44.1, 44.1, 44.1, 43.95, 43.95, 43.95, 43.95, 43.95, 43.69, 43.69, 43.69], "power_watts_avg": 43.94, "power_watts_peak": 44.1, "energy_joules_est": 55.34, "sample_count": 13, "duration_seconds": 1.259}, "timestamp": "2026-01-11T13:30:28.611651"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 621.59, "latencies_ms": [621.59], "images_per_second": 1.609, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a sparkly black dress stands in front of a stainless steel refrigerator, holding a glass of orange juice.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 45.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 39.3, 39.3, 39.3, 39.3, 39.3], "power_watts_avg": 40.55, "power_watts_peak": 43.69, "energy_joules_est": 25.24, "sample_count": 7, "duration_seconds": 0.622}, "timestamp": "2026-01-11T13:30:29.323259"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1432.978, "latencies_ms": [1432.978], "images_per_second": 0.698, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "woman: 1\ndress: 1\nglasses: 1\nwine bottle: 1\nfoil roll: 1\nrefrigerator: 1\ncounter: 1\ncabinets: 4\nfloor: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.55, 42.55, 42.55, 42.55, 42.55, 46.54, 46.54, 46.54, 46.54, 46.54, 42.51, 42.51, 42.51, 42.51, 42.51], "power_watts_avg": 43.87, "power_watts_peak": 46.54, "energy_joules_est": 62.89, "sample_count": 15, "duration_seconds": 1.434}, "timestamp": "2026-01-11T13:30:30.835301"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 817.625, "latencies_ms": [817.625], "images_per_second": 1.223, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The woman is standing near the refrigerator, which occupies the foreground of the image. The kitchen counter and cabinets are positioned in the background, extending beyond the immediate foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.56, 33.56, 33.56, 33.56, 33.56, 42.49, 42.49, 42.49, 42.49], "power_watts_avg": 37.53, "power_watts_peak": 42.49, "energy_joules_est": 30.72, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:30:31.747596"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1095.541, "latencies_ms": [1095.541], "images_per_second": 0.913, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A woman in a sparkly black dress is standing in a kitchen, holding a glass of orange juice. She is smiling and appears to be enjoying herself. The kitchen features wooden cabinets, a stainless steel refrigerator, and a tiled backsplash.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.49, 40.81, 40.81, 40.81, 40.81, 40.81, 41.85, 41.85, 41.85, 41.85, 41.85], "power_watts_avg": 41.43, "power_watts_peak": 42.49, "energy_joules_est": 45.41, "sample_count": 11, "duration_seconds": 1.096}, "timestamp": "2026-01-11T13:30:32.860576"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1109.083, "latencies_ms": [1109.083], "images_per_second": 0.902, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The kitchen features warm brown wooden cabinets and light-colored tile flooring. The stainless steel refrigerator stands out, adding a modern touch to the space. The woman is wearing black dress and glasses, completing the stylish ensemble.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 43.56, 43.56, 43.49, 43.49, 43.49, 43.49, 43.49, 43.43, 43.43, 43.43], "power_watts_avg": 43.5, "power_watts_peak": 43.56, "energy_joules_est": 48.26, "sample_count": 12, "duration_seconds": 1.11}, "timestamp": "2026-01-11T13:30:34.074107"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 667.403, "latencies_ms": [667.403], "images_per_second": 1.498, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A yellow school bus is reflected in the side mirror of a vehicle, capturing a glimpse of the road ahead.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.43, 43.43, 39.65, 39.65, 39.65, 39.65, 39.65], "power_watts_avg": 40.73, "power_watts_peak": 43.43, "energy_joules_est": 27.2, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:30:34.785663"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1077.077, "latencies_ms": [1077.077], "images_per_second": 0.928, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "school bus: 1\nroad: 2\ncar: 1\ntraffic light: 1\nbuildings: 2\nsign: 1\npole: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.74, 41.74, 41.74, 41.74, 41.74, 45.71, 45.71, 45.71, 45.71, 45.71, 43.62], "power_watts_avg": 43.72, "power_watts_peak": 45.71, "energy_joules_est": 47.09, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-11T13:30:35.897485"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 857.125, "latencies_ms": [857.125], "images_per_second": 1.167, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The school bus is positioned in the foreground, partially obscuring the background. The mirror reflects the school bus and the surrounding environment, including other vehicles and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.62, 43.62, 43.62, 43.62, 43.25, 43.25, 43.25, 43.25, 43.25], "power_watts_avg": 43.42, "power_watts_peak": 43.62, "energy_joules_est": 37.24, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:30:36.808895"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 787.223, "latencies_ms": [787.223], "images_per_second": 1.27, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A yellow school bus is reflected in the side mirror of a vehicle. The mirror also reflects a road with cars and a partially visible building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.9, "ram_available_mb": 109451.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 42.97, 42.97, 42.97, 43.04, 43.04, 43.04], "power_watts_avg": 43.0, "power_watts_peak": 43.04, "energy_joules_est": 33.86, "sample_count": 8, "duration_seconds": 0.788}, "timestamp": "2026-01-11T13:30:37.616902"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 875.603, "latencies_ms": [875.603], "images_per_second": 1.142, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The yellow school bus is reflected in the round side mirror. The mirror reflects a partly cloudy sky and a roadway with cars. The bus appears to be parked or stopped.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [43.04, 43.04, 49.6, 49.6, 49.6, 49.6, 49.6, 43.56, 43.56], "power_watts_avg": 46.8, "power_watts_peak": 49.6, "energy_joules_est": 41.02, "sample_count": 9, "duration_seconds": 0.876}, "timestamp": "2026-01-11T13:30:38.526578"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 631.608, "latencies_ms": [631.608], "images_per_second": 1.583, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A gray cat is sitting on a wooden table near two potted plants, while a brown dog stands nearby, seemingly observing the cat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 43.56, 42.89, 42.89, 42.89, 42.89], "power_watts_avg": 43.18, "power_watts_peak": 43.56, "energy_joules_est": 27.3, "sample_count": 7, "duration_seconds": 0.632}, "timestamp": "2026-01-11T13:30:39.237566"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 890.652, "latencies_ms": [890.652], "images_per_second": 1.123, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "cat: 1\ndog: 1\nplant: 2\npot: 2\ntable: 1\nwindow: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.89, 37.17, 37.17, 37.17, 37.17, 37.17, 37.51, 37.51, 37.51], "power_watts_avg": 37.92, "power_watts_peak": 42.89, "energy_joules_est": 33.79, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:30:40.150020"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 569.39, "latencies_ms": [569.39], "images_per_second": 1.756, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the small potted plants. The dog is further in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.51, 37.51, 42.88, 42.88, 42.88, 42.88], "power_watts_avg": 41.09, "power_watts_peak": 42.88, "energy_joules_est": 23.42, "sample_count": 6, "duration_seconds": 0.57}, "timestamp": "2026-01-11T13:30:40.759462"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 793.588, "latencies_ms": [793.588], "images_per_second": 1.26, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A cat and a dog are seen together on a wooden surface, possibly a table or deck. The cat is sitting and looking down, while the dog stands nearby, seemingly observing the cat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.88, 37.87, 37.87, 37.87, 37.87, 37.87, 39.31, 39.31], "power_watts_avg": 38.86, "power_watts_peak": 42.88, "energy_joules_est": 30.85, "sample_count": 8, "duration_seconds": 0.794}, "timestamp": "2026-01-11T13:30:41.567706"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 741.339, "latencies_ms": [741.339], "images_per_second": 1.349, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The cat is gray, and the dog is brown. The lighting appears to be natural daylight. The cat and dog are sitting near a wooden table and planters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.1, "ram_available_mb": 109451.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [39.31, 39.31, 42.69, 42.69, 42.69, 42.69, 42.69, 38.4], "power_watts_avg": 41.3, "power_watts_peak": 42.69, "energy_joules_est": 30.63, "sample_count": 8, "duration_seconds": 0.742}, "timestamp": "2026-01-11T13:30:42.374901"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 759.958, "latencies_ms": [759.958], "images_per_second": 1.316, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A female soccer player in a blue jersey is skillfully dribbling the ball while another player in a yellow jersey watches.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [38.4, 38.4, 38.4, 38.4, 42.5, 42.5, 42.5, 42.5], "power_watts_avg": 40.45, "power_watts_peak": 42.5, "energy_joules_est": 30.77, "sample_count": 8, "duration_seconds": 0.761}, "timestamp": "2026-01-11T13:30:43.187257"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1206.641, "latencies_ms": [1206.641], "images_per_second": 0.829, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "woman: 1\nball: 1\njersey: 1\nshorts: 1\nheadband: 1\nhair: 1\nface: 1\nbackground: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.5, 44.23, 44.23, 44.23, 44.23, 44.23, 42.6, 42.6, 42.6, 42.6, 42.6, 41.73, 41.73], "power_watts_avg": 43.08, "power_watts_peak": 44.23, "energy_joules_est": 52.01, "sample_count": 13, "duration_seconds": 1.207}, "timestamp": "2026-01-11T13:30:44.498865"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 718.228, "latencies_ms": [718.228], "images_per_second": 1.392, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The ball is positioned in the foreground, slightly to the left of the main subject. The background is blurred, suggesting the focus is on the player in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.73, 41.73, 41.73, 42.19, 42.19, 42.19, 42.19, 42.19], "power_watts_avg": 42.01, "power_watts_peak": 42.19, "energy_joules_est": 30.2, "sample_count": 8, "duration_seconds": 0.719}, "timestamp": "2026-01-11T13:30:45.309895"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 785.905, "latencies_ms": [785.905], "images_per_second": 1.272, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A female soccer player in a blue jersey is dribbling the ball on a field. Another player in a yellow jersey is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [41.67, 41.67, 41.67, 41.67, 41.67, 41.92, 41.92, 41.92], "power_watts_avg": 41.76, "power_watts_peak": 41.92, "energy_joules_est": 32.84, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:30:46.119284"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 804.872, "latencies_ms": [804.872], "images_per_second": 1.242, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The player is wearing a blue jersey with red and white accents. The ball is white with blue and red markings. The setting appears to be outdoors in natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.92, 41.92, 48.66, 48.66, 48.66, 48.66, 48.66, 43.76, 43.76], "power_watts_avg": 46.07, "power_watts_peak": 48.66, "energy_joules_est": 37.1, "sample_count": 9, "duration_seconds": 0.805}, "timestamp": "2026-01-11T13:30:47.027636"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 534.965, "latencies_ms": [534.965], "images_per_second": 1.869, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two giraffes stand in a grassy enclosure, one leaning over a wooden fence while the other faces away from the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 40.93, 40.93, 40.93], "power_watts_avg": 42.34, "power_watts_peak": 43.76, "energy_joules_est": 22.68, "sample_count": 6, "duration_seconds": 0.536}, "timestamp": "2026-01-11T13:30:47.637790"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 844.482, "latencies_ms": [844.482], "images_per_second": 1.184, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "giraffe: 2\nfence: 1\ntrees: 6\ngrass: 6\ndirt: 1\npath: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 24.0}, "power_stats": {"power_watts_samples": [40.93, 40.93, 40.7, 40.7, 40.7, 40.7, 40.7, 37.51, 37.51], "power_watts_avg": 40.04, "power_watts_peak": 40.93, "energy_joules_est": 33.83, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-11T13:30:48.548177"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 975.182, "latencies_ms": [975.182], "images_per_second": 1.025, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The giraffes are positioned near the fence and trees in the background, suggesting they are in a relatively enclosed area. The giraffes are situated in a grassy area, which further reinforces the impression of a zoo or wildlife park setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.8, "ram_available_mb": 109447.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [37.51, 37.51, 37.51, 38.13, 38.13, 38.13, 38.13, 38.13, 37.67, 37.67], "power_watts_avg": 37.85, "power_watts_peak": 38.13, "energy_joules_est": 36.92, "sample_count": 10, "duration_seconds": 0.975}, "timestamp": "2026-01-11T13:30:49.556612"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1074.032, "latencies_ms": [1074.032], "images_per_second": 0.931, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "Two giraffes are in a zoo enclosure. One giraffe is bending over a wooden fence, seemingly reaching for something, while the other giraffe stands nearby, observing its surroundings. The enclosure is surrounded by lush green trees and grass, creating a natural habitat for the animals.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13058.8, "ram_available_mb": 109447.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [37.67, 37.67, 37.67, 38.29, 38.29, 38.29, 38.29, 38.29, 38.24, 38.24, 38.24], "power_watts_avg": 38.11, "power_watts_peak": 38.29, "energy_joules_est": 40.94, "sample_count": 11, "duration_seconds": 1.074}, "timestamp": "2026-01-11T13:30:50.667594"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 804.427, "latencies_ms": [804.427], "images_per_second": 1.243, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The giraffes exhibit a mix of brown and tan patterns, illuminated by natural daylight. The enclosure is constructed from light-colored wood and features natural greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [38.24, 36.06, 36.06, 36.06, 36.06, 36.06, 37.43, 37.43, 37.43], "power_watts_avg": 36.76, "power_watts_peak": 38.24, "energy_joules_est": 29.59, "sample_count": 9, "duration_seconds": 0.805}, "timestamp": "2026-01-11T13:30:51.575881"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 773.697, "latencies_ms": [773.697], "images_per_second": 1.292, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Three pieces of luggage, including a suitcase, a duffel bag, and a smaller bag, are neatly arranged on the floor near a curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [37.43, 37.43, 42.16, 42.16, 42.16, 42.16, 42.16, 43.35], "power_watts_avg": 41.12, "power_watts_peak": 43.35, "energy_joules_est": 31.84, "sample_count": 8, "duration_seconds": 0.774}, "timestamp": "2026-01-11T13:30:52.386272"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 994.037, "latencies_ms": [994.037], "images_per_second": 1.006, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "suitcase: 1\nbag: 1\ncarpet: 1\ncurtains: 1\nbooks: 2\nplastic bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 43.35, 47.82, 47.82, 47.82, 47.82, 47.82, 44.81], "power_watts_avg": 45.73, "power_watts_peak": 47.82, "energy_joules_est": 45.49, "sample_count": 10, "duration_seconds": 0.995}, "timestamp": "2026-01-11T13:30:53.396038"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1127.884, "latencies_ms": [1127.884], "images_per_second": 0.887, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close arrangement, with the suitcase and handbag in the foreground and the black bag and suitcase further back. The suitcase is situated between the handbag and the black bag, creating a sense of depth in the composition.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [44.81, 44.81, 44.81, 44.81, 45.16, 45.16, 45.16, 45.16, 45.16, 45.04, 45.04, 45.04], "power_watts_avg": 45.02, "power_watts_peak": 45.16, "energy_joules_est": 50.79, "sample_count": 12, "duration_seconds": 1.128}, "timestamp": "2026-01-11T13:30:54.607479"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 969.987, "latencies_ms": [969.987], "images_per_second": 1.031, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a room with several pieces of luggage, including a suitcase, a tote bag, and a smaller bag, arranged on the floor near a curtain. The bags appear to be packed for travel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [45.04, 45.04, 39.47, 39.47, 39.47, 39.47, 39.47, 44.07, 44.07, 44.07], "power_watts_avg": 41.96, "power_watts_peak": 45.04, "energy_joules_est": 40.72, "sample_count": 10, "duration_seconds": 0.97}, "timestamp": "2026-01-11T13:30:55.616613"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1210.744, "latencies_ms": [1210.744], "images_per_second": 0.826, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The suitcase appears to be gray or dark gray in color. The lighting in the image is soft and diffused, suggesting natural light coming from a window or overhead light. The suitcase appears to be made of fabric or canvas, potentially a soft material suitable for travel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.07, 44.07, 44.42, 44.42, 44.42, 44.42, 44.42, 44.95, 44.95, 44.95, 44.95, 44.95, 38.85], "power_watts_avg": 44.14, "power_watts_peak": 44.95, "energy_joules_est": 53.47, "sample_count": 13, "duration_seconds": 1.211}, "timestamp": "2026-01-11T13:30:56.928056"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 605.065, "latencies_ms": [605.065], "images_per_second": 1.653, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two men are riding donkeys down a rocky trail in a forest, surrounded by tall trees and rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.85, 38.85, 38.85, 38.85, 42.0, 42.0, 42.0], "power_watts_avg": 40.2, "power_watts_peak": 42.0, "energy_joules_est": 24.36, "sample_count": 7, "duration_seconds": 0.606}, "timestamp": "2026-01-11T13:30:57.636174"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1180.56, "latencies_ms": [1180.56], "images_per_second": 0.847, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "tree: 5\nrocks: 6\nhorse: 2\nman: 2\nbandana: 1\nbackpack: 1\nground: 2\npath: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.0, 42.0, 45.92, 45.92, 45.92, 45.92, 45.92, 42.04, 42.04, 42.04, 42.04, 42.04], "power_watts_avg": 43.65, "power_watts_peak": 45.92, "energy_joules_est": 51.55, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-11T13:30:58.848022"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 922.439, "latencies_ms": [922.439], "images_per_second": 1.084, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The man and horse are positioned in the foreground of the image, moving along a path that extends into the background. The man and horse are relatively close to the viewer, while the path extends further into the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.36, 39.36, 39.36, 39.36, 39.36, 43.8, 43.8, 43.8, 43.8, 43.8], "power_watts_avg": 41.58, "power_watts_peak": 43.8, "energy_joules_est": 38.37, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-11T13:30:59.857728"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 683.211, "latencies_ms": [683.211], "images_per_second": 1.464, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two people are riding donkeys along a rocky trail in a forest. The trail is surrounded by tall trees and appears to be well-traveled.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.0, "ram_available_mb": 109446.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 44.03, 44.03, 44.03, 43.08, 43.08], "power_watts_avg": 43.76, "power_watts_peak": 44.03, "energy_joules_est": 29.93, "sample_count": 7, "duration_seconds": 0.684}, "timestamp": "2026-01-11T13:31:00.566555"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1365.617, "latencies_ms": [1365.617], "images_per_second": 0.732, "prompt_tokens": 18, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The scene is bathed in sunlight, creating a warm and inviting atmosphere. The colors are vibrant, with the green of the trees contrasting with the blue of the man's shirt and the brown of the horses' coats. The lighting is natural, illuminating the path and the surrounding forest. The materials appear to be natural, sturdy, and suitable for outdoor activities.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13059.9, "ram_available_mb": 109446.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.08, 43.08, 51.73, 51.73, 51.73, 51.73, 51.73, 44.13, 44.13, 44.13, 44.13, 44.13, 35.43, 35.43], "power_watts_avg": 45.45, "power_watts_peak": 51.73, "energy_joules_est": 62.08, "sample_count": 14, "duration_seconds": 1.366}, "timestamp": "2026-01-11T13:31:01.978876"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 651.3, "latencies_ms": [651.3], "images_per_second": 1.535, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A man in a sweatshirt and jeans rides a horse, holding the reins and guiding it along a track.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.43, 35.43, 35.43, 43.32, 43.32, 43.32, 43.32], "power_watts_avg": 39.94, "power_watts_peak": 43.32, "energy_joules_est": 26.03, "sample_count": 7, "duration_seconds": 0.652}, "timestamp": "2026-01-11T13:31:02.688546"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1390.958, "latencies_ms": [1390.958], "images_per_second": 0.719, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "horse: 1\nman: 1\nsaddle: 1\ncowboy hat: 0\nhelmet: 0\nhelmet: 0\nhelmet: 0\nhelmet: 0\nhelmet: 0", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.32, 44.88, 44.88, 44.88, 44.88, 44.88, 43.4, 43.4, 43.4, 43.4, 43.4, 42.03, 42.03, 42.03], "power_watts_avg": 43.63, "power_watts_peak": 44.88, "energy_joules_est": 60.7, "sample_count": 14, "duration_seconds": 1.391}, "timestamp": "2026-01-11T13:31:04.101052"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 841.694, "latencies_ms": [841.694], "images_per_second": 1.188, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The man is positioned near the foreground of the image, riding a horse. The background features blurred structures, possibly buildings or tents, which create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.03, 42.03, 40.97, 40.97, 40.97, 40.97, 40.97, 44.03, 44.03], "power_watts_avg": 41.88, "power_watts_peak": 44.03, "energy_joules_est": 35.29, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:31:05.012542"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 826.021, "latencies_ms": [826.021], "images_per_second": 1.211, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A man is riding a horse in a black and white image, possibly at a racetrack or similar venue. The horse and rider appear to be in motion, creating a dynamic scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 44.03, 46.51, 46.51, 46.51, 46.51, 46.51, 43.03], "power_watts_avg": 45.29, "power_watts_peak": 46.51, "energy_joules_est": 37.43, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:31:05.920789"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 725.106, "latencies_ms": [725.106], "images_per_second": 1.379, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The horse and rider appear to be wearing dark-colored clothing. The background is blurred, suggesting motion, and appears to be outdoors in natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.03, 43.03, 43.03, 43.03, 42.56, 42.56, 42.56, 42.56], "power_watts_avg": 42.79, "power_watts_peak": 43.03, "energy_joules_est": 31.06, "sample_count": 8, "duration_seconds": 0.726}, "timestamp": "2026-01-11T13:31:06.732829"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 622.942, "latencies_ms": [622.942], "images_per_second": 1.605, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Three ducks are swimming leisurely in a calm, reflective body of water, surrounded by lush greenery and tall grasses.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [42.56, 41.03, 41.03, 41.03, 41.03, 41.03, 42.48], "power_watts_avg": 41.46, "power_watts_peak": 42.56, "energy_joules_est": 25.85, "sample_count": 7, "duration_seconds": 0.623}, "timestamp": "2026-01-11T13:31:07.445162"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 938.356, "latencies_ms": [938.356], "images_per_second": 1.066, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "goose: 4\nwater: 4\nshore: 4\ngrass: 4\ntrees: 4\nbushes: 4", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13059.1, "ram_available_mb": 109447.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 42.48, 52.91, 52.91, 52.91, 52.91, 52.91, 42.81], "power_watts_avg": 47.73, "power_watts_peak": 52.91, "energy_joules_est": 44.8, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-11T13:31:08.455678"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 759.545, "latencies_ms": [759.545], "images_per_second": 1.317, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground of the image, with the water providing a background. The geese are situated near the water's edge, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.81, 42.81, 42.81, 42.81, 42.97, 42.97, 42.97, 42.97], "power_watts_avg": 42.89, "power_watts_peak": 42.97, "energy_joules_est": 32.61, "sample_count": 8, "duration_seconds": 0.76}, "timestamp": "2026-01-11T13:31:09.264339"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 597.285, "latencies_ms": [597.285], "images_per_second": 1.674, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of geese is swimming in a calm body of water near a grassy bank with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.97, 42.33, 42.33, 42.33, 42.33, 42.33], "power_watts_avg": 42.44, "power_watts_peak": 42.97, "energy_joules_est": 25.36, "sample_count": 6, "duration_seconds": 0.598}, "timestamp": "2026-01-11T13:31:09.871236"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1101.778, "latencies_ms": [1101.778], "images_per_second": 0.908, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The water is a calm, reflective blue-green. The lighting suggests a sunny day, with some shadows cast on the water's surface. The scene is dominated by natural colors, with green vegetation and brown grasses along the shoreline.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 43.27, 43.27, 53.49, 53.49, 53.49, 53.49, 53.49, 43.83, 43.83], "power_watts_avg": 48.02, "power_watts_peak": 53.49, "energy_joules_est": 52.92, "sample_count": 11, "duration_seconds": 1.102}, "timestamp": "2026-01-11T13:31:10.984309"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 612.112, "latencies_ms": [612.112], "images_per_second": 1.634, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "An orange and white cat is comfortably resting on the hood of a black Mercedes-Benz car parked in a residential area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.83, 43.83, 43.83, 38.44, 38.44, 38.44, 38.44], "power_watts_avg": 40.75, "power_watts_peak": 43.83, "energy_joules_est": 24.96, "sample_count": 7, "duration_seconds": 0.612}, "timestamp": "2026-01-11T13:31:11.693824"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1081.188, "latencies_ms": [1081.188], "images_per_second": 0.925, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "cat: 1\ncar: 1\nmercedes: 1\ngrill: 1\nbush: 1\nfence: 1\nwindow: 2\nbuilding: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.44, 39.47, 39.47, 39.47, 39.47, 39.47, 37.07, 37.07, 37.07, 37.07, 37.07], "power_watts_avg": 38.28, "power_watts_peak": 39.47, "energy_joules_est": 41.4, "sample_count": 11, "duration_seconds": 1.081}, "timestamp": "2026-01-11T13:31:12.802697"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 713.488, "latencies_ms": [713.488], "images_per_second": 1.402, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The cat is positioned on the car's hood, near the front grill. The car is parked in front of a house with a fence and plants visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.26, 36.26, 36.26, 36.26, 36.26, 38.14, 38.14, 38.14], "power_watts_avg": 36.97, "power_watts_peak": 38.14, "energy_joules_est": 26.4, "sample_count": 8, "duration_seconds": 0.714}, "timestamp": "2026-01-11T13:31:13.611932"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 802.202, "latencies_ms": [802.202], "images_per_second": 1.247, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A calico cat is resting on the hood of a black Mercedes-Benz parked on a residential street. The car is parked in front of a house with a green bush nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 38.0}, "power_stats": {"power_watts_samples": [38.14, 38.14, 41.02, 41.02, 41.02, 41.02, 41.02, 36.84], "power_watts_avg": 39.78, "power_watts_peak": 41.02, "energy_joules_est": 31.92, "sample_count": 8, "duration_seconds": 0.802}, "timestamp": "2026-01-11T13:31:14.419091"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 554.063, "latencies_ms": [554.063], "images_per_second": 1.805, "prompt_tokens": 18, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The car is black and appears to be made of metal. The lighting suggests it's daytime, and the weather seems pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.84, 36.84, 36.84, 36.84, 38.32, 38.32], "power_watts_avg": 37.33, "power_watts_peak": 38.32, "energy_joules_est": 20.69, "sample_count": 6, "duration_seconds": 0.554}, "timestamp": "2026-01-11T13:31:15.026623"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 841.486, "latencies_ms": [841.486], "images_per_second": 1.188, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A snowboarder in a brown jacket and yellow pants is captured mid-air, performing a trick against a clear blue sky, with snow spraying up behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.32, 38.32, 38.32, 46.56, 46.56, 46.56, 46.56, 46.56, 42.74], "power_watts_avg": 43.39, "power_watts_peak": 46.56, "energy_joules_est": 36.52, "sample_count": 9, "duration_seconds": 0.842}, "timestamp": "2026-01-11T13:31:15.935672"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1264.307, "latencies_ms": [1264.307], "images_per_second": 0.791, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "snowboard: 1\nsnow: 2\nsky: 1\nclouds: 0\nperson: 1\ngloves: 1\nhelmet: 1\npants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.74, 42.74, 42.74, 42.74, 43.1, 43.1, 43.1, 43.1, 43.1, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 42.89, "power_watts_peak": 43.1, "energy_joules_est": 54.24, "sample_count": 13, "duration_seconds": 1.265}, "timestamp": "2026-01-11T13:31:17.247885"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1045.768, "latencies_ms": [1045.768], "images_per_second": 0.956, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The snowboarder is positioned in the foreground, mid-air, against a clear blue sky. The snowboard is situated in the background, slightly elevated above the snow. The snowboarder is angled towards the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.77, 33.01, 33.01, 33.01, 33.01, 33.01, 43.38, 43.38, 43.38, 43.38, 43.38], "power_watts_avg": 38.61, "power_watts_peak": 43.38, "energy_joules_est": 40.4, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-11T13:31:18.360015"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 743.091, "latencies_ms": [743.091], "images_per_second": 1.346, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A snowboarder is captured mid-air, performing a trick against a clear blue sky. The scene takes place on a snow-covered slope.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.85, 43.85, 43.85, 43.85, 43.85, 42.97, 42.97, 42.97], "power_watts_avg": 43.52, "power_watts_peak": 43.85, "energy_joules_est": 32.36, "sample_count": 8, "duration_seconds": 0.744}, "timestamp": "2026-01-11T13:31:19.170069"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 917.75, "latencies_ms": [917.75], "images_per_second": 1.09, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The snowboarder is wearing a brown jacket and yellow pants. The sky is clear and blue, indicating a sunny day. The snowboard is white and appears to be made of foam or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.97, 45.6, 45.6, 45.6, 45.6, 45.6, 42.9, 42.9, 42.9, 42.9], "power_watts_avg": 44.26, "power_watts_peak": 45.6, "energy_joules_est": 40.63, "sample_count": 10, "duration_seconds": 0.918}, "timestamp": "2026-01-11T13:31:20.179799"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 783.418, "latencies_ms": [783.418], "images_per_second": 1.276, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The bathroom features a vintage-style toilet with a wooden seat and a white tank, situated beneath a white pipe and partially hidden by a wooden door.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.9, 41.89, 41.89, 41.89, 41.89, 41.89, 42.59, 42.59], "power_watts_avg": 42.19, "power_watts_peak": 42.9, "energy_joules_est": 33.08, "sample_count": 8, "duration_seconds": 0.784}, "timestamp": "2026-01-11T13:31:20.989047"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1286.518, "latencies_ms": [1286.518], "images_per_second": 0.777, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Toilet: 1\nBathtub: 1\nPipes: 6\nChain: 1\nPaper: 1\nFloor: 1\nWalls: 2\nDoor: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 42.59, 51.16, 51.16, 51.16, 51.16, 51.16, 43.66, 43.66, 43.66, 43.66, 43.66], "power_watts_avg": 46.3, "power_watts_peak": 51.16, "energy_joules_est": 59.58, "sample_count": 13, "duration_seconds": 1.287}, "timestamp": "2026-01-11T13:31:22.299294"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 721.966, "latencies_ms": [721.966], "images_per_second": 1.385, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, slightly to the left of the bathtub. The bathtub is situated in the background, further away from the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.02, 34.02, 34.02, 34.02, 34.02, 44.0, 44.0, 44.0], "power_watts_avg": 37.76, "power_watts_peak": 44.0, "energy_joules_est": 27.27, "sample_count": 8, "duration_seconds": 0.722}, "timestamp": "2026-01-11T13:31:23.107238"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1220.691, "latencies_ms": [1220.691], "images_per_second": 0.819, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The bathroom features a vintage-style toilet with a wooden seat and a chain hanging from the tank. A white bathtub is situated next to the toilet, partially obscured by pipes. The space appears to be in a basement or attic area, with exposed pipes and aged fixtures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.0, 44.0, 49.29, 49.29, 49.29, 49.29, 49.29, 42.36, 42.36, 42.36, 42.36, 42.36, 36.54], "power_watts_avg": 44.83, "power_watts_peak": 49.29, "energy_joules_est": 54.74, "sample_count": 13, "duration_seconds": 1.221}, "timestamp": "2026-01-11T13:31:24.419631"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1020.73, "latencies_ms": [1020.73], "images_per_second": 0.98, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The bathroom features a predominantly white color scheme with exposed pipes and fixtures. The lighting is dim, creating a somewhat subdued atmosphere. The materials appear to be old and possibly antique, contributing to the vintage feel of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [36.54, 36.54, 36.54, 36.54, 42.09, 42.09, 42.09, 42.09, 42.09, 42.2, 42.2], "power_watts_avg": 40.09, "power_watts_peak": 42.2, "energy_joules_est": 40.94, "sample_count": 11, "duration_seconds": 1.021}, "timestamp": "2026-01-11T13:31:25.530607"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 835.963, "latencies_ms": [835.963], "images_per_second": 1.196, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The statue depicts two children, one standing and one kneeling, holding a colorful kite that soars high above them, symbolizing freedom and joy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.2, 42.2, 42.2, 41.88, 41.88, 41.88, 41.88, 41.88, 42.19], "power_watts_avg": 42.02, "power_watts_peak": 42.2, "energy_joules_est": 35.14, "sample_count": 9, "duration_seconds": 0.836}, "timestamp": "2026-01-11T13:31:26.440830"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 993.007, "latencies_ms": [993.007], "images_per_second": 1.007, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "kite: 1\nstatue: 2\nbuilding: 1\nsky: 1\nclouds: 1\nreflection: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.19, 42.19, 42.19, 42.19, 42.51, 42.51, 42.51, 42.51, 42.51, 42.35], "power_watts_avg": 42.36, "power_watts_peak": 42.51, "energy_joules_est": 42.1, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-11T13:31:27.449767"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 731.374, "latencies_ms": [731.374], "images_per_second": 1.367, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The statue is positioned in the foreground, slightly to the right of the kite. The kite is situated in the background, near the top of the building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [42.35, 42.35, 42.35, 42.35, 43.98, 43.98, 43.98, 43.98], "power_watts_avg": 43.16, "power_watts_peak": 43.98, "energy_joules_est": 31.58, "sample_count": 8, "duration_seconds": 0.732}, "timestamp": "2026-01-11T13:31:28.261394"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1154.222, "latencies_ms": [1154.222], "images_per_second": 0.866, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Two bronze statues of children, one holding a colorful kite, are positioned on a pedestal in front of a modern glass and steel building. The scene suggests a public space, possibly a park or plaza, where children play and enjoy the outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.98, 42.44, 42.44, 42.44, 42.44, 42.44, 42.35, 42.35, 42.35, 42.35, 42.35, 43.78], "power_watts_avg": 42.64, "power_watts_peak": 43.98, "energy_joules_est": 49.23, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:31:29.469818"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1290.113, "latencies_ms": [1290.113], "images_per_second": 0.775, "prompt_tokens": 18, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The kite is multicolored with stripes of yellow, blue, and red. The lighting in the image is soft and diffused, suggesting an overcast sky. The statue appears to be made of a light-colored material, possibly stone or concrete. The overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 42.93, 42.93, 42.93, 42.93, 42.93, 43.04, 43.04, 43.04, 43.04, 43.04], "power_watts_avg": 43.17, "power_watts_peak": 43.78, "energy_joules_est": 55.73, "sample_count": 13, "duration_seconds": 1.291}, "timestamp": "2026-01-11T13:31:30.783173"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 957.614, "latencies_ms": [957.614], "images_per_second": 1.044, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A wooden table displays a vibrant array of fresh vegetables, including red radishes, green asparagus, carrots, potatoes, cucumbers, broccoli, strawberries, and green beans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [33.36, 33.36, 33.36, 33.36, 33.36, 43.15, 43.15, 43.15, 43.15, 43.15], "power_watts_avg": 38.25, "power_watts_peak": 43.15, "energy_joules_est": 36.65, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-11T13:31:31.796209"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1354.106, "latencies_ms": [1354.106], "images_per_second": 0.738, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "strawberries: 10\nbroccoli: 2\ncucumbers: 2\nasparagus: 1\nradishes: 8\npeas: 1\ncarrots: 4\npotatoes: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.81, 42.81, 42.81, 42.81, 42.81, 43.08, 43.08, 43.08, 43.08, 43.08, 43.58, 43.58, 43.58, 43.58], "power_watts_avg": 43.13, "power_watts_peak": 43.58, "energy_joules_est": 58.42, "sample_count": 14, "duration_seconds": 1.355}, "timestamp": "2026-01-11T13:31:33.211373"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 952.825, "latencies_ms": [952.825], "images_per_second": 1.05, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The strawberries are positioned to the left of the vegetables, occupying the foreground. The vegetables, including carrots, radishes, potatoes, and green beans, are spread out in the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.58, 35.11, 35.11, 35.11, 35.11, 35.11, 43.05, 43.05, 43.05, 43.05], "power_watts_avg": 39.13, "power_watts_peak": 43.58, "energy_joules_est": 37.31, "sample_count": 10, "duration_seconds": 0.953}, "timestamp": "2026-01-11T13:31:34.221539"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1231.219, "latencies_ms": [1231.219], "images_per_second": 0.812, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a vibrant display of fresh produce, including strawberries, broccoli, radishes, carrots, asparagus, potatoes, and green beans. The produce is arranged on a wooden surface, possibly a table or countertop, showcasing a colorful and healthy assortment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.05, 43.77, 43.77, 43.77, 43.77, 43.77, 43.45, 43.45, 43.45, 43.45, 43.45, 42.46, 42.46], "power_watts_avg": 43.39, "power_watts_peak": 43.77, "energy_joules_est": 53.44, "sample_count": 13, "duration_seconds": 1.232}, "timestamp": "2026-01-11T13:31:35.530588"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1056.593, "latencies_ms": [1056.593], "images_per_second": 0.946, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The produce displays vibrant colors, including reds, greens, and oranges. The lighting appears to be natural, possibly from overhead, suggesting an outdoor setting. The vegetables appear to be fresh and crisp, indicating good quality and care in preparation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 42.46, 42.2, 42.2, 42.2, 42.2, 42.2, 42.26, 42.26, 42.26], "power_watts_avg": 42.28, "power_watts_peak": 42.46, "energy_joules_est": 44.7, "sample_count": 11, "duration_seconds": 1.057}, "timestamp": "2026-01-11T13:31:36.642083"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 692.98, "latencies_ms": [692.98], "images_per_second": 1.443, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three friends are laughing and playing a video game together, sitting on a bed and using Wii remotes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.26, 42.26, 39.15, 39.15, 39.15, 39.15, 39.15], "power_watts_avg": 40.04, "power_watts_peak": 42.26, "energy_joules_est": 27.78, "sample_count": 7, "duration_seconds": 0.694}, "timestamp": "2026-01-11T13:31:37.350445"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1203.93, "latencies_ms": [1203.93], "images_per_second": 0.831, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "projector: 1\nscreen: 1\nwii controller: 2\ncouch: 2\nman: 3\nman: 2\nman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.91, 42.91, 42.91, 42.91, 42.91, 48.46, 48.46, 48.46, 48.46, 48.46, 43.5, 43.5], "power_watts_avg": 45.32, "power_watts_peak": 48.46, "energy_joules_est": 54.58, "sample_count": 12, "duration_seconds": 1.204}, "timestamp": "2026-01-11T13:31:38.561798"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 812.566, "latencies_ms": [812.566], "images_per_second": 1.231, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the projection screen and remote control placed behind them. The background is somewhat blurred, drawing attention to the people in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 43.5, 43.7, 43.7, 43.7, 43.7, 43.7, 44.03], "power_watts_avg": 43.67, "power_watts_peak": 44.03, "energy_joules_est": 35.5, "sample_count": 9, "duration_seconds": 0.813}, "timestamp": "2026-01-11T13:31:39.467549"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 813.038, "latencies_ms": [813.038], "images_per_second": 1.23, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Three people are gathered in a dimly lit room, watching a video game on a projector. They are comfortably seated on a couch and bed, each holding a game controller.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 44.03, 44.03, 42.99, 42.99, 42.99, 42.99, 42.99], "power_watts_avg": 43.46, "power_watts_peak": 44.03, "energy_joules_est": 35.35, "sample_count": 9, "duration_seconds": 0.813}, "timestamp": "2026-01-11T13:31:40.377392"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1135.622, "latencies_ms": [1135.622], "images_per_second": 0.881, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The room is dimly lit, creating a moody atmosphere. The walls appear to be a light color, possibly white or off-white. The couch is covered in a colorful, patterned fabric. The overall ambiance suggests a casual, relaxed setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 42.53, 42.53, 42.01, 42.01, 42.01, 42.01, 42.01, 42.0, 42.0, 42.0], "power_watts_avg": 42.18, "power_watts_peak": 42.53, "energy_joules_est": 47.93, "sample_count": 12, "duration_seconds": 1.136}, "timestamp": "2026-01-11T13:31:41.591353"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 622.107, "latencies_ms": [622.107], "images_per_second": 1.607, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A group of cows, including white, brown, and black ones, are resting and grazing peacefully in a lush green field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [42.0, 42.0, 41.1, 41.1, 41.1, 41.1, 41.1], "power_watts_avg": 41.36, "power_watts_peak": 42.0, "energy_joules_est": 25.74, "sample_count": 7, "duration_seconds": 0.622}, "timestamp": "2026-01-11T13:31:42.302408"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1219.949, "latencies_ms": [1219.949], "images_per_second": 0.82, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "tree: 1\ncow: 5\nsheep: 1\ngrass: 8\ncow: 5\ncow: 1\ncow: 1\ncow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.77, 41.77, 41.77, 41.77, 41.77, 44.39, 44.39, 44.39, 44.39, 44.39, 43.77, 43.77, 43.77], "power_watts_avg": 43.24, "power_watts_peak": 44.39, "energy_joules_est": 52.76, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:31:43.616501"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 999.312, "latencies_ms": [999.312], "images_per_second": 1.001, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The foreground features a young lamb resting near the base of a tree, positioned between the foreground and the background. The background includes several cows lying down in the grassy field, extending from the foreground to the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 39.48, 39.48, 39.48, 39.48, 39.48, 42.19, 42.19, 42.19], "power_watts_avg": 41.15, "power_watts_peak": 43.77, "energy_joules_est": 41.14, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:31:44.627785"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 679.326, "latencies_ms": [679.326], "images_per_second": 1.472, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A group of cows, including some calves, are resting in a lush green field. A large tree trunk is visible near the animals.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.19, 42.19, 43.59, 43.59, 43.59, 43.59, 43.59], "power_watts_avg": 43.19, "power_watts_peak": 43.59, "energy_joules_est": 29.36, "sample_count": 7, "duration_seconds": 0.68}, "timestamp": "2026-01-11T13:31:45.337412"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 975.728, "latencies_ms": [975.728], "images_per_second": 1.025, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The field is predominantly green with patches of sunlight filtering through the trees, creating a bright and peaceful atmosphere. The grass appears lush and well-maintained, contributing to the overall tranquility of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.87, 43.87, 43.87, 43.87, 43.87, 47.49, 47.49, 47.49, 47.49, 47.49], "power_watts_avg": 45.68, "power_watts_peak": 47.49, "energy_joules_est": 44.6, "sample_count": 10, "duration_seconds": 0.976}, "timestamp": "2026-01-11T13:31:46.349474"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 745.465, "latencies_ms": [745.465], "images_per_second": 1.341, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A large group of boys in uniform, sitting and standing together in front of a brick building, poses for a school photograph in April 1929.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 43.46, 43.46, 43.46, 43.52, 43.52, 43.52], "power_watts_avg": 43.48, "power_watts_peak": 43.52, "energy_joules_est": 32.44, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-11T13:31:47.159928"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1330.974, "latencies_ms": [1330.974], "images_per_second": 0.751, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "group: 20\nboys: 20\nschool building: 10\nsitting: 10\nsocks: 10\nshoes: 10\njackets: 10\nsuits: 10\nties: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.2, "ram_available_mb": 109448.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 47.66, 47.66, 47.66, 47.66, 47.66, 43.03, 43.03, 43.03, 43.03, 43.03, 38.89, 38.89], "power_watts_avg": 44.16, "power_watts_peak": 47.66, "energy_joules_est": 58.8, "sample_count": 14, "duration_seconds": 1.331}, "timestamp": "2026-01-11T13:31:48.570603"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 855.886, "latencies_ms": [855.886], "images_per_second": 1.168, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal formation, with the boys standing and sitting in the foreground and the brick building in the background. The boys are grouped together, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.2, "ram_available_mb": 109448.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.2, "ram_available_mb": 109448.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.89, 38.89, 38.89, 41.69, 41.69, 41.69, 41.69, 42.54, 42.54], "power_watts_avg": 40.95, "power_watts_peak": 42.54, "energy_joules_est": 35.07, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-11T13:31:49.480216"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 992.479, "latencies_ms": [992.479], "images_per_second": 1.008, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A large group of boys, likely from Goodmayes Boys' School, poses for a group photograph in April 1929. The photo captures the school building in the background and the boys sitting on the ground in front.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.2, "ram_available_mb": 109448.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 43.64, 43.64, 43.64, 43.64, 43.64, 42.77, 42.77], "power_watts_avg": 43.14, "power_watts_peak": 43.64, "energy_joules_est": 42.84, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-11T13:31:50.489699"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 905.422, "latencies_ms": [905.422], "images_per_second": 1.104, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The photograph is in black and white and appears to be taken outdoors in natural light. The students are wearing formal attire, including suits and ties. The building in the background suggests a school setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 43.28, 43.28, 43.28, 43.28, 43.28, 43.35, 43.35], "power_watts_avg": 43.14, "power_watts_peak": 43.35, "energy_joules_est": 39.08, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-11T13:31:51.499900"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 624.691, "latencies_ms": [624.691], "images_per_second": 1.601, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A rainbow-colored kite soars high in the blue sky, tethered to a person standing on a grassy field below.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 36.66, 36.66, 36.66, 36.66], "power_watts_avg": 39.53, "power_watts_peak": 43.35, "energy_joules_est": 24.71, "sample_count": 7, "duration_seconds": 0.625}, "timestamp": "2026-01-11T13:31:52.209566"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 707.868, "latencies_ms": [707.868], "images_per_second": 1.413, "prompt_tokens": 21, "response_tokens_est": 22, "n_tiles": 1, "output_text": "kite: 1\nperson: 1\ntrees: 4\nbuildings: 3\nsky: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.66, 37.74, 37.74, 37.74, 37.74, 37.74, 36.99, 36.99], "power_watts_avg": 37.42, "power_watts_peak": 37.74, "energy_joules_est": 26.5, "sample_count": 8, "duration_seconds": 0.708}, "timestamp": "2026-01-11T13:31:53.017668"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 856.949, "latencies_ms": [856.949], "images_per_second": 1.167, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The kite is positioned to the right of the image, flying high above a grassy field. The background features trees and residential buildings, suggesting the kite is flying in a park or open space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.99, 36.99, 36.99, 38.96, 38.96, 38.96, 38.96, 38.96, 36.84], "power_watts_avg": 38.07, "power_watts_peak": 38.96, "energy_joules_est": 32.64, "sample_count": 9, "duration_seconds": 0.857}, "timestamp": "2026-01-11T13:31:53.926289"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 679.066, "latencies_ms": [679.066], "images_per_second": 1.473, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene is set in a park-like area with trees and buildings in the background. A colorful kite is flying high in the sky, caught in the wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.84, 36.84, 36.84, 36.84, 37.86, 37.86, 37.86], "power_watts_avg": 37.28, "power_watts_peak": 37.86, "energy_joules_est": 25.34, "sample_count": 7, "duration_seconds": 0.68}, "timestamp": "2026-01-11T13:31:54.636907"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 881.65, "latencies_ms": [881.65], "images_per_second": 1.134, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The kite is brightly colored, showcasing a rainbow of hues. The lighting suggests a sunny day with clear skies. The materials appear to be fabric and possibly plastic, giving it a flexible and colorful appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.7, "ram_available_mb": 109447.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.6, "ram_available_mb": 109449.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [37.86, 37.86, 42.17, 42.17, 42.17, 42.17, 42.17, 38.29, 38.29], "power_watts_avg": 40.35, "power_watts_peak": 42.17, "energy_joules_est": 35.59, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-11T13:31:55.548666"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 621.843, "latencies_ms": [621.843], "images_per_second": 1.608, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A large cheese pizza with red sauce and melted cheese sits in a cardboard box on a black surface.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13056.6, "ram_available_mb": 109449.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13056.6, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [38.29, 38.29, 38.29, 43.32, 43.32, 43.32, 43.32], "power_watts_avg": 41.16, "power_watts_peak": 43.32, "energy_joules_est": 25.62, "sample_count": 7, "duration_seconds": 0.622}, "timestamp": "2026-01-11T13:31:56.262210"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1442.776, "latencies_ms": [1442.776], "images_per_second": 0.693, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Pizza: 8\nCheese: 8\nTomato sauce: 8\nPepperoni: 8\nTomato sauce: 8\nCheese: 8\nSauce: 8\nBaking: 8\nBox: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.6, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.6, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.32, 41.66, 41.66, 41.66, 41.66, 41.66, 42.94, 42.94, 42.94, 42.94, 42.94, 44.77, 44.77, 44.77, 44.77], "power_watts_avg": 43.03, "power_watts_peak": 44.77, "energy_joules_est": 62.1, "sample_count": 15, "duration_seconds": 1.443}, "timestamp": "2026-01-11T13:31:57.774781"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 986.245, "latencies_ms": [986.245], "images_per_second": 1.014, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object is a pizza placed in the center of the box. The pizza is situated in the foreground, with the box and pizza box occupying the background. The pizza is relatively large, suggesting it is likely a personal-sized pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.6, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [32.9, 32.9, 32.9, 32.9, 32.9, 42.97, 42.97, 42.97, 42.97, 42.97], "power_watts_avg": 37.93, "power_watts_peak": 42.97, "energy_joules_est": 37.42, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-11T13:31:58.784285"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 903.693, "latencies_ms": [903.693], "images_per_second": 1.107, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A large cheese pizza sits in a cardboard box on a dark surface. The pizza is cut into eight slices and appears freshly baked, with melted cheese covering the crust.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [44.02, 44.02, 44.02, 44.02, 44.02, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 43.62, "power_watts_peak": 44.02, "energy_joules_est": 39.44, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:31:59.693698"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1037.602, "latencies_ms": [1037.602], "images_per_second": 0.964, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The pizza is topped with melted cheese and has a golden-brown crust. The cheese appears slightly browned, indicating it has been cooked. The lighting in the image is bright, highlighting the colors and textures of the pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [43.13, 46.74, 46.74, 46.74, 46.74, 46.74, 43.8, 43.8, 43.8, 43.8, 43.8], "power_watts_avg": 45.08, "power_watts_peak": 46.74, "energy_joules_est": 46.78, "sample_count": 11, "duration_seconds": 1.038}, "timestamp": "2026-01-11T13:32:00.804697"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 664.873, "latencies_ms": [664.873], "images_per_second": 1.504, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Two women are sitting inside an open white refrigerator on a city sidewalk, one smoking a cigarette and the other holding a drink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13053.0, "ram_available_mb": 109453.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [40.72, 40.72, 40.72, 40.72, 40.72, 42.91, 42.91], "power_watts_avg": 41.34, "power_watts_peak": 42.91, "energy_joules_est": 27.5, "sample_count": 7, "duration_seconds": 0.665}, "timestamp": "2026-01-11T13:32:01.515913"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1176.378, "latencies_ms": [1176.378], "images_per_second": 0.85, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "woman: 2\nrefrigerator: 1\ncup: 2\ncigarette: 1\nwindow: 1\nstreet: 2\nsidewalk: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.0, "ram_available_mb": 109453.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13053.2, "ram_available_mb": 109453.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [42.91, 42.91, 42.91, 53.55, 53.55, 53.55, 53.55, 53.55, 43.68, 43.68, 43.68, 43.68], "power_watts_avg": 47.6, "power_watts_peak": 53.55, "energy_joules_est": 56.01, "sample_count": 12, "duration_seconds": 1.177}, "timestamp": "2026-01-11T13:32:02.726005"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1035.069, "latencies_ms": [1035.069], "images_per_second": 0.966, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The woman on the left is positioned in the foreground, leaning against the wall and holding a cigarette. The open refrigerator is situated in the background, partially obscured by the woman. The street and buildings are visible in the background, suggesting an urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.2, "ram_available_mb": 109453.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.2, "ram_available_mb": 109453.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.68, 35.03, 35.03, 35.03, 35.03, 35.03, 43.4, 43.4, 43.4, 43.4, 43.4], "power_watts_avg": 39.62, "power_watts_peak": 43.68, "energy_joules_est": 41.03, "sample_count": 11, "duration_seconds": 1.036}, "timestamp": "2026-01-11T13:32:03.836434"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 810.75, "latencies_ms": [810.75], "images_per_second": 1.233, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two women are sitting on a sidewalk outside a building, engaged in conversation. One woman is smoking a cigarette, while the other is sitting inside an open refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.2, "ram_available_mb": 109453.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 43.38, 43.38, 42.99, 42.99, 42.99, 42.99], "power_watts_avg": 43.2, "power_watts_peak": 43.38, "energy_joules_est": 35.05, "sample_count": 9, "duration_seconds": 0.811}, "timestamp": "2026-01-11T13:32:04.747728"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 924.685, "latencies_ms": [924.685], "images_per_second": 1.081, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The woman is wearing a brown jacket and dark blue jeans. The scene is lit by natural daylight, creating a warm ambiance. The presence of a beverage suggests a casual, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 12.0}, "power_stats": {"power_watts_samples": [42.99, 41.78, 41.78, 41.78, 41.78, 41.78, 42.5, 42.5, 42.5, 42.5], "power_watts_avg": 42.19, "power_watts_peak": 42.99, "energy_joules_est": 39.02, "sample_count": 10, "duration_seconds": 0.925}, "timestamp": "2026-01-11T13:32:05.759586"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 570.344, "latencies_ms": [570.344], "images_per_second": 1.753, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man wearing a straw hat is preparing a meal of hot dogs on a silver tray.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [42.5, 42.63, 42.63, 42.63, 42.63, 42.63], "power_watts_avg": 42.61, "power_watts_peak": 42.63, "energy_joules_est": 24.32, "sample_count": 6, "duration_seconds": 0.571}, "timestamp": "2026-01-11T13:32:06.369073"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1211.327, "latencies_ms": [1211.327], "images_per_second": 0.826, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "hot dog: 8\nbun: 8\ntray: 1\nman: 1\nhat: 1\ngrass: 1\nchair: 1\nsweatshirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 42.61, 42.61, 53.7, 53.7, 53.7, 53.7, 53.7, 43.83, 43.83, 43.83], "power_watts_avg": 47.15, "power_watts_peak": 53.7, "energy_joules_est": 57.13, "sample_count": 13, "duration_seconds": 1.212}, "timestamp": "2026-01-11T13:32:07.682277"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 820.571, "latencies_ms": [820.571], "images_per_second": 1.219, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main object is a person holding a tray of hot dogs. The tray is placed in the foreground, slightly to the right of the person. The background consists of grass and a white fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [43.83, 36.34, 36.34, 36.34, 36.34, 36.34, 42.25, 42.25, 42.25], "power_watts_avg": 39.15, "power_watts_peak": 43.83, "energy_joules_est": 32.14, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:32:08.592375"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 910.976, "latencies_ms": [910.976], "images_per_second": 1.098, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A man is preparing hot dogs on a tray outdoors, likely at a picnic or outdoor gathering. He appears to be in a casual setting, possibly a backyard or park, with some grass visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.25, 42.25, 48.22, 48.22, 48.22, 48.22, 48.22, 42.85, 42.85, 42.85], "power_watts_avg": 45.42, "power_watts_peak": 48.22, "energy_joules_est": 41.39, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:32:09.602026"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1147.387, "latencies_ms": [1147.387], "images_per_second": 0.872, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The hot dogs are red and appear to be cooked on a tray. The lighting is bright, likely from sunlight, creating a warm and inviting atmosphere. The tray is made of aluminum foil, suggesting it is for outdoor cooking. The overall scene suggests a casual, outdoor gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.03, 42.03, 42.03, 42.03, 42.03, 42.64, 42.64, 42.64, 42.64, 42.64], "power_watts_avg": 42.42, "power_watts_peak": 42.85, "energy_joules_est": 48.68, "sample_count": 12, "duration_seconds": 1.148}, "timestamp": "2026-01-11T13:32:10.815333"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 780.162, "latencies_ms": [780.162], "images_per_second": 1.282, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The living room features a desk with a laptop, a chair, a couch, a bookshelf, a radiator, and a star decoration, creating a cozy and functional space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13053.1, "ram_available_mb": 109453.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13053.5, "ram_available_mb": 109452.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [36.46, 36.46, 36.46, 36.46, 36.46, 42.9, 42.9, 42.9], "power_watts_avg": 38.88, "power_watts_peak": 42.9, "energy_joules_est": 30.34, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-11T13:32:11.626565"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1241.075, "latencies_ms": [1241.075], "images_per_second": 0.806, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "desk: 1\nlaptop: 1\nchair: 1\nbookshelf: 2\nbooks: 2\nheater: 1\ncouch: 1\nbags: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.5, "ram_available_mb": 109452.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.9, 42.9, 50.4, 50.4, 50.4, 50.4, 50.4, 43.64, 43.64, 43.64, 43.64, 43.64, 36.81], "power_watts_avg": 45.6, "power_watts_peak": 50.4, "energy_joules_est": 56.6, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-11T13:32:12.941489"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 714.875, "latencies_ms": [714.875], "images_per_second": 1.399, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The desk and chair are positioned to the left of the couch, near the foreground. The bookshelf is located in the background, near the couch.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.81, 36.81, 36.81, 36.81, 42.83, 42.83, 42.83, 42.83], "power_watts_avg": 39.82, "power_watts_peak": 42.83, "energy_joules_est": 28.49, "sample_count": 8, "duration_seconds": 0.715}, "timestamp": "2026-01-11T13:32:13.752560"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1319.756, "latencies_ms": [1319.756], "images_per_second": 0.758, "prompt_tokens": 19, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The room appears to be a home office or study area. A desk with a laptop is positioned on the left side, while a bookshelf filled with books occupies the center. A couch with personal items, including a backpack and pillows, is situated on the right side. The room is dimly lit, with a star decoration hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.83, 41.26, 41.26, 41.26, 41.26, 41.26, 41.88, 41.88, 41.88, 41.88, 41.88, 43.51, 43.51, 43.51], "power_watts_avg": 42.07, "power_watts_peak": 43.51, "energy_joules_est": 55.55, "sample_count": 14, "duration_seconds": 1.32}, "timestamp": "2026-01-11T13:32:15.166124"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 934.173, "latencies_ms": [934.173], "images_per_second": 1.07, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The room has neutral-colored walls and carpeting. The lighting appears to be soft and warm, creating a calm atmosphere. The furniture includes a desk with a laptop and a couch with books and blankets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.51, 43.51, 36.88, 36.88, 36.88, 36.88, 36.88, 42.32, 42.32, 42.32], "power_watts_avg": 39.83, "power_watts_peak": 43.51, "energy_joules_est": 37.24, "sample_count": 10, "duration_seconds": 0.935}, "timestamp": "2026-01-11T13:32:16.176628"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 575.744, "latencies_ms": [575.744], "images_per_second": 1.737, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two majestic elephants stand in a grassy field, their trunks intertwined in a gentle interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.32, 41.93, 41.93, 41.93, 41.93, 41.93], "power_watts_avg": 42.0, "power_watts_peak": 42.32, "energy_joules_est": 24.2, "sample_count": 6, "duration_seconds": 0.576}, "timestamp": "2026-01-11T13:32:16.786380"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1103.679, "latencies_ms": [1103.679], "images_per_second": 0.906, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "elephant: 2\ntrunk: 2\ntusks: 2\ngrass: 2\nleaves: 2\nbushes: 2\nhills: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.21, 42.21, 42.21, 42.21, 42.21, 49.92, 49.92, 49.92, 49.92, 49.92, 44.34], "power_watts_avg": 45.91, "power_watts_peak": 49.92, "energy_joules_est": 50.68, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-11T13:32:17.896649"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1057.744, "latencies_ms": [1057.744], "images_per_second": 0.945, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned relatively close to the viewer, creating a sense of proximity and interaction. The foreground is dominated by the elephants, while the background features more vegetation and a hazy sky, suggesting the scene is situated in a relatively open area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.8, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.34, 44.34, 44.34, 44.34, 44.0, 44.0, 44.0, 44.0, 44.0, 44.02, 44.02], "power_watts_avg": 44.13, "power_watts_peak": 44.34, "energy_joules_est": 46.7, "sample_count": 11, "duration_seconds": 1.058}, "timestamp": "2026-01-11T13:32:19.006178"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 812.223, "latencies_ms": [812.223], "images_per_second": 1.231, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Two elephants are seen interacting in a grassy field with scattered trees and shrubs. The scene appears to be in a natural habitat, possibly a savanna or grassland.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13053.8, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.02, 44.02, 44.02, 43.3, 43.3, 43.3, 43.3, 43.3, 43.13], "power_watts_avg": 43.52, "power_watts_peak": 44.02, "energy_joules_est": 35.37, "sample_count": 9, "duration_seconds": 0.813}, "timestamp": "2026-01-11T13:32:19.915939"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1050.655, "latencies_ms": [1050.655], "images_per_second": 0.952, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The elephants are brown in color. Their skin appears thick and textured. The lighting is soft and diffused, suggesting an overcast sky. The environment is composed of green grass and bushes, indicating a natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.13, 43.13, 43.13, 43.13, 42.29, 42.29, 42.29, 42.29, 42.29, 42.24, 42.24], "power_watts_avg": 42.58, "power_watts_peak": 43.13, "energy_joules_est": 44.76, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-11T13:32:21.026294"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 807.494, "latencies_ms": [807.494], "images_per_second": 1.238, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A man is holding a white frisbee and a green bottle, possibly preparing to throw the frisbee during a game or practice session in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.24, 42.24, 42.24, 43.01, 43.01, 43.01, 43.01, 43.01, 43.19], "power_watts_avg": 42.77, "power_watts_peak": 43.19, "energy_joules_est": 34.56, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:32:21.936692"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1316.33, "latencies_ms": [1316.33], "images_per_second": 0.76, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "man: 1\nfrisbee: 1\nbottle: 1\nsunglasses: 1\nbelt: 1\nshorts: 1\ngrass: 1\ntrees: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 43.19, 43.19, 42.56, 42.56, 42.56, 42.56, 42.56, 42.61, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 42.76, "power_watts_peak": 43.19, "energy_joules_est": 56.29, "sample_count": 14, "duration_seconds": 1.317}, "timestamp": "2026-01-11T13:32:23.349696"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 937.428, "latencies_ms": [937.428], "images_per_second": 1.067, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is positioned in the foreground, holding a frisbee and bottle, while another person can be seen in the background walking away. The frisbee and bottle are located close to the man, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.76, 33.76, 33.76, 33.76, 33.76, 42.62, 42.62, 42.62, 42.62, 42.62], "power_watts_avg": 38.19, "power_watts_peak": 42.62, "energy_joules_est": 35.81, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-11T13:32:24.360139"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 999.811, "latencies_ms": [999.811], "images_per_second": 1.0, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A man is playing frisbee in a park. He is shirtless and wearing khaki shorts, carrying a frisbee and a green bottle. Another person can be seen in the background, walking across the grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.7, "ram_available_mb": 109452.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.0, "ram_available_mb": 109452.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.95, 42.95, 42.95, 42.95, 42.95, 42.96, 42.96, 42.96, 42.96, 42.96], "power_watts_avg": 42.95, "power_watts_peak": 42.96, "energy_joules_est": 42.97, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:32:25.370219"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1064.756, "latencies_ms": [1064.756], "images_per_second": 0.939, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The man is shirtless and wearing khaki shorts. He holds a white frisbee and a green bottle in his hands. The scene takes place on a sunny day with a clear blue sky. The grass appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.0, "ram_available_mb": 109452.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.0, "ram_available_mb": 109452.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 42.86, 42.86, 42.86, 43.99, 43.99, 43.99, 43.99, 43.99, 44.19], "power_watts_avg": 43.49, "power_watts_peak": 44.19, "energy_joules_est": 46.34, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:32:26.480949"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 668.194, "latencies_ms": [668.194], "images_per_second": 1.497, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young boy in a blue soccer jersey is cutting into a large chocolate cake designed to look like a skateboard, complete with wheels and flames.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.19, 44.19, 44.19, 38.11, 38.11, 38.11, 38.11], "power_watts_avg": 40.71, "power_watts_peak": 44.19, "energy_joules_est": 27.24, "sample_count": 7, "duration_seconds": 0.669}, "timestamp": "2026-01-11T13:32:27.191308"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 939.241, "latencies_ms": [939.241], "images_per_second": 1.065, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cake: 1\nknife: 1\nplates: 2\ntoys: 2\ntable: 2\nfoil: 1\ntablecloth: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.11, 41.24, 41.24, 41.24, 41.24, 41.24, 38.45, 38.45, 38.45, 38.45], "power_watts_avg": 39.81, "power_watts_peak": 41.24, "energy_joules_est": 37.41, "sample_count": 10, "duration_seconds": 0.94}, "timestamp": "2026-01-11T13:32:28.200483"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 671.122, "latencies_ms": [671.122], "images_per_second": 1.49, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The main object is a boy cutting a cake. The cake is placed on a table near him. The background is blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.45, 38.3, 38.3, 38.3, 38.3, 38.3, 37.76], "power_watts_avg": 38.25, "power_watts_peak": 38.45, "energy_joules_est": 25.67, "sample_count": 7, "duration_seconds": 0.671}, "timestamp": "2026-01-11T13:32:28.909176"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 972.175, "latencies_ms": [972.175], "images_per_second": 1.029, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A young boy in a blue soccer jersey is cutting a chocolate cake shaped like a skateboard on a table covered with a colorful tablecloth. The cake has chocolate wheels and flames on top, and small toy figures are scattered around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.76, 37.76, 37.76, 37.76, 40.82, 40.82, 40.82, 40.82, 40.82, 38.14], "power_watts_avg": 39.33, "power_watts_peak": 40.82, "energy_joules_est": 38.26, "sample_count": 10, "duration_seconds": 0.973}, "timestamp": "2026-01-11T13:32:29.921806"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 915.787, "latencies_ms": [915.787], "images_per_second": 1.092, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The cake is primarily dark brown with red and yellow accents. The lighting in the image is warm and somewhat dim, creating a cozy atmosphere. The materials appear to be chocolate and fondant, and the weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.9, "ram_available_mb": 109452.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.14, 38.14, 38.14, 38.14, 38.18, 38.18, 38.18, 38.18, 38.18, 38.09], "power_watts_avg": 38.16, "power_watts_peak": 38.18, "energy_joules_est": 34.96, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-11T13:32:30.933550"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 463.853, "latencies_ms": [463.853], "images_per_second": 2.156, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two zebras are standing close together, one in the foreground and the other partially visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.09, 38.09, 38.09, 38.09, 36.9], "power_watts_avg": 37.85, "power_watts_peak": 38.09, "energy_joules_est": 17.58, "sample_count": 5, "duration_seconds": 0.464}, "timestamp": "2026-01-11T13:32:31.441603"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1010.282, "latencies_ms": [1010.282], "images_per_second": 0.99, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "zebra: 2\nface: 2\neye: 2\nmouth: 1\nnose: 1\nhead: 1\nears: 1\nbody: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.9, 36.9, 36.9, 36.9, 41.11, 41.11, 41.11, 41.11, 41.11, 38.22, 38.22], "power_watts_avg": 39.05, "power_watts_peak": 41.11, "energy_joules_est": 39.48, "sample_count": 11, "duration_seconds": 1.011}, "timestamp": "2026-01-11T13:32:32.552860"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 916.944, "latencies_ms": [916.944], "images_per_second": 1.091, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The zebra's head is positioned in the foreground, partially obscuring the background. The zebra is situated close to the viewer, suggesting proximity. The zebra's head is angled towards the viewer, further emphasizing its presence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [38.22, 38.22, 38.22, 37.04, 37.04, 37.04, 37.04, 37.04, 36.96, 36.96], "power_watts_avg": 37.38, "power_watts_peak": 38.22, "energy_joules_est": 34.29, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-11T13:32:33.562997"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 682.313, "latencies_ms": [682.313], "images_per_second": 1.466, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two zebras are seen in a zoo enclosure, one in the foreground and the other partially visible in the background. The setting appears to be outdoors, with some greenery visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.1, "ram_available_mb": 109452.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.96, 36.96, 36.96, 37.09, 37.09, 37.09, 37.09], "power_watts_avg": 37.03, "power_watts_peak": 37.09, "energy_joules_est": 25.29, "sample_count": 7, "duration_seconds": 0.683}, "timestamp": "2026-01-11T13:32:34.270247"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 649.404, "latencies_ms": [649.404], "images_per_second": 1.54, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The zebra's coat is predominantly black and white. The lighting suggests a sunny day. The zebra appears to be eating from a trough or feeding area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.09, 36.44, 36.44, 36.44, 36.44, 36.44, 38.03], "power_watts_avg": 36.76, "power_watts_peak": 38.03, "energy_joules_est": 23.88, "sample_count": 7, "duration_seconds": 0.65}, "timestamp": "2026-01-11T13:32:34.979258"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 706.048, "latencies_ms": [706.048], "images_per_second": 1.416, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two trains are stationed at the La Spezia Centrale train station, Italy, as indicated by the sign above the platform.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 15.0}, "power_stats": {"power_watts_samples": [38.03, 38.03, 38.03, 38.03, 47.41, 47.41, 47.41, 47.41], "power_watts_avg": 42.72, "power_watts_peak": 47.41, "energy_joules_est": 30.18, "sample_count": 8, "duration_seconds": 0.707}, "timestamp": "2026-01-11T13:32:35.790605"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1062.399, "latencies_ms": [1062.399], "images_per_second": 0.941, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "train: 2\nplatform: 2\nsign: 1\nbuildings: 2\npeople: 1\nmountains: 1\ntracks: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.16, 41.16, 41.16, 41.16, 41.16, 42.42, 42.42, 42.42, 42.42, 42.42, 43.51], "power_watts_avg": 41.94, "power_watts_peak": 43.51, "energy_joules_est": 44.58, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:32:36.903805"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1369.156, "latencies_ms": [1369.156], "images_per_second": 0.73, "prompt_tokens": 25, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The main objects are positioned in a spatial arrangement that suggests a transition between the foreground and the background. The train is situated further back, implying a greater distance between the station and the train tracks. The perspective of the image, taken from under the station roof, emphasizes the depth and distance between the station and the train.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.51, 43.51, 43.51, 43.51, 43.43, 43.43, 43.43, 43.43, 43.43, 43.42, 43.42, 43.42, 43.42, 43.42], "power_watts_avg": 43.45, "power_watts_peak": 43.51, "energy_joules_est": 59.5, "sample_count": 14, "duration_seconds": 1.369}, "timestamp": "2026-01-11T13:32:38.316756"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1096.691, "latencies_ms": [1096.691], "images_per_second": 0.912, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a train station in La Spezia, Centrale, Italy. A train is stationed on the tracks, waiting for passengers. The station features a covered platform and multiple train tracks, creating a functional and bustling environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.81, 33.81, 33.81, 33.81, 33.81, 43.18, 43.18, 43.18, 43.18, 43.18, 43.13], "power_watts_avg": 38.92, "power_watts_peak": 43.18, "energy_joules_est": 42.7, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:32:39.427172"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1034.292, "latencies_ms": [1034.292], "images_per_second": 0.967, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The train station is illuminated by overhead lights, creating a bright and welcoming atmosphere. The platform is made of brick, contrasting with the modern train cars. The black and white photograph captures the architectural details of the station and the train tracks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.13, 43.13, 43.13, 43.13, 44.05, 44.05, 44.05, 44.05, 44.05, 43.98, 43.98], "power_watts_avg": 43.7, "power_watts_peak": 44.05, "energy_joules_est": 45.21, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-11T13:32:40.537839"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 714.224, "latencies_ms": [714.224], "images_per_second": 1.4, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A woman in a black wetsuit sits on a red surfboard in the ocean, gazing out at the horizon as the sun sets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.98, 43.98, 43.98, 42.85, 42.85, 42.85, 42.85, 42.85], "power_watts_avg": 43.28, "power_watts_peak": 43.98, "energy_joules_est": 30.93, "sample_count": 8, "duration_seconds": 0.715}, "timestamp": "2026-01-11T13:32:41.348143"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1080.622, "latencies_ms": [1080.622], "images_per_second": 0.925, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "woman: 1\nsurfboard: 1\nwater: 1\nsky: 1\nclouds: 1\nsunset: 1\nmountains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.3, "ram_available_mb": 109452.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 42.54, 42.54, 42.72, 42.72, 42.72, 42.72, 42.72, 43.11], "power_watts_avg": 42.68, "power_watts_peak": 43.11, "energy_joules_est": 46.13, "sample_count": 11, "duration_seconds": 1.081}, "timestamp": "2026-01-11T13:32:42.459051"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1004.706, "latencies_ms": [1004.706], "images_per_second": 0.995, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The woman is positioned in the foreground of the image, close to the red surfboard. The ocean stretches behind her, occupying the majority of the background. The setting sun casts a warm glow over the scene, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.2, "ram_available_mb": 109452.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 43.11, 43.11, 44.04, 44.04, 44.04, 44.04, 44.04, 43.77, 43.77], "power_watts_avg": 43.65, "power_watts_peak": 44.04, "energy_joules_est": 43.87, "sample_count": 11, "duration_seconds": 1.005}, "timestamp": "2026-01-11T13:32:43.570235"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 806.555, "latencies_ms": [806.555], "images_per_second": 1.24, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A woman is sitting on a red surfboard in the ocean at sunset. The sky is filled with clouds, and the water reflects the warm hues of the setting sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 43.77, 40.67, 40.67, 40.67, 40.67, 40.67, 41.8], "power_watts_avg": 41.83, "power_watts_peak": 43.77, "energy_joules_est": 33.76, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-11T13:32:44.478810"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1418.842, "latencies_ms": [1418.842], "images_per_second": 0.705, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The sunset colors the sky in hues of orange and pink, creating a dramatic backdrop for the surfer. The water appears dark and somewhat choppy, reflecting the soft light of the setting sun. The surfer is wearing a dark wetsuit, enhancing the contrast against the warm tones of the sky and water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.8, 41.8, 41.8, 41.8, 43.25, 43.25, 43.25, 43.25, 43.25, 42.08, 42.08, 42.08, 42.08, 33.41, 33.41], "power_watts_avg": 41.24, "power_watts_peak": 43.25, "energy_joules_est": 58.55, "sample_count": 15, "duration_seconds": 1.42}, "timestamp": "2026-01-11T13:32:45.993315"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 641.185, "latencies_ms": [641.185], "images_per_second": 1.56, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man and a woman are enjoying a meal of sushi and pastries while seated on a train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.41, 33.41, 33.41, 41.85, 41.85, 41.85, 41.85], "power_watts_avg": 38.23, "power_watts_peak": 41.85, "energy_joules_est": 24.53, "sample_count": 7, "duration_seconds": 0.642}, "timestamp": "2026-01-11T13:32:46.704285"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1276.247, "latencies_ms": [1276.247], "images_per_second": 0.784, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "man: 2\nwoman: 2\nchopsticks: 2\nfood: 3\ntable: 2\nsushi: 1\nplate: 1\nwindow: 1\ntrain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.5, "ram_available_mb": 109451.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.85, 43.92, 43.92, 43.92, 43.92, 43.92, 43.04, 43.04, 43.04, 43.04, 43.04, 41.33, 41.33], "power_watts_avg": 43.02, "power_watts_peak": 43.92, "energy_joules_est": 54.92, "sample_count": 13, "duration_seconds": 1.277}, "timestamp": "2026-01-11T13:32:48.015915"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 763.864, "latencies_ms": [763.864], "images_per_second": 1.309, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the man on the left and the woman on the right. The background is slightly blurred, suggesting they are situated further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.33, 41.33, 41.33, 43.38, 43.38, 43.38, 43.38, 43.38], "power_watts_avg": 42.61, "power_watts_peak": 43.38, "energy_joules_est": 32.57, "sample_count": 8, "duration_seconds": 0.764}, "timestamp": "2026-01-11T13:32:48.824140"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 926.955, "latencies_ms": [926.955], "images_per_second": 1.079, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A man and a woman are enjoying a meal together on a train. The meal consists of sushi rolls, meat, and vegetables. They are seated at a table with food containers and chopsticks.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.73, 43.73, 43.73, 43.3, 43.3, 43.3, 43.3, 43.3], "power_watts_avg": 43.51, "power_watts_peak": 43.73, "energy_joules_est": 40.35, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-11T13:32:49.833178"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1319.877, "latencies_ms": [1319.877], "images_per_second": 0.758, "prompt_tokens": 18, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The train's interior is primarily light-colored, possibly off-white or beige. The lighting appears to be soft and diffused, creating a calm atmosphere. The train's seats and surfaces appear to be made of a durable, possibly plastic or metal material. The overall ambiance suggests a comfortable and clean travel experience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.76, 42.76, 42.76, 42.76, 42.76, 42.65, 42.65, 42.65, 42.65, 42.65, 43.18, 43.18, 43.18, 43.18], "power_watts_avg": 42.84, "power_watts_peak": 43.18, "energy_joules_est": 56.57, "sample_count": 14, "duration_seconds": 1.321}, "timestamp": "2026-01-11T13:32:51.245816"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 781.937, "latencies_ms": [781.937], "images_per_second": 1.279, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two men in business attire, one in a white shirt and black tie and the other in a pink shirt and striped tie, walk down a city street at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.18, 32.64, 32.64, 32.64, 32.64, 32.64, 42.35, 42.35], "power_watts_avg": 36.39, "power_watts_peak": 43.18, "energy_joules_est": 28.46, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-11T13:32:52.056440"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1141.466, "latencies_ms": [1141.466], "images_per_second": 0.876, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "building: 2\nstreet: 2\ncrosswalk: 2\nman: 2\ncar: 1\nman: 1\ntie: 2\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.35, 42.35, 42.35, 53.69, 53.69, 53.69, 53.69, 53.69, 43.46, 43.46, 43.46, 43.46], "power_watts_avg": 47.44, "power_watts_peak": 53.69, "energy_joules_est": 54.18, "sample_count": 12, "duration_seconds": 1.142}, "timestamp": "2026-01-11T13:32:53.269533"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 560.443, "latencies_ms": [560.443], "images_per_second": 1.784, "prompt_tokens": 25, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The two men are positioned in the foreground of the image, with the building and street behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.46, 33.27, 33.27, 33.27, 33.27, 33.27], "power_watts_avg": 34.97, "power_watts_peak": 43.46, "energy_joules_est": 19.62, "sample_count": 6, "duration_seconds": 0.561}, "timestamp": "2026-01-11T13:32:53.878353"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1119.849, "latencies_ms": [1119.849], "images_per_second": 0.893, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Two men in business attire are walking down a city street at night, passing a building with signage that says \"Hierro Y Alberto.\"  The scene is illuminated by streetlights, creating a nighttime ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 42.87, 42.87, 42.87, 54.03, 54.03, 54.03, 54.03, 54.03, 43.44, 43.44], "power_watts_avg": 47.62, "power_watts_peak": 54.03, "energy_joules_est": 53.34, "sample_count": 12, "duration_seconds": 1.12}, "timestamp": "2026-01-11T13:32:55.090459"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 888.438, "latencies_ms": [888.438], "images_per_second": 1.126, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The men are wearing dark suits and ties. The scene is lit by streetlights, creating a nighttime atmosphere. The buildings in the background are illuminated, contributing to the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13054.4, "ram_available_mb": 109451.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13052.8, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 40.66, 40.66, 40.66, 40.66, 40.66, 42.48, 42.48], "power_watts_avg": 41.68, "power_watts_peak": 43.44, "energy_joules_est": 37.05, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:32:55.999870"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 672.077, "latencies_ms": [672.077], "images_per_second": 1.488, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A man in a gray shirt and glasses is standing behind a bar, holding a wine bottle and wiping it with a cloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13052.8, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13052.8, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 45.93, 45.93, 45.93, 45.93], "power_watts_avg": 44.45, "power_watts_peak": 45.93, "energy_joules_est": 29.89, "sample_count": 7, "duration_seconds": 0.672}, "timestamp": "2026-01-11T13:32:56.708955"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1422.203, "latencies_ms": [1422.203], "images_per_second": 0.703, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "wine bottle: 1\nwine glass: 1\nwine bottle: 1\nwine glass: 1\ntowel: 1\npitcher: 1\nmenu: 1\ncounter: 1\nperson: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.93, 46.14, 46.14, 46.14, 46.14, 46.14, 43.87, 43.87, 43.87, 43.87, 43.87, 42.82, 42.82, 42.82, 42.82], "power_watts_avg": 44.49, "power_watts_peak": 46.14, "energy_joules_est": 63.28, "sample_count": 15, "duration_seconds": 1.423}, "timestamp": "2026-01-11T13:32:58.221852"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1152.321, "latencies_ms": [1152.321], "images_per_second": 0.868, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main object is a person standing at the bar, cleaning a wine bottle with a cloth. The wine bottle is positioned in the foreground, slightly to the right of the person. The bar counter and wine bottles are in the background, extending from the left to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.82, 34.27, 34.27, 34.27, 34.27, 34.27, 42.41, 42.41, 42.41, 42.41, 42.41, 42.02], "power_watts_avg": 39.02, "power_watts_peak": 42.82, "energy_joules_est": 44.97, "sample_count": 12, "duration_seconds": 1.153}, "timestamp": "2026-01-11T13:32:59.433972"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1007.596, "latencies_ms": [1007.596], "images_per_second": 0.992, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A man is standing behind a bar, cleaning a wine bottle with a cloth. He appears to be in a wine tasting setting, with wine bottles and glasses visible on the bar. The atmosphere seems relaxed and casual.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.02, 42.02, 42.02, 42.02, 43.04, 43.04, 43.04, 43.04, 43.04, 42.96, 42.96], "power_watts_avg": 42.65, "power_watts_peak": 43.04, "energy_joules_est": 43.01, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-11T13:33:00.546933"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1057.863, "latencies_ms": [1057.863], "images_per_second": 0.945, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The wine bottles are predominantly dark, indicating a likely red wine color. The lighting in the scene is warm and inviting, creating a cozy atmosphere. The wooden bar counter and shelving unit contribute to the overall rustic ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13052.7, "ram_available_mb": 109453.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.4, "ram_available_mb": 109452.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 42.96, 41.24, 41.24, 41.24, 41.24, 41.24, 41.87, 41.87, 41.87], "power_watts_avg": 41.88, "power_watts_peak": 42.96, "energy_joules_est": 44.33, "sample_count": 11, "duration_seconds": 1.058}, "timestamp": "2026-01-11T13:33:01.658975"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 861.375, "latencies_ms": [861.375], "images_per_second": 1.161, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A tennis player, dressed in white, is captured mid-swing with a blue and white racket, poised to strike a yellow tennis ball in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.4, "ram_available_mb": 109452.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13053.4, "ram_available_mb": 109452.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [41.87, 41.87, 39.27, 39.27, 39.27, 39.27, 39.27, 43.05, 43.05], "power_watts_avg": 40.69, "power_watts_peak": 43.05, "energy_joules_est": 35.07, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:33:02.569613"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1322.814, "latencies_ms": [1322.814], "images_per_second": 0.756, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 4\nTennis player: 1\nTennis shirt: 1\nTennis shorts: 1\nTennis wristbands: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13053.4, "ram_available_mb": 109452.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13053.3, "ram_available_mb": 109453.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 48.08, 48.08, 48.08, 48.08, 48.08, 43.34, 43.34, 43.34, 43.34, 43.34, 35.15], "power_watts_avg": 44.39, "power_watts_peak": 48.08, "energy_joules_est": 58.73, "sample_count": 14, "duration_seconds": 1.323}, "timestamp": "2026-01-11T13:33:03.981619"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 794.728, "latencies_ms": [794.728], "images_per_second": 1.258, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, preparing to hit the tennis ball. The tennis court extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13053.3, "ram_available_mb": 109453.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13054.6, "ram_available_mb": 109451.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.15, 35.15, 35.15, 35.15, 42.43, 42.43, 42.43, 42.43], "power_watts_avg": 38.79, "power_watts_peak": 42.43, "energy_joules_est": 30.83, "sample_count": 8, "duration_seconds": 0.795}, "timestamp": "2026-01-11T13:33:04.789002"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1062.838, "latencies_ms": [1062.838], "images_per_second": 0.941, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A tennis player is executing a forehand shot on a grass court, captured mid-swing with a blue and white racket. The player is wearing white shorts and a white shirt, showcasing their athletic form.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13054.6, "ram_available_mb": 109451.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 42.67, 42.67, 44.02, 44.02, 44.02, 44.02, 44.02, 43.6], "power_watts_avg": 43.37, "power_watts_peak": 44.02, "energy_joules_est": 46.11, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:33:05.900168"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1004.229, "latencies_ms": [1004.229], "images_per_second": 0.996, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The tennis player is wearing a white shirt and shorts. The grass court is well-maintained and appears to be sunny. The player is using a blue and white tennis racket to hit the tennis ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 43.6, 42.91, 42.91, 42.91, 42.91, 42.91, 43.05], "power_watts_avg": 43.2, "power_watts_peak": 43.6, "energy_joules_est": 43.4, "sample_count": 10, "duration_seconds": 1.005}, "timestamp": "2026-01-11T13:33:06.911298"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 750.091, "latencies_ms": [750.091], "images_per_second": 1.333, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and orange cat is perched atop a wooden TV stand, attentively watching a television screen displaying a man's face.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 43.05, 43.75, 43.75, 43.75, 43.75], "power_watts_avg": 43.4, "power_watts_peak": 43.75, "energy_joules_est": 32.57, "sample_count": 8, "duration_seconds": 0.75}, "timestamp": "2026-01-11T13:33:07.722427"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1142.38, "latencies_ms": [1142.38], "images_per_second": 0.875, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "cat: 1\ntelevision: 1\ndvd player: 1\ncable box: 1\ncup: 1\ntable: 1\nshelf: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.0, "ram_available_mb": 109451.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.75, 44.83, 44.83, 44.83, 44.83, 44.83, 43.19, 43.19, 43.19, 43.19, 43.19, 43.24], "power_watts_avg": 43.92, "power_watts_peak": 44.83, "energy_joules_est": 50.19, "sample_count": 12, "duration_seconds": 1.143}, "timestamp": "2026-01-11T13:33:08.932046"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 787.679, "latencies_ms": [787.679], "images_per_second": 1.27, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the television and DVD player. The television and DVD player are situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 43.24, 43.24, 42.53, 42.53, 42.53, 42.53], "power_watts_avg": 42.89, "power_watts_peak": 43.24, "energy_joules_est": 33.79, "sample_count": 8, "duration_seconds": 0.788}, "timestamp": "2026-01-11T13:33:09.741166"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1040.315, "latencies_ms": [1040.315], "images_per_second": 0.961, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A white and orange cat is perched atop a wooden TV stand, watching a television screen displaying a man's face. The TV stand is situated in a room with a yellow wall and a partially visible blue curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.53, 43.03, 43.03, 43.03, 43.03, 43.03, 43.67, 43.67, 43.67, 43.67, 43.67], "power_watts_avg": 43.28, "power_watts_peak": 43.67, "energy_joules_est": 45.05, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-11T13:33:10.852466"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1077.098, "latencies_ms": [1077.098], "images_per_second": 0.928, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The cat is primarily white with orange markings. The lighting in the room appears to be soft and warm, creating a cozy atmosphere. The TV and entertainment center are made of wood and metal, contributing to the overall aesthetic of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.2, "ram_available_mb": 109451.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13055.7, "ram_available_mb": 109450.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.37, 43.37, 43.37, 43.37, 43.37, 42.73, 42.73, 42.73, 42.73, 42.73, 42.38], "power_watts_avg": 42.99, "power_watts_peak": 43.37, "energy_joules_est": 46.33, "sample_count": 11, "duration_seconds": 1.078}, "timestamp": "2026-01-11T13:33:11.962758"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 668.053, "latencies_ms": [668.053], "images_per_second": 1.497, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A blue circular sign with a white silhouette of a person walking with a child on a bicycle is mounted on a metal pole.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.7, "ram_available_mb": 109450.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 42.97, 42.97, 42.97], "power_watts_avg": 42.63, "power_watts_peak": 42.97, "energy_joules_est": 28.51, "sample_count": 7, "duration_seconds": 0.669}, "timestamp": "2026-01-11T13:33:12.671787"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 917.005, "latencies_ms": [917.005], "images_per_second": 1.091, "prompt_tokens": 21, "response_tokens_est": 25, "n_tiles": 1, "output_text": "sign: 2\nbicycle: 1\nchild: 1\ntree: 1\nstreet light: 1\nmetal: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 47.46, 47.46, 47.46, 47.46, 47.46, 43.45, 43.45, 43.45], "power_watts_avg": 45.36, "power_watts_peak": 47.46, "energy_joules_est": 41.61, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-11T13:33:13.681331"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1273.591, "latencies_ms": [1273.591], "images_per_second": 0.785, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The sign is positioned in the foreground, partially obscured by the tree branches. The sign is situated near the top of a pole, suggesting it is located at a height or in a location with limited visibility. The sign is further back from the tree branches, implying a distance between the sign and the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.0, "ram_available_mb": 109450.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 43.07, 43.07, 43.07, 43.07, 43.07, 42.58, 42.58, 42.58, 42.58, 42.58, 39.99], "power_watts_avg": 42.71, "power_watts_peak": 43.45, "energy_joules_est": 54.42, "sample_count": 13, "duration_seconds": 1.274}, "timestamp": "2026-01-11T13:33:14.993185"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1160.558, "latencies_ms": [1160.558], "images_per_second": 0.862, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene is set outdoors on a sunny day, with a blue circular sign featuring a bicycle symbol and a pedestrian symbol. Below this sign is a smaller rectangular sign with Chinese characters. The signs are mounted on a metal pole, partially obscured by green foliage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [39.99, 39.99, 39.99, 43.37, 43.37, 43.37, 43.37, 43.37, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 42.56, "power_watts_peak": 43.48, "energy_joules_est": 49.44, "sample_count": 12, "duration_seconds": 1.162}, "timestamp": "2026-01-11T13:33:16.208885"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 761.166, "latencies_ms": [761.166], "images_per_second": 1.314, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The sign is blue and features white text. The lighting suggests a sunny day. The sign appears to be made of metal and has a weathered appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.48, 36.46, 36.46, 36.46, 36.46, 36.46, 43.14, 43.14], "power_watts_avg": 39.01, "power_watts_peak": 43.48, "energy_joules_est": 29.71, "sample_count": 8, "duration_seconds": 0.762}, "timestamp": "2026-01-11T13:33:17.017448"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 713.105, "latencies_ms": [713.105], "images_per_second": 1.402, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young girl with black hair and yellow earrings is sitting at a wooden table in a restaurant, enjoying a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 43.14, 51.03, 51.03, 51.03, 51.03, 51.03], "power_watts_avg": 48.07, "power_watts_peak": 51.03, "energy_joules_est": 34.29, "sample_count": 8, "duration_seconds": 0.713}, "timestamp": "2026-01-11T13:33:17.830535"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1285.454, "latencies_ms": [1285.454], "images_per_second": 0.778, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Pizza: 2\nPizza pan: 1\nGlass of water: 1\nPaper napkin: 1\nBook: 1\nGirl: 1\nChair: 4\nTable: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.63, 42.63, 42.63, 42.63, 42.63, 42.69, 42.69, 42.69, 42.69, 42.69, 43.11, 43.11, 43.11], "power_watts_avg": 42.76, "power_watts_peak": 43.11, "energy_joules_est": 54.99, "sample_count": 13, "duration_seconds": 1.286}, "timestamp": "2026-01-11T13:33:19.143638"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1129.988, "latencies_ms": [1129.988], "images_per_second": 0.885, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The girl is positioned in the foreground of the image, sitting at a table with a partially eaten pizza and a glass of water. The table is situated between two chairs, further back in the scene. The background features additional tables and chairs, suggesting a restaurant setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 40.46, 40.46, 40.46, 40.46, 40.46, 43.62, 43.62, 43.62, 43.62, 43.62], "power_watts_avg": 42.22, "power_watts_peak": 43.62, "energy_joules_est": 47.72, "sample_count": 12, "duration_seconds": 1.13}, "timestamp": "2026-01-11T13:33:20.357269"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1056.767, "latencies_ms": [1056.767], "images_per_second": 0.946, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A young girl with braided hair is seated at a wooden table in a restaurant, enjoying a slice of pizza and a glass of water. The restaurant has a casual atmosphere with wooden chairs and tables, and several other people can be seen in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13055.9, "ram_available_mb": 109450.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.5, 37.5, 37.5, 37.5, 37.5, 42.5, 42.5, 42.5, 42.5, 42.5, 43.26], "power_watts_avg": 40.3, "power_watts_peak": 43.26, "energy_joules_est": 42.6, "sample_count": 11, "duration_seconds": 1.057}, "timestamp": "2026-01-11T13:33:21.470163"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 892.634, "latencies_ms": [892.634], "images_per_second": 1.12, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The restaurant has a warm ambiance with wooden furniture and dim lighting. Visible colors include browns, yellows, and greens from the food. The atmosphere appears cozy and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.26, 43.26, 43.26, 43.26, 43.47, 43.47, 43.47, 43.47, 43.47], "power_watts_avg": 43.38, "power_watts_peak": 43.47, "energy_joules_est": 38.74, "sample_count": 9, "duration_seconds": 0.893}, "timestamp": "2026-01-11T13:33:22.380684"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 793.78, "latencies_ms": [793.78], "images_per_second": 1.26, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A table is set with plates of food, bowls of vegetables, bread rolls, a glass of water, and a spoon, indicating a meal preparation or serving scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.25, 43.25, 43.25, 43.25, 43.25, 44.05, 44.05, 44.05], "power_watts_avg": 43.55, "power_watts_peak": 44.05, "energy_joules_est": 34.59, "sample_count": 8, "duration_seconds": 0.794}, "timestamp": "2026-01-11T13:33:23.193321"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1477.876, "latencies_ms": [1477.876], "images_per_second": 0.677, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "broccoli: 2\ncauliflower: 2\nbread rolls: 4\ncasserole: 1\ncoconut: 1\nwater: 1\naluminum foil: 1\nplate: 2\nlid: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.05, 48.58, 48.58, 48.58, 48.58, 48.58, 44.08, 44.08, 44.08, 44.08, 44.08, 40.77, 40.77, 40.77, 40.77], "power_watts_avg": 44.7, "power_watts_peak": 48.58, "energy_joules_est": 66.08, "sample_count": 15, "duration_seconds": 1.478}, "timestamp": "2026-01-11T13:33:24.708199"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1136.728, "latencies_ms": [1136.728], "images_per_second": 0.88, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The broccoli, cauliflower, and bread are placed in the foreground, while the plates of food and the utensils are situated in the background. The arrangement suggests a casual, home-cooked meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.77, 37.09, 37.09, 37.09, 37.09, 37.09, 43.59, 43.59, 43.59, 43.59, 43.59, 41.41], "power_watts_avg": 40.46, "power_watts_peak": 43.59, "energy_joules_est": 46.02, "sample_count": 12, "duration_seconds": 1.137}, "timestamp": "2026-01-11T13:33:25.919695"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1375.8, "latencies_ms": [1375.8], "images_per_second": 0.727, "prompt_tokens": 19, "response_tokens_est": 68, "n_tiles": 1, "output_text": "The scene depicts a casual outdoor meal setup on a stainless steel countertop. A large bowl of fresh vegetables, including broccoli and cauliflower, is prominently displayed. Alongside the vegetables, there are plates with rice, broccoli, and bread, along with a glass of water and a spoon. The overall atmosphere suggests a relaxed and informal gathering.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.41, 41.41, 41.41, 41.41, 43.04, 43.04, 43.04, 43.04, 43.04, 43.27, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 42.65, "power_watts_peak": 43.27, "energy_joules_est": 58.7, "sample_count": 14, "duration_seconds": 1.376}, "timestamp": "2026-01-11T13:33:27.332375"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1241.787, "latencies_ms": [1241.787], "images_per_second": 0.805, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The food is brightly colored, predominantly orange and green. The lighting is soft and diffused, creating a warm and inviting atmosphere. The dishes appear to be made of metal and glass, reflecting the ambient light. The setting suggests a casual, home-cooked meal, possibly in a rustic kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 34.11, 34.11, 43.72, 43.72, 43.72, 43.72, 43.72, 43.91, 43.91, 43.91], "power_watts_avg": 40.07, "power_watts_peak": 43.91, "energy_joules_est": 49.77, "sample_count": 13, "duration_seconds": 1.242}, "timestamp": "2026-01-11T13:33:28.644460"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 799.677, "latencies_ms": [799.677], "images_per_second": 1.251, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A green and white bus is stopped at a traffic light on a busy city street, with several cars waiting behind it and a person walking on the sidewalk nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.91, 43.91, 39.98, 39.98, 39.98, 39.98, 39.98, 43.06], "power_watts_avg": 41.35, "power_watts_peak": 43.91, "energy_joules_est": 33.09, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-11T13:33:29.457060"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1243.041, "latencies_ms": [1243.041], "images_per_second": 0.804, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "street sign: 1\nbus: 1\ncar: 2\ntruck: 1\nvan: 1\ntree: 2\nbuildings: 5\ncars: 5\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.06, 43.06, 43.06, 43.06, 48.55, 48.55, 48.55, 48.55, 48.55, 44.56, 44.56, 44.56, 44.56], "power_watts_avg": 45.63, "power_watts_peak": 48.55, "energy_joules_est": 56.74, "sample_count": 13, "duration_seconds": 1.243}, "timestamp": "2026-01-11T13:33:30.770738"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 983.455, "latencies_ms": [983.455], "images_per_second": 1.017, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The foreground features a street intersection with cars, a bus, and a truck. The background includes buildings, trees, and a street sign. The vehicles are positioned relatively close to the viewer, suggesting they are in a relatively close proximity to each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 24.0}, "power_stats": {"power_watts_samples": [44.56, 33.19, 33.19, 33.19, 33.19, 33.19, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 38.36, "power_watts_peak": 44.56, "energy_joules_est": 37.74, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-11T13:33:31.782437"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1056.506, "latencies_ms": [1056.506], "images_per_second": 0.947, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a busy city street with several vehicles, including a bus, cars, and a truck, navigating through traffic. Pedestrians are walking along the sidewalk, and buildings line the street, creating a typical urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.27, 43.89, 43.89, 43.89, 43.89, 43.89, 44.08, 44.08, 44.08, 44.08, 44.08], "power_watts_avg": 43.92, "power_watts_peak": 44.08, "energy_joules_est": 46.43, "sample_count": 11, "duration_seconds": 1.057}, "timestamp": "2026-01-11T13:33:32.894380"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1269.751, "latencies_ms": [1269.751], "images_per_second": 0.788, "prompt_tokens": 18, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The scene is dominated by various colors, including red, green, and white. The lighting appears to be natural daylight, creating a pleasant atmosphere. The buildings in the background are primarily brick and concrete, contributing to the urban setting. The overall scene suggests a typical city street with cars, a bus, and pedestrians.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.1, "ram_available_mb": 109450.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.65, 44.65, 44.65, 44.65, 43.34, 43.34, 43.34, 43.34, 43.34, 43.55, 43.55, 43.55, 43.55], "power_watts_avg": 43.81, "power_watts_peak": 44.65, "energy_joules_est": 55.65, "sample_count": 13, "duration_seconds": 1.27}, "timestamp": "2026-01-11T13:33:34.207623"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 642.513, "latencies_ms": [642.513], "images_per_second": 1.556, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A black laptop computer with a visible screen is open on a white table, accompanied by a cell phone, a small device, and a tripod.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.55, 36.05, 36.05, 36.05, 36.05, 36.05, 37.21], "power_watts_avg": 37.29, "power_watts_peak": 43.55, "energy_joules_est": 23.97, "sample_count": 7, "duration_seconds": 0.643}, "timestamp": "2026-01-11T13:33:34.916811"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 873.362, "latencies_ms": [873.362], "images_per_second": 1.145, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "laptop: 1\nphone: 1\ntripod: 1\nsmall device: 1\ntable: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.21, 37.21, 37.21, 37.21, 38.59, 38.59, 38.59, 38.59, 38.59], "power_watts_avg": 37.98, "power_watts_peak": 38.59, "energy_joules_est": 33.19, "sample_count": 9, "duration_seconds": 0.874}, "timestamp": "2026-01-11T13:33:35.825259"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 868.009, "latencies_ms": [868.009], "images_per_second": 1.152, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The laptop is positioned in the foreground, slightly to the right of the camera. The person's red shirt is partially visible in the background, near the laptop. The cell phone is situated near the laptop, slightly further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.37, 37.37, 37.37, 37.37, 37.37, 38.01, 38.01, 38.01, 38.01], "power_watts_avg": 37.65, "power_watts_peak": 38.01, "energy_joules_est": 32.7, "sample_count": 9, "duration_seconds": 0.869}, "timestamp": "2026-01-11T13:33:36.734160"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 973.104, "latencies_ms": [973.104], "images_per_second": 1.028, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a workspace with a Toshiba laptop open on a table, accompanied by a smartphone, a small device, and a tripod. The laptop screen displays a Windows desktop, indicating a typical work or study environment.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [38.01, 39.84, 39.84, 39.84, 39.84, 39.84, 38.11, 38.11, 38.11, 38.11], "power_watts_avg": 38.97, "power_watts_peak": 39.84, "energy_joules_est": 37.94, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-11T13:33:37.743051"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 547.627, "latencies_ms": [547.627], "images_per_second": 1.826, "prompt_tokens": 18, "response_tokens_est": 21, "n_tiles": 1, "output_text": "The laptop is black. The table is white. The screen is reflecting light. The phone is dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.5, "ram_available_mb": 109449.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.0, "ram_available_mb": 109449.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [38.11, 38.36, 38.36, 38.36, 38.36, 38.36], "power_watts_avg": 38.32, "power_watts_peak": 38.36, "energy_joules_est": 21.01, "sample_count": 6, "duration_seconds": 0.548}, "timestamp": "2026-01-11T13:33:38.350065"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 770.746, "latencies_ms": [770.746], "images_per_second": 1.297, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A desk with a computer setup, keyboard, mouse, books, papers, and a water bottle is situated near a window in an office.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.0, "ram_available_mb": 109449.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.82, 37.82, 37.82, 37.82, 37.82, 45.58, 45.58, 45.58], "power_watts_avg": 40.73, "power_watts_peak": 45.58, "energy_joules_est": 31.42, "sample_count": 8, "duration_seconds": 0.771}, "timestamp": "2026-01-11T13:33:39.161704"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1247.333, "latencies_ms": [1247.333], "images_per_second": 0.802, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "computer monitor: 1\nkeyboard: 1\nlaptop: 1\nmouse: 1\nbooks: 5\nwater bottle: 1\ndesk: 2\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.58, 45.58, 48.76, 48.76, 48.76, 48.76, 48.76, 43.28, 43.28, 43.28, 43.28, 43.28, 38.6], "power_watts_avg": 45.38, "power_watts_peak": 48.76, "energy_joules_est": 56.63, "sample_count": 13, "duration_seconds": 1.248}, "timestamp": "2026-01-11T13:33:40.475784"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1007.564, "latencies_ms": [1007.564], "images_per_second": 0.992, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal arrangement, with the computer monitor and keyboard in the foreground and the books and laptop in the background. The desk is situated near a window, which provides natural light and a view of the outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 47.0}, "power_stats": {"power_watts_samples": [38.6, 38.6, 38.6, 38.6, 42.03, 42.03, 42.03, 42.03, 42.03, 42.16, 42.16], "power_watts_avg": 40.81, "power_watts_peak": 42.16, "energy_joules_est": 41.15, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-11T13:33:41.585549"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.374, "latencies_ms": [1052.374], "images_per_second": 0.95, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a well-organized workspace with a desk featuring a computer setup, including a monitor, keyboard, mouse, laptop, and books. A large window provides natural light, enhancing the overall atmosphere of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [42.16, 42.16, 42.16, 40.94, 40.94, 40.94, 40.94, 40.94, 42.2, 42.2, 42.2], "power_watts_avg": 41.62, "power_watts_peak": 42.2, "energy_joules_est": 43.83, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:33:42.697820"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 994.013, "latencies_ms": [994.013], "images_per_second": 1.006, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The desk is light beige or tan. The lighting appears to be natural daylight coming in through a window with blinds. The desk is equipped with a computer setup, including a monitor, keyboard, mouse, and laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.3, "ram_available_mb": 109444.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.6, "ram_available_mb": 109443.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [42.2, 39.55, 39.55, 39.55, 39.55, 39.55, 42.94, 42.94, 42.94, 42.94], "power_watts_avg": 41.17, "power_watts_peak": 42.94, "energy_joules_est": 40.94, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-11T13:33:43.705890"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 827.656, "latencies_ms": [827.656], "images_per_second": 1.208, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A skateboarder wearing a black shirt and helmet is performing an impressive trick mid-air, flipping their skateboard while airborne.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [42.94, 43.1, 43.1, 43.1, 43.1, 43.1, 43.57, 43.57, 43.57], "power_watts_avg": 43.24, "power_watts_peak": 43.57, "energy_joules_est": 35.81, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:33:44.616268"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1163.308, "latencies_ms": [1163.308], "images_per_second": 0.86, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "skateboard: 1\nhelmet: 1\ncamera: 1\nskateboarder: 1\nspectators: 6\nstage: 1\nbanner: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.57, 43.57, 47.61, 47.61, 47.61, 47.61, 47.61, 42.85, 42.85, 42.85, 42.85, 42.85], "power_watts_avg": 44.95, "power_watts_peak": 47.61, "energy_joules_est": 52.31, "sample_count": 12, "duration_seconds": 1.164}, "timestamp": "2026-01-11T13:33:45.829644"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1295.694, "latencies_ms": [1295.694], "images_per_second": 0.772, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick above a crowd of spectators. The skateboarder is relatively close to the spectators, suggesting the action is happening close to the audience. The background is filled with spectators, further emphasizing the proximity of the action to the audience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.35, 36.35, 36.35, 36.35, 36.35, 43.31, 43.31, 43.31, 43.31, 43.31, 43.34, 43.34, 43.34], "power_watts_avg": 40.64, "power_watts_peak": 43.34, "energy_joules_est": 52.67, "sample_count": 13, "duration_seconds": 1.296}, "timestamp": "2026-01-11T13:33:47.144196"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 969.831, "latencies_ms": [969.831], "images_per_second": 1.031, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A skateboarder is performing a trick mid-air, capturing the attention of spectators seated in a large indoor arena. The setting appears to be a professional skateboarding competition or event.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 40.98, 40.98, 40.98, 40.98, 40.98, 44.28, 44.28, 44.28], "power_watts_avg": 42.45, "power_watts_peak": 44.28, "energy_joules_est": 41.18, "sample_count": 10, "duration_seconds": 0.97}, "timestamp": "2026-01-11T13:33:48.156924"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1220.219, "latencies_ms": [1220.219], "images_per_second": 0.82, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The skateboarder is wearing black clothing and a red and white helmet. The lighting is focused on the skateboarder, creating a dramatic effect. The skateboard appears to be made of wood and metal. The setting appears to be indoors, possibly in a large arena or stadium.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.28, 44.28, 44.12, 44.12, 44.12, 44.12, 44.12, 43.42, 43.42, 43.42, 43.42, 43.42, 38.5], "power_watts_avg": 43.44, "power_watts_peak": 44.28, "energy_joules_est": 53.02, "sample_count": 13, "duration_seconds": 1.221}, "timestamp": "2026-01-11T13:33:49.471311"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 824.147, "latencies_ms": [824.147], "images_per_second": 1.213, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "An orange fire hydrant, adorned with a smiley face and a bowtie, stands on a sidewalk next to a tree, with cars parked on the street in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [38.5, 38.5, 38.5, 38.5, 42.29, 42.29, 42.29, 42.29, 42.29], "power_watts_avg": 40.6, "power_watts_peak": 42.29, "energy_joules_est": 33.48, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-11T13:33:50.383849"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1070.183, "latencies_ms": [1070.183], "images_per_second": 0.934, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "hydrant: 1\nstreet: 2\ncars: 2\ntrees: 2\nbuildings: 2\nsidewalk: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.64, 42.64, 42.64, 42.64, 42.64, 42.57, 42.57, 42.57, 42.57, 42.57, 42.24], "power_watts_avg": 42.57, "power_watts_peak": 42.64, "energy_joules_est": 45.59, "sample_count": 11, "duration_seconds": 1.071}, "timestamp": "2026-01-11T13:33:51.496845"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 775.998, "latencies_ms": [775.998], "images_per_second": 1.289, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The fire hydrant is positioned in the foreground, slightly to the right of the viewer. The street and sidewalk are in the background, with the cars parked further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.24, 42.24, 42.24, 43.44, 43.44, 43.44, 43.44, 43.44], "power_watts_avg": 42.99, "power_watts_peak": 43.44, "energy_joules_est": 33.38, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:33:52.305369"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 910.483, "latencies_ms": [910.483], "images_per_second": 1.098, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "An orange fire hydrant with a smiley face and bowtie is situated on a sidewalk next to a tree and street.  Cars are parked along the street in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.85, 42.85, 42.85, 43.48, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 43.17, "power_watts_peak": 43.48, "energy_joules_est": 39.33, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:33:53.316889"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 716.836, "latencies_ms": [716.836], "images_per_second": 1.395, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The fire hydrant is painted bright orange and has a smiley face painted on it. The scene appears to be sunny and outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.27, 42.27, 42.27, 42.27, 42.27, 42.62, 42.62, 42.62], "power_watts_avg": 42.4, "power_watts_peak": 42.62, "energy_joules_est": 30.42, "sample_count": 8, "duration_seconds": 0.717}, "timestamp": "2026-01-11T13:33:54.125063"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 635.076, "latencies_ms": [635.076], "images_per_second": 1.575, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A green cart loaded with old suitcases in various sizes and colors is positioned in front of a green building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [42.62, 42.62, 50.08, 50.08, 50.08, 50.08, 50.08], "power_watts_avg": 47.95, "power_watts_peak": 50.08, "energy_joules_est": 30.48, "sample_count": 7, "duration_seconds": 0.636}, "timestamp": "2026-01-11T13:33:54.835723"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1040.099, "latencies_ms": [1040.099], "images_per_second": 0.961, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "suitcase: 8\ncart: 8\nbicycle: 1\nposter: 1\ndoor: 1\nfloor: 1\nwall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.97, 41.97, 41.97, 41.97, 41.97, 46.2, 46.2, 46.2, 46.2, 46.2, 43.22], "power_watts_avg": 44.01, "power_watts_peak": 46.2, "energy_joules_est": 45.79, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-11T13:33:55.946189"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1104.983, "latencies_ms": [1104.983], "images_per_second": 0.905, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The suitcases are stacked and piled together, occupying the foreground of the image. The green cart is positioned in the background, slightly out of focus. The suitcases are positioned in front of a green door, suggesting they are being transported or moved.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13062.5, "ram_available_mb": 109443.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.22, 43.22, 43.22, 43.22, 43.17, 43.17, 43.17, 43.17, 43.17, 43.28, 43.28], "power_watts_avg": 43.21, "power_watts_peak": 43.28, "energy_joules_est": 47.77, "sample_count": 11, "duration_seconds": 1.106}, "timestamp": "2026-01-11T13:33:57.056909"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1038.83, "latencies_ms": [1038.83], "images_per_second": 0.963, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a vintage luggage cart loaded with several suitcases and trunks, positioned in front of a green building. The luggage appears to be old and possibly antique, adding a nostalgic touch to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 43.28, 44.43, 44.43, 44.43, 44.43, 44.43, 44.16, 44.16, 44.16], "power_watts_avg": 44.04, "power_watts_peak": 44.43, "energy_joules_est": 45.76, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-11T13:33:58.167715"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1021.788, "latencies_ms": [1021.788], "images_per_second": 0.979, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The luggage is primarily a mix of brown, blue, and green colors. The lighting appears to be natural, possibly from daylight, creating a warm and inviting atmosphere. The luggage appears to be made of sturdy materials, suggesting vintage or antique construction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.16, 44.16, 38.77, 38.77, 38.77, 38.77, 38.77, 43.12, 43.12, 43.12, 43.12], "power_watts_avg": 41.33, "power_watts_peak": 44.16, "energy_joules_est": 42.24, "sample_count": 11, "duration_seconds": 1.022}, "timestamp": "2026-01-11T13:33:59.277692"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 639.768, "latencies_ms": [639.768], "images_per_second": 1.563, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A young girl in a pink dress is sitting on a brown couch, holding a white Wii remote and appearing focused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.12, 37.33, 37.33, 37.33, 37.33, 37.33, 42.49], "power_watts_avg": 38.89, "power_watts_peak": 43.12, "energy_joules_est": 24.9, "sample_count": 7, "duration_seconds": 0.64}, "timestamp": "2026-01-11T13:33:59.987192"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1080.114, "latencies_ms": [1080.114], "images_per_second": 0.926, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "girl: 1\ndress: 1\ncouch: 1\nwindow blinds: 2\ncontroller: 1\nwii: 1\ncamera: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 42.49, 42.49, 53.88, 53.88, 53.88, 53.88, 53.88, 43.34, 43.34], "power_watts_avg": 47.82, "power_watts_peak": 53.88, "energy_joules_est": 51.67, "sample_count": 11, "duration_seconds": 1.081}, "timestamp": "2026-01-11T13:34:01.097103"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 912.799, "latencies_ms": [912.799], "images_per_second": 1.096, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The girl is positioned near the foreground of the image, standing on a couch. She is holding a Wii remote in her right hand. The couch is situated in the background, extending from left to right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 42.72, 42.72, 42.72, 42.72, 42.72, 43.96, 43.96, 43.96], "power_watts_avg": 43.22, "power_watts_peak": 43.96, "energy_joules_est": 39.46, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-11T13:34:02.106265"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1154.289, "latencies_ms": [1154.289], "images_per_second": 0.866, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "A young girl is sitting on a brown couch, holding a white Wii remote and appearing to play a video game. She is wearing a pink dress and has a serious expression on her face. The room has brown cushions, a window with blinds, and a red curtain in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.96, 43.96, 42.16, 42.16, 42.16, 42.16, 42.16, 42.42, 42.42, 42.42, 42.42, 42.42], "power_watts_avg": 42.57, "power_watts_peak": 43.96, "energy_joules_est": 49.15, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:34:03.317038"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1161.081, "latencies_ms": [1161.081], "images_per_second": 0.861, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The girl is wearing a pink dress with brown floral patterns. The lighting in the room is soft and diffused, suggesting natural light from a window. The couch appears to be upholstered in a neutral fabric. The overall atmosphere is calm and relaxed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.3, "ram_available_mb": 109448.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.87, 35.87, 35.87, 35.87, 35.87, 43.24, 43.24, 43.24, 43.24, 43.24, 43.7, 43.7], "power_watts_avg": 40.24, "power_watts_peak": 43.7, "energy_joules_est": 46.74, "sample_count": 12, "duration_seconds": 1.161}, "timestamp": "2026-01-11T13:34:04.530650"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 902.303, "latencies_ms": [902.303], "images_per_second": 1.108, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A sleek glass and metal desk is set up in a room with a window, holding an open laptop, a keyboard, a mouse, a jar, a pair of headphones, and a computer tower.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [43.7, 43.7, 43.7, 43.13, 43.13, 43.13, 43.13, 43.13, 43.08], "power_watts_avg": 43.31, "power_watts_peak": 43.7, "energy_joules_est": 39.1, "sample_count": 9, "duration_seconds": 0.903}, "timestamp": "2026-01-11T13:34:05.439537"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1741.213, "latencies_ms": [1741.213], "images_per_second": 0.574, "prompt_tokens": 21, "response_tokens_est": 56, "n_tiles": 1, "output_text": "laptop: 1\nkeyboard: 2\nmouse: 1\nheadphones: 1\nglass jar: 1\ntrash can: 1\ncomputer tower: 1\ndesk: 2\nchair: 1\nfloor: 1\nwindow: 1\nheater: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.08, 43.08, 43.08, 43.08, 44.32, 44.32, 44.32, 44.32, 44.32, 44.24, 44.24, 44.24, 44.24, 44.24, 33.78, 33.78, 33.78, 33.78], "power_watts_avg": 41.68, "power_watts_peak": 44.32, "energy_joules_est": 72.59, "sample_count": 18, "duration_seconds": 1.742}, "timestamp": "2026-01-11T13:34:07.255869"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1011.93, "latencies_ms": [1011.93], "images_per_second": 0.988, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The laptop is positioned on the left side of the desk, near the window. The chair is situated in the foreground, closer to the viewer. The desk and chair occupy the central portion of the image, with the computer tower and keyboard placed in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.0, "ram_available_mb": 109447.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.78, 33.6, 33.6, 33.6, 33.6, 33.6, 42.92, 42.92, 42.92, 42.92, 42.92], "power_watts_avg": 37.85, "power_watts_peak": 42.92, "energy_joules_est": 38.33, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:34:08.368495"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 898.632, "latencies_ms": [898.632], "images_per_second": 1.113, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a home office setup with a desk, laptop, keyboard, mouse, headphones, and a computer tower. A trash can and a window are also visible in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.0, "ram_available_mb": 109447.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.69, 43.69, 43.69, 42.34, 42.34, 42.34, 42.34], "power_watts_avg": 43.09, "power_watts_peak": 43.69, "energy_joules_est": 38.73, "sample_count": 9, "duration_seconds": 0.899}, "timestamp": "2026-01-11T13:34:09.276866"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1098.564, "latencies_ms": [1098.564], "images_per_second": 0.91, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The desk is primarily made of clear glass, giving it a modern and transparent appearance. The chair is made of gray fabric, providing comfort and support. The lighting in the room appears to be natural and soft, contributing to a calm atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.34, 42.42, 42.42, 42.42, 42.42, 42.42, 43.3, 43.3, 43.3, 43.3, 43.3], "power_watts_avg": 42.81, "power_watts_peak": 43.3, "energy_joules_est": 47.07, "sample_count": 11, "duration_seconds": 1.099}, "timestamp": "2026-01-11T13:34:10.386790"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 777.229, "latencies_ms": [777.229], "images_per_second": 1.287, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A person is enjoying a freshly made vegetable pizza topped with pepperoni, mushrooms, green peppers, and bell peppers, using a knife and fork.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 43.19, 43.19, 43.19, 43.92, 43.92, 43.92], "power_watts_avg": 43.46, "power_watts_peak": 43.92, "energy_joules_est": 33.81, "sample_count": 8, "duration_seconds": 0.778}, "timestamp": "2026-01-11T13:34:11.199777"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1330.523, "latencies_ms": [1330.523], "images_per_second": 0.752, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Pizza: 8\nPepperoni: 2\nMushrooms: 4\nGreen peppers: 3\nTomato: 1\nCheese: 1\nSauce: 1\nFork: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.1, "ram_available_mb": 109449.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.92, 48.02, 48.02, 48.02, 48.02, 48.02, 43.77, 43.77, 43.77, 43.77, 43.77, 40.14, 40.14, 40.14], "power_watts_avg": 44.52, "power_watts_peak": 48.02, "energy_joules_est": 59.26, "sample_count": 14, "duration_seconds": 1.331}, "timestamp": "2026-01-11T13:34:12.610739"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 955.172, "latencies_ms": [955.172], "images_per_second": 1.047, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The pizza is positioned in the foreground of the image, with the person's hand and fork visible in the background. The table and checkered tablecloth are placed in the background, further emphasizing the spatial relationship between the objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [40.14, 40.14, 40.97, 40.97, 40.97, 40.97, 40.97, 42.86, 42.86, 42.86], "power_watts_avg": 41.37, "power_watts_peak": 42.86, "energy_joules_est": 39.53, "sample_count": 10, "duration_seconds": 0.956}, "timestamp": "2026-01-11T13:34:13.622627"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 992.595, "latencies_ms": [992.595], "images_per_second": 1.007, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A person is enjoying a freshly made pizza topped with pepperoni, mushrooms, green peppers, and bell peppers. The pizza is served on a white plate, placed on a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 42.52, 42.52, 42.52, 42.52, 42.52, 43.23, 43.23, 43.23], "power_watts_avg": 42.8, "power_watts_peak": 43.23, "energy_joules_est": 42.5, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-11T13:34:14.633253"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 995.34, "latencies_ms": [995.34], "images_per_second": 1.005, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The pizza is topped with vibrant red sauce, melted cheese, and several green bell peppers. The lighting is warm and inviting, creating a pleasant atmosphere. The pizza appears to be freshly baked and served on a white plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.23, 43.23, 43.69, 43.69, 43.69, 43.69, 43.69, 43.58, 43.58, 43.58], "power_watts_avg": 43.57, "power_watts_peak": 43.69, "energy_joules_est": 43.39, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-11T13:34:15.642263"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 750.019, "latencies_ms": [750.019], "images_per_second": 1.333, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and red Metropolitan Transit System bus is parked on the side of the road, carrying passengers and displaying its route number.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 43.62, 43.62, 43.62, 43.62, 43.62, 45.16], "power_watts_avg": 43.8, "power_watts_peak": 45.16, "energy_joules_est": 32.88, "sample_count": 8, "duration_seconds": 0.751}, "timestamp": "2026-01-11T13:34:16.452591"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1126.593, "latencies_ms": [1126.593], "images_per_second": 0.888, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bus: 5\ntree: 1\nbuilding: 2\nwindow: 4\nsign: 1\nbaby: 1\nman: 1\ncar: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.16, 45.16, 45.16, 45.16, 48.94, 48.94, 48.94, 48.94, 48.94, 44.44, 44.44, 44.44], "power_watts_avg": 46.56, "power_watts_peak": 48.94, "energy_joules_est": 52.48, "sample_count": 12, "duration_seconds": 1.127}, "timestamp": "2026-01-11T13:34:17.662848"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1046.835, "latencies_ms": [1046.835], "images_per_second": 0.955, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, slightly to the right of the viewer. The building in the background occupies the upper portion of the image, extending from the left edge to the top right corner. The bus is parked or stopped near the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [44.44, 44.44, 38.73, 38.73, 38.73, 38.73, 38.73, 44.13, 44.13, 44.13, 44.13], "power_watts_avg": 41.73, "power_watts_peak": 44.44, "energy_joules_est": 43.7, "sample_count": 11, "duration_seconds": 1.047}, "timestamp": "2026-01-11T13:34:18.774428"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 937.8, "latencies_ms": [937.8], "images_per_second": 1.066, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A white and red Metropolitan Transit System bus is parked near a tall building, with people visible inside and outside the bus. The scene suggests a typical urban environment with a transit system.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 34.0}, "power_stats": {"power_watts_samples": [44.13, 38.03, 38.03, 38.03, 38.03, 38.03, 44.24, 44.24, 44.24, 44.24], "power_watts_avg": 41.12, "power_watts_peak": 44.24, "energy_joules_est": 38.58, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-11T13:34:19.785868"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 948.047, "latencies_ms": [948.047], "images_per_second": 1.055, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The bus is primarily white with red accents. The lighting appears to be natural daylight, creating a bright and pleasant atmosphere. The bus appears to be modern in design, constructed from metal and glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 37.0}, "power_stats": {"power_watts_samples": [44.24, 43.86, 43.86, 43.86, 43.86, 43.86, 43.94, 43.94, 43.94, 43.94], "power_watts_avg": 43.93, "power_watts_peak": 44.24, "energy_joules_est": 41.67, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-11T13:34:20.795921"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 419.649, "latencies_ms": [419.649], "images_per_second": 2.383, "prompt_tokens": 8, "response_tokens_est": 14, "n_tiles": 1, "output_text": "A baseball glove and cap rest on the ground near a metal pole.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [43.94, 44.43, 44.43, 44.43, 44.43], "power_watts_avg": 44.33, "power_watts_peak": 44.43, "energy_joules_est": 18.63, "sample_count": 5, "duration_seconds": 0.42}, "timestamp": "2026-01-11T13:34:21.305046"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 949.653, "latencies_ms": [949.653], "images_per_second": 1.053, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "baseball cap: 1\nbaseball glove: 1\nbaseball: 1\nfence post: 1\nground: 1\nsand: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.24, 36.24, 36.24, 36.24, 36.24, 41.47, 41.47, 41.47, 41.47, 41.47], "power_watts_avg": 38.85, "power_watts_peak": 41.47, "energy_joules_est": 36.91, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-11T13:34:22.314547"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 735.763, "latencies_ms": [735.763], "images_per_second": 1.359, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The baseball glove and cap are positioned close to the ground, close to the right edge of the image. The glove is partially obscured by the cap, lying in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.48, 37.48, 37.48, 37.48, 37.48, 37.72, 37.72, 37.72], "power_watts_avg": 37.57, "power_watts_peak": 37.72, "energy_joules_est": 27.66, "sample_count": 8, "duration_seconds": 0.736}, "timestamp": "2026-01-11T13:34:23.123420"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 759.583, "latencies_ms": [759.583], "images_per_second": 1.317, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A baseball glove and cap rest on the ground near a metal pole, likely at a baseball field. The scene suggests a moment of anticipation or preparation for a game.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.72, 37.72, 41.59, 41.59, 41.59, 41.59, 41.59, 37.18], "power_watts_avg": 40.07, "power_watts_peak": 41.59, "energy_joules_est": 30.49, "sample_count": 8, "duration_seconds": 0.761}, "timestamp": "2026-01-11T13:34:23.936205"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 674.978, "latencies_ms": [674.978], "images_per_second": 1.482, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The baseball cap is navy blue, and the glove is tan and leather-like. The lighting suggests it might be sunny, and the ground appears to be dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.18, 37.18, 37.18, 37.18, 38.02, 38.02, 38.02], "power_watts_avg": 37.54, "power_watts_peak": 38.02, "energy_joules_est": 25.36, "sample_count": 7, "duration_seconds": 0.676}, "timestamp": "2026-01-11T13:34:24.646059"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 659.167, "latencies_ms": [659.167], "images_per_second": 1.517, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A surfer in a red shirt skillfully rides a white and green striped surfboard on a turquoise wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.02, 38.02, 44.51, 44.51, 44.51, 44.51, 44.51], "power_watts_avg": 42.66, "power_watts_peak": 44.51, "energy_joules_est": 28.14, "sample_count": 7, "duration_seconds": 0.66}, "timestamp": "2026-01-11T13:34:25.357659"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 945.267, "latencies_ms": [945.267], "images_per_second": 1.058, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "surfboard: 1\nperson: 1\nwaves: 2\nwater: 1\nsky: 1\nsurfboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.64, 43.64, 43.64, 43.64, 43.64, 47.74, 47.74, 47.74, 47.74, 47.74], "power_watts_avg": 45.69, "power_watts_peak": 47.74, "energy_joules_est": 43.2, "sample_count": 10, "duration_seconds": 0.946}, "timestamp": "2026-01-11T13:34:26.369523"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 729.969, "latencies_ms": [729.969], "images_per_second": 1.37, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The wave is further in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.59, 43.59, 43.59, 43.59, 43.59, 43.53, 43.53, 43.53], "power_watts_avg": 43.57, "power_watts_peak": 43.59, "energy_joules_est": 31.83, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:34:27.182060"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 842.611, "latencies_ms": [842.611], "images_per_second": 1.187, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A surfer in a red shirt skillfully rides a wave on a yellow and white surfboard. The ocean is a vibrant turquoise color, creating a dynamic and energetic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 47.31, 47.31, 47.31, 47.31, 47.31, 43.13, 43.13], "power_watts_avg": 45.54, "power_watts_peak": 47.31, "energy_joules_est": 38.4, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:34:28.093931"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 863.291, "latencies_ms": [863.291], "images_per_second": 1.158, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The water is a vibrant turquoise color, creating a striking contrast with the white and green surfboard. The lighting suggests a sunny day with bright, natural light illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.13, 43.13, 43.13, 48.39, 48.39, 48.39, 48.39, 48.39, 43.06], "power_watts_avg": 46.04, "power_watts_peak": 48.39, "energy_joules_est": 39.77, "sample_count": 9, "duration_seconds": 0.864}, "timestamp": "2026-01-11T13:34:29.004336"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 534.052, "latencies_ms": [534.052], "images_per_second": 1.872, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A bathroom features a white toilet, sink, and mirror, with decorative items placed on the countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.06, 43.06, 43.06, 39.49, 39.49, 39.49], "power_watts_avg": 41.28, "power_watts_peak": 43.06, "energy_joules_est": 22.07, "sample_count": 6, "duration_seconds": 0.535}, "timestamp": "2026-01-11T13:34:29.614592"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1285.441, "latencies_ms": [1285.441], "images_per_second": 0.778, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "toilet: 1\nsink: 1\nmirror: 1\nleaf: 1\nfaucet: 1\nsoap dispenser: 1\ntoilet brush: 1\ntoilet paper: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [39.49, 39.49, 41.27, 41.27, 41.27, 41.27, 41.27, 37.74, 37.74, 37.74, 37.74, 37.74, 34.25], "power_watts_avg": 39.1, "power_watts_peak": 41.27, "energy_joules_est": 50.27, "sample_count": 13, "duration_seconds": 1.286}, "timestamp": "2026-01-11T13:34:30.926723"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 669.061, "latencies_ms": [669.061], "images_per_second": 1.495, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The toilet is positioned to the left of the sink, which is situated in the background. The toilet and sink are located close together, creating a functional and compact bathroom layout.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [34.25, 34.25, 34.25, 34.25, 38.65, 38.65, 38.65], "power_watts_avg": 36.14, "power_watts_peak": 38.65, "energy_joules_est": 24.2, "sample_count": 7, "duration_seconds": 0.67}, "timestamp": "2026-01-11T13:34:31.637235"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 807.497, "latencies_ms": [807.497], "images_per_second": 1.238, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The black and white image depicts a bathroom setting with a toilet, sink, and decorative elements. The toilet is positioned next to the sink, and the bathroom appears to be clean and well-maintained.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [38.65, 38.65, 42.51, 42.51, 42.51, 42.51, 42.51, 37.47, 37.47], "power_watts_avg": 40.53, "power_watts_peak": 42.51, "energy_joules_est": 32.76, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:34:32.545633"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 800.371, "latencies_ms": [800.371], "images_per_second": 1.249, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The bathroom features a black and white color scheme, illuminated by natural light coming in from the window. The walls are tiled with stone-like tiles, and the floor is dark and shiny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.47, 37.47, 37.47, 36.21, 36.21, 36.21, 36.21, 36.21], "power_watts_avg": 36.68, "power_watts_peak": 37.47, "energy_joules_est": 29.37, "sample_count": 8, "duration_seconds": 0.801}, "timestamp": "2026-01-11T13:34:33.354057"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 941.229, "latencies_ms": [941.229], "images_per_second": 1.062, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A white clock tower with a green dome and clock face is situated atop a red-tiled roof, partially obscured by a white gazebo with ornate carvings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.71, 36.71, 36.71, 36.71, 36.71, 43.22, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 39.96, "power_watts_peak": 43.22, "energy_joules_est": 37.64, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:34:34.366576"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1154.498, "latencies_ms": [1154.498], "images_per_second": 0.866, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "gazebo: 2\nbell tower: 1\nclock face: 1\nroof tiles: 8\nbell: 1\nlight fixtures: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.42, 43.42, 43.42, 43.42, 43.42, 42.87, 42.87, 42.87, 42.87, 42.87, 42.61, 42.61], "power_watts_avg": 43.06, "power_watts_peak": 43.42, "energy_joules_est": 49.73, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:34:35.577250"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1165.007, "latencies_ms": [1165.007], "images_per_second": 0.858, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The white clock tower is positioned in the foreground, slightly to the right of the gazebo. The gazebo is situated in the background, extending from left to right. The clock tower and gazebo are separated by a distance, emphasizing the spatial relationship between the two structures.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 42.61, 42.61, 42.61, 42.61, 42.61, 42.97, 42.97, 42.97, 42.97], "power_watts_avg": 42.73, "power_watts_peak": 42.97, "energy_joules_est": 49.8, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-11T13:34:36.789446"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 931.597, "latencies_ms": [931.597], "images_per_second": 1.073, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set in a historic area, featuring a white clock tower with a green dome, situated atop a tiled roof. The tower is surrounded by ornate architectural elements and stands against a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [42.97, 34.15, 34.15, 34.15, 34.15, 34.15, 43.55, 43.55, 43.55, 43.55], "power_watts_avg": 38.8, "power_watts_peak": 43.55, "energy_joules_est": 36.16, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-11T13:34:37.800345"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1232.774, "latencies_ms": [1232.774], "images_per_second": 0.811, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The building features a distinctive green dome roof and clock tower, contrasting with the clear blue sky. The roof is made of terracotta tiles, adding a warm and rustic touch to the structure. The lighting is soft and diffused, enhancing the overall atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.55, 43.17, 43.17, 43.17, 43.17, 43.17, 42.84, 42.84, 42.84, 42.84, 42.84, 44.23, 44.23], "power_watts_avg": 43.24, "power_watts_peak": 44.23, "energy_joules_est": 53.34, "sample_count": 13, "duration_seconds": 1.234}, "timestamp": "2026-01-11T13:34:39.111929"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 564.23, "latencies_ms": [564.23], "images_per_second": 1.772, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A group of elephants, including one in the foreground, is seen walking along a dirt path surrounded by trees and bushes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.23, 44.23, 41.05, 41.05, 41.05, 41.05], "power_watts_avg": 42.11, "power_watts_peak": 44.23, "energy_joules_est": 23.77, "sample_count": 6, "duration_seconds": 0.565}, "timestamp": "2026-01-11T13:34:39.721040"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1050.875, "latencies_ms": [1050.875], "images_per_second": 0.952, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "elephant: 6\ntusk: 2\ntrunk: 1\nears: 4\nbody: 5\nhair: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [41.05, 45.15, 45.15, 45.15, 45.15, 45.15, 45.25, 45.25, 45.25, 45.25, 45.25], "power_watts_avg": 44.82, "power_watts_peak": 45.25, "energy_joules_est": 47.13, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-11T13:34:40.830775"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 951.781, "latencies_ms": [951.781], "images_per_second": 1.051, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The elephant in the foreground is positioned to the left of the image, drawing the viewer's attention to its presence. The elephants in the background are slightly out of focus, creating a sense of depth and distance between the foreground and the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.9, "ram_available_mb": 109447.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.05, 42.05, 42.05, 42.05, 42.05, 43.51, 43.51, 43.51, 43.51, 43.51], "power_watts_avg": 42.78, "power_watts_peak": 43.51, "energy_joules_est": 40.74, "sample_count": 10, "duration_seconds": 0.952}, "timestamp": "2026-01-11T13:34:41.843100"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 822.28, "latencies_ms": [822.28], "images_per_second": 1.216, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of elephants is gathered in a natural setting, possibly a savanna or forest. The elephants are standing close together, partially obscured by vegetation and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.7, 43.7, 43.7, 43.7, 43.7, 43.36, 43.36, 43.36, 43.36], "power_watts_avg": 43.55, "power_watts_peak": 43.7, "energy_joules_est": 35.82, "sample_count": 9, "duration_seconds": 0.822}, "timestamp": "2026-01-11T13:34:42.755001"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 991.765, "latencies_ms": [991.765], "images_per_second": 1.008, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The elephants are primarily gray in color. The lighting suggests an overcast day, with diffused light filtering through the trees. The scene appears to be set in a natural environment with dirt paths and vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 4.0}, "power_stats": {"power_watts_samples": [43.36, 43.04, 43.04, 43.04, 43.04, 43.04, 42.66, 42.66, 42.66, 42.66], "power_watts_avg": 42.92, "power_watts_peak": 43.36, "energy_joules_est": 42.59, "sample_count": 10, "duration_seconds": 0.992}, "timestamp": "2026-01-11T13:34:43.766337"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 709.755, "latencies_ms": [709.755], "images_per_second": 1.409, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The open refrigerator door reveals an empty interior with four shelves, two crisper drawers, and a carton of eggs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [42.66, 44.02, 44.02, 44.02, 44.02, 44.02, 43.69, 43.69], "power_watts_avg": 43.77, "power_watts_peak": 44.02, "energy_joules_est": 31.09, "sample_count": 8, "duration_seconds": 0.71}, "timestamp": "2026-01-11T13:34:44.578197"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1542.857, "latencies_ms": [1542.857], "images_per_second": 0.648, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Egg carton: 2\nOrange juice bottle: 1\nIce maker: 1\nFridge door: 3\nPlastic drawer dividers: 2\nEmpty shelves: 3\nFridge door shelves: 3\nRefrigerator interior: 7", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.69, 52.16, 52.16, 52.16, 52.16, 52.16, 42.57, 42.57, 42.57, 42.57, 42.57, 35.4, 35.4, 35.4], "power_watts_avg": 44.43, "power_watts_peak": 52.16, "energy_joules_est": 68.58, "sample_count": 16, "duration_seconds": 1.543}, "timestamp": "2026-01-11T13:34:46.193422"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1169.667, "latencies_ms": [1169.667], "images_per_second": 0.855, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main object, the refrigerator, is positioned to the left of the foreground, partially obscuring the view. The eggs are located further back in the refrigerator, towards the top. The overall arrangement suggests a typical kitchen layout, with the refrigerator serving as the central focal point.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.4, 35.4, 37.27, 37.27, 37.27, 37.27, 37.27, 42.79, 42.79, 42.79, 42.79, 42.79], "power_watts_avg": 39.26, "power_watts_peak": 42.79, "energy_joules_est": 45.94, "sample_count": 12, "duration_seconds": 1.17}, "timestamp": "2026-01-11T13:34:47.406733"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1011.813, "latencies_ms": [1011.813], "images_per_second": 0.988, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts an empty refrigerator in a kitchen, illuminated by a light source inside. The refrigerator is stocked with various items, including a carton of eggs, a bottle of liquid, and a few other unidentified items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.43, 40.43, 40.43, 40.43, 43.46, 43.46, 43.46, 43.46, 43.46, 43.55, 43.55], "power_watts_avg": 42.38, "power_watts_peak": 43.55, "energy_joules_est": 42.89, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-11T13:34:48.519882"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 847.94, "latencies_ms": [847.94], "images_per_second": 1.179, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The refrigerator is white and appears clean and empty. The lighting inside the refrigerator is bright, creating a well-lit interior. The refrigerator's shelves are made of clear plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.55, 43.55, 43.55, 42.59, 42.59, 42.59, 42.59, 42.59, 42.54], "power_watts_avg": 42.91, "power_watts_peak": 43.55, "energy_joules_est": 36.41, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-11T13:34:49.430758"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 640.065, "latencies_ms": [640.065], "images_per_second": 1.562, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A bunch of ripe yellow bananas with small stickers is neatly arranged on a blue tray.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 42.54, 43.76, 43.76, 43.76], "power_watts_avg": 43.06, "power_watts_peak": 43.76, "energy_joules_est": 27.59, "sample_count": 7, "duration_seconds": 0.641}, "timestamp": "2026-01-11T13:34:50.141843"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 780.598, "latencies_ms": [780.598], "images_per_second": 1.281, "prompt_tokens": 21, "response_tokens_est": 20, "n_tiles": 1, "output_text": "bananas: 8\nstickers: 2\nmetal tray: 1\npurple background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 50.13, 50.13, 50.13, 50.13, 50.13, 44.05], "power_watts_avg": 47.78, "power_watts_peak": 50.13, "energy_joules_est": 37.31, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:34:50.953319"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 768.886, "latencies_ms": [768.886], "images_per_second": 1.301, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, creating a sense of proximity and depth. The background is blurred, drawing attention to the bananas in the foreground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.05, 44.05, 44.05, 44.05, 49.64, 49.64, 49.64, 49.64], "power_watts_avg": 46.85, "power_watts_peak": 49.64, "energy_joules_est": 36.04, "sample_count": 8, "duration_seconds": 0.769}, "timestamp": "2026-01-11T13:34:51.764657"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 950.709, "latencies_ms": [950.709], "images_per_second": 1.052, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene features a close-up view of a bunch of ripe bananas resting on a metallic surface. The bananas are yellow and appear fresh. The background is blurred, drawing attention to the bananas and the metallic surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 42.0}, "power_stats": {"power_watts_samples": [49.64, 44.5, 44.5, 44.5, 44.5, 44.5, 44.3, 44.3, 44.3, 44.3], "power_watts_avg": 44.94, "power_watts_peak": 49.64, "energy_joules_est": 42.73, "sample_count": 10, "duration_seconds": 0.951}, "timestamp": "2026-01-11T13:34:52.775826"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1078.148, "latencies_ms": [1078.148], "images_per_second": 0.928, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The bananas are predominantly yellow, indicating a ripe stage. The lighting appears to be soft and diffused, possibly from a diffused light source. The bananas appear to be resting on a reflective surface, possibly metal, which adds depth to the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.3, 44.17, 44.17, 44.17, 44.17, 44.17, 44.08, 44.08, 44.08, 44.08, 44.08], "power_watts_avg": 44.14, "power_watts_peak": 44.3, "energy_joules_est": 47.61, "sample_count": 11, "duration_seconds": 1.079}, "timestamp": "2026-01-11T13:34:53.888564"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 817.531, "latencies_ms": [817.531], "images_per_second": 1.223, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A row of tall, shiny orange fire hydrants with gold knobs is lined up on a city sidewalk, contrasting with the surrounding urban landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.08, 45.08, 45.08, 45.08, 45.08, 44.71, 44.71, 44.71, 44.71], "power_watts_avg": 44.92, "power_watts_peak": 45.08, "energy_joules_est": 36.75, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:34:54.801418"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1115.536, "latencies_ms": [1115.536], "images_per_second": 0.896, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "fire hydrant: 4\npipes: 4\nbuildings: 5\ntrees: 2\nstreet: 1\npeople: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.71, 43.43, 43.43, 43.43, 43.43, 43.43, 43.76, 43.76, 43.76, 43.76, 43.76, 45.1], "power_watts_avg": 43.81, "power_watts_peak": 45.1, "energy_joules_est": 48.9, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-11T13:34:56.013201"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 943.592, "latencies_ms": [943.592], "images_per_second": 1.06, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The fire hydrants are positioned in the foreground, slightly to the right of the center. The cityscape, including skyscrapers and buildings, stretches out in the background, further emphasizing the urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.1, 45.1, 45.1, 42.95, 42.95, 42.95, 42.95, 42.95, 42.87, 42.87], "power_watts_avg": 43.58, "power_watts_peak": 45.1, "energy_joules_est": 41.14, "sample_count": 10, "duration_seconds": 0.944}, "timestamp": "2026-01-11T13:34:57.023873"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1196.923, "latencies_ms": [1196.923], "images_per_second": 0.835, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a city street with tall buildings in the background and a row of copper-colored fire hydrants lined up on the sidewalk. The fire hydrants are positioned in a row, seemingly awaiting use. The overall atmosphere suggests a calm, urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.2, "ram_available_mb": 109447.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 42.87, 44.07, 44.07, 44.07, 44.07, 44.07, 44.14, 44.14, 44.14, 44.14], "power_watts_avg": 43.79, "power_watts_peak": 44.14, "energy_joules_est": 52.44, "sample_count": 12, "duration_seconds": 1.197}, "timestamp": "2026-01-11T13:34:58.237848"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 910.806, "latencies_ms": [910.806], "images_per_second": 1.098, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The fire hydrants are copper-colored and stand out against the light gray stone pavement. The lighting suggests an overcast day, giving the scene a muted tone.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.14, 35.63, 35.63, 35.63, 35.63, 35.63, 45.25, 45.25, 45.25, 45.25], "power_watts_avg": 40.33, "power_watts_peak": 45.25, "energy_joules_est": 36.74, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:34:59.251010"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 835.481, "latencies_ms": [835.481], "images_per_second": 1.197, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A jockey wearing a white helmet and riding a brown pony harnessed to a red carriage, competes in a race on a dirt track.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.25, 44.03, 44.03, 44.03, 44.03, 44.03, 42.52, 42.52, 42.52], "power_watts_avg": 43.66, "power_watts_peak": 45.25, "energy_joules_est": 36.5, "sample_count": 9, "duration_seconds": 0.836}, "timestamp": "2026-01-11T13:35:00.164283"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1002.843, "latencies_ms": [1002.843], "images_per_second": 0.997, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "horse: 1\nperson: 1\ncart: 1\nnumber: 1\nroad: 1\ngrass: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.52, 42.52, 47.88, 47.88, 47.88, 47.88, 47.88, 42.94, 42.94, 42.94], "power_watts_avg": 45.33, "power_watts_peak": 47.88, "energy_joules_est": 45.48, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-11T13:35:01.175189"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 913.89, "latencies_ms": [913.89], "images_per_second": 1.094, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The horse and driver are positioned in the foreground of the image, with the horse and cart moving towards the background. The track is situated near the background, extending beyond the immediate focus of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.3, "ram_available_mb": 109447.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [42.94, 42.94, 43.67, 43.67, 43.67, 43.67, 43.67, 43.66, 43.66, 43.66], "power_watts_avg": 43.52, "power_watts_peak": 43.67, "energy_joules_est": 39.8, "sample_count": 10, "duration_seconds": 0.914}, "timestamp": "2026-01-11T13:35:02.187112"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.425, "latencies_ms": [1052.425], "images_per_second": 0.95, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A jockey and horse are racing on a dirt track. The jockey is wearing a helmet and riding a red carriage with a number 8 displayed. The horse is brown and pulling the carriage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.66, 43.66, 41.75, 41.75, 41.75, 41.75, 41.75, 42.36, 42.36, 42.36, 42.36], "power_watts_avg": 42.32, "power_watts_peak": 43.66, "energy_joules_est": 44.56, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:35:03.299778"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 780.984, "latencies_ms": [780.984], "images_per_second": 1.28, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The horse and driver are brown. The scene is well-lit, likely under bright sunlight. The horse appears to be harnessed for a race or competition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.36, 39.01, 39.01, 39.01, 39.01, 39.01, 43.18, 43.18], "power_watts_avg": 40.47, "power_watts_peak": 43.18, "energy_joules_est": 31.62, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:35:04.107813"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 518.917, "latencies_ms": [518.917], "images_per_second": 1.927, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A brown dog with white markings stands alertly on a gray deck in a backyard, gazing at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.18, 43.18, 48.86, 48.86, 48.86, 48.86], "power_watts_avg": 46.97, "power_watts_peak": 48.86, "energy_joules_est": 24.39, "sample_count": 6, "duration_seconds": 0.519}, "timestamp": "2026-01-11T13:35:04.718215"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 961.959, "latencies_ms": [961.959], "images_per_second": 1.04, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "dog: 1\nfence: 1\ntree: 1\nlemon: 2\nwooden bench: 1\ngrass: 1\nshrubs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 38.0}, "power_stats": {"power_watts_samples": [48.86, 40.08, 40.08, 40.08, 40.08, 40.08, 37.55, 37.55, 37.55, 37.55], "power_watts_avg": 39.95, "power_watts_peak": 48.86, "energy_joules_est": 38.44, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-11T13:35:05.728896"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1001.322, "latencies_ms": [1001.322], "images_per_second": 0.999, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The dog is positioned in the foreground, slightly to the right of the image. The fence and tree are in the background, extending from left to right. The dog is situated on a raised surface, which appears to be a patio or deck, placed between the dog and the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 37.0}, "power_stats": {"power_watts_samples": [37.55, 38.6, 38.6, 38.6, 38.6, 38.6, 38.05, 38.05, 38.05, 38.05], "power_watts_avg": 38.28, "power_watts_peak": 38.6, "energy_joules_est": 38.34, "sample_count": 10, "duration_seconds": 1.002}, "timestamp": "2026-01-11T13:35:06.738746"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 717.551, "latencies_ms": [717.551], "images_per_second": 1.394, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A brown dog stands on a wooden deck in a backyard, looking towards the camera. Behind the dog, a wooden fence borders a garden area with trees and bushes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [38.05, 38.26, 38.26, 38.26, 38.26, 38.26, 38.85, 38.85], "power_watts_avg": 38.38, "power_watts_peak": 38.85, "energy_joules_est": 27.55, "sample_count": 8, "duration_seconds": 0.718}, "timestamp": "2026-01-11T13:35:07.547254"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1091.375, "latencies_ms": [1091.375], "images_per_second": 0.916, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The dog is light brown with white markings on its chest and underbelly. The lighting is bright, likely from sunlight, and the dog is standing on a gray surface, possibly a deck or patio. The dog appears to be in a backyard setting with trees and a wooden fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.85, 38.85, 38.85, 39.89, 39.89, 39.89, 39.89, 39.89, 37.03, 37.03, 37.03], "power_watts_avg": 38.82, "power_watts_peak": 39.89, "energy_joules_est": 42.39, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-11T13:35:08.657634"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 938.144, "latencies_ms": [938.144], "images_per_second": 1.066, "prompt_tokens": 8, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A person wearing red pants and blue and yellow shoes stands on a wooden bench with a handwritten sign that reads \"WEINER, YOU'VE GOT TO BE SITTING ME!!\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.6, "ram_available_mb": 109446.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [37.03, 37.03, 39.64, 39.64, 39.64, 39.64, 39.64, 43.73, 43.73, 43.73], "power_watts_avg": 40.34, "power_watts_peak": 43.73, "energy_joules_est": 37.88, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-11T13:35:09.670161"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1004.039, "latencies_ms": [1004.039], "images_per_second": 0.996, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Bench: 2\nSign: 1\nPerson's legs: 2\nShoes: 2\nBricks: 4\nWood: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.6, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.5, 43.5, 43.5, 43.5, 43.5, 42.71, 42.71, 42.71], "power_watts_avg": 43.31, "power_watts_peak": 43.73, "energy_joules_est": 43.51, "sample_count": 10, "duration_seconds": 1.005}, "timestamp": "2026-01-11T13:35:10.681219"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 940.985, "latencies_ms": [940.985], "images_per_second": 1.063, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The wooden bench is positioned in the foreground, close to the person's feet. The person's feet are placed on the bench, slightly behind the bench. The bench is situated against a light-colored wall or fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.6, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [42.71, 42.71, 44.21, 44.21, 44.21, 44.21, 44.21, 44.1, 44.1, 44.1], "power_watts_avg": 43.88, "power_watts_peak": 44.21, "energy_joules_est": 41.31, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:35:11.690442"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1034.605, "latencies_ms": [1034.605], "images_per_second": 0.967, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A person in red pants and shoes is standing on a wooden bench with a sign that reads \"WEINER. You've got to be sitting me!!!\" The bench is situated on a brick pavement against a concrete wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [44.1, 44.1, 42.61, 42.61, 42.61, 42.61, 42.61, 42.87, 42.87, 42.87, 42.87], "power_watts_avg": 42.98, "power_watts_peak": 44.1, "energy_joules_est": 44.49, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-11T13:35:12.801217"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 855.802, "latencies_ms": [855.802], "images_per_second": 1.168, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The bench is made of wood and has a light brown color. The lighting in the image suggests it was taken during daylight hours. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [42.87, 39.15, 39.15, 39.15, 39.15, 39.15, 42.43, 42.43, 42.43], "power_watts_avg": 40.66, "power_watts_peak": 42.87, "energy_joules_est": 34.82, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-11T13:35:13.711846"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 919.598, "latencies_ms": [919.598], "images_per_second": 1.087, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The living room features a red sofa, a wooden coffee table with tea and pastries, a wooden dresser, a flat-screen TV, and lamps, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 42.0}, "power_stats": {"power_watts_samples": [42.43, 46.11, 46.11, 46.11, 46.11, 46.11, 42.68, 42.68, 42.68, 42.68], "power_watts_avg": 44.37, "power_watts_peak": 46.11, "energy_joules_est": 40.83, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-11T13:35:14.723792"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1397.427, "latencies_ms": [1397.427], "images_per_second": 0.716, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "sofa: 2\ntable: 1\nchairs: 2\nlamp: 2\ntea set: 1\ntea pot: 1\ntelevision: 1\ndresser: 1\nbooks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.68, 42.63, 42.63, 42.63, 42.63, 42.63, 42.38, 42.38, 42.38, 42.38, 42.38, 41.42, 41.42, 41.42], "power_watts_avg": 42.28, "power_watts_peak": 42.68, "energy_joules_est": 59.12, "sample_count": 14, "duration_seconds": 1.398}, "timestamp": "2026-01-11T13:35:16.137664"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1053.961, "latencies_ms": [1053.961], "images_per_second": 0.949, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The orange couch is positioned to the left of the dining table and chairs. The dining table and chairs are situated in the background, slightly further away than the couch. The television is positioned in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.42, 41.42, 41.19, 41.19, 41.19, 41.19, 41.19, 43.44, 43.44, 43.44, 43.44], "power_watts_avg": 42.05, "power_watts_peak": 43.44, "energy_joules_est": 44.33, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-11T13:35:17.248906"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1490.324, "latencies_ms": [1490.324], "images_per_second": 0.671, "prompt_tokens": 19, "response_tokens_est": 74, "n_tiles": 1, "output_text": "The scene depicts a cozy hotel room with a comfortable living area and a dining area. The living area features a red sofa, a wooden coffee table, and a small side table with a lamp and flowers. The dining area has a round table set for tea or coffee, surrounded by chairs. The room is well-lit by natural light coming through a window with curtains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.44, 37.97, 37.97, 37.97, 37.97, 37.97, 43.2, 43.2, 43.2, 43.2, 43.2, 42.64, 42.64, 42.64, 42.64], "power_watts_avg": 41.32, "power_watts_peak": 43.44, "energy_joules_est": 61.61, "sample_count": 15, "duration_seconds": 1.491}, "timestamp": "2026-01-11T13:35:18.761723"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1270.347, "latencies_ms": [1270.347], "images_per_second": 0.787, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The room features a warm color scheme with orange walls and brown curtains. The lighting is soft and warm, creating a cozy atmosphere. The furniture includes a red sofa, a round table with chairs, and a wooden dresser. A large window provides natural light, enhancing the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.64, 35.34, 35.34, 35.34, 35.34, 35.34, 44.01, 44.01, 44.01, 44.01, 44.01, 42.58, 42.58], "power_watts_avg": 40.35, "power_watts_peak": 44.01, "energy_joules_est": 51.28, "sample_count": 13, "duration_seconds": 1.271}, "timestamp": "2026-01-11T13:35:20.076474"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 822.467, "latencies_ms": [822.467], "images_per_second": 1.216, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A black frying pan is filled with a vibrant stir fry of broccoli, bell peppers, carrots, and sliced meat, all coated in a light brown sauce.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.5, "ram_available_mb": 109446.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.58, 42.58, 42.58, 43.65, 43.65, 43.65, 43.65, 43.65, 43.52], "power_watts_avg": 43.28, "power_watts_peak": 43.65, "energy_joules_est": 35.62, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-11T13:35:20.986762"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1288.783, "latencies_ms": [1288.783], "images_per_second": 0.776, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "broccoli: 8\ncarrots: 8\npeppers: 8\nham: 8\nzucchini: 2\npotatoes: 2\nsalt: 1\nspoon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 43.52, 43.52, 42.23, 42.23, 42.23, 42.23, 42.23, 42.36, 42.36, 42.36, 42.36], "power_watts_avg": 42.67, "power_watts_peak": 43.52, "energy_joules_est": 55.01, "sample_count": 13, "duration_seconds": 1.289}, "timestamp": "2026-01-11T13:35:22.298018"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 667.366, "latencies_ms": [667.366], "images_per_second": 1.498, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The broccoli, carrots, and meat are positioned in the foreground of the image, with the pan and spoon placed in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.36, 33.4, 33.4, 33.4, 33.4, 33.4, 43.58], "power_watts_avg": 36.14, "power_watts_peak": 43.58, "energy_joules_est": 24.14, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:35:23.007240"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 981.805, "latencies_ms": [981.805], "images_per_second": 1.019, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A skillet filled with a colorful mix of vegetables, including broccoli, carrots, and meat, is being prepared on a stovetop. A serving spoon rests in the pan, indicating the cooking process is underway.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 43.58, 43.58, 53.93, 53.93, 53.93, 53.93, 43.42, 43.42], "power_watts_avg": 47.69, "power_watts_peak": 53.93, "energy_joules_est": 46.86, "sample_count": 10, "duration_seconds": 0.983}, "timestamp": "2026-01-11T13:35:24.017512"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1221.573, "latencies_ms": [1221.573], "images_per_second": 0.819, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The vegetables in the pan display vibrant colors, including green broccoli, orange carrots, and red bell peppers. The lighting in the image is bright, highlighting the textures and colors of the ingredients. The pan appears to be made of metal, and the vegetables seem to be cooked together.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13059.4, "ram_available_mb": 109446.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.42, 43.42, 43.42, 42.83, 42.83, 42.83, 42.83, 42.83, 42.58, 42.58, 42.58, 42.58, 42.58], "power_watts_avg": 42.87, "power_watts_peak": 43.42, "energy_joules_est": 52.38, "sample_count": 13, "duration_seconds": 1.222}, "timestamp": "2026-01-11T13:35:25.328652"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 620.04, "latencies_ms": [620.04], "images_per_second": 1.613, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three hot dogs, each topped with yellow mustard, are arranged on a dark plate on a countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.01, 32.01, 32.01, 32.01, 32.01, 42.3, 42.3], "power_watts_avg": 34.95, "power_watts_peak": 42.3, "energy_joules_est": 21.7, "sample_count": 7, "duration_seconds": 0.621}, "timestamp": "2026-01-11T13:35:26.039276"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 964.735, "latencies_ms": [964.735], "images_per_second": 1.037, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "hot dog: 3\nbun: 2\nmustard: 2\nplate: 1\ntable: 1\nmagazine: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.3, 42.3, 42.3, 52.8, 52.8, 52.8, 52.8, 52.8, 42.74, 42.74], "power_watts_avg": 47.64, "power_watts_peak": 52.8, "energy_joules_est": 45.98, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-11T13:35:27.049643"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 954.101, "latencies_ms": [954.101], "images_per_second": 1.048, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned close together, with the hot dogs placed in the foreground and the magazine slightly out of focus in the background. The hot dogs are placed on a dark plate, which contrasts with the lighter color of the magazine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.74, 42.74, 42.74, 43.48, 43.48, 43.48, 43.48, 43.48, 43.59, 43.59], "power_watts_avg": 43.28, "power_watts_peak": 43.59, "energy_joules_est": 41.32, "sample_count": 10, "duration_seconds": 0.955}, "timestamp": "2026-01-11T13:35:28.059625"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 678.45, "latencies_ms": [678.45], "images_per_second": 1.474, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Three hot dogs topped with mustard are arranged on a dark plate on a countertop. A magazine is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.59, 43.59, 43.59, 43.33, 43.33, 43.33, 43.33], "power_watts_avg": 43.44, "power_watts_peak": 43.59, "energy_joules_est": 29.5, "sample_count": 7, "duration_seconds": 0.679}, "timestamp": "2026-01-11T13:35:28.771457"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 760.372, "latencies_ms": [760.372], "images_per_second": 1.315, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The hot dogs are topped with yellow mustard. The plate appears to be dark brown or black. The lighting is bright, likely from overhead lighting.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [43.33, 44.29, 44.29, 44.29, 44.29, 44.29, 43.72, 43.72], "power_watts_avg": 44.03, "power_watts_peak": 44.29, "energy_joules_est": 33.5, "sample_count": 8, "duration_seconds": 0.761}, "timestamp": "2026-01-11T13:35:29.581352"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 606.09, "latencies_ms": [606.09], "images_per_second": 1.65, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A group of people are enjoying a sunny day at the beach, swimming and playing in the water under a green umbrella.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.72, 43.72, 43.72, 53.57, 53.57, 53.57, 53.57], "power_watts_avg": 49.35, "power_watts_peak": 53.57, "energy_joules_est": 29.94, "sample_count": 7, "duration_seconds": 0.607}, "timestamp": "2026-01-11T13:35:30.293086"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 976.401, "latencies_ms": [976.401], "images_per_second": 1.024, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Umbrella: 1\nBeach chairs: 2\nSand: 1\nWater: 4\nPeople: 4\nWaves: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [53.57, 41.57, 41.57, 41.57, 41.57, 41.57, 42.65, 42.65, 42.65, 42.65], "power_watts_avg": 43.2, "power_watts_peak": 53.57, "energy_joules_est": 42.21, "sample_count": 10, "duration_seconds": 0.977}, "timestamp": "2026-01-11T13:35:31.306160"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 781.119, "latencies_ms": [781.119], "images_per_second": 1.28, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the beach chair and umbrella situated near the middle ground. The water extends to the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.65, 43.61, 43.61, 43.61, 43.61, 43.61, 43.42, 43.42], "power_watts_avg": 43.44, "power_watts_peak": 43.61, "energy_joules_est": 33.96, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-11T13:35:32.116104"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 940.436, "latencies_ms": [940.436], "images_per_second": 1.063, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of people are enjoying a sunny day at the beach, swimming and playing in the ocean. Two beach chairs with colorful covers are set up on the sandy shore, providing shade and seating for relaxation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.42, 43.42, 53.42, 53.42, 53.42, 53.42, 53.42, 43.68, 43.68, 43.68], "power_watts_avg": 48.5, "power_watts_peak": 53.42, "energy_joules_est": 45.62, "sample_count": 10, "duration_seconds": 0.941}, "timestamp": "2026-01-11T13:35:33.127293"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1041.979, "latencies_ms": [1041.979], "images_per_second": 0.96, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The beach is sandy and appears damp, likely due to recent rain or ocean spray. The umbrella is green and vibrant, providing shade from the sun. The lighting suggests a sunny day, with clear skies and bright sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.68, 43.68, 42.28, 42.28, 42.28, 42.28, 42.28, 43.09, 43.09, 43.09, 43.09], "power_watts_avg": 42.83, "power_watts_peak": 43.68, "energy_joules_est": 44.64, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:35:34.240268"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 782.747, "latencies_ms": [782.747], "images_per_second": 1.278, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The vintage kitchen features a wooden table with a white bowl, various kitchenware, and a white refrigerator, all set against a green and white floral wallpaper.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.09, 37.31, 37.31, 37.31, 37.31, 37.31, 43.11, 43.11], "power_watts_avg": 39.48, "power_watts_peak": 43.11, "energy_joules_est": 30.93, "sample_count": 8, "duration_seconds": 0.783}, "timestamp": "2026-01-11T13:35:35.051992"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1686.897, "latencies_ms": [1686.897], "images_per_second": 0.593, "prompt_tokens": 21, "response_tokens_est": 56, "n_tiles": 1, "output_text": "kitchen: 6\ntable: 1\ncabinets: 4\nrefrigerator: 1\nsink: 1\nfaucet: 1\npan: 1\nwooden chair: 1\nwooden bucket: 1\nfan: 1\nwallpaper: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.0, "ram_available_mb": 109448.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 43.11, 52.41, 52.41, 52.41, 52.41, 52.41, 44.07, 44.07, 44.07, 44.07, 44.07, 34.24, 34.24, 34.24, 34.24], "power_watts_avg": 44.04, "power_watts_peak": 52.41, "energy_joules_est": 74.32, "sample_count": 17, "duration_seconds": 1.688}, "timestamp": "2026-01-11T13:35:36.768889"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 901.948, "latencies_ms": [901.948], "images_per_second": 1.109, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The kitchen is positioned in the foreground, with the dining table, chairs, and appliances located near the center and background. The kitchen is further back, with cabinets and appliances extending towards the back wall.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [34.24, 35.17, 35.17, 35.17, 35.17, 35.17, 44.24, 44.24, 44.24], "power_watts_avg": 38.09, "power_watts_peak": 44.24, "energy_joules_est": 34.37, "sample_count": 9, "duration_seconds": 0.902}, "timestamp": "2026-01-11T13:35:37.679456"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 860.499, "latencies_ms": [860.499], "images_per_second": 1.162, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The scene depicts a vintage kitchen exhibit, featuring antique appliances and furniture. The kitchen is decorated with green and white wallpaper and showcases a retro aesthetic.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [44.24, 44.24, 50.45, 50.45, 50.45, 50.45, 50.45, 43.88, 43.88], "power_watts_avg": 47.61, "power_watts_peak": 50.45, "energy_joules_est": 40.99, "sample_count": 9, "duration_seconds": 0.861}, "timestamp": "2026-01-11T13:35:38.590375"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1258.679, "latencies_ms": [1258.679], "images_per_second": 0.794, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The kitchen features green and white color schemes, creating a vintage aesthetic. The lighting is soft and diffused, enhancing the overall ambiance. The materials include wood, metal, and fabric, adding to the rustic charm. The kitchen also appears well-equipped with vintage appliances and utensils.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.88, 43.88, 43.88, 47.1, 47.1, 47.1, 47.1, 47.1, 43.24, 43.24, 43.24, 43.24, 43.24], "power_watts_avg": 44.87, "power_watts_peak": 47.1, "energy_joules_est": 56.5, "sample_count": 13, "duration_seconds": 1.259}, "timestamp": "2026-01-11T13:35:39.905333"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 647.369, "latencies_ms": [647.369], "images_per_second": 1.545, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A black and white dog is playing with a brown frisbee in a wooded area, surrounded by fallen leaves and tall trees.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.53, 34.53, 34.53, 34.53, 34.53, 43.35, 43.35], "power_watts_avg": 37.05, "power_watts_peak": 43.35, "energy_joules_est": 24.01, "sample_count": 7, "duration_seconds": 0.648}, "timestamp": "2026-01-11T13:35:40.617089"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 919.108, "latencies_ms": [919.108], "images_per_second": 1.088, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "tree: 1\nground: 1\nfrisbee: 1\ndog: 1\nleaves: 4\nshadow: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.5, "ram_available_mb": 109447.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 51.66, 51.66, 51.66, 51.66, 51.66, 43.69, 43.69, 43.69], "power_watts_avg": 47.61, "power_watts_peak": 51.66, "energy_joules_est": 43.76, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:35:41.628976"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 935.53, "latencies_ms": [935.53], "images_per_second": 1.069, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The dog is positioned to the left of the image, close to the foreground. The tree trunk occupies the background, extending from the left edge towards the center. The dog appears to be interacting with the ground near the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.06, 43.06, 43.06, 43.06, 43.06, 42.69, 42.69, 42.69], "power_watts_avg": 43.07, "power_watts_peak": 43.69, "energy_joules_est": 40.32, "sample_count": 10, "duration_seconds": 0.936}, "timestamp": "2026-01-11T13:35:42.642244"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 800.802, "latencies_ms": [800.802], "images_per_second": 1.249, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A black and tan dog is playing with a frisbee in a park with fallen leaves on the ground. A large tree trunk with moss is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.1, "ram_available_mb": 109448.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.69, 42.69, 42.7, 42.7, 42.7, 42.7, 42.7, 43.02], "power_watts_avg": 42.74, "power_watts_peak": 43.02, "energy_joules_est": 34.25, "sample_count": 8, "duration_seconds": 0.801}, "timestamp": "2026-01-11T13:35:43.453319"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 972.994, "latencies_ms": [972.994], "images_per_second": 1.028, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The dog is black and white and appears to be playing with a brown frisbee. The ground is covered with fallen leaves, suggesting it's autumn. The lighting is soft and diffused, likely due to overcast conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.4, "ram_available_mb": 109447.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 46.67, 46.67, 46.67, 46.67, 46.67, 44.44], "power_watts_avg": 44.99, "power_watts_peak": 46.67, "energy_joules_est": 43.79, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-11T13:35:44.464559"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 650.326, "latencies_ms": [650.326], "images_per_second": 1.538, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A person wearing skis and carrying a backpack is skiing down a snowy slope, leaving a trail behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [44.44, 44.44, 44.44, 44.44, 43.68, 43.68, 43.68], "power_watts_avg": 44.11, "power_watts_peak": 44.44, "energy_joules_est": 28.71, "sample_count": 7, "duration_seconds": 0.651}, "timestamp": "2026-01-11T13:35:45.175119"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1346.533, "latencies_ms": [1346.533], "images_per_second": 0.743, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Ski: 2\nSki poles: 2\nSki boots: 2\nBackpack: 1\nSnow: 6\nSki tracks: 4\nTrees: 4\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.68, 43.68, 49.57, 49.57, 49.57, 49.57, 49.57, 43.38, 43.38, 43.38, 43.38, 43.38, 38.5, 38.5], "power_watts_avg": 44.93, "power_watts_peak": 49.57, "energy_joules_est": 60.53, "sample_count": 14, "duration_seconds": 1.347}, "timestamp": "2026-01-11T13:35:46.590741"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 941.78, "latencies_ms": [941.78], "images_per_second": 1.062, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, moving towards the background. The skis are located in the foreground, moving towards the background. The skier is facing away from the camera, moving towards the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.5, 38.5, 38.5, 42.83, 42.83, 42.83, 42.83, 42.83, 42.91, 42.91], "power_watts_avg": 41.54, "power_watts_peak": 42.91, "energy_joules_est": 39.15, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:35:47.600580"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1073.573, "latencies_ms": [1073.573], "images_per_second": 0.931, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "A person is cross-country skiing down a snowy slope, wearing a white hat and carrying a backpack. They are using ski poles to navigate the terrain. The background features a forest and a clear blue sky, suggesting a pleasant winter day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.91, 42.91, 42.91, 41.47, 41.47, 41.47, 41.47, 41.47, 42.67, 42.67, 42.67], "power_watts_avg": 42.19, "power_watts_peak": 42.91, "energy_joules_est": 45.32, "sample_count": 11, "duration_seconds": 1.074}, "timestamp": "2026-01-11T13:35:48.710775"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 907.5, "latencies_ms": [907.5], "images_per_second": 1.102, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The skier is wearing a light blue and white jacket, dark pants, and bright green ski boots. The snow is bright white, and the lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13058.6, "ram_available_mb": 109447.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 39.79, 39.79, 39.79, 39.79, 39.79, 43.28, 43.28, 43.28], "power_watts_avg": 41.41, "power_watts_peak": 43.28, "energy_joules_est": 37.59, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:35:49.721093"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 619.893, "latencies_ms": [619.893], "images_per_second": 1.613, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "An orange and black BNSF freight train travels through a wooded area, passing through a field with dry grass and bare trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [43.28, 42.18, 42.18, 42.18, 42.18, 42.18, 36.64], "power_watts_avg": 41.55, "power_watts_peak": 43.28, "energy_joules_est": 25.79, "sample_count": 7, "duration_seconds": 0.621}, "timestamp": "2026-01-11T13:35:50.432460"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1320.922, "latencies_ms": [1320.922], "images_per_second": 0.757, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Train: 2\nTrain car: 2\nTrain engine: 1\nTrain wheels: 4\nTrain tracks: 1\nTrain windows: 2\nTrain cab: 1\nTrain number: 6009", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [36.64, 36.64, 36.64, 36.64, 37.97, 37.97, 37.97, 37.97, 37.97, 37.37, 37.37, 37.37, 37.37, 37.37], "power_watts_avg": 37.38, "power_watts_peak": 37.97, "energy_joules_est": 49.38, "sample_count": 14, "duration_seconds": 1.321}, "timestamp": "2026-01-11T13:35:51.843043"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 848.524, "latencies_ms": [848.524], "images_per_second": 1.179, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The orange and black BNSF train is positioned in the foreground, moving from left to right across the image. The background consists of bare trees and a clear blue sky, creating a contrast with the vibrant colors of the train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [33.11, 33.11, 33.11, 33.11, 33.11, 37.31, 37.31, 37.31, 37.31], "power_watts_avg": 34.98, "power_watts_peak": 37.31, "energy_joules_est": 29.7, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:35:52.753094"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 804.165, "latencies_ms": [804.165], "images_per_second": 1.244, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "An orange and black BNSF freight train travels through a rural landscape, passing through a wooded area with bare trees. The clear blue sky indicates a bright, sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 27.0}, "power_stats": {"power_watts_samples": [37.31, 39.51, 39.51, 39.51, 39.51, 39.51, 37.51, 37.51], "power_watts_avg": 38.73, "power_watts_peak": 39.51, "energy_joules_est": 31.16, "sample_count": 8, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:35:53.563525"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 704.364, "latencies_ms": [704.364], "images_per_second": 1.42, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The train is primarily orange with black and yellow accents. The lighting suggests it is likely daytime. The train appears to be made of metal and has a robust design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [37.51, 37.51, 37.51, 41.11, 41.11, 41.11, 41.11, 41.11], "power_watts_avg": 39.76, "power_watts_peak": 41.11, "energy_joules_est": 28.03, "sample_count": 8, "duration_seconds": 0.705}, "timestamp": "2026-01-11T13:35:54.374117"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 905.213, "latencies_ms": [905.213], "images_per_second": 1.105, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A wooden table holds a white plate with a slice of seeded bread topped with creamy avocado spread, a small bowl of roasted broccoli, and a small dish of white cream cheese.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.4, 37.4, 37.4, 37.4, 37.4, 42.11, 42.11, 42.11, 42.11, 42.11], "power_watts_avg": 39.76, "power_watts_peak": 42.11, "energy_joules_est": 36.02, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-11T13:35:55.386632"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1161.741, "latencies_ms": [1161.741], "images_per_second": 0.861, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "toast: 2\navocado spread: 1\ncream cheese: 1\nbroccoli: 6\nbowl: 1\ntable: 1\ntext: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.5, "ram_available_mb": 109448.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 42.48, 42.48, 42.5, 42.5, 42.5, 42.5, 42.5, 42.4, 42.4], "power_watts_avg": 42.48, "power_watts_peak": 42.5, "energy_joules_est": 49.37, "sample_count": 12, "duration_seconds": 1.162}, "timestamp": "2026-01-11T13:35:56.600918"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1049.873, "latencies_ms": [1049.873], "images_per_second": 0.952, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and visually appealing manner. The avocado spread is on the left, and the broccoli is on the right, separated by a small bowl of cream cheese. The arrangement suggests a focus on healthy and nutritious food choices.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.4, 42.4, 42.4, 42.91, 42.91, 42.91, 42.91, 42.91, 43.21, 43.21, 43.21], "power_watts_avg": 42.85, "power_watts_peak": 43.21, "energy_joules_est": 45.01, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-11T13:35:57.713379"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1015.473, "latencies_ms": [1015.473], "images_per_second": 0.985, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a simple, healthy meal consisting of a piece of whole grain toast topped with avocado, a small bowl of roasted broccoli, and a small bowl of white cream cheese. The meal is served on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [43.21, 43.21, 38.77, 38.77, 38.77, 38.77, 43.11, 43.11, 43.11, 43.11, 43.11], "power_watts_avg": 41.55, "power_watts_peak": 43.21, "energy_joules_est": 42.21, "sample_count": 11, "duration_seconds": 1.016}, "timestamp": "2026-01-11T13:35:58.824634"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1294.243, "latencies_ms": [1294.243], "images_per_second": 0.773, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The plate features a light blue rim and a white base. The food items include green guacamole, a creamy white spread, and a vibrant green broccoli floret. The plate rests on a wooden surface, and the lighting is soft and warm, enhancing the colors and textures of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.02, 39.02, 39.02, 39.02, 39.02, 42.19, 42.19, 42.19, 42.19, 42.19, 43.9, 43.9, 43.9], "power_watts_avg": 41.37, "power_watts_peak": 43.9, "energy_joules_est": 53.56, "sample_count": 13, "duration_seconds": 1.295}, "timestamp": "2026-01-11T13:36:00.138804"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 697.964, "latencies_ms": [697.964], "images_per_second": 1.433, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A person is sleeping on a wooden bench, wrapped in an orange blanket, with a blue backpack placed beside them and a parking meter nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.9, 43.9, 41.61, 41.61, 41.61, 41.61, 41.61], "power_watts_avg": 42.26, "power_watts_peak": 43.9, "energy_joules_est": 29.51, "sample_count": 7, "duration_seconds": 0.698}, "timestamp": "2026-01-11T13:36:00.849069"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1222.562, "latencies_ms": [1222.562], "images_per_second": 0.818, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "park bench: 2\nparking meter: 2\nperson: 1\nblanket: 1\nbackpack: 1\ncar: 1\ngrass: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.01, 44.01, 44.01, 44.01, 44.01, 47.21, 47.21, 47.21, 47.21, 47.21, 44.03, 44.03, 44.03], "power_watts_avg": 45.25, "power_watts_peak": 47.21, "energy_joules_est": 55.34, "sample_count": 13, "duration_seconds": 1.223}, "timestamp": "2026-01-11T13:36:02.163926"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 942.299, "latencies_ms": [942.299], "images_per_second": 1.061, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bench is positioned in the foreground, slightly to the right of the image. The person sleeping on the bench is in the mid-ground, closer to the viewer. The parking meter and street are in the background, further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 39.38, 39.38, 39.38, 39.38, 39.38, 42.7, 42.7, 42.7], "power_watts_avg": 41.31, "power_watts_peak": 44.03, "energy_joules_est": 38.94, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-11T13:36:03.175479"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 749.769, "latencies_ms": [749.769], "images_per_second": 1.334, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A person is sleeping on a wooden bench in a park-like setting. The bench is situated near a parking meter and has a backpack placed on it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.7, 42.7, 43.3, 43.3, 43.3, 43.3, 43.3, 42.8], "power_watts_avg": 43.09, "power_watts_peak": 43.3, "energy_joules_est": 32.33, "sample_count": 8, "duration_seconds": 0.75}, "timestamp": "2026-01-11T13:36:03.987071"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1062.526, "latencies_ms": [1062.526], "images_per_second": 0.941, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bench is light brown and appears to be made of wood. The lighting suggests it's daytime, and the colors are vibrant, reflecting the outdoor environment. The materials appear to be sturdy and weather-resistant, suitable for outdoor use.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.8, 42.8, 42.8, 42.8, 46.38, 46.38, 46.38, 46.38, 46.38, 42.57, 42.57], "power_watts_avg": 44.38, "power_watts_peak": 46.38, "energy_joules_est": 47.18, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:36:05.099450"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 756.819, "latencies_ms": [756.819], "images_per_second": 1.321, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A vibrant vase with dried flowers and leaves sits on a white pedestal, accompanied by smaller vases and decorative items, against a brown wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.57, 42.57, 42.57, 43.22, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 42.98, "power_watts_peak": 43.22, "energy_joules_est": 32.55, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:36:05.911497"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1278.241, "latencies_ms": [1278.241], "images_per_second": 0.782, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "vase: 1\nlotus seed pod: 2\nstalk: 2\nbush: 2\nwhisk: 1\nflower: 1\npot: 2\nbowl: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 43.35, 43.35, 43.67, 43.67, 43.67, 43.67, 43.67, 43.63, 43.63, 43.63], "power_watts_avg": 43.54, "power_watts_peak": 43.67, "energy_joules_est": 55.68, "sample_count": 13, "duration_seconds": 1.279}, "timestamp": "2026-01-11T13:36:07.222847"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 894.991, "latencies_ms": [894.991], "images_per_second": 1.117, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main object, appearing to be the vase, sits in the foreground, positioned slightly to the right of the viewer. The background features other ceramic items and displays, suggesting a larger collection or exhibition space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.63, 37.18, 37.18, 37.18, 37.18, 37.18, 43.6, 43.6, 43.6], "power_watts_avg": 40.04, "power_watts_peak": 43.63, "energy_joules_est": 35.85, "sample_count": 9, "duration_seconds": 0.896}, "timestamp": "2026-01-11T13:36:08.132897"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1684.2, "latencies_ms": [1684.2], "images_per_second": 0.594, "prompt_tokens": 19, "response_tokens_est": 78, "n_tiles": 1, "output_text": "The scene depicts a display of handcrafted pottery and dried floral arrangements at a market or exhibition. The arrangement features a variety of dried plants in shades of brown and beige, complemented by decorative elements like dried seed pods and a small bird figurine. The setting is indoors, with white pedestals and brown walls, creating a visually appealing and organized environment for showcasing the artworks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 49.62, 49.62, 49.62, 49.62, 49.62, 44.03, 44.03, 44.03, 44.03, 44.03, 36.68, 36.68, 36.68, 36.68, 36.68], "power_watts_avg": 43.46, "power_watts_peak": 49.62, "energy_joules_est": 73.22, "sample_count": 17, "duration_seconds": 1.685}, "timestamp": "2026-01-11T13:36:09.851644"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1179.397, "latencies_ms": [1179.397], "images_per_second": 0.848, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The vase is primarily dark brown and gold, showcasing a blend of earthy tones. The arrangement includes dried grasses and seed pods, creating a harmonious and textured display. The lighting is soft and diffused, enhancing the colors without harsh shadows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.8, 33.8, 33.8, 33.8, 33.8, 43.84, 43.84, 43.84, 43.84, 43.84, 43.79, 43.79], "power_watts_avg": 39.65, "power_watts_peak": 43.84, "energy_joules_est": 46.77, "sample_count": 12, "duration_seconds": 1.18}, "timestamp": "2026-01-11T13:36:11.063169"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 749.329, "latencies_ms": [749.329], "images_per_second": 1.335, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young man is skillfully riding a skateboard down a concrete ramp in a skate park, wearing a helmet and protective gear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.79, 43.79, 43.79, 44.1, 44.1, 44.1, 44.1, 44.1], "power_watts_avg": 43.98, "power_watts_peak": 44.1, "energy_joules_est": 32.99, "sample_count": 8, "duration_seconds": 0.75}, "timestamp": "2026-01-11T13:36:11.874425"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1277.35, "latencies_ms": [1277.35], "images_per_second": 0.783, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "helmet: 1\nknee pads: 2\nshin guards: 2\nskateboard: 1\njeans: 1\nshirt: 1\nfence: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.9, "ram_available_mb": 109448.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.89, 43.89, 43.89, 43.89, 43.89, 43.38, 43.38, 43.38, 43.38, 43.38, 43.27, 43.27, 43.27], "power_watts_avg": 43.55, "power_watts_peak": 43.89, "energy_joules_est": 55.64, "sample_count": 13, "duration_seconds": 1.278}, "timestamp": "2026-01-11T13:36:13.186370"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1240.131, "latencies_ms": [1240.131], "images_per_second": 0.806, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground of the image, maneuvering through the concrete bowl. The skateboard is situated near the center of the image, partially obscured by the bowl's curves. The skateboarder is facing the camera, engaging in the activity.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 39.48, 39.48, 39.48, 39.48, 39.48, 43.85, 43.85, 43.85, 43.85, 43.85, 39.25], "power_watts_avg": 41.72, "power_watts_peak": 43.85, "energy_joules_est": 51.76, "sample_count": 13, "duration_seconds": 1.24}, "timestamp": "2026-01-11T13:36:14.495738"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1024.023, "latencies_ms": [1024.023], "images_per_second": 0.977, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A skateboarder is performing a trick on a curved concrete ramp at a skatepark. Another person is visible in the background, possibly watching the skateboarder. The setting suggests an outdoor recreational area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13056.9, "ram_available_mb": 109449.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [39.25, 39.25, 39.25, 39.25, 42.95, 42.95, 42.95, 42.95, 42.95, 43.08, 43.08], "power_watts_avg": 41.63, "power_watts_peak": 43.08, "energy_joules_est": 42.66, "sample_count": 11, "duration_seconds": 1.025}, "timestamp": "2026-01-11T13:36:15.607530"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1002.144, "latencies_ms": [1002.144], "images_per_second": 0.998, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The skateboarder is wearing a white shirt, blue jeans, and a black helmet. The concrete surface appears to be well-maintained and smooth. The lighting suggests it's likely daytime, with sunlight illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [43.08, 43.08, 43.08, 42.37, 42.37, 42.37, 42.37, 42.37, 42.56, 42.56], "power_watts_avg": 42.62, "power_watts_peak": 43.08, "energy_joules_est": 42.73, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-11T13:36:16.617255"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 780.618, "latencies_ms": [780.618], "images_per_second": 1.281, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A large Christmas tree adorned with twinkling lights stands tall in the heart of a bustling city square, surrounded by people enjoying the festive atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.4, "ram_available_mb": 109448.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [42.56, 42.56, 42.56, 42.38, 42.38, 42.38, 42.38, 43.95], "power_watts_avg": 42.64, "power_watts_peak": 43.95, "energy_joules_est": 33.31, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:36:17.429058"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1092.176, "latencies_ms": [1092.176], "images_per_second": 0.916, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "clock tower: 2\nchristmas tree: 1\nlights: 10\nstreet: 5\nbuildings: 5\npeople: 2\ncars: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 43.95, 45.99, 45.99, 45.99, 45.99, 45.99, 43.67, 43.67], "power_watts_avg": 44.83, "power_watts_peak": 45.99, "energy_joules_est": 48.99, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-11T13:36:18.540354"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 992.913, "latencies_ms": [992.913], "images_per_second": 1.007, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The large clock tower stands prominently in the foreground, positioned between the left side of the image and the Christmas tree. The Christmas tree occupies the central-right portion of the image, extending beyond the frame of the main objects.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [43.67, 43.67, 43.67, 44.05, 44.05, 44.05, 44.05, 44.05, 43.78, 43.78], "power_watts_avg": 43.88, "power_watts_peak": 44.05, "energy_joules_est": 43.58, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-11T13:36:19.549998"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 991.961, "latencies_ms": [991.961], "images_per_second": 1.008, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts a festive city square at night, featuring a tall clock tower adorned with Christmas lights and a large decorated Christmas tree. People are gathered around the tree and clock tower, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 57.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 43.45, 43.45, 43.45, 43.45, 43.45, 43.53, 43.53], "power_watts_avg": 43.56, "power_watts_peak": 43.78, "energy_joules_est": 43.23, "sample_count": 10, "duration_seconds": 0.992}, "timestamp": "2026-01-11T13:36:20.559948"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1085.547, "latencies_ms": [1085.547], "images_per_second": 0.921, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The Christmas tree is decorated with blue and white lights, creating a festive atmosphere. The clock tower is illuminated with warm yellow lights, adding to the overall warmth of the scene. The wet street reflects the lights and creates a reflective surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 43.53, 43.67, 43.67, 43.67, 43.67, 43.67, 43.58, 43.58, 43.58], "power_watts_avg": 43.61, "power_watts_peak": 43.67, "energy_joules_est": 47.37, "sample_count": 11, "duration_seconds": 1.086}, "timestamp": "2026-01-11T13:36:21.672143"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 804.014, "latencies_ms": [804.014], "images_per_second": 1.244, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A young man in a blue shirt and black shorts is playing tennis, swinging his racket to hit a yellow tennis ball on a green court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.7, "ram_available_mb": 109448.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 39.77, 39.77, 39.77, 39.77, 39.77, 43.46, 43.46], "power_watts_avg": 41.44, "power_watts_peak": 43.58, "energy_joules_est": 33.34, "sample_count": 9, "duration_seconds": 0.805}, "timestamp": "2026-01-11T13:36:22.585591"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1417.908, "latencies_ms": [1417.908], "images_per_second": 0.705, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 2\nTennis player: 1\nTennis shoes: 2\nTennis net: 1\nTrees: 2\nFence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 43.46, 45.93, 45.93, 45.93, 45.93, 45.93, 42.43, 42.43, 42.43, 42.43, 42.43, 34.59, 34.59], "power_watts_avg": 42.76, "power_watts_peak": 45.93, "energy_joules_est": 60.65, "sample_count": 15, "duration_seconds": 1.418}, "timestamp": "2026-01-11T13:36:24.094631"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1170.581, "latencies_ms": [1170.581], "images_per_second": 0.854, "prompt_tokens": 25, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The tennis player is positioned on the right side of the image, near the foreground of the tennis court. The tennis ball is visible in the air, near the player's racket, suggesting they are in the middle of a swing. The tennis court extends into the background, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.59, 34.59, 34.59, 42.07, 42.07, 42.07, 42.07, 42.07, 42.29, 42.29, 42.29, 42.29], "power_watts_avg": 40.27, "power_watts_peak": 42.29, "energy_joules_est": 47.15, "sample_count": 12, "duration_seconds": 1.171}, "timestamp": "2026-01-11T13:36:25.304698"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1108.436, "latencies_ms": [1108.436], "images_per_second": 0.902, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A young boy is playing tennis on a court. He is wearing a blue shirt and black shorts, swinging his racket to hit a tennis ball. The setting appears to be a park or recreational area with a chain-link fence and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.29, 33.3, 33.3, 33.3, 33.3, 33.3, 43.12, 43.12, 43.12, 43.12, 43.12, 44.12], "power_watts_avg": 39.04, "power_watts_peak": 44.12, "energy_joules_est": 43.3, "sample_count": 12, "duration_seconds": 1.109}, "timestamp": "2026-01-11T13:36:26.516149"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 917.886, "latencies_ms": [917.886], "images_per_second": 1.089, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The tennis court appears to be made of dark gray or black material. The lighting suggests an outdoor setting, possibly on a sunny day. The tennis racket is yellow and appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [44.12, 44.12, 44.12, 44.12, 42.38, 42.38, 42.38, 42.38, 42.38, 42.25], "power_watts_avg": 43.06, "power_watts_peak": 44.12, "energy_joules_est": 39.56, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:36:27.528274"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 627.032, "latencies_ms": [627.032], "images_per_second": 1.595, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The living room features a white fireplace with green marble surround, flanked by built-in bookshelves filled with books and framed artwork.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.25, 42.25, 42.25, 36.78, 36.78, 36.78, 36.78], "power_watts_avg": 39.12, "power_watts_peak": 42.25, "energy_joules_est": 24.55, "sample_count": 7, "duration_seconds": 0.628}, "timestamp": "2026-01-11T13:36:28.238720"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1011.613, "latencies_ms": [1011.613], "images_per_second": 0.989, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "bookcase: 6\nfireplace: 2\nlamp: 2\narmchair: 1\nside table: 2\nplant: 2\nsofa: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.78, 38.33, 38.33, 38.33, 38.33, 38.33, 37.13, 37.13, 37.13, 37.13, 37.13], "power_watts_avg": 37.64, "power_watts_peak": 38.33, "energy_joules_est": 38.1, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-11T13:36:29.348798"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 779.09, "latencies_ms": [779.09], "images_per_second": 1.284, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bookshelves are positioned on the left side of the image, while the armchair is situated in the foreground. The fireplace is situated in the background, slightly further away than the bookshelves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.26, 35.26, 35.26, 35.26, 35.26, 36.68, 36.68, 36.68], "power_watts_avg": 35.79, "power_watts_peak": 36.68, "energy_joules_est": 27.9, "sample_count": 8, "duration_seconds": 0.779}, "timestamp": "2026-01-11T13:36:30.157828"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 861.086, "latencies_ms": [861.086], "images_per_second": 1.161, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The living room features a white fireplace with green marble surround, surrounded by built-in bookshelves filled with books. The room is furnished with beige armchairs and matching sofas, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.68, 36.68, 42.34, 42.34, 42.34, 42.34, 42.34, 38.25, 38.25], "power_watts_avg": 40.18, "power_watts_peak": 42.34, "energy_joules_est": 34.62, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:36:31.068851"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 780.386, "latencies_ms": [780.386], "images_per_second": 1.281, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The room features a green marble fireplace mantel, white walls, and warm lighting from lamps. The furniture includes beige armchairs and a beige sofa, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.25, 38.25, 38.25, 38.04, 38.04, 38.04, 38.04, 38.04], "power_watts_avg": 38.12, "power_watts_peak": 38.25, "energy_joules_est": 29.77, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:36:31.879084"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 712.914, "latencies_ms": [712.914], "images_per_second": 1.403, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Three zebras are grazing on grass in a field, with one partially visible on the left side and the other two standing close together on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.08, 38.08, 38.08, 38.08, 38.08, 43.94, 43.94, 43.94], "power_watts_avg": 40.28, "power_watts_peak": 43.94, "energy_joules_est": 28.74, "sample_count": 8, "duration_seconds": 0.713}, "timestamp": "2026-01-11T13:36:32.691593"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 928.173, "latencies_ms": [928.173], "images_per_second": 1.077, "prompt_tokens": 21, "response_tokens_est": 25, "n_tiles": 1, "output_text": "zebra: 3\ngrass: 2\ndirt: 1\ntree: 1\nsky: 1\nbush: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [43.94, 43.94, 47.67, 47.67, 47.67, 47.67, 47.67, 42.54, 42.54, 42.54], "power_watts_avg": 45.38, "power_watts_peak": 47.67, "energy_joules_est": 42.15, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-11T13:36:33.703477"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1010.068, "latencies_ms": [1010.068], "images_per_second": 0.99, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close proximity to each other, with the zebra on the left closest to the viewer and the zebra on the right further away. The foreground is dominated by the grassy area, while the background features more sparse vegetation and trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.38, 42.38, 42.38, 42.38, 42.38, 43.11, 43.11, 43.11, 43.11], "power_watts_avg": 42.67, "power_watts_peak": 43.11, "energy_joules_est": 43.12, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-11T13:36:34.815970"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 962.333, "latencies_ms": [962.333], "images_per_second": 1.039, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Three zebras are grazing on grass in a savanna-like environment. The zebras are standing near a dirt patch and surrounded by dry grass and sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 37.0}, "power_stats": {"power_watts_samples": [43.11, 38.75, 38.75, 38.75, 38.75, 38.75, 41.75, 41.75, 41.75, 41.75], "power_watts_avg": 40.39, "power_watts_peak": 43.11, "energy_joules_est": 38.88, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-11T13:36:35.824575"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 786.931, "latencies_ms": [786.931], "images_per_second": 1.271, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The zebras exhibit striking black and white stripes. The lighting is bright and sunny, creating a vivid contrast against the greenery and the dirt ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 42.85, 42.85, 42.85, 42.77, 42.77, 42.77], "power_watts_avg": 42.82, "power_watts_peak": 42.85, "energy_joules_est": 33.73, "sample_count": 8, "duration_seconds": 0.788}, "timestamp": "2026-01-11T13:36:36.636952"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 711.174, "latencies_ms": [711.174], "images_per_second": 1.406, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of people, mostly older adults, are gathered around a wooden table in a cozy restaurant, enjoying a meal and conversation.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13057.8, "ram_available_mb": 109448.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 49.99, 49.99, 49.99, 49.99, 49.99, 43.38], "power_watts_avg": 47.36, "power_watts_peak": 49.99, "energy_joules_est": 33.7, "sample_count": 8, "duration_seconds": 0.711}, "timestamp": "2026-01-11T13:36:37.449779"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1245.679, "latencies_ms": [1245.679], "images_per_second": 0.803, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "table: 6\nchairs: 4\npeople: 10\nserving dishes: 2\nserving cups: 2\nbottles: 2\nclocks: 1\nframes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.3, "ram_available_mb": 109449.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 43.38, 44.89, 44.89, 44.89, 44.89, 44.89, 42.51, 42.51, 42.51, 42.51], "power_watts_avg": 43.69, "power_watts_peak": 44.89, "energy_joules_est": 54.45, "sample_count": 13, "duration_seconds": 1.246}, "timestamp": "2026-01-11T13:36:38.762851"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1119.748, "latencies_ms": [1119.748], "images_per_second": 0.893, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective in the image. The foreground features the seated people, while the background includes additional tables, chairs, and a counter. The chairs are placed at various distances from the foreground, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.51, 34.33, 34.33, 34.33, 34.33, 34.33, 43.18, 43.18, 43.18, 43.18, 43.18, 43.69], "power_watts_avg": 39.48, "power_watts_peak": 43.69, "energy_joules_est": 44.23, "sample_count": 12, "duration_seconds": 1.12}, "timestamp": "2026-01-11T13:36:39.976854"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1128.291, "latencies_ms": [1128.291], "images_per_second": 0.886, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A group of people are gathered around a long wooden table in a restaurant, enjoying a meal together. The restaurant has a rustic atmosphere with exposed brick walls and wooden floors. Various items like cups, bottles, and napkins are placed on the table.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.69, 43.69, 42.48, 42.48, 42.48, 42.48, 42.48, 42.46, 42.46, 42.46], "power_watts_avg": 42.88, "power_watts_peak": 43.69, "energy_joules_est": 48.38, "sample_count": 12, "duration_seconds": 1.128}, "timestamp": "2026-01-11T13:36:41.187563"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1145.236, "latencies_ms": [1145.236], "images_per_second": 0.873, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The restaurant has a warm and inviting atmosphere with wooden floors and exposed brick walls. The lighting is warm and inviting, complementing the cozy ambiance. The tables are set with plates, cups, and condiments, further enhancing the dining experience.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13057.2, "ram_available_mb": 109449.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.46, 42.46, 38.51, 38.51, 38.51, 38.51, 38.51, 42.94, 42.94, 42.94, 42.94, 42.94], "power_watts_avg": 41.01, "power_watts_peak": 42.94, "energy_joules_est": 46.98, "sample_count": 12, "duration_seconds": 1.146}, "timestamp": "2026-01-11T13:36:42.397637"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 770.844, "latencies_ms": [770.844], "images_per_second": 1.297, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A flock of twelve elegant white swans glides gracefully across the dark water, their gleaming bodies contrasting beautifully with the surrounding environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13057.6, "ram_available_mb": 109448.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [39.41, 39.41, 39.41, 39.41, 39.41, 43.14, 43.14, 43.14], "power_watts_avg": 40.81, "power_watts_peak": 43.14, "energy_joules_est": 31.47, "sample_count": 8, "duration_seconds": 0.771}, "timestamp": "2026-01-11T13:36:43.206676"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 954.637, "latencies_ms": [954.637], "images_per_second": 1.048, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "swans: 12\nboats: 6\nsailboats: 4\ndock: 1\nshore: 1\nsand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.8, "ram_available_mb": 109445.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 47.35, 47.35, 47.35, 47.35, 47.35, 43.74, 43.74, 43.74], "power_watts_avg": 45.42, "power_watts_peak": 47.35, "energy_joules_est": 43.39, "sample_count": 10, "duration_seconds": 0.955}, "timestamp": "2026-01-11T13:36:44.214035"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 785.786, "latencies_ms": [785.786], "images_per_second": 1.273, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the swans primarily on the right side of the image. The boats and harbor are situated in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.74, 43.74, 43.33, 43.33, 43.33, 43.33, 43.33, 43.43], "power_watts_avg": 43.44, "power_watts_peak": 43.74, "energy_joules_est": 34.16, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:36:45.021582"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1158.968, "latencies_ms": [1158.968], "images_per_second": 0.863, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The scene depicts a serene harbor with a flock of white swans swimming in the dark water.  Several boats are docked in the background, and a few people can be seen walking along the shoreline. The setting appears to be a picturesque coastal area with calm waters and a picturesque backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.43, 43.43, 43.43, 43.43, 50.83, 50.83, 50.83, 50.83, 50.83, 43.8, 43.8, 43.8], "power_watts_avg": 46.6, "power_watts_peak": 50.83, "energy_joules_est": 54.03, "sample_count": 12, "duration_seconds": 1.159}, "timestamp": "2026-01-11T13:36:46.231989"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1231.299, "latencies_ms": [1231.299], "images_per_second": 0.812, "prompt_tokens": 18, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The water is a dark blue-purple color, creating a striking contrast with the white swans. The lighting suggests it might be near sunrise or sunset, casting a warm glow on the scene. The swans appear to be swimming leisurely, and the overall atmosphere is serene and picturesque.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.8, 36.17, 36.17, 36.17, 36.17, 36.17, 43.16, 43.16, 43.16, 43.16, 43.16, 40.94, 40.94], "power_watts_avg": 40.18, "power_watts_peak": 43.8, "energy_joules_est": 49.49, "sample_count": 13, "duration_seconds": 1.232}, "timestamp": "2026-01-11T13:36:47.542587"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 651.862, "latencies_ms": [651.862], "images_per_second": 1.534, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A newlywed couple cuts their wedding cake together at their reception, surrounded by the lively atmosphere of the event.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [40.94, 40.94, 40.94, 42.81, 42.81, 42.81, 42.81], "power_watts_avg": 42.01, "power_watts_peak": 42.81, "energy_joules_est": 27.42, "sample_count": 7, "duration_seconds": 0.653}, "timestamp": "2026-01-11T13:36:48.254266"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1586.822, "latencies_ms": [1586.822], "images_per_second": 0.63, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Cake: 3\nWedding dress: 1\nBride: 1\nGroom: 1\nTable: 1\nCandles: 1\nSpeaker: 1\nMusical instruments: 2\nFlags: 2\nDance floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.81, 44.07, 44.07, 44.07, 44.07, 44.07, 43.51, 43.51, 43.51, 43.51, 43.51, 42.34, 42.34, 42.34, 42.34, 42.34], "power_watts_avg": 43.28, "power_watts_peak": 44.07, "energy_joules_est": 68.69, "sample_count": 16, "duration_seconds": 1.587}, "timestamp": "2026-01-11T13:36:49.866576"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 813.048, "latencies_ms": [813.048], "images_per_second": 1.23, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the bride and groom cutting the cake. The background includes additional guests and tables, suggesting the event is taking place in a larger venue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.2, 34.2, 34.2, 34.2, 34.2, 43.83, 43.83, 43.83, 43.83], "power_watts_avg": 38.48, "power_watts_peak": 43.83, "energy_joules_est": 31.3, "sample_count": 9, "duration_seconds": 0.814}, "timestamp": "2026-01-11T13:36:50.777507"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 822.71, "latencies_ms": [822.71], "images_per_second": 1.215, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A bride and groom are cutting their wedding cake inside a tent decorated with colorful pennants.  A band is playing in the background, and guests are standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 9.0}, "power_stats": {"power_watts_samples": [43.83, 43.0, 43.0, 43.0, 43.0, 43.0, 42.45, 42.45, 42.45], "power_watts_avg": 42.91, "power_watts_peak": 43.83, "energy_joules_est": 35.32, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-11T13:36:51.687794"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1077.231, "latencies_ms": [1077.231], "images_per_second": 0.928, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The wedding cake is multi-colored and appears to be made of fondant or similar material. The lighting in the tent creates a warm, inviting atmosphere. The venue is decorated with festive pennant flags, adding to the celebratory ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [42.45, 42.45, 48.48, 48.48, 48.48, 48.48, 48.48, 42.37, 42.37, 42.37, 42.37], "power_watts_avg": 45.16, "power_watts_peak": 48.48, "energy_joules_est": 48.67, "sample_count": 11, "duration_seconds": 1.078}, "timestamp": "2026-01-11T13:36:52.797418"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 862.937, "latencies_ms": [862.937], "images_per_second": 1.159, "prompt_tokens": 8, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The living room features a blue sofa, a wooden coffee table, a glass-topped side table with a lamp, a potted plant, a vase, and a framed picture on the wall.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13061.5, "ram_available_mb": 109444.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [42.37, 37.25, 37.25, 37.25, 37.25, 37.25, 43.48, 43.48, 43.48], "power_watts_avg": 39.89, "power_watts_peak": 43.48, "energy_joules_est": 34.46, "sample_count": 9, "duration_seconds": 0.864}, "timestamp": "2026-01-11T13:36:53.708945"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1178.185, "latencies_ms": [1178.185], "images_per_second": 0.849, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "plant: 2\nlamp: 1\ntable: 2\ncouch: 2\nrug: 1\nside table: 1\npicture: 2\nbook: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 48.31, 48.31, 48.31, 48.31, 48.31, 43.12, 43.12, 43.12, 43.12, 43.12], "power_watts_avg": 45.34, "power_watts_peak": 48.31, "energy_joules_est": 53.44, "sample_count": 12, "duration_seconds": 1.179}, "timestamp": "2026-01-11T13:36:54.920490"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1075.714, "latencies_ms": [1075.714], "images_per_second": 0.93, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The sofa is positioned in the foreground, facing the window and lamp. The coffee table is situated near the sofa, partially obscured by the sofa. The window and lamp are located in the background, offering a view and light to the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.28, 40.28, 40.28, 40.28, 40.28, 43.7, 43.7, 43.7, 43.7, 43.7, 44.03], "power_watts_avg": 42.18, "power_watts_peak": 44.03, "energy_joules_est": 45.4, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-11T13:36:56.032678"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1285.468, "latencies_ms": [1285.468], "images_per_second": 0.778, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The living room features a cozy and inviting atmosphere with deep red walls, natural light from several windows, and a variety of furniture including a blue sofa, a wooden coffee table, and a small side table with a lamp and plant. The space is decorated with artwork and plants, creating a warm and welcoming environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 44.03, 43.84, 43.84, 43.84, 43.84, 43.84, 43.78, 43.78, 43.78, 43.78, 43.78], "power_watts_avg": 43.86, "power_watts_peak": 44.03, "energy_joules_est": 56.4, "sample_count": 13, "duration_seconds": 1.286}, "timestamp": "2026-01-11T13:36:57.345708"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1174.253, "latencies_ms": [1174.253], "images_per_second": 0.852, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The room features a deep red wall, complemented by white lace curtains. The lighting is soft and warm, creating a cozy atmosphere. The furniture, including dark blue sofas and a wooden coffee table, is crafted from rich, natural materials.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.03, 34.03, 34.03, 34.03, 34.03, 43.68, 43.68, 43.68, 43.68, 43.68, 43.33, 43.33], "power_watts_avg": 39.6, "power_watts_peak": 43.68, "energy_joules_est": 46.52, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-11T13:36:58.556733"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 674.537, "latencies_ms": [674.537], "images_per_second": 1.482, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two dolls with red hair and round eyes are sitting together, holding hands and facing each other.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.33, 43.33, 43.33, 44.77, 44.77, 44.77, 44.77], "power_watts_avg": 44.15, "power_watts_peak": 44.77, "energy_joules_est": 29.81, "sample_count": 7, "duration_seconds": 0.675}, "timestamp": "2026-01-11T13:36:59.269424"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1164.442, "latencies_ms": [1164.442], "images_per_second": 0.859, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "clock: 10\nperson: 2\nbook: 5\nhair: 2\nface: 2\neyes: 2\nclock hands: 5\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.77, 45.38, 45.38, 45.38, 45.38, 45.38, 45.18, 45.18, 45.18, 45.18, 45.18, 45.4], "power_watts_avg": 45.25, "power_watts_peak": 45.4, "energy_joules_est": 52.71, "sample_count": 12, "duration_seconds": 1.165}, "timestamp": "2026-01-11T13:37:00.481793"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 968.451, "latencies_ms": [968.451], "images_per_second": 1.033, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The left object appears to be a clock positioned close to the viewer, while the right object is further away, partially obscured by the clock. The foreground is relatively close, while the background is further away, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 109444.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [45.4, 45.4, 45.4, 45.4, 44.8, 44.8, 44.8, 44.8, 44.8, 44.83], "power_watts_avg": 45.04, "power_watts_peak": 45.4, "energy_joules_est": 43.64, "sample_count": 10, "duration_seconds": 0.969}, "timestamp": "2026-01-11T13:37:01.493741"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1245.333, "latencies_ms": [1245.333], "images_per_second": 0.803, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "Two dolls with clock faces are positioned side-by-side, creating a surreal and dreamlike scene. The clocks appear to overlap and partially obscure each other, enhancing the surreal effect. The setting appears to be indoors, possibly a bedroom or living room, with a wooden surface visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.0, "ram_available_mb": 109445.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [44.83, 44.83, 44.83, 44.83, 45.05, 45.05, 45.05, 45.05, 45.05, 44.98, 44.98, 44.98, 44.98], "power_watts_avg": 44.96, "power_watts_peak": 45.05, "energy_joules_est": 56.01, "sample_count": 13, "duration_seconds": 1.246}, "timestamp": "2026-01-11T13:37:02.809012"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1735.236, "latencies_ms": [1735.236], "images_per_second": 0.576, "prompt_tokens": 18, "response_tokens_est": 90, "n_tiles": 1, "output_text": "The dominant colors are warm hues of orange and red, contrasted by the cool yellowish tones of the clock faces. The lighting creates a soft, dreamy effect, enhancing the surreal and artistic nature of the image. The materials appear to be fabric and possibly paper, giving the composition a slightly textured and layered look. The weather is not explicitly visible in the image, but the overall mood and atmosphere are suggestive of a warm, cozy setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.98, 32.79, 32.79, 32.79, 32.79, 32.79, 44.17, 44.17, 44.17, 44.17, 44.17, 45.09, 45.09, 45.09, 45.09, 45.09, 34.09, 34.09], "power_watts_avg": 40.19, "power_watts_peak": 45.09, "energy_joules_est": 69.76, "sample_count": 18, "duration_seconds": 1.736}, "timestamp": "2026-01-11T13:37:04.625674"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 618.415, "latencies_ms": [618.415], "images_per_second": 1.617, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young boy, wearing a black helmet and tan jacket, sits on a black and silver scooter, looking to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [34.09, 34.09, 34.09, 36.78, 36.78, 36.78, 36.78], "power_watts_avg": 35.63, "power_watts_peak": 36.78, "energy_joules_est": 22.05, "sample_count": 7, "duration_seconds": 0.619}, "timestamp": "2026-01-11T13:37:05.335371"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1135.484, "latencies_ms": [1135.484], "images_per_second": 0.881, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "helmet: 1\nmotorcycle: 1\nman: 1\npants: 1\nshoes: 1\njacket: 1\nmirror: 1\nface: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.9, "ram_available_mb": 109445.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.36, 35.36, 35.36, 35.36, 35.36, 36.66, 36.66, 36.66, 36.66, 36.66, 38.05, 38.05], "power_watts_avg": 36.35, "power_watts_peak": 38.05, "energy_joules_est": 41.29, "sample_count": 12, "duration_seconds": 1.136}, "timestamp": "2026-01-11T13:37:06.546072"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 745.505, "latencies_ms": [745.505], "images_per_second": 1.341, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The man is positioned in the foreground of the image, riding a scooter. The scooter is situated in the background, partially obscured by the man and other people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.05, 38.05, 38.05, 37.52, 37.52, 37.52, 37.52, 37.52], "power_watts_avg": 37.72, "power_watts_peak": 38.05, "energy_joules_est": 28.13, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-11T13:37:07.353241"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.556, "latencies_ms": [1052.556], "images_per_second": 0.95, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A young boy is riding a scooter in a busy area, possibly a city street. He wears a tan jacket and beige pants, sitting comfortably on the scooter while looking to his right. Other people are visible in the background, suggesting a public setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.1, "ram_available_mb": 109445.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.12, 37.12, 37.12, 37.12, 37.12, 37.68, 37.68, 37.68, 37.68, 37.68, 37.77], "power_watts_avg": 37.43, "power_watts_peak": 37.77, "energy_joules_est": 39.41, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-11T13:37:08.465094"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 686.564, "latencies_ms": [686.564], "images_per_second": 1.457, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scooter is primarily silver and black. The lighting appears to be natural daylight. The materials appear to be durable plastic and metal. The weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.77, 37.77, 37.77, 37.77, 37.47, 37.47, 37.47], "power_watts_avg": 37.64, "power_watts_peak": 37.77, "energy_joules_est": 25.85, "sample_count": 7, "duration_seconds": 0.687}, "timestamp": "2026-01-11T13:37:09.172569"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 435.768, "latencies_ms": [435.768], "images_per_second": 2.295, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A large pizza with melted cheese and herbs is being sliced and served on a wooden table.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.47, 37.47, 42.09, 42.09, 42.09], "power_watts_avg": 40.24, "power_watts_peak": 42.09, "energy_joules_est": 17.55, "sample_count": 5, "duration_seconds": 0.436}, "timestamp": "2026-01-11T13:37:09.680152"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1667.948, "latencies_ms": [1667.948], "images_per_second": 0.6, "prompt_tokens": 21, "response_tokens_est": 60, "n_tiles": 1, "output_text": "Pizza: 8\nCheese: 8\nSpinach: 8\nTomato sauce: 8\nTomatoes: 8\nBasil: 8\nCheese: 8\nSauce: 8\nOlive oil: 8\nBaking pan: 8\nPizza stone: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.09, 42.09, 42.04, 42.04, 42.04, 42.04, 42.04, 37.31, 37.31, 37.31, 37.31, 37.31, 33.95, 33.95, 33.95, 33.95, 33.95], "power_watts_avg": 38.27, "power_watts_peak": 42.09, "energy_joules_est": 63.85, "sample_count": 17, "duration_seconds": 1.668}, "timestamp": "2026-01-11T13:37:11.395818"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 765.985, "latencies_ms": [765.985], "images_per_second": 1.306, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main object is a large, freshly baked pizza, positioned in the foreground of the image. The background features kitchen elements and a partially visible person's arm, suggesting the setting is a professional kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.07, 34.07, 34.07, 34.07, 34.07, 37.96, 37.96, 37.96], "power_watts_avg": 35.53, "power_watts_peak": 37.96, "energy_joules_est": 27.24, "sample_count": 8, "duration_seconds": 0.767}, "timestamp": "2026-01-11T13:37:12.204959"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 701.351, "latencies_ms": [701.351], "images_per_second": 1.426, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A large pizza with green toppings is being prepared on a large wooden table in a dimly lit kitchen. A person is visible in the background, seemingly involved in the pizza-making process.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.96, 37.96, 42.23, 42.23, 42.23, 42.23, 42.23], "power_watts_avg": 41.01, "power_watts_peak": 42.23, "energy_joules_est": 28.77, "sample_count": 7, "duration_seconds": 0.702}, "timestamp": "2026-01-11T13:37:12.913367"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 795.634, "latencies_ms": [795.634], "images_per_second": 1.257, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The pizza has a golden-brown crust and a creamy, melted cheese topping. The lighting is dim, creating a warm, cozy atmosphere. The pizza appears to be freshly baked and ready to be served.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.3, "ram_available_mb": 109445.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.03, 38.03, 38.03, 38.03, 38.03, 38.59, 38.59, 38.59], "power_watts_avg": 38.24, "power_watts_peak": 38.59, "energy_joules_est": 30.44, "sample_count": 8, "duration_seconds": 0.796}, "timestamp": "2026-01-11T13:37:13.723542"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 717.174, "latencies_ms": [717.174], "images_per_second": 1.394, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A female tennis player, dressed in white, is captured mid-serve on a grass court, holding a tennis racket and poised to hit the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [38.59, 38.59, 43.06, 43.06, 43.06, 43.06, 43.06, 38.28], "power_watts_avg": 41.34, "power_watts_peak": 43.06, "energy_joules_est": 29.66, "sample_count": 8, "duration_seconds": 0.717}, "timestamp": "2026-01-11T13:37:14.536635"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1230.021, "latencies_ms": [1230.021], "images_per_second": 0.813, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis skirt: 1\nTennis shoes: 2\nTennis visor: 1\nTennis net: 1\nTennis court: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.28, 38.28, 38.28, 37.94, 37.94, 37.94, 37.94, 37.94, 36.89, 36.89, 36.89, 36.89, 36.89], "power_watts_avg": 37.62, "power_watts_peak": 38.28, "energy_joules_est": 46.29, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-11T13:37:15.850760"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 780.724, "latencies_ms": [780.724], "images_per_second": 1.281, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, reaching up with her right arm to hit the ball. The tennis court extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.75, 32.75, 32.75, 32.75, 32.75, 37.01, 37.01, 37.01], "power_watts_avg": 34.34, "power_watts_peak": 37.01, "energy_joules_est": 26.83, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:37:16.661532"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 740.065, "latencies_ms": [740.065], "images_per_second": 1.351, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A woman in a white tennis outfit is playing tennis on a grass court, reaching up to hit the ball with her racket. The setting appears to be a sunny day at the tennis court.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [37.01, 37.01, 42.36, 42.36, 42.36, 42.36, 42.36, 37.92], "power_watts_avg": 40.47, "power_watts_peak": 42.36, "energy_joules_est": 29.96, "sample_count": 8, "duration_seconds": 0.74}, "timestamp": "2026-01-11T13:37:17.472814"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 691.364, "latencies_ms": [691.364], "images_per_second": 1.446, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The tennis player is wearing a white outfit. The tennis court is green and appears to be well-maintained. The lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.92, 37.92, 37.92, 37.92, 36.75, 36.75, 36.75], "power_watts_avg": 37.42, "power_watts_peak": 37.92, "energy_joules_est": 25.89, "sample_count": 7, "duration_seconds": 0.692}, "timestamp": "2026-01-11T13:37:18.181946"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 837.295, "latencies_ms": [837.295], "images_per_second": 1.194, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A white toilet is situated in a small bathroom with yellow walls and brown tiled flooring, accompanied by a white bathtub, a shower curtain, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.7, "ram_available_mb": 109444.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.75, 36.75, 43.88, 43.88, 43.88, 43.88, 43.88, 43.88, 43.88], "power_watts_avg": 42.29, "power_watts_peak": 43.88, "energy_joules_est": 35.44, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-11T13:37:19.093291"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1487.371, "latencies_ms": [1487.371], "images_per_second": 0.672, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "toilet: 1\nshower curtain: 1\nbathroom towel rack: 2\ntoilet paper: 1\nbathtub: 1\ncloset: 3\nbedspread: 1\nshower curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.88, 43.88, 43.88, 45.99, 45.99, 45.99, 45.99, 45.99, 42.71, 42.71, 42.71, 42.71, 42.71, 33.89, 33.89], "power_watts_avg": 42.86, "power_watts_peak": 45.99, "energy_joules_est": 63.77, "sample_count": 15, "duration_seconds": 1.488}, "timestamp": "2026-01-11T13:37:20.608105"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 728.272, "latencies_ms": [728.272], "images_per_second": 1.373, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The toilet is positioned to the left of the shower and bathtub. The closet is located to the right of the toilet, further back in the room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13063.0, "ram_available_mb": 109443.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [33.89, 33.89, 33.89, 43.65, 43.65, 43.65, 43.65, 43.65], "power_watts_avg": 39.99, "power_watts_peak": 43.65, "energy_joules_est": 29.14, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-11T13:37:21.419227"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.119, "latencies_ms": [828.119], "images_per_second": 1.208, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The bathroom features a white toilet, a bathtub with a shower curtain, and a closet with wire shelving. Towels hang on a towel rack above the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.8, 43.8, 43.8, 43.8, 43.8, 42.68, 42.68, 42.68, 42.68], "power_watts_avg": 43.3, "power_watts_peak": 43.8, "energy_joules_est": 35.88, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:37:22.330758"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1229.85, "latencies_ms": [1229.85], "images_per_second": 0.813, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The bathroom features a pale yellow color scheme, creating a warm and inviting atmosphere. The lighting appears to be soft and diffused, enhancing the overall ambiance. The materials used include white fixtures for the toilet and shower, beige tiles for the floor, and metal shelving for storage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13063.2, "ram_available_mb": 109443.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.12, 41.12, 41.12, 41.12, 41.12, 42.71, 42.71, 42.71, 42.71, 42.71, 44.39, 44.39, 44.39], "power_watts_avg": 42.48, "power_watts_peak": 44.39, "energy_joules_est": 52.26, "sample_count": 13, "duration_seconds": 1.23}, "timestamp": "2026-01-11T13:37:23.645762"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 556.359, "latencies_ms": [556.359], "images_per_second": 1.797, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "Two people are standing in a room, holding wine glasses and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.39, 44.39, 41.23, 41.23, 41.23, 41.23], "power_watts_avg": 42.28, "power_watts_peak": 44.39, "energy_joules_est": 23.55, "sample_count": 6, "duration_seconds": 0.557}, "timestamp": "2026-01-11T13:37:24.255566"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1231.229, "latencies_ms": [1231.229], "images_per_second": 0.812, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Wine glass: 2\nWine bottle: 1\nWine: 2\nTable: 2\nChair: 1\nWindow: 1\nMan: 3\nWoman: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.23, 44.98, 44.98, 44.98, 44.98, 44.98, 44.77, 44.77, 44.77, 44.77, 44.77, 42.22, 42.22], "power_watts_avg": 44.19, "power_watts_peak": 44.98, "energy_joules_est": 54.43, "sample_count": 13, "duration_seconds": 1.232}, "timestamp": "2026-01-11T13:37:25.568987"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 893.445, "latencies_ms": [893.445], "images_per_second": 1.119, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a man and woman holding wine glasses between them. The background features additional people and a dining table, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.22, 42.22, 42.22, 42.66, 42.66, 42.66, 42.66, 42.66, 42.22], "power_watts_avg": 42.47, "power_watts_peak": 42.66, "energy_joules_est": 37.96, "sample_count": 9, "duration_seconds": 0.894}, "timestamp": "2026-01-11T13:37:26.479157"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 918.405, "latencies_ms": [918.405], "images_per_second": 1.089, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene depicts a casual gathering in a home or restaurant, where two people are holding wine glasses and smiling at the camera. The setting is relaxed, with other individuals visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [42.22, 42.22, 42.22, 42.22, 42.99, 42.99, 42.99, 42.99, 42.99, 43.53], "power_watts_avg": 42.74, "power_watts_peak": 43.53, "energy_joules_est": 39.28, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:37:27.487355"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1180.716, "latencies_ms": [1180.716], "images_per_second": 0.847, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The wine glasses are clear with red wine inside. The lighting is soft and warm, creating a pleasant atmosphere. The glasses appear to be made of glass and have a simple design. The overall setting suggests a casual, relaxed environment, possibly a wine tasting event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 43.53, 43.53, 42.69, 42.69, 42.69, 42.69, 42.69, 42.48, 42.48, 42.48], "power_watts_avg": 42.92, "power_watts_peak": 43.53, "energy_joules_est": 50.7, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-11T13:37:28.700354"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 779.153, "latencies_ms": [779.153], "images_per_second": 1.283, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A surfer skillfully rides a wave on a surfboard, showcasing their expertise and balance amidst the powerful blue-green water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 39.29, 39.29, 39.29, 39.29, 39.29, 43.65], "power_watts_avg": 40.63, "power_watts_peak": 43.65, "energy_joules_est": 31.68, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-11T13:37:29.511699"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1057.422, "latencies_ms": [1057.422], "images_per_second": 0.946, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "wave: 1\nsurfer: 1\nsurfboard: 1\nwater: 1\nsand: 1\nsky: 1\npeople: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 43.65, 43.65, 48.81, 48.81, 48.81, 48.81, 48.81, 43.78, 43.78], "power_watts_avg": 46.02, "power_watts_peak": 48.81, "energy_joules_est": 48.67, "sample_count": 11, "duration_seconds": 1.058}, "timestamp": "2026-01-11T13:37:30.624001"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1122.162, "latencies_ms": [1122.162], "images_per_second": 0.891, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave that extends into the background. The wave is curling over, creating a tunnel-like effect. The surfer is relatively close to the wave, navigating it within the curling crest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 42.74, 42.74, 42.74, 42.74, 42.74, 43.5, 43.5, 43.5, 43.5], "power_watts_avg": 43.26, "power_watts_peak": 43.78, "energy_joules_est": 48.57, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:37:31.836618"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1038.127, "latencies_ms": [1038.127], "images_per_second": 0.963, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A surfer skillfully rides a wave in the ocean, wearing a wetsuit and riding a light-colored surfboard. The wave is breaking, creating a dramatic scene with clear blue water and a sandy beach in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.29, 33.29, 33.29, 33.29, 33.29, 42.73, 42.73, 42.73, 42.73, 42.73, 43.83], "power_watts_avg": 38.54, "power_watts_peak": 43.83, "energy_joules_est": 40.03, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-11T13:37:32.950068"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1173.959, "latencies_ms": [1173.959], "images_per_second": 0.852, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The water is a vibrant teal color, creating a striking contrast with the white foam of the wave. The lighting is bright and clear, illuminating the surfer and the wave's curves. The surfboard appears to be made of a light-colored wood or composite material.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.83, 43.83, 43.83, 43.83, 42.72, 42.72, 42.72, 42.72, 42.72, 42.87, 42.87, 42.87], "power_watts_avg": 43.13, "power_watts_peak": 43.83, "energy_joules_est": 50.65, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-11T13:37:34.162815"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 711.39, "latencies_ms": [711.39], "images_per_second": 1.406, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A wooden table holds six open laptops, some with visible keyboards and screens, and a red and black backpack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.7, "ram_available_mb": 109429.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 40.95, 40.95, 40.95, 40.95, 40.95, 42.82], "power_watts_avg": 41.66, "power_watts_peak": 42.87, "energy_joules_est": 29.67, "sample_count": 8, "duration_seconds": 0.712}, "timestamp": "2026-01-11T13:37:34.973635"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1496.607, "latencies_ms": [1496.607], "images_per_second": 0.668, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "laptop: 5\nbackpack: 1\ncables: 10\nwires: 10\nlaptop charger: 1\nlaptop power adapter: 1\nlaptop keyboard: 5\nlaptop screen: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.7, "ram_available_mb": 109429.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.7, "ram_available_mb": 109429.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.82, 44.3, 44.3, 44.3, 44.3, 44.3, 42.4, 42.4, 42.4, 42.4, 42.4, 34.19], "power_watts_avg": 42.6, "power_watts_peak": 44.3, "energy_joules_est": 63.78, "sample_count": 15, "duration_seconds": 1.497}, "timestamp": "2026-01-11T13:37:36.486302"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 888.895, "latencies_ms": [888.895], "images_per_second": 1.125, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned in a somewhat haphazard manner, with laptops and bags placed close together in the foreground. The background features additional laptops, suggesting a larger collection or workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.7, "ram_available_mb": 109429.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.19, 34.19, 34.19, 34.19, 44.24, 44.24, 44.24, 44.24, 44.24], "power_watts_avg": 39.77, "power_watts_peak": 44.24, "energy_joules_est": 35.38, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:37:37.396897"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 804.804, "latencies_ms": [804.804], "images_per_second": 1.243, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A group of open laptops is arranged on a wooden table in a room.  The laptops are connected to various cables and cords, suggesting a workspace or study area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.22, 44.22, 44.22, 44.22, 44.22, 44.13, 44.13, 44.13, 44.13], "power_watts_avg": 44.18, "power_watts_peak": 44.22, "energy_joules_est": 35.58, "sample_count": 9, "duration_seconds": 0.805}, "timestamp": "2026-01-11T13:37:38.306536"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 986.572, "latencies_ms": [986.572], "images_per_second": 1.014, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The laptops are primarily black and silver. The lighting is soft and diffused, suggesting indoor lighting. The laptops appear to be made of metal and plastic. The overall setting appears casual and possibly a workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.13, 42.29, 42.29, 42.29, 42.29, 42.29, 42.34, 42.34, 42.34, 42.34], "power_watts_avg": 42.49, "power_watts_peak": 44.13, "energy_joules_est": 41.95, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-11T13:37:39.317824"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 772.901, "latencies_ms": [772.901], "images_per_second": 1.294, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A skier in an orange and green jacket is performing an impressive jump, crossing their skis in the air while holding ski poles.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.34, 43.84, 43.84, 43.84, 43.84, 43.84, 43.43, 43.43], "power_watts_avg": 43.55, "power_watts_peak": 43.84, "energy_joules_est": 33.66, "sample_count": 8, "duration_seconds": 0.773}, "timestamp": "2026-01-11T13:37:40.129394"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1301.102, "latencies_ms": [1301.102], "images_per_second": 0.769, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "skier: 2\nskis: 2\nsnowboard: 1\nski poles: 1\nhelmet: 1\ngloves: 1\ngoggles: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.43, 43.43, 43.43, 53.2, 53.2, 53.2, 53.2, 53.2, 43.67, 43.67, 43.67, 43.67, 34.77], "power_watts_avg": 46.59, "power_watts_peak": 53.2, "energy_joules_est": 60.64, "sample_count": 13, "duration_seconds": 1.301}, "timestamp": "2026-01-11T13:37:41.440759"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1084.319, "latencies_ms": [1084.319], "images_per_second": 0.922, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, mid-air, performing a jump. The background features another skier further away, seemingly observing the action. The foreground is relatively empty, while the background is populated by the skier.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 34.77, 44.4, 44.4, 44.4, 44.4, 44.4, 44.39, 44.39], "power_watts_avg": 40.89, "power_watts_peak": 44.4, "energy_joules_est": 44.35, "sample_count": 11, "duration_seconds": 1.085}, "timestamp": "2026-01-11T13:37:42.551651"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 882.137, "latencies_ms": [882.137], "images_per_second": 1.134, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A skier is performing a jump in the air, showcasing their skill and athleticism. The scene takes place on a snowy slope, with another skier visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [44.39, 44.39, 44.39, 43.63, 43.63, 43.63, 43.63, 43.63, 43.76], "power_watts_avg": 43.9, "power_watts_peak": 44.39, "energy_joules_est": 38.75, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-11T13:37:43.461987"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1131.146, "latencies_ms": [1131.146], "images_per_second": 0.884, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The skier is wearing bright orange and green clothing. The lighting is bright and clear, creating a vivid contrast against the blue sky. The skis appear to be made of metal and have a black and white design. The snow is bright white, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 43.76, 43.8, 43.8, 43.8, 43.8, 43.8, 43.83, 43.83, 43.83], "power_watts_avg": 43.8, "power_watts_peak": 43.83, "energy_joules_est": 49.56, "sample_count": 12, "duration_seconds": 1.132}, "timestamp": "2026-01-11T13:37:44.672701"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 615.13, "latencies_ms": [615.13], "images_per_second": 1.626, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A small bird perches on the window sill of a boat, gazing out at the calm, dark blue water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 57.0}, "power_stats": {"power_watts_samples": [43.83, 43.83, 37.14, 37.14, 37.14, 37.14, 37.14], "power_watts_avg": 39.05, "power_watts_peak": 43.83, "energy_joules_est": 24.04, "sample_count": 7, "duration_seconds": 0.616}, "timestamp": "2026-01-11T13:37:45.383789"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1061.316, "latencies_ms": [1061.316], "images_per_second": 0.942, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "porthole: 1\nbird: 1\nwater: 1\nmetal: 1\npane: 1\nframe: 1\nhandle: 1\nsign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.16, 36.16, 36.16, 36.16, 36.16, 36.99, 36.99, 36.99, 36.99, 36.99, 37.98], "power_watts_avg": 36.7, "power_watts_peak": 37.98, "energy_joules_est": 38.96, "sample_count": 11, "duration_seconds": 1.062}, "timestamp": "2026-01-11T13:37:46.494331"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 817.709, "latencies_ms": [817.709], "images_per_second": 1.223, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The main object is a bird perched on a window sill, positioned near the foreground of the image. The background features a body of water and a distant shoreline, suggesting the bird is at a considerable distance from the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.98, 37.98, 37.98, 37.98, 37.96, 37.96, 37.96, 37.96, 37.96], "power_watts_avg": 37.97, "power_watts_peak": 37.98, "energy_joules_est": 31.07, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:37:47.402972"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 806.747, "latencies_ms": [806.747], "images_per_second": 1.24, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A bird is perched on a rusty porthole window, gazing out at the calm, greyish-blue water. A rocky coastline is visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.5, 37.5, 37.5, 37.5, 37.5, 36.4, 36.4, 36.4, 36.4], "power_watts_avg": 37.01, "power_watts_peak": 37.5, "energy_joules_est": 29.87, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-11T13:37:48.312807"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 945.412, "latencies_ms": [945.412], "images_per_second": 1.058, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The water appears gray and somewhat murky. The window frame is rusty, suggesting age or exposure to the elements. The overall lighting is dim, casting shadows and highlighting the bird's silhouette against the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.4, 35.47, 35.47, 35.47, 35.47, 35.47, 36.85, 36.85, 36.85, 36.85], "power_watts_avg": 36.11, "power_watts_peak": 36.85, "energy_joules_est": 34.16, "sample_count": 10, "duration_seconds": 0.946}, "timestamp": "2026-01-11T13:37:49.322865"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 609.046, "latencies_ms": [609.046], "images_per_second": 1.642, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man is cleaning a bathroom stall while another man stands nearby, possibly observing or waiting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.85, 37.19, 37.19, 37.19, 37.19, 37.19, 42.83], "power_watts_avg": 37.95, "power_watts_peak": 42.83, "energy_joules_est": 23.13, "sample_count": 7, "duration_seconds": 0.61}, "timestamp": "2026-01-11T13:37:50.032337"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2046.933, "latencies_ms": [2046.933], "images_per_second": 0.489, "prompt_tokens": 21, "response_tokens_est": 63, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper: 2\ntoilet brush: 1\ntoilet cleaner: 1\ntoilet cleaner bucket: 1\ntoilet cleaner mop: 1\ntoilet cleaner shelf: 2\ntoilet lid: 1\ntoilet seat: 1\ntoilet seat cover: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.83, 42.83, 42.83, 42.83, 52.86, 52.86, 52.86, 52.86, 42.29, 42.29, 42.29, 42.29, 42.29, 33.78, 33.78, 33.78, 33.78, 33.78, 33.72, 33.72, 33.72], "power_watts_avg": 41.16, "power_watts_peak": 52.86, "energy_joules_est": 84.26, "sample_count": 21, "duration_seconds": 2.047}, "timestamp": "2026-01-11T13:37:52.149729"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 861.959, "latencies_ms": [861.959], "images_per_second": 1.16, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in a way that suggests a spatial relationship between the foreground, which includes the toilet and bucket, and the background, which includes the shelves and the person cleaning the bathroom.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.72, 33.72, 38.01, 38.01, 38.01, 38.01, 38.01, 41.9, 41.9], "power_watts_avg": 37.92, "power_watts_peak": 41.9, "energy_joules_est": 32.73, "sample_count": 9, "duration_seconds": 0.863}, "timestamp": "2026-01-11T13:37:53.111074"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 820.422, "latencies_ms": [820.422], "images_per_second": 1.219, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two men are working in a bathroom, cleaning and organizing the space. One man is cleaning the floor, while the other is reaching into a toilet stall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.9, 41.9, 41.9, 48.13, 48.13, 48.13, 48.13, 48.13, 43.02], "power_watts_avg": 45.48, "power_watts_peak": 48.13, "energy_joules_est": 37.33, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:37:54.021834"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 868.031, "latencies_ms": [868.031], "images_per_second": 1.152, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The bathroom has a light brown color scheme. The lighting appears to be artificial, likely fluorescent. The floor is covered in teal mop stains, suggesting recent cleaning activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 42.41, 42.41, 42.41, 42.41, 42.41], "power_watts_avg": 42.68, "power_watts_peak": 43.02, "energy_joules_est": 37.06, "sample_count": 9, "duration_seconds": 0.868}, "timestamp": "2026-01-11T13:37:54.932827"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 789.563, "latencies_ms": [789.563], "images_per_second": 1.267, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man is standing in a dark hallway, holding an open umbrella that partially obscures his face, shielding him from the rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.21, 42.21, 42.21, 42.21, 43.37, 43.37, 43.37, 43.37], "power_watts_avg": 42.79, "power_watts_peak": 43.37, "energy_joules_est": 33.82, "sample_count": 8, "duration_seconds": 0.79}, "timestamp": "2026-01-11T13:37:55.744216"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1283.591, "latencies_ms": [1283.591], "images_per_second": 0.779, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Umbrella: 1\nPerson: 1\nDoor: 2\nWall: 2\nPicture frame: 1\nRadiator: 1\nFloor: 1\nDoor handle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.37, 47.12, 47.12, 47.12, 47.12, 47.12, 43.85, 43.85, 43.85, 43.85, 43.85, 40.46, 40.46], "power_watts_avg": 44.55, "power_watts_peak": 47.12, "energy_joules_est": 57.21, "sample_count": 13, "duration_seconds": 1.284}, "timestamp": "2026-01-11T13:37:57.058687"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1238.746, "latencies_ms": [1238.746], "images_per_second": 0.807, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The man is standing in the foreground of the image, holding an umbrella that partially obscures him. The umbrella is positioned above him, creating a sense of depth and perspective. The background features a hallway with red walls, doors, and framed pictures, adding to the overall setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.46, 40.46, 40.46, 43.86, 43.86, 43.86, 43.86, 43.86, 43.84, 43.84, 43.84, 43.84, 43.84], "power_watts_avg": 43.07, "power_watts_peak": 43.86, "energy_joules_est": 53.37, "sample_count": 13, "duration_seconds": 1.239}, "timestamp": "2026-01-11T13:37:58.373098"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 880.507, "latencies_ms": [880.507], "images_per_second": 1.136, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man is standing in a hallway, holding an umbrella to shield himself from the rain. The hallway has red walls and features framed pictures and mirrors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.19, 33.19, 33.19, 33.19, 33.19, 42.3, 42.3, 42.3, 42.3], "power_watts_avg": 37.24, "power_watts_peak": 42.3, "energy_joules_est": 32.8, "sample_count": 9, "duration_seconds": 0.881}, "timestamp": "2026-01-11T13:37:59.284599"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1079.903, "latencies_ms": [1079.903], "images_per_second": 0.926, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The walls are painted a reddish-orange color. The lighting is dim, creating a moody atmosphere. The umbrella appears to be made of a dark material, possibly plastic or metal, and it's being held by the person in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.3, 44.25, 44.25, 44.25, 44.25, 44.25, 43.03, 43.03, 43.03, 43.03, 43.03], "power_watts_avg": 43.52, "power_watts_peak": 44.25, "energy_joules_est": 47.01, "sample_count": 11, "duration_seconds": 1.08}, "timestamp": "2026-01-11T13:38:00.396162"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 829.667, "latencies_ms": [829.667], "images_per_second": 1.205, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man wearing a red shirt and carrying a backpack is standing on a rocky path, looking upwards, while another person in a yellow outfit is walking nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.04, 42.04, 42.04, 42.04, 42.04, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 42.59, "power_watts_peak": 43.28, "energy_joules_est": 35.36, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-11T13:38:01.310181"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1187.359, "latencies_ms": [1187.359], "images_per_second": 0.842, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "stairs: 5\nsign: 4\nman: 1\nbackpack: 1\npole: 1\nwater: 1\nrocks: 5\nvegetation: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.28, 42.11, 42.11, 42.11, 42.11, 42.11, 42.52, 42.52, 42.52, 42.52, 42.52, 44.03], "power_watts_avg": 42.54, "power_watts_peak": 44.03, "energy_joules_est": 50.53, "sample_count": 12, "duration_seconds": 1.188}, "timestamp": "2026-01-11T13:38:02.523620"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1012.212, "latencies_ms": [1012.212], "images_per_second": 0.988, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The man in the foreground is standing near the stream and looking upwards. The man in the background is walking up a path near the stream. The foreground and background are relatively close together, and the man in the foreground is relatively closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 44.03, 44.03, 43.61, 43.61, 43.61, 43.61, 43.61, 43.78, 43.78], "power_watts_avg": 43.79, "power_watts_peak": 44.03, "energy_joules_est": 44.35, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:38:03.637541"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 880.082, "latencies_ms": [880.082], "images_per_second": 1.136, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two hikers, one with an orange jacket and the other with a blue backpack, are walking along a trail in a lush, forested area. A wooden bridge with signs is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 40.93, 40.93, 40.93, 40.93, 40.93, 42.18, 42.18], "power_watts_avg": 41.84, "power_watts_peak": 43.78, "energy_joules_est": 36.84, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-11T13:38:04.548261"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1094.352, "latencies_ms": [1094.352], "images_per_second": 0.914, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The man is wearing an orange jacket and blue jeans. The scene is lit by natural sunlight, creating a warm and inviting atmosphere. The setting appears to be outdoors in a natural environment, possibly a forest or park, with lush greenery and rocks visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [42.18, 42.18, 42.18, 44.69, 44.69, 44.69, 44.69, 44.69, 43.34, 43.34, 43.34], "power_watts_avg": 43.64, "power_watts_peak": 44.69, "energy_joules_est": 47.77, "sample_count": 11, "duration_seconds": 1.095}, "timestamp": "2026-01-11T13:38:05.658747"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 646.932, "latencies_ms": [646.932], "images_per_second": 1.546, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Four men in business attire are standing together in a room, smiling and posing for a photo.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 42.2, 42.2, 42.2, 42.2, 42.2], "power_watts_avg": 42.52, "power_watts_peak": 43.34, "energy_joules_est": 27.54, "sample_count": 7, "duration_seconds": 0.648}, "timestamp": "2026-01-11T13:38:06.368525"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1143.01, "latencies_ms": [1143.01], "images_per_second": 0.875, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "man: 3\nman: 2\nman: 1\nman: 1\nman: 1\nman: 1\nman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.16, 44.16, 44.16, 44.16, 44.16, 46.48, 46.48, 46.48, 46.48, 46.48, 44.37, 44.37], "power_watts_avg": 45.16, "power_watts_peak": 46.48, "energy_joules_est": 51.65, "sample_count": 12, "duration_seconds": 1.144}, "timestamp": "2026-01-11T13:38:07.580688"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 899.303, "latencies_ms": [899.303], "images_per_second": 1.112, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The four men are standing close together in the foreground, with a bar and chairs visible in the background. The bar is positioned to the left of the men, while the chairs are placed towards the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.37, 44.37, 44.37, 43.71, 43.71, 43.71, 43.71, 43.71, 43.74], "power_watts_avg": 43.93, "power_watts_peak": 44.37, "energy_joules_est": 39.52, "sample_count": 9, "duration_seconds": 0.9}, "timestamp": "2026-01-11T13:38:08.490353"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1050.048, "latencies_ms": [1050.048], "images_per_second": 0.952, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "Four men are standing together in a room, possibly at a social gathering or event. They are dressed in business casual attire and appear to be posing for a photo. The setting includes a bar area with bottles and glasses visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [43.74, 43.74, 43.74, 43.74, 45.8, 45.8, 45.8, 45.8, 45.8, 44.8, 44.8], "power_watts_avg": 44.87, "power_watts_peak": 45.8, "energy_joules_est": 47.13, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-11T13:38:09.601450"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1056.707, "latencies_ms": [1056.707], "images_per_second": 0.946, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The men are wearing light-colored shirts and suits. The lighting is bright, likely from overhead fixtures. The chairs appear to be made of wood and fabric. The setting suggests an indoor event, possibly a meeting or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.8, 44.8, 44.8, 43.09, 43.09, 43.09, 43.09, 43.09, 44.28, 44.28, 44.28], "power_watts_avg": 43.88, "power_watts_peak": 44.8, "energy_joules_est": 46.38, "sample_count": 11, "duration_seconds": 1.057}, "timestamp": "2026-01-11T13:38:10.711316"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 697.186, "latencies_ms": [697.186], "images_per_second": 1.434, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A yellow traffic sign is mounted on a black pole at a city intersection, with cars and buses visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [44.28, 44.28, 39.55, 39.55, 39.55, 39.55, 39.55], "power_watts_avg": 40.9, "power_watts_peak": 44.28, "energy_joules_est": 28.54, "sample_count": 7, "duration_seconds": 0.698}, "timestamp": "2026-01-11T13:38:11.420374"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1133.334, "latencies_ms": [1133.334], "images_per_second": 0.882, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "pole: 1\nsign: 1\nbus: 1\ncar: 2\nstreet light: 1\nbuildings: 5\nbus stop: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 42.53, 42.53, 42.53, 48.29, 48.29, 48.29, 48.29, 48.29, 43.26, 43.26], "power_watts_avg": 45.05, "power_watts_peak": 48.29, "energy_joules_est": 51.09, "sample_count": 12, "duration_seconds": 1.134}, "timestamp": "2026-01-11T13:38:12.631605"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 889.368, "latencies_ms": [889.368], "images_per_second": 1.124, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The foreground features a damaged traffic signal pole, positioned near the center of the image. The background showcases a typical city street scene with buildings, parked cars, and traffic lights.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.26, 43.26, 43.26, 41.4, 41.4, 41.4, 41.4, 41.4, 42.47], "power_watts_avg": 42.14, "power_watts_peak": 43.26, "energy_joules_est": 37.49, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:38:13.540662"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1017.92, "latencies_ms": [1017.92], "images_per_second": 0.982, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a city street with buildings lining both sides. A yellow traffic sign is partially obscured by a damaged pole on the left side of the road. Several vehicles, including cars and a bus, are visible traveling down the street.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.47, 42.47, 42.47, 42.47, 45.0, 45.0, 45.0, 45.0, 43.8, 43.8, 43.8], "power_watts_avg": 43.75, "power_watts_peak": 45.0, "energy_joules_est": 44.55, "sample_count": 11, "duration_seconds": 1.018}, "timestamp": "2026-01-11T13:38:14.652329"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1189.604, "latencies_ms": [1189.604], "images_per_second": 0.841, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The street is paved with asphalt and appears wet, likely due to recent rain. The buildings lining the street are primarily brick and feature various storefronts.  The scene is illuminated by streetlights, giving the impression of an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.8, 43.8, 39.77, 39.77, 39.77, 39.77, 39.77, 42.35, 42.35, 42.35, 42.35, 42.35], "power_watts_avg": 41.52, "power_watts_peak": 43.8, "energy_joules_est": 49.4, "sample_count": 12, "duration_seconds": 1.19}, "timestamp": "2026-01-11T13:38:15.862461"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 657.348, "latencies_ms": [657.348], "images_per_second": 1.521, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A young man in a white shirt and cap is standing on a tennis court, holding a tennis racket and preparing to serve.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.5, "ram_available_mb": 109426.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.51, 36.51, 36.51, 36.51, 36.51, 43.65, 43.65], "power_watts_avg": 38.55, "power_watts_peak": 43.65, "energy_joules_est": 25.37, "sample_count": 7, "duration_seconds": 0.658}, "timestamp": "2026-01-11T13:38:16.574519"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1189.786, "latencies_ms": [1189.786], "images_per_second": 0.84, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 2\nFence: 2\nSign: 2\nPerson: 1\nGrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.5, "ram_available_mb": 109426.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 43.65, 53.02, 53.02, 53.02, 53.02, 53.02, 43.16, 43.16, 43.16, 43.16], "power_watts_avg": 47.39, "power_watts_peak": 53.02, "energy_joules_est": 56.41, "sample_count": 12, "duration_seconds": 1.19}, "timestamp": "2026-01-11T13:38:17.788444"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1050.768, "latencies_ms": [1050.768], "images_per_second": 0.952, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, facing the left side of the court. The tennis racket is held in his right hand, positioned in the foreground. The tennis court extends into the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.16, 35.03, 35.03, 35.03, 35.03, 35.03, 43.67, 43.67, 43.67, 43.67, 43.67], "power_watts_avg": 39.7, "power_watts_peak": 43.67, "energy_joules_est": 41.72, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-11T13:38:18.899426"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 958.395, "latencies_ms": [958.395], "images_per_second": 1.043, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A young man is playing tennis on a green court at night. He holds a tennis racket and appears to be preparing to hit a ball. The court is enclosed by a fence, and there are signs visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 42.49, 42.49, 42.49, 43.23, 43.23, 43.23, 43.23, 43.23], "power_watts_avg": 42.86, "power_watts_peak": 43.23, "energy_joules_est": 41.1, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-11T13:38:19.912409"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 976.947, "latencies_ms": [976.947], "images_per_second": 1.024, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The tennis court is green and appears to be well-lit by artificial lighting. The court's surface is smooth and appears to be made of a durable material. The overall scene suggests an outdoor tennis court at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.39, 43.39, 43.39, 43.39, 43.39, 43.35, 43.35, 43.35, 43.35, 43.35], "power_watts_avg": 43.37, "power_watts_peak": 43.39, "energy_joules_est": 42.39, "sample_count": 10, "duration_seconds": 0.977}, "timestamp": "2026-01-11T13:38:20.924470"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 889.03, "latencies_ms": [889.03], "images_per_second": 1.125, "prompt_tokens": 8, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Two skiers, one in a black jacket and the other in a white and gray outfit, greet each other with a high-five while standing near a blue fence on a snowy slope.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.39, 43.39, 43.39, 43.39, 43.39, 44.59, 44.59, 44.59, 44.59], "power_watts_avg": 43.93, "power_watts_peak": 44.59, "energy_joules_est": 39.07, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:38:21.838543"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1302.044, "latencies_ms": [1302.044], "images_per_second": 0.768, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "helmet: 2\ngloves: 2\nski poles: 4\nskis: 2\nsnow: 2\nbib: 1\ngoggles: 1\nbib: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.59, 44.21, 44.21, 44.21, 44.21, 44.21, 45.02, 45.02, 45.02, 45.02, 45.05, 45.05, 45.05], "power_watts_avg": 44.68, "power_watts_peak": 45.05, "energy_joules_est": 58.19, "sample_count": 13, "duration_seconds": 1.302}, "timestamp": "2026-01-11T13:38:23.150255"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 725.35, "latencies_ms": [725.35], "images_per_second": 1.379, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the skiers interacting between them. The skiers are located in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.05, 45.05, 42.78, 42.78, 42.78, 42.78, 42.78, 45.46], "power_watts_avg": 43.68, "power_watts_peak": 45.46, "energy_joules_est": 31.71, "sample_count": 8, "duration_seconds": 0.726}, "timestamp": "2026-01-11T13:38:23.960721"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 895.672, "latencies_ms": [895.672], "images_per_second": 1.116, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Two skiers are congratulating each other after completing a race. They are standing near a blue safety net on a snowy slope, surrounded by other skiers and ski equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [45.46, 45.46, 45.46, 45.46, 46.8, 46.8, 46.8, 46.8, 46.8], "power_watts_avg": 46.2, "power_watts_peak": 46.8, "energy_joules_est": 41.41, "sample_count": 9, "duration_seconds": 0.896}, "timestamp": "2026-01-11T13:38:24.871549"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1371.991, "latencies_ms": [1371.991], "images_per_second": 0.729, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The skiers are wearing bright, colorful gear that stands out against the snowy background. The lighting is bright enough to illuminate their faces and equipment clearly. The skiers are wearing helmets and goggles, indicating safety precautions. The snow appears well-groomed and relatively undisturbed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 43.82, 43.82, 44.54, 44.54, 44.54, 44.54, 44.54, 44.83, 44.83, 44.83, 44.83], "power_watts_avg": 44.37, "power_watts_peak": 44.83, "energy_joules_est": 60.89, "sample_count": 14, "duration_seconds": 1.373}, "timestamp": "2026-01-11T13:38:26.282233"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 641.783, "latencies_ms": [641.783], "images_per_second": 1.558, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A large blue semi-truck is driving down a wet residential street, passing parked cars and houses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.83, 34.86, 34.86, 34.86, 34.86, 34.86, 43.5], "power_watts_avg": 37.52, "power_watts_peak": 44.83, "energy_joules_est": 24.11, "sample_count": 7, "duration_seconds": 0.643}, "timestamp": "2026-01-11T13:38:26.992172"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1412.57, "latencies_ms": [1412.57], "images_per_second": 0.708, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "Truck: 1\nCar: 1\nBus: 1\nTrees: 2\nHouses: 2\nStreet: 2\nSidewalk: 2\nGrass: 2\nLamp post: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 43.5, 43.5, 52.78, 52.78, 52.78, 52.78, 52.78, 42.82, 42.82, 42.82, 42.82, 42.82, 33.64], "power_watts_avg": 45.71, "power_watts_peak": 52.78, "energy_joules_est": 64.57, "sample_count": 15, "duration_seconds": 1.413}, "timestamp": "2026-01-11T13:38:28.505675"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1087.555, "latencies_ms": [1087.555], "images_per_second": 0.919, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The main object, a blue truck, is positioned in the foreground of the image, moving down the street. The background features residential houses and parked cars, creating a residential setting. The truck is relatively close to the viewer, emphasizing its presence in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [33.64, 33.64, 33.64, 33.64, 42.13, 42.13, 42.13, 42.13, 42.13, 42.12, 42.12], "power_watts_avg": 39.04, "power_watts_peak": 42.13, "energy_joules_est": 42.48, "sample_count": 11, "duration_seconds": 1.088}, "timestamp": "2026-01-11T13:38:29.616039"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 940.597, "latencies_ms": [940.597], "images_per_second": 1.063, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A large blue semi-truck is driving down a wet residential street, passing parked cars and houses. The scene suggests a typical suburban or urban area with residential homes and businesses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [42.12, 42.12, 42.12, 43.35, 43.35, 43.35, 43.35, 43.35, 43.98, 43.98], "power_watts_avg": 43.11, "power_watts_peak": 43.98, "energy_joules_est": 40.56, "sample_count": 10, "duration_seconds": 0.941}, "timestamp": "2026-01-11T13:38:30.626907"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 891.74, "latencies_ms": [891.74], "images_per_second": 1.121, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The truck is primarily blue. The street appears wet, suggesting recent rain. The lighting is bright, likely due to daylight conditions. The truck's trailer is covered in gray material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.98, 43.98, 43.98, 43.41, 43.41, 43.41, 43.41, 43.41, 42.89], "power_watts_avg": 43.54, "power_watts_peak": 43.98, "energy_joules_est": 38.85, "sample_count": 9, "duration_seconds": 0.892}, "timestamp": "2026-01-11T13:38:31.537232"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 707.413, "latencies_ms": [707.413], "images_per_second": 1.414, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A large commercial airplane is approaching the runway, preparing for takeoff amidst a hazy sky and distant mountains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.89, 42.89, 42.89, 42.89, 44.87, 44.87, 44.87, 44.87], "power_watts_avg": 43.88, "power_watts_peak": 44.87, "energy_joules_est": 31.1, "sample_count": 8, "duration_seconds": 0.709}, "timestamp": "2026-01-11T13:38:32.349826"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 960.052, "latencies_ms": [960.052], "images_per_second": 1.042, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "airplane: 1\nrunway: 1\nlights: 4\nmountains: 1\ngrass: 1\nfog: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.3, 42.3, 42.3, 42.3, 42.3, 42.37, 42.37, 42.37, 42.37, 42.37], "power_watts_avg": 42.33, "power_watts_peak": 42.37, "energy_joules_est": 40.67, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-11T13:38:33.361096"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 916.964, "latencies_ms": [916.964], "images_per_second": 1.091, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The plane is positioned towards the center of the image, moving towards the viewer. The foreground features airport infrastructure, including poles and lights, while the background showcases a hazy landscape with mountains in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 43.78, 43.78, 43.44, 43.44, 43.44, 43.44, 43.44], "power_watts_avg": 43.61, "power_watts_peak": 43.78, "energy_joules_est": 40.02, "sample_count": 10, "duration_seconds": 0.918}, "timestamp": "2026-01-11T13:38:34.370986"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 811.748, "latencies_ms": [811.748], "images_per_second": 1.232, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A large passenger jet is approaching a runway, possibly taxiing. The scene is set in a mountainous area, with hazy skies and distant mountains visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 42.48, 42.48, 42.76, 42.76, 42.76, 42.76], "power_watts_avg": 42.6, "power_watts_peak": 42.76, "energy_joules_est": 34.61, "sample_count": 9, "duration_seconds": 0.812}, "timestamp": "2026-01-11T13:38:35.281222"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 901.91, "latencies_ms": [901.91], "images_per_second": 1.109, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The plane is primarily white and blue. The runway is wet, indicating recent rain or moisture. The scene is illuminated by several orange floodlights, enhancing visibility on the runway.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.4, "ram_available_mb": 109425.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.76, 43.49, 43.49, 43.49, 43.49, 43.49, 42.35, 42.35, 42.35], "power_watts_avg": 43.03, "power_watts_peak": 43.49, "energy_joules_est": 38.83, "sample_count": 9, "duration_seconds": 0.902}, "timestamp": "2026-01-11T13:38:36.192021"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 564.455, "latencies_ms": [564.455], "images_per_second": 1.772, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Two women are standing on a sandy beach, one holding a tennis racket high in the air, while the other looks on.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.35, 42.35, 47.3, 47.3, 47.3, 47.3], "power_watts_avg": 45.65, "power_watts_peak": 47.3, "energy_joules_est": 25.79, "sample_count": 6, "duration_seconds": 0.565}, "timestamp": "2026-01-11T13:38:36.802135"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1208.272, "latencies_ms": [1208.272], "images_per_second": 0.828, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "American flag: 1\nLife guard tower: 1\nTennis racket: 1\nTowel: 1\nWater bottle: 1\nPeople: 6\nTrees: 1\nMountains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [47.3, 38.82, 38.82, 38.82, 38.82, 38.82, 38.21, 38.21, 38.21, 38.21, 38.21, 37.98, 37.98], "power_watts_avg": 39.11, "power_watts_peak": 47.3, "energy_joules_est": 47.28, "sample_count": 13, "duration_seconds": 1.209}, "timestamp": "2026-01-11T13:38:38.116042"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 907.871, "latencies_ms": [907.871], "images_per_second": 1.101, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The woman on the left is positioned in the foreground, while the woman on the right is further back, near the lifeguard stand. The tennis racket is held high, suggesting the woman on the right is actively participating in the tennis game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.98, 37.98, 37.98, 37.16, 37.16, 37.16, 37.16, 37.16, 37.19, 37.19], "power_watts_avg": 37.41, "power_watts_peak": 37.98, "energy_joules_est": 33.99, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:38:39.126449"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 717.392, "latencies_ms": [717.392], "images_per_second": 1.394, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene takes place on a sandy beach with mountains in the background. Two young women are in the foreground, one holding a tennis racket and the other appearing to be in a heated exchange.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.3, "ram_available_mb": 109426.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.19, 37.19, 37.19, 36.78, 36.78, 36.78, 36.78, 36.78], "power_watts_avg": 36.93, "power_watts_peak": 37.19, "energy_joules_est": 26.52, "sample_count": 8, "duration_seconds": 0.718}, "timestamp": "2026-01-11T13:38:39.935559"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1108.463, "latencies_ms": [1108.463], "images_per_second": 0.902, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene is bathed in warm sunlight, creating a vibrant atmosphere. The colors are predominantly earthy tones, complementing the natural surroundings. The lighting is soft and diffused, enhancing the overall ambiance. The materials appear to be natural, consistent with the beach setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.63, 36.63, 36.63, 36.63, 36.63, 37.07, 37.07, 37.07, 37.07, 37.07, 37.16, 37.16], "power_watts_avg": 36.9, "power_watts_peak": 37.16, "energy_joules_est": 40.92, "sample_count": 12, "duration_seconds": 1.109}, "timestamp": "2026-01-11T13:38:41.148659"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 742.669, "latencies_ms": [742.669], "images_per_second": 1.346, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A male tennis player, dressed in blue and white, stands on a blue tennis court, holding a tennis racket and appearing contemplative.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.16, 37.16, 40.68, 40.68, 40.68, 40.68, 40.68, 42.44], "power_watts_avg": 40.02, "power_watts_peak": 42.44, "energy_joules_est": 29.73, "sample_count": 8, "duration_seconds": 0.743}, "timestamp": "2026-01-11T13:38:41.957038"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1491.643, "latencies_ms": [1491.643], "images_per_second": 0.67, "prompt_tokens": 21, "response_tokens_est": 48, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis shoes: 2\nTennis court: 1\nTennis player: 1\nTennis headband: 1\nTennis shorts: 1\nTennis socks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.44, 42.44, 42.44, 42.44, 45.47, 45.47, 45.47, 45.47, 45.47, 42.84, 42.84, 42.84, 42.84, 42.84, 34.13], "power_watts_avg": 43.03, "power_watts_peak": 45.47, "energy_joules_est": 64.2, "sample_count": 15, "duration_seconds": 1.492}, "timestamp": "2026-01-11T13:38:43.471269"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1082.585, "latencies_ms": [1082.585], "images_per_second": 0.924, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, facing the left side of the court. The tennis ball is held in his right hand, further away from the player. The tennis court extends into the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.13, 34.13, 34.13, 34.13, 43.81, 43.81, 43.81, 43.81, 43.81, 43.6, 43.6], "power_watts_avg": 40.25, "power_watts_peak": 43.81, "energy_joules_est": 43.59, "sample_count": 11, "duration_seconds": 1.083}, "timestamp": "2026-01-11T13:38:44.581182"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1255.043, "latencies_ms": [1255.043], "images_per_second": 0.797, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "A tennis player, dressed in blue and white, is seen on a blue tennis court, appearing somewhat dejected or contemplative. He holds a tennis racket in his right hand and looks down, possibly reflecting on his performance or strategizing for the next point.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 43.45, 43.45, 43.45, 43.45, 43.45, 43.66, 43.66, 43.66, 43.66, 43.66], "power_watts_avg": 43.57, "power_watts_peak": 43.66, "energy_joules_est": 54.69, "sample_count": 13, "duration_seconds": 1.255}, "timestamp": "2026-01-11T13:38:45.892733"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 987.306, "latencies_ms": [987.306], "images_per_second": 1.013, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The tennis court is painted a light blue color. The lighting in the image is bright and creates a strong contrast with the blue surface. The tennis racket appears to be made of metal and has a classic design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [33.32, 33.32, 33.32, 33.32, 33.32, 42.73, 42.73, 42.73, 42.73, 42.73], "power_watts_avg": 38.03, "power_watts_peak": 42.73, "energy_joules_est": 37.56, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-11T13:38:46.903000"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 658.484, "latencies_ms": [658.484], "images_per_second": 1.519, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A woman in a pink shirt and khaki shorts is standing in a kitchen, preparing food on a black stove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 43.02, 43.82, 43.82], "power_watts_avg": 43.25, "power_watts_peak": 43.82, "energy_joules_est": 28.51, "sample_count": 7, "duration_seconds": 0.659}, "timestamp": "2026-01-11T13:38:47.613036"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1645.679, "latencies_ms": [1645.679], "images_per_second": 0.608, "prompt_tokens": 21, "response_tokens_est": 54, "n_tiles": 1, "output_text": "oven: 4\npan: 1\nkettle: 1\ncup: 1\nsaucepan: 1\nwooden spoon: 1\nwooden spoon rest: 1\nwooden spoon: 1\nwooden spoon: 1\nwooden spoon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 53.2, 53.2, 53.2, 53.2, 53.2, 43.59, 43.59, 43.59, 43.59, 43.59, 34.07, 34.07, 34.07, 34.07], "power_watts_avg": 44.21, "power_watts_peak": 53.2, "energy_joules_est": 72.79, "sample_count": 17, "duration_seconds": 1.646}, "timestamp": "2026-01-11T13:38:49.327273"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1121.687, "latencies_ms": [1121.687], "images_per_second": 0.892, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The woman is positioned to the left of the stove, seemingly preparing food. The stove occupies the central foreground, extending from the left edge to the bottom right of the image. The kitchen area extends from the left side to the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.07, 32.69, 32.69, 32.69, 32.69, 32.69, 43.07, 43.07, 43.07, 43.07, 43.07, 44.36], "power_watts_avg": 38.1, "power_watts_peak": 44.36, "energy_joules_est": 42.76, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-11T13:38:50.538279"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.658, "latencies_ms": [933.658], "images_per_second": 1.071, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A woman is cooking on a large, black wood-burning stove in a kitchen. The stove is situated beneath a black metal hood, and there are various kitchen items and utensils scattered around.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13080.6, "ram_available_mb": 109425.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [44.36, 44.36, 44.36, 44.36, 42.68, 42.68, 42.68, 42.68, 42.68, 42.84], "power_watts_avg": 43.37, "power_watts_peak": 44.36, "energy_joules_est": 40.52, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:38:51.550150"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 852.842, "latencies_ms": [852.842], "images_per_second": 1.173, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The kitchen features a black wood-burning stove with exposed brick underneath. The walls are painted white, and the overall lighting is dim, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 42.84, 42.54, 42.54, 42.54, 42.54, 42.54, 42.61], "power_watts_avg": 42.65, "power_watts_peak": 42.84, "energy_joules_est": 36.39, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-11T13:38:52.461478"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 706.266, "latencies_ms": [706.266], "images_per_second": 1.416, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two giraffes stand tall and majestic in a zoo enclosure, surrounded by rocks and trees, with a tan building in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 42.61, 44.23, 44.23, 44.23, 44.23], "power_watts_avg": 43.42, "power_watts_peak": 44.23, "energy_joules_est": 30.69, "sample_count": 8, "duration_seconds": 0.707}, "timestamp": "2026-01-11T13:38:53.274438"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 999.493, "latencies_ms": [999.493], "images_per_second": 1.001, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "giraffe: 2\nbuilding: 1\nrocks: 10\ntrees: 5\ngrass: 2\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.23, 44.69, 44.69, 44.69, 44.69, 44.69, 43.46, 43.46, 43.46, 43.46], "power_watts_avg": 44.15, "power_watts_peak": 44.69, "energy_joules_est": 44.14, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:38:54.286489"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 824.418, "latencies_ms": [824.418], "images_per_second": 1.213, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a building in the background. The giraffes are situated in a somewhat open area with rocks and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.46, 45.27, 45.27, 45.27, 45.27, 45.27, 44.91, 44.91, 44.91], "power_watts_avg": 44.95, "power_watts_peak": 45.27, "energy_joules_est": 37.08, "sample_count": 9, "duration_seconds": 0.825}, "timestamp": "2026-01-11T13:38:55.198486"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 694.586, "latencies_ms": [694.586], "images_per_second": 1.44, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Two giraffes stand in a zoo enclosure, surrounded by rocks and trees. A tan building is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.91, 44.91, 49.68, 49.68, 49.68, 49.68, 49.68], "power_watts_avg": 48.32, "power_watts_peak": 49.68, "energy_joules_est": 33.59, "sample_count": 7, "duration_seconds": 0.695}, "timestamp": "2026-01-11T13:38:55.908545"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1359.217, "latencies_ms": [1359.217], "images_per_second": 0.736, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The giraffes exhibit a rich brown coloration with lighter spots. The lighting in the image appears to be natural, possibly from overcast skies, giving the scene a soft, diffused quality. The giraffes are standing on a rocky terrain, which adds texture and depth to the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.72, 43.72, 43.72, 43.72, 43.72, 49.93, 49.93, 49.93, 49.93, 49.93, 44.92, 44.92, 44.92, 44.92], "power_watts_avg": 46.28, "power_watts_peak": 49.93, "energy_joules_est": 62.92, "sample_count": 14, "duration_seconds": 1.36}, "timestamp": "2026-01-11T13:38:57.321574"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 672.079, "latencies_ms": [672.079], "images_per_second": 1.488, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young baseball player in a green and yellow uniform is swinging a bat, attempting to hit a baseball that is mid-air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.92, 32.57, 32.57, 32.57, 32.57, 32.57, 43.17], "power_watts_avg": 35.85, "power_watts_peak": 44.92, "energy_joules_est": 24.11, "sample_count": 7, "duration_seconds": 0.673}, "timestamp": "2026-01-11T13:38:58.034396"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1538.935, "latencies_ms": [1538.935], "images_per_second": 0.65, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball: 1\nbaseball glove: 1\nbaseball: 1\nbaseball field: 1\nbaseball diamond: 1\nbaseball field fence: 1\nbaseball: 1\nbaseball helmet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 43.17, 43.17, 54.66, 54.66, 54.66, 54.66, 54.66, 44.19, 44.19, 44.19, 44.19, 44.19, 34.37, 34.37], "power_watts_avg": 45.98, "power_watts_peak": 54.66, "energy_joules_est": 70.78, "sample_count": 16, "duration_seconds": 1.539}, "timestamp": "2026-01-11T13:38:59.649305"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1030.521, "latencies_ms": [1030.521], "images_per_second": 0.97, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the incoming baseball. The baseball is in the air, near the batter, suggesting the batter is moving towards the ball. The background features a chain-link fence, grass, and a parked vehicle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.37, 34.37, 41.39, 41.39, 41.39, 41.39, 41.39, 43.3, 43.3, 43.3, 43.3], "power_watts_avg": 40.81, "power_watts_peak": 43.3, "energy_joules_est": 42.08, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-11T13:39:00.762392"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 802.057, "latencies_ms": [802.057], "images_per_second": 1.247, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A young baseball player is swinging a bat at a ball during a game. The setting is a baseball field with a chain-link fence and grassy areas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 9.0}, "power_stats": {"power_watts_samples": [43.3, 37.35, 37.35, 37.35, 37.35, 37.35, 42.62, 42.62], "power_watts_avg": 39.41, "power_watts_peak": 43.3, "energy_joules_est": 31.63, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-11T13:39:01.572380"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 857.318, "latencies_ms": [857.318], "images_per_second": 1.166, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The batter is wearing a green and gold uniform. The lighting appears to be natural sunlight, creating a bright and clear atmosphere. The baseball bat is blue, and the ground is dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.62, 42.62, 42.62, 51.67, 51.67, 51.67, 51.67, 51.67, 44.14], "power_watts_avg": 47.82, "power_watts_peak": 51.67, "energy_joules_est": 41.02, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:39:02.484121"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 706.746, "latencies_ms": [706.746], "images_per_second": 1.415, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A vintage car is parked next to a red and white bus on a cobblestone street, with several people walking nearby.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [44.14, 44.14, 44.14, 44.14, 43.06, 43.06, 43.06, 43.06], "power_watts_avg": 43.6, "power_watts_peak": 44.14, "energy_joules_est": 30.84, "sample_count": 8, "duration_seconds": 0.707}, "timestamp": "2026-01-11T13:39:03.296255"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1181.126, "latencies_ms": [1181.126], "images_per_second": 0.847, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "car: 3\nmotorcycle: 4\nbus: 1\ntank: 1\nhistorical vehicle: 1\nhistorical building: 1\ntrees: 4\nflag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.06, 42.34, 42.34, 42.34, 42.34, 42.34, 42.4, 42.4, 42.4, 42.4, 42.4, 44.66], "power_watts_avg": 42.62, "power_watts_peak": 44.66, "energy_joules_est": 50.35, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-11T13:39:04.509642"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 861.109, "latencies_ms": [861.109], "images_per_second": 1.161, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The black vintage cars are positioned in the foreground, slightly to the left of the center. The cobblestone street extends into the background, separating the vehicles from the people and the buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [44.66, 44.66, 44.66, 44.66, 44.24, 44.24, 44.24, 44.24, 44.24], "power_watts_avg": 44.43, "power_watts_peak": 44.66, "energy_joules_est": 38.28, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:39:05.419295"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1161.106, "latencies_ms": [1161.106], "images_per_second": 0.861, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a vintage car show or gathering, featuring various antique vehicles parked on a cobblestone street. A red double-decker bus and several vintage cars are also present, alongside people admiring the vehicles and engaging in conversations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.13, 44.13, 44.13, 44.13, 44.13, 43.77, 43.77, 43.77, 43.77, 43.77, 43.54, 43.54], "power_watts_avg": 43.88, "power_watts_peak": 44.13, "energy_joules_est": 50.96, "sample_count": 12, "duration_seconds": 1.161}, "timestamp": "2026-01-11T13:39:06.631672"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 928.593, "latencies_ms": [928.593], "images_per_second": 1.077, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cobblestone street is illuminated by sunlight, creating a warm, inviting atmosphere.  The vehicles, including vintage cars and buses, are parked in a way that suggests a historical or exhibition setting.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 43.48, 43.48, 43.48, 43.48, 43.48, 43.46, 43.46], "power_watts_avg": 43.49, "power_watts_peak": 43.54, "energy_joules_est": 40.41, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-11T13:39:07.642451"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 693.278, "latencies_ms": [693.278], "images_per_second": 1.442, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "The setting sun casts a warm glow over the city street, illuminating the blurred lights and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 43.46, 42.65, 42.65, 42.65, 42.65], "power_watts_avg": 43.0, "power_watts_peak": 43.46, "energy_joules_est": 29.83, "sample_count": 7, "duration_seconds": 0.694}, "timestamp": "2026-01-11T13:39:08.351895"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1122.743, "latencies_ms": [1122.743], "images_per_second": 0.891, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Parking meter: 2\nSunset: 1\nBuildings: 2\nLights: 4\nCar: 1\nBus: 1\nStreet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 42.49, 42.49, 42.49, 45.85, 45.85, 45.85, 45.85, 45.85, 44.2, 44.2], "power_watts_avg": 44.18, "power_watts_peak": 45.85, "energy_joules_est": 49.61, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:39:09.565001"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 870.74, "latencies_ms": [870.74], "images_per_second": 1.148, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The parking meters are positioned in the foreground, slightly to the right of the viewer. The setting sun in the background creates a warm glow and soft light, enhancing the overall ambiance of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.2, 44.2, 44.2, 43.28, 43.28, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 43.59, "power_watts_peak": 44.2, "energy_joules_est": 37.97, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:39:10.476708"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 748.593, "latencies_ms": [748.593], "images_per_second": 1.336, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene is set at sunset, with two parking meters in the foreground. The sun is setting in the background, casting a warm glow over the urban landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 43.28, 43.28, 43.88, 43.88, 43.88, 43.88], "power_watts_avg": 43.58, "power_watts_peak": 43.88, "energy_joules_est": 32.63, "sample_count": 8, "duration_seconds": 0.749}, "timestamp": "2026-01-11T13:39:11.287765"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 934.841, "latencies_ms": [934.841], "images_per_second": 1.07, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The parking meters are dark brown or black. The lighting suggests it's either sunrise or sunset, creating a warm, golden glow. The scene appears to be outdoors, possibly on a street or in a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.88, 45.3, 45.3, 45.3, 45.3, 45.3, 43.45, 43.45, 43.45, 43.45], "power_watts_avg": 44.42, "power_watts_peak": 45.3, "energy_joules_est": 41.55, "sample_count": 10, "duration_seconds": 0.935}, "timestamp": "2026-01-11T13:39:12.299038"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 727.295, "latencies_ms": [727.295], "images_per_second": 1.375, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A couple stands next to a large brown suitcase with travel stickers, positioned in front of a Fidelity Investments building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.45, 42.27, 42.27, 42.27, 42.27, 42.27, 42.37, 42.37], "power_watts_avg": 42.44, "power_watts_peak": 43.45, "energy_joules_est": 30.89, "sample_count": 8, "duration_seconds": 0.728}, "timestamp": "2026-01-11T13:39:13.110834"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1155.631, "latencies_ms": [1155.631], "images_per_second": 0.865, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "suitcase: 1\nstatue: 1\nman: 2\nwoman: 2\nman: 1\nwoman: 1\nman: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.37, 42.37, 42.37, 50.95, 50.95, 50.95, 50.95, 50.95, 42.68, 42.68, 42.68, 42.68], "power_watts_avg": 46.04, "power_watts_peak": 50.95, "energy_joules_est": 53.24, "sample_count": 12, "duration_seconds": 1.156}, "timestamp": "2026-01-11T13:39:14.323471"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1053.394, "latencies_ms": [1053.394], "images_per_second": 0.949, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The large suitcase is positioned in the foreground, slightly to the left of the couple. The couple stands in the background, slightly to the right of the suitcase. The suitcase and couple are situated on a raised platform or plinth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.68, 33.62, 33.62, 33.62, 33.62, 33.62, 42.87, 42.87, 42.87, 42.87, 42.87], "power_watts_avg": 38.65, "power_watts_peak": 42.87, "energy_joules_est": 40.72, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-11T13:39:15.437478"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1152.652, "latencies_ms": [1152.652], "images_per_second": 0.868, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A large brown suitcase adorned with various travel stickers sits on a pedestal in a public area, possibly a plaza or square. A couple stands nearby, seemingly admiring the suitcase and possibly discussing its contents or significance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.0, 44.0, 44.0, 44.0, 44.0, 43.0, 43.0, 43.0, 43.0, 43.0, 42.96, 42.96], "power_watts_avg": 43.41, "power_watts_peak": 44.0, "energy_joules_est": 50.05, "sample_count": 12, "duration_seconds": 1.153}, "timestamp": "2026-01-11T13:39:16.648963"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1252.887, "latencies_ms": [1252.887], "images_per_second": 0.798, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The suitcase is brown and adorned with various stickers, showcasing a mix of colors. The lighting in the image is bright, highlighting the details of the suitcase and the stickers. The suitcase appears to be made of leather or a similar material. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 42.96, 42.03, 42.03, 42.03, 42.03, 43.01, 43.01, 43.01, 43.01, 43.01, 35.55], "power_watts_avg": 42.12, "power_watts_peak": 43.01, "energy_joules_est": 52.8, "sample_count": 13, "duration_seconds": 1.253}, "timestamp": "2026-01-11T13:39:17.961605"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 971.036, "latencies_ms": [971.036], "images_per_second": 1.03, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The dish features a medley of grilled chicken, saut\u00e9ed mushrooms, and fresh broccoli, all topped with herbs and spices, creating a visually appealing and flavorful meal.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.55, 35.55, 35.55, 35.55, 42.67, 42.67, 42.67, 42.67, 42.67, 42.53], "power_watts_avg": 39.81, "power_watts_peak": 42.67, "energy_joules_est": 38.68, "sample_count": 10, "duration_seconds": 0.972}, "timestamp": "2026-01-11T13:39:18.974898"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1146.741, "latencies_ms": [1146.741], "images_per_second": 0.872, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Mushrooms: 8\nBroccoli: 2\nChicken: 2\nParsley: 2\nBlack pepper: 2\nWhite wine: 1\nWhite sauce: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 42.53, 42.53, 43.27, 43.27, 43.27, 43.27, 43.27, 43.78, 43.78, 43.78], "power_watts_avg": 43.15, "power_watts_peak": 43.78, "energy_joules_est": 49.49, "sample_count": 12, "duration_seconds": 1.147}, "timestamp": "2026-01-11T13:39:20.187439"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 781.307, "latencies_ms": [781.307], "images_per_second": 1.28, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the mushrooms and broccoli slightly behind and to the right. The mushrooms are placed closer to the viewer, while the broccoli is further in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 40.76, 40.76, 40.76, 40.76, 40.76, 43.29], "power_watts_avg": 41.83, "power_watts_peak": 43.78, "energy_joules_est": 32.7, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-11T13:39:20.996718"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1106.271, "latencies_ms": [1106.271], "images_per_second": 0.904, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene features a plate of grilled fish with mushrooms and broccoli, garnished with fresh parsley. The dish is presented on a dark surface, possibly a table or countertop, enhancing the visual appeal of the meal.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.29, 43.29, 43.29, 43.29, 47.17, 47.17, 47.17, 47.17, 47.17, 43.76, 43.76], "power_watts_avg": 45.14, "power_watts_peak": 47.17, "energy_joules_est": 49.95, "sample_count": 11, "duration_seconds": 1.107}, "timestamp": "2026-01-11T13:39:22.108728"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1448.492, "latencies_ms": [1448.492], "images_per_second": 0.69, "prompt_tokens": 18, "response_tokens_est": 70, "n_tiles": 1, "output_text": "The dish features a mix of vibrant colors, including green broccoli, white fish, and brown mushrooms. The lighting is warm and inviting, enhancing the visual appeal of the meal. The fish appears to be seasoned with herbs and spices, and the mushrooms are saut\u00e9ed alongside the fish. The overall presentation suggests a carefully prepared and appetizing dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 44.01, 44.01, 44.01, 44.01, 44.01, 44.09, 44.09, 44.09, 44.09, 44.09, 33.84, 33.84], "power_watts_avg": 42.63, "power_watts_peak": 44.09, "energy_joules_est": 61.77, "sample_count": 15, "duration_seconds": 1.449}, "timestamp": "2026-01-11T13:39:23.623542"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 583.668, "latencies_ms": [583.668], "images_per_second": 1.713, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A wooden crate brimming with fresh, vibrant vegetables is displayed, showcasing an abundance of colorful produce.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [33.84, 33.84, 33.84, 37.43, 37.43, 37.43], "power_watts_avg": 35.64, "power_watts_peak": 37.43, "energy_joules_est": 20.82, "sample_count": 6, "duration_seconds": 0.584}, "timestamp": "2026-01-11T13:39:24.232461"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1036.384, "latencies_ms": [1036.384], "images_per_second": 0.965, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "carrots: 10\nbroccoli: 2\ncabbage: 1\nlettuce: 1\nasparagus: 1\nonions: 4\nspinach: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.43, 37.43, 41.86, 41.86, 41.86, 41.86, 41.86, 38.47, 38.47, 38.47, 38.47], "power_watts_avg": 39.82, "power_watts_peak": 41.86, "energy_joules_est": 41.29, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-11T13:39:25.342722"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 806.518, "latencies_ms": [806.518], "images_per_second": 1.24, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The carrots are positioned in the foreground, slightly to the right of the image. The broccoli and cabbage are placed in the background, extending towards the left side of the image. The arrangement creates a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.47, 32.69, 32.69, 32.69, 32.69, 32.69, 37.7, 37.7, 37.7], "power_watts_avg": 35.0, "power_watts_peak": 38.47, "energy_joules_est": 28.24, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-11T13:39:26.250451"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1190.214, "latencies_ms": [1190.214], "images_per_second": 0.84, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a vibrant display of fresh produce at a market or grocery store. The produce includes carrots, leafy greens, and cabbage, arranged in baskets and crates. The setting suggests a bustling marketplace where customers can browse and purchase fresh, healthy items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.7, 37.7, 41.28, 41.28, 41.28, 41.28, 36.71, 36.71, 36.71, 36.71, 36.71, 35.25], "power_watts_avg": 38.28, "power_watts_peak": 41.28, "energy_joules_est": 45.58, "sample_count": 12, "duration_seconds": 1.191}, "timestamp": "2026-01-11T13:39:27.463407"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 881.02, "latencies_ms": [881.02], "images_per_second": 1.135, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The carrots are bright orange and appear to be freshly picked. The produce is arranged in baskets with natural light illuminating the scene. The vegetables are displayed in baskets and crates, suggesting they are for sale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [35.25, 35.25, 35.25, 35.25, 38.66, 38.66, 38.66, 38.66, 38.66], "power_watts_avg": 37.14, "power_watts_peak": 38.66, "energy_joules_est": 32.74, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-11T13:39:28.373893"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 577.719, "latencies_ms": [577.719], "images_per_second": 1.731, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A conveyor belt is transporting freshly made glazed doughnuts through a bustling bakery shop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.5, 38.5, 38.5, 38.5, 38.5, 37.89], "power_watts_avg": 38.4, "power_watts_peak": 38.5, "energy_joules_est": 22.21, "sample_count": 6, "duration_seconds": 0.578}, "timestamp": "2026-01-11T13:39:28.982666"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1232.161, "latencies_ms": [1232.161], "images_per_second": 0.812, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "donuts: 10\nconveyor belt: 10\noven: 10\ntray: 10\nsafety sign: 2\nhot box: 1\nconveyor belt: 5\npeople: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.89, 37.89, 37.89, 37.89, 42.37, 42.37, 42.37, 42.37, 42.37, 38.06, 38.06, 38.06, 38.06], "power_watts_avg": 39.66, "power_watts_peak": 42.37, "energy_joules_est": 48.9, "sample_count": 13, "duration_seconds": 1.233}, "timestamp": "2026-01-11T13:39:30.296211"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 850.687, "latencies_ms": [850.687], "images_per_second": 1.176, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the conveyor belt and doughnut-making equipment extending towards the background. The doughnuts are moving along the conveyor belt, illustrating the process of production.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.06, 34.29, 34.29, 34.29, 34.29, 34.29, 37.01, 37.01, 37.01], "power_watts_avg": 35.61, "power_watts_peak": 38.06, "energy_joules_est": 30.31, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-11T13:39:31.207045"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 919.477, "latencies_ms": [919.477], "images_per_second": 1.088, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene depicts a busy bakery or doughnut factory where freshly made doughnuts are being prepared and transported on conveyor belts. Workers can be seen attending to tasks and customers throughout the process.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.01, 37.01, 40.28, 40.28, 40.28, 40.28, 40.28, 37.62, 37.62, 37.62], "power_watts_avg": 38.83, "power_watts_peak": 40.28, "energy_joules_est": 35.72, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-11T13:39:32.218919"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1441.793, "latencies_ms": [1441.793], "images_per_second": 0.694, "prompt_tokens": 18, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The donuts on the conveyor belt are golden-brown, indicating they are freshly baked. The lighting in the bakery is bright, illuminating the donuts and creating an inviting atmosphere. The donuts appear to be made of a light-colored dough, possibly glazed or frosted. The overall scene suggests a bustling bakery environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.62, 37.62, 36.76, 36.76, 36.76, 36.76, 36.76, 36.26, 36.26, 36.26, 36.26, 36.26, 33.11, 33.11, 33.11], "power_watts_avg": 35.98, "power_watts_peak": 37.62, "energy_joules_est": 51.9, "sample_count": 15, "duration_seconds": 1.442}, "timestamp": "2026-01-11T13:39:33.729864"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 719.523, "latencies_ms": [719.523], "images_per_second": 1.39, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man in green is preparing to throw an orange frisbee in a wooded area, surrounded by tall trees and fallen leaves.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 24.0}, "power_stats": {"power_watts_samples": [33.11, 33.11, 37.87, 37.87, 37.87, 37.87, 37.87, 42.38], "power_watts_avg": 37.25, "power_watts_peak": 42.38, "energy_joules_est": 26.83, "sample_count": 8, "duration_seconds": 0.72}, "timestamp": "2026-01-11T13:39:34.541883"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1212.516, "latencies_ms": [1212.516], "images_per_second": 0.825, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "tree: 1\nthrowing disc: 1\nperson: 1\nfrisbee: 1\nground: 1\nleaves: 1\nbranches: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 47.1, 47.1, 47.1, 47.1, 47.1, 42.24, 42.24, 42.24, 42.24], "power_watts_avg": 44.15, "power_watts_peak": 47.1, "energy_joules_est": 53.56, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-11T13:39:35.853921"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 898.799, "latencies_ms": [898.799], "images_per_second": 1.113, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The man is positioned near the center of the image, slightly to the right of the fallen tree trunk. The ground is mostly covered in fallen leaves and twigs, creating a natural, wooded setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [31.93, 31.93, 31.93, 31.93, 31.93, 42.56, 42.56, 42.56, 42.56], "power_watts_avg": 36.66, "power_watts_peak": 42.56, "energy_joules_est": 32.96, "sample_count": 9, "duration_seconds": 0.899}, "timestamp": "2026-01-11T13:39:36.761238"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1018.836, "latencies_ms": [1018.836], "images_per_second": 0.982, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A man is playing disc golf in a wooded area. He's positioned near a fallen tree, preparing to throw a disc. The setting appears to be a natural, wooded area with pine trees and leaf-covered ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.56, 47.7, 47.7, 47.7, 47.7, 47.7, 44.09, 44.09, 44.09, 44.09, 44.09], "power_watts_avg": 45.59, "power_watts_peak": 47.7, "energy_joules_est": 46.47, "sample_count": 11, "duration_seconds": 1.019}, "timestamp": "2026-01-11T13:39:37.871042"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1154.237, "latencies_ms": [1154.237], "images_per_second": 0.866, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene is bathed in natural daylight, creating a warm and inviting atmosphere. The ground is covered with fallen leaves, hinting at a recent rainfall or seasonal change. The presence of a fallen tree trunk adds a touch of rustic charm to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.89, 39.89, 39.89, 39.89, 39.89, 42.47, 42.47, 42.47, 42.47, 42.47, 43.99, 43.99], "power_watts_avg": 41.65, "power_watts_peak": 43.99, "energy_joules_est": 48.09, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:39:39.084847"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 683.952, "latencies_ms": [683.952], "images_per_second": 1.462, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The bathroom features a white sink, toilet, and shower with striped curtains, complemented by beige tiles on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.99, 43.99, 43.99, 42.95, 42.95, 42.95, 42.95], "power_watts_avg": 43.39, "power_watts_peak": 43.99, "energy_joules_est": 29.7, "sample_count": 7, "duration_seconds": 0.684}, "timestamp": "2026-01-11T13:39:39.794853"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1798.708, "latencies_ms": [1798.708], "images_per_second": 0.556, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "sink: 1\ntoilet: 1\nshower: 1\nbathroom mirror: 1\nshower curtain: 1\ntoilet paper holder: 1\nshampoo bottle: 1\ncleaning solution: 1\ntowel rack: 1\ndoor handle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.95, 44.95, 44.95, 44.95, 44.95, 44.95, 43.83, 43.83, 43.83, 43.83, 43.83, 42.9, 42.9, 42.9, 42.9, 42.9, 33.7, 33.7], "power_watts_avg": 42.71, "power_watts_peak": 44.95, "energy_joules_est": 76.84, "sample_count": 18, "duration_seconds": 1.799}, "timestamp": "2026-01-11T13:39:41.611815"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 802.334, "latencies_ms": [802.334], "images_per_second": 1.246, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The sink is located on the left side of the image, while the toilet is situated in the background. The bathroom is relatively narrow and positioned close to the shower and bathtub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [33.7, 33.7, 33.7, 43.19, 43.19, 43.19, 43.19, 43.19], "power_watts_avg": 39.63, "power_watts_peak": 43.19, "energy_joules_est": 31.82, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-11T13:39:42.420895"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1093.042, "latencies_ms": [1093.042], "images_per_second": 0.915, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bathroom features a white sink, toilet, and bathtub with striped shower curtains. The walls are painted a light yellow, and the floor is tiled in a beige color. Various cleaning supplies are scattered across the countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 43.5, 43.5, 43.5, 43.89, 43.89, 43.89, 43.89, 43.89, 43.84], "power_watts_avg": 43.71, "power_watts_peak": 43.89, "energy_joules_est": 47.79, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-11T13:39:43.530443"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 847.976, "latencies_ms": [847.976], "images_per_second": 1.179, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bathroom features a beige color scheme, illuminated by a light fixture. The floor is tiled in a light brown color. The shower curtain is striped in blue and green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13084.5, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [43.84, 43.84, 43.84, 43.84, 44.1, 44.1, 44.1, 44.1, 44.1], "power_watts_avg": 43.98, "power_watts_peak": 44.1, "energy_joules_est": 37.31, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-11T13:39:44.439381"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 804.99, "latencies_ms": [804.99], "images_per_second": 1.242, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A kitchen features a wooden island with a sink, silver faucet, and black countertop, accompanied by wooden cabinets, a dining table, and chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.5, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.5, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.97, 43.97, 43.97, 43.97, 43.97, 43.01, 43.01, 43.01, 43.01], "power_watts_avg": 43.54, "power_watts_peak": 43.97, "energy_joules_est": 35.08, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-11T13:39:45.350854"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1464.264, "latencies_ms": [1464.264], "images_per_second": 0.683, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "kitchen sink: 2\nwooden cabinets: 4\ncountertop: 2\nwooden island: 1\nfaucet: 1\nwindow: 2\ntable: 1\nchairs: 2\ntoaster: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.5, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13084.5, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.01, 41.19, 41.19, 41.19, 41.19, 41.19, 42.39, 42.39, 42.39, 42.39, 44.38, 44.38, 44.38, 44.38, 44.38], "power_watts_avg": 42.7, "power_watts_peak": 44.38, "energy_joules_est": 62.54, "sample_count": 15, "duration_seconds": 1.465}, "timestamp": "2026-01-11T13:39:46.865863"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1151.388, "latencies_ms": [1151.388], "images_per_second": 0.869, "prompt_tokens": 25, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The sink is located in the foreground, positioned between the left and central sides of the image. The wooden counter extends from the sink towards the background, occupying a significant portion of the foreground. The kitchen area extends beyond the counter and sink area, with chairs and a dining table visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.5, "ram_available_mb": 109421.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13084.4, "ram_available_mb": 109421.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [32.83, 32.83, 32.83, 32.83, 32.83, 43.04, 43.04, 43.04, 43.04, 43.04, 44.13, 44.13], "power_watts_avg": 38.97, "power_watts_peak": 44.13, "energy_joules_est": 44.9, "sample_count": 12, "duration_seconds": 1.152}, "timestamp": "2026-01-11T13:39:48.079412"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1174.181, "latencies_ms": [1174.181], "images_per_second": 0.852, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The kitchen features a modern design with light wood cabinetry, a dark countertop, and a large island with a sink and faucet. A dining area with wooden chairs and a table is visible in the background, adjacent to windows that offer natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.4, "ram_available_mb": 109421.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.4, "ram_available_mb": 109421.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.13, 44.13, 44.13, 43.17, 43.17, 43.17, 43.17, 43.17, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 43.43, "power_watts_peak": 44.13, "energy_joules_est": 51.01, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-11T13:39:49.290793"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1062.448, "latencies_ms": [1062.448], "images_per_second": 0.941, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The kitchen features a light wood countertop with a dark granite top. The lighting is bright, likely from overhead fixtures, creating a well-lit space. The materials appear to be natural wood and granite, contributing to the warm and inviting ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.4, "ram_available_mb": 109421.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.22, 35.84, 35.84, 35.84, 35.84, 35.84, 43.56, 43.56, 43.56, 43.56, 43.56], "power_watts_avg": 40.02, "power_watts_peak": 43.56, "energy_joules_est": 42.54, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:39:50.400914"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 617.574, "latencies_ms": [617.574], "images_per_second": 1.619, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A person is sleeping peacefully on a bed covered with a black comforter and white daisy patterns.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 42.86, 42.86, 42.86, 43.27, 43.27], "power_watts_avg": 42.98, "power_watts_peak": 43.27, "energy_joules_est": 26.56, "sample_count": 7, "duration_seconds": 0.618}, "timestamp": "2026-01-11T13:39:51.112028"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1180.053, "latencies_ms": [1180.053], "images_per_second": 0.847, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Bed: 2\nPillow: 1\nBlanket: 2\nBedspread: 2\nChild: 1\nNightstand: 1\nCord: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 43.27, 52.41, 52.41, 52.41, 52.41, 52.41, 42.79, 42.79, 42.79, 42.79], "power_watts_avg": 46.92, "power_watts_peak": 52.41, "energy_joules_est": 55.38, "sample_count": 12, "duration_seconds": 1.18}, "timestamp": "2026-01-11T13:39:52.323110"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 785.155, "latencies_ms": [785.155], "images_per_second": 1.274, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The child is lying in bed near the edge, partially covered by a blanket. The bed occupies the foreground, while the child's face is visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.79, 34.07, 34.07, 34.07, 34.07, 34.07, 44.05, 44.05], "power_watts_avg": 37.65, "power_watts_peak": 44.05, "energy_joules_est": 29.58, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:39:53.131925"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 804.526, "latencies_ms": [804.526], "images_per_second": 1.243, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young child is sleeping peacefully on a bed covered with a dark blanket adorned with white daisy patterns. The room is dimly lit, creating a cozy and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.05, 44.05, 44.05, 53.98, 53.98, 53.98, 53.98, 53.98, 44.16], "power_watts_avg": 49.58, "power_watts_peak": 53.98, "energy_joules_est": 39.91, "sample_count": 9, "duration_seconds": 0.805}, "timestamp": "2026-01-11T13:39:54.041269"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 798.158, "latencies_ms": [798.158], "images_per_second": 1.253, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The bedspread is dark blue with white daisy patterns. The lighting is dim, creating a moody atmosphere. The material appears to be soft and possibly cotton.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.16, 44.16, 44.16, 44.16, 43.63, 43.63, 43.63, 43.63], "power_watts_avg": 43.89, "power_watts_peak": 44.16, "energy_joules_est": 35.07, "sample_count": 8, "duration_seconds": 0.799}, "timestamp": "2026-01-11T13:39:54.853724"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 762.763, "latencies_ms": [762.763], "images_per_second": 1.311, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young skateboarder in white shoes and gray shorts is captured mid-trick on a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.63, 42.31, 42.31, 42.31, 42.31, 44.08, 44.08, 44.08], "power_watts_avg": 43.14, "power_watts_peak": 44.08, "energy_joules_est": 32.93, "sample_count": 8, "duration_seconds": 0.763}, "timestamp": "2026-01-11T13:39:55.665081"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1229.059, "latencies_ms": [1229.059], "images_per_second": 0.814, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "shoe: 1\nskateboard: 1\nskater: 1\nshorts: 1\nsocks: 1\nbuilding: 1\ntrees: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.08, 44.08, 51.77, 51.77, 51.77, 51.77, 51.77, 43.66, 43.66, 43.66, 43.66, 43.66, 35.71], "power_watts_avg": 46.23, "power_watts_peak": 51.77, "energy_joules_est": 56.84, "sample_count": 13, "duration_seconds": 1.23}, "timestamp": "2026-01-11T13:39:56.979828"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1174.834, "latencies_ms": [1174.834], "images_per_second": 0.851, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, moving towards the left side of the image. The background features buildings and a clear sky, suggesting an urban setting. The skateboarder's shadow is cast on the ground, indicating a relatively bright and sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.71, 35.71, 35.71, 35.71, 42.52, 42.52, 42.52, 42.52, 42.52, 42.55, 42.55, 42.55], "power_watts_avg": 40.26, "power_watts_peak": 42.55, "energy_joules_est": 47.32, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-11T13:39:58.192943"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 958.285, "latencies_ms": [958.285], "images_per_second": 1.044, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene depicts a skateboarder performing a trick on a concrete ramp in a skate park. Another person, possibly a skateboarder or spectator, is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.55, 42.55, 40.29, 40.29, 40.29, 40.29, 40.29, 43.39, 43.39, 43.39], "power_watts_avg": 41.67, "power_watts_peak": 43.39, "energy_joules_est": 39.96, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-11T13:39:59.205032"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 785.175, "latencies_ms": [785.175], "images_per_second": 1.274, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The skateboarder is wearing light-colored shoes. The lighting is bright, likely from natural sunlight, creating a clear contrast against the black and white image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.39, 43.39, 43.4, 43.4, 43.4, 43.4, 43.4, 43.53], "power_watts_avg": 43.41, "power_watts_peak": 43.53, "energy_joules_est": 34.1, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:40:00.013313"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 965.108, "latencies_ms": [965.108], "images_per_second": 1.036, "prompt_tokens": 8, "response_tokens_est": 48, "n_tiles": 1, "output_text": "A man is lying on the floor surrounded by various objects, including a laptop displaying a plant, a camera, a book, a tennis racket, a cell phone, a water bottle, a calendar, a camera lens, and a bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 43.53, 43.53, 47.23, 47.23, 47.23, 47.23, 47.23, 44.27], "power_watts_avg": 45.46, "power_watts_peak": 47.23, "energy_joules_est": 43.89, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-11T13:40:01.025176"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1389.186, "latencies_ms": [1389.186], "images_per_second": 0.72, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "laptop: 2\ncamera: 2\ncell phone: 1\nwater bottle: 1\nracket: 1\nkey: 1\ncalendar: 2\nbook: 1\ntennis racket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.27, 44.27, 44.27, 44.27, 43.8, 43.8, 43.8, 43.8, 43.8, 43.81, 43.81, 43.81, 43.81, 43.81], "power_watts_avg": 43.94, "power_watts_peak": 44.27, "energy_joules_est": 61.06, "sample_count": 14, "duration_seconds": 1.39}, "timestamp": "2026-01-11T13:40:02.439238"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1509.391, "latencies_ms": [1509.391], "images_per_second": 0.663, "prompt_tokens": 25, "response_tokens_est": 84, "n_tiles": 1, "output_text": "The man is positioned on the left side of the image, lying down with his head resting on the ground. The objects surrounding him are placed at various distances, creating a sense of depth and perspective. The foreground includes a tennis racket, a cell phone, a camera, a book, a laptop, a bag, and a calendar. The background features the man and the objects, creating a sense of proximity and interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 34.18, 34.18, 34.18, 44.2, 44.2, 44.2, 44.2, 44.2, 44.38, 44.38, 44.38, 44.38, 44.38], "power_watts_avg": 40.92, "power_watts_peak": 44.38, "energy_joules_est": 61.78, "sample_count": 15, "duration_seconds": 1.51}, "timestamp": "2026-01-11T13:40:03.953440"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1065.721, "latencies_ms": [1065.721], "images_per_second": 0.938, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A man is lying on the floor surrounded by various items, including a laptop displaying a plant, a camera, a cell phone, a tennis racket, a book titled \"The Men Who Built India,\" a calendar, a water bottle, and a bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.2, 34.2, 34.2, 34.2, 44.54, 44.54, 44.54, 44.54, 44.54, 44.47, 44.47], "power_watts_avg": 40.77, "power_watts_peak": 44.54, "energy_joules_est": 43.47, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-11T13:40:05.066927"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 852.338, "latencies_ms": [852.338], "images_per_second": 1.173, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene features a beige carpet with soft lighting, creating a warm and inviting atmosphere. The objects are primarily black, white, and red, giving the impression of a casual, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.47, 44.47, 44.47, 43.97, 43.97, 43.97, 43.97, 43.97, 43.76], "power_watts_avg": 44.11, "power_watts_peak": 44.47, "energy_joules_est": 37.62, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-11T13:40:05.978757"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 822.68, "latencies_ms": [822.68], "images_per_second": 1.216, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A black electric stovetop with four burners sits on a black countertop, accompanied by a spice rack, a utensil holder, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 43.76, 43.21, 43.21, 43.21, 43.21, 43.21], "power_watts_avg": 43.45, "power_watts_peak": 43.76, "energy_joules_est": 35.77, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-11T13:40:06.892304"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1388.536, "latencies_ms": [1388.536], "images_per_second": 0.72, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "spice rack: 5\noven: 4\ncountertop: 4\noven handle: 1\noven knob: 1\noven handle: 1\noven handle: 1\noven handle: 1\noven handle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.43, 42.43, 42.43, 42.43, 42.43, 42.9, 42.9, 42.9, 42.9, 42.9, 44.01, 44.01, 44.01, 44.01], "power_watts_avg": 43.05, "power_watts_peak": 44.01, "energy_joules_est": 59.79, "sample_count": 14, "duration_seconds": 1.389}, "timestamp": "2026-01-11T13:40:08.303443"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 777.856, "latencies_ms": [777.856], "images_per_second": 1.286, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The spice rack is positioned to the left of the stove, partially obscured by the countertop. The oven is situated in the background, further away from the spice rack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.01, 35.63, 35.63, 35.63, 35.63, 35.63, 44.14, 44.14], "power_watts_avg": 38.81, "power_watts_peak": 44.14, "energy_joules_est": 30.2, "sample_count": 8, "duration_seconds": 0.778}, "timestamp": "2026-01-11T13:40:09.113510"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 842.823, "latencies_ms": [842.823], "images_per_second": 1.186, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The scene depicts a modern kitchen with a black electric cooktop, a spice rack, and a decorative towel. The counter is clean and organized, ready for use.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.14, 44.14, 44.14, 53.52, 53.52, 53.52, 53.52, 53.52, 43.73], "power_watts_avg": 49.31, "power_watts_peak": 53.52, "energy_joules_est": 41.58, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:40:10.024232"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1105.62, "latencies_ms": [1105.62], "images_per_second": 0.904, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The kitchen features a marble backsplash in shades of yellow, gray, and white. The lighting is bright, likely from overhead fixtures, creating a warm and inviting atmosphere. The countertop appears to be made of dark material, possibly granite or laminate.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.73, 43.73, 43.28, 43.28, 43.28, 43.28, 43.28, 42.71, 42.71], "power_watts_avg": 43.34, "power_watts_peak": 43.73, "energy_joules_est": 47.95, "sample_count": 11, "duration_seconds": 1.106}, "timestamp": "2026-01-11T13:40:11.138508"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 842.151, "latencies_ms": [842.151], "images_per_second": 1.187, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young man is enjoying a plate of assorted donuts, including chocolate and glazed varieties, while sipping coffee in a cozy cafe setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.71, 42.71, 42.71, 43.42, 43.42, 43.42, 43.42, 43.42, 43.9], "power_watts_avg": 43.24, "power_watts_peak": 43.9, "energy_joules_est": 36.44, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:40:12.048057"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1645.093, "latencies_ms": [1645.093], "images_per_second": 0.608, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "Donut: 2\nChocolate glazed donut: 1\nChocolate frosted donut: 1\nChocolate sprinkles: 1\nCoffee cup: 1\nSoda: 1\nBrown paper bag: 1\nWooden chair: 1\nTable: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.9, 43.9, 43.9, 43.9, 43.71, 43.71, 43.71, 43.71, 43.71, 43.41, 43.41, 43.41, 43.41, 43.41, 34.3, 34.3, 34.3], "power_watts_avg": 42.01, "power_watts_peak": 43.9, "energy_joules_est": 69.12, "sample_count": 17, "duration_seconds": 1.645}, "timestamp": "2026-01-11T13:40:13.761649"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 890.369, "latencies_ms": [890.369], "images_per_second": 1.123, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The donuts are placed in the foreground of the image, with the person eating them in the background. The table and chairs are positioned in the background, suggesting the setting is a cafe or restaurant.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 20.0}, "power_stats": {"power_watts_samples": [34.3, 34.3, 37.01, 37.01, 37.01, 37.01, 42.94, 42.94, 42.94], "power_watts_avg": 38.38, "power_watts_peak": 42.94, "energy_joules_est": 34.19, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:40:14.672018"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1448.908, "latencies_ms": [1448.908], "images_per_second": 0.69, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The scene takes place in a brightly lit cafe or bakery, where a person is enjoying a selection of donuts on trays and plates. A man is seated at a table, partially visible in the frame, eating a donut. The atmosphere is casual and inviting, with various donuts and beverages available.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.94, 42.94, 49.11, 49.11, 49.11, 49.11, 49.11, 43.74, 43.74, 43.74, 43.74, 43.74, 35.61, 35.61, 35.61], "power_watts_avg": 43.8, "power_watts_peak": 49.11, "energy_joules_est": 63.47, "sample_count": 15, "duration_seconds": 1.449}, "timestamp": "2026-01-11T13:40:16.183649"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1007.82, "latencies_ms": [1007.82], "images_per_second": 0.992, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The donuts are primarily in shades of brown and dark chocolate. The lighting in the image is warm and slightly dim, creating a cozy atmosphere. The donuts appear to be made of dough and coated in chocolate glaze.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.61, 35.61, 40.56, 40.56, 40.56, 40.56, 40.56, 43.49, 43.49, 43.49, 43.49], "power_watts_avg": 40.73, "power_watts_peak": 43.49, "energy_joules_est": 41.06, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-11T13:40:17.295713"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 642.788, "latencies_ms": [642.788], "images_per_second": 1.556, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The bathroom features a unique sink design with two basins, one larger and one smaller, placed on a glass countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.49, 36.89, 36.89, 36.89, 36.89, 36.89, 42.65], "power_watts_avg": 38.66, "power_watts_peak": 43.49, "energy_joules_est": 24.87, "sample_count": 7, "duration_seconds": 0.643}, "timestamp": "2026-01-11T13:40:18.005985"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1162.346, "latencies_ms": [1162.346], "images_per_second": 0.86, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "sink: 2\ntoilet: 1\nbathroom: 2\nglass top: 1\ndecorative plate: 1\nshells: 1\nfloor tiles: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.65, 42.65, 42.65, 42.65, 51.95, 51.95, 51.95, 51.95, 51.95, 43.28, 43.28, 43.28], "power_watts_avg": 46.69, "power_watts_peak": 51.95, "energy_joules_est": 54.28, "sample_count": 12, "duration_seconds": 1.163}, "timestamp": "2026-01-11T13:40:19.218621"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 955.351, "latencies_ms": [955.351], "images_per_second": 1.047, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The sink and toilet are placed close together, while the decorative bowl and partially visible toilet are situated further back in the bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 39.78, 39.78, 39.78, 39.78, 39.78, 43.48, 43.48, 43.48], "power_watts_avg": 41.59, "power_watts_peak": 43.48, "energy_joules_est": 39.76, "sample_count": 10, "duration_seconds": 0.956}, "timestamp": "2026-01-11T13:40:20.228549"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 943.339, "latencies_ms": [943.339], "images_per_second": 1.06, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a bathroom with a modern design, featuring white sinks, a glass-topped counter, and a cow-print toilet seat. The bathroom is situated on a black and white checkered floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.89, 43.89, 43.89, 43.89, 43.89, 43.69, 43.69, 43.69], "power_watts_avg": 43.75, "power_watts_peak": 43.89, "energy_joules_est": 41.29, "sample_count": 10, "duration_seconds": 0.944}, "timestamp": "2026-01-11T13:40:21.237730"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 999.07, "latencies_ms": [999.07], "images_per_second": 1.001, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The bathroom features a predominantly white color scheme with black accents. The lighting is bright and evenly distributed, creating a clean and welcoming atmosphere. The sink is made of clear glass and appears to be functional and durable.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.93, 43.93, 43.93, 43.93, 43.93, 42.93, 42.93, 42.93], "power_watts_avg": 43.58, "power_watts_peak": 43.93, "energy_joules_est": 43.57, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:40:22.247934"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 841.529, "latencies_ms": [841.529], "images_per_second": 1.188, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Three stuffed animals are perched atop a weathered wooden cross, adorned with a white beaded rosary, situated in a grassy area near a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 43.12, 43.12, 43.12, 43.12, 43.12, 44.01, 44.01], "power_watts_avg": 43.27, "power_watts_peak": 44.01, "energy_joules_est": 36.44, "sample_count": 9, "duration_seconds": 0.842}, "timestamp": "2026-01-11T13:40:23.160921"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1120.454, "latencies_ms": [1120.454], "images_per_second": 0.892, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "cross: 3\nbears: 3\nstone: 1\nsign: 2\ngrass: 2\npath: 1\ntree: 1\nbush: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.01, 44.01, 44.01, 48.48, 48.48, 48.48, 48.48, 43.12, 43.12, 43.12, 43.12, 43.12], "power_watts_avg": 45.13, "power_watts_peak": 48.48, "energy_joules_est": 50.58, "sample_count": 12, "duration_seconds": 1.121}, "timestamp": "2026-01-11T13:40:24.373414"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 830.4, "latencies_ms": [830.4], "images_per_second": 1.204, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The stuffed animals are positioned prominently in the foreground, contrasting with the more distant background elements. The cross stands prominently in the background, partially obscured by the stuffed animals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.22, 35.22, 35.22, 35.22, 35.22, 42.54, 42.54, 42.54, 42.54], "power_watts_avg": 38.47, "power_watts_peak": 42.54, "energy_joules_est": 31.96, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-11T13:40:25.282681"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1053.05, "latencies_ms": [1053.05], "images_per_second": 0.95, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a grave with a wooden cross adorned with stuffed animals, symbolizing a memorial for Joseph Panis, a mystic and maluvant. The cross is situated in a grassy area surrounded by trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.54, 45.1, 45.1, 45.1, 45.1, 45.1, 43.0, 43.0, 43.0, 43.0, 43.0], "power_watts_avg": 43.91, "power_watts_peak": 45.1, "energy_joules_est": 46.27, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-11T13:40:26.394865"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1096.677, "latencies_ms": [1096.677], "images_per_second": 0.912, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The cross appears to be made of light brown or tan stone. The lighting in the image is soft and diffused, suggesting an overcast day. The materials appear to be natural stone, possibly a light-colored stone or concrete base for the cross.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 42.61, 42.61, 43.51, 43.51, 43.51, 43.51, 43.51, 43.48], "power_watts_avg": 43.1, "power_watts_peak": 43.51, "energy_joules_est": 47.29, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:40:27.504830"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 651.582, "latencies_ms": [651.582], "images_per_second": 1.535, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A large group of people are gathered in a spacious, modern restaurant, enjoying a meal and engaging in lively conversation.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.48, 43.48, 43.73, 43.73, 43.73], "power_watts_avg": 43.58, "power_watts_peak": 43.73, "energy_joules_est": 28.42, "sample_count": 7, "duration_seconds": 0.652}, "timestamp": "2026-01-11T13:40:28.216302"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1233.892, "latencies_ms": [1233.892], "images_per_second": 0.81, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "large clock: 8\nmetal beams: 8\nwooden chairs: 8\ncoffee shop: 8\nwooden counter: 8\npeople: 8\ntable: 8\nmenu: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 49.85, 49.85, 49.85, 49.85, 49.85, 43.44, 43.44, 43.44, 43.44, 43.44, 37.91], "power_watts_avg": 45.53, "power_watts_peak": 49.85, "energy_joules_est": 56.19, "sample_count": 13, "duration_seconds": 1.234}, "timestamp": "2026-01-11T13:40:29.527714"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1076.86, "latencies_ms": [1076.86], "images_per_second": 0.929, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The large clock dominates the background, positioned near the center and slightly to the right of the main seating area. The foreground features tables and chairs arranged around the clock, providing a space for patrons to sit and enjoy their meals.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [37.91, 37.91, 37.91, 37.91, 43.34, 43.34, 43.34, 43.34, 43.34, 42.84, 42.84], "power_watts_avg": 41.28, "power_watts_peak": 43.34, "energy_joules_est": 44.47, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-11T13:40:30.639490"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 973.902, "latencies_ms": [973.902], "images_per_second": 1.027, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a bustling restaurant with a large clock on the wall, offering a unique atmosphere for patrons. The restaurant is filled with people seated at tables, enjoying their meals and engaging in conversations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 42.84, 42.95, 42.95, 42.95, 42.95, 42.95, 43.39, 43.39], "power_watts_avg": 43.0, "power_watts_peak": 43.39, "energy_joules_est": 41.9, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-11T13:40:31.650733"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1100.303, "latencies_ms": [1100.303], "images_per_second": 0.909, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The interior of the caf\u00e9 is illuminated by warm lighting, creating a cozy atmosphere. The walls are painted in a light beige color, and the ceiling features exposed metal beams. The large clock on the wall adds a unique architectural element to the space.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.39, 43.39, 43.39, 43.03, 43.03, 43.03, 43.03, 43.03, 43.53, 43.53, 43.53], "power_watts_avg": 43.26, "power_watts_peak": 43.53, "energy_joules_est": 47.63, "sample_count": 11, "duration_seconds": 1.101}, "timestamp": "2026-01-11T13:40:32.760579"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 596.599, "latencies_ms": [596.599], "images_per_second": 1.676, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man and a child are enjoying a day of snowboarding down a snowy hill, surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 38.66, 38.66, 38.66, 38.66], "power_watts_avg": 40.28, "power_watts_peak": 43.53, "energy_joules_est": 24.04, "sample_count": 6, "duration_seconds": 0.597}, "timestamp": "2026-01-11T13:40:33.367858"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1366.613, "latencies_ms": [1366.613], "images_per_second": 0.732, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "snowboard: 2\nperson: 2\nsnow: 6\ntree: 4\nrocks: 2\nsnowboard: 2\nskis: 2\ngoggles: 1\nhat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.91, 43.91, 43.91, 43.91, 43.91, 51.54, 51.54, 51.54, 51.54, 51.54, 44.65, 44.65, 44.65, 44.65], "power_watts_avg": 46.85, "power_watts_peak": 51.54, "energy_joules_est": 64.05, "sample_count": 14, "duration_seconds": 1.367}, "timestamp": "2026-01-11T13:40:34.780340"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 736.728, "latencies_ms": [736.728], "images_per_second": 1.357, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the child on the left and the adult on the right. The background features the snowy slope and trees, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [44.65, 36.45, 36.45, 36.45, 36.45, 36.45, 43.93, 43.93], "power_watts_avg": 39.35, "power_watts_peak": 44.65, "energy_joules_est": 29.0, "sample_count": 8, "duration_seconds": 0.737}, "timestamp": "2026-01-11T13:40:35.589513"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 771.639, "latencies_ms": [771.639], "images_per_second": 1.296, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two people are snowboarding down a snowy slope in a wooded area. The scene is bright and sunny, with snow-covered trees and a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [43.93, 43.93, 43.93, 51.8, 51.8, 51.8, 51.8, 51.8], "power_watts_avg": 48.85, "power_watts_peak": 51.8, "energy_joules_est": 37.72, "sample_count": 8, "duration_seconds": 0.772}, "timestamp": "2026-01-11T13:40:36.398715"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 729.731, "latencies_ms": [729.731], "images_per_second": 1.37, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The snow is bright white, indicating good lighting conditions. The snow appears smooth and undisturbed, suggesting good weather conditions for skiing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.25, 43.25, 43.25, 43.25, 43.25, 43.63, 43.63, 43.63], "power_watts_avg": 43.39, "power_watts_peak": 43.63, "energy_joules_est": 31.69, "sample_count": 8, "duration_seconds": 0.73}, "timestamp": "2026-01-11T13:40:37.206182"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 698.517, "latencies_ms": [698.517], "images_per_second": 1.432, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A pair of feet wearing black flip-flops is standing on a wooden floor, accompanied by three old cell phones and a black flip-flop case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.63, 43.63, 47.32, 47.32, 47.32, 47.32, 47.32], "power_watts_avg": 46.27, "power_watts_peak": 47.32, "energy_joules_est": 32.34, "sample_count": 7, "duration_seconds": 0.699}, "timestamp": "2026-01-11T13:40:37.916370"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1566.323, "latencies_ms": [1566.323], "images_per_second": 0.638, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "Cell phone: 3\nFlip phone: 2\nCell phone cover: 1\nCell phone body: 1\nFlip phone: 1\nFlip phone screen: 1\nFlip phone buttons: 4\nFlip phone flip: 1\nFlip phone flip cover: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.49, 37.49, 37.49, 37.49, 37.49, 38.49, 38.49, 38.49, 38.49, 38.49, 38.57, 38.57, 38.57, 38.57, 38.57, 34.06], "power_watts_avg": 37.93, "power_watts_peak": 38.57, "energy_joules_est": 59.42, "sample_count": 16, "duration_seconds": 1.567}, "timestamp": "2026-01-11T13:40:39.531565"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 724.618, "latencies_ms": [724.618], "images_per_second": 1.38, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The person's feet are positioned in the foreground, partially obscuring the background. The flip-flops are placed near the center and slightly to the right of the feet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.06, 34.06, 34.06, 34.06, 38.08, 38.08, 38.08, 38.08], "power_watts_avg": 36.07, "power_watts_peak": 38.08, "energy_joules_est": 26.16, "sample_count": 8, "duration_seconds": 0.725}, "timestamp": "2026-01-11T13:40:40.339634"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1245.629, "latencies_ms": [1245.629], "images_per_second": 0.803, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The scene depicts a person's feet wearing flip-flops on a wooden floor. The floor shows signs of wear and tear, with scratches and scuff marks. Nearby on the floor are three cell phones: one open, revealing its internal components, and another closed, seemingly intact.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.08, 36.63, 36.63, 36.63, 36.63, 36.63, 37.15, 37.15, 37.15, 37.15, 37.15, 38.38, 38.38], "power_watts_avg": 37.21, "power_watts_peak": 38.38, "energy_joules_est": 46.36, "sample_count": 13, "duration_seconds": 1.246}, "timestamp": "2026-01-11T13:40:41.650415"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 970.658, "latencies_ms": [970.658], "images_per_second": 1.03, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The wooden floor is brown and appears worn. The lighting is soft and diffused, suggesting natural light. The cell phones are black and appear to be made of plastic or metal. The phone's internal components are visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [38.38, 38.38, 38.38, 37.02, 37.02, 37.02, 37.02, 37.02, 37.16, 37.16], "power_watts_avg": 37.46, "power_watts_peak": 38.38, "energy_joules_est": 36.38, "sample_count": 10, "duration_seconds": 0.971}, "timestamp": "2026-01-11T13:40:42.657322"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 802.564, "latencies_ms": [802.564], "images_per_second": 1.246, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The Palace of Westminster, home to the British Parliament, is illuminated by warm lights and stands majestically on the banks of the River Thames in London, with boats passing by in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [37.16, 37.16, 37.16, 38.0, 38.0, 38.0, 38.0, 38.0], "power_watts_avg": 37.69, "power_watts_peak": 38.0, "energy_joules_est": 30.27, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-11T13:40:43.468480"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 888.268, "latencies_ms": [888.268], "images_per_second": 1.126, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "building: 8\ntower: 1\nclock: 2\nflag: 1\nboat: 3\nwater: 4\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.23, 38.23, 38.23, 38.23, 38.58, 38.58, 38.58, 38.58, 38.58], "power_watts_avg": 38.42, "power_watts_peak": 38.58, "energy_joules_est": 34.14, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:40:44.376231"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 732.627, "latencies_ms": [732.627], "images_per_second": 1.365, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned close together, with the Palace of Westminster situated in the background. The foreground features boats on the river, while the background includes additional buildings and a clock tower.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.7, 38.7, 38.7, 38.7, 38.7, 38.49, 38.49, 38.49], "power_watts_avg": 38.62, "power_watts_peak": 38.7, "energy_joules_est": 28.32, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:40:45.186621"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 780.115, "latencies_ms": [780.115], "images_per_second": 1.282, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts the Palace of Westminster in London, illuminated against the evening sky. Boats are moored along the riverbank, and Big Ben is visible in the distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.49, 38.49, 41.53, 41.53, 41.53, 41.53, 41.53, 37.24], "power_watts_avg": 40.23, "power_watts_peak": 41.53, "energy_joules_est": 31.41, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:40:45.997581"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 833.037, "latencies_ms": [833.037], "images_per_second": 1.2, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The buildings are primarily illuminated in warm yellow light, creating a striking contrast against the muted, cloudy sky. The river reflects the soft light, giving the scene a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.24, 37.24, 37.24, 37.24, 37.7, 37.7, 37.7, 37.7, 37.7], "power_watts_avg": 37.49, "power_watts_peak": 37.7, "energy_joules_est": 31.25, "sample_count": 9, "duration_seconds": 0.834}, "timestamp": "2026-01-11T13:40:46.909560"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 806.739, "latencies_ms": [806.739], "images_per_second": 1.24, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The living room features a wooden floor, a ceiling fan, a green recliner, a gray couch, a coffee table, a television, and various decorative items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.41, 37.41, 37.41, 37.41, 37.41, 42.5, 42.5, 42.5, 42.5], "power_watts_avg": 39.67, "power_watts_peak": 42.5, "energy_joules_est": 32.03, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-11T13:40:47.822143"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1585.094, "latencies_ms": [1585.094], "images_per_second": 0.631, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "chair: 2\ncouch: 2\ntv: 1\nmirror: 1\ntelevision: 1\ncoffee table: 1\nshelving unit: 1\nplant: 2\nbicycle: 1\nceiling fan: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.5, "ram_available_mb": 109423.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.5, 41.64, 41.64, 41.64, 41.64, 41.64, 42.32, 42.32, 42.32, 42.32, 42.32, 44.35, 44.35, 44.35, 44.35, 44.35], "power_watts_avg": 42.75, "power_watts_peak": 44.35, "energy_joules_est": 67.79, "sample_count": 16, "duration_seconds": 1.586}, "timestamp": "2026-01-11T13:40:49.438178"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1214.757, "latencies_ms": [1214.757], "images_per_second": 0.823, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a large window providing natural light on the left side. The foreground features the living room furniture, while the background includes additional furniture and decor. The objects are situated in a manner that allows for easy movement and interaction within the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.5, "ram_available_mb": 109423.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.7, "ram_available_mb": 109423.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [34.13, 34.13, 34.13, 34.13, 34.13, 43.47, 43.47, 43.47, 43.47, 43.47, 43.56, 43.56, 43.56], "power_watts_avg": 39.9, "power_watts_peak": 43.56, "energy_joules_est": 48.49, "sample_count": 13, "duration_seconds": 1.215}, "timestamp": "2026-01-11T13:40:50.752816"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1316.159, "latencies_ms": [1316.159], "images_per_second": 0.76, "prompt_tokens": 19, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The living room features a wooden floor, a ceiling fan, and several windows that let in natural light. The room is furnished with a green recliner, a gray armchair, a coffee table, and a television set.  A bicycle, a potted plant, and various other items contribute to the room's cluttered appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 36.77, 36.77, 36.77, 36.77, 36.77, 42.34, 42.34, 42.34, 42.34, 42.34, 40.74, 40.74], "power_watts_avg": 40.3, "power_watts_peak": 43.56, "energy_joules_est": 53.05, "sample_count": 14, "duration_seconds": 1.316}, "timestamp": "2026-01-11T13:40:52.167518"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1197.903, "latencies_ms": [1197.903], "images_per_second": 0.835, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The room features a warm color scheme, with light-colored walls and wooden flooring. The lighting is natural and diffused, creating a cozy atmosphere. Various materials like wood, metal, and fabric are visible, contributing to the room's overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [40.74, 40.74, 40.74, 40.5, 40.5, 40.5, 40.5, 42.13, 42.13, 42.13, 42.13, 42.13], "power_watts_avg": 41.24, "power_watts_peak": 42.13, "energy_joules_est": 49.42, "sample_count": 12, "duration_seconds": 1.198}, "timestamp": "2026-01-11T13:40:53.379891"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 590.704, "latencies_ms": [590.704], "images_per_second": 1.693, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A red metal parking meter post with two attached parking meters stands on the sidewalk in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.58, 35.58, 35.58, 35.58, 35.58, 43.9], "power_watts_avg": 36.97, "power_watts_peak": 43.9, "energy_joules_est": 21.85, "sample_count": 6, "duration_seconds": 0.591}, "timestamp": "2026-01-11T13:40:53.988757"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1319.89, "latencies_ms": [1319.89], "images_per_second": 0.758, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Parking meter: 2\nBicycle rack: 1\nStreet sign: 1\nBuilding: 1\nBushes: 2\nSidewalk: 1\nStreet: 1\nCrack in pavement: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.9, 43.9, 43.9, 43.9, 54.66, 54.66, 54.66, 54.66, 54.66, 44.35, 44.35, 44.35, 44.35, 44.35], "power_watts_avg": 47.9, "power_watts_peak": 54.66, "energy_joules_est": 63.24, "sample_count": 14, "duration_seconds": 1.32}, "timestamp": "2026-01-11T13:40:55.400904"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1097.32, "latencies_ms": [1097.32], "images_per_second": 0.911, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The parking meters are positioned in the foreground, slightly to the left of the red post. The building in the background occupies the upper portion of the image, extending from the left edge to the center. The parking meters are located in the foreground, while the building is further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.47, 33.47, 33.47, 33.47, 33.47, 42.77, 42.77, 42.77, 42.77, 42.77, 43.38], "power_watts_avg": 38.6, "power_watts_peak": 43.38, "energy_joules_est": 42.37, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-11T13:40:56.510456"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 916.027, "latencies_ms": [916.027], "images_per_second": 1.092, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A red parking meter stands on a sidewalk in front of a brick building with a large advertisement celebrating 40 years of saving lives. The scene suggests a public space, possibly near a shopping center or commercial area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 43.38, 44.07, 44.07, 44.07, 44.07, 44.07, 44.06], "power_watts_avg": 43.79, "power_watts_peak": 44.07, "energy_joules_est": 40.12, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-11T13:40:57.519950"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 779.082, "latencies_ms": [779.082], "images_per_second": 1.284, "prompt_tokens": 18, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The parking meters are black and silver. The red metal post stands out against the brick sidewalk and street. The lighting suggests it's daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 44.06, 44.06, 42.6, 42.6, 42.6, 42.6], "power_watts_avg": 43.33, "power_watts_peak": 44.06, "energy_joules_est": 33.77, "sample_count": 8, "duration_seconds": 0.779}, "timestamp": "2026-01-11T13:40:58.327784"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 650.408, "latencies_ms": [650.408], "images_per_second": 1.537, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man and woman are sitting on a couch, playing a video game together while enjoying snacks and drinks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.6, 42.17, 42.17, 42.17, 42.17, 42.17, 42.96], "power_watts_avg": 42.34, "power_watts_peak": 42.96, "energy_joules_est": 27.57, "sample_count": 7, "duration_seconds": 0.651}, "timestamp": "2026-01-11T13:40:59.036617"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1754.031, "latencies_ms": [1754.031], "images_per_second": 0.57, "prompt_tokens": 21, "response_tokens_est": 59, "n_tiles": 1, "output_text": "television: 1\ncouch: 2\nman: 1\nwoman: 1\npotted poinsettia: 1\ncandles: 2\nsoda cans: 1\nsoda bottle: 1\nsoda glass: 1\nchips: 1\nsunglasses: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.96, 42.96, 42.96, 42.96, 52.74, 52.74, 52.74, 52.74, 52.74, 43.39, 43.39, 43.39, 43.39, 43.39, 34.17, 34.17, 34.17, 34.17], "power_watts_avg": 43.84, "power_watts_peak": 52.74, "energy_joules_est": 76.92, "sample_count": 18, "duration_seconds": 1.754}, "timestamp": "2026-01-11T13:41:00.848489"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 771.933, "latencies_ms": [771.933], "images_per_second": 1.295, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The television is positioned to the left of the couch, near the foreground. The man and woman are seated on the couch in the background, slightly further away.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 28.0}, "power_stats": {"power_watts_samples": [34.17, 33.49, 33.49, 33.49, 33.49, 33.49, 43.24, 43.24], "power_watts_avg": 36.02, "power_watts_peak": 43.24, "energy_joules_est": 27.82, "sample_count": 8, "duration_seconds": 0.772}, "timestamp": "2026-01-11T13:41:01.658199"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 955.343, "latencies_ms": [955.343], "images_per_second": 1.047, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A man and a woman are sitting on a couch in a living room, watching television together. They are surrounded by various items, including a poinsettia, snacks, drinks, and a lit candle, creating a cozy and relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 43.24, 53.7, 53.7, 53.7, 53.7, 53.7, 43.6, 43.6], "power_watts_avg": 48.54, "power_watts_peak": 53.7, "energy_joules_est": 46.38, "sample_count": 10, "duration_seconds": 0.956}, "timestamp": "2026-01-11T13:41:02.667912"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1023.819, "latencies_ms": [1023.819], "images_per_second": 0.977, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The room is lit with warm lighting, creating a cozy atmosphere. The walls are painted a light color, and the overall decor includes various colors and textures. The furniture includes a couch, a coffee table, and a television set.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 42.67, 42.67, 42.67, 42.67, 43.38, 43.38, 43.38, 43.38], "power_watts_avg": 43.18, "power_watts_peak": 43.6, "energy_joules_est": 44.22, "sample_count": 11, "duration_seconds": 1.024}, "timestamp": "2026-01-11T13:41:03.779872"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 624.033, "latencies_ms": [624.033], "images_per_second": 1.602, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A hand is holding a silver control panel with six circular buttons, likely for a modern toilet control system.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.38, 37.38, 37.38, 37.38, 37.38, 37.38, 42.38], "power_watts_avg": 38.95, "power_watts_peak": 43.38, "energy_joules_est": 24.33, "sample_count": 7, "duration_seconds": 0.625}, "timestamp": "2026-01-11T13:41:04.490099"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2020.859, "latencies_ms": [2020.859], "images_per_second": 0.495, "prompt_tokens": 21, "response_tokens_est": 63, "n_tiles": 1, "output_text": "toilet: 1\ntoilet seat: 1\ntoilet lid: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet seat cover: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet seat cover: 1\ntoilet seat cover: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.2, "ram_available_mb": 109423.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 49.85, 49.85, 49.85, 49.85, 49.85, 42.87, 42.87, 42.87, 42.87, 42.87, 34.2, 34.2, 34.2, 34.2, 34.2, 34.04, 34.04], "power_watts_avg": 41.53, "power_watts_peak": 49.85, "energy_joules_est": 83.94, "sample_count": 21, "duration_seconds": 2.021}, "timestamp": "2026-01-11T13:41:06.610272"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 824.41, "latencies_ms": [824.41], "images_per_second": 1.213, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, while the hand holding the control is slightly further in the background. The toilet and hand are relatively close together, suggesting an intimate setting.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13083.2, "ram_available_mb": 109423.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.04, 34.04, 34.04, 41.09, 41.09, 41.09, 41.09, 41.09, 41.73], "power_watts_avg": 38.81, "power_watts_peak": 41.73, "energy_joules_est": 32.04, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:41:07.571673"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 863.755, "latencies_ms": [863.755], "images_per_second": 1.158, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A person is holding a control panel with six buttons, likely for a toilet or bidet. The control panel is mounted on a stand and positioned next to a toilet lid.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [41.73, 41.73, 41.73, 44.11, 44.11, 44.11, 44.11, 44.11, 42.48], "power_watts_avg": 43.14, "power_watts_peak": 44.11, "energy_joules_est": 37.28, "sample_count": 9, "duration_seconds": 0.864}, "timestamp": "2026-01-11T13:41:08.482956"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1044.297, "latencies_ms": [1044.297], "images_per_second": 0.958, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The bathroom features a white color scheme, creating a clean and minimalist aesthetic. The lighting is soft and diffused, contributing to a calm atmosphere. The materials appear to be modern and sleek, enhancing the overall design of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 42.48, 43.46, 43.46, 43.46, 43.46, 43.46, 43.54, 43.54], "power_watts_avg": 43.12, "power_watts_peak": 43.54, "energy_joules_est": 45.05, "sample_count": 11, "duration_seconds": 1.045}, "timestamp": "2026-01-11T13:41:09.596768"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 706.907, "latencies_ms": [706.907], "images_per_second": 1.415, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two snowboarders are captured mid-air, performing a thrilling trick against a backdrop of snowy mountains and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 42.81, 42.81, 42.81, 42.81, 42.81], "power_watts_avg": 43.08, "power_watts_peak": 43.54, "energy_joules_est": 30.48, "sample_count": 8, "duration_seconds": 0.707}, "timestamp": "2026-01-11T13:41:10.407035"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1479.637, "latencies_ms": [1479.637], "images_per_second": 0.676, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Snowboard: 2\nSnowboarder: 2\nSnowboard: 1\nSnowboard ramp: 2\nSnowboard: 1\nSnowboarders: 2\nSpectators: 1\nSky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.59, 41.59, 41.59, 41.59, 41.59, 42.5, 42.5, 42.5, 42.5, 42.5, 43.76, 43.76, 43.76, 43.76, 43.76], "power_watts_avg": 42.62, "power_watts_peak": 43.76, "energy_joules_est": 63.07, "sample_count": 15, "duration_seconds": 1.48}, "timestamp": "2026-01-11T13:41:11.922860"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1152.571, "latencies_ms": [1152.571], "images_per_second": 0.868, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The snowboarder is positioned in the foreground, performing a trick near the camera. The spectators are located in the background, watching the snowboarders. The terrain is relatively flat and snowy, with snowboarders performing stunts and jumps.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.78, 33.78, 33.78, 33.78, 33.78, 43.58, 43.58, 43.58, 43.58, 43.58, 43.5, 43.5], "power_watts_avg": 39.48, "power_watts_peak": 43.58, "energy_joules_est": 45.52, "sample_count": 12, "duration_seconds": 1.153}, "timestamp": "2026-01-11T13:41:13.138079"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 995.979, "latencies_ms": [995.979], "images_per_second": 1.004, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Two snowboarders are performing aerial tricks on a snow-covered slope, drawing the attention of a crowd of spectators. The scene takes place outdoors on a sunny day, with snow-covered terrain and clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 43.5, 43.0, 43.0, 43.0, 43.0, 43.0, 42.8, 42.8], "power_watts_avg": 43.11, "power_watts_peak": 43.5, "energy_joules_est": 42.96, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-11T13:41:14.150331"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1393.748, "latencies_ms": [1393.748], "images_per_second": 0.717, "prompt_tokens": 18, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The snowboarders are wearing bright red jackets. The scene is brightly lit by the sun, creating a vibrant atmosphere. The snowboarders are performing tricks off a snow-covered ramp, which appears to be constructed from snow and possibly some type of artificial material. The overall scene conveys a sense of excitement and athleticism.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.8, 42.8, 42.8, 42.47, 42.47, 42.47, 42.47, 42.47, 43.48, 43.48, 43.48, 43.48, 43.48, 35.66], "power_watts_avg": 42.41, "power_watts_peak": 43.48, "energy_joules_est": 59.14, "sample_count": 14, "duration_seconds": 1.394}, "timestamp": "2026-01-11T13:41:15.565331"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 737.576, "latencies_ms": [737.576], "images_per_second": 1.356, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A wooden desk with a computer setup, a lamp, and a chair occupies a small corner of a room, accompanied by a potted plant and a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [35.66, 35.66, 35.66, 35.66, 43.43, 43.43, 43.43, 43.43], "power_watts_avg": 39.54, "power_watts_peak": 43.43, "energy_joules_est": 29.18, "sample_count": 8, "duration_seconds": 0.738}, "timestamp": "2026-01-11T13:41:16.377320"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1474.682, "latencies_ms": [1474.682], "images_per_second": 0.678, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "desk: 2\nlaptop: 1\nchair: 1\nlamp: 1\ncomputer monitor: 1\nkeyboard: 1\nmouse: 1\nplant: 1\nbookshelf: 1\ncouch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 42.28, 42.28, 42.28, 43.12, 43.12, 43.12, 43.12, 43.12, 44.43, 44.43, 44.43, 44.43, 44.43], "power_watts_avg": 43.28, "power_watts_peak": 44.43, "energy_joules_est": 63.84, "sample_count": 15, "duration_seconds": 1.475}, "timestamp": "2026-01-11T13:41:17.890924"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 989.495, "latencies_ms": [989.495], "images_per_second": 1.011, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main objects are positioned in a corner of the room, with the desk and chair placed near the corner of the room. The desk and chair are placed in the foreground, while the couch and bookshelf are located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.51, 33.51, 33.51, 33.51, 33.51, 43.13, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 38.32, "power_watts_peak": 43.13, "energy_joules_est": 37.94, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:41:18.903475"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1313.416, "latencies_ms": [1313.416], "images_per_second": 0.761, "prompt_tokens": 19, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene depicts a home office setup with a desk, computer equipment, a lamp, and a chair. A laptop, keyboard, and mouse are positioned on the desk, along with a laptop computer. A potted plant adds a touch of greenery to the space, and a white couch is partially visible in the corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 43.56, 43.56, 43.56, 43.51, 43.51, 43.51, 43.51, 43.51, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 43.46, "power_watts_peak": 43.56, "energy_joules_est": 57.1, "sample_count": 14, "duration_seconds": 1.314}, "timestamp": "2026-01-11T13:41:20.318794"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1059.873, "latencies_ms": [1059.873], "images_per_second": 0.944, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The room features a light wood desk with a black chair and a black lamp. The desk is illuminated by a warm lamp, creating a cozy atmosphere. The carpet is light-colored, complementing the overall neutral color scheme of the room.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.27, 33.63, 33.63, 33.63, 33.63, 33.63, 42.26, 42.26, 42.26, 42.26, 42.26], "power_watts_avg": 38.43, "power_watts_peak": 43.27, "energy_joules_est": 40.75, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-11T13:41:21.429602"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 649.832, "latencies_ms": [649.832], "images_per_second": 1.539, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "Two motorcyclists are riding down a dirt road surrounded by rolling hills and lush vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.13, 42.13, 42.13, 42.13, 42.13, 42.1, 42.1], "power_watts_avg": 42.12, "power_watts_peak": 42.13, "energy_joules_est": 27.39, "sample_count": 7, "duration_seconds": 0.65}, "timestamp": "2026-01-11T13:41:22.139612"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1084.962, "latencies_ms": [1084.962], "images_per_second": 0.922, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "motorcycle: 2\nperson: 1\nroad: 1\nhills: 4\ntrees: 2\nsky: 1\nclouds: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.1, 42.1, 42.1, 51.41, 51.41, 51.41, 51.41, 51.41, 43.11, 43.11, 43.11], "power_watts_avg": 46.6, "power_watts_peak": 51.41, "energy_joules_est": 50.61, "sample_count": 11, "duration_seconds": 1.086}, "timestamp": "2026-01-11T13:41:23.254118"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1150.498, "latencies_ms": [1150.498], "images_per_second": 0.869, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The main object is a motorcycle positioned in the middle of the dirt road, moving away from the viewer. The foreground features the rider's gloved hand, suggesting they are riding the motorcycle. The background showcases rolling hills and distant mountains, creating a sense of vastness and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 39.01, 39.01, 39.01, 39.01, 39.01, 43.45, 43.45, 43.45, 43.45, 43.45], "power_watts_avg": 41.54, "power_watts_peak": 43.45, "energy_joules_est": 47.8, "sample_count": 12, "duration_seconds": 1.151}, "timestamp": "2026-01-11T13:41:24.467111"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 859.397, "latencies_ms": [859.397], "images_per_second": 1.164, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two motorcyclists are riding on a dirt road that winds through a mountainous landscape. The sky is partly cloudy, and the surrounding terrain is covered in green vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [39.41, 39.41, 39.41, 39.41, 39.41, 43.09, 43.09, 43.09, 43.09], "power_watts_avg": 41.05, "power_watts_peak": 43.09, "energy_joules_est": 35.3, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-11T13:41:25.378689"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1003.747, "latencies_ms": [1003.747], "images_per_second": 0.996, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The sky is a bright blue with scattered white clouds. The lighting suggests it's likely daytime. The motorcycle appears to be made of metal and has a red seat. The overall scene conveys a sense of adventure and open space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.09, 42.09, 42.09, 42.09, 42.09, 42.94, 42.94, 42.94, 42.94, 42.94], "power_watts_avg": 42.52, "power_watts_peak": 42.94, "energy_joules_est": 42.7, "sample_count": 10, "duration_seconds": 1.004}, "timestamp": "2026-01-11T13:41:26.391490"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 512.433, "latencies_ms": [512.433], "images_per_second": 1.951, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A wooden dining table with a bowl of fresh fruit, including oranges and bananas, is situated in the center of the kitchen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.83, 43.83, 43.83, 43.83, 43.83, 38.71], "power_watts_avg": 42.98, "power_watts_peak": 43.83, "energy_joules_est": 22.04, "sample_count": 6, "duration_seconds": 0.513}, "timestamp": "2026-01-11T13:41:27.001254"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1422.854, "latencies_ms": [1422.854], "images_per_second": 0.703, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "oven: 1\nstove: 1\nrange hood: 1\ncabinets: 6\ncountertops: 2\nsink: 1\nfridge: 1\ntable: 1\nchairs: 2\nfruit bowl: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.71, 38.71, 38.71, 38.71, 42.07, 42.07, 42.07, 42.07, 42.07, 37.09, 37.09, 37.09, 37.09, 37.09, 33.73], "power_watts_avg": 38.96, "power_watts_peak": 42.07, "energy_joules_est": 55.44, "sample_count": 15, "duration_seconds": 1.423}, "timestamp": "2026-01-11T13:41:28.515973"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 620.929, "latencies_ms": [620.929], "images_per_second": 1.61, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The kitchen is positioned to the right of the dining table. The dining table occupies the foreground, while the kitchen counters and appliances are located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.73, 33.73, 33.73, 33.73, 37.25, 37.25, 37.25], "power_watts_avg": 35.24, "power_watts_peak": 37.25, "energy_joules_est": 21.9, "sample_count": 7, "duration_seconds": 0.621}, "timestamp": "2026-01-11T13:41:29.225858"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 761.147, "latencies_ms": [761.147], "images_per_second": 1.314, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The kitchen and dining area are well-lit and clean, creating a bright and welcoming atmosphere.  A bowl of fresh fruit sits on the dining table, ready to be enjoyed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.25, 37.25, 40.68, 40.68, 40.68, 40.68, 40.68, 37.27], "power_watts_avg": 39.4, "power_watts_peak": 40.68, "energy_joules_est": 30.01, "sample_count": 8, "duration_seconds": 0.762}, "timestamp": "2026-01-11T13:41:30.036117"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 829.379, "latencies_ms": [829.379], "images_per_second": 1.206, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The kitchen features light brown wooden cabinets, white appliances, and light beige walls. The lighting is bright and evenly distributed, creating a welcoming atmosphere. The kitchen also has a clean and organized appearance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.27, 37.27, 37.27, 37.27, 37.77, 37.77, 37.77, 37.77, 37.77], "power_watts_avg": 37.55, "power_watts_peak": 37.77, "energy_joules_est": 31.16, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-11T13:41:30.947578"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 788.972, "latencies_ms": [788.972], "images_per_second": 1.267, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A female tennis player, dressed in black and white, is poised to hit a yellow tennis ball with her racket on a blue tennis court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.73, 37.73, 37.73, 37.73, 37.73, 42.6, 42.6, 42.6], "power_watts_avg": 39.56, "power_watts_peak": 42.6, "energy_joules_est": 31.23, "sample_count": 8, "duration_seconds": 0.79}, "timestamp": "2026-01-11T13:41:31.759285"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1455.78, "latencies_ms": [1455.78], "images_per_second": 0.687, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Tennis ball: 1\nRacket: 1\nTennis skirt: 1\nTennis shoes: 2\nTennis visor: 1\nTennis court: 1\nTennis player: 1\nTennis ball: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 47.82, 47.82, 47.82, 47.82, 47.82, 44.0, 44.0, 44.0, 44.0, 44.0, 39.1, 39.1, 39.1], "power_watts_avg": 44.11, "power_watts_peak": 47.82, "energy_joules_est": 64.23, "sample_count": 15, "duration_seconds": 1.456}, "timestamp": "2026-01-11T13:41:33.273756"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1078.96, "latencies_ms": [1078.96], "images_per_second": 0.927, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, reaching up towards the tennis ball. The tennis court extends into the background, creating a sense of depth and space. The player's attire and the presence of a ball suggest they are actively engaged in a tennis match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.1, 37.45, 37.45, 37.45, 37.45, 37.45, 43.0, 43.0, 43.0, 43.0, 43.0], "power_watts_avg": 40.13, "power_watts_peak": 43.0, "energy_joules_est": 43.31, "sample_count": 11, "duration_seconds": 1.079}, "timestamp": "2026-01-11T13:41:34.387496"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 884.16, "latencies_ms": [884.16], "images_per_second": 1.131, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A female tennis player is serving a tennis ball on a green court. She is wearing a white top and black skirt and holds a tennis racket in her right hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.29, 40.29, 40.29, 40.29, 40.29, 43.62, 43.62, 43.62, 43.62], "power_watts_avg": 41.77, "power_watts_peak": 43.62, "energy_joules_est": 36.95, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-11T13:41:35.297851"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 803.959, "latencies_ms": [803.959], "images_per_second": 1.244, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The tennis court is green. The lighting appears to be bright, likely from overhead fixtures. The tennis racket is red and white. The weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.62, 46.53, 46.53, 46.53, 46.53, 46.53, 43.38, 43.38], "power_watts_avg": 45.38, "power_watts_peak": 46.53, "energy_joules_est": 36.51, "sample_count": 8, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:41:36.108321"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 530.698, "latencies_ms": [530.698], "images_per_second": 1.884, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A red fire hydrant with a white cap is situated on a sidewalk next to a yellow pedestrian crossing sign.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 46.71, 46.71, 46.71], "power_watts_avg": 45.05, "power_watts_peak": 46.71, "energy_joules_est": 23.93, "sample_count": 6, "duration_seconds": 0.531}, "timestamp": "2026-01-11T13:41:36.717721"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1195.231, "latencies_ms": [1195.231], "images_per_second": 0.837, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "fire hydrant: 1\ncrosswalk sign: 1\nstreet sign: 1\nchild crossing sign: 1\nperson walking: 1\nbuildings: 2\ntrees: 2\nsidewalk: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.71, 46.71, 42.2, 42.2, 42.2, 42.2, 42.2, 37.53, 37.53, 37.53, 37.53, 37.53], "power_watts_avg": 41.01, "power_watts_peak": 46.71, "energy_joules_est": 49.02, "sample_count": 12, "duration_seconds": 1.196}, "timestamp": "2026-01-11T13:41:37.927900"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1079.293, "latencies_ms": [1079.293], "images_per_second": 0.927, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The red fire hydrant is positioned in the foreground, slightly to the right of the viewer. The sidewalk extends into the background, separating the viewer from the street and buildings. A pedestrian crossing sign is visible near the fire hydrant, further emphasizing the urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.0, 34.0, 34.0, 34.0, 34.0, 38.4, 38.4, 38.4, 38.4, 38.4, 38.32], "power_watts_avg": 36.39, "power_watts_peak": 38.4, "energy_joules_est": 39.3, "sample_count": 11, "duration_seconds": 1.08}, "timestamp": "2026-01-11T13:41:39.039760"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 813.817, "latencies_ms": [813.817], "images_per_second": 1.229, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A red fire hydrant is situated on a sidewalk next to a tree. A pedestrian crossing sign is visible nearby, indicating a pedestrian crossing area. A person can be seen walking on the sidewalk in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [38.32, 38.32, 38.32, 38.32, 38.18, 38.18, 38.18, 38.18, 38.18], "power_watts_avg": 38.24, "power_watts_peak": 38.32, "energy_joules_est": 31.13, "sample_count": 9, "duration_seconds": 0.814}, "timestamp": "2026-01-11T13:41:39.950299"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 612.648, "latencies_ms": [612.648], "images_per_second": 1.632, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The fire hydrant is red and appears to be made of metal. The surrounding area is well-lit, suggesting sunny weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [37.75, 37.75, 37.75, 37.75, 37.75, 36.61, 36.61], "power_watts_avg": 37.42, "power_watts_peak": 37.75, "energy_joules_est": 22.95, "sample_count": 7, "duration_seconds": 0.613}, "timestamp": "2026-01-11T13:41:40.660087"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 730.807, "latencies_ms": [730.807], "images_per_second": 1.368, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A white toilet with a closed lid is situated in a small bathroom, accompanied by a white toilet brush, a green wastebasket, and a white toilet paper dispenser.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [36.61, 36.61, 36.61, 39.65, 39.65, 39.65, 39.65, 39.65], "power_watts_avg": 38.51, "power_watts_peak": 39.65, "energy_joules_est": 28.16, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:41:41.469269"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1725.389, "latencies_ms": [1725.389], "images_per_second": 0.58, "prompt_tokens": 21, "response_tokens_est": 55, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper dispenser: 1\ntoilet brush: 1\ntoilet seat: 1\ntoilet tank: 1\ntoilet lid: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet paper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.66, 36.66, 36.66, 36.66, 36.66, 37.23, 37.23, 37.23, 37.23, 37.23, 37.3, 37.3, 37.3, 37.3, 33.72, 33.72, 33.72, 33.72], "power_watts_avg": 36.3, "power_watts_peak": 37.3, "energy_joules_est": 62.66, "sample_count": 18, "duration_seconds": 1.726}, "timestamp": "2026-01-11T13:41:43.284599"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 765.397, "latencies_ms": [765.397], "images_per_second": 1.307, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The toilet is positioned to the right of the paper towel dispenser. The toilet is situated further back in the bathroom, partially obscured by the paper towel dispenser.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.72, 35.25, 35.25, 35.25, 35.25, 35.25, 36.38, 36.38], "power_watts_avg": 35.34, "power_watts_peak": 36.38, "energy_joules_est": 27.06, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-11T13:41:44.090562"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 951.071, "latencies_ms": [951.071], "images_per_second": 1.051, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a small bathroom with a white toilet, toilet brush, toilet paper dispenser, and a small turquoise wastebasket. The toilet is positioned centrally in the image, and the overall setting appears clean and functional.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.38, 36.38, 36.38, 39.77, 39.77, 39.77, 39.77, 39.77, 38.14, 38.14], "power_watts_avg": 38.43, "power_watts_peak": 39.77, "energy_joules_est": 36.57, "sample_count": 10, "duration_seconds": 0.952}, "timestamp": "2026-01-11T13:41:45.099808"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 955.527, "latencies_ms": [955.527], "images_per_second": 1.047, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The toilet is white and appears to be made of plastic or ceramic. The lighting in the bathroom is soft and diffused, creating a calm atmosphere. The walls are painted a light color, and the floor is carpeted in a neutral tone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.14, 38.14, 38.14, 37.66, 37.66, 37.66, 37.66, 37.66, 37.7, 37.7], "power_watts_avg": 37.81, "power_watts_peak": 38.14, "energy_joules_est": 36.14, "sample_count": 10, "duration_seconds": 0.956}, "timestamp": "2026-01-11T13:41:46.110298"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 771.188, "latencies_ms": [771.188], "images_per_second": 1.297, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A lone skier in a bright red jacket and pants descends a snowy mountain, leaving a trail in the pristine white snow.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.7, 37.7, 37.7, 43.27, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 41.18, "power_watts_peak": 43.27, "energy_joules_est": 31.77, "sample_count": 8, "duration_seconds": 0.771}, "timestamp": "2026-01-11T13:41:46.919720"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1204.516, "latencies_ms": [1204.516], "images_per_second": 0.83, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "person: 1\nski: 1\nsnow: 2\nmountains: 1\nsky: 1\nclouds: 0\nhills: 1\ntracks: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 43.19, 43.19, 43.19, 43.29, 43.29, 43.29, 43.29, 43.29, 43.38, 43.38], "power_watts_avg": 43.27, "power_watts_peak": 43.38, "energy_joules_est": 52.13, "sample_count": 12, "duration_seconds": 1.205}, "timestamp": "2026-01-11T13:41:48.133172"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 783.951, "latencies_ms": [783.951], "images_per_second": 1.276, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, moving towards the left side of the image. The snow-covered mountain rises in the background, creating a sense of distance and scale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.1, "ram_available_mb": 109424.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.1, "ram_available_mb": 109424.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 43.97, 43.97, 43.97, 43.97, 43.97], "power_watts_avg": 43.75, "power_watts_peak": 43.97, "energy_joules_est": 34.31, "sample_count": 8, "duration_seconds": 0.784}, "timestamp": "2026-01-11T13:41:48.943596"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 923.847, "latencies_ms": [923.847], "images_per_second": 1.082, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A person is skiing down a snow-covered mountain, wearing bright red clothing and carrying ski poles. The mountain is covered in snow and has a distinct peak in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.1, "ram_available_mb": 109424.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13082.1, "ram_available_mb": 109424.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 43.82, 43.82, 43.04, 43.04, 43.04, 43.04, 43.04], "power_watts_avg": 43.43, "power_watts_peak": 43.82, "energy_joules_est": 40.14, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-11T13:41:49.954322"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1188.16, "latencies_ms": [1188.16], "images_per_second": 0.842, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The skier is wearing a bright red jacket. The lighting is bright and sunny, creating a clear contrast against the white snow. The materials appear to be typical skiing gear, including skis, poles, and backpacks. The weather is sunny and clear, ideal for skiing.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13082.1, "ram_available_mb": 109424.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.8, 42.8, 42.8, 42.8, 42.8, 42.76, 42.76, 42.76, 42.76, 42.76, 42.82, 42.82], "power_watts_avg": 42.79, "power_watts_peak": 42.82, "energy_joules_est": 50.86, "sample_count": 12, "duration_seconds": 1.189}, "timestamp": "2026-01-11T13:41:51.162845"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 858.223, "latencies_ms": [858.223], "images_per_second": 1.165, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A man wearing a red and white top and black pants is cross-country skiing through a snowy forest, skillfully maneuvering his poles and gliding over the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.92, 42.92, 42.92, 42.92, 42.92, 43.92], "power_watts_avg": 43.0, "power_watts_peak": 43.92, "energy_joules_est": 36.94, "sample_count": 9, "duration_seconds": 0.859}, "timestamp": "2026-01-11T13:41:52.074161"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1232.247, "latencies_ms": [1232.247], "images_per_second": 0.812, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "man: 2\nskis: 2\nsnow: 8\ntrees: 8\nsnow covered ground: 8\ngloves: 2\nhat: 1\nbib: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.92, 43.92, 43.92, 43.92, 44.15, 44.15, 44.15, 44.15, 43.26, 43.26, 43.26, 43.26, 43.26], "power_watts_avg": 43.74, "power_watts_peak": 44.15, "energy_joules_est": 53.91, "sample_count": 13, "duration_seconds": 1.233}, "timestamp": "2026-01-11T13:41:53.385216"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1020.546, "latencies_ms": [1020.546], "images_per_second": 0.98, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main object is a skier positioned in the foreground of the image, moving towards the left side of the frame. The background consists of snow-covered trees and a snowy landscape, suggesting the setting is near a mountain or forested area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.95, 32.95, 32.95, 32.95, 32.95, 42.89, 42.89, 42.89, 42.89, 42.89, 43.81], "power_watts_avg": 38.46, "power_watts_peak": 43.81, "energy_joules_est": 39.27, "sample_count": 11, "duration_seconds": 1.021}, "timestamp": "2026-01-11T13:41:54.498772"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 986.639, "latencies_ms": [986.639], "images_per_second": 1.014, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A man is cross-country skiing through a snowy forest, wearing a red and white top and dark pants. Another person is visible in the distance, also skiing. The scene is set in a mountainous area with snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.81, 43.81, 43.81, 43.81, 42.54, 42.54, 42.54, 42.54, 42.54, 42.88], "power_watts_avg": 43.08, "power_watts_peak": 43.81, "energy_joules_est": 42.52, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-11T13:41:55.511752"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 845.222, "latencies_ms": [845.222], "images_per_second": 1.183, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The snow is white, reflecting the light. The trees are dark green, indicating a winter setting. The scene is well-lit, possibly by sunlight filtering through the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 42.88, 42.88, 43.84, 43.84, 43.84, 43.84, 43.84], "power_watts_avg": 43.42, "power_watts_peak": 43.84, "energy_joules_est": 36.71, "sample_count": 9, "duration_seconds": 0.846}, "timestamp": "2026-01-11T13:41:56.423230"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 735.281, "latencies_ms": [735.281], "images_per_second": 1.36, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A computer setup is displayed on a desk, featuring a monitor, keyboard, and mouse, with the word \"WORKPLACE\" written above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 43.58, 43.58, 43.58, 42.86, 42.86, 42.86], "power_watts_avg": 43.31, "power_watts_peak": 43.58, "energy_joules_est": 31.87, "sample_count": 8, "duration_seconds": 0.736}, "timestamp": "2026-01-11T13:41:57.235637"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1230.207, "latencies_ms": [1230.207], "images_per_second": 0.813, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "keyboard: 2\nmouse: 1\ncomputer monitor: 1\ndesk: 2\nlaptop: 1\nmousepad: 1\nmouse: 1\ncord: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 48.47, 48.47, 48.47, 48.47, 48.47, 43.19, 43.19, 43.19, 43.19, 43.19, 37.87], "power_watts_avg": 44.76, "power_watts_peak": 48.47, "energy_joules_est": 55.08, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-11T13:41:58.549421"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 801.384, "latencies_ms": [801.384], "images_per_second": 1.248, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The keyboard and mouse are positioned in the foreground, closer to the viewer. The monitor is situated in the background, slightly elevated and providing a view of the workspace.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [37.87, 37.87, 37.87, 37.87, 42.58, 42.58, 42.58, 42.58], "power_watts_avg": 40.22, "power_watts_peak": 42.58, "energy_joules_est": 32.25, "sample_count": 8, "duration_seconds": 0.802}, "timestamp": "2026-01-11T13:41:59.358808"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1239.98, "latencies_ms": [1239.98], "images_per_second": 0.806, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a workspace with a computer setup on a desk. A monitor displays an image of a desk with a computer and keyboard, while a mouse sits in front of the keyboard. The word \"WORKPLACE\" is prominently displayed, suggesting the setting is designed for productivity and computer use.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.58, 42.2, 42.2, 42.2, 42.2, 42.2, 43.9, 43.9, 43.9, 43.9, 43.9, 43.56, 43.56], "power_watts_avg": 43.09, "power_watts_peak": 43.9, "energy_joules_est": 53.46, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-11T13:42:00.670100"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1142.789, "latencies_ms": [1142.789], "images_per_second": 0.875, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The computer setup is primarily in grayscale, emphasizing the monochrome aesthetic. The lighting appears to be soft and diffused, contributing to a calm and focused atmosphere. The materials appear to be sleek and modern, complementing the minimalist design of the workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.9, "ram_available_mb": 109429.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 43.56, 42.25, 42.25, 42.25, 42.25, 42.25, 43.24, 43.24, 43.24, 43.24], "power_watts_avg": 42.91, "power_watts_peak": 43.56, "energy_joules_est": 49.07, "sample_count": 12, "duration_seconds": 1.143}, "timestamp": "2026-01-11T13:42:01.882652"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 692.468, "latencies_ms": [692.468], "images_per_second": 1.444, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A woman in a red shirt is sitting at a table in a train, holding a bagel and smiling while enjoying her meal.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13076.9, "ram_available_mb": 109429.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 36.0}, "power_stats": {"power_watts_samples": [34.67, 34.67, 34.67, 34.67, 34.67, 42.58, 42.58], "power_watts_avg": 36.93, "power_watts_peak": 42.58, "energy_joules_est": 25.6, "sample_count": 7, "duration_seconds": 0.693}, "timestamp": "2026-01-11T13:42:02.593219"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1082.754, "latencies_ms": [1082.754], "images_per_second": 0.924, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bagel: 1\nwoman: 1\ncup: 1\ntable: 1\nwindow: 1\nman: 1\nman in red shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [42.58, 42.58, 42.58, 53.77, 53.77, 53.77, 53.77, 53.77, 43.95, 43.95, 43.95], "power_watts_avg": 48.04, "power_watts_peak": 53.77, "energy_joules_est": 52.04, "sample_count": 11, "duration_seconds": 1.083}, "timestamp": "2026-01-11T13:42:03.707116"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1240.108, "latencies_ms": [1240.108], "images_per_second": 0.806, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, holding the bagel and smiling. The train car is behind her, extending into the background. The bagel is situated in the foreground, close to the woman's hand, while a coffee cup and a box are placed further back on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 41.31, 41.31, 41.31, 41.31, 41.31, 43.62, 43.62, 43.62, 43.62, 43.62, 36.44], "power_watts_avg": 42.23, "power_watts_peak": 43.95, "energy_joules_est": 52.39, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-11T13:42:05.022591"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 790.744, "latencies_ms": [790.744], "images_per_second": 1.265, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A woman is sitting in a train car, holding a bagel and smiling at the camera. She is surrounded by other passengers and appears to be enjoying her meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.44, 36.44, 36.44, 36.44, 42.8, 42.8, 42.8, 42.8], "power_watts_avg": 39.62, "power_watts_peak": 42.8, "energy_joules_est": 31.35, "sample_count": 8, "duration_seconds": 0.791}, "timestamp": "2026-01-11T13:42:05.833088"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 832.382, "latencies_ms": [832.382], "images_per_second": 1.201, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The woman is wearing a maroon shirt. The bagel is light brown. The train interior has warm lighting. The bagel appears to have a cream filling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [42.8, 43.39, 43.39, 43.39, 43.39, 43.39, 43.68, 43.68, 43.68], "power_watts_avg": 43.42, "power_watts_peak": 43.68, "energy_joules_est": 36.16, "sample_count": 9, "duration_seconds": 0.833}, "timestamp": "2026-01-11T13:42:06.745583"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 633.389, "latencies_ms": [633.389], "images_per_second": 1.579, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a field, displaying their distinctive black and white stripes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.68, 43.68, 48.68, 48.68, 48.68, 48.68, 48.68], "power_watts_avg": 47.25, "power_watts_peak": 48.68, "energy_joules_est": 29.95, "sample_count": 7, "duration_seconds": 0.634}, "timestamp": "2026-01-11T13:42:07.457723"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1256.569, "latencies_ms": [1256.569], "images_per_second": 0.796, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "zebra: 2\ngrass: 2\nfence: 1\nzebra: 1\nzebra: 1\nzebra: 1\nzebra: 1\nzebra: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 42.97, 42.97, 42.97, 47.07, 47.07, 47.07, 47.07, 47.07, 42.6, 42.6, 42.6], "power_watts_avg": 44.46, "power_watts_peak": 47.07, "energy_joules_est": 55.89, "sample_count": 13, "duration_seconds": 1.257}, "timestamp": "2026-01-11T13:42:08.771338"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 991.43, "latencies_ms": [991.43], "images_per_second": 1.009, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The zebras are positioned close together in the foreground, grazing on the grass. The background is slightly blurred, drawing focus to the zebras. The zebras are located near the center of the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 37.77, 37.77, 37.77, 37.77, 37.77, 43.43, 43.43, 43.43], "power_watts_avg": 40.43, "power_watts_peak": 43.43, "energy_joules_est": 40.1, "sample_count": 10, "duration_seconds": 0.992}, "timestamp": "2026-01-11T13:42:09.782558"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 779.397, "latencies_ms": [779.397], "images_per_second": 1.283, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a grassy field. The zebras are facing away from the camera, focused on their meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [43.43, 43.43, 43.67, 43.67, 43.67, 43.67, 44.27, 44.27], "power_watts_avg": 43.76, "power_watts_peak": 44.27, "energy_joules_est": 34.12, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-11T13:42:10.592717"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 903.417, "latencies_ms": [903.417], "images_per_second": 1.107, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The zebras have black and white stripes. The lighting appears to be natural, possibly sunlight, giving the scene a bright and lively atmosphere. The grass appears to be short and green, suggesting a healthy environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [44.27, 44.27, 44.27, 51.07, 51.07, 51.07, 51.07, 51.07, 43.71], "power_watts_avg": 47.99, "power_watts_peak": 51.07, "energy_joules_est": 43.37, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:42:11.503967"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 778.425, "latencies_ms": [778.425], "images_per_second": 1.285, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two young men in white shirts and dark pants are riding a green bicycle down a busy city street, surrounded by other vehicles and pedestrians.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.71, 43.71, 43.71, 43.71, 43.81, 43.81, 43.81, 43.81], "power_watts_avg": 43.76, "power_watts_peak": 43.81, "energy_joules_est": 34.08, "sample_count": 8, "duration_seconds": 0.779}, "timestamp": "2026-01-11T13:42:12.316997"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1380.325, "latencies_ms": [1380.325], "images_per_second": 0.724, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bicycle: 2\nmotorcycle: 3\nscooter: 2\nman: 2\nwoman: 1\nman on bike: 2\nstorefront: 2\nsign: 1\nplants: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.81, 45.72, 45.72, 45.72, 45.72, 45.72, 43.51, 43.51, 43.51, 43.51, 43.51, 42.77, 42.77, 42.77], "power_watts_avg": 44.16, "power_watts_peak": 45.72, "energy_joules_est": 60.97, "sample_count": 14, "duration_seconds": 1.381}, "timestamp": "2026-01-11T13:42:13.731638"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 856.676, "latencies_ms": [856.676], "images_per_second": 1.167, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the two boys riding a bicycle in the middle ground. The background features other motorcycles and pedestrians, indicating a busy urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 40.11, 40.11, 40.11, 40.11, 40.11, 43.5, 43.5], "power_watts_avg": 41.46, "power_watts_peak": 43.5, "energy_joules_est": 35.54, "sample_count": 9, "duration_seconds": 0.857}, "timestamp": "2026-01-11T13:42:14.643609"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 718.817, "latencies_ms": [718.817], "images_per_second": 1.391, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Two young men in uniform are riding a green bicycle on a busy city street, surrounded by other motorbikes and pedestrians.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.5, 43.5, 43.5, 47.47, 47.47, 47.47, 47.47, 47.47], "power_watts_avg": 45.99, "power_watts_peak": 47.47, "energy_joules_est": 33.08, "sample_count": 8, "duration_seconds": 0.719}, "timestamp": "2026-01-11T13:42:15.454833"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1135.108, "latencies_ms": [1135.108], "images_per_second": 0.881, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene is brightly lit, likely by natural or artificial light. The colors are vibrant and varied, contributing to the lively atmosphere. The materials appear to be primarily metal and plastic, typical of urban transportation. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.07, 43.07, 43.07, 43.07, 43.07, 42.54, 42.54, 42.54, 42.54, 42.54, 42.75, 42.75], "power_watts_avg": 42.8, "power_watts_peak": 43.07, "energy_joules_est": 48.59, "sample_count": 12, "duration_seconds": 1.135}, "timestamp": "2026-01-11T13:42:16.667596"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 647.806, "latencies_ms": [647.806], "images_per_second": 1.544, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two tennis players are engaged in a match on a grass court, with one player preparing to serve and the other returning the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [42.75, 42.75, 42.75, 41.66, 41.66, 41.66, 41.66], "power_watts_avg": 42.12, "power_watts_peak": 42.75, "energy_joules_est": 27.3, "sample_count": 7, "duration_seconds": 0.648}, "timestamp": "2026-01-11T13:42:17.377685"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1166.18, "latencies_ms": [1166.18], "images_per_second": 0.858, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "chair: 2\nnet: 1\nball: 1\ntennis racket: 1\ntennis ball: 1\nspectators: 10\ntennis court: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.6, "ram_available_mb": 109428.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.66, 41.81, 41.81, 41.81, 41.81, 41.81, 44.09, 44.09, 44.09, 44.09, 44.09, 43.67], "power_watts_avg": 42.9, "power_watts_peak": 44.09, "energy_joules_est": 50.05, "sample_count": 12, "duration_seconds": 1.167}, "timestamp": "2026-01-11T13:42:18.590717"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1091.192, "latencies_ms": [1091.192], "images_per_second": 0.916, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The tennis court is positioned centrally in the image, with a player on the left side preparing to serve the ball. The player is positioned near the baseline, close to the net. The background features spectators seated in bleachers, watching the match unfold.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.6, "ram_available_mb": 109428.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.6, "ram_available_mb": 109428.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [43.67, 43.67, 43.67, 43.74, 43.74, 43.74, 43.74, 43.74, 43.46, 43.46, 43.46], "power_watts_avg": 43.64, "power_watts_peak": 43.74, "energy_joules_est": 47.64, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-11T13:42:19.703917"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 949.026, "latencies_ms": [949.026], "images_per_second": 1.054, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a tennis match taking place on a grass court, with two players actively engaged in a rally. Spectators are seated in stands surrounding the court, watching the match unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.6, "ram_available_mb": 109428.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 41.26, 41.26, 41.26, 41.26, 41.26, 43.86, 43.86, 43.86], "power_watts_avg": 42.48, "power_watts_peak": 43.86, "energy_joules_est": 40.33, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-11T13:42:20.715582"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1019.82, "latencies_ms": [1019.82], "images_per_second": 0.981, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The tennis court is green and appears to be well-maintained. The lighting is bright, illuminating the players and court surface. The materials appear to be natural grass and synthetic turf. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [43.86, 43.86, 43.14, 43.14, 43.14, 43.14, 43.14, 43.3, 43.3, 43.3, 43.3], "power_watts_avg": 43.33, "power_watts_peak": 43.86, "energy_joules_est": 44.21, "sample_count": 11, "duration_seconds": 1.02}, "timestamp": "2026-01-11T13:42:21.827820"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 800.567, "latencies_ms": [800.567], "images_per_second": 1.249, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The living room features a brown sofa, a wooden coffee table with a sewing machine, a flat-screen TV, and several potted plants, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 29.0}, "power_stats": {"power_watts_samples": [43.3, 36.68, 36.68, 36.68, 36.68, 36.68, 42.67, 42.67], "power_watts_avg": 39.01, "power_watts_peak": 43.3, "energy_joules_est": 31.25, "sample_count": 8, "duration_seconds": 0.801}, "timestamp": "2026-01-11T13:42:22.639537"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1603.239, "latencies_ms": [1603.239], "images_per_second": 0.624, "prompt_tokens": 21, "response_tokens_est": 55, "n_tiles": 1, "output_text": "television: 1\ncurtains: 2\nsofa: 1\ncushion: 1\ncoffee table: 1\nsewing machine: 1\nplants: 2\nfloor cushions: 1\nbookshelf: 1\nlamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 53.61, 53.61, 53.61, 53.61, 53.61, 44.2, 44.2, 44.2, 44.2, 44.2, 33.92, 33.92, 33.92], "power_watts_avg": 44.93, "power_watts_peak": 53.61, "energy_joules_est": 72.05, "sample_count": 16, "duration_seconds": 1.604}, "timestamp": "2026-01-11T13:42:24.255800"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 971.216, "latencies_ms": [971.216], "images_per_second": 1.03, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The sofa and coffee table are positioned close together, creating a cozy and intimate seating area. The TV and sewing machine are placed further back in the room, providing a clear separation from the seating area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.92, 33.92, 39.27, 39.27, 39.27, 39.27, 39.27, 44.31, 44.31, 44.31], "power_watts_avg": 39.71, "power_watts_peak": 44.31, "energy_joules_est": 38.59, "sample_count": 10, "duration_seconds": 0.972}, "timestamp": "2026-01-11T13:42:25.265632"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1229.807, "latencies_ms": [1229.807], "images_per_second": 0.813, "prompt_tokens": 19, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The living room features a brown sofa, a wooden coffee table, and a flat-screen TV on a stand. Various plants are scattered throughout the space, adding a touch of greenery and color. A sewing machine sits on the coffee table, indicating a possible hobby or creative space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.31, 44.31, 43.31, 43.31, 43.31, 43.31, 43.31, 43.41, 43.41, 43.41, 43.41, 43.41, 40.19], "power_watts_avg": 43.26, "power_watts_peak": 44.31, "energy_joules_est": 53.23, "sample_count": 13, "duration_seconds": 1.23}, "timestamp": "2026-01-11T13:42:26.581323"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 857.814, "latencies_ms": [857.814], "images_per_second": 1.166, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The room features a warm color scheme with brown furniture, white curtains, and natural light coming in through the window. The lighting appears soft and diffused, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.19, 40.19, 40.19, 40.19, 42.77, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 41.62, "power_watts_peak": 42.77, "energy_joules_est": 35.72, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:42:27.490750"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 776.929, "latencies_ms": [776.929], "images_per_second": 1.287, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A female tennis player in a red dress and white visor stands on a clay court, holding a tennis racket and appearing to celebrate a point.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.12, 43.12, 43.12, 43.12, 43.45, 43.45, 43.45, 43.45], "power_watts_avg": 43.28, "power_watts_peak": 43.45, "energy_joules_est": 33.65, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:42:28.301957"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1120.055, "latencies_ms": [1120.055], "images_per_second": 0.893, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "woman: 1\ntennis racket: 1\ntennis dress: 1\nvisor: 1\ncourt: 1\nclothing: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.45, 45.59, 45.59, 45.59, 45.59, 45.59, 43.74, 43.74, 43.74, 43.74, 43.74, 42.51], "power_watts_avg": 44.38, "power_watts_peak": 45.59, "energy_joules_est": 49.74, "sample_count": 12, "duration_seconds": 1.121}, "timestamp": "2026-01-11T13:42:29.515289"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 802.721, "latencies_ms": [802.721], "images_per_second": 1.246, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground of the image, facing the viewer. The tennis court extends into the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 42.51, 42.51, 42.03, 42.03, 42.03, 42.03], "power_watts_avg": 42.27, "power_watts_peak": 42.51, "energy_joules_est": 33.95, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-11T13:42:30.324476"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 800.435, "latencies_ms": [800.435], "images_per_second": 1.249, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A woman in a red tennis dress and visor is standing on a clay tennis court, holding a tennis racket and appearing to be in the middle of a tennis match.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.03, 43.73, 43.73, 43.73, 43.73, 43.73, 44.51, 44.51], "power_watts_avg": 43.71, "power_watts_peak": 44.51, "energy_joules_est": 35.0, "sample_count": 8, "duration_seconds": 0.801}, "timestamp": "2026-01-11T13:42:31.132041"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 755.576, "latencies_ms": [755.576], "images_per_second": 1.323, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The tennis player is wearing a bright red dress and a white visor. The clay court is reddish-brown, and the lighting appears to be natural sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.51, 44.51, 44.51, 54.2, 54.2, 54.2, 54.2, 54.2], "power_watts_avg": 50.56, "power_watts_peak": 54.2, "energy_joules_est": 38.22, "sample_count": 8, "duration_seconds": 0.756}, "timestamp": "2026-01-11T13:42:31.941018"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 940.276, "latencies_ms": [940.276], "images_per_second": 1.064, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A bustling city street lined with brick buildings, cars, and pedestrians, features a prominent OmniFest billboard and several businesses, including a restaurant and a movie theater.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.53, 44.53, 44.53, 44.53, 44.53, 42.52, 42.52, 42.52, 42.52, 42.52], "power_watts_avg": 43.52, "power_watts_peak": 44.53, "energy_joules_est": 40.97, "sample_count": 10, "duration_seconds": 0.941}, "timestamp": "2026-01-11T13:42:32.950862"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1199.955, "latencies_ms": [1199.955], "images_per_second": 0.833, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "billboard: 1\nstreet light: 2\ncar: 3\nbuilding: 6\nrestaurant: 2\npeople: 2\ntable: 1\nchairs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 42.73, 42.73, 42.56, 42.56, 42.56, 42.56, 42.56, 42.73, 42.73], "power_watts_avg": 42.66, "power_watts_peak": 42.73, "energy_joules_est": 51.23, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-11T13:42:34.164052"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1107.026, "latencies_ms": [1107.026], "images_per_second": 0.903, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The foreground features parked cars and pedestrians, creating a sense of movement and activity. The background showcases a bustling street lined with buildings, further emphasizing the urban setting. The billboard in the left foreground adds a visual element to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 43.98, 43.98, 43.98, 43.98, 43.98, 44.1, 44.1, 44.1, 44.1], "power_watts_avg": 43.71, "power_watts_peak": 44.1, "energy_joules_est": 48.41, "sample_count": 12, "duration_seconds": 1.108}, "timestamp": "2026-01-11T13:42:35.376978"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 921.3, "latencies_ms": [921.3], "images_per_second": 1.085, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a bustling city street lined with colorful buildings, busy with cars and pedestrians. The atmosphere suggests a lively urban environment, possibly during a special event or festival.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.1, 33.77, 33.77, 33.77, 33.77, 33.77, 42.31, 42.31, 42.31, 42.31], "power_watts_avg": 38.22, "power_watts_peak": 44.1, "energy_joules_est": 35.24, "sample_count": 10, "duration_seconds": 0.922}, "timestamp": "2026-01-11T13:42:36.390274"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1049.69, "latencies_ms": [1049.69], "images_per_second": 0.953, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The buildings exhibit a mix of colors, including reds, browns, and grays. The lighting is relatively even, suggesting an overcast day. The buildings appear to be constructed of brick and stone, contributing to the overall urban aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 42.86, 42.86, 42.86, 42.83, 42.83, 42.83, 42.83, 42.83, 44.34], "power_watts_avg": 42.98, "power_watts_peak": 44.34, "energy_joules_est": 45.14, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-11T13:42:37.503383"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 754.559, "latencies_ms": [754.559], "images_per_second": 1.325, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A female tennis player in a red outfit and white visor is poised to hit a yellow tennis ball on a blue and green court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.34, 44.34, 44.34, 44.34, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 43.8, "power_watts_peak": 44.34, "energy_joules_est": 33.09, "sample_count": 8, "duration_seconds": 0.755}, "timestamp": "2026-01-11T13:42:38.314714"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1180.173, "latencies_ms": [1180.173], "images_per_second": 0.847, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 2\nTennis player: 1\nTennis shoes: 2\nTennis visor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.27, 44.47, 44.47, 44.47, 44.47, 44.47, 43.6, 43.6, 43.6, 43.6, 43.6, 43.13], "power_watts_avg": 43.9, "power_watts_peak": 44.47, "energy_joules_est": 51.83, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-11T13:42:39.528128"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 987.139, "latencies_ms": [987.139], "images_per_second": 1.013, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The tennis player is positioned on the left side of the image, facing towards the right side. The tennis ball is in the background, near the player's feet. The tennis court is visible in the background, extending beyond the player's feet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.13, 43.13, 43.13, 43.13, 43.8, 43.8, 43.8, 43.8, 43.8, 43.57], "power_watts_avg": 43.51, "power_watts_peak": 43.8, "energy_joules_est": 42.97, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-11T13:42:40.540221"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 936.707, "latencies_ms": [936.707], "images_per_second": 1.068, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A woman in a red tennis outfit is playing tennis on a blue and green court, poised to hit a yellow tennis ball. She is wearing a visor and holding a tennis racket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.57, 43.57, 43.57, 43.57, 44.06, 44.06, 44.06, 44.06, 44.06, 43.82], "power_watts_avg": 43.84, "power_watts_peak": 44.06, "energy_joules_est": 41.09, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-11T13:42:41.553965"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 861.649, "latencies_ms": [861.649], "images_per_second": 1.161, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The tennis player is wearing a vibrant red outfit and white shoes. The green tennis court is well-lit, and the bright yellow tennis ball is visible in mid-air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 43.82, 42.71, 42.71, 42.71, 42.71, 42.71], "power_watts_avg": 43.2, "power_watts_peak": 43.82, "energy_joules_est": 37.24, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:42:42.465090"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 619.572, "latencies_ms": [619.572], "images_per_second": 1.614, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A blue and silver train travels along a curving track, passing through a lush green forest.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.84, 42.84, 42.84, 42.84, 42.84, 44.26, 44.26], "power_watts_avg": 43.25, "power_watts_peak": 44.26, "energy_joules_est": 26.81, "sample_count": 7, "duration_seconds": 0.62}, "timestamp": "2026-01-11T13:42:43.177819"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1450.865, "latencies_ms": [1450.865], "images_per_second": 0.689, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Train: 2\nTrain car: 2\nTrain tracks: 2\nTrain windows: 6\nTrain headlights: 2\nTrain door: 2\nTrain engine: 1\nTrain conductor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.26, 44.26, 44.26, 53.05, 53.05, 53.05, 53.05, 53.05, 44.01, 44.01, 44.01, 44.01, 44.01, 36.62, 36.62], "power_watts_avg": 46.09, "power_watts_peak": 53.05, "energy_joules_est": 66.89, "sample_count": 15, "duration_seconds": 1.451}, "timestamp": "2026-01-11T13:42:44.689804"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 815.801, "latencies_ms": [815.801], "images_per_second": 1.226, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The blue and silver train is positioned in the foreground, moving towards the viewer. The train tracks are visible in the background, curving gently through the vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [36.62, 36.62, 42.41, 42.41, 42.41, 42.41, 42.41, 44.43, 44.43], "power_watts_avg": 41.57, "power_watts_peak": 44.43, "energy_joules_est": 33.94, "sample_count": 9, "duration_seconds": 0.816}, "timestamp": "2026-01-11T13:42:45.602182"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 830.396, "latencies_ms": [830.396], "images_per_second": 1.204, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A blue and silver train travels along a narrow, winding track through a lush, wooded area. The train appears to be moving through a natural, undisturbed environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [44.43, 44.43, 44.43, 45.67, 45.67, 45.67, 45.67, 45.67, 43.27], "power_watts_avg": 44.99, "power_watts_peak": 45.67, "energy_joules_est": 37.38, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-11T13:42:46.513432"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 830.162, "latencies_ms": [830.162], "images_per_second": 1.205, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The train is primarily silver and blue with orange accents. The lighting suggests it might be daytime. The train appears to be made of metal and has a modern design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 43.27, 43.27, 43.69, 43.69, 43.69, 43.69, 43.69], "power_watts_avg": 43.51, "power_watts_peak": 43.69, "energy_joules_est": 36.14, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-11T13:42:47.423846"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 734.573, "latencies_ms": [734.573], "images_per_second": 1.361, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two cats, one tabby and one striped, sleep peacefully on a pink blanket atop a red couch, accompanied by two remote controls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 42.97, 42.97, 42.97, 42.49, 42.49, 42.49], "power_watts_avg": 42.79, "power_watts_peak": 42.97, "energy_joules_est": 31.46, "sample_count": 8, "duration_seconds": 0.735}, "timestamp": "2026-01-11T13:42:48.237017"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 839.062, "latencies_ms": [839.062], "images_per_second": 1.192, "prompt_tokens": 21, "response_tokens_est": 21, "n_tiles": 1, "output_text": "cat: 2\nremote: 1\nblanket: 2\ncouch: 2\ncat: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 49.07, 49.07, 49.07, 49.07, 49.07, 42.97, 42.97], "power_watts_avg": 46.26, "power_watts_peak": 49.07, "energy_joules_est": 38.84, "sample_count": 9, "duration_seconds": 0.84}, "timestamp": "2026-01-11T13:42:49.145991"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 935.992, "latencies_ms": [935.992], "images_per_second": 1.068, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cats are positioned close together on the pink blanket, with the cat on the left partially covering the remote control. The cats are lying down on the blanket, which occupies the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 42.97, 45.9, 45.9, 45.9, 45.9, 45.9, 42.78, 42.78], "power_watts_avg": 44.4, "power_watts_peak": 45.9, "energy_joules_est": 41.58, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-11T13:42:50.157017"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1032.444, "latencies_ms": [1032.444], "images_per_second": 0.969, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "Two tabby cats are sleeping on a pink blanket on a red couch. One cat is curled up on the left, while the other is curled up on the right. A remote control is visible on the couch near the cats.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.78, 42.78, 42.78, 43.13, 43.13, 43.13, 43.13, 43.13, 42.76, 42.76, 42.76], "power_watts_avg": 42.93, "power_watts_peak": 43.13, "energy_joules_est": 44.35, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-11T13:42:51.269714"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 704.031, "latencies_ms": [704.031], "images_per_second": 1.42, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The cats are resting on a bright pink blanket. The lighting in the image appears to be soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.76, 42.76, 38.67, 38.67, 38.67, 38.67, 38.67, 42.47], "power_watts_avg": 40.17, "power_watts_peak": 42.76, "energy_joules_est": 28.3, "sample_count": 8, "duration_seconds": 0.705}, "timestamp": "2026-01-11T13:42:52.079953"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 682.187, "latencies_ms": [682.187], "images_per_second": 1.466, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Two surfers navigate rapids in a river, surrounded by lush greenery and trees, with one skillfully riding a wave and the other holding a blue surfboard.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.47, 42.47, 42.47, 42.47, 40.9, 40.9, 40.9], "power_watts_avg": 41.79, "power_watts_peak": 42.47, "energy_joules_est": 28.54, "sample_count": 7, "duration_seconds": 0.683}, "timestamp": "2026-01-11T13:42:52.789852"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1053.178, "latencies_ms": [1053.178], "images_per_second": 0.95, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "river: 2\nbridge: 1\nbench: 1\nperson: 1\nsurfboard: 1\ntree: 1\nground: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.9, "ram_available_mb": 109421.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13085.1, "ram_available_mb": 109421.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [40.9, 40.07, 40.07, 40.07, 40.07, 40.07, 38.34, 38.34, 38.34, 38.34, 38.34], "power_watts_avg": 39.36, "power_watts_peak": 40.9, "energy_joules_est": 41.48, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-11T13:42:53.900941"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 646.674, "latencies_ms": [646.674], "images_per_second": 1.546, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The main object is a person surfing in a river, positioned in the foreground. The river flows in the background, separating the foreground from the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.1, "ram_available_mb": 109421.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.1, "ram_available_mb": 109421.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 34.85, 34.85, 37.72, 37.72], "power_watts_avg": 35.67, "power_watts_peak": 37.72, "energy_joules_est": 23.09, "sample_count": 7, "duration_seconds": 0.647}, "timestamp": "2026-01-11T13:42:54.610102"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1058.095, "latencies_ms": [1058.095], "images_per_second": 0.945, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a river with rapids, where two people are surfing. One surfer is riding a wave in the river, while another surfer stands nearby holding a blue surfboard. The setting is outdoors, surrounded by trees and a stone bridge in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.1, "ram_available_mb": 109421.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13085.1, "ram_available_mb": 109421.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.72, 37.72, 37.72, 42.37, 42.37, 42.37, 42.37, 42.37, 37.66, 37.66, 37.66], "power_watts_avg": 39.82, "power_watts_peak": 42.37, "energy_joules_est": 42.15, "sample_count": 11, "duration_seconds": 1.059}, "timestamp": "2026-01-11T13:42:55.720271"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 956.658, "latencies_ms": [956.658], "images_per_second": 1.045, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The water appears murky and brown, suggesting possible pollution or sedimentation. The lighting is subdued, likely due to overcast conditions or shade from the surrounding trees. The material of the water appears to be flowing rapidly, creating a dynamic scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13085.1, "ram_available_mb": 109421.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [37.66, 37.66, 37.98, 37.98, 37.98, 37.98, 37.98, 37.96, 37.96, 37.96], "power_watts_avg": 37.91, "power_watts_peak": 37.98, "energy_joules_est": 36.29, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:42:56.733325"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 678.003, "latencies_ms": [678.003], "images_per_second": 1.475, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman in a black jacket and blue jeans is holding a colorful kite while standing in a grassy field with a young girl.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [37.96, 37.96, 40.24, 40.24, 40.24, 40.24, 40.24], "power_watts_avg": 39.59, "power_watts_peak": 40.24, "energy_joules_est": 26.86, "sample_count": 7, "duration_seconds": 0.679}, "timestamp": "2026-01-11T13:42:57.443389"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1016.629, "latencies_ms": [1016.629], "images_per_second": 0.984, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "woman: 2\nkite: 1\nchild: 1\ngrass: 1\ntrees: 4\nfence: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.3, "ram_available_mb": 109421.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 43.24, 43.24, 43.24, 47.52, 47.52, 47.52, 47.52, 47.52, 44.09], "power_watts_avg": 45.26, "power_watts_peak": 47.52, "energy_joules_est": 46.04, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-11T13:42:58.556611"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 771.995, "latencies_ms": [771.995], "images_per_second": 1.295, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The woman and child are standing in the foreground of the image. The kite is positioned in the background, slightly further away than the woman and child.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [44.09, 44.09, 44.09, 44.09, 42.73, 42.73, 42.73, 42.73], "power_watts_avg": 43.41, "power_watts_peak": 44.09, "energy_joules_est": 33.53, "sample_count": 8, "duration_seconds": 0.773}, "timestamp": "2026-01-11T13:42:59.363933"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 779.16, "latencies_ms": [779.16], "images_per_second": 1.283, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A woman and a child are flying a colorful butterfly kite in a park. The park is surrounded by trees, and several other people are visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.73, 42.47, 42.47, 42.47, 42.47, 42.47, 43.57, 43.57], "power_watts_avg": 42.78, "power_watts_peak": 43.57, "energy_joules_est": 33.35, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-11T13:43:00.173742"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 828.418, "latencies_ms": [828.418], "images_per_second": 1.207, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The kite is colorful with pink, orange, and blue patterns. The woman and child are standing on a grassy field under a clear, sunny sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.57, 43.57, 43.57, 54.01, 54.01, 54.01, 54.01, 54.01, 44.03], "power_watts_avg": 49.42, "power_watts_peak": 54.01, "energy_joules_est": 40.96, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:43:01.080686"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 946.239, "latencies_ms": [946.239], "images_per_second": 1.057, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young male tennis player, wearing a white shirt and maroon cap, is crouched low and poised to hit a tennis ball with his yellow racket on a blue court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.6, "ram_available_mb": 109420.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13085.5, "ram_available_mb": 109420.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.03, 44.03, 44.03, 44.03, 43.75, 43.75, 43.75, 43.75, 43.75, 42.64], "power_watts_avg": 43.75, "power_watts_peak": 44.03, "energy_joules_est": 41.41, "sample_count": 10, "duration_seconds": 0.947}, "timestamp": "2026-01-11T13:43:02.091659"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1620.419, "latencies_ms": [1620.419], "images_per_second": 0.617, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 1\nNet: 1\nTennis player: 1\nTennis racket: 1\nTennis ball: 1\nTennis ball: 1\nTennis player: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.5, "ram_available_mb": 109420.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13085.5, "ram_available_mb": 109420.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.64, 42.64, 42.64, 42.78, 42.78, 42.78, 42.78, 42.78, 42.6, 42.6, 42.6, 42.6, 42.6, 33.8, 33.8, 33.8, 33.8], "power_watts_avg": 40.59, "power_watts_peak": 42.78, "energy_joules_est": 65.79, "sample_count": 17, "duration_seconds": 1.621}, "timestamp": "2026-01-11T13:43:03.806452"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1038.186, "latencies_ms": [1038.186], "images_per_second": 0.963, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, near the net, preparing to hit the ball. The tennis ball is in the air, near the player's racket. The background features a green curtain and a banner advertising \"National Masters.\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.5, "ram_available_mb": 109420.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [33.8, 35.94, 35.94, 35.94, 35.94, 35.94, 42.5, 42.5, 42.5, 42.5, 42.5], "power_watts_avg": 38.73, "power_watts_peak": 42.5, "energy_joules_est": 40.22, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-11T13:43:04.917567"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1298.861, "latencies_ms": [1298.861], "images_per_second": 0.77, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A young male tennis player is crouching low and preparing to hit a tennis ball during a match on a blue court. He wears a white shirt and a maroon cap. Behind him, a green fence displays a banner reading \"Are you next? National Masters.\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.54, 40.54, 40.54, 40.54, 40.54, 42.89, 42.89, 42.89, 42.89, 42.89, 43.66, 43.66, 43.66], "power_watts_avg": 42.16, "power_watts_peak": 43.66, "energy_joules_est": 54.78, "sample_count": 13, "duration_seconds": 1.299}, "timestamp": "2026-01-11T13:43:06.231302"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 968.299, "latencies_ms": [968.299], "images_per_second": 1.033, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The tennis court is painted blue. The lighting appears to be natural sunlight, creating a bright and clear atmosphere. The materials appear to be standard tennis court surface and netting. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.66, 43.66, 40.94, 40.94, 40.94, 40.94, 40.94, 43.75, 43.75, 43.75], "power_watts_avg": 42.33, "power_watts_peak": 43.75, "energy_joules_est": 41.01, "sample_count": 10, "duration_seconds": 0.969}, "timestamp": "2026-01-11T13:43:07.242847"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 647.21, "latencies_ms": [647.21], "images_per_second": 1.545, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "The room is filled with boxes, furniture, and personal belongings, indicating a recent move or reorganization.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.75, 43.75, 43.64, 43.64, 43.64, 43.64, 43.64], "power_watts_avg": 43.67, "power_watts_peak": 43.75, "energy_joules_est": 28.29, "sample_count": 7, "duration_seconds": 0.648}, "timestamp": "2026-01-11T13:43:07.953467"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1438.461, "latencies_ms": [1438.461], "images_per_second": 0.695, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\nbrown comforter: 1\nwooden door: 1\nbox: 2\ncardboard: 1\nchair: 1\nmirror: 1\nwooden floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.41, 43.41, 43.41, 43.41, 43.41, 46.22, 46.22, 46.22, 46.22, 46.22, 42.87, 42.87, 42.87, 42.87, 42.87], "power_watts_avg": 44.17, "power_watts_peak": 46.22, "energy_joules_est": 63.56, "sample_count": 15, "duration_seconds": 1.439}, "timestamp": "2026-01-11T13:43:09.469214"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1030.192, "latencies_ms": [1030.192], "images_per_second": 0.971, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned to the left of the image. The chair is situated in the background, near a doorway. The bed and chair are separated by a small gap, further emphasizing the spatial relationship between the objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.77, 33.77, 33.77, 33.77, 33.77, 42.69, 42.69, 42.69, 42.69, 42.69, 43.01], "power_watts_avg": 38.66, "power_watts_peak": 43.01, "energy_joules_est": 39.85, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-11T13:43:10.582193"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1082.308, "latencies_ms": [1082.308], "images_per_second": 0.924, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The room appears to be in the midst of moving or renovation, evidenced by the presence of boxes, furniture, and debris scattered across the floor. The room features a rustic brick wall and a wooden door, suggesting an older or industrial-style living space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.01, 42.94, 42.94, 42.94, 42.94, 42.94, 42.71, 42.71], "power_watts_avg": 42.92, "power_watts_peak": 43.01, "energy_joules_est": 46.48, "sample_count": 11, "duration_seconds": 1.083}, "timestamp": "2026-01-11T13:43:11.694280"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 906.471, "latencies_ms": [906.471], "images_per_second": 1.103, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The room features a rustic brick wall and a wooden floor. The lighting is dim, creating a cozy atmosphere. The furniture includes a bed, a chair, and various boxes and furniture items scattered around the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.71, 42.71, 42.7, 42.7, 42.7, 42.7, 42.7, 44.06, 44.06, 44.06], "power_watts_avg": 43.11, "power_watts_peak": 44.06, "energy_joules_est": 39.09, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-11T13:43:12.704982"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 684.233, "latencies_ms": [684.233], "images_per_second": 1.461, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A rider wearing a red and green shirt and helmet is guiding a brown horse over a wooden obstacle in a grassy field.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 42.15, 42.15, 42.15, 42.15, 42.15], "power_watts_avg": 42.69, "power_watts_peak": 44.06, "energy_joules_est": 29.23, "sample_count": 7, "duration_seconds": 0.685}, "timestamp": "2026-01-11T13:43:13.416913"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1258.531, "latencies_ms": [1258.531], "images_per_second": 0.795, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Horse: 1\nJockey: 1\nFence: 1\nFlowers: 1\nPost: 1\nSign: 1\nGround: 1\nTrees: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.41, 42.41, 42.41, 42.41, 42.41, 46.13, 46.13, 46.13, 46.13, 46.13, 43.65, 43.65, 43.65], "power_watts_avg": 44.13, "power_watts_peak": 46.13, "energy_joules_est": 55.56, "sample_count": 13, "duration_seconds": 1.259}, "timestamp": "2026-01-11T13:43:14.730212"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 757.081, "latencies_ms": [757.081], "images_per_second": 1.321, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The horse and rider are positioned in the foreground, jumping over a wooden obstacle. The background features trees and greenery, creating a natural setting for the event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 40.41, 40.41, 40.41, 40.41, 40.41, 43.02], "power_watts_avg": 41.55, "power_watts_peak": 43.65, "energy_joules_est": 31.48, "sample_count": 8, "duration_seconds": 0.758}, "timestamp": "2026-01-11T13:43:15.541242"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 937.126, "latencies_ms": [937.126], "images_per_second": 1.067, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A rider in a red and green jacket is guiding a chestnut horse over a wooden obstacle in a park setting. The horse is mid-jump, showcasing its athleticism and skill.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 46.18, 46.18, 46.18, 46.18, 46.18, 43.12], "power_watts_avg": 44.61, "power_watts_peak": 46.18, "energy_joules_est": 41.83, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-11T13:43:16.553636"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 887.521, "latencies_ms": [887.521], "images_per_second": 1.127, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The horse is brown, adorned with a colorful saddle and bridle. The rider is wearing a red and green jacket. The scene is brightly lit, suggesting sunny weather conditions.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.2, "ram_available_mb": 109422.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.12, 43.12, 43.12, 43.12, 42.78, 42.78, 42.78, 42.78, 42.78], "power_watts_avg": 42.93, "power_watts_peak": 43.12, "energy_joules_est": 38.12, "sample_count": 9, "duration_seconds": 0.888}, "timestamp": "2026-01-11T13:43:17.462828"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 509.835, "latencies_ms": [509.835], "images_per_second": 1.961, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two men are seated under a white umbrella, conversing in front of a small cart filled with various items.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13084.2, "ram_available_mb": 109422.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.2, "ram_available_mb": 109422.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.74, 42.74, 42.74, 42.74, 42.74, 38.2], "power_watts_avg": 41.99, "power_watts_peak": 42.74, "energy_joules_est": 21.45, "sample_count": 6, "duration_seconds": 0.511}, "timestamp": "2026-01-11T13:43:18.073808"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1227.679, "latencies_ms": [1227.679], "images_per_second": 0.815, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Umbrella: 2\nMan: 2\nChair: 1\nCar: 1\nBicycle: 1\nStreet: 1\nSign: 1\nBox: 1\nTools: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.2, "ram_available_mb": 109422.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.2, 38.2, 38.2, 38.2, 41.35, 41.35, 41.35, 41.35, 41.35, 36.98, 36.98, 36.98, 36.98], "power_watts_avg": 39.03, "power_watts_peak": 41.35, "energy_joules_est": 47.94, "sample_count": 13, "duration_seconds": 1.228}, "timestamp": "2026-01-11T13:43:19.386870"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 776.919, "latencies_ms": [776.919], "images_per_second": 1.287, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the vendor's cart and umbrella providing shade in the background. The vendor is seated on a chair, positioned closer to the viewer than the cart and umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.98, 32.22, 32.22, 32.22, 32.22, 32.22, 37.14, 37.14], "power_watts_avg": 34.05, "power_watts_peak": 37.14, "energy_joules_est": 26.47, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:43:20.197926"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 861.463, "latencies_ms": [861.463], "images_per_second": 1.161, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Two men are seated under a large umbrella on a city sidewalk, seemingly engaged in a conversation or observing something. Various items are displayed on tables nearby, suggesting a street vendor or small shop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13084.1, "ram_available_mb": 109422.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.14, 37.14, 42.6, 42.6, 42.6, 42.6, 42.6, 38.0, 38.0], "power_watts_avg": 40.36, "power_watts_peak": 42.6, "energy_joules_est": 34.79, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:43:21.109083"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 999.447, "latencies_ms": [999.447], "images_per_second": 1.001, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene is black and white, creating a vintage feel. The lighting appears to be natural daylight, casting shadows and highlighting the textures of the objects and people. The materials appear to be primarily wood and metal, contributing to the overall rustic ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.1, "ram_available_mb": 109422.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13084.1, "ram_available_mb": 109422.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.0, 38.0, 38.0, 37.15, 37.15, 37.15, 37.15, 37.15, 37.28, 37.28], "power_watts_avg": 37.43, "power_watts_peak": 38.0, "energy_joules_est": 37.42, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-11T13:43:22.120272"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 867.803, "latencies_ms": [867.803], "images_per_second": 1.152, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The kitchen features a white refrigerator, stove, dishwasher, and cabinets, complemented by a black ceiling fan, tiled floor, and yellow backsplash.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.1, "ram_available_mb": 109422.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.28, 37.28, 37.28, 44.07, 44.07, 44.07, 44.07, 44.07, 43.98], "power_watts_avg": 41.8, "power_watts_peak": 44.07, "energy_joules_est": 36.3, "sample_count": 9, "duration_seconds": 0.868}, "timestamp": "2026-01-11T13:43:23.034328"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1428.92, "latencies_ms": [1428.92], "images_per_second": 0.7, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "kitchen: 8\ncountertop: 2\ncabinets: 8\nrefrigerator: 1\ntoaster: 1\noven: 2\ndishwasher: 1\nwindow: 2\nceiling fan: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.98, 43.98, 43.98, 43.98, 43.42, 43.42, 43.42, 43.42, 43.42, 43.7, 43.7, 43.7, 43.7, 43.7, 34.24], "power_watts_avg": 43.05, "power_watts_peak": 43.98, "energy_joules_est": 61.52, "sample_count": 15, "duration_seconds": 1.429}, "timestamp": "2026-01-11T13:43:24.549606"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1126.624, "latencies_ms": [1126.624], "images_per_second": 0.888, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned in a kitchen layout, with the stove and refrigerator located towards the right side of the image. The sink and dishwasher are situated in the foreground, closer to the viewer. The window and ceiling fan are located in the background, further away from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.24, 34.24, 34.24, 34.24, 42.87, 42.87, 42.87, 42.87, 42.87, 42.82, 42.82, 42.82], "power_watts_avg": 39.98, "power_watts_peak": 42.87, "energy_joules_est": 45.06, "sample_count": 12, "duration_seconds": 1.127}, "timestamp": "2026-01-11T13:43:25.764280"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 848.455, "latencies_ms": [848.455], "images_per_second": 1.179, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The kitchen features a classic design with light blue cabinets, a dark countertop, and a ceiling fan. The space is well-lit and appears clean and organized.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 38.54, 38.54, 38.54, 38.54, 38.54, 42.49, 42.49], "power_watts_avg": 40.37, "power_watts_peak": 42.82, "energy_joules_est": 34.27, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-11T13:43:26.676072"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1034.07, "latencies_ms": [1034.07], "images_per_second": 0.967, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The kitchen features white cabinets and dark gray tile flooring. The lighting is primarily from overhead fixtures, creating a warm ambiance. The kitchen is equipped with modern appliances, including a refrigerator and a dishwasher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [42.49, 42.49, 42.49, 46.74, 46.74, 46.74, 46.74, 46.74, 42.93, 42.93, 42.93], "power_watts_avg": 44.54, "power_watts_peak": 46.74, "energy_joules_est": 46.08, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-11T13:43:27.786124"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 710.998, "latencies_ms": [710.998], "images_per_second": 1.406, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young child sleeps peacefully on a bed with a blue and white floral comforter, smiling as they lay on their side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 38.76, 38.76, 38.76, 38.76, 38.76, 42.83], "power_watts_avg": 40.31, "power_watts_peak": 42.93, "energy_joules_est": 28.67, "sample_count": 8, "duration_seconds": 0.711}, "timestamp": "2026-01-11T13:43:28.596831"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1282.658, "latencies_ms": [1282.658], "images_per_second": 0.78, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "bed: 2\nblanket: 2\npillow: 1\ntoddler: 1\npacifier: 1\ntelevision: 1\nwall: 1\ncord: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.83, 42.83, 42.83, 47.86, 47.86, 47.86, 47.86, 47.86, 42.61, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 44.68, "power_watts_peak": 47.86, "energy_joules_est": 57.32, "sample_count": 13, "duration_seconds": 1.283}, "timestamp": "2026-01-11T13:43:29.912415"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 918.588, "latencies_ms": [918.588], "images_per_second": 1.089, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main object is a child lying in bed near a wall. The bed occupies the foreground, while the wall is in the background. The child is positioned close to the wall, suggesting they are close by.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [34.06, 34.06, 34.06, 34.06, 34.06, 43.38, 43.38, 43.38, 43.38, 43.38], "power_watts_avg": 38.72, "power_watts_peak": 43.38, "energy_joules_est": 35.59, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:43:30.923081"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 750.428, "latencies_ms": [750.428], "images_per_second": 1.333, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A young child is sleeping peacefully on a bed with a train-themed bedding. The child is smiling and has a pacifier in their mouth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.9, "ram_available_mb": 109422.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [42.55, 42.55, 42.55, 42.55, 42.55, 42.38, 42.38, 42.38], "power_watts_avg": 42.49, "power_watts_peak": 42.55, "energy_joules_est": 31.9, "sample_count": 8, "duration_seconds": 0.751}, "timestamp": "2026-01-11T13:43:31.731512"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 945.05, "latencies_ms": [945.05], "images_per_second": 1.058, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The child's bed is covered with a blue and white floral blanket. The lighting in the room is dim, creating a cozy atmosphere. The child is wearing a white tank top and appears to be sleeping peacefully.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 49.74, 49.74, 49.74, 49.74, 49.74, 42.74, 42.74, 42.74], "power_watts_avg": 46.17, "power_watts_peak": 49.74, "energy_joules_est": 43.65, "sample_count": 10, "duration_seconds": 0.945}, "timestamp": "2026-01-11T13:43:32.743491"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 798.781, "latencies_ms": [798.781], "images_per_second": 1.252, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A green highway sign with graffiti reading \"Quesens Bronx\" and a \"No Trucks\" sign above it indicates no trucks are allowed in the area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [42.74, 42.74, 40.43, 40.43, 40.43, 40.43, 40.43, 37.46], "power_watts_avg": 40.63, "power_watts_peak": 42.74, "energy_joules_est": 32.48, "sample_count": 8, "duration_seconds": 0.799}, "timestamp": "2026-01-11T13:43:33.554442"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1011.58, "latencies_ms": [1011.58], "images_per_second": 0.989, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "No trucks: 1\nEast: 1\nQueens Bronx: 1\n278: 1\nSign: 1\nGraffiti: 1\nMetal structure: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.46, 37.46, 37.46, 37.46, 38.92, 38.92, 38.92, 38.92, 38.92, 38.87, 38.87], "power_watts_avg": 38.38, "power_watts_peak": 38.92, "energy_joules_est": 38.84, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-11T13:43:34.666167"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 635.924, "latencies_ms": [635.924], "images_per_second": 1.573, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The green sign is positioned in the foreground, slightly to the right of the main sign. The background is mostly clear, offering a view of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [38.87, 38.87, 38.87, 37.24, 37.24, 37.24, 37.24], "power_watts_avg": 37.94, "power_watts_peak": 38.87, "energy_joules_est": 24.13, "sample_count": 7, "duration_seconds": 0.636}, "timestamp": "2026-01-11T13:43:35.375799"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 952.452, "latencies_ms": [952.452], "images_per_second": 1.05, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts a highway sign displaying \"No Trucks\" above a green sign indicating the direction to Queens Bronx. A smaller sign above the main one reads \"East 278.\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.24, 35.7, 35.7, 35.7, 35.7, 35.7, 36.58, 36.58, 36.58, 36.58], "power_watts_avg": 36.21, "power_watts_peak": 37.24, "energy_joules_est": 34.5, "sample_count": 10, "duration_seconds": 0.953}, "timestamp": "2026-01-11T13:43:36.387571"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 690.707, "latencies_ms": [690.707], "images_per_second": 1.448, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The green highway sign is brightly lit, contrasting against the overcast sky. The sign appears to be made of metal and shows signs of wear and graffiti.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.58, 36.52, 36.52, 36.52, 36.52, 36.52, 37.37], "power_watts_avg": 36.65, "power_watts_peak": 37.37, "energy_joules_est": 25.33, "sample_count": 7, "duration_seconds": 0.691}, "timestamp": "2026-01-11T13:43:37.096609"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 758.67, "latencies_ms": [758.67], "images_per_second": 1.318, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A red Chevrolet pickup truck is parked in a lot, facing away from the camera, with other vehicles and tents visible in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [37.37, 37.37, 37.37, 48.27, 48.27, 48.27, 48.27, 48.27], "power_watts_avg": 44.18, "power_watts_peak": 48.27, "energy_joules_est": 33.54, "sample_count": 8, "duration_seconds": 0.759}, "timestamp": "2026-01-11T13:43:37.909179"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1349.449, "latencies_ms": [1349.449], "images_per_second": 0.741, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Truck: 2\nTires: 4\nWheels: 2\nTailgate: 1\nChrome: 1\nLicense plate: 1\nMirror: 1\nStreet light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.66, 42.66, 42.66, 42.66, 42.66, 43.34, 43.34, 43.34, 43.34, 43.34, 44.37, 44.37, 44.37, 44.37], "power_watts_avg": 43.39, "power_watts_peak": 44.37, "energy_joules_est": 58.57, "sample_count": 14, "duration_seconds": 1.35}, "timestamp": "2026-01-11T13:43:39.323687"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 914.961, "latencies_ms": [914.961], "images_per_second": 1.093, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main object is a red Chevrolet pickup truck parked in the foreground of the image. The background features other vehicles, including a blue car and a green tent, suggesting an outdoor setting or gathering.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.37, 35.75, 35.75, 35.75, 35.75, 35.75, 43.19, 43.19, 43.19, 43.19], "power_watts_avg": 39.59, "power_watts_peak": 44.37, "energy_joules_est": 36.24, "sample_count": 10, "duration_seconds": 0.915}, "timestamp": "2026-01-11T13:43:40.335469"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1004.712, "latencies_ms": [1004.712], "images_per_second": 0.995, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a vintage red Chevrolet pickup truck parked in a parking lot, possibly at a car show or similar event. Other vehicles, including a blue car and a green tent, are also visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.19, 42.0, 42.0, 42.0, 42.0, 42.0, 42.39, 42.39, 42.39, 42.39], "power_watts_avg": 42.28, "power_watts_peak": 43.19, "energy_joules_est": 42.49, "sample_count": 10, "duration_seconds": 1.005}, "timestamp": "2026-01-11T13:43:41.346538"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1043.863, "latencies_ms": [1043.863], "images_per_second": 0.958, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The red pickup truck stands out against the light blue sky. Its shiny paint reflects the sunlight, creating a vibrant contrast. The truck is parked in a parking lot, suggesting an outdoor setting, possibly during a car show or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.39, 44.49, 44.49, 44.49, 44.49, 44.49, 44.32, 44.32, 44.32, 44.32, 44.32], "power_watts_avg": 44.22, "power_watts_peak": 44.49, "energy_joules_est": 46.18, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-11T13:43:42.459470"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 651.202, "latencies_ms": [651.202], "images_per_second": 1.536, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Three cows are visible behind a barbed wire fence, gazing at the camera in a rural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 42.86, 42.86, 42.86, 42.61, 42.61], "power_watts_avg": 42.79, "power_watts_peak": 42.86, "energy_joules_est": 27.89, "sample_count": 7, "duration_seconds": 0.652}, "timestamp": "2026-01-11T13:43:43.170066"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1393.23, "latencies_ms": [1393.23], "images_per_second": 0.718, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Barbed wire fence: 5\nCow ears: 4\nCow head: 3\nCow body: 2\nCow tail: 1\nGrass: 6\nTrees: 1\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 52.44, 52.44, 52.44, 52.44, 52.44, 43.23, 43.23, 43.23, 43.23, 43.23, 34.17], "power_watts_avg": 45.74, "power_watts_peak": 52.44, "energy_joules_est": 63.75, "sample_count": 14, "duration_seconds": 1.394}, "timestamp": "2026-01-11T13:43:44.584040"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 815.101, "latencies_ms": [815.101], "images_per_second": 1.227, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the barbed wire fence separating them from the background. The cows are situated near the fence, partially obscured by it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [34.17, 34.17, 34.17, 34.17, 43.62, 43.62, 43.62, 43.62, 43.62], "power_watts_avg": 39.42, "power_watts_peak": 43.62, "energy_joules_est": 32.15, "sample_count": 9, "duration_seconds": 0.816}, "timestamp": "2026-01-11T13:43:45.496712"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 765.189, "latencies_ms": [765.189], "images_per_second": 1.307, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Three cows are seen behind a barbed wire fence in a field. The black and white image captures a pastoral scene with grazing cattle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 43.45, 43.45, 43.45, 42.06, 42.06, 42.06], "power_watts_avg": 42.93, "power_watts_peak": 43.45, "energy_joules_est": 32.87, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-11T13:43:46.307968"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 869.405, "latencies_ms": [869.405], "images_per_second": 1.15, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cows are primarily black and white. The lighting suggests a bright, sunny day. The cows are seen in a grassy field with barbed wire fencing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.06, 45.21, 45.21, 45.21, 45.21, 45.21, 42.9, 42.9, 42.9], "power_watts_avg": 44.09, "power_watts_peak": 45.21, "energy_joules_est": 38.35, "sample_count": 9, "duration_seconds": 0.87}, "timestamp": "2026-01-11T13:43:47.218394"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 699.398, "latencies_ms": [699.398], "images_per_second": 1.43, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The room features a cozy and inviting atmosphere with a warm color scheme, a comfortable bed, a fireplace, a television, and two chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.9, 42.9, 48.05, 48.05, 48.05, 48.05, 48.05], "power_watts_avg": 46.58, "power_watts_peak": 48.05, "energy_joules_est": 32.61, "sample_count": 7, "duration_seconds": 0.7}, "timestamp": "2026-01-11T13:43:47.927559"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1225.321, "latencies_ms": [1225.321], "images_per_second": 0.816, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bed: 6\nchair: 2\nwindow: 2\nfireplace: 1\ntelevision: 1\nclock: 1\nlamp: 1\nsofa: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 43.09, 43.09, 43.09, 46.6, 46.6, 46.6, 46.6, 46.6, 43.91, 43.91, 43.91], "power_watts_avg": 44.63, "power_watts_peak": 46.6, "energy_joules_est": 54.7, "sample_count": 13, "duration_seconds": 1.226}, "timestamp": "2026-01-11T13:43:49.239002"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 966.203, "latencies_ms": [966.203], "images_per_second": 1.035, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and harmonious manner, with the bed dominating the left side of the image and the seating area on the right. The seating area is situated closer to the viewer, creating a sense of proximity and comfort.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.91, 43.91, 39.38, 39.38, 39.38, 39.38, 39.38, 42.58, 42.58, 42.58], "power_watts_avg": 41.25, "power_watts_peak": 43.91, "energy_joules_est": 39.86, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-11T13:43:50.249016"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 771.18, "latencies_ms": [771.18], "images_per_second": 1.297, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The scene depicts a cozy bedroom with a large bed, wooden furniture, and a fireplace. The room is lit by warm lighting, creating a comfortable and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.58, 42.58, 43.2, 43.2, 43.2, 43.2, 43.2, 42.93], "power_watts_avg": 43.01, "power_watts_peak": 43.2, "energy_joules_est": 33.2, "sample_count": 8, "duration_seconds": 0.772}, "timestamp": "2026-01-11T13:43:51.057574"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1012.937, "latencies_ms": [1012.937], "images_per_second": 0.987, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room features a warm color scheme with brown and beige tones. The lighting is soft and warm, creating a cozy atmosphere. The furniture includes wooden elements and a stone fireplace, adding a rustic touch to the space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 42.93, 42.93, 47.51, 47.51, 47.51, 47.51, 47.51, 43.63, 43.63], "power_watts_avg": 45.14, "power_watts_peak": 47.51, "energy_joules_est": 45.76, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-11T13:43:52.171093"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 618.453, "latencies_ms": [618.453], "images_per_second": 1.617, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Three black birds with white speckled feathers are walking across a dry, grassy hillside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.9, "ram_available_mb": 109425.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.63, 43.63, 43.63, 42.13, 42.13, 42.13, 42.13], "power_watts_avg": 42.77, "power_watts_peak": 43.63, "energy_joules_est": 26.47, "sample_count": 7, "duration_seconds": 0.619}, "timestamp": "2026-01-11T13:43:52.879963"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 802.777, "latencies_ms": [802.777], "images_per_second": 1.246, "prompt_tokens": 21, "response_tokens_est": 19, "n_tiles": 1, "output_text": "bird: 3\ngrass: 2\ntree: 1\nbush: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 19.0}, "power_stats": {"power_watts_samples": [42.13, 40.6, 40.6, 40.6, 40.6, 40.6, 42.73, 42.73], "power_watts_avg": 41.32, "power_watts_peak": 42.73, "energy_joules_est": 33.2, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-11T13:43:53.690619"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 915.817, "latencies_ms": [915.817], "images_per_second": 1.092, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a background of dry grass and trees. The foreground is dominated by the dry grass, while the background features more vegetation and trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 52.84, 52.84, 52.84, 52.84, 52.84, 44.06, 44.06], "power_watts_avg": 48.05, "power_watts_peak": 52.84, "energy_joules_est": 44.03, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-11T13:43:54.697376"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.684, "latencies_ms": [828.684], "images_per_second": 1.207, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Three black birds with blue heads and necks are walking across a dry, grassy hillside.  The birds appear to be grazing or foraging in the sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 44.06, 43.85, 43.85, 43.85, 43.85, 42.63, 42.63], "power_watts_avg": 43.65, "power_watts_peak": 44.06, "energy_joules_est": 36.19, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:43:55.609890"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1161.861, "latencies_ms": [1161.861], "images_per_second": 0.861, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The birds have dark gray plumage with black speckles. Their feathers appear slightly ruffled, giving them a somewhat mottled appearance. The lighting suggests an overcast sky, casting a soft, diffused light across the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [42.63, 42.63, 42.63, 43.64, 43.64, 43.64, 43.64, 43.64, 42.51, 42.51, 42.51, 42.51], "power_watts_avg": 43.01, "power_watts_peak": 43.64, "energy_joules_est": 50.0, "sample_count": 12, "duration_seconds": 1.163}, "timestamp": "2026-01-11T13:43:56.822509"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 626.884, "latencies_ms": [626.884], "images_per_second": 1.595, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Three people are posing for a photo on a snowy hill, wearing winter gear and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 34.0}, "power_stats": {"power_watts_samples": [42.51, 35.69, 35.69, 35.69, 35.69, 35.69, 43.05], "power_watts_avg": 37.71, "power_watts_peak": 43.05, "energy_joules_est": 23.66, "sample_count": 7, "duration_seconds": 0.627}, "timestamp": "2026-01-11T13:43:57.532241"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1354.025, "latencies_ms": [1354.025], "images_per_second": 0.739, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "snowboard: 2\nsnowshoes: 2\nsnow poles: 4\ngoggles: 1\njacket: 2\nhat: 1\nbackpack: 1\nsnow: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 43.05, 51.3, 51.3, 51.3, 51.3, 51.3, 42.96, 42.96, 42.96, 42.96, 42.96], "power_watts_avg": 45.96, "power_watts_peak": 51.3, "energy_joules_est": 62.26, "sample_count": 14, "duration_seconds": 1.355}, "timestamp": "2026-01-11T13:43:58.945769"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 977.634, "latencies_ms": [977.634], "images_per_second": 1.023, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The three people are positioned in a snowy landscape, with the person on the left closest to the camera and the person on the right furthest away. The foreground is dominated by the snow-covered ground, while the background features snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.82, 33.82, 33.82, 33.82, 33.82, 43.13, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 38.48, "power_watts_peak": 43.13, "energy_joules_est": 37.64, "sample_count": 10, "duration_seconds": 0.978}, "timestamp": "2026-01-11T13:43:59.956244"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 958.546, "latencies_ms": [958.546], "images_per_second": 1.043, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Three people are snowshoeing on a snowy slope in a forested area. They are dressed in winter gear and holding ski poles, enjoying a winter activity amidst the snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.48, 43.48, 43.48, 43.59, 43.59, 43.59, 43.59, 43.59], "power_watts_avg": 43.54, "power_watts_peak": 43.59, "energy_joules_est": 41.74, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-11T13:44:00.963815"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 956.676, "latencies_ms": [956.676], "images_per_second": 1.045, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The snow is white and appears well-groomed. The lighting is bright and evenly distributed, illuminating the scene. The snow appears to be fresh and undisturbed, suggesting good weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.3, "ram_available_mb": 109424.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 43.44, 43.44, 43.44, 43.11, 43.11, 43.11, 43.11, 43.11], "power_watts_avg": 43.28, "power_watts_peak": 43.44, "energy_joules_est": 41.43, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:44:01.975378"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 785.401, "latencies_ms": [785.401], "images_per_second": 1.273, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A white and blue city bus numbered 51 is parked on the side of the road, displaying \"Crosstown\" on its electronic sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.06, 43.06, 43.06, 43.06, 43.06, 44.24, 44.24, 44.24], "power_watts_avg": 43.5, "power_watts_peak": 44.24, "energy_joules_est": 34.19, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:44:02.787518"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2139.501, "latencies_ms": [2139.501], "images_per_second": 0.467, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "Bus: 2\nNumber plate: 1\nLicense plate: 1\nBus number: 51\nBus route: Crosstown\nBus front: 2\nBus windows: 2\nBus headlights: 2\nBus windshield wipers: 2\nBus front bumper: 2\nBus side mirrors: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.24, 44.24, 48.45, 48.45, 48.45, 48.45, 48.45, 44.9, 44.9, 44.9, 44.9, 44.9, 40.6, 40.6, 40.6, 40.6, 40.6, 33.95, 33.95, 33.95, 33.95, 33.95], "power_watts_avg": 42.18, "power_watts_peak": 48.45, "energy_joules_est": 90.27, "sample_count": 22, "duration_seconds": 2.14}, "timestamp": "2026-01-11T13:44:05.003842"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 996.613, "latencies_ms": [996.613], "images_per_second": 1.003, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, facing the viewer. The building is partially visible in the background, situated to the right of the bus. The bus is parked on the street, further back from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.91, 33.91, 33.91, 33.91, 42.68, 42.68, 42.68, 42.68, 42.68, 42.67], "power_watts_avg": 39.17, "power_watts_peak": 42.68, "energy_joules_est": 39.06, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-11T13:44:06.062969"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1325.421, "latencies_ms": [1325.421], "images_per_second": 0.754, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "A white and blue bus is parked on the side of a road, displaying the number 51 and the destination \"Crosstown.\" A person can be seen standing near the bus, possibly waiting to board or observing the bus. The setting appears to be an urban environment with a brick building visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 42.67, 44.56, 44.56, 44.56, 44.56, 44.56, 44.73, 44.73, 44.73, 44.73, 44.73], "power_watts_avg": 44.08, "power_watts_peak": 44.73, "energy_joules_est": 58.47, "sample_count": 14, "duration_seconds": 1.326}, "timestamp": "2026-01-11T13:44:07.473756"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1163.754, "latencies_ms": [1163.754], "images_per_second": 0.859, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The bus is primarily white with blue and green accents. The lighting appears to be bright and sunny, illuminating the bus and its surroundings. The materials appear to be standard bus construction, with clear glass windows and metal framing. The weather appears to be sunny and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.7, 33.7, 33.7, 33.7, 33.7, 43.65, 43.65, 43.65, 43.65, 43.65, 43.85, 43.85], "power_watts_avg": 39.54, "power_watts_peak": 43.85, "energy_joules_est": 46.03, "sample_count": 12, "duration_seconds": 1.164}, "timestamp": "2026-01-11T13:44:08.684059"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 919.376, "latencies_ms": [919.376], "images_per_second": 1.088, "prompt_tokens": 8, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A man dressed in a blue blazer, white collared shirt, striped tie, gray pleated skirt, black tights, and black shoes is standing against a white wall, holding a black purse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [43.85, 43.85, 43.85, 36.94, 36.94, 36.94, 36.94, 36.94, 37.02, 37.02], "power_watts_avg": 39.03, "power_watts_peak": 43.85, "energy_joules_est": 35.92, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-11T13:44:09.695374"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1153.521, "latencies_ms": [1153.521], "images_per_second": 0.867, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Jacket: 2\nSkirt: 1\nTie: 1\nShirt: 1\nPants: 1\nTights: 1\nHandbag: 1\nShoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.2, "ram_available_mb": 109424.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [37.02, 37.02, 37.02, 36.91, 36.91, 36.91, 36.91, 36.91, 37.16, 37.16, 37.16, 37.16], "power_watts_avg": 37.02, "power_watts_peak": 37.16, "energy_joules_est": 42.72, "sample_count": 12, "duration_seconds": 1.154}, "timestamp": "2026-01-11T13:44:10.904192"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 859.436, "latencies_ms": [859.436], "images_per_second": 1.164, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The man is positioned in the foreground, wearing a school uniform and holding a handbag. The handbag is situated near his feet. The background features a white wall with a red stripe, providing a neutral backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.2, "ram_available_mb": 109424.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.2, "ram_available_mb": 109424.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [37.16, 33.28, 33.28, 33.28, 33.28, 37.88, 37.88, 37.88, 37.88], "power_watts_avg": 35.76, "power_watts_peak": 37.88, "energy_joules_est": 30.76, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-11T13:44:11.814704"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 990.981, "latencies_ms": [990.981], "images_per_second": 1.009, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A young man is standing in a school uniform, wearing a blue blazer, white shirt, and striped tie. He is dressed in a gray pleated skirt and carrying a black handbag. The setting appears to be a school hallway or corridor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.2, "ram_available_mb": 109424.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.2, "ram_available_mb": 109424.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 36.0}, "power_stats": {"power_watts_samples": [37.88, 40.91, 40.91, 40.91, 40.91, 40.91, 37.9, 37.9, 37.9, 37.9], "power_watts_avg": 39.41, "power_watts_peak": 40.91, "energy_joules_est": 39.06, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-11T13:44:12.823944"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1408.509, "latencies_ms": [1408.509], "images_per_second": 0.71, "prompt_tokens": 18, "response_tokens_est": 74, "n_tiles": 1, "output_text": "The man's attire is predominantly blue and gray, accented with red and blue stripes. The lighting appears to be artificial, casting a soft glow on his outfit. The materials appear to be standard school uniforms, composed of fabric and possibly some synthetic elements. The weather appears to be cool and possibly rainy, as evidenced by the dark shoes and the presence of a bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.2, "ram_available_mb": 109424.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.9, 37.8, 37.8, 37.8, 37.8, 37.8, 37.83, 37.83, 37.83, 37.83, 37.83, 35.62, 35.62, 35.62, 35.62], "power_watts_avg": 37.24, "power_watts_peak": 37.9, "energy_joules_est": 52.47, "sample_count": 15, "duration_seconds": 1.409}, "timestamp": "2026-01-11T13:44:14.336276"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 635.246, "latencies_ms": [635.246], "images_per_second": 1.574, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A train yard filled with multiple train cars and tracks is visible in the hazy image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.62, 33.55, 33.55, 33.55, 33.55, 33.55, 41.44], "power_watts_avg": 34.98, "power_watts_peak": 41.44, "energy_joules_est": 22.24, "sample_count": 7, "duration_seconds": 0.636}, "timestamp": "2026-01-11T13:44:15.046863"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1178.743, "latencies_ms": [1178.743], "images_per_second": 0.848, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Train car: 5\nTrain cars: 6\nTrain tracks: 4\nPower lines: 6\nTrees: 2\nBuilding: 1\nFog: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.44, 41.44, 41.44, 41.44, 50.96, 50.96, 50.96, 50.96, 50.96, 43.01, 43.01, 43.01], "power_watts_avg": 45.8, "power_watts_peak": 50.96, "energy_joules_est": 54.0, "sample_count": 12, "duration_seconds": 1.179}, "timestamp": "2026-01-11T13:44:16.259290"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 778.25, "latencies_ms": [778.25], "images_per_second": 1.285, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the train cars extending into the background. The train tracks run parallel to the train cars, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 39.63, 39.63, 39.63, 39.63, 39.63, 43.77], "power_watts_avg": 40.99, "power_watts_peak": 43.77, "energy_joules_est": 31.92, "sample_count": 8, "duration_seconds": 0.779}, "timestamp": "2026-01-11T13:44:17.069351"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1233.263, "latencies_ms": [1233.263], "images_per_second": 0.811, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene depicts a train yard or rail yard with multiple train cars and tracks. The image is captured in sepia tones, giving it a vintage or nostalgic feel. The hazy atmosphere and limited visibility suggest it might be early morning or late evening.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.77, 43.77, 43.77, 43.77, 49.05, 49.05, 49.05, 49.05, 49.05, 43.94, 43.94, 43.94, 43.94], "power_watts_avg": 45.85, "power_watts_peak": 49.05, "energy_joules_est": 56.56, "sample_count": 13, "duration_seconds": 1.234}, "timestamp": "2026-01-11T13:44:18.381235"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1476.695, "latencies_ms": [1476.695], "images_per_second": 0.677, "prompt_tokens": 18, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene is dominated by muted, brownish-gold hues, creating a somber atmosphere. The lighting suggests an overcast or hazy day, with soft, diffused light filtering through the haze. Visible materials include metal, wood, and possibly plastic or concrete, contributing to the industrial feel of the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.6, "ram_available_mb": 109423.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.94, 32.12, 32.12, 32.12, 32.12, 32.12, 42.83, 42.83, 42.83, 42.83, 42.83, 44.51, 44.51, 44.51, 44.51], "power_watts_avg": 39.78, "power_watts_peak": 44.51, "energy_joules_est": 58.76, "sample_count": 15, "duration_seconds": 1.477}, "timestamp": "2026-01-11T13:44:19.895318"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 665.264, "latencies_ms": [665.264], "images_per_second": 1.503, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A bathroom floor is cluttered with various items, including skis, gloves, a helmet, a potted plant, a toilet, a sink, and a towel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [44.51, 33.21, 33.21, 33.21, 33.21, 33.21, 37.89], "power_watts_avg": 35.49, "power_watts_peak": 44.51, "energy_joules_est": 23.63, "sample_count": 7, "duration_seconds": 0.666}, "timestamp": "2026-01-11T13:44:20.605268"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1182.415, "latencies_ms": [1182.415], "images_per_second": 0.846, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "toilet: 1\nplant: 1\nsnowboard: 1\ngloves: 2\nskis: 2\nhelmet: 1\nshoes: 4\nclothes: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.89, 37.89, 37.89, 42.87, 42.87, 42.87, 42.87, 42.87, 38.2, 38.2, 38.2, 38.2], "power_watts_avg": 40.07, "power_watts_peak": 42.87, "energy_joules_est": 47.4, "sample_count": 12, "duration_seconds": 1.183}, "timestamp": "2026-01-11T13:44:21.817122"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 617.006, "latencies_ms": [617.006], "images_per_second": 1.621, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The toilet is positioned to the left of the image, near the foreground. The skis are located in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [38.2, 36.84, 36.84, 36.84, 36.84, 36.84, 38.31], "power_watts_avg": 37.25, "power_watts_peak": 38.31, "energy_joules_est": 23.0, "sample_count": 7, "duration_seconds": 0.618}, "timestamp": "2026-01-11T13:44:22.526840"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 926.366, "latencies_ms": [926.366], "images_per_second": 1.079, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a bathroom with a toilet, sink, and various personal items scattered on the floor, including skis, gloves, and a helmet. The overall setting appears disorganized and possibly undergoing some cleaning or reorganization.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.31, 38.31, 38.31, 38.31, 39.19, 39.19, 39.19, 39.19, 39.19, 36.5], "power_watts_avg": 38.57, "power_watts_peak": 39.19, "energy_joules_est": 35.76, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-11T13:44:23.538310"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 887.502, "latencies_ms": [887.502], "images_per_second": 1.127, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bathroom features a white toilet and a small plant on a stand. The floor is covered in skis and ski boots, indicating skiing activities. The lighting is dim, contributing to the overall subdued atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.5, 36.5, 36.5, 36.5, 37.33, 37.33, 37.33, 37.33, 37.33], "power_watts_avg": 36.96, "power_watts_peak": 37.33, "energy_joules_est": 32.83, "sample_count": 9, "duration_seconds": 0.888}, "timestamp": "2026-01-11T13:44:24.448483"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 657.536, "latencies_ms": [657.536], "images_per_second": 1.521, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A polar bear is playing with colorful balls in a pool of water, appearing to be enjoying its time outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.32, 37.32, 37.32, 37.32, 37.32, 43.69, 43.69], "power_watts_avg": 39.14, "power_watts_peak": 43.69, "energy_joules_est": 25.76, "sample_count": 7, "duration_seconds": 0.658}, "timestamp": "2026-01-11T13:44:25.159496"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1098.049, "latencies_ms": [1098.049], "images_per_second": 0.911, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "ball: 3\npaw: 2\ntowel: 1\nwater: 2\nsand: 1\nrocks: 1\nzoo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 43.69, 53.17, 53.17, 53.17, 53.17, 53.17, 43.45, 43.45, 43.45], "power_watts_avg": 47.93, "power_watts_peak": 53.17, "energy_joules_est": 52.64, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-11T13:44:26.270077"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 868.474, "latencies_ms": [868.474], "images_per_second": 1.151, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The green and yellow balls are positioned in the foreground, close to the polar bear. The background features the rocky terrain and sand, suggesting the polar bear is in a zoo enclosure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 39.43, 39.43, 39.43, 39.43, 39.43, 43.66, 43.66], "power_watts_avg": 41.27, "power_watts_peak": 43.66, "energy_joules_est": 35.86, "sample_count": 9, "duration_seconds": 0.869}, "timestamp": "2026-01-11T13:44:27.178406"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 721.907, "latencies_ms": [721.907], "images_per_second": 1.385, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A polar bear is playing with colorful balls in a pool of water. The setting appears to be a zoo enclosure with rocks and sandy ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.66, 43.66, 43.66, 48.2, 48.2, 48.2, 48.2, 48.2], "power_watts_avg": 46.49, "power_watts_peak": 48.2, "energy_joules_est": 33.59, "sample_count": 8, "duration_seconds": 0.722}, "timestamp": "2026-01-11T13:44:27.986960"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 711.052, "latencies_ms": [711.052], "images_per_second": 1.406, "prompt_tokens": 18, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The polar bear is predominantly white. The water appears dark and murky. The bear is playing with colorful balls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.63, 43.63, 43.63, 43.63, 43.63, 43.12, 43.12, 43.12], "power_watts_avg": 43.44, "power_watts_peak": 43.63, "energy_joules_est": 30.91, "sample_count": 8, "duration_seconds": 0.712}, "timestamp": "2026-01-11T13:44:28.795749"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 736.614, "latencies_ms": [736.614], "images_per_second": 1.358, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A person is sitting on a wooden chair wearing blue slippers and jeans, while holding a Samsung cell phone in their right hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 58.0}, "power_stats": {"power_watts_samples": [43.12, 43.12, 45.06, 45.06, 45.06, 45.06, 45.06, 42.4], "power_watts_avg": 44.25, "power_watts_peak": 45.06, "energy_joules_est": 32.62, "sample_count": 8, "duration_seconds": 0.737}, "timestamp": "2026-01-11T13:44:29.606223"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1122.753, "latencies_ms": [1122.753], "images_per_second": 0.891, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "chair: 2\nslippers: 2\nsocks: 2\nphone: 1\nwindow: 1\nwooden floor: 4\nblue jeans: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [42.4, 42.4, 42.4, 42.4, 49.84, 49.84, 49.84, 49.84, 42.74, 42.74, 42.74, 42.74], "power_watts_avg": 45.0, "power_watts_peak": 49.84, "energy_joules_est": 50.54, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:44:30.819116"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 742.387, "latencies_ms": [742.387], "images_per_second": 1.347, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The chair is positioned in the foreground, while the cell phone is held in the background. The chair and cell phone are located near each other, suggesting proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 35.0}, "power_stats": {"power_watts_samples": [42.74, 34.93, 34.93, 34.93, 34.93, 34.93, 42.63, 42.63], "power_watts_avg": 37.83, "power_watts_peak": 42.74, "energy_joules_est": 28.11, "sample_count": 8, "duration_seconds": 0.743}, "timestamp": "2026-01-11T13:44:31.629542"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1016.904, "latencies_ms": [1016.904], "images_per_second": 0.983, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts a person sitting on a wooden chair, wearing blue slippers and jeans. The right side shows a Samsung cell phone being held by a hand, displaying the time and possibly a text message.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [42.63, 42.63, 42.63, 51.47, 51.47, 51.47, 51.47, 51.47, 43.04, 43.04, 43.04], "power_watts_avg": 46.76, "power_watts_peak": 51.47, "energy_joules_est": 47.57, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-11T13:44:32.741739"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 956.585, "latencies_ms": [956.585], "images_per_second": 1.045, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The chair is light brown and appears to be made of wood. The floor is made of polished wood planks. The lighting in the image is soft and diffused, suggesting natural light from a nearby window.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.8, "ram_available_mb": 109422.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.04, 43.04, 39.62, 39.62, 39.62, 39.62, 39.62, 42.7, 42.7, 42.7], "power_watts_avg": 41.23, "power_watts_peak": 43.04, "energy_joules_est": 39.46, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:44:33.752545"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 649.258, "latencies_ms": [649.258], "images_per_second": 1.54, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A yellow and black train travels down a snowy track, passing through a forest of snow-covered trees and bushes.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13083.8, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.7, 42.7, 43.42, 43.42, 43.42, 43.42, 43.42], "power_watts_avg": 43.22, "power_watts_peak": 43.42, "energy_joules_est": 28.09, "sample_count": 7, "duration_seconds": 0.65}, "timestamp": "2026-01-11T13:44:34.465227"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1413.002, "latencies_ms": [1413.002], "images_per_second": 0.708, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Train: 1\nTrees: 6\nSnow: 6\nSky: 1\nTrain tracks: 2\nPower lines: 2\nTraffic light: 1\nSnow-covered ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.54, 44.54, 44.54, 44.54, 44.54, 48.4, 48.4, 48.4, 48.4, 48.4, 44.05, 44.05, 44.05, 44.05, 44.05], "power_watts_avg": 45.66, "power_watts_peak": 48.4, "energy_joules_est": 64.55, "sample_count": 15, "duration_seconds": 1.414}, "timestamp": "2026-01-11T13:44:35.980635"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 823.455, "latencies_ms": [823.455], "images_per_second": 1.214, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The train is moving from left to right, occupying the foreground of the image. The snowy landscape and trees in the background create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.56, 33.56, 33.56, 33.56, 33.56, 43.56, 43.56, 43.56, 43.56], "power_watts_avg": 38.0, "power_watts_peak": 43.56, "energy_joules_est": 31.31, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-11T13:44:36.892656"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 974.406, "latencies_ms": [974.406], "images_per_second": 1.026, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A yellow train travels through a snowy landscape, passing through a forest of snow-covered trees. The scene is captured from a distance, emphasizing the vastness of the snowy terrain and the train's journey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.7, "ram_available_mb": 109422.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.2, "ram_available_mb": 109423.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 30.0}, "power_stats": {"power_watts_samples": [43.56, 41.84, 41.84, 41.84, 41.84, 41.84, 43.83, 43.83, 43.83, 43.83], "power_watts_avg": 42.81, "power_watts_peak": 43.83, "energy_joules_est": 41.74, "sample_count": 10, "duration_seconds": 0.975}, "timestamp": "2026-01-11T13:44:37.904418"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1115.074, "latencies_ms": [1115.074], "images_per_second": 0.897, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The train is yellow and appears to be moving through the snowy landscape. The lighting is soft and diffused, typical of overcast conditions. The scene is dominated by shades of white and gray, reflecting the snow and sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13083.2, "ram_available_mb": 109423.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.83, 44.62, 44.62, 44.62, 44.62, 44.62, 44.76, 44.76, 44.76, 44.76, 45.58, 45.58], "power_watts_avg": 44.76, "power_watts_peak": 45.58, "energy_joules_est": 49.93, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-11T13:44:39.117058"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 631.444, "latencies_ms": [631.444], "images_per_second": 1.584, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "People are walking through a large pile of snow on a city street, navigating the snow-covered path.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.58, 45.58, 45.58, 42.52, 42.52, 42.52, 42.52], "power_watts_avg": 43.83, "power_watts_peak": 45.58, "energy_joules_est": 27.7, "sample_count": 7, "duration_seconds": 0.632}, "timestamp": "2026-01-11T13:44:39.829404"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1076.185, "latencies_ms": [1076.185], "images_per_second": 0.929, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "snow: 10\nfire hydrant: 1\npiles of snow: 5\npeople walking: 4\ncar: 1\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.52, 44.83, 44.83, 44.83, 44.83, 44.83, 42.19, 42.19, 42.19, 42.19, 42.19], "power_watts_avg": 43.42, "power_watts_peak": 44.83, "energy_joules_est": 46.75, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-11T13:44:40.941322"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 931.537, "latencies_ms": [931.537], "images_per_second": 1.073, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The snow pile is positioned to the left of the foreground, partially obscuring the view of the street and sidewalk.  In the background, several people can be seen walking along the snow-covered sidewalk and road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.1, "ram_available_mb": 109423.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [40.96, 40.96, 40.96, 40.96, 40.96, 43.4, 43.4, 43.4, 43.4, 43.4], "power_watts_avg": 42.18, "power_watts_peak": 43.4, "energy_joules_est": 39.32, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-11T13:44:41.948802"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 943.512, "latencies_ms": [943.512], "images_per_second": 1.06, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A group of people are walking through a snowy city street, navigating around large piles of snow. A fire hydrant is partially buried in the snow, highlighting the significant snow accumulation in the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.97, 42.97, 42.97, 42.97, 42.97, 42.68, 42.68, 42.68, 42.68, 42.68], "power_watts_avg": 42.82, "power_watts_peak": 42.97, "energy_joules_est": 40.42, "sample_count": 10, "duration_seconds": 0.944}, "timestamp": "2026-01-11T13:44:42.959863"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1099.876, "latencies_ms": [1099.876], "images_per_second": 0.909, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The snow is white and appears quite thick and heavy. The lighting suggests an overcast day, with diffused light that doesn't cast harsh shadows. The snow appears to be made of ice and snow, with a dark gray or black color.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.89, 42.89, 42.89, 42.89, 42.89, 43.01, 43.01, 43.01, 43.01, 43.01, 43.61], "power_watts_avg": 43.01, "power_watts_peak": 43.61, "energy_joules_est": 47.34, "sample_count": 11, "duration_seconds": 1.101}, "timestamp": "2026-01-11T13:44:44.072297"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 599.705, "latencies_ms": [599.705], "images_per_second": 1.667, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A yellow and black sign with a cartoonish mouth is attached to a metal pole near a tree in a park-like setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.61, 43.61, 43.61, 43.61, 38.55, 38.55], "power_watts_avg": 41.92, "power_watts_peak": 43.61, "energy_joules_est": 25.15, "sample_count": 6, "duration_seconds": 0.6}, "timestamp": "2026-01-11T13:44:44.682311"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 935.529, "latencies_ms": [935.529], "images_per_second": 1.069, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Tow Zone: 1\nNo Parking sign: 1\nYellow sign: 1\nStreet light: 1\nBuilding: 1\nTrees: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.55, 38.55, 38.55, 43.37, 43.37, 43.37, 43.37, 43.37, 39.0, 39.0], "power_watts_avg": 41.05, "power_watts_peak": 43.37, "energy_joules_est": 38.42, "sample_count": 10, "duration_seconds": 0.936}, "timestamp": "2026-01-11T13:44:45.694933"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 731.089, "latencies_ms": [731.089], "images_per_second": 1.368, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The large tree on the left dominates the foreground, partially obscuring the background buildings. The yellow sign is positioned near the tree, slightly further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.0, 39.0, 39.0, 37.92, 37.92, 37.92, 37.92, 37.92], "power_watts_avg": 38.33, "power_watts_peak": 39.0, "energy_joules_est": 28.03, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:44:46.504377"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 854.106, "latencies_ms": [854.106], "images_per_second": 1.171, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a street corner with two signs: a no parking sign and a yellow and black sign attached to a pole. The signs are situated amidst lush green trees, creating a pleasant and visually appealing environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.86, 37.86, 37.86, 37.86, 37.86, 37.67, 37.67, 37.67, 37.67], "power_watts_avg": 37.77, "power_watts_peak": 37.86, "energy_joules_est": 32.27, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-11T13:44:47.414939"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 697.428, "latencies_ms": [697.428], "images_per_second": 1.434, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The sign is primarily white with red lettering. The lighting suggests a sunny day. The sign appears to be made of metal and has a weathered appearance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.67, 36.67, 36.67, 36.67, 36.67, 37.66, 37.66], "power_watts_avg": 36.96, "power_watts_peak": 37.66, "energy_joules_est": 25.79, "sample_count": 7, "duration_seconds": 0.698}, "timestamp": "2026-01-11T13:44:48.125461"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 610.045, "latencies_ms": [610.045], "images_per_second": 1.639, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A beige teddy bear wearing glasses sits on a red surface with a keyboard, mouse, microphone, and iPod.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.66, 37.66, 37.66, 42.9, 42.9, 42.9, 42.9], "power_watts_avg": 40.65, "power_watts_peak": 42.9, "energy_joules_est": 24.82, "sample_count": 7, "duration_seconds": 0.611}, "timestamp": "2026-01-11T13:44:48.834671"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1012.752, "latencies_ms": [1012.752], "images_per_second": 0.987, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "bear: 1\nglasses: 1\niPod: 1\nmicrophone: 1\nkeyboard: 1\nmouse: 1\nred surface: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [42.9, 39.57, 39.57, 39.57, 39.57, 39.57, 37.04, 37.04, 37.04, 37.04, 37.04], "power_watts_avg": 38.72, "power_watts_peak": 42.9, "energy_joules_est": 39.24, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:44:49.945203"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 714.581, "latencies_ms": [714.581], "images_per_second": 1.399, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The teddy bear is positioned in the foreground, slightly to the right of the keyboard. The keyboard and teddy bear are placed close together, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [35.05, 35.05, 35.05, 35.05, 35.05, 36.73, 36.73, 36.73], "power_watts_avg": 35.68, "power_watts_peak": 36.73, "energy_joules_est": 25.52, "sample_count": 8, "duration_seconds": 0.715}, "timestamp": "2026-01-11T13:44:50.754423"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 761.839, "latencies_ms": [761.839], "images_per_second": 1.313, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A teddy bear wearing glasses sits on a red surface, connected to a computer via cables.  A microphone, keyboard, and iPod are also present on the table.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [36.73, 36.73, 41.28, 41.28, 41.28, 41.28, 41.28, 37.07], "power_watts_avg": 39.62, "power_watts_peak": 41.28, "energy_joules_est": 30.19, "sample_count": 8, "duration_seconds": 0.762}, "timestamp": "2026-01-11T13:44:51.563924"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 905.176, "latencies_ms": [905.176], "images_per_second": 1.105, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The teddy bear is light brown and wears glasses. The lighting is dim, creating a moody atmosphere. The teddy bear appears to be made of a soft, plush material. The background is a dark blue wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.07, 37.07, 37.07, 37.07, 38.04, 38.04, 38.04, 38.04, 38.04], "power_watts_avg": 37.61, "power_watts_peak": 38.04, "energy_joules_est": 34.05, "sample_count": 9, "duration_seconds": 0.905}, "timestamp": "2026-01-11T13:44:52.474468"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 666.309, "latencies_ms": [666.309], "images_per_second": 1.501, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A skier in an orange suit is captured mid-air, performing a trick on a snowy slope with trees and a rocky hillside in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.0, 38.0, 38.0, 38.0, 38.0, 38.82, 38.82], "power_watts_avg": 38.24, "power_watts_peak": 38.82, "energy_joules_est": 25.5, "sample_count": 7, "duration_seconds": 0.667}, "timestamp": "2026-01-11T13:44:53.185868"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1214.186, "latencies_ms": [1214.186], "images_per_second": 0.824, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "skier: 2\nskis: 2\nsnow: 2\nhill: 1\ntree: 1\nlog: 1\nsnowboard: 0\ngloves: 2\nhelmet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.82, 38.82, 38.82, 43.17, 43.17, 43.17, 43.17, 43.17, 38.31, 38.31, 38.31, 38.31, 38.31], "power_watts_avg": 40.3, "power_watts_peak": 43.17, "energy_joules_est": 48.95, "sample_count": 13, "duration_seconds": 1.215}, "timestamp": "2026-01-11T13:44:54.501016"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 819.87, "latencies_ms": [819.87], "images_per_second": 1.22, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, mid-jump, with the snowy mountain and trees in the background. The image captures the dynamic motion of the skier against the serene, snowy landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.05, 34.05, 34.05, 34.05, 34.05, 36.62, 36.62, 36.62, 36.62], "power_watts_avg": 35.2, "power_watts_peak": 36.62, "energy_joules_est": 28.88, "sample_count": 9, "duration_seconds": 0.82}, "timestamp": "2026-01-11T13:44:55.411635"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 705.12, "latencies_ms": [705.12], "images_per_second": 1.418, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A skier is captured mid-air, performing a trick on a snowy slope. The scene is set against a backdrop of a snow-covered mountain under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 34.73, 34.73, 37.03, 37.03, 37.03], "power_watts_avg": 35.59, "power_watts_peak": 37.03, "energy_joules_est": 25.11, "sample_count": 8, "duration_seconds": 0.706}, "timestamp": "2026-01-11T13:44:56.217501"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1065.685, "latencies_ms": [1065.685], "images_per_second": 0.938, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The skier is wearing bright orange clothing. The lighting is bright and sunny, creating a contrast against the white snow. The skier is captured mid-air, showcasing their skill and athleticism. The snowy mountain landscape adds to the picturesque setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.03, 37.03, 41.76, 41.76, 41.76, 41.76, 41.76, 36.77, 36.77, 36.77, 36.77], "power_watts_avg": 39.09, "power_watts_peak": 41.76, "energy_joules_est": 41.67, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-11T13:44:57.329813"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 817.421, "latencies_ms": [817.421], "images_per_second": 1.223, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two surfers in wetsuits ride waves in the ocean, one standing on a green surfboard and the other crouched on a yellow surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.77, 36.4, 36.4, 36.4, 36.4, 36.4, 44.45, 44.45, 44.45], "power_watts_avg": 39.12, "power_watts_peak": 44.45, "energy_joules_est": 31.99, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:44:58.242302"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 869.014, "latencies_ms": [869.014], "images_per_second": 1.151, "prompt_tokens": 21, "response_tokens_est": 23, "n_tiles": 1, "output_text": "waves: 2\nsurfers: 2\nsurfboards: 2\nwater: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.45, 44.45, 48.56, 48.56, 48.56, 48.56, 48.56, 43.65, 43.65], "power_watts_avg": 46.55, "power_watts_peak": 48.56, "energy_joules_est": 40.48, "sample_count": 9, "duration_seconds": 0.87}, "timestamp": "2026-01-11T13:44:59.152632"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1165.593, "latencies_ms": [1165.593], "images_per_second": 0.858, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects are positioned relatively close to the viewer, creating a sense of proximity and depth. The foreground features the surfers, while the background showcases the vast expanse of the ocean. The scene appears to be captured from a distance, emphasizing the vastness and scale of the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 43.65, 48.11, 48.11, 48.11, 48.11, 48.11, 44.65, 44.65, 44.65, 44.65], "power_watts_avg": 45.84, "power_watts_peak": 48.11, "energy_joules_est": 53.45, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-11T13:45:00.365474"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 865.864, "latencies_ms": [865.864], "images_per_second": 1.155, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two surfers are riding waves in the ocean. The scene is dynamic and energetic, capturing the thrill of surfing amidst the vastness of the sea.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.65, 34.54, 34.54, 34.54, 34.54, 34.54, 44.3, 44.3, 44.3], "power_watts_avg": 38.91, "power_watts_peak": 44.65, "energy_joules_est": 33.72, "sample_count": 9, "duration_seconds": 0.866}, "timestamp": "2026-01-11T13:45:01.277043"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1181.184, "latencies_ms": [1181.184], "images_per_second": 0.847, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The ocean is a deep blue, suggesting low light conditions, possibly near dawn or dusk. The lighting is soft and diffused, possibly indicating a cloudy or overcast sky. Visible materials include waves, ocean water, and surfboards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.3, 44.3, 50.35, 50.35, 50.35, 50.35, 50.35, 44.57, 44.57, 44.57, 44.57, 44.57], "power_watts_avg": 46.93, "power_watts_peak": 50.35, "energy_joules_est": 55.46, "sample_count": 12, "duration_seconds": 1.182}, "timestamp": "2026-01-11T13:45:02.489673"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 941.796, "latencies_ms": [941.796], "images_per_second": 1.062, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A freshly baked pizza with cheese, tomato sauce, onions, and pineapple chunks sits on a metal tray, accompanied by a fork, knife, and salt shaker on a blue table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.94, 39.94, 39.94, 39.94, 39.94, 43.46, 43.46, 43.46, 43.46, 43.46], "power_watts_avg": 41.7, "power_watts_peak": 43.46, "energy_joules_est": 39.29, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:45:03.502598"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1701.437, "latencies_ms": [1701.437], "images_per_second": 0.588, "prompt_tokens": 21, "response_tokens_est": 55, "n_tiles": 1, "output_text": "Pizza: 8\nPepper shaker: 1\nSalt shaker: 1\nFork: 1\nKnife: 1\nNapkin: 1\nCheese: 1\nTomato sauce: 1\nSpinach: 1\nPineapple: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.72, 43.72, 43.72, 43.72, 43.72, 43.17, 43.17, 43.17, 43.17, 43.17, 43.12, 43.12, 43.12, 43.12, 33.6, 33.6, 33.6], "power_watts_avg": 41.63, "power_watts_peak": 43.72, "energy_joules_est": 70.85, "sample_count": 17, "duration_seconds": 1.702}, "timestamp": "2026-01-11T13:45:05.220045"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 816.63, "latencies_ms": [816.63], "images_per_second": 1.225, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The pizza is positioned in the foreground, slightly to the right of the table. The table occupies the middle ground of the image, and the background is blurred and out of focus.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.6, 33.6, 42.26, 42.26, 42.26, 42.26, 42.26, 43.83, 43.83], "power_watts_avg": 40.69, "power_watts_peak": 43.83, "energy_joules_est": 33.25, "sample_count": 9, "duration_seconds": 0.817}, "timestamp": "2026-01-11T13:45:06.130735"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 985.075, "latencies_ms": [985.075], "images_per_second": 1.015, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set in a dimly lit restaurant or bar, showcasing a freshly baked pizza with toppings on a metal tray, accompanied by a salt shaker and a fork. The atmosphere is casual and relaxed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.83, 43.83, 43.83, 44.8, 44.8, 44.8, 44.8, 44.8, 42.48, 42.48], "power_watts_avg": 44.04, "power_watts_peak": 44.8, "energy_joules_est": 43.41, "sample_count": 10, "duration_seconds": 0.986}, "timestamp": "2026-01-11T13:45:07.142593"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 850.046, "latencies_ms": [850.046], "images_per_second": 1.176, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The pizza is topped with vibrant red sauce, melted cheese, and chunks of pineapple. The table is dark blue, and the lighting creates a warm, inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 43.66, 43.66, 43.66, 43.66, 43.66, 43.73], "power_watts_avg": 43.28, "power_watts_peak": 43.73, "energy_joules_est": 36.81, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-11T13:45:08.049865"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 667.779, "latencies_ms": [667.779], "images_per_second": 1.498, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A black metal clock with Roman numerals is mounted on a pole, displaying the time as approximately 2:55.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.73, 43.73, 43.14, 43.14, 43.14], "power_watts_avg": 43.47, "power_watts_peak": 43.73, "energy_joules_est": 29.06, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-11T13:45:08.760192"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1068.334, "latencies_ms": [1068.334], "images_per_second": 0.936, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "clock: 1\nstreet light: 1\nbuildings: 4\ncars: 2\ntrees: 1\nsnow: 2\npots: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [43.14, 43.14, 49.45, 49.45, 49.45, 49.45, 49.45, 43.6, 43.6, 43.6, 43.6], "power_watts_avg": 46.17, "power_watts_peak": 49.45, "energy_joules_est": 49.34, "sample_count": 11, "duration_seconds": 1.069}, "timestamp": "2026-01-11T13:45:09.867590"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 833.894, "latencies_ms": [833.894], "images_per_second": 1.199, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The clock is positioned in the foreground on the left side of the image, dominating the left side of the frame. The street and buildings extend into the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 51.0}, "power_stats": {"power_watts_samples": [43.6, 37.78, 37.78, 37.78, 37.78, 37.78, 43.52, 43.52, 43.52], "power_watts_avg": 40.34, "power_watts_peak": 43.6, "energy_joules_est": 33.66, "sample_count": 9, "duration_seconds": 0.834}, "timestamp": "2026-01-11T13:45:10.779091"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1520.757, "latencies_ms": [1520.757], "images_per_second": 0.658, "prompt_tokens": 19, "response_tokens_est": 75, "n_tiles": 1, "output_text": "The scene depicts a snowy street in a small town or village during winter. A large clock is prominently displayed on a post on the left side of the image. The street is lined with brick buildings, some with shops and businesses visible, and there are parked cars along the sides. The overall atmosphere is peaceful and quiet, typical of a quiet winter day in a small town.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 48.69, 48.69, 48.69, 48.69, 48.69, 42.94, 42.94, 42.94, 42.94, 42.94, 37.94, 37.94, 37.94, 37.94], "power_watts_avg": 43.56, "power_watts_peak": 48.69, "energy_joules_est": 66.26, "sample_count": 16, "duration_seconds": 1.521}, "timestamp": "2026-01-11T13:45:12.395969"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1154.745, "latencies_ms": [1154.745], "images_per_second": 0.866, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The buildings are primarily brick and painted in shades of red and beige. The street is lit by streetlights, creating a warm glow against the cold, snowy backdrop. The snow covers the ground and street, enhancing the winter ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.94, 31.71, 31.71, 31.71, 31.71, 31.71, 41.6, 41.6, 41.6, 41.6, 41.6, 43.82], "power_watts_avg": 37.36, "power_watts_peak": 43.82, "energy_joules_est": 43.16, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:45:13.609190"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 911.384, "latencies_ms": [911.384], "images_per_second": 1.097, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A baseball player in a white uniform with blue accents is swinging his bat, connecting with the ball mid-air, while a catcher in a red uniform crouches behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 43.82, 43.25, 43.25, 43.25, 43.25, 43.32, 43.32], "power_watts_avg": 43.49, "power_watts_peak": 43.82, "energy_joules_est": 39.66, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-11T13:45:14.622109"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1535.678, "latencies_ms": [1535.678], "images_per_second": 0.651, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball: 1\nbaseball glove: 1\nbaseball: 1\nbaseball field: 1\nbaseball player: 1\nbaseball umpire: 1\nbaseball umpire's mask: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.32, 43.32, 43.32, 42.46, 42.46, 42.46, 42.46, 42.46, 42.45, 42.45, 42.45, 42.45, 42.45, 33.96, 33.96, 33.96], "power_watts_avg": 41.02, "power_watts_peak": 43.32, "energy_joules_est": 63.02, "sample_count": 16, "duration_seconds": 1.536}, "timestamp": "2026-01-11T13:45:16.238279"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 649.715, "latencies_ms": [649.715], "images_per_second": 1.539, "prompt_tokens": 25, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the pitcher. The catcher is positioned in the background, behind the batter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.96, 33.96, 40.73, 40.73, 40.73, 40.73, 40.73], "power_watts_avg": 38.8, "power_watts_peak": 40.73, "energy_joules_est": 25.23, "sample_count": 7, "duration_seconds": 0.65}, "timestamp": "2026-01-11T13:45:16.948853"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1088.677, "latencies_ms": [1088.677], "images_per_second": 0.919, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter in a white uniform with blue accents is swinging at a pitched ball, while a catcher in a red uniform is crouched behind home plate, ready to receive the pitch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.48, 42.48, 42.48, 42.48, 42.48, 45.46, 45.46, 45.46, 45.46, 45.46, 43.63], "power_watts_avg": 43.94, "power_watts_peak": 45.46, "energy_joules_est": 47.86, "sample_count": 11, "duration_seconds": 1.089}, "timestamp": "2026-01-11T13:45:18.060553"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1144.314, "latencies_ms": [1144.314], "images_per_second": 0.874, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The baseball player is wearing a white and blue uniform. The lighting appears to be natural daylight, creating a bright and clear atmosphere on the field. The baseball is visible mid-flight, indicating a powerful swing. The overall setting suggests a sunny day at a professional baseball game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.63, 43.63, 43.63, 43.63, 44.11, 44.11, 44.11, 44.11, 44.11, 44.05, 44.05, 44.05], "power_watts_avg": 43.93, "power_watts_peak": 44.11, "energy_joules_est": 50.29, "sample_count": 12, "duration_seconds": 1.145}, "timestamp": "2026-01-11T13:45:19.273329"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 750.805, "latencies_ms": [750.805], "images_per_second": 1.332, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A brown teddy bear with a red bow tie sits comfortably on a wicker chair with a dark red cushion, positioned against a striped curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.05, 44.05, 39.38, 39.38, 39.38, 39.38, 39.38, 43.2], "power_watts_avg": 41.02, "power_watts_peak": 44.05, "energy_joules_est": 30.82, "sample_count": 8, "duration_seconds": 0.751}, "timestamp": "2026-01-11T13:45:20.084372"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1028.367, "latencies_ms": [1028.367], "images_per_second": 0.972, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "chair: 2\nteddy bear: 1\nwicker: 2\nred cushion: 1\nbow tie: 1\ncurtains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.2, 43.2, 43.2, 43.2, 47.39, 47.39, 47.39, 47.39, 47.39, 43.36, 43.36], "power_watts_avg": 45.13, "power_watts_peak": 47.39, "energy_joules_est": 46.44, "sample_count": 11, "duration_seconds": 1.029}, "timestamp": "2026-01-11T13:45:21.196617"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 857.838, "latencies_ms": [857.838], "images_per_second": 1.166, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The brown teddy bear is positioned in the foreground, slightly to the right of the wicker chair. The chair is situated in the background, partially obscured by the teddy bear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.36, 43.36, 43.36, 42.62, 42.62, 42.62, 42.62, 42.62, 42.82], "power_watts_avg": 42.89, "power_watts_peak": 43.36, "energy_joules_est": 36.81, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:45:22.108008"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 904.661, "latencies_ms": [904.661], "images_per_second": 1.105, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A brown teddy bear with a red bow sits on a wicker chair with a dark wooden backrest and armrests. A blue and white striped curtain is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.82, 43.28, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 43.08, "power_watts_peak": 43.28, "energy_joules_est": 38.99, "sample_count": 9, "duration_seconds": 0.905}, "timestamp": "2026-01-11T13:45:23.019295"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 840.95, "latencies_ms": [840.95], "images_per_second": 1.189, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The chair features a combination of brown and red colors. The lighting appears to be soft and warm, creating a cozy atmosphere. The chair is made of wicker and has a plush cushion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 44.11, 44.11, 44.11, 44.11, 44.11], "power_watts_avg": 43.63, "power_watts_peak": 44.11, "energy_joules_est": 36.7, "sample_count": 9, "duration_seconds": 0.841}, "timestamp": "2026-01-11T13:45:23.931061"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 756.427, "latencies_ms": [756.427], "images_per_second": 1.322, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two snowboarders, dressed in red jackets and helmets, stand on a snowy mountain peak, preparing to descend the slopes under a bright, sunny sky.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [42.98, 42.98, 42.98, 42.98, 42.98, 37.45, 37.45, 37.45], "power_watts_avg": 40.91, "power_watts_peak": 42.98, "energy_joules_est": 30.97, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-11T13:45:24.742861"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1091.832, "latencies_ms": [1091.832], "images_per_second": 0.916, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "person: 2\nsnowboard: 1\nhelmet: 1\ngloves: 1\nsnow: 1\nrocks: 1\nsky: 1\nsun: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [37.45, 37.45, 42.15, 42.15, 42.15, 42.15, 42.15, 38.16, 38.16, 38.16, 38.16], "power_watts_avg": 39.85, "power_watts_peak": 42.15, "energy_joules_est": 43.53, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-11T13:45:25.855443"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 785.853, "latencies_ms": [785.853], "images_per_second": 1.273, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the snowy mountain range in the background. The man and woman are standing relatively close to the foreground, seemingly preparing to snowboard or ski down the mountain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [38.16, 36.25, 36.25, 36.25, 36.25, 36.25, 38.61, 38.61], "power_watts_avg": 37.08, "power_watts_peak": 38.61, "energy_joules_est": 29.16, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:45:26.665223"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 582.931, "latencies_ms": [582.931], "images_per_second": 1.715, "prompt_tokens": 19, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two snowboarders are standing on a snow-covered mountain peak, enjoying the bright sunlight and breathtaking mountain views.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [38.61, 38.61, 38.61, 40.95, 40.95, 40.95], "power_watts_avg": 39.78, "power_watts_peak": 40.95, "energy_joules_est": 23.21, "sample_count": 6, "duration_seconds": 0.584}, "timestamp": "2026-01-11T13:45:27.272518"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 867.645, "latencies_ms": [867.645], "images_per_second": 1.153, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The snowboarders are wearing bright red jackets. The sun is shining brightly, creating a lens flare effect. The snowboard is black and appears to be made of metal. The weather is sunny and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.95, 40.95, 42.6, 42.6, 42.6, 42.6, 42.6, 38.25, 38.25], "power_watts_avg": 41.27, "power_watts_peak": 42.6, "energy_joules_est": 35.83, "sample_count": 9, "duration_seconds": 0.868}, "timestamp": "2026-01-11T13:45:28.182340"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 721.97, "latencies_ms": [721.97], "images_per_second": 1.385, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A cluster of ripe, red apples hangs from a tree branch, surrounded by green leaves and partially obscured by a weathered, textured trunk.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.25, 38.25, 38.25, 43.67, 43.67, 43.67, 43.67, 43.67], "power_watts_avg": 41.64, "power_watts_peak": 43.67, "energy_joules_est": 30.08, "sample_count": 8, "duration_seconds": 0.723}, "timestamp": "2026-01-11T13:45:28.993430"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 912.254, "latencies_ms": [912.254], "images_per_second": 1.096, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "apples: 5\ntree: 1\nleaves: 4\nbranches: 6\nfruit: 4\ntree trunk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.37, 43.37, 43.37, 43.37, 43.37, 43.45, 43.45, 43.45, 43.45, 43.45], "power_watts_avg": 43.41, "power_watts_peak": 43.45, "energy_joules_est": 39.63, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-11T13:45:30.004968"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 716.12, "latencies_ms": [716.12], "images_per_second": 1.396, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The apples are positioned in the foreground, close to the tree trunk. The background is blurred, drawing focus to the apples and the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.72, 42.72, 42.72, 42.72, 42.72, 42.31, 42.31, 42.31], "power_watts_avg": 42.57, "power_watts_peak": 42.72, "energy_joules_est": 30.52, "sample_count": 8, "duration_seconds": 0.717}, "timestamp": "2026-01-11T13:45:30.816111"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 877.121, "latencies_ms": [877.121], "images_per_second": 1.14, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts an apple tree with ripe, red apples hanging from its branches. The background is blurred, revealing a natural setting with additional trees and a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 42.0}, "power_stats": {"power_watts_samples": [42.31, 42.31, 45.12, 45.12, 45.12, 45.12, 45.12, 42.53, 42.53], "power_watts_avg": 43.92, "power_watts_peak": 45.12, "energy_joules_est": 38.55, "sample_count": 9, "duration_seconds": 0.878}, "timestamp": "2026-01-11T13:45:31.724994"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1096.091, "latencies_ms": [1096.091], "images_per_second": 0.912, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The apples are predominantly red, contrasting with the brown and gray tones of the tree bark and leaves. The lighting suggests an outdoor setting, possibly during late afternoon or early evening. The apples appear to be ripe and ready for picking.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 49.07, 49.07, 49.07, 49.07, 49.07, 43.65, 43.65, 43.65, 43.65], "power_watts_avg": 45.91, "power_watts_peak": 49.07, "energy_joules_est": 50.35, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:45:32.836932"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 684.889, "latencies_ms": [684.889], "images_per_second": 1.46, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two chefs are working diligently in a commercial kitchen, preparing food using various cooking utensils and equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [43.65, 38.1, 38.1, 38.1, 38.1, 38.1, 43.95], "power_watts_avg": 39.73, "power_watts_peak": 43.95, "energy_joules_est": 27.23, "sample_count": 7, "duration_seconds": 0.685}, "timestamp": "2026-01-11T13:45:33.547562"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1463.302, "latencies_ms": [1463.302], "images_per_second": 0.683, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "pan: 2\ntongs: 2\ncutting board: 1\ncontainer: 1\ntray: 1\nserving dish: 1\ncontainer: 1\nlidded container: 1\nshelves: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13082.4, "ram_available_mb": 109423.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 43.95, 51.99, 51.99, 51.99, 51.99, 51.99, 43.89, 43.89, 43.89, 43.89, 43.89, 33.93], "power_watts_avg": 45.94, "power_watts_peak": 51.99, "energy_joules_est": 67.25, "sample_count": 15, "duration_seconds": 1.464}, "timestamp": "2026-01-11T13:45:35.062993"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 923.455, "latencies_ms": [923.455], "images_per_second": 1.083, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective in the image. The foreground features the chefs actively working, while the background showcases the kitchen's layout and equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.8, "ram_available_mb": 109425.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.93, 33.93, 33.93, 33.93, 43.45, 43.45, 43.45, 43.45, 43.45, 43.34], "power_watts_avg": 39.63, "power_watts_peak": 43.45, "energy_joules_est": 36.62, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-11T13:45:36.070327"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1045.409, "latencies_ms": [1045.409], "images_per_second": 0.957, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a busy commercial kitchen where two chefs are working together to prepare food. They are surrounded by various cooking equipment, utensils, and ingredients, emphasizing the active and industrious atmosphere of the kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 43.34, 43.34, 42.63, 42.63, 42.63, 42.63, 42.63, 42.66, 42.66], "power_watts_avg": 42.89, "power_watts_peak": 43.34, "energy_joules_est": 44.86, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-11T13:45:37.182220"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1144.475, "latencies_ms": [1144.475], "images_per_second": 0.874, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The kitchen is brightly lit with yellow fluorescent lights, creating a warm and inviting atmosphere. The stainless steel surfaces and utensils suggest a modern and efficient design. The overall appearance is clean and organized, reflecting a well-maintained professional kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.66, 42.66, 42.66, 43.12, 43.12, 43.12, 43.12, 43.12, 43.06, 43.06, 43.06, 43.06], "power_watts_avg": 42.99, "power_watts_peak": 43.12, "energy_joules_est": 49.21, "sample_count": 12, "duration_seconds": 1.145}, "timestamp": "2026-01-11T13:45:38.395230"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 580.143, "latencies_ms": [580.143], "images_per_second": 1.724, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A group of motorcyclists has gathered on the side of a road, sitting and standing near their parked motorcycles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.06, 32.66, 32.66, 32.66, 32.66, 32.66], "power_watts_avg": 34.39, "power_watts_peak": 43.06, "energy_joules_est": 19.97, "sample_count": 6, "duration_seconds": 0.581}, "timestamp": "2026-01-11T13:45:39.004914"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1068.854, "latencies_ms": [1068.854], "images_per_second": 0.936, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "motorcycle: 8\nbike: 8\nhelmet: 2\nperson: 2\nroad: 8\nsky: 8\nclouds: 8\nflag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.25, 37.25, 37.25, 37.25, 37.25, 42.95, 42.95, 42.95, 42.95, 42.95, 38.38], "power_watts_avg": 39.94, "power_watts_peak": 42.95, "energy_joules_est": 42.7, "sample_count": 11, "duration_seconds": 1.069}, "timestamp": "2026-01-11T13:45:40.116830"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1134.058, "latencies_ms": [1134.058], "images_per_second": 0.882, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned on the left side of the image, appearing relatively close together. The foreground is dominated by the road and motorcycles, while the background features more motorcycles and a cloudy sky. The motorcycles are parked in a somewhat scattered manner, extending from the foreground to the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.38, 38.38, 38.38, 38.38, 37.98, 37.98, 37.98, 37.98, 37.98, 37.94, 37.94, 37.94], "power_watts_avg": 38.1, "power_watts_peak": 38.38, "energy_joules_est": 43.22, "sample_count": 12, "duration_seconds": 1.134}, "timestamp": "2026-01-11T13:45:41.330085"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 902.054, "latencies_ms": [902.054], "images_per_second": 1.109, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A group of motorcyclists is gathered on a roadside near a body of water, enjoying a ride together.  The setting appears to be rural or coastal, with motocross bikes parked along the roadside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.94, 35.78, 35.78, 35.78, 35.78, 35.78, 37.32, 37.32, 37.32], "power_watts_avg": 36.53, "power_watts_peak": 37.94, "energy_joules_est": 32.96, "sample_count": 9, "duration_seconds": 0.902}, "timestamp": "2026-01-11T13:45:42.241141"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 915.793, "latencies_ms": [915.793], "images_per_second": 1.092, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The sky is cloudy and gray, creating a muted atmosphere. The motorcycles are parked in a somewhat haphazard manner, facing different directions. The overall scene suggests a gathering of motorcycle enthusiasts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.32, 37.32, 40.87, 40.87, 40.87, 40.87, 40.87, 38.55, 38.55, 38.55], "power_watts_avg": 39.46, "power_watts_peak": 40.87, "energy_joules_est": 36.17, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-11T13:45:43.253019"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 904.856, "latencies_ms": [904.856], "images_per_second": 1.105, "prompt_tokens": 8, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A small, single-engine propeller plane with registration number G-RVMZ is captured in mid-flight, leaving a trail of smoke as it soars through the cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.55, 38.55, 39.55, 39.55, 39.55, 39.55, 39.55, 42.16, 42.16], "power_watts_avg": 39.9, "power_watts_peak": 42.16, "energy_joules_est": 36.13, "sample_count": 9, "duration_seconds": 0.905}, "timestamp": "2026-01-11T13:45:44.165725"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 932.521, "latencies_ms": [932.521], "images_per_second": 1.072, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "plane: 1\nclouds: 2\nsmoke: 1\nperson: 1\nwings: 2\npropeller: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.16, 42.16, 42.16, 46.95, 46.95, 46.95, 46.95, 46.95, 44.22, 44.22], "power_watts_avg": 44.97, "power_watts_peak": 46.95, "energy_joules_est": 41.95, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-11T13:45:45.175046"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 807.785, "latencies_ms": [807.785], "images_per_second": 1.238, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The small propeller plane is positioned in the foreground, moving from left to right across the image. The vast sky occupies the background, creating a sense of space and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.0, "ram_available_mb": 109422.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.22, 44.22, 44.22, 42.92, 42.92, 42.92, 42.92, 42.92, 42.99], "power_watts_avg": 43.36, "power_watts_peak": 44.22, "energy_joules_est": 35.05, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:45:46.084782"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 959.038, "latencies_ms": [959.038], "images_per_second": 1.043, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A small, single-engine propeller plane is captured in mid-flight, moving from left to right across a cloudy sky. The image is in sepia tones, giving it a vintage or timeless feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.99, 42.99, 42.99, 42.99, 42.62, 42.62, 42.62, 42.62, 42.62, 42.54], "power_watts_avg": 42.76, "power_watts_peak": 42.99, "energy_joules_est": 41.02, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-11T13:45:47.094057"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 726.553, "latencies_ms": [726.553], "images_per_second": 1.376, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The plane is primarily white with black accents. The sky is cloudy, and the image has a sepia tone, giving it a vintage feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 42.54, 43.44, 43.44, 43.44, 43.44], "power_watts_avg": 42.99, "power_watts_peak": 43.44, "energy_joules_est": 31.26, "sample_count": 8, "duration_seconds": 0.727}, "timestamp": "2026-01-11T13:45:47.905137"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 735.314, "latencies_ms": [735.314], "images_per_second": 1.36, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A group of four sheep, including two adult sheep and two younger ones, are standing on a grassy hill overlooking a serene blue lake surrounded by majestic mountains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [43.44, 41.94, 41.94, 41.94, 41.94, 41.94, 42.77, 42.77], "power_watts_avg": 42.33, "power_watts_peak": 43.44, "energy_joules_est": 31.15, "sample_count": 8, "duration_seconds": 0.736}, "timestamp": "2026-01-11T13:45:48.717910"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 928.855, "latencies_ms": [928.855], "images_per_second": 1.077, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "mountains: 5\nwater: 1\nsheep: 4\ngrass: 6\nrocks: 6\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 52.6, 52.6, 52.6, 52.6, 52.6, 43.24, 43.24], "power_watts_avg": 47.78, "power_watts_peak": 52.6, "energy_joules_est": 44.39, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-11T13:45:49.730066"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 717.969, "latencies_ms": [717.969], "images_per_second": 1.393, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the mountains and lake in the background. The sheep are situated near the water's edge, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 43.41, 43.41, 43.41, 43.41, 43.41, 43.11], "power_watts_avg": 43.33, "power_watts_peak": 43.41, "energy_joules_est": 31.12, "sample_count": 8, "duration_seconds": 0.718}, "timestamp": "2026-01-11T13:45:50.540330"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 752.881, "latencies_ms": [752.881], "images_per_second": 1.328, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A group of sheep is grazing on a grassy hillside overlooking a turquoise lake. The landscape features rolling hills and mountains, creating a picturesque and serene setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.11, 43.11, 43.11, 43.11, 44.67, 44.67, 44.67, 44.67], "power_watts_avg": 43.89, "power_watts_peak": 44.67, "energy_joules_est": 33.06, "sample_count": 8, "duration_seconds": 0.753}, "timestamp": "2026-01-11T13:45:51.349233"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 995.013, "latencies_ms": [995.013], "images_per_second": 1.005, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The sheep are primarily white, contrasting with the green grass and brown mountains. The lighting is bright and sunny, creating a pleasant atmosphere. The mountains appear dry and rocky, further enhancing the natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.6, "ram_available_mb": 109421.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.67, 44.55, 44.55, 44.55, 44.55, 44.55, 43.34, 43.34, 43.34, 43.34], "power_watts_avg": 44.08, "power_watts_peak": 44.67, "energy_joules_est": 43.88, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-11T13:45:52.360165"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 507.501, "latencies_ms": [507.501], "images_per_second": 1.97, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A woman in a wheelchair is preparing to serve a tennis ball during a game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.34, 43.48, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 43.46, "power_watts_peak": 43.48, "energy_joules_est": 22.08, "sample_count": 6, "duration_seconds": 0.508}, "timestamp": "2026-01-11T13:45:52.970019"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1222.161, "latencies_ms": [1222.161], "images_per_second": 0.818, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "woman: 2\ntennis racket: 1\nwheelchair: 2\nbasketball hoop: 1\nbasketball: 1\nwoman: 1\nshorts: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.23, 43.23, 43.23, 43.23, 43.23, 51.92, 51.92, 51.92, 51.92, 51.92, 43.36, 43.36, 43.36], "power_watts_avg": 46.6, "power_watts_peak": 51.92, "energy_joules_est": 56.98, "sample_count": 13, "duration_seconds": 1.223}, "timestamp": "2026-01-11T13:45:54.282317"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1167.67, "latencies_ms": [1167.67], "images_per_second": 0.856, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The woman is positioned in the foreground of the image, holding a tennis racket and facing the camera. The background includes another woman in a wheelchair, suggesting they are playing tennis together. The foreground and background are relatively close together, with the woman in the foreground being more in focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13084.8, "ram_available_mb": 109421.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.36, 43.36, 38.79, 38.79, 38.79, 38.79, 38.79, 42.62, 42.62, 42.62, 42.62, 42.62], "power_watts_avg": 41.15, "power_watts_peak": 43.36, "energy_joules_est": 48.06, "sample_count": 12, "duration_seconds": 1.168}, "timestamp": "2026-01-11T13:45:55.493589"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 852.307, "latencies_ms": [852.307], "images_per_second": 1.173, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two women are playing wheelchair tennis in a gymnasium. One woman is seated in a wheelchair holding a tennis racket, while the other woman is standing and watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13084.7, "ram_available_mb": 109421.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [39.13, 39.13, 39.13, 39.13, 39.13, 43.64, 43.64, 43.64, 43.64], "power_watts_avg": 41.14, "power_watts_peak": 43.64, "energy_joules_est": 35.08, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-11T13:45:56.403760"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1088.55, "latencies_ms": [1088.55], "images_per_second": 0.919, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The woman is wearing a gray t-shirt. The tennis racket she's holding is red and black. The setting appears to be indoors, likely in a gymnasium or sports facility. The lighting is bright, illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.64, 42.28, 42.28, 42.28, 42.28, 42.28, 42.64, 42.64, 42.64, 42.64, 42.64], "power_watts_avg": 42.57, "power_watts_peak": 43.64, "energy_joules_est": 46.36, "sample_count": 11, "duration_seconds": 1.089}, "timestamp": "2026-01-11T13:45:57.513201"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 797.433, "latencies_ms": [797.433], "images_per_second": 1.254, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A young girl, dressed in a pink plaid shirt and blue jeans, sits confidently on a brown leather saddle atop a horse wearing a purple blanket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.91, 43.91, 43.91, 43.91, 43.91, 44.79, 44.79, 44.79], "power_watts_avg": 44.24, "power_watts_peak": 44.79, "energy_joules_est": 35.31, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-11T13:45:58.320909"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1372.417, "latencies_ms": [1372.417], "images_per_second": 0.729, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "helmet: 1\npony saddle: 1\nsaddle: 1\nboot: 1\njewelry: 1\njeans: 1\nshirt: 1\nbracelet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.79, 44.79, 48.93, 48.93, 48.93, 48.93, 48.93, 45.3, 45.3, 45.3, 45.3, 41.59, 41.59, 41.59], "power_watts_avg": 45.73, "power_watts_peak": 48.93, "energy_joules_est": 62.77, "sample_count": 14, "duration_seconds": 1.373}, "timestamp": "2026-01-11T13:45:59.733099"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 933.452, "latencies_ms": [933.452], "images_per_second": 1.071, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The child is positioned near the center of the image, sitting on the saddle and facing the left side of the image. The horse and saddle are in the foreground, while the background consists of trees and greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [41.59, 41.59, 42.04, 42.04, 42.04, 42.04, 42.04, 44.24, 44.24, 44.24], "power_watts_avg": 42.61, "power_watts_peak": 44.24, "energy_joules_est": 39.79, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:46:00.741710"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 766.191, "latencies_ms": [766.191], "images_per_second": 1.305, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A young child is sitting on a horse's saddle, wearing a helmet and riding boots. The setting appears to be a wooded area with a purple saddle blanket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.24, 44.24, 44.16, 44.16, 44.16, 44.16, 44.16, 44.29], "power_watts_avg": 44.2, "power_watts_peak": 44.29, "energy_joules_est": 33.88, "sample_count": 8, "duration_seconds": 0.767}, "timestamp": "2026-01-11T13:46:01.549060"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 929.968, "latencies_ms": [929.968], "images_per_second": 1.075, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The child is wearing a pink and white plaid shirt and blue jeans. The child is sitting on a brown leather saddle. The saddle is on a purple blanket. The child is wearing brown boots.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [44.29, 44.29, 44.29, 44.29, 47.85, 47.85, 47.85, 47.85, 47.85, 44.68], "power_watts_avg": 46.11, "power_watts_peak": 47.85, "energy_joules_est": 42.91, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-11T13:46:02.556907"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 570.696, "latencies_ms": [570.696], "images_per_second": 1.752, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three surfers in wetsuits ride waves in the deep blue ocean of Raglan, New Zealand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.68, 44.68, 44.68, 44.68, 37.35, 37.35], "power_watts_avg": 42.23, "power_watts_peak": 44.68, "energy_joules_est": 24.13, "sample_count": 6, "duration_seconds": 0.571}, "timestamp": "2026-01-11T13:46:03.164700"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 859.213, "latencies_ms": [859.213], "images_per_second": 1.164, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "waves: 2\nsurfers: 3\nsurfboards: 2\nwater: 1\nsky: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.35, 37.35, 37.35, 41.55, 41.55, 41.55, 41.55, 41.55, 38.21], "power_watts_avg": 39.78, "power_watts_peak": 41.55, "energy_joules_est": 34.19, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-11T13:46:04.070773"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 623.898, "latencies_ms": [623.898], "images_per_second": 1.603, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the ocean extending behind them. Surfers can be seen in the background, further away from the main action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.21, 38.21, 38.21, 38.21, 37.63, 37.63, 37.63], "power_watts_avg": 37.96, "power_watts_peak": 38.21, "energy_joules_est": 23.71, "sample_count": 7, "duration_seconds": 0.625}, "timestamp": "2026-01-11T13:46:04.777812"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 930.585, "latencies_ms": [930.585], "images_per_second": 1.075, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two surfers are riding waves in the ocean, wearing wetsuits and skillfully maneuvering their surfboards. The scene is set in Raglan, New Zealand, showcasing a typical surfing environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [37.63, 37.63, 41.13, 41.13, 41.13, 41.13, 41.13, 37.41, 37.41, 37.41], "power_watts_avg": 39.31, "power_watts_peak": 41.13, "energy_joules_est": 36.61, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-11T13:46:05.787626"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1039.281, "latencies_ms": [1039.281], "images_per_second": 0.962, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The ocean is a deep blue color. The lighting suggests a sunny day with bright sunlight. The surfers are wearing wetsuits, indicating the presence of cold water. The overall scene conveys a dynamic and energetic atmosphere typical of New Zealand surfing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [37.41, 37.41, 36.97, 36.97, 36.97, 36.97, 36.97, 37.24, 37.24, 37.24, 37.24], "power_watts_avg": 37.15, "power_watts_peak": 37.41, "energy_joules_est": 38.62, "sample_count": 11, "duration_seconds": 1.04}, "timestamp": "2026-01-11T13:46:06.897033"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 493.562, "latencies_ms": [493.562], "images_per_second": 2.026, "prompt_tokens": 8, "response_tokens_est": 14, "n_tiles": 1, "output_text": "A kitchen with an open window reveals a view of a building outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.9, "ram_available_mb": 109423.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 47.0}, "power_stats": {"power_watts_samples": [37.24, 33.21, 33.21, 33.21, 33.21], "power_watts_avg": 34.02, "power_watts_peak": 37.24, "energy_joules_est": 16.8, "sample_count": 5, "duration_seconds": 0.494}, "timestamp": "2026-01-11T13:46:07.407016"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1146.419, "latencies_ms": [1146.419], "images_per_second": 0.872, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "window: 4\ncupboard: 2\nshelf: 2\npot: 1\nplant: 1\ntable: 1\noven: 1\ncounter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.21, 42.36, 42.36, 42.36, 42.36, 42.36, 54.76, 54.76, 54.76, 54.76, 54.76, 43.9], "power_watts_avg": 46.89, "power_watts_peak": 54.76, "energy_joules_est": 53.78, "sample_count": 12, "duration_seconds": 1.147}, "timestamp": "2026-01-11T13:46:08.617272"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1135.917, "latencies_ms": [1135.917], "images_per_second": 0.88, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The kitchen is positioned to the right of the window, offering a view of the outside. The window occupies the central portion of the image, partially obscuring the view of the kitchen area. The kitchen itself is situated to the left of the window, occupying the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [43.9, 43.9, 43.9, 43.9, 42.7, 42.7, 42.7, 42.7, 42.7, 42.91, 42.91, 42.91], "power_watts_avg": 43.15, "power_watts_peak": 43.9, "energy_joules_est": 49.05, "sample_count": 12, "duration_seconds": 1.137}, "timestamp": "2026-01-11T13:46:09.830773"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1196.388, "latencies_ms": [1196.388], "images_per_second": 0.836, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a cozy kitchen with warm lighting and a large window offering a view of the outside. The window is slightly open, revealing a glimpse of the outside world. Various kitchen items and appliances are visible, including a stove, cabinets, and shelves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.0, "ram_available_mb": 109423.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.91, 35.99, 35.99, 35.99, 35.99, 35.99, 42.24, 42.24, 42.24, 42.24, 42.24, 41.37], "power_watts_avg": 39.62, "power_watts_peak": 42.91, "energy_joules_est": 47.42, "sample_count": 12, "duration_seconds": 1.197}, "timestamp": "2026-01-11T13:46:11.038978"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 941.423, "latencies_ms": [941.423], "images_per_second": 1.062, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The room is dimly lit, creating a warm and cozy atmosphere. The window is frosted, suggesting recent rain or mist. The wooden cabinets and appliances add a rustic charm to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.37, 41.37, 41.37, 41.37, 43.98, 43.98, 43.98, 43.98, 43.98, 44.2], "power_watts_avg": 42.96, "power_watts_peak": 44.2, "energy_joules_est": 40.47, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:46:12.050918"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 772.542, "latencies_ms": [772.542], "images_per_second": 1.294, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A pineapple, oranges, incense sticks, and red cups are arranged on a table, symbolizing a traditional Chinese religious setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.2, 44.2, 44.2, 44.2, 43.33, 43.33, 43.33, 43.33], "power_watts_avg": 43.77, "power_watts_peak": 44.2, "energy_joules_est": 33.83, "sample_count": 8, "duration_seconds": 0.773}, "timestamp": "2026-01-11T13:46:12.863164"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1142.608, "latencies_ms": [1142.608], "images_per_second": 0.875, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "pineapple: 1\nincense sticks: 8\norange: 4\nred cups: 4\nred bowl: 1\nred tablecloth: 1\nred background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.33, 44.24, 44.24, 44.24, 44.24, 44.24, 43.77, 43.77, 43.77, 43.77, 43.77, 43.9], "power_watts_avg": 43.94, "power_watts_peak": 44.24, "energy_joules_est": 50.24, "sample_count": 12, "duration_seconds": 1.143}, "timestamp": "2026-01-11T13:46:14.075299"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 881.704, "latencies_ms": [881.704], "images_per_second": 1.134, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The pineapple is positioned to the left of the incense sticks and oranges. The pineapple and oranges are placed in the foreground, while the incense sticks and container are situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.9, 43.9, 43.9, 43.9, 43.37, 43.37, 43.37, 43.37, 43.37], "power_watts_avg": 43.61, "power_watts_peak": 43.9, "energy_joules_est": 38.47, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-11T13:46:14.986058"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1089.479, "latencies_ms": [1089.479], "images_per_second": 0.918, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a traditional Chinese altar or shrine. A pineapple, incense sticks, oranges, and small red cups are arranged on a red surface. A red sign with Chinese characters is visible behind the pineapple.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.3, 43.3, 43.3, 43.3, 43.3, 43.84, 43.84, 43.84, 43.84, 43.84, 43.66], "power_watts_avg": 43.58, "power_watts_peak": 43.84, "energy_joules_est": 47.49, "sample_count": 11, "duration_seconds": 1.09}, "timestamp": "2026-01-11T13:46:16.096371"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1243.425, "latencies_ms": [1243.425], "images_per_second": 0.804, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene features a vibrant red background, contrasted by the green pineapple and bright orange fruits. Red cups are arranged near the pineapple and oranges, adding pops of color to the setting. The lighting is soft and warm, enhancing the visual appeal of the objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.66, 43.66, 43.66, 43.66, 43.78, 43.78, 43.78, 43.78, 43.78, 43.47, 43.47, 43.47, 43.47], "power_watts_avg": 43.64, "power_watts_peak": 43.78, "energy_joules_est": 54.28, "sample_count": 13, "duration_seconds": 1.244}, "timestamp": "2026-01-11T13:46:17.407074"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 703.205, "latencies_ms": [703.205], "images_per_second": 1.422, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A man is holding a plate with a sandwich, fries, and a small cup of sauce, smiling at the camera in a casual restaurant setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.47, 32.34, 32.34, 32.34, 32.34, 32.34, 43.03], "power_watts_avg": 35.45, "power_watts_peak": 43.47, "energy_joules_est": 24.94, "sample_count": 7, "duration_seconds": 0.703}, "timestamp": "2026-01-11T13:46:18.118472"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1287.859, "latencies_ms": [1287.859], "images_per_second": 0.776, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "man: 2\nfries: 1\ntostada: 1\ntartar sauce: 1\ngrilled cheese: 1\ntable: 1\nmenu: 1\nclock: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.03, 43.03, 43.03, 43.03, 54.94, 54.94, 54.94, 54.94, 54.94, 44.5, 44.5, 44.5, 44.5], "power_watts_avg": 48.06, "power_watts_peak": 54.94, "energy_joules_est": 61.92, "sample_count": 13, "duration_seconds": 1.288}, "timestamp": "2026-01-11T13:46:19.432614"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1231.447, "latencies_ms": [1231.447], "images_per_second": 0.812, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The man is holding the plate of food in front of him, positioned in the foreground. The background features other patrons and tables, suggesting the setting is a restaurant or cafe. The man is holding the plate of food near a counter or bar area, indicating a casual dining environment.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.81, 33.81, 33.81, 33.81, 33.81, 43.99, 43.99, 43.99, 43.99, 43.99, 44.21, 44.21, 44.21], "power_watts_avg": 40.12, "power_watts_peak": 44.21, "energy_joules_est": 49.43, "sample_count": 13, "duration_seconds": 1.232}, "timestamp": "2026-01-11T13:46:20.747065"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 780.779, "latencies_ms": [780.779], "images_per_second": 1.281, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A man is taking a selfie while holding a plate with a sandwich, fries, and a small cup of sauce. The setting appears to be a casual restaurant or diner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.21, 44.21, 40.23, 40.23, 40.23, 40.23, 40.23, 42.92], "power_watts_avg": 41.56, "power_watts_peak": 44.21, "energy_joules_est": 32.47, "sample_count": 8, "duration_seconds": 0.781}, "timestamp": "2026-01-11T13:46:21.555552"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 939.437, "latencies_ms": [939.437], "images_per_second": 1.064, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The man is wearing glasses and has a beard. The food on his plate includes golden-brown fries and a fried egg sandwich. The lighting in the image is bright, likely from overhead lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.92, 42.92, 42.92, 42.92, 46.83, 46.83, 46.83, 46.83, 46.83, 43.95], "power_watts_avg": 44.98, "power_watts_peak": 46.83, "energy_joules_est": 42.29, "sample_count": 10, "duration_seconds": 0.94}, "timestamp": "2026-01-11T13:46:22.565675"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 713.02, "latencies_ms": [713.02], "images_per_second": 1.402, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Two individuals are walking on a wet sidewalk in an urban setting, holding umbrellas to shield themselves from the rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 43.95, 42.7, 42.7, 42.7, 42.7], "power_watts_avg": 43.32, "power_watts_peak": 43.95, "energy_joules_est": 30.9, "sample_count": 8, "duration_seconds": 0.713}, "timestamp": "2026-01-11T13:46:23.376064"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1106.488, "latencies_ms": [1106.488], "images_per_second": 0.904, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "building: 5\nmetal structure: 2\nbicycles: 3\nperson: 2\nperson with umbrella: 1\ngrass: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.7, 42.06, 42.06, 42.06, 42.06, 42.06, 42.43, 42.43, 42.43, 42.43, 42.43, 43.18], "power_watts_avg": 42.36, "power_watts_peak": 43.18, "energy_joules_est": 46.89, "sample_count": 12, "duration_seconds": 1.107}, "timestamp": "2026-01-11T13:46:24.588638"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1385.959, "latencies_ms": [1385.959], "images_per_second": 0.722, "prompt_tokens": 25, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The main objects are positioned in a manner that creates a sense of depth and perspective. The foreground features the metal grate and window frame, while the background includes other buildings, trees, and possibly a parking lot. The perspective suggests the viewer is looking out from inside a building, observing the scene from the opposite side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.18, 43.18, 43.18, 43.18, 42.23, 42.23, 42.23, 42.23, 42.23, 42.3, 42.3, 42.3, 42.3, 42.3], "power_watts_avg": 42.52, "power_watts_peak": 43.18, "energy_joules_est": 58.96, "sample_count": 14, "duration_seconds": 1.387}, "timestamp": "2026-01-11T13:46:26.002131"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1036.954, "latencies_ms": [1036.954], "images_per_second": 0.964, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a modern, gray building complex on a rainy day. Two individuals are walking on the wet pavement while holding umbrellas.  Bicycles are parked near a metal grate in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.6, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.75, 33.75, 33.75, 33.75, 33.75, 43.8, 43.8, 43.8, 43.8, 43.8, 43.55], "power_watts_avg": 39.21, "power_watts_peak": 43.8, "energy_joules_est": 40.67, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-11T13:46:27.113018"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 849.298, "latencies_ms": [849.298], "images_per_second": 1.177, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The building exterior is primarily gray and appears to be made of metal or concrete. The scene is illuminated by natural light, suggesting an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.55, 43.55, 43.55, 43.55, 42.1, 42.1, 42.1, 42.1, 42.1], "power_watts_avg": 42.74, "power_watts_peak": 43.55, "energy_joules_est": 36.33, "sample_count": 9, "duration_seconds": 0.85}, "timestamp": "2026-01-11T13:46:28.023673"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 702.501, "latencies_ms": [702.501], "images_per_second": 1.423, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A generous amount of creamy white mayonnaise is spread across a piece of bread, accompanied by a fork and knife on the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.05, 42.05, 42.05, 42.05, 42.05, 43.01, 43.01], "power_watts_avg": 42.33, "power_watts_peak": 43.01, "energy_joules_est": 29.77, "sample_count": 7, "duration_seconds": 0.703}, "timestamp": "2026-01-11T13:46:28.733958"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 866.111, "latencies_ms": [866.111], "images_per_second": 1.155, "prompt_tokens": 21, "response_tokens_est": 21, "n_tiles": 1, "output_text": "fork: 3\nknife: 1\nplate: 1\nbread: 1\nmayonnaise: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 51.08, 51.08, 51.08, 51.08, 51.08, 44.28, 44.28], "power_watts_avg": 47.77, "power_watts_peak": 51.08, "energy_joules_est": 41.4, "sample_count": 9, "duration_seconds": 0.867}, "timestamp": "2026-01-11T13:46:29.643223"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 901.917, "latencies_ms": [901.917], "images_per_second": 1.109, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The left foreground is dominated by the creamy substance, likely mayonnaise. The background is blurred, drawing focus to the foreground object. The object is positioned near the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [44.28, 44.28, 44.28, 45.97, 45.97, 45.97, 45.97, 45.97, 43.66], "power_watts_avg": 45.15, "power_watts_peak": 45.97, "energy_joules_est": 40.75, "sample_count": 9, "duration_seconds": 0.902}, "timestamp": "2026-01-11T13:46:30.553220"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 796.386, "latencies_ms": [796.386], "images_per_second": 1.256, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene is set on a plate with a fork and knife nearby. The focus is on a generous amount of mayonnaise spread on a piece of bread.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.66, 43.66, 43.66, 43.66, 43.68, 43.68, 43.68, 43.68], "power_watts_avg": 43.67, "power_watts_peak": 43.68, "energy_joules_est": 34.79, "sample_count": 8, "duration_seconds": 0.797}, "timestamp": "2026-01-11T13:46:31.362016"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1133.753, "latencies_ms": [1133.753], "images_per_second": 0.882, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The food is predominantly a pale yellow color, possibly due to mayonnaise or a similar condiment. The lighting is soft and diffused, creating a gentle glow on the food's surface. The food appears to be on a piece of bread or bread-like base.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.68, 46.38, 46.38, 46.38, 46.38, 46.38, 44.4, 44.4, 44.4, 44.4, 44.4, 42.82], "power_watts_avg": 45.03, "power_watts_peak": 46.38, "energy_joules_est": 51.08, "sample_count": 12, "duration_seconds": 1.134}, "timestamp": "2026-01-11T13:46:32.572617"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 735.401, "latencies_ms": [735.401], "images_per_second": 1.36, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A silver laptop with a green leaf background is open on a white desk, accompanied by a black mouse, a keyboard, and a mousepad with a red design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.82, 43.16, 43.16, 43.16, 43.16], "power_watts_avg": 42.99, "power_watts_peak": 43.16, "energy_joules_est": 31.64, "sample_count": 8, "duration_seconds": 0.736}, "timestamp": "2026-01-11T13:46:33.384595"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1200.554, "latencies_ms": [1200.554], "images_per_second": 0.833, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "laptop: 1\nkeyboard: 1\nmouse: 1\nspeaker: 1\nmouse pad: 1\nphone: 1\ncomputer monitor: 2\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.16, 43.45, 43.45, 43.45, 43.45, 43.45, 43.25, 43.25, 43.25, 43.25, 43.25, 44.12], "power_watts_avg": 43.4, "power_watts_peak": 44.12, "energy_joules_est": 52.12, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-11T13:46:34.597190"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1013.074, "latencies_ms": [1013.074], "images_per_second": 0.987, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The laptop is in the foreground, while the monitor and keyboard are placed in the background. The desk surface extends beyond the laptop and keyboard, partially obscured by the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [44.12, 44.12, 44.12, 44.12, 44.43, 44.43, 44.43, 44.43, 44.43, 44.62, 44.62], "power_watts_avg": 44.35, "power_watts_peak": 44.62, "energy_joules_est": 44.94, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:46:35.707134"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 989.941, "latencies_ms": [989.941], "images_per_second": 1.01, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a workspace with a laptop displaying a green leaf background, a desktop computer monitor, a keyboard, a mouse, and a speaker. The laptop is open and positioned on a desk with a window nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.62, 44.62, 44.62, 42.98, 42.98, 42.98, 42.98, 42.98, 42.71, 42.71], "power_watts_avg": 43.42, "power_watts_peak": 44.62, "energy_joules_est": 42.99, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:46:36.718108"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1002.187, "latencies_ms": [1002.187], "images_per_second": 0.998, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The laptop is silver and has a green leaf background on its screen. The desk is white and appears clean and organized. The lighting in the image is bright, likely from natural light coming in through a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [42.71, 42.71, 42.71, 44.55, 44.55, 44.55, 44.55, 44.55, 44.07, 44.07], "power_watts_avg": 43.91, "power_watts_peak": 44.55, "energy_joules_est": 44.02, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-11T13:46:37.728837"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 525.467, "latencies_ms": [525.467], "images_per_second": 1.903, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A young girl is sitting on a bed in a cozy bedroom, playing with toys.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.07, 44.07, 44.82, 44.82, 44.82, 44.82], "power_watts_avg": 44.57, "power_watts_peak": 44.82, "energy_joules_est": 23.43, "sample_count": 6, "duration_seconds": 0.526}, "timestamp": "2026-01-11T13:46:38.338531"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1164.608, "latencies_ms": [1164.608], "images_per_second": 0.859, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\nnightstand: 1\nlamp: 1\ntoys: 2\ntable: 1\nchair: 1\nfloor: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.82, 47.24, 47.24, 47.24, 47.24, 47.24, 43.89, 43.89, 43.89, 43.89, 43.89, 41.48], "power_watts_avg": 45.16, "power_watts_peak": 47.24, "energy_joules_est": 52.64, "sample_count": 12, "duration_seconds": 1.165}, "timestamp": "2026-01-11T13:46:39.551881"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 733.064, "latencies_ms": [733.064], "images_per_second": 1.364, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned between the table and the chair. The table and chair are located in the background, further away from the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13083.5, "ram_available_mb": 109422.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.48, 41.48, 41.48, 41.48, 44.02, 44.02, 44.02, 44.02], "power_watts_avg": 42.75, "power_watts_peak": 44.02, "energy_joules_est": 31.35, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:46:40.359830"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.131, "latencies_ms": [933.131], "images_per_second": 1.072, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young girl is sitting on a bed in a room with orange walls. The room has a simple decor, featuring a bed, a nightstand, and a small table with a lamp. Various toys are scattered around the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.02, 45.69, 45.69, 45.69, 45.69, 45.69, 43.19, 43.19, 43.19, 43.19], "power_watts_avg": 44.52, "power_watts_peak": 45.69, "energy_joules_est": 41.56, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-11T13:46:41.368987"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 918.234, "latencies_ms": [918.234], "images_per_second": 1.089, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The room features warm orange walls and warm lighting, creating a cozy atmosphere. The bed is made with a brown and red patterned bedspread, and there are toys scattered around, suggesting recent play.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.19, 42.6, 42.6, 42.6, 42.6, 42.6, 42.84, 42.84, 42.84, 42.84], "power_watts_avg": 42.76, "power_watts_peak": 43.19, "energy_joules_est": 39.28, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:46:42.378861"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 847.444, "latencies_ms": [847.444], "images_per_second": 1.18, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A batter in a red uniform is poised to swing at a pitch, while a catcher and an umpire stand nearby, observing the play.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.84, 42.57, 42.57, 42.57, 42.57, 42.57, 42.23, 42.23, 42.23], "power_watts_avg": 42.49, "power_watts_peak": 42.84, "energy_joules_est": 36.04, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-11T13:46:43.291408"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1317.567, "latencies_ms": [1317.567], "images_per_second": 0.759, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "batter: 1\ncatcher: 1\numpire: 1\nbaseball bat: 1\nbaseball glove: 1\nbaseball field: 1\nbase: 1\nhome plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.23, 42.23, 48.95, 48.95, 48.95, 48.95, 48.95, 43.17, 43.17, 43.17, 43.17, 43.17, 38.75, 38.75], "power_watts_avg": 44.47, "power_watts_peak": 48.95, "energy_joules_est": 58.62, "sample_count": 14, "duration_seconds": 1.318}, "timestamp": "2026-01-11T13:46:44.705233"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 786.037, "latencies_ms": [786.037], "images_per_second": 1.272, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The batter is positioned to the left of the catcher, close to the foreground. The umpire is situated to the right of the catcher, further in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [38.75, 38.75, 38.75, 42.95, 42.95, 42.95, 42.95, 42.95], "power_watts_avg": 41.37, "power_watts_peak": 42.95, "energy_joules_est": 32.53, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:46:45.513426"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 959.994, "latencies_ms": [959.994], "images_per_second": 1.042, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter in a red uniform is swinging at a pitch, while a catcher in gray and an umpire in black observe the play.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 42.88, 42.88, 42.88, 44.07, 44.07, 44.07, 44.07, 44.07], "power_watts_avg": 43.47, "power_watts_peak": 44.07, "energy_joules_est": 41.76, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-11T13:46:46.523434"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1157.916, "latencies_ms": [1157.916], "images_per_second": 0.864, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The baseball game is played under bright sunlight, creating a vibrant and energetic atmosphere. The field is well-maintained and appears to be made of dirt or clay. The players' uniforms are predominantly red and white, contrasting with the green grass of the outfield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.88, 43.88, 43.88, 43.88, 43.88, 43.3, 43.3, 43.3, 43.3, 43.3, 43.26, 43.26], "power_watts_avg": 43.53, "power_watts_peak": 43.88, "energy_joules_est": 50.43, "sample_count": 12, "duration_seconds": 1.158}, "timestamp": "2026-01-11T13:46:47.737719"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 440.904, "latencies_ms": [440.904], "images_per_second": 2.268, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A white and brown cat is eating a dead small bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [43.26, 43.26, 37.86, 37.86, 37.86], "power_watts_avg": 40.02, "power_watts_peak": 43.26, "energy_joules_est": 17.67, "sample_count": 5, "duration_seconds": 0.441}, "timestamp": "2026-01-11T13:46:48.247793"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 909.57, "latencies_ms": [909.57], "images_per_second": 1.099, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cat: 1\nbird: 1\nfeather: 1\ntape: 1\nground: 1\nnet: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.86, 37.86, 41.82, 41.82, 41.82, 41.82, 41.82, 37.86, 37.86, 37.86], "power_watts_avg": 39.84, "power_watts_peak": 41.82, "energy_joules_est": 36.26, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-11T13:46:49.258192"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 745.459, "latencies_ms": [745.459], "images_per_second": 1.341, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the bird. The bird is lying on the ground near the cat. The cat is situated in the background, partially obscured by the bird.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.4, "ram_available_mb": 109422.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.86, 37.86, 36.47, 36.47, 36.47, 36.47, 36.47, 36.34], "power_watts_avg": 36.8, "power_watts_peak": 37.86, "energy_joules_est": 27.46, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-11T13:46:50.066430"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 607.771, "latencies_ms": [607.771], "images_per_second": 1.645, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and gray cat is eating a small bird on a concrete surface. The bird is positioned near the cat's paws.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.34, 36.34, 36.34, 36.34, 37.44, 37.44, 37.44], "power_watts_avg": 36.82, "power_watts_peak": 37.44, "energy_joules_est": 22.4, "sample_count": 7, "duration_seconds": 0.609}, "timestamp": "2026-01-11T13:46:50.774044"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 807.356, "latencies_ms": [807.356], "images_per_second": 1.239, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The cat's fur is predominantly white and gray. The lighting suggests a sunny outdoor setting. The cat is eating a dead bird, which appears to be brown and gray in color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13083.3, "ram_available_mb": 109423.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [37.44, 37.44, 40.63, 40.63, 40.63, 40.63, 40.63, 36.99, 36.99], "power_watts_avg": 39.11, "power_watts_peak": 40.63, "energy_joules_est": 31.59, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:46:51.684838"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 644.076, "latencies_ms": [644.076], "images_per_second": 1.553, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A hand holds a sandwich with fresh ingredients, including tomato, spinach, and cheese, on a white plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13083.6, "ram_available_mb": 109422.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.99, 36.99, 36.99, 42.18, 42.18, 42.18, 42.18], "power_watts_avg": 39.96, "power_watts_peak": 42.18, "energy_joules_est": 25.75, "sample_count": 7, "duration_seconds": 0.644}, "timestamp": "2026-01-11T13:46:52.392263"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1190.331, "latencies_ms": [1190.331], "images_per_second": 0.84, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "tomato: 1\nbasil: 1\nmozzarella: 1\nbread: 2\nmayonnaise: 1\ncheese: 1\ncutting board: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.18, 42.61, 42.61, 42.61, 42.61, 42.61, 43.02, 43.02, 43.02, 43.02, 43.02, 43.76], "power_watts_avg": 42.84, "power_watts_peak": 43.76, "energy_joules_est": 51.01, "sample_count": 12, "duration_seconds": 1.191}, "timestamp": "2026-01-11T13:46:53.604762"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 882.534, "latencies_ms": [882.534], "images_per_second": 1.133, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The hand is holding the sandwich in the foreground, while the background features a stove and possibly a cutting board. The sandwich is positioned near the stove, suggesting it is being prepared or consumed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 43.76, 43.92, 43.92, 43.92, 43.92, 43.92], "power_watts_avg": 43.85, "power_watts_peak": 43.92, "energy_joules_est": 38.71, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-11T13:46:54.516400"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 770.212, "latencies_ms": [770.212], "images_per_second": 1.298, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A hand is holding a sandwich with tomato, basil, and cheese on a white cutting board. The sandwich is being prepared or assembled in a kitchen setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.75, 43.75, 43.75, 43.75, 43.75, 43.85, 43.85, 43.85], "power_watts_avg": 43.79, "power_watts_peak": 43.85, "energy_joules_est": 33.75, "sample_count": 8, "duration_seconds": 0.771}, "timestamp": "2026-01-11T13:46:55.323625"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1020.131, "latencies_ms": [1020.131], "images_per_second": 0.98, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The sandwich features a vibrant mix of colors: the red tomato, green basil, and white cheese contrast beautifully against the light-colored bread. The lighting is soft and somewhat dim, enhancing the visual appeal of the ingredients.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.85, 43.85, 48.28, 48.28, 48.28, 48.28, 48.28, 43.72, 43.72, 43.72, 43.72], "power_watts_avg": 45.82, "power_watts_peak": 48.28, "energy_joules_est": 46.76, "sample_count": 11, "duration_seconds": 1.02}, "timestamp": "2026-01-11T13:46:56.435839"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 519.423, "latencies_ms": [519.423], "images_per_second": 1.925, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two young girls are sitting on the edge of a boat, enjoying the blue ocean and wearing hats.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.42, 37.42, 37.42, 37.42, 37.42, 37.21], "power_watts_avg": 37.38, "power_watts_peak": 37.42, "energy_joules_est": 19.43, "sample_count": 6, "duration_seconds": 0.52}, "timestamp": "2026-01-11T13:46:57.045062"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1184.355, "latencies_ms": [1184.355], "images_per_second": 0.844, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Hat: 1\nJeans: 1\nShirt: 1\nPants: 1\nLife preserver: 1\nRope: 1\nBoat: 1\nWater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.21, 37.21, 37.21, 37.21, 41.85, 41.85, 41.85, 41.85, 41.85, 36.7, 36.7, 36.7], "power_watts_avg": 39.02, "power_watts_peak": 41.85, "energy_joules_est": 46.22, "sample_count": 12, "duration_seconds": 1.185}, "timestamp": "2026-01-11T13:46:58.258818"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 855.397, "latencies_ms": [855.397], "images_per_second": 1.169, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned close together on the boat, with the woman on the left leaning over the railing and the girl on the right sitting further back. The boat is situated in the background, and the water extends to the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.7, 36.7, 38.28, 38.28, 38.28, 38.28, 38.28, 38.38, 38.38], "power_watts_avg": 37.95, "power_watts_peak": 38.38, "energy_joules_est": 32.48, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-11T13:46:59.168568"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 907.136, "latencies_ms": [907.136], "images_per_second": 1.102, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Two young girls are sitting on the edge of a white boat, enjoying the blue ocean. They are wearing casual summer clothing and hats. The scene suggests a leisurely boat ride or outing on the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.38, 38.38, 38.38, 37.98, 37.98, 37.98, 37.98, 37.98, 38.0, 38.0], "power_watts_avg": 38.1, "power_watts_peak": 38.38, "energy_joules_est": 34.6, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:47:00.182302"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 724.469, "latencies_ms": [724.469], "images_per_second": 1.38, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The boat is primarily white, contrasting with the deep blue of the ocean. The lighting suggests a sunny day, and the materials appear to be sturdy and weather-resistant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.0, 38.0, 38.0, 36.84, 36.84, 36.84, 36.84, 36.84], "power_watts_avg": 37.28, "power_watts_peak": 38.0, "energy_joules_est": 27.03, "sample_count": 8, "duration_seconds": 0.725}, "timestamp": "2026-01-11T13:47:00.993054"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 550.381, "latencies_ms": [550.381], "images_per_second": 1.817, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A white sheep with pink ears stands on a grassy hill, gazing directly at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.39, 36.39, 36.39, 36.39, 36.39, 42.77], "power_watts_avg": 37.46, "power_watts_peak": 42.77, "energy_joules_est": 20.64, "sample_count": 6, "duration_seconds": 0.551}, "timestamp": "2026-01-11T13:47:01.605173"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1036.752, "latencies_ms": [1036.752], "images_per_second": 0.965, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "Sheep: 1\nStone wall: 2\nGrass: 4\nGround: 4\nBushes: 2\nYellow lichen: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [42.77, 42.77, 42.77, 42.77, 51.96, 51.96, 51.96, 51.96, 51.96, 43.38, 43.38], "power_watts_avg": 47.06, "power_watts_peak": 51.96, "energy_joules_est": 48.81, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-11T13:47:02.717697"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 784.55, "latencies_ms": [784.55], "images_per_second": 1.275, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, slightly to the right of the viewer. The stone wall and grass are in the background, extending beyond the sheep's immediate surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 42.78, 42.78, 42.78, 42.78, 42.78], "power_watts_avg": 43.01, "power_watts_peak": 43.38, "energy_joules_est": 33.76, "sample_count": 8, "duration_seconds": 0.785}, "timestamp": "2026-01-11T13:47:03.527628"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 681.421, "latencies_ms": [681.421], "images_per_second": 1.468, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A white sheep stands in a grassy field, facing the camera. A stone wall with yellow lichen is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 43.02, 45.29, 45.29], "power_watts_avg": 43.67, "power_watts_peak": 45.29, "energy_joules_est": 29.78, "sample_count": 7, "duration_seconds": 0.682}, "timestamp": "2026-01-11T13:47:04.237423"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1043.942, "latencies_ms": [1043.942], "images_per_second": 0.958, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The sheep is predominantly white. Its wool appears soft and fluffy. The lighting suggests a sunny day, with bright sunlight illuminating the scene. The sheep is standing on a grassy area, which appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.29, 45.29, 52.59, 52.59, 52.59, 52.59, 52.59, 43.72, 43.72, 43.72, 43.72], "power_watts_avg": 48.04, "power_watts_peak": 52.59, "energy_joules_est": 50.17, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-11T13:47:05.349728"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 610.732, "latencies_ms": [610.732], "images_per_second": 1.637, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "Two men are loading a large black pipe onto a flatbed truck in a parking lot.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.72, 37.47, 37.47, 37.47, 37.47, 37.47, 42.61], "power_watts_avg": 39.1, "power_watts_peak": 43.72, "energy_joules_est": 23.91, "sample_count": 7, "duration_seconds": 0.611}, "timestamp": "2026-01-11T13:47:06.061445"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1246.008, "latencies_ms": [1246.008], "images_per_second": 0.803, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Pipe: 2\nCrates: 2\nTruck: 1\nMan: 1\nTrees: 1\nBuilding: 1\nCars: 1\nManhole cover: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 42.61, 42.61, 49.85, 49.85, 49.85, 49.85, 49.85, 42.53, 42.53, 42.53, 42.53], "power_watts_avg": 45.37, "power_watts_peak": 49.85, "energy_joules_est": 56.55, "sample_count": 13, "duration_seconds": 1.246}, "timestamp": "2026-01-11T13:47:07.373934"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 860.547, "latencies_ms": [860.547], "images_per_second": 1.162, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the truck transporting them further back. The truck is parked in a parking lot, indicating a relatively close proximity between the objects and the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.53, 35.17, 35.17, 35.17, 35.17, 35.17, 43.18, 43.18, 43.18], "power_watts_avg": 38.66, "power_watts_peak": 43.18, "energy_joules_est": 33.29, "sample_count": 9, "duration_seconds": 0.861}, "timestamp": "2026-01-11T13:47:08.284958"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 741.503, "latencies_ms": [741.503], "images_per_second": 1.349, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two men are loading a large pipe onto a flatbed truck in a parking lot. The truck is carrying several cases and equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.18, 43.18, 49.23, 49.23, 49.23, 49.23, 49.23, 43.51], "power_watts_avg": 47.0, "power_watts_peak": 49.23, "energy_joules_est": 34.87, "sample_count": 8, "duration_seconds": 0.742}, "timestamp": "2026-01-11T13:47:09.095536"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 854.159, "latencies_ms": [854.159], "images_per_second": 1.171, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The truck is primarily black and yellow. The lighting appears to be natural daylight. The materials include black plastic pipes and gray plastic cases. The weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.51, 43.51, 43.51, 43.51, 46.03, 46.03, 46.03, 46.03, 46.03], "power_watts_avg": 44.91, "power_watts_peak": 46.03, "energy_joules_est": 38.37, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-11T13:47:10.006322"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 675.254, "latencies_ms": [675.254], "images_per_second": 1.481, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Three giraffes walk along a dirt path near a pond in a lush, wooded area, accompanied by a resting deer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.63, 42.63, 42.63, 42.63, 42.63, 43.25, 43.25], "power_watts_avg": 42.81, "power_watts_peak": 43.25, "energy_joules_est": 28.93, "sample_count": 7, "duration_seconds": 0.676}, "timestamp": "2026-01-11T13:47:10.717320"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1104.421, "latencies_ms": [1104.421], "images_per_second": 0.905, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "giraffe: 3\ntree: 2\npond: 1\nrocks: 1\ndeer: 1\nfence: 1\npath: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [43.25, 43.25, 43.25, 52.27, 52.27, 52.27, 52.27, 52.27, 44.05, 44.05, 44.05], "power_watts_avg": 47.57, "power_watts_peak": 52.27, "energy_joules_est": 52.55, "sample_count": 11, "duration_seconds": 1.105}, "timestamp": "2026-01-11T13:47:11.830671"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 838.562, "latencies_ms": [838.562], "images_per_second": 1.193, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The giraffes are positioned in the foreground, moving towards the left side of the image. The pond and trees in the background create a natural setting, separating the main subjects from the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [44.05, 44.05, 39.64, 39.64, 39.64, 39.64, 39.64, 44.48, 44.48], "power_watts_avg": 41.69, "power_watts_peak": 44.48, "energy_joules_est": 34.98, "sample_count": 9, "duration_seconds": 0.839}, "timestamp": "2026-01-11T13:47:12.742514"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 989.488, "latencies_ms": [989.488], "images_per_second": 1.011, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Three giraffes are walking along a dirt path near a pond in a wooded area. A deer is resting nearby, observing the giraffes. The setting appears to be a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.48, 44.48, 48.7, 48.7, 48.7, 48.7, 48.7, 43.1, 43.1, 43.1], "power_watts_avg": 46.17, "power_watts_peak": 48.7, "energy_joules_est": 45.71, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:47:13.754676"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1269.618, "latencies_ms": [1269.618], "images_per_second": 0.788, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The giraffes have distinctive brown and white patterns. The lighting appears to be natural, possibly overcast, creating a soft, diffused effect. The giraffes are walking on a dirt path near a body of water, which reflects the surroundings. The overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.1, 43.1, 42.8, 42.8, 42.8, 42.8, 42.8, 43.42, 43.42, 43.42, 43.42, 43.42, 36.42], "power_watts_avg": 42.59, "power_watts_peak": 43.42, "energy_joules_est": 54.09, "sample_count": 13, "duration_seconds": 1.27}, "timestamp": "2026-01-11T13:47:15.065993"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 817.789, "latencies_ms": [817.789], "images_per_second": 1.223, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A delicious pizza topped with mushrooms, artichokes, and ham is served on a white plate, accompanied by two glasses of beer, in a cozy restaurant setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.42, 36.42, 36.42, 36.42, 43.18, 43.18, 43.18, 43.18, 43.18], "power_watts_avg": 40.17, "power_watts_peak": 43.18, "energy_joules_est": 32.88, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:47:15.978500"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1315.608, "latencies_ms": [1315.608], "images_per_second": 0.76, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Pizza: 2\nWine glass: 2\nBeer glass: 1\nTablecloth: 2\nChairs: 2\nCutlery: 1\nBowl: 1\nPerson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.42, 42.42, 42.42, 42.42, 42.42, 42.71, 42.71, 42.71, 42.71, 42.71, 43.5, 43.5, 43.5, 43.5], "power_watts_avg": 42.83, "power_watts_peak": 43.5, "energy_joules_est": 56.38, "sample_count": 14, "duration_seconds": 1.316}, "timestamp": "2026-01-11T13:47:17.394103"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 846.577, "latencies_ms": [846.577], "images_per_second": 1.181, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the pizza and wine glass placed slightly behind and to the right. The dining area extends in the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.5, 33.25, 33.25, 33.25, 33.25, 33.25, 41.88, 41.88, 41.88], "power_watts_avg": 37.26, "power_watts_peak": 43.5, "energy_joules_est": 31.57, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-11T13:47:18.305018"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 968.008, "latencies_ms": [968.008], "images_per_second": 1.033, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a restaurant setting with a table set for a meal, featuring a pizza with toppings and two glasses of beer. The restaurant appears well-stocked with wine bottles and has a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.88, 41.88, 47.78, 47.78, 47.78, 47.78, 47.78, 42.99, 42.99, 42.99], "power_watts_avg": 45.16, "power_watts_peak": 47.78, "energy_joules_est": 43.73, "sample_count": 10, "duration_seconds": 0.968}, "timestamp": "2026-01-11T13:47:19.314767"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1237.845, "latencies_ms": [1237.845], "images_per_second": 0.808, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The pizza is topped with vibrant red sauce, creamy white cheese, and colorful vegetables like artichokes and mushrooms. The table setting includes blue tablecloths, wine glasses, and a beer glass. The lighting is warm and inviting, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.99, 42.99, 43.76, 43.76, 43.76, 43.76, 43.76, 42.95, 42.95, 42.95, 42.95, 42.95, 38.01], "power_watts_avg": 42.89, "power_watts_peak": 43.76, "energy_joules_est": 53.11, "sample_count": 13, "duration_seconds": 1.238}, "timestamp": "2026-01-11T13:47:20.627653"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 694.55, "latencies_ms": [694.55], "images_per_second": 1.44, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A black cat with white paws is drinking water from a running faucet in a white sink, accompanied by a bottle of soap.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [38.01, 38.01, 38.01, 38.01, 42.52, 42.52, 42.52], "power_watts_avg": 39.95, "power_watts_peak": 42.52, "energy_joules_est": 27.77, "sample_count": 7, "duration_seconds": 0.695}, "timestamp": "2026-01-11T13:47:21.338663"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1170.061, "latencies_ms": [1170.061], "images_per_second": 0.855, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "sink: 2\nfaucet: 1\nbottle: 1\nsoap dispenser: 1\nbowl: 1\ncat: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.52, 46.79, 46.79, 46.79, 46.79, 46.79, 44.04, 44.04, 44.04, 44.04, 44.04, 41.02], "power_watts_avg": 44.81, "power_watts_peak": 46.79, "energy_joules_est": 52.44, "sample_count": 12, "duration_seconds": 1.17}, "timestamp": "2026-01-11T13:47:22.551958"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 873.696, "latencies_ms": [873.696], "images_per_second": 1.145, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The black cat is positioned in the foreground, close to the water flowing from the faucet. The sink and soap dispenser are placed in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [41.02, 41.02, 41.02, 41.02, 43.3, 43.3, 43.3, 43.3, 43.3], "power_watts_avg": 42.29, "power_watts_peak": 43.3, "energy_joules_est": 36.96, "sample_count": 9, "duration_seconds": 0.874}, "timestamp": "2026-01-11T13:47:23.460995"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 774.777, "latencies_ms": [774.777], "images_per_second": 1.291, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A black cat is drinking water from a faucet in a bathroom sink. A bottle of soap and a small white dish are also present on the counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 43.09, 43.09, 43.09, 43.49, 43.49, 43.49], "power_watts_avg": 43.24, "power_watts_peak": 43.49, "energy_joules_est": 33.51, "sample_count": 8, "duration_seconds": 0.775}, "timestamp": "2026-01-11T13:47:24.269128"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1116.342, "latencies_ms": [1116.342], "images_per_second": 0.896, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The sink is white and appears to be made of porcelain or ceramic. The lighting in the bathroom is soft and diffused, creating a calm atmosphere. The cat is drinking from the faucet, which appears to be chrome or silver in color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.49, 43.49, 50.97, 50.97, 50.97, 50.97, 50.97, 43.28, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 46.52, "power_watts_peak": 50.97, "energy_joules_est": 51.95, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-11T13:47:25.481615"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 675.665, "latencies_ms": [675.665], "images_per_second": 1.48, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two people are riding in a horse-drawn carriage through a muddy field, guided by a person holding a whip.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.92, 35.92, 35.92, 35.92, 35.92, 43.46, 43.46], "power_watts_avg": 38.08, "power_watts_peak": 43.46, "energy_joules_est": 25.75, "sample_count": 7, "duration_seconds": 0.676}, "timestamp": "2026-01-11T13:47:26.193154"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1237.197, "latencies_ms": [1237.197], "images_per_second": 0.808, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "carriage: 2\nhorse: 1\nperson: 2\nhelmet: 1\nfence: 1\npuddle: 1\nbuilding: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.46, 43.46, 43.46, 55.33, 55.33, 55.33, 55.33, 55.33, 44.68, 44.68, 44.68, 44.68, 44.68], "power_watts_avg": 48.49, "power_watts_peak": 55.33, "energy_joules_est": 60.02, "sample_count": 13, "duration_seconds": 1.238}, "timestamp": "2026-01-11T13:47:27.504218"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 868.927, "latencies_ms": [868.927], "images_per_second": 1.151, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The horse and carriage are positioned in the foreground, moving towards the background. The horses and carriage are situated in a muddy area, which suggests a rural or agricultural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 34.89, 44.02, 44.02, 44.02, 44.02], "power_watts_avg": 38.95, "power_watts_peak": 44.02, "energy_joules_est": 33.85, "sample_count": 9, "duration_seconds": 0.869}, "timestamp": "2026-01-11T13:47:28.413301"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1087.35, "latencies_ms": [1087.35], "images_per_second": 0.92, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Two people are riding in a horse-drawn carriage through a muddy field. The carriage is pulled by a brown horse, and there are puddles reflecting the scene. In the background, a barn and trees are visible under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.02, 43.69, 43.69, 43.69, 43.69, 43.69, 44.99, 44.99, 44.99, 44.99, 44.99], "power_watts_avg": 44.31, "power_watts_peak": 44.99, "energy_joules_est": 48.22, "sample_count": 11, "duration_seconds": 1.088}, "timestamp": "2026-01-11T13:47:29.528482"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 960.544, "latencies_ms": [960.544], "images_per_second": 1.041, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The horse and carriage are brown, appearing to be made of wood. The scene is lit by natural sunlight, creating a warm, inviting atmosphere. The ground is muddy and wet, reflecting the surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.73, 45.73, 45.73, 45.73, 45.73, 45.53, 45.53, 45.53, 45.53, 45.53], "power_watts_avg": 45.63, "power_watts_peak": 45.73, "energy_joules_est": 43.85, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-11T13:47:30.540753"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 705.204, "latencies_ms": [705.204], "images_per_second": 1.418, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A newlywed couple stands under a black and white umbrella, smiling and holding each other's hands, dressed in formal wedding attire.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.54, 45.54, 45.54, 45.54, 45.54, 43.65, 43.65, 43.65], "power_watts_avg": 44.83, "power_watts_peak": 45.54, "energy_joules_est": 31.64, "sample_count": 8, "duration_seconds": 0.706}, "timestamp": "2026-01-11T13:47:31.352989"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1169.298, "latencies_ms": [1169.298], "images_per_second": 0.855, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bride: 1\ngroom: 1\numbrella: 1\ndress: 1\nflowers: 1\ngrass: 1\nbuilding: 1\npeople: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.65, 45.67, 45.67, 45.67, 45.67, 45.67, 42.62, 42.62, 42.62, 42.62, 42.62, 41.88], "power_watts_avg": 43.92, "power_watts_peak": 45.67, "energy_joules_est": 51.36, "sample_count": 12, "duration_seconds": 1.17}, "timestamp": "2026-01-11T13:47:32.564683"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 894.067, "latencies_ms": [894.067], "images_per_second": 1.118, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The bride is positioned to the left of the groom, standing in the foreground. The couple is standing near a stone building in the background. The foreground is primarily grass, while the background includes other individuals and a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.88, 41.88, 41.88, 41.88, 44.12, 44.12, 44.12, 44.12, 44.12], "power_watts_avg": 43.12, "power_watts_peak": 44.12, "energy_joules_est": 38.57, "sample_count": 9, "duration_seconds": 0.894}, "timestamp": "2026-01-11T13:47:33.474432"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 827.559, "latencies_ms": [827.559], "images_per_second": 1.208, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A bride and groom are walking on a grassy area under a black and white umbrella, likely after their wedding ceremony. The setting appears to be a garden or outdoor venue with a stone building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.04, 44.04, 44.04, 44.04, 44.04, 44.22, 44.22, 44.22, 44.22], "power_watts_avg": 44.12, "power_watts_peak": 44.22, "energy_joules_est": 36.52, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:47:34.384713"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1033.918, "latencies_ms": [1033.918], "images_per_second": 0.967, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The bride is wearing a white dress and holding a bouquet of orange and yellow flowers. The groom is wearing a dark suit and holding a black and white umbrella. The scene appears to be outdoors on a sunny day, with grass and a stone building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.22, 44.62, 44.62, 44.62, 44.62, 44.62, 43.17, 43.17, 43.17, 43.17, 43.17], "power_watts_avg": 43.93, "power_watts_peak": 44.62, "energy_joules_est": 45.43, "sample_count": 11, "duration_seconds": 1.034}, "timestamp": "2026-01-11T13:47:35.492702"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 591.48, "latencies_ms": [591.48], "images_per_second": 1.691, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two people are enjoying a day at the beach, one lying on the sand and the other sitting up playing with a colorful kite.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.59, 43.59, 43.59, 43.59, 43.59, 36.93], "power_watts_avg": 42.48, "power_watts_peak": 43.59, "energy_joules_est": 25.15, "sample_count": 6, "duration_seconds": 0.592}, "timestamp": "2026-01-11T13:47:36.103307"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 926.453, "latencies_ms": [926.453], "images_per_second": 1.079, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "kite: 2\nperson: 2\nwatch: 1\nshorts: 1\nsand: 6\nocean: 2\nwaves: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.93, 36.93, 36.93, 36.93, 41.84, 41.84, 41.84, 41.84, 41.84, 38.73], "power_watts_avg": 39.56, "power_watts_peak": 41.84, "energy_joules_est": 36.67, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-11T13:47:37.111649"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 561.171, "latencies_ms": [561.171], "images_per_second": 1.782, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The man is lying on the sand in the foreground, close to the water. The kite is positioned in the background, near the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.73, 38.73, 38.73, 38.73, 37.6, 37.6], "power_watts_avg": 38.36, "power_watts_peak": 38.73, "energy_joules_est": 21.54, "sample_count": 6, "duration_seconds": 0.561}, "timestamp": "2026-01-11T13:47:37.718933"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 913.221, "latencies_ms": [913.221], "images_per_second": 1.095, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene takes place on a sandy beach near the ocean, where two people are enjoying a sunny day. One person is lying down on the sand, while another is sitting and flying a kite with colorful ribbons.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 58.0}, "power_stats": {"power_watts_samples": [37.6, 37.6, 37.6, 41.44, 41.44, 41.44, 41.44, 41.44, 37.8, 37.8], "power_watts_avg": 39.56, "power_watts_peak": 41.44, "energy_joules_est": 36.14, "sample_count": 10, "duration_seconds": 0.914}, "timestamp": "2026-01-11T13:47:38.730882"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 661.924, "latencies_ms": [661.924], "images_per_second": 1.511, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The beach is sandy and appears warm in color. The lighting suggests a sunny day, and the materials are primarily sand and cloth.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [37.8, 37.8, 37.8, 36.77, 36.77, 36.77, 36.77], "power_watts_avg": 37.21, "power_watts_peak": 37.8, "energy_joules_est": 24.64, "sample_count": 7, "duration_seconds": 0.662}, "timestamp": "2026-01-11T13:47:39.440441"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 673.329, "latencies_ms": [673.329], "images_per_second": 1.485, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The living room features a brown sofa, a red armchair, a black coffee table, a lamp, a television, and two windows with wooden shutters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.77, 35.95, 35.95, 35.95, 35.95, 35.95, 37.61], "power_watts_avg": 36.31, "power_watts_peak": 37.61, "energy_joules_est": 24.46, "sample_count": 7, "duration_seconds": 0.674}, "timestamp": "2026-01-11T13:47:40.150957"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1137.378, "latencies_ms": [1137.378], "images_per_second": 0.879, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "sofa: 2\nlamp: 5\ntable: 1\nchair: 1\nstools: 2\nwindow shutters: 2\ntelevision: 1\nfloor lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.61, 37.61, 37.61, 42.85, 42.85, 42.85, 42.85, 42.85, 38.34, 38.34, 38.34, 38.34], "power_watts_avg": 40.04, "power_watts_peak": 42.85, "energy_joules_est": 45.55, "sample_count": 12, "duration_seconds": 1.138}, "timestamp": "2026-01-11T13:47:41.362120"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 905.607, "latencies_ms": [905.607], "images_per_second": 1.104, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The brown couch is positioned to the left of the image, occupying the foreground. The small table and chairs are situated near the center, near the window. The television is positioned in the background, near the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.34, 35.75, 35.75, 35.75, 35.75, 35.75, 37.48, 37.48, 37.48, 37.48], "power_watts_avg": 36.7, "power_watts_peak": 38.34, "energy_joules_est": 33.25, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-11T13:47:42.374104"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 911.724, "latencies_ms": [911.724], "images_per_second": 1.097, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The living room features a cozy atmosphere with a brown sofa, red armchair, coffee table, and floor lamp. The room is lit by natural light from windows with wooden shutters, creating a warm and inviting ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.48, 35.95, 35.95, 35.95, 35.95, 35.95, 36.56, 36.56, 36.56, 36.56], "power_watts_avg": 36.35, "power_watts_peak": 37.48, "energy_joules_est": 33.15, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-11T13:47:43.385777"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 829.294, "latencies_ms": [829.294], "images_per_second": 1.206, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The room features light beige walls and wooden shutters. The lighting is warm and inviting, illuminating the space. A brown sofa, red armchair, and black table provide seating options.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.56, 36.35, 36.35, 36.35, 36.35, 36.35, 36.78, 36.78, 36.78], "power_watts_avg": 36.52, "power_watts_peak": 36.78, "energy_joules_est": 30.29, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-11T13:47:44.295239"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 575.255, "latencies_ms": [575.255], "images_per_second": 1.738, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man is enjoying a slice of cake while sitting in a park, surrounded by lush greenery.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [36.78, 36.78, 42.13, 42.13, 42.13, 42.13], "power_watts_avg": 40.35, "power_watts_peak": 42.13, "energy_joules_est": 23.22, "sample_count": 6, "duration_seconds": 0.576}, "timestamp": "2026-01-11T13:47:44.904655"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1120.516, "latencies_ms": [1120.516], "images_per_second": 0.892, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cake: 1\nspoon: 1\nplate: 1\nt-shirt: 1\ntree: 2\ngrass: 2\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.13, 44.01, 44.01, 44.01, 44.01, 44.01, 49.7, 49.7, 49.7, 49.7, 49.7, 44.75], "power_watts_avg": 46.29, "power_watts_peak": 49.7, "energy_joules_est": 51.88, "sample_count": 12, "duration_seconds": 1.121}, "timestamp": "2026-01-11T13:47:46.115942"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1074.302, "latencies_ms": [1074.302], "images_per_second": 0.931, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The man is positioned in the foreground, eating a piece of cake with a spoon. The cake is situated near the center, slightly to the right of the man. The background consists of green grass and trees, creating a natural setting for the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.75, 44.75, 44.75, 44.75, 43.36, 43.36, 43.36, 43.36, 43.36, 43.47, 43.47], "power_watts_avg": 43.89, "power_watts_peak": 44.75, "energy_joules_est": 47.17, "sample_count": 11, "duration_seconds": 1.075}, "timestamp": "2026-01-11T13:47:47.226477"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 939.859, "latencies_ms": [939.859], "images_per_second": 1.064, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A man is enjoying a slice of cake outdoors in a park-like setting with green grass and trees. He's using a spoon to eat the cake while seated on a lawn chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.47, 43.47, 43.47, 42.59, 42.59, 42.59, 42.59, 42.59, 44.34, 44.34], "power_watts_avg": 43.21, "power_watts_peak": 44.34, "energy_joules_est": 40.66, "sample_count": 10, "duration_seconds": 0.941}, "timestamp": "2026-01-11T13:47:48.240232"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 987.782, "latencies_ms": [987.782], "images_per_second": 1.012, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The man is wearing a blue shirt. The cake is topped with white frosting and appears to have a raspberry or berry filling. The setting is outdoors with natural lighting filtering through the trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.34, 44.34, 44.34, 43.4, 43.4, 43.4, 43.4, 43.4, 43.81, 43.81], "power_watts_avg": 43.77, "power_watts_peak": 44.34, "energy_joules_est": 43.25, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-11T13:47:49.250842"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 520.063, "latencies_ms": [520.063], "images_per_second": 1.923, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A man stands next to a brown donkey carrying a woven basket filled with various bags and luggage.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.81, 43.81, 40.6, 40.6, 40.6, 40.6], "power_watts_avg": 41.67, "power_watts_peak": 43.81, "energy_joules_est": 21.69, "sample_count": 6, "duration_seconds": 0.521}, "timestamp": "2026-01-11T13:47:49.860472"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 956.375, "latencies_ms": [956.375], "images_per_second": 1.046, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "donkey: 3\nbags: 2\nblanket: 2\nhiking boots: 1\nman: 1\nground: 1\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.1, "ram_available_mb": 109427.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 8.0}, "power_stats": {"power_watts_samples": [40.6, 40.41, 40.41, 40.41, 40.41, 40.41, 37.42, 37.42, 37.42, 37.42], "power_watts_avg": 39.23, "power_watts_peak": 40.6, "energy_joules_est": 37.53, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:47:50.869585"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 814.629, "latencies_ms": [814.629], "images_per_second": 1.228, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is standing to the left of the donkey. The donkey is positioned in the foreground, partially obscuring the man's face. The background consists of bare trees and a dirt path.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.0, "ram_available_mb": 109427.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 37.0}, "power_stats": {"power_watts_samples": [37.42, 38.76, 38.76, 38.76, 38.76, 38.76, 37.47, 37.47, 37.47], "power_watts_avg": 38.18, "power_watts_peak": 38.76, "energy_joules_est": 31.12, "sample_count": 9, "duration_seconds": 0.815}, "timestamp": "2026-01-11T13:47:51.779862"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 657.474, "latencies_ms": [657.474], "images_per_second": 1.521, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man stands next to a donkey carrying various bags and luggage. The scene takes place outdoors in a natural setting with trees and rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 58.0}, "power_stats": {"power_watts_samples": [37.47, 37.47, 38.25, 38.25, 38.25, 38.25, 38.25], "power_watts_avg": 38.03, "power_watts_peak": 38.25, "energy_joules_est": 25.02, "sample_count": 7, "duration_seconds": 0.658}, "timestamp": "2026-01-11T13:47:52.486172"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 754.48, "latencies_ms": [754.48], "images_per_second": 1.325, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The donkey is brown and has a woven basket on its back. The man is wearing purple and gray clothing. The scene is outdoors in natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.89, 36.89, 36.89, 36.89, 36.89, 37.42, 37.42, 37.42], "power_watts_avg": 37.09, "power_watts_peak": 37.42, "energy_joules_est": 28.0, "sample_count": 8, "duration_seconds": 0.755}, "timestamp": "2026-01-11T13:47:53.295569"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 591.699, "latencies_ms": [591.699], "images_per_second": 1.69, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A brightly lit blue bridge spans across a calm river, reflecting the vibrant lights and creating a serene nighttime scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.42, 37.42, 41.0, 41.0, 41.0, 41.0], "power_watts_avg": 39.81, "power_watts_peak": 41.0, "energy_joules_est": 23.58, "sample_count": 6, "duration_seconds": 0.592}, "timestamp": "2026-01-11T13:47:53.905841"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 913.407, "latencies_ms": [913.407], "images_per_second": 1.095, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "bridge: 4\nriver: 1\nboat: 1\npeople: 6\nlights: 5\ntrees: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.0, 38.55, 38.55, 38.55, 38.55, 38.55, 38.31, 38.31, 38.31, 38.31], "power_watts_avg": 38.7, "power_watts_peak": 41.0, "energy_joules_est": 35.36, "sample_count": 10, "duration_seconds": 0.914}, "timestamp": "2026-01-11T13:47:54.911661"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 704.706, "latencies_ms": [704.706], "images_per_second": 1.419, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The foreground features a paved walkway with people walking along it. In the background, the blue-lit bridge spans across the river, connecting the two sides.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 38.0}, "power_stats": {"power_watts_samples": [38.31, 37.55, 37.55, 37.55, 37.55, 37.55, 37.01, 37.01], "power_watts_avg": 37.51, "power_watts_peak": 38.31, "energy_joules_est": 26.46, "sample_count": 8, "duration_seconds": 0.705}, "timestamp": "2026-01-11T13:47:55.720937"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 830.417, "latencies_ms": [830.417], "images_per_second": 1.204, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene is set at night, featuring a brightly lit blue bridge spanning a river. A boat is docked at the riverbank, and several people are gathered on the walkway near the water's edge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [37.01, 37.01, 37.01, 40.9, 40.9, 40.9, 40.9, 40.9, 36.84], "power_watts_avg": 39.15, "power_watts_peak": 40.9, "energy_joules_est": 32.54, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-11T13:47:56.631539"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1126.586, "latencies_ms": [1126.586], "images_per_second": 0.888, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The bridge is illuminated with blue and white lights, creating a striking visual effect against the dark night sky. The water reflects the vibrant colors of the lights, adding to the captivating scene. People are gathered on the walkway near the water's edge, enjoying the illuminated view.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.84, 36.84, 36.84, 36.84, 37.1, 37.1, 37.1, 37.1, 37.1, 37.01, 37.01, 37.01], "power_watts_avg": 36.99, "power_watts_peak": 37.1, "energy_joules_est": 41.69, "sample_count": 12, "duration_seconds": 1.127}, "timestamp": "2026-01-11T13:47:57.843817"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 561.353, "latencies_ms": [561.353], "images_per_second": 1.781, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A person's foot is visible wearing a pink shoe with a bow on top, resting on a weathered blue wooden bench.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 20.0}, "power_stats": {"power_watts_samples": [37.01, 37.01, 35.32, 35.32, 35.32, 35.32], "power_watts_avg": 35.88, "power_watts_peak": 37.01, "energy_joules_est": 20.16, "sample_count": 6, "duration_seconds": 0.562}, "timestamp": "2026-01-11T13:47:58.454782"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 857.992, "latencies_ms": [857.992], "images_per_second": 1.166, "prompt_tokens": 21, "response_tokens_est": 25, "n_tiles": 1, "output_text": "shoe: 1\nbow: 1\npants: 1\nbench: 4\nwood: 4\npaint: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.37, 36.37, 36.37, 36.37, 36.37, 39.38, 39.38, 39.38, 39.38], "power_watts_avg": 37.71, "power_watts_peak": 39.38, "energy_joules_est": 32.37, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:47:59.365173"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 682.932, "latencies_ms": [682.932], "images_per_second": 1.464, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The pink shoe is positioned in the foreground, close to the person's leg. The blue wooden surface forms the background, creating a contrast with the vibrant pink shoe.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [39.38, 39.92, 39.92, 39.92, 39.92, 39.92, 37.46], "power_watts_avg": 39.49, "power_watts_peak": 39.92, "energy_joules_est": 27.0, "sample_count": 7, "duration_seconds": 0.684}, "timestamp": "2026-01-11T13:48:00.075727"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 773.878, "latencies_ms": [773.878], "images_per_second": 1.292, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A person is sitting on worn wooden benches with peeling paint, wearing bright pink flats and blue jeans. The scene suggests a casual, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.46, 37.46, 37.46, 37.46, 40.55, 40.55, 40.55, 40.55], "power_watts_avg": 39.0, "power_watts_peak": 40.55, "energy_joules_est": 30.2, "sample_count": 8, "duration_seconds": 0.774}, "timestamp": "2026-01-11T13:48:00.885366"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 654.988, "latencies_ms": [654.988], "images_per_second": 1.527, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The pink shoe stands out against the blue and green painted wooden surface. The lighting appears to be natural, possibly sunlight, giving the scene a vibrant feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [40.55, 39.66, 39.66, 39.66, 39.66, 39.66, 38.22], "power_watts_avg": 39.58, "power_watts_peak": 40.55, "energy_joules_est": 25.94, "sample_count": 7, "duration_seconds": 0.655}, "timestamp": "2026-01-11T13:48:01.592613"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 678.689, "latencies_ms": [678.689], "images_per_second": 1.473, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman in a green sweater is holding a knife and standing next to a young boy in a plaid shirt at a dining table.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [38.22, 38.22, 38.22, 38.22, 46.29, 46.29, 46.29], "power_watts_avg": 41.68, "power_watts_peak": 46.29, "energy_joules_est": 28.31, "sample_count": 7, "duration_seconds": 0.679}, "timestamp": "2026-01-11T13:48:02.304439"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 992.451, "latencies_ms": [992.451], "images_per_second": 1.008, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "woman: 2\nknife: 1\ntable: 1\ncake: 1\ncup: 1\nboy: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [46.29, 46.29, 48.92, 48.92, 48.92, 48.92, 48.92, 43.92, 43.92, 43.92], "power_watts_avg": 46.89, "power_watts_peak": 48.92, "energy_joules_est": 46.56, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-11T13:48:03.318479"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 870.279, "latencies_ms": [870.279], "images_per_second": 1.149, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, holding the knife. The boy stands in the background, slightly further away. The table occupies the foreground, with a cake and cup placed on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.92, 43.92, 43.55, 43.55, 43.55, 43.55, 43.55, 43.99, 43.99], "power_watts_avg": 43.73, "power_watts_peak": 43.99, "energy_joules_est": 38.08, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:48:04.228942"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1098.676, "latencies_ms": [1098.676], "images_per_second": 0.91, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "A woman is holding a knife and appears to be preparing to cut a cake or cake tin. A young boy stands nearby, observing the scene. The setting appears to be a dining room or kitchen, with a table, chairs, and a red wall visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.99, 43.99, 43.99, 48.05, 48.05, 48.05, 48.05, 48.05, 43.81, 43.81, 43.81], "power_watts_avg": 45.78, "power_watts_peak": 48.05, "energy_joules_est": 50.33, "sample_count": 11, "duration_seconds": 1.099}, "timestamp": "2026-01-11T13:48:05.341888"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1172.239, "latencies_ms": [1172.239], "images_per_second": 0.853, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The room has a red wall and soft lighting, creating a warm and inviting atmosphere. The woman is wearing a green cardigan and patterned pants, while the boy is dressed in a blue plaid shirt. A cake is visible on the table, contributing to the festive ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.2, "ram_available_mb": 109427.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.81, 43.81, 39.51, 39.51, 39.51, 39.51, 39.51, 44.11, 44.11, 44.11, 44.11, 44.11], "power_watts_avg": 42.15, "power_watts_peak": 44.11, "energy_joules_est": 49.43, "sample_count": 12, "duration_seconds": 1.173}, "timestamp": "2026-01-11T13:48:06.553585"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 557.511, "latencies_ms": [557.511], "images_per_second": 1.794, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "Two elephants stand side by side in an indoor arena, facing the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [41.15, 41.15, 41.15, 41.15, 43.6, 43.6], "power_watts_avg": 41.97, "power_watts_peak": 43.6, "energy_joules_est": 23.42, "sample_count": 6, "duration_seconds": 0.558}, "timestamp": "2026-01-11T13:48:07.161986"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1327.389, "latencies_ms": [1327.389], "images_per_second": 0.753, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Elephant: 2\nCircus ring: 2\nBleachers: 4\nLighting equipment: 2\nPerson in red vest: 1\nPerson in black shirt: 1\nPerson in black pants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 53.19, 53.19, 53.19, 53.19, 53.19, 43.41, 43.41, 43.41, 43.41, 43.41, 33.93], "power_watts_avg": 46.26, "power_watts_peak": 53.19, "energy_joules_est": 61.43, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-11T13:48:08.575929"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 889.469, "latencies_ms": [889.469], "images_per_second": 1.124, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a person standing near the right side of the foreground. The background features bleachers, suggesting the setting is a circus or arena.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.4, "ram_available_mb": 109426.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [33.93, 33.93, 33.93, 33.93, 42.62, 42.62, 42.62, 42.62, 42.62], "power_watts_avg": 38.76, "power_watts_peak": 42.62, "energy_joules_est": 34.5, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-11T13:48:09.487332"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 906.304, "latencies_ms": [906.304], "images_per_second": 1.103, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two elephants are performing in a circus ring. A person is assisting one of the elephants, possibly performing a routine or interacting with the animal. The setting is indoors, with bleachers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 42.38, 43.65, 43.65, 43.65, 43.65, 43.65], "power_watts_avg": 43.02, "power_watts_peak": 43.65, "energy_joules_est": 39.01, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-11T13:48:10.495545"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 918.731, "latencies_ms": [918.731], "images_per_second": 1.088, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The elephants are brown and gray. The lighting in the arena is bright and focused, illuminating the scene. The arena appears to be constructed of concrete and metal, with bleachers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 42.87, 42.87, 42.87, 42.27, 42.27, 42.27, 42.27, 42.27], "power_watts_avg": 42.57, "power_watts_peak": 42.87, "energy_joules_est": 39.14, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:48:11.504985"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 852.907, "latencies_ms": [852.907], "images_per_second": 1.172, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Three jockeys on horseback are galloping along the wet sand of a beach, their horses' hooves kicking up small waves as they race towards the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.23, 42.23, 42.23, 42.23, 42.23, 42.46, 42.46, 42.46, 42.46], "power_watts_avg": 42.33, "power_watts_peak": 42.46, "energy_joules_est": 36.14, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-11T13:48:12.414160"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 998.653, "latencies_ms": [998.653], "images_per_second": 1.001, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Horses: 3\nJockeys: 2\nBeach: 2\nSand: 2\nWater: 2\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.46, 41.59, 41.59, 41.59, 41.59, 41.59, 43.18, 43.18, 43.18, 43.18], "power_watts_avg": 42.32, "power_watts_peak": 43.18, "energy_joules_est": 42.27, "sample_count": 10, "duration_seconds": 0.999}, "timestamp": "2026-01-11T13:48:13.423528"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 888.453, "latencies_ms": [888.453], "images_per_second": 1.126, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the horses running towards the background. The horses are relatively close to the viewer, while the background is further away, suggesting the scene is captured from a distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.18, 43.61, 43.61, 43.61, 43.61, 43.61, 43.89, 43.89, 43.89], "power_watts_avg": 43.65, "power_watts_peak": 43.89, "energy_joules_est": 38.8, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:48:14.332675"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1128.506, "latencies_ms": [1128.506], "images_per_second": 0.886, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Two jockeys on horseback are galloping across a sandy beach, their horses' hooves kicking up small waves as they race. The scene is captured in sepia tones, giving it a nostalgic and timeless feel.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.89, 43.89, 48.84, 48.84, 48.84, 48.84, 48.84, 43.48, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 45.78, "power_watts_peak": 48.84, "energy_joules_est": 51.71, "sample_count": 12, "duration_seconds": 1.129}, "timestamp": "2026-01-11T13:48:15.546646"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 996.125, "latencies_ms": [996.125], "images_per_second": 1.004, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The horses and riders are wearing light-colored clothing. The scene is illuminated by soft, diffused light, likely from the overcast sky. The sandy beach and ocean suggest a coastal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [39.09, 39.09, 39.09, 39.09, 39.09, 42.58, 42.58, 42.58, 42.58, 42.58], "power_watts_avg": 40.84, "power_watts_peak": 42.58, "energy_joules_est": 40.7, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-11T13:48:16.559115"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 736.997, "latencies_ms": [736.997], "images_per_second": 1.357, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young man in a black snowsuit and goggles is talking on his cellphone while standing in a snowy area surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13079.3, "ram_available_mb": 109427.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 42.38, 42.38, 43.71, 43.71, 43.71, 43.71], "power_watts_avg": 43.04, "power_watts_peak": 43.71, "energy_joules_est": 31.74, "sample_count": 8, "duration_seconds": 0.737}, "timestamp": "2026-01-11T13:48:17.370936"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1454.85, "latencies_ms": [1454.85], "images_per_second": 0.687, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Goggles: 1\nJacket: 1\nT-shirt: 1\nSnowboard: 1\nPhone: 1\nPinstripe: 1\nBrooch: 1\nTrees: 1\nSnow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.71, 46.75, 46.75, 46.75, 46.75, 46.75, 43.21, 43.21, 43.21, 43.21, 43.21, 41.9, 41.9, 41.9, 41.9], "power_watts_avg": 44.07, "power_watts_peak": 46.75, "energy_joules_est": 64.13, "sample_count": 15, "duration_seconds": 1.455}, "timestamp": "2026-01-11T13:48:18.886726"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1164.662, "latencies_ms": [1164.662], "images_per_second": 0.859, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The main object is a person wearing a winter jacket, standing in the foreground of the image. The background consists of snow and trees, indicating a relatively cold environment. The person appears to be engaged in a phone conversation, further emphasizing the proximity of the person to the snowy background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.9, 36.07, 36.07, 36.07, 36.07, 36.07, 42.88, 42.88, 42.88, 42.88, 42.88, 41.01], "power_watts_avg": 39.8, "power_watts_peak": 42.88, "energy_joules_est": 46.38, "sample_count": 12, "duration_seconds": 1.165}, "timestamp": "2026-01-11T13:48:20.096602"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 881.31, "latencies_ms": [881.31], "images_per_second": 1.135, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A young man is outdoors in a snowy setting, wearing a black snowboarding jacket and goggles. He is talking on a cell phone while standing amidst snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.01, 41.01, 41.01, 41.01, 43.55, 43.55, 43.55, 43.55, 43.55], "power_watts_avg": 42.42, "power_watts_peak": 43.55, "energy_joules_est": 37.4, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-11T13:48:21.007683"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 803.422, "latencies_ms": [803.422], "images_per_second": 1.245, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The person is wearing a black jacket with vertical pinstripes. The lighting suggests it's daytime, and the snowy ground indicates a cold, wintery environment.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.28, 43.28, 43.28, 43.28, 43.28, 43.94, 43.94, 43.94, 43.94], "power_watts_avg": 43.57, "power_watts_peak": 43.94, "energy_joules_est": 35.02, "sample_count": 9, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:48:21.916499"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 666.308, "latencies_ms": [666.308], "images_per_second": 1.501, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A white dirt bike with black saddlebags is parked next to a green tent in a grassy field at sunset.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [43.94, 42.96, 42.96, 42.96, 42.96, 42.96, 42.05], "power_watts_avg": 42.97, "power_watts_peak": 43.94, "energy_joules_est": 28.66, "sample_count": 7, "duration_seconds": 0.667}, "timestamp": "2026-01-11T13:48:22.626999"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1086.239, "latencies_ms": [1086.239], "images_per_second": 0.921, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "tent: 1\nmotorcycle: 1\nbags: 2\ntires: 2\nsunset: 1\ntrees: 4\ngrass: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [42.05, 42.05, 42.05, 42.05, 53.65, 53.65, 53.65, 53.65, 53.65, 43.45, 43.45], "power_watts_avg": 47.58, "power_watts_peak": 53.65, "energy_joules_est": 51.7, "sample_count": 11, "duration_seconds": 1.087}, "timestamp": "2026-01-11T13:48:23.737153"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 741.027, "latencies_ms": [741.027], "images_per_second": 1.349, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The green tent is positioned in the foreground, slightly to the left of the motorcycle. The motorcycle is situated in the background, closer to the center and slightly to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.45, 43.45, 43.45, 43.65, 43.65, 43.65, 43.65, 43.65], "power_watts_avg": 43.58, "power_watts_peak": 43.65, "energy_joules_est": 32.31, "sample_count": 8, "duration_seconds": 0.741}, "timestamp": "2026-01-11T13:48:24.547687"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 819.492, "latencies_ms": [819.492], "images_per_second": 1.22, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a camping area in a wooded area during sunset. A green tent is set up next to a parked motorcycle, providing a peaceful and rustic setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.94, 43.94, 43.94, 43.94, 43.94, 43.48, 43.48, 43.48, 43.48], "power_watts_avg": 43.73, "power_watts_peak": 43.94, "energy_joules_est": 35.86, "sample_count": 9, "duration_seconds": 0.82}, "timestamp": "2026-01-11T13:48:25.459165"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 983.391, "latencies_ms": [983.391], "images_per_second": 1.017, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The tent is green, and the surrounding area is covered in dry grass. The lighting suggests it's either early morning or late evening. The materials appear to be canvas and possibly a metal frame for the motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.6, 41.6, 41.6, 41.6, 41.6, 42.58, 42.58, 42.58, 42.58, 42.58], "power_watts_avg": 42.09, "power_watts_peak": 42.58, "energy_joules_est": 41.42, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-11T13:48:26.470858"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 750.514, "latencies_ms": [750.514], "images_per_second": 1.332, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A vintage steam locomotive numbered 67371 pulls passenger cars along a track, with people waiting on the platform and buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.13, 44.13, 44.13, 44.13, 44.13, 43.69, 43.69, 43.69], "power_watts_avg": 43.97, "power_watts_peak": 44.13, "energy_joules_est": 33.01, "sample_count": 8, "duration_seconds": 0.751}, "timestamp": "2026-01-11T13:48:27.278716"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1154.936, "latencies_ms": [1154.936], "images_per_second": 0.866, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "steam locomotive: 1\ntrain carriages: 3\npeople: 3\nplatform: 1\nsign: 1\nbuildings: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.69, 43.69, 50.9, 50.9, 50.9, 50.9, 50.9, 43.19, 43.19, 43.19, 43.19, 43.19], "power_watts_avg": 46.48, "power_watts_peak": 50.9, "energy_joules_est": 53.71, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:48:28.492760"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 735.369, "latencies_ms": [735.369], "images_per_second": 1.36, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The steam locomotive is positioned in the foreground, facing the viewer. The train station and surrounding buildings are in the background, appearing relatively distant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.43, 36.43, 36.43, 36.43, 36.43, 43.25, 43.25, 43.25], "power_watts_avg": 38.99, "power_watts_peak": 43.25, "energy_joules_est": 28.69, "sample_count": 8, "duration_seconds": 0.736}, "timestamp": "2026-01-11T13:48:29.303468"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 833.25, "latencies_ms": [833.25], "images_per_second": 1.2, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a vintage steam locomotive pulling passenger cars at a train station. A group of people is waiting on the platform, observing the train as it departs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.2, "ram_available_mb": 109426.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.25, 43.25, 50.02, 50.02, 50.02, 50.02, 50.02, 43.0, 43.0], "power_watts_avg": 46.95, "power_watts_peak": 50.02, "energy_joules_est": 39.15, "sample_count": 9, "duration_seconds": 0.834}, "timestamp": "2026-01-11T13:48:30.212197"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1096.659, "latencies_ms": [1096.659], "images_per_second": 0.912, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The train is primarily dark in color, contrasting with the lighter background of the station. The lighting suggests it was taken during daytime. The train appears to be made of metal and has a smokestack, indicating it might be steam-powered.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.0, 43.0, 43.0, 45.84, 45.84, 45.84, 45.84, 45.84, 42.6, 42.6, 42.6], "power_watts_avg": 44.18, "power_watts_peak": 45.84, "energy_joules_est": 48.48, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-11T13:48:31.326120"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 744.735, "latencies_ms": [744.735], "images_per_second": 1.343, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Numerous Chinese street signs and advertisements are suspended from wires above a bustling urban street, displaying various characters and phrases.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 39.97, 39.97, 39.97, 39.97, 39.97, 43.98], "power_watts_avg": 41.13, "power_watts_peak": 43.98, "energy_joules_est": 30.66, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-11T13:48:32.138854"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1030.693, "latencies_ms": [1030.693], "images_per_second": 0.97, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "building: 10\nsign: 10\nstreet: 10\ncar: 1\nstreetlights: 2\npower lines: 2\nbuildings: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.98, 43.98, 43.98, 43.98, 48.53, 48.53, 48.53, 48.53, 48.53, 43.44, 43.44], "power_watts_avg": 45.95, "power_watts_peak": 48.53, "energy_joules_est": 47.37, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-11T13:48:33.251368"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1007.937, "latencies_ms": [1007.937], "images_per_second": 0.992, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The foreground features numerous signs and wires hanging from the buildings, creating a dense and intricate urban scene. The background includes buildings of varying heights and architectural styles, further emphasizing the density and complexity of the cityscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 43.44, 42.56, 42.56, 42.56, 42.56, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 43.06, "power_watts_peak": 43.44, "energy_joules_est": 43.42, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-11T13:48:34.363986"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1219.452, "latencies_ms": [1219.452], "images_per_second": 0.82, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The black and white image depicts a bustling city street lined with numerous multi-storied buildings adorned with numerous signs in Chinese characters. The signs suggest a commercial area, possibly a street market or shopping district, with various shops and businesses visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.27, 37.32, 37.32, 37.32, 37.32, 37.32, 41.91, 41.91, 41.91, 41.91, 41.91, 40.51, 40.51], "power_watts_avg": 40.03, "power_watts_peak": 43.27, "energy_joules_est": 48.83, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-11T13:48:35.676138"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1432.797, "latencies_ms": [1432.797], "images_per_second": 0.698, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The black and white photograph captures a dense urban environment with numerous signs and buildings. The signs display Chinese characters and appear to hang from wires above. The lighting is uneven, with some areas brighter than others, creating a dramatic effect. The buildings are constructed of concrete and metal, giving the scene a gritty and industrial feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.51, 40.51, 40.51, 42.5, 42.5, 42.5, 42.5, 42.5, 42.63, 42.63, 42.63, 42.63, 42.63, 33.96, 33.96], "power_watts_avg": 41.01, "power_watts_peak": 42.63, "energy_joules_est": 58.77, "sample_count": 15, "duration_seconds": 1.433}, "timestamp": "2026-01-11T13:48:37.186990"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 789.701, "latencies_ms": [789.701], "images_per_second": 1.266, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A man in blue shorts and sunglasses sits on a concrete ledge by a body of water, with a \"CLOSED Lakefront Trail\" sign in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.96, 33.96, 33.96, 43.0, 43.0, 43.0, 43.0, 43.0], "power_watts_avg": 39.61, "power_watts_peak": 43.0, "energy_joules_est": 31.29, "sample_count": 8, "duration_seconds": 0.79}, "timestamp": "2026-01-11T13:48:37.996534"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1122.793, "latencies_ms": [1122.793], "images_per_second": 0.891, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "man: 1\nsign: 1\ngrass: 1\nwater: 1\nsign: 1\nwood: 1\npolice: 1\ncross: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.92, 42.92, 42.92, 42.92, 42.92, 43.9, 43.9, 43.9, 43.9, 43.9, 43.73, 43.73], "power_watts_avg": 43.47, "power_watts_peak": 43.9, "energy_joules_est": 48.81, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:48:39.207270"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1065.825, "latencies_ms": [1065.825], "images_per_second": 0.938, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is positioned near the lake, sitting on the concrete bank. The lake stretches across the background, providing a serene backdrop. The foreground features the closed sign and the wooden plank, partially obstructing the view of the lake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.1, "ram_available_mb": 109426.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.73, 43.73, 43.73, 42.7, 42.7, 42.7, 42.7, 42.7, 42.42, 42.42, 42.42], "power_watts_avg": 42.91, "power_watts_peak": 43.73, "energy_joules_est": 45.74, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-11T13:48:40.315588"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 844.076, "latencies_ms": [844.076], "images_per_second": 1.185, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A man is sitting on the edge of a concrete structure near a body of water, enjoying the view. A red and white sign indicates that the lakefront trail is closed.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.42, 42.42, 39.6, 39.6, 39.6, 39.6, 39.6, 43.43, 43.43], "power_watts_avg": 41.08, "power_watts_peak": 43.43, "energy_joules_est": 34.7, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-11T13:48:41.225443"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1086.572, "latencies_ms": [1086.572], "images_per_second": 0.92, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene is bathed in natural daylight, creating a bright and airy atmosphere. The grass appears slightly dry, suggesting it might be a sunny day. The lake's surface reflects the sunlight, adding to the overall brightness of the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.43, 43.43, 43.43, 47.49, 47.49, 47.49, 47.49, 47.49, 43.17, 43.17, 43.17], "power_watts_avg": 45.2, "power_watts_peak": 47.49, "energy_joules_est": 49.13, "sample_count": 11, "duration_seconds": 1.087}, "timestamp": "2026-01-11T13:48:42.335616"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 719.705, "latencies_ms": [719.705], "images_per_second": 1.389, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A golden retriever dog stands attentively in a lush green field, its tongue hanging out, alongside a majestic brown horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 39.21, 39.21, 39.21, 39.21, 39.21, 43.89], "power_watts_avg": 40.78, "power_watts_peak": 43.89, "energy_joules_est": 29.37, "sample_count": 8, "duration_seconds": 0.72}, "timestamp": "2026-01-11T13:48:43.147148"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 876.025, "latencies_ms": [876.025], "images_per_second": 1.142, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "horse: 1\ndog: 1\ngrass: 2\nsky: 1\ntrees: 1\nground: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13080.0, "ram_available_mb": 109426.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.8, "ram_available_mb": 109428.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.89, 43.89, 43.89, 43.89, 47.66, 47.66, 47.66, 47.66, 47.66], "power_watts_avg": 45.99, "power_watts_peak": 47.66, "energy_joules_est": 40.31, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-11T13:48:44.057262"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 827.275, "latencies_ms": [827.275], "images_per_second": 1.209, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The dog and horse are positioned close to the foreground, creating a sense of proximity and interaction. The horse is slightly further in the background, emphasizing the vastness of the grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.8, "ram_available_mb": 109428.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13079.0, "ram_available_mb": 109427.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.81, 42.81, 42.81, 42.81, 43.71, 43.71, 43.71, 43.71, 43.71], "power_watts_avg": 43.31, "power_watts_peak": 43.71, "energy_joules_est": 35.84, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:48:44.965212"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 925.544, "latencies_ms": [925.544], "images_per_second": 1.08, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "In the image, a brown horse and a golden retriever are standing in a green field. The horse is positioned slightly behind the dog, appearing to be observing or interacting with the dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.0, "ram_available_mb": 109427.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13080.7, "ram_available_mb": 109425.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.51, 42.51, 42.51, 42.51, 42.51, 42.83, 42.83, 42.83, 42.83, 42.83], "power_watts_avg": 42.67, "power_watts_peak": 42.83, "energy_joules_est": 39.5, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-11T13:48:45.975498"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 831.811, "latencies_ms": [831.811], "images_per_second": 1.202, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The horse and dog are brown and white respectively. The lighting is bright and sunny, creating a pleasant atmosphere. The scene takes place in a green field under a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 42.88, 42.88, 42.88, 42.64, 42.64, 42.64, 42.64], "power_watts_avg": 42.77, "power_watts_peak": 42.88, "energy_joules_est": 35.59, "sample_count": 9, "duration_seconds": 0.832}, "timestamp": "2026-01-11T13:48:46.885192"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 598.261, "latencies_ms": [598.261], "images_per_second": 1.672, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A volleyball game is in progress, with players in green and blue uniforms actively participating.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 28.0}, "power_stats": {"power_watts_samples": [42.64, 45.53, 45.53, 45.53, 45.53, 45.53], "power_watts_avg": 45.05, "power_watts_peak": 45.53, "energy_joules_est": 26.98, "sample_count": 6, "duration_seconds": 0.599}, "timestamp": "2026-01-11T13:48:47.493417"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1532.448, "latencies_ms": [1532.448], "images_per_second": 0.653, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "volleyball: 8\nnet: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.83, 42.83, 42.83, 42.83, 42.83, 52.6, 52.6, 52.6, 52.6, 52.6, 44.45, 44.45, 44.45, 44.45, 44.45, 34.3], "power_watts_avg": 45.86, "power_watts_peak": 52.6, "energy_joules_est": 70.29, "sample_count": 16, "duration_seconds": 1.533}, "timestamp": "2026-01-11T13:48:49.108051"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1210.027, "latencies_ms": [1210.027], "images_per_second": 0.826, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The volleyball game is taking place in a large, open indoor space. The players are spread out across the court, with some closer to the net and others further away. The foreground player is preparing to hit the volleyball, while the background players are positioned near the net.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.3, 34.3, 34.3, 34.3, 42.98, 42.98, 42.98, 42.98, 42.98, 42.94, 42.94, 42.94, 42.94], "power_watts_avg": 40.3, "power_watts_peak": 42.98, "energy_joules_est": 48.77, "sample_count": 13, "duration_seconds": 1.21}, "timestamp": "2026-01-11T13:48:50.421292"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 921.632, "latencies_ms": [921.632], "images_per_second": 1.085, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of people are playing volleyball in a large, indoor gymnasium. The players are wearing green and blue uniforms, and the game is taking place on a blue court with orange and white lines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.94, 33.27, 33.27, 33.27, 33.27, 33.27, 42.42, 42.42, 42.42, 42.42], "power_watts_avg": 37.9, "power_watts_peak": 42.94, "energy_joules_est": 34.95, "sample_count": 10, "duration_seconds": 0.922}, "timestamp": "2026-01-11T13:48:51.432292"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 851.173, "latencies_ms": [851.173], "images_per_second": 1.175, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The gym has light blue flooring and neutral lighting. The volleyball net is white, and the players are wearing various colors, including green and blue.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.42, 42.1, 42.1, 42.1, 42.1, 42.1, 42.53, 42.53, 42.53], "power_watts_avg": 42.28, "power_watts_peak": 42.53, "energy_joules_est": 36.0, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-11T13:48:52.341326"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 891.148, "latencies_ms": [891.148], "images_per_second": 1.122, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A group of zebras and wildebeests are seen grazing and walking across a grassy plain near a body of water, with a large flock of flamingos visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 48.26, 48.26, 48.26, 48.26, 48.26, 43.21, 43.21], "power_watts_avg": 45.87, "power_watts_peak": 48.26, "energy_joules_est": 40.89, "sample_count": 9, "duration_seconds": 0.891}, "timestamp": "2026-01-11T13:48:53.251243"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1152.118, "latencies_ms": [1152.118], "images_per_second": 0.868, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "zebras: 5\nflamingos: 10\nwildebeests: 4\ngrass: 8\nwater: 2\nhills: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.21, 43.21, 43.21, 48.58, 48.58, 48.58, 48.58, 48.58, 44.11, 44.11, 44.11, 44.11], "power_watts_avg": 45.75, "power_watts_peak": 48.58, "energy_joules_est": 52.71, "sample_count": 12, "duration_seconds": 1.152}, "timestamp": "2026-01-11T13:48:54.463942"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1190.375, "latencies_ms": [1190.375], "images_per_second": 0.84, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The zebras are positioned in the foreground, moving across the grassy plain. The wildebeest are grazing in the background, near the left side of the image. The large flock of flamingos is situated in the background, near the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13074.9, "ram_available_mb": 109431.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.86, 33.86, 33.86, 33.86, 33.86, 42.64, 42.64, 42.64, 42.64, 42.64, 43.48, 43.48], "power_watts_avg": 39.12, "power_watts_peak": 43.48, "energy_joules_est": 46.59, "sample_count": 12, "duration_seconds": 1.191}, "timestamp": "2026-01-11T13:48:55.675276"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1191.562, "latencies_ms": [1191.562], "images_per_second": 0.839, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene depicts a vast grassy plain with zebras and wildebeests grazing and moving across the landscape. A large flock of flamingos is gathered on a body of water in the background, creating a striking contrast between the animals and the vibrant pink hues.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13074.9, "ram_available_mb": 109431.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.48, 43.73, 43.73, 43.73, 43.73, 43.73, 43.62, 43.62, 43.62, 43.62], "power_watts_avg": 43.63, "power_watts_peak": 43.73, "energy_joules_est": 52.01, "sample_count": 12, "duration_seconds": 1.192}, "timestamp": "2026-01-11T13:48:56.886084"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1325.799, "latencies_ms": [1325.799], "images_per_second": 0.754, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene is dominated by vibrant colors from the flamingos and the zebras' distinctive black and white stripes. The lighting is soft and diffused, suggesting an overcast sky or diffused sunlight. The landscape appears dry and dusty, with sparse vegetation and rocky terrain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.62, 36.12, 36.12, 36.12, 36.12, 36.12, 43.91, 43.91, 43.91, 43.91, 43.91, 42.26, 42.26, 42.26], "power_watts_avg": 40.75, "power_watts_peak": 43.91, "energy_joules_est": 54.05, "sample_count": 14, "duration_seconds": 1.326}, "timestamp": "2026-01-11T13:48:58.297747"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 679.918, "latencies_ms": [679.918], "images_per_second": 1.471, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "An orange and white cat is sitting on a wooden deck, looking at its reflection in the glass surface in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.26, 42.26, 39.24, 39.24, 39.24, 39.24, 39.24], "power_watts_avg": 40.1, "power_watts_peak": 42.26, "energy_joules_est": 27.29, "sample_count": 7, "duration_seconds": 0.68}, "timestamp": "2026-01-11T13:48:59.007569"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1184.379, "latencies_ms": [1184.379], "images_per_second": 0.844, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "cat: 2\nmirror: 1\nwooden planks: 8\nglass: 1\nreflection: 1\ncat's fur: 2\ncat's eyes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.07, 42.07, 42.07, 42.07, 42.07, 46.33, 46.33, 46.33, 46.33, 46.33, 43.87, 43.87], "power_watts_avg": 44.14, "power_watts_peak": 46.33, "energy_joules_est": 52.31, "sample_count": 12, "duration_seconds": 1.185}, "timestamp": "2026-01-11T13:49:00.221892"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 903.378, "latencies_ms": [903.378], "images_per_second": 1.107, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The orange and white cat is positioned in the foreground, looking at its reflection in the glass surface. The wooden deck extends into the background, providing a contrast to the cat's vibrant colors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.87, 43.87, 43.87, 43.3, 43.3, 43.3, 43.3, 43.3, 43.58], "power_watts_avg": 43.52, "power_watts_peak": 43.87, "energy_joules_est": 39.32, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:49:01.132821"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 993.566, "latencies_ms": [993.566], "images_per_second": 1.006, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene takes place on a wooden deck outdoors, likely on a patio or deck area. The cat is interacting with its reflection in a glass surface, possibly enjoying a moment of self-grooming or observing its surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.58, 43.58, 43.58, 43.58, 44.54, 44.54, 44.54, 44.54, 44.54, 43.97], "power_watts_avg": 44.1, "power_watts_peak": 44.54, "energy_joules_est": 43.84, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-11T13:49:02.144278"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 828.024, "latencies_ms": [828.024], "images_per_second": 1.208, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The cat is primarily orange and white. The lighting appears to be natural, possibly from sunlight filtering through the glass. The cat is sitting on a wooden surface, which appears to be outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.97, 43.97, 43.97, 43.97, 43.87, 43.87, 43.87, 43.87, 43.87], "power_watts_avg": 43.91, "power_watts_peak": 43.97, "energy_joules_est": 36.38, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:49:03.054115"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 617.214, "latencies_ms": [617.214], "images_per_second": 1.62, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Several boats are docked along the shore of a calm lake, with a large building visible in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.68, 43.68, 43.68, 43.68, 43.68, 42.28, 42.28], "power_watts_avg": 43.28, "power_watts_peak": 43.68, "energy_joules_est": 26.74, "sample_count": 7, "duration_seconds": 0.618}, "timestamp": "2026-01-11T13:49:03.764223"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1147.143, "latencies_ms": [1147.143], "images_per_second": 0.872, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Boat: 4\nLamp post: 1\nBuildings: 2\nTrees: 6\nWater: 5\nSky: 1\nHills: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 49.64, 49.64, 49.64, 49.64, 49.64, 42.69, 42.69, 42.69, 42.69, 42.69], "power_watts_avg": 45.51, "power_watts_peak": 49.64, "energy_joules_est": 52.24, "sample_count": 12, "duration_seconds": 1.148}, "timestamp": "2026-01-11T13:49:04.975731"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 892.078, "latencies_ms": [892.078], "images_per_second": 1.121, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the waterway and buildings in the background. The foreground includes several boats docked near the shore, while the background features more buildings and a larger body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.67, 35.67, 35.67, 35.67, 35.67, 42.86, 42.86, 42.86, 42.86], "power_watts_avg": 38.86, "power_watts_peak": 42.86, "energy_joules_est": 34.69, "sample_count": 9, "duration_seconds": 0.893}, "timestamp": "2026-01-11T13:49:05.885483"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1029.911, "latencies_ms": [1029.911], "images_per_second": 0.971, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a serene lakeside town with several boats docked along the shore. The buildings in the background suggest a resort or hotel complex. The calm water reflects the hazy sky, creating a tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.86, 46.37, 46.37, 46.37, 46.37, 46.37, 43.84, 43.84, 43.84, 43.84, 43.84], "power_watts_avg": 44.9, "power_watts_peak": 46.37, "energy_joules_est": 46.27, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-11T13:49:06.996828"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 981.806, "latencies_ms": [981.806], "images_per_second": 1.019, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The water is a calm, grayish-blue color. The lighting suggests an overcast day, with diffused light. The boats are primarily white and appear to be made of metal or fiberglass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.2, "ram_available_mb": 109431.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.75, 41.75, 41.75, 41.75, 41.75, 42.95, 42.95, 42.95, 42.95, 42.95], "power_watts_avg": 42.35, "power_watts_peak": 42.95, "energy_joules_est": 41.59, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-11T13:49:08.007436"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 450.264, "latencies_ms": [450.264], "images_per_second": 2.221, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A man walks his bicycle down a city street, wearing a towel around his waist.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.71, 43.71, 43.71, 43.71, 43.71], "power_watts_avg": 43.71, "power_watts_peak": 43.71, "energy_joules_est": 19.7, "sample_count": 5, "duration_seconds": 0.451}, "timestamp": "2026-01-11T13:49:08.516788"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1138.204, "latencies_ms": [1138.204], "images_per_second": 0.879, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "building: 2\nsign: 2\nbicycle: 2\nman: 1\ntowel: 1\nperson: 1\numbrella: 1\nair conditioner: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.26, 38.26, 38.26, 38.26, 38.26, 42.06, 42.06, 42.06, 42.06, 42.06, 37.82, 37.82], "power_watts_avg": 39.77, "power_watts_peak": 42.06, "energy_joules_est": 45.29, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-11T13:49:09.729698"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 843.48, "latencies_ms": [843.48], "images_per_second": 1.186, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The man is positioned in the foreground, facing the camera. The bicycle is situated in the background, slightly to the right. The storefront and signage are located in the background, further away from the man.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [37.82, 37.82, 37.82, 37.17, 37.17, 37.17, 37.17, 37.17, 37.08], "power_watts_avg": 37.38, "power_watts_peak": 37.82, "energy_joules_est": 31.55, "sample_count": 9, "duration_seconds": 0.844}, "timestamp": "2026-01-11T13:49:10.639766"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1061.698, "latencies_ms": [1061.698], "images_per_second": 0.942, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a street scene in what appears to be a Chinese town. A man is walking with a bicycle, wearing a towel around his waist. Behind him, there are several shops and signs in Chinese characters, indicating a bustling and possibly touristy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.08, 37.08, 37.08, 37.08, 37.61, 37.61, 37.61, 37.61, 37.61, 37.36, 37.36], "power_watts_avg": 37.37, "power_watts_peak": 37.61, "energy_joules_est": 39.71, "sample_count": 11, "duration_seconds": 1.062}, "timestamp": "2026-01-11T13:49:11.750085"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 771.195, "latencies_ms": [771.195], "images_per_second": 1.297, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene is black and white, illuminated by natural light. The buildings appear to have a simple, possibly temporary construction style. The overall atmosphere is somewhat somber and quiet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 57.0}, "power_stats": {"power_watts_samples": [37.36, 37.36, 37.36, 37.36, 37.36, 37.36, 37.36, 37.36], "power_watts_avg": 37.36, "power_watts_peak": 37.36, "energy_joules_est": 28.82, "sample_count": 8, "duration_seconds": 0.771}, "timestamp": "2026-01-11T13:49:12.558585"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 662.08, "latencies_ms": [662.08], "images_per_second": 1.51, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A market stall displays numerous bunches of ripe, yellow bananas hanging from blue ropes, showcasing their vibrant color and abundance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.42, 37.42, 37.42, 37.42, 37.42, 37.67, 37.67], "power_watts_avg": 37.49, "power_watts_peak": 37.67, "energy_joules_est": 24.84, "sample_count": 7, "duration_seconds": 0.663}, "timestamp": "2026-01-11T13:49:13.266322"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1092.674, "latencies_ms": [1092.674], "images_per_second": 0.915, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bananas: 12\nropes: 8\nclothes: 1\nmetal scale: 1\nblue container: 1\nwooden structure: 1\nred curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.67, 37.67, 41.72, 41.72, 41.72, 41.72, 41.72, 37.79, 37.79, 37.79, 37.79], "power_watts_avg": 39.55, "power_watts_peak": 41.72, "energy_joules_est": 43.24, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-11T13:49:14.379599"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 810.053, "latencies_ms": [810.053], "images_per_second": 1.234, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bananas are primarily displayed in the foreground, hanging from the ceiling and suspended from the structure above. The background features the storefront and partially visible items, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.79, 36.61, 36.61, 36.61, 36.61, 36.61, 38.49, 38.49, 38.49], "power_watts_avg": 37.37, "power_watts_peak": 38.49, "energy_joules_est": 30.28, "sample_count": 9, "duration_seconds": 0.81}, "timestamp": "2026-01-11T13:49:15.290096"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 785.418, "latencies_ms": [785.418], "images_per_second": 1.273, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene depicts a market stall displaying a large quantity of ripe, yellow bananas hanging from strings. The bananas are arranged in bunches and appear to be fresh and ready for sale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.49, 38.49, 38.91, 38.91, 38.91, 38.91, 38.91, 37.09], "power_watts_avg": 38.58, "power_watts_peak": 38.91, "energy_joules_est": 30.32, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:49:16.097985"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1011.394, "latencies_ms": [1011.394], "images_per_second": 0.989, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The bananas are predominantly yellow, indicating they are ripe. The lighting appears to be natural, possibly sunlight, giving the bananas a vibrant appearance. The bananas are hanging from strings, suggesting they are likely for sale or display. The overall scene suggests a market setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.09, 37.09, 37.09, 37.09, 38.49, 38.49, 38.49, 38.49, 38.49, 38.65, 38.65], "power_watts_avg": 38.01, "power_watts_peak": 38.65, "energy_joules_est": 38.46, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-11T13:49:17.209084"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 617.331, "latencies_ms": [617.331], "images_per_second": 1.62, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "An electric train travels through a picturesque countryside, passing through a lush green field with distant mountains in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.65, 38.65, 38.65, 42.43, 42.43, 42.43, 42.43], "power_watts_avg": 40.81, "power_watts_peak": 42.43, "energy_joules_est": 25.22, "sample_count": 7, "duration_seconds": 0.618}, "timestamp": "2026-01-11T13:49:17.920035"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1436.745, "latencies_ms": [1436.745], "images_per_second": 0.696, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Train car: 4\nTrain car: 2\nTrain car: 1\nTrain car: 1\nTrain car: 1\nTrain car: 1\nTrain car: 1\nTrain car: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.43, 41.83, 41.83, 41.83, 41.83, 41.83, 42.45, 42.45, 42.45, 42.45, 42.45, 44.33, 44.33, 44.33, 44.33], "power_watts_avg": 42.74, "power_watts_peak": 44.33, "energy_joules_est": 61.44, "sample_count": 15, "duration_seconds": 1.437}, "timestamp": "2026-01-11T13:49:19.434447"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 975.645, "latencies_ms": [975.645], "images_per_second": 1.025, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main object is a train traveling from left to right in the foreground, moving past a grassy field and towards a distant mountain range. The train is positioned near the center of the image, occupying a significant portion of the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.4, "ram_available_mb": 109430.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.33, 32.8, 32.8, 32.8, 32.8, 32.8, 43.06, 43.06, 43.06, 43.06], "power_watts_avg": 38.06, "power_watts_peak": 44.33, "energy_joules_est": 37.15, "sample_count": 10, "duration_seconds": 0.976}, "timestamp": "2026-01-11T13:49:20.445216"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1091.074, "latencies_ms": [1091.074], "images_per_second": 0.917, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a green and white electric train traveling through a rural landscape, pulling several red freight cars along tracks. The setting includes rolling hills, fields, and distant mountains, creating a picturesque backdrop for the train's journey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.06, 43.58, 43.58, 43.58, 43.58, 43.58, 43.59, 43.59, 43.59, 43.59, 43.59], "power_watts_avg": 43.54, "power_watts_peak": 43.59, "energy_joules_est": 47.52, "sample_count": 11, "duration_seconds": 1.091}, "timestamp": "2026-01-11T13:49:21.557336"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 991.164, "latencies_ms": [991.164], "images_per_second": 1.009, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The train is painted in green and white. The scene is illuminated by natural daylight, creating a bright and clear atmosphere. The train appears to be made of sturdy metal and wood, typical of older electric trains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.24, 44.24, 44.24, 44.24, 44.24, 43.77, 43.77, 43.77, 43.77, 43.77], "power_watts_avg": 44.0, "power_watts_peak": 44.24, "energy_joules_est": 43.64, "sample_count": 10, "duration_seconds": 0.992}, "timestamp": "2026-01-11T13:49:22.569173"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 623.146, "latencies_ms": [623.146], "images_per_second": 1.605, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man in khaki shorts and a green hat is standing on a sandy beach, holding a kite and possibly preparing to fly it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 43.82, 38.24, 38.24, 38.24], "power_watts_avg": 41.43, "power_watts_peak": 43.82, "energy_joules_est": 25.83, "sample_count": 7, "duration_seconds": 0.623}, "timestamp": "2026-01-11T13:49:23.278922"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1045.817, "latencies_ms": [1045.817], "images_per_second": 0.956, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "kite: 1\nman: 1\nhat: 1\nsandals: 1\nbeach: 1\nocean: 2\nwaves: 2\nchair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.24, 38.24, 41.57, 41.57, 41.57, 41.57, 41.57, 37.34, 37.34, 37.34, 37.34], "power_watts_avg": 39.42, "power_watts_peak": 41.57, "energy_joules_est": 41.25, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-11T13:49:24.390499"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 834.058, "latencies_ms": [834.058], "images_per_second": 1.199, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The man is standing on the left side of the image, facing the ocean. The kite is positioned in the background, near the right edge of the image. The man appears to be holding the kite string.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.34, 35.62, 35.62, 35.62, 35.62, 35.62, 37.33, 37.33, 37.33], "power_watts_avg": 36.38, "power_watts_peak": 37.34, "energy_joules_est": 30.36, "sample_count": 9, "duration_seconds": 0.835}, "timestamp": "2026-01-11T13:49:25.300642"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 730.697, "latencies_ms": [730.697], "images_per_second": 1.369, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is standing on a sandy beach, flying a kite while holding a kite string in his right hand. He appears to be enjoying the beach weather and the activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.33, 37.33, 39.49, 39.49, 39.49, 39.49, 39.49, 37.69], "power_watts_avg": 38.73, "power_watts_peak": 39.49, "energy_joules_est": 28.31, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:49:26.107720"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1113.964, "latencies_ms": [1113.964], "images_per_second": 0.898, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The beach is sandy and appears light gray. The sky is bright blue, suggesting sunny weather. The man is wearing khaki shorts and a dark shirt, and he is holding a kite string. The kite is partially visible and appears to be yellow and red.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.69, 37.69, 37.69, 37.69, 36.65, 36.65, 36.65, 36.65, 36.65, 36.59, 36.59, 36.59], "power_watts_avg": 36.98, "power_watts_peak": 37.69, "energy_joules_est": 41.21, "sample_count": 12, "duration_seconds": 1.114}, "timestamp": "2026-01-11T13:49:27.319457"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 673.743, "latencies_ms": [673.743], "images_per_second": 1.484, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two orange plastic planters hold healthy broccoli plants with large, green leaves and heads of varying sizes.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [36.59, 36.59, 38.74, 38.74, 38.74, 38.74, 38.74], "power_watts_avg": 38.12, "power_watts_peak": 38.74, "energy_joules_est": 25.71, "sample_count": 7, "duration_seconds": 0.674}, "timestamp": "2026-01-11T13:49:28.029322"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1066.064, "latencies_ms": [1066.064], "images_per_second": 0.938, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Broccoli: 2\nLeaves: 6\nBroccoli florets: 2\nPot: 2\nSoil: 1\nGround: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.15, 42.15, 42.15, 42.15, 42.15, 47.92, 47.92, 47.92, 47.92, 47.92, 43.62], "power_watts_avg": 44.9, "power_watts_peak": 47.92, "energy_joules_est": 47.89, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-11T13:49:29.141805"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 846.797, "latencies_ms": [846.797], "images_per_second": 1.181, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the broccoli plants growing in raised, rectangular containers. The background is relatively empty, emphasizing the broccoli plants in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.62, 43.62, 43.62, 43.62, 43.82, 43.82, 43.82, 43.82, 43.82], "power_watts_avg": 43.73, "power_watts_peak": 43.82, "energy_joules_est": 37.05, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-11T13:49:30.052807"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1126.774, "latencies_ms": [1126.774], "images_per_second": 0.887, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a garden bed with two broccoli plants growing in raised orange plastic containers. The plants have large, green leaves and appear healthy, indicating a well-maintained garden. The ground is sandy and appears to be part of a larger outdoor space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 43.76, 43.76, 43.28, 43.28, 43.28, 43.28, 43.28, 43.15, 43.15], "power_watts_avg": 43.46, "power_watts_peak": 43.76, "energy_joules_est": 48.99, "sample_count": 12, "duration_seconds": 1.127}, "timestamp": "2026-01-11T13:49:31.265757"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1224.945, "latencies_ms": [1224.945], "images_per_second": 0.816, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The broccoli plants exhibit a vibrant green color, indicating healthy growth. The lighting appears to be natural, possibly sunlight, enhancing the freshness and color of the leaves. The plants are housed in terracotta-colored plastic containers, suggesting they are being grown in a controlled environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.15, 43.15, 43.15, 40.66, 40.66, 40.66, 40.66, 42.25, 42.25, 42.25, 42.25, 42.25, 36.0], "power_watts_avg": 41.49, "power_watts_peak": 43.15, "energy_joules_est": 50.84, "sample_count": 13, "duration_seconds": 1.225}, "timestamp": "2026-01-11T13:49:32.580553"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 753.401, "latencies_ms": [753.401], "images_per_second": 1.327, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A young boy is sitting on a small pony while an older man holds its reins, guiding it near a red building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [36.0, 36.0, 36.0, 36.0, 42.15, 42.15, 42.15, 42.15], "power_watts_avg": 39.07, "power_watts_peak": 42.15, "energy_joules_est": 29.45, "sample_count": 8, "duration_seconds": 0.754}, "timestamp": "2026-01-11T13:49:33.393069"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1163.818, "latencies_ms": [1163.818], "images_per_second": 0.859, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "pony: 1\nman: 1\nchild: 1\nbuilding: 1\nleash: 1\nchair: 1\ntable: 1\nlantern: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.15, 44.08, 44.08, 44.08, 44.08, 44.08, 43.25, 43.25, 43.25, 43.25, 43.25, 41.78], "power_watts_avg": 43.38, "power_watts_peak": 44.08, "energy_joules_est": 50.51, "sample_count": 12, "duration_seconds": 1.164}, "timestamp": "2026-01-11T13:49:34.603442"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1114.204, "latencies_ms": [1114.204], "images_per_second": 0.898, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The pony is positioned in the foreground, close to the man and child. The man and child are standing in the background, slightly further away. The pony is situated near a red building, which serves as the backdrop for the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [41.78, 41.78, 41.78, 41.78, 43.13, 43.13, 43.13, 43.13, 43.13, 42.85, 42.85, 42.85], "power_watts_avg": 42.61, "power_watts_peak": 43.13, "energy_joules_est": 47.5, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-11T13:49:35.815202"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 860.999, "latencies_ms": [860.999], "images_per_second": 1.161, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A young boy is riding a small pony outside a red building, possibly a house or stable. A man is leading the pony and guiding it through the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 47.0}, "power_stats": {"power_watts_samples": [42.85, 42.85, 38.88, 38.88, 38.88, 38.88, 38.88, 42.73, 42.73], "power_watts_avg": 40.62, "power_watts_peak": 42.85, "energy_joules_est": 35.01, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-11T13:49:36.726864"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 871.89, "latencies_ms": [871.89], "images_per_second": 1.147, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The pony is light brown with a white blaze on its face. The man is wearing a blue shirt and dark pants. The scene appears to be outdoors in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 47.29, 47.29, 47.29, 47.29, 47.29, 43.59], "power_watts_avg": 45.36, "power_watts_peak": 47.29, "energy_joules_est": 39.57, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-11T13:49:37.637689"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 653.856, "latencies_ms": [653.856], "images_per_second": 1.529, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young boy in a blue striped shirt is walking along a dirt path in a field of blue flowers, holding a stuffed animal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.59, 43.59, 43.59, 43.59, 44.14, 44.14, 44.14], "power_watts_avg": 43.83, "power_watts_peak": 44.14, "energy_joules_est": 28.67, "sample_count": 7, "duration_seconds": 0.654}, "timestamp": "2026-01-11T13:49:38.348871"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1282.228, "latencies_ms": [1282.228], "images_per_second": 0.78, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "bluebells: 100\npath: 100\ntoddler: 1\nstriped shirt: 1\nblue jeans: 1\nstuffed animal: 1\ngrass: 1\nflowers: 100", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.14, 44.14, 47.69, 47.69, 47.69, 47.69, 47.69, 43.46, 43.46, 43.46, 43.46, 43.46, 39.41], "power_watts_avg": 44.88, "power_watts_peak": 47.69, "energy_joules_est": 57.57, "sample_count": 13, "duration_seconds": 1.283}, "timestamp": "2026-01-11T13:49:39.665081"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1029.403, "latencies_ms": [1029.403], "images_per_second": 0.971, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The child is walking towards a field of blue flowers, moving from left to right. The flowers are in the foreground, creating a natural border. The child is walking on a path that extends into the background, further away from the flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [39.41, 39.41, 39.41, 39.41, 43.66, 43.66, 43.66, 43.66, 43.66, 43.87, 43.87], "power_watts_avg": 42.15, "power_watts_peak": 43.87, "energy_joules_est": 43.42, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-11T13:49:40.776586"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 840.306, "latencies_ms": [840.306], "images_per_second": 1.19, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A young boy walks along a dirt path through a field of bluebells. He carries a stuffed animal, possibly a teddy bear, while exploring the vibrant flowers.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.87, 43.87, 40.42, 40.42, 40.42, 40.42, 40.42, 42.55, 42.55], "power_watts_avg": 41.66, "power_watts_peak": 43.87, "energy_joules_est": 35.03, "sample_count": 9, "duration_seconds": 0.841}, "timestamp": "2026-01-11T13:49:41.687010"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1014.906, "latencies_ms": [1014.906], "images_per_second": 0.985, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is dominated by vibrant shades of blue and purple from the flowers, creating a striking contrast against the dirt path. The lighting suggests a sunny day, and the materials appear to be natural, organic elements like dirt and plants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.55, 42.55, 42.55, 45.34, 45.34, 45.34, 45.34, 45.34, 43.23, 43.23, 43.23], "power_watts_avg": 44.01, "power_watts_peak": 45.34, "energy_joules_est": 44.69, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-11T13:49:42.799505"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 586.336, "latencies_ms": [586.336], "images_per_second": 1.706, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A large orange rests on the edge of a parking lot, surrounded by parked cars and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [43.23, 43.23, 39.68, 39.68, 39.68, 39.68], "power_watts_avg": 40.86, "power_watts_peak": 43.23, "energy_joules_est": 23.98, "sample_count": 6, "duration_seconds": 0.587}, "timestamp": "2026-01-11T13:49:43.408407"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1032.695, "latencies_ms": [1032.695], "images_per_second": 0.968, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "orange: 1\ncar: 2\ntree: 3\nroad: 4\nparking lot: 5\norange: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [39.68, 43.78, 43.78, 43.78, 43.78, 43.78, 46.82, 46.82, 46.82, 46.82, 46.82], "power_watts_avg": 44.79, "power_watts_peak": 46.82, "energy_joules_est": 46.28, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-11T13:49:44.520678"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 775.518, "latencies_ms": [775.518], "images_per_second": 1.289, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The orange is positioned in the foreground, slightly to the left of the viewer. The parking lot with cars in the background extends into the distance, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 43.44, 43.44, 43.44, 43.12, 43.12, 43.12], "power_watts_avg": 43.32, "power_watts_peak": 43.44, "energy_joules_est": 33.62, "sample_count": 8, "duration_seconds": 0.776}, "timestamp": "2026-01-11T13:49:45.330408"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 870.739, "latencies_ms": [870.739], "images_per_second": 1.148, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A large orange rests on the asphalt of a parking lot, contrasting with the surrounding cars and trees. The scene suggests a parking lot or roadside area with parked vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.12, 43.12, 49.18, 49.18, 49.18, 49.18, 49.18, 43.83, 43.83], "power_watts_avg": 46.65, "power_watts_peak": 49.18, "energy_joules_est": 40.63, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:49:46.241564"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1168.064, "latencies_ms": [1168.064], "images_per_second": 0.856, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The orange is predominantly orange with dark brown/black patches. The lighting appears to be natural daylight, creating a contrast between the bright orange and the darker areas of the orange. The orange appears to be resting on a dark asphalt surface, which contrasts with the orange's vibrant color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.83, 43.83, 43.83, 48.17, 48.17, 48.17, 48.17, 48.17, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 45.45, "power_watts_peak": 48.17, "energy_joules_est": 53.12, "sample_count": 12, "duration_seconds": 1.169}, "timestamp": "2026-01-11T13:49:47.455161"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 715.644, "latencies_ms": [715.644], "images_per_second": 1.397, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a gray suit and tie is sitting at a wooden table, smiling at the camera while enjoying a meal and drinks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.27, 34.12, 34.12, 34.12, 34.12, 34.12, 44.73, 44.73], "power_watts_avg": 37.92, "power_watts_peak": 44.73, "energy_joules_est": 27.16, "sample_count": 8, "duration_seconds": 0.716}, "timestamp": "2026-01-11T13:49:48.266697"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1092.204, "latencies_ms": [1092.204], "images_per_second": 0.916, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "bowl: 1\nkeys: 2\nbottles: 2\nbeer bottles: 2\nman: 1\ntable: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.73, 44.73, 44.73, 53.23, 53.23, 53.23, 53.23, 53.23, 43.88, 43.88, 43.88], "power_watts_avg": 48.36, "power_watts_peak": 53.23, "energy_joules_est": 52.85, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-11T13:49:49.376036"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1011.693, "latencies_ms": [1011.693], "images_per_second": 0.988, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main object is a man sitting at a table, positioned in the foreground. The table occupies the middle ground, separating him from the background. The table also has items on it, such as a bowl, keys, and bottles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.88, 39.66, 39.66, 39.66, 39.66, 39.66, 45.33, 45.33, 45.33, 45.33, 45.33], "power_watts_avg": 42.62, "power_watts_peak": 45.33, "energy_joules_est": 43.14, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-11T13:49:50.487191"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1077.863, "latencies_ms": [1077.863], "images_per_second": 0.928, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A man is sitting at a wooden table, wearing a gray suit and tie. He is smiling and appears to be enjoying a meal or snack. Beside him on the table are two bottles of Corona beer and a bowl of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.9, 41.9, 41.9, 41.9, 41.9, 43.46, 43.46, 43.46, 43.46, 43.46, 44.9], "power_watts_avg": 42.88, "power_watts_peak": 44.9, "energy_joules_est": 46.24, "sample_count": 11, "duration_seconds": 1.078}, "timestamp": "2026-01-11T13:49:51.599637"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1234.484, "latencies_ms": [1234.484], "images_per_second": 0.81, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The man is wearing a gray suit and white shirt. His suit appears to be made of a smooth, possibly synthetic material. The lighting in the image is soft and warm, creating a pleasant atmosphere. The table is light-colored wood, and there are two bottles of Corona beer visible.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [44.9, 44.9, 44.9, 44.9, 44.62, 44.62, 44.62, 44.62, 44.62, 44.57, 44.57, 44.57, 44.57], "power_watts_avg": 44.69, "power_watts_peak": 44.9, "energy_joules_est": 55.19, "sample_count": 13, "duration_seconds": 1.235}, "timestamp": "2026-01-11T13:49:52.911546"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 752.988, "latencies_ms": [752.988], "images_per_second": 1.328, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The hotel room features a neatly made double bed with white linens, a small desk with a chair, a window, and a suitcase on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [44.57, 33.81, 33.81, 33.81, 33.81, 33.81, 42.74, 42.74], "power_watts_avg": 37.39, "power_watts_peak": 44.57, "energy_joules_est": 28.18, "sample_count": 8, "duration_seconds": 0.754}, "timestamp": "2026-01-11T13:49:53.722852"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1206.164, "latencies_ms": [1206.164], "images_per_second": 0.829, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\ntowels: 2\ndesk: 1\nchair: 1\nsuitcase: 1\nwindow: 1\nlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [42.74, 42.74, 42.74, 53.07, 53.07, 53.07, 53.07, 53.07, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 47.21, "power_watts_peak": 53.07, "energy_joules_est": 56.96, "sample_count": 12, "duration_seconds": 1.207}, "timestamp": "2026-01-11T13:49:54.936989"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 924.269, "latencies_ms": [924.269], "images_per_second": 1.082, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned between the desk and chair. The desk and chair are located in the background, near the window. The bed is situated further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.5, "ram_available_mb": 109429.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.22, 33.94, 33.94, 33.94, 33.94, 33.94, 44.08, 44.08, 44.08, 44.08], "power_watts_avg": 38.92, "power_watts_peak": 44.08, "energy_joules_est": 35.99, "sample_count": 10, "duration_seconds": 0.925}, "timestamp": "2026-01-11T13:49:55.949452"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 748.078, "latencies_ms": [748.078], "images_per_second": 1.337, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene depicts a hotel room with two twin beds, a desk, and a chair. The room is clean and appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.0, "ram_available_mb": 109433.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [44.08, 42.14, 42.14, 42.14, 42.14, 42.14, 42.28, 42.28], "power_watts_avg": 42.42, "power_watts_peak": 44.08, "energy_joules_est": 31.75, "sample_count": 8, "duration_seconds": 0.748}, "timestamp": "2026-01-11T13:49:56.756728"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1163.833, "latencies_ms": [1163.833], "images_per_second": 0.859, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The room features light beige walls and carpeting. The bed is covered with white linens and pillows. The lighting is soft and diffused, creating a calm atmosphere. A window provides natural light, contributing to the overall ambiance of the hotel room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 42.28, 52.04, 52.04, 52.04, 52.04, 52.04, 43.16, 43.16, 43.16, 43.16], "power_watts_avg": 46.64, "power_watts_peak": 52.04, "energy_joules_est": 54.31, "sample_count": 12, "duration_seconds": 1.164}, "timestamp": "2026-01-11T13:49:57.966872"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 643.527, "latencies_ms": [643.527], "images_per_second": 1.554, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Three stuffed animals, including a teddy bear, a snowman, and a polar bear, are arranged together on a blue surface against a colorful backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.16, 34.26, 34.26, 34.26, 34.26, 34.26, 37.96], "power_watts_avg": 36.06, "power_watts_peak": 43.16, "energy_joules_est": 23.23, "sample_count": 7, "duration_seconds": 0.644}, "timestamp": "2026-01-11T13:49:58.678650"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1238.871, "latencies_ms": [1238.871], "images_per_second": 0.807, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "bear: 1\npolar bear: 1\nsnowman: 1\nhat: 1\nred heart: 1\ncoca cola: 1\ntoy cane: 1\ngreen fabric: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.96, 37.96, 37.96, 42.16, 42.16, 42.16, 42.16, 42.16, 37.41, 37.41, 37.41, 37.41, 37.41], "power_watts_avg": 39.36, "power_watts_peak": 42.16, "energy_joules_est": 48.78, "sample_count": 13, "duration_seconds": 1.239}, "timestamp": "2026-01-11T13:49:59.991106"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 842.268, "latencies_ms": [842.268], "images_per_second": 1.187, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the Coca-Cola bear and snowman slightly behind and to the right of the bear. The background features an orange surface with a painted design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.18, 33.18, 33.18, 33.18, 33.18, 37.41, 37.41, 37.41, 37.41], "power_watts_avg": 35.06, "power_watts_peak": 37.41, "energy_joules_est": 29.55, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-11T13:50:00.900176"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1157.903, "latencies_ms": [1157.903], "images_per_second": 0.864, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "Three stuffed animals, including a teddy bear, a polar bear, and a snowman, are arranged on a blue blanket against a vibrant orange background. The teddy bear wears a green hat and has a Coca-Cola scarf. The snowman also has a Coca-Cola scarf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.41, 39.04, 39.04, 39.04, 39.04, 39.04, 37.9, 37.9, 37.9, 37.9, 37.9, 36.52], "power_watts_avg": 38.22, "power_watts_peak": 39.04, "energy_joules_est": 44.27, "sample_count": 12, "duration_seconds": 1.158}, "timestamp": "2026-01-11T13:50:02.112496"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 983.583, "latencies_ms": [983.583], "images_per_second": 1.017, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The teddy bears are light brown and white. The lighting is soft and warm, creating a cozy atmosphere. The teddy bears appear to be made of plush fabric. The background features a vibrant orange and red design, suggesting an artistic or festive setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.52, 36.52, 36.52, 36.52, 37.8, 37.8, 37.8, 37.8, 37.8, 37.78], "power_watts_avg": 37.29, "power_watts_peak": 37.8, "energy_joules_est": 36.68, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-11T13:50:03.122685"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 616.865, "latencies_ms": [616.865], "images_per_second": 1.621, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A clear glass bowl filled with bright, round oranges sits on a textured silver tablecloth.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.78, 37.78, 37.78, 37.78, 44.79, 44.79, 44.79], "power_watts_avg": 40.79, "power_watts_peak": 44.79, "energy_joules_est": 25.18, "sample_count": 7, "duration_seconds": 0.617}, "timestamp": "2026-01-11T13:50:03.834153"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1406.116, "latencies_ms": [1406.116], "images_per_second": 0.711, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Orange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.79, 44.79, 48.85, 48.85, 48.85, 48.85, 48.85, 43.85, 43.85, 43.85, 43.85, 43.85, 40.98, 40.98], "power_watts_avg": 45.36, "power_watts_peak": 48.85, "energy_joules_est": 63.8, "sample_count": 14, "duration_seconds": 1.406}, "timestamp": "2026-01-11T13:50:05.246638"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 827.081, "latencies_ms": [827.081], "images_per_second": 1.209, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close and centered arrangement. The bowl is placed in the foreground, while the oranges are situated in the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [40.98, 40.98, 40.98, 43.62, 43.62, 43.62, 43.62, 43.62, 45.38], "power_watts_avg": 42.94, "power_watts_peak": 45.38, "energy_joules_est": 35.54, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:50:06.157078"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.534, "latencies_ms": [828.534], "images_per_second": 1.207, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A clear glass bowl filled with bright oranges sits on a textured silver surface, possibly a tablecloth. The oranges are arranged neatly and appear to be fresh.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.38, 45.38, 45.38, 45.38, 45.38, 45.38, 45.38, 45.38, 45.38], "power_watts_avg": 45.38, "power_watts_peak": 45.38, "energy_joules_est": 37.61, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-11T13:50:07.067222"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1346.992, "latencies_ms": [1346.992], "images_per_second": 0.742, "prompt_tokens": 18, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The oranges are bright orange and appear to be ripe. The lighting is soft and diffused, creating a gentle glow on the oranges. The bowl is made of clear glass and has a dark reddish-brown rim. The surface the bowl rests on appears to be textured, possibly a tablecloth or placemat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 43.65, 43.65, 43.65, 43.27, 43.27, 43.27, 43.27, 43.27, 43.44, 43.44, 43.44, 43.44], "power_watts_avg": 43.45, "power_watts_peak": 43.65, "energy_joules_est": 58.54, "sample_count": 14, "duration_seconds": 1.347}, "timestamp": "2026-01-11T13:50:08.478119"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 552.519, "latencies_ms": [552.519], "images_per_second": 1.81, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A surfer skillfully rides a large, powerful wave in the ocean, showcasing their expertise and balance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13072.9, "ram_available_mb": 109433.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13073.3, "ram_available_mb": 109433.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.1, 33.1, 33.1, 33.1, 33.1, 37.51], "power_watts_avg": 33.83, "power_watts_peak": 37.51, "energy_joules_est": 18.71, "sample_count": 6, "duration_seconds": 0.553}, "timestamp": "2026-01-11T13:50:09.084930"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 845.732, "latencies_ms": [845.732], "images_per_second": 1.182, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "wave: 1\nsurfer: 1\nsurfboard: 1\nwater: 1\nsky: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.3, "ram_available_mb": 109433.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [37.51, 37.51, 37.51, 37.51, 42.05, 42.05, 42.05, 42.05, 42.05], "power_watts_avg": 40.03, "power_watts_peak": 42.05, "energy_joules_est": 33.87, "sample_count": 9, "duration_seconds": 0.846}, "timestamp": "2026-01-11T13:50:09.996473"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 930.578, "latencies_ms": [930.578], "images_per_second": 1.075, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main object is a large wave curling over, creating a dramatic foreground scene. The background features the ocean horizon, emphasizing the vastness of the scene. The wave is positioned close to the viewer, drawing attention to its size and power.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [37.26, 37.26, 37.26, 37.26, 37.26, 37.92, 37.92, 37.92, 37.92, 37.92], "power_watts_avg": 37.59, "power_watts_peak": 37.92, "energy_joules_est": 34.99, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-11T13:50:11.005309"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 599.371, "latencies_ms": [599.371], "images_per_second": 1.668, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A surfer is riding a large, powerful wave in the ocean. The sky is overcast, creating a dramatic backdrop for the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [37.33, 37.33, 37.33, 37.33, 37.33, 37.3], "power_watts_avg": 37.33, "power_watts_peak": 37.33, "energy_joules_est": 22.38, "sample_count": 6, "duration_seconds": 0.6}, "timestamp": "2026-01-11T13:50:11.613409"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 825.509, "latencies_ms": [825.509], "images_per_second": 1.211, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The wave is predominantly a deep blue color, contrasting with the white foam and spray from the breaking wave. The lighting suggests an overcast sky, creating a dramatic and moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.5, "ram_available_mb": 109432.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.3, 37.3, 37.3, 37.3, 42.56, 42.56, 42.56, 42.56, 42.56], "power_watts_avg": 40.22, "power_watts_peak": 42.56, "energy_joules_est": 33.22, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:50:12.520665"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 648.188, "latencies_ms": [648.188], "images_per_second": 1.543, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A tabby and white cat is sitting in front of a laptop, attentively looking at the Twitter page displayed on the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.5, "ram_available_mb": 109432.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.8, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [38.06, 38.06, 38.06, 38.06, 38.06, 42.7, 42.7], "power_watts_avg": 39.38, "power_watts_peak": 42.7, "energy_joules_est": 25.55, "sample_count": 7, "duration_seconds": 0.649}, "timestamp": "2026-01-11T13:50:13.230848"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1277.484, "latencies_ms": [1277.484], "images_per_second": 0.783, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "laptop: 1\ncat: 1\nkeyboard: 1\nlaptop screen: 1\nTwitter logo: 1\ntext: 1\ncouch: 1\npillow: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13073.8, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.8, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.7, 42.7, 42.7, 52.69, 52.69, 52.69, 52.69, 52.69, 43.26, 43.26, 43.26, 43.26, 43.26], "power_watts_avg": 46.76, "power_watts_peak": 52.69, "energy_joules_est": 59.75, "sample_count": 13, "duration_seconds": 1.278}, "timestamp": "2026-01-11T13:50:14.542630"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 633.488, "latencies_ms": [633.488], "images_per_second": 1.579, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the laptop. The laptop is situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.8, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13073.8, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 34.18, 34.18, 34.18, 44.05, 44.05], "power_watts_avg": 37.0, "power_watts_peak": 44.05, "energy_joules_est": 23.45, "sample_count": 7, "duration_seconds": 0.634}, "timestamp": "2026-01-11T13:50:15.252725"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 990.712, "latencies_ms": [990.712], "images_per_second": 1.009, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A tabby and white cat is sitting on a couch, attentively looking at a laptop screen displaying the Twitter website. The laptop is positioned on a surface, possibly a table or desk, in a casual indoor setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13073.8, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.05, 44.05, 44.05, 52.76, 52.76, 52.76, 52.76, 52.76, 43.01, 43.01], "power_watts_avg": 48.2, "power_watts_peak": 52.76, "energy_joules_est": 47.76, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-11T13:50:16.264608"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1120.057, "latencies_ms": [1120.057], "images_per_second": 0.893, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The cat is primarily white with brown and gray stripes. The lighting in the image is soft and diffused, suggesting an indoor setting with natural light. The cat appears to be comfortably perched on the laptop, seemingly focused on the Twitter page.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.91, 43.91, 43.91, 43.91, 43.91, 43.81, 43.81, 43.81, 43.81], "power_watts_avg": 43.65, "power_watts_peak": 43.91, "energy_joules_est": 48.91, "sample_count": 12, "duration_seconds": 1.12}, "timestamp": "2026-01-11T13:50:17.476031"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 541.677, "latencies_ms": [541.677], "images_per_second": 1.846, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of six horses, including two brown ones and three black ones, are gathered around a hay feeder in a field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.34, 32.34, 32.34, 32.34, 32.34, 36.98], "power_watts_avg": 33.11, "power_watts_peak": 36.98, "energy_joules_est": 17.95, "sample_count": 6, "duration_seconds": 0.542}, "timestamp": "2026-01-11T13:50:18.085554"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 778.148, "latencies_ms": [778.148], "images_per_second": 1.285, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "horse: 5\nhay: 2\nfence: 1\nground: 2\ntrees: 2\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.98, 36.98, 36.98, 36.98, 42.67, 42.67, 42.67, 42.67], "power_watts_avg": 39.82, "power_watts_peak": 42.67, "energy_joules_est": 31.0, "sample_count": 8, "duration_seconds": 0.778}, "timestamp": "2026-01-11T13:50:18.895068"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 826.335, "latencies_ms": [826.335], "images_per_second": 1.21, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a young horse on the left and a group of horses in the background. The horses are grouped together near the hay pile, suggesting they are in a feeding area or stable.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [42.67, 41.27, 41.27, 41.27, 41.27, 41.27, 38.49, 38.49, 38.49], "power_watts_avg": 40.5, "power_watts_peak": 42.67, "energy_joules_est": 33.49, "sample_count": 9, "duration_seconds": 0.827}, "timestamp": "2026-01-11T13:50:19.805492"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 681.354, "latencies_ms": [681.354], "images_per_second": 1.468, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of horses, including adults and a young one, are gathered in a field near a hay feeder. The scene suggests a rural or farm setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [38.49, 38.49, 38.12, 38.12, 38.12, 38.12, 38.12], "power_watts_avg": 38.22, "power_watts_peak": 38.49, "energy_joules_est": 26.06, "sample_count": 7, "duration_seconds": 0.682}, "timestamp": "2026-01-11T13:50:20.513891"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 871.815, "latencies_ms": [871.815], "images_per_second": 1.147, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The horses are primarily dark brown or black. The lighting appears to be natural, possibly overcast, creating a somewhat muted atmosphere. The scene suggests a rural setting with a mix of natural and artificial light sources.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [36.86, 36.86, 36.86, 36.86, 36.86, 38.23, 38.23, 38.23, 38.23], "power_watts_avg": 37.47, "power_watts_peak": 38.23, "energy_joules_est": 32.68, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-11T13:50:21.420522"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 785.102, "latencies_ms": [785.102], "images_per_second": 1.274, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man wearing a black wetsuit skillfully maneuvers a yellow surfboard, crouching low and carving through the waves in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.23, 39.78, 39.78, 39.78, 39.78, 39.78, 43.76, 43.76], "power_watts_avg": 40.58, "power_watts_peak": 43.76, "energy_joules_est": 31.88, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-11T13:50:22.231837"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1047.699, "latencies_ms": [1047.699], "images_per_second": 0.954, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "surfboard: 1\nperson: 1\nwater: 1\nwaves: 2\ncliff: 1\nsky: 1\nshore: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.7, "ram_available_mb": 109432.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.76, 43.76, 43.76, 52.43, 52.43, 52.43, 52.43, 52.43, 43.84, 43.84, 43.84], "power_watts_avg": 47.72, "power_watts_peak": 52.43, "energy_joules_est": 50.02, "sample_count": 11, "duration_seconds": 1.048}, "timestamp": "2026-01-11T13:50:23.339931"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 855.484, "latencies_ms": [855.484], "images_per_second": 1.169, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave near the shore. The background features the ocean and a distant shoreline, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.84, 43.84, 39.57, 39.57, 39.57, 39.57, 39.57, 43.38, 43.38], "power_watts_avg": 41.37, "power_watts_peak": 43.84, "energy_joules_est": 35.41, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-11T13:50:24.248874"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1145.658, "latencies_ms": [1145.658], "images_per_second": 0.873, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "A man is surfing on a wave in the ocean, wearing a black wetsuit. He is riding a yellow surfboard through the water, creating a splash as it cuts through the waves. The background features a sandy beach and a cliff, contributing to the coastal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.6, "ram_available_mb": 109432.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 43.38, 47.51, 47.51, 47.51, 47.51, 47.51, 43.18, 43.18, 43.18, 43.18], "power_watts_avg": 45.03, "power_watts_peak": 47.51, "energy_joules_est": 51.6, "sample_count": 12, "duration_seconds": 1.146}, "timestamp": "2026-01-11T13:50:25.460148"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 751.702, "latencies_ms": [751.702], "images_per_second": 1.33, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The surfer is wearing a dark-colored wetsuit. The water appears a greenish-blue, and the sky is partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13073.9, "ram_available_mb": 109432.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13074.5, "ram_available_mb": 109431.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.18, 32.95, 32.95, 32.95, 32.95, 32.95, 43.15, 43.15], "power_watts_avg": 36.78, "power_watts_peak": 43.18, "energy_joules_est": 27.66, "sample_count": 8, "duration_seconds": 0.752}, "timestamp": "2026-01-11T13:50:26.269484"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 727.138, "latencies_ms": [727.138], "images_per_second": 1.375, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Three uniquely carved pumpkins are displayed in a hallway, accompanied by a vase of pink flowers and a small figurine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.5, "ram_available_mb": 109431.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.15, 43.15, 43.15, 51.45, 51.45, 51.45, 51.45, 51.45], "power_watts_avg": 48.34, "power_watts_peak": 51.45, "energy_joules_est": 35.18, "sample_count": 8, "duration_seconds": 0.728}, "timestamp": "2026-01-11T13:50:27.080853"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1315.546, "latencies_ms": [1315.546], "images_per_second": 0.76, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "pumpkin: 3\nrose: 2\nglass: 1\nperson: 1\ncarved pumpkin: 2\npumpkin: 1\nflower: 1\npumpkin: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.62, 42.62, 42.62, 42.62, 43.61, 43.61, 43.61, 43.61, 43.61, 41.97, 41.97, 41.97, 41.97, 41.97], "power_watts_avg": 42.74, "power_watts_peak": 43.61, "energy_joules_est": 56.24, "sample_count": 14, "duration_seconds": 1.316}, "timestamp": "2026-01-11T13:50:28.491013"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 883.211, "latencies_ms": [883.211], "images_per_second": 1.132, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The pumpkins are positioned in the foreground, with the flowers and decorations placed behind them.  The background features bookshelves, suggesting the scene is in a library or study area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [32.3, 32.3, 32.3, 32.3, 32.3, 42.6, 42.6, 42.6, 42.6], "power_watts_avg": 36.88, "power_watts_peak": 42.6, "energy_joules_est": 32.59, "sample_count": 9, "duration_seconds": 0.884}, "timestamp": "2026-01-11T13:50:29.402039"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1169.013, "latencies_ms": [1169.013], "images_per_second": 0.855, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a Halloween-themed display featuring three carved pumpkins and a vase of pink flowers. A small figurine of a man is perched on one of the pumpkins. The pumpkins are displayed on a table or shelf alongside other Halloween decorations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.6, 47.32, 47.32, 47.32, 47.32, 47.32, 44.16, 44.16, 44.16, 44.16, 44.16, 42.1], "power_watts_avg": 45.18, "power_watts_peak": 47.32, "energy_joules_est": 52.83, "sample_count": 12, "duration_seconds": 1.169}, "timestamp": "2026-01-11T13:50:30.611210"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 895.981, "latencies_ms": [895.981], "images_per_second": 1.116, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The pumpkins are orange and feature painted faces. The lighting appears to be artificial, creating a warm glow. The materials appear to be carved pumpkins and glass, typical for Halloween decorations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13074.8, "ram_available_mb": 109431.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.1, 42.1, 42.1, 42.1, 43.73, 43.73, 43.73, 43.73, 43.73], "power_watts_avg": 43.01, "power_watts_peak": 43.73, "energy_joules_est": 38.56, "sample_count": 9, "duration_seconds": 0.897}, "timestamp": "2026-01-11T13:50:31.518274"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 575.834, "latencies_ms": [575.834], "images_per_second": 1.737, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A white sink with a faucet is situated in a bathroom, accompanied by a black trash bag on the floor and a mirror on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.48, 43.48, 43.48, 38.44], "power_watts_avg": 42.64, "power_watts_peak": 43.48, "energy_joules_est": 24.57, "sample_count": 6, "duration_seconds": 0.576}, "timestamp": "2026-01-11T13:50:32.126900"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1160.642, "latencies_ms": [1160.642], "images_per_second": 0.862, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "sink: 1\nmirror: 1\ntoiletries: 2\nshelf: 1\ndoor: 1\ntrash bag: 1\npipes: 1\nfloor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.1, "ram_available_mb": 109431.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.44, 38.44, 38.44, 38.44, 43.24, 43.24, 43.24, 43.24, 43.24, 38.65, 38.65, 38.65], "power_watts_avg": 40.49, "power_watts_peak": 43.24, "energy_joules_est": 47.01, "sample_count": 12, "duration_seconds": 1.161}, "timestamp": "2026-01-11T13:50:33.338275"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 598.465, "latencies_ms": [598.465], "images_per_second": 1.671, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The sink is positioned to the left of the mirror and slightly in front of the door. The trash bag is located in the foreground, near the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.0, "ram_available_mb": 109431.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.65, 38.65, 37.83, 37.83, 37.83, 37.83], "power_watts_avg": 38.1, "power_watts_peak": 38.65, "energy_joules_est": 22.82, "sample_count": 6, "duration_seconds": 0.599}, "timestamp": "2026-01-11T13:50:33.946050"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 787.923, "latencies_ms": [787.923], "images_per_second": 1.269, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bathroom appears to be in a state of disrepair or abandonment.  A sink, mirror, and door are present, along with a trash bag on the floor. The walls show signs of wear and tear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.3, "ram_available_mb": 109431.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [37.83, 38.73, 38.73, 38.73, 38.73, 38.73, 38.64, 38.64], "power_watts_avg": 38.59, "power_watts_peak": 38.73, "energy_joules_est": 30.45, "sample_count": 8, "duration_seconds": 0.789}, "timestamp": "2026-01-11T13:50:34.754475"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 805.896, "latencies_ms": [805.896], "images_per_second": 1.241, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bathroom walls are painted a pale yellow. The lighting is dim, creating a somewhat subdued atmosphere. The walls show signs of wear and tear, with visible stains and imperfections.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [38.64, 38.64, 38.64, 43.26, 43.26, 43.26, 43.26, 43.26, 38.15], "power_watts_avg": 41.15, "power_watts_peak": 43.26, "energy_joules_est": 33.18, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-11T13:50:35.662730"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 553.872, "latencies_ms": [553.872], "images_per_second": 1.805, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A young child sits on a bed, focused intently on a laptop screen in front of them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [38.15, 38.15, 38.15, 38.15, 42.29, 42.29], "power_watts_avg": 39.53, "power_watts_peak": 42.29, "energy_joules_est": 21.92, "sample_count": 6, "duration_seconds": 0.555}, "timestamp": "2026-01-11T13:50:36.273065"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1111.433, "latencies_ms": [1111.433], "images_per_second": 0.9, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "laptop: 1\nbed: 1\ntoddler: 1\nchild: 1\nhair clip: 1\nshirt: 1\nshorts: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.29, 42.29, 42.29, 50.35, 50.35, 50.35, 50.35, 50.35, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 45.96, "power_watts_peak": 50.35, "energy_joules_est": 51.11, "sample_count": 12, "duration_seconds": 1.112}, "timestamp": "2026-01-11T13:50:37.484830"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 900.161, "latencies_ms": [900.161], "images_per_second": 1.111, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The baby is positioned near the laptop, seemingly observing its screen. The laptop is placed on a surface, which appears to be a bed, providing a clear view of the baby's face and the laptop screen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.49, 34.49, 34.49, 34.49, 34.49, 42.54, 42.54, 42.54, 42.54], "power_watts_avg": 38.07, "power_watts_peak": 42.54, "energy_joules_est": 34.28, "sample_count": 9, "duration_seconds": 0.9}, "timestamp": "2026-01-11T13:50:38.394582"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 632.124, "latencies_ms": [632.124], "images_per_second": 1.582, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young child is sitting on a bed, focused on a laptop screen. The setting appears to be a bedroom or home environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.54, 47.68, 47.68, 47.68, 47.68, 47.68, 43.96], "power_watts_avg": 46.42, "power_watts_peak": 47.68, "energy_joules_est": 29.35, "sample_count": 7, "duration_seconds": 0.632}, "timestamp": "2026-01-11T13:50:39.103877"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 744.029, "latencies_ms": [744.029], "images_per_second": 1.344, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The baby is wearing a white shirt. The laptop is silver. The background is plain white. The lighting is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.96, 43.96, 43.96, 43.96, 50.47, 50.47, 50.47, 50.47], "power_watts_avg": 47.21, "power_watts_peak": 50.47, "energy_joules_est": 35.14, "sample_count": 8, "duration_seconds": 0.744}, "timestamp": "2026-01-11T13:50:39.912201"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 627.547, "latencies_ms": [627.547], "images_per_second": 1.594, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A skier dressed in winter gear skillfully navigates a snowy slope, leaving a trail of powdery snow behind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [50.47, 44.69, 44.69, 44.69, 44.69, 44.69, 37.91], "power_watts_avg": 44.54, "power_watts_peak": 50.47, "energy_joules_est": 27.98, "sample_count": 7, "duration_seconds": 0.628}, "timestamp": "2026-01-11T13:50:40.623232"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1115.777, "latencies_ms": [1115.777], "images_per_second": 0.896, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "person: 1\nski: 2\npole: 1\ngloves: 2\nskis: 2\nsnow: 2\ntrees: 2\ngoggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.91, 37.91, 37.91, 37.91, 39.95, 39.95, 39.95, 39.95, 39.95, 36.99, 36.99, 36.99], "power_watts_avg": 38.53, "power_watts_peak": 39.95, "energy_joules_est": 43.0, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-11T13:50:41.831988"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 657.967, "latencies_ms": [657.967], "images_per_second": 1.52, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, moving towards the left side of the image. The snowy slope and trees in the background create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.7, "ram_available_mb": 109430.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [36.99, 36.99, 37.32, 37.32, 37.32, 37.32, 37.32], "power_watts_avg": 37.23, "power_watts_peak": 37.32, "energy_joules_est": 24.51, "sample_count": 7, "duration_seconds": 0.658}, "timestamp": "2026-01-11T13:50:42.539728"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 649.864, "latencies_ms": [649.864], "images_per_second": 1.539, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A skier is carving down a snowy slope, leaning forward with poles in hand, amidst a backdrop of snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.22, 37.22, 37.22, 37.22, 37.22, 37.81, 37.81], "power_watts_avg": 37.39, "power_watts_peak": 37.81, "energy_joules_est": 24.31, "sample_count": 7, "duration_seconds": 0.65}, "timestamp": "2026-01-11T13:50:43.249444"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 906.489, "latencies_ms": [906.489], "images_per_second": 1.103, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The skier is wearing a brown jacket and dark pants. The lighting is bright and sunny, creating a contrast against the white snow. The skier is skiing down a snow-covered slope with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.81, 37.81, 37.81, 41.6, 41.6, 41.6, 41.6, 41.6, 37.63, 37.63], "power_watts_avg": 39.67, "power_watts_peak": 41.6, "energy_joules_est": 35.98, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-11T13:50:44.259544"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 791.226, "latencies_ms": [791.226], "images_per_second": 1.264, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The hotel room features a king-sized bed with white linens, a wooden headboard, and blue and gray pillows, accompanied by a blue armchair and a nightstand with a lamp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.63, 37.63, 37.63, 36.65, 36.65, 36.65, 36.65, 36.65], "power_watts_avg": 37.02, "power_watts_peak": 37.63, "energy_joules_est": 29.31, "sample_count": 8, "duration_seconds": 0.792}, "timestamp": "2026-01-11T13:50:45.071107"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1134.26, "latencies_ms": [1134.26], "images_per_second": 0.882, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "bed: 1\npillows: 4\nlamp: 2\narmchair: 1\nwindow: 1\nsuitcase: 1\ncarpet: 1\nside table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.7, 36.7, 36.7, 36.7, 36.7, 38.34, 38.34, 38.34, 38.34, 38.34, 38.23, 38.23], "power_watts_avg": 37.64, "power_watts_peak": 38.34, "energy_joules_est": 42.7, "sample_count": 12, "duration_seconds": 1.135}, "timestamp": "2026-01-11T13:50:46.285092"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 938.067, "latencies_ms": [938.067], "images_per_second": 1.066, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and harmonious manner, with the bed occupying the foreground and the chair and suitcase placed near the left side of the image. The window and lamp are situated in the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.23, 38.23, 37.3, 37.3, 37.3, 37.3, 37.3, 37.27, 37.27, 37.27], "power_watts_avg": 37.48, "power_watts_peak": 38.23, "energy_joules_est": 35.18, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-11T13:50:47.295351"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 762.684, "latencies_ms": [762.684], "images_per_second": 1.311, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a hotel room with a large bed, a blue armchair, and a window providing natural light. The room is clean and organized, with a lamp providing soft lighting.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.27, 37.27, 37.15, 37.15, 37.15, 37.15, 37.15, 37.22], "power_watts_avg": 37.19, "power_watts_peak": 37.27, "energy_joules_est": 28.38, "sample_count": 8, "duration_seconds": 0.763}, "timestamp": "2026-01-11T13:50:48.104030"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 929.025, "latencies_ms": [929.025], "images_per_second": 1.076, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The room features a light-colored bed with white bedding and pillows. The walls are painted in a light beige color, and the carpet is a neutral tone. A window with sheer curtains allows natural light to enter the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.6, "ram_available_mb": 109430.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.22, 37.22, 37.22, 37.22, 37.42, 37.42, 37.42, 37.42, 37.42, 37.38], "power_watts_avg": 37.33, "power_watts_peak": 37.42, "energy_joules_est": 34.71, "sample_count": 10, "duration_seconds": 0.93}, "timestamp": "2026-01-11T13:50:49.116895"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 841.927, "latencies_ms": [841.927], "images_per_second": 1.188, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A skier in vibrant orange pants and a white jacket skillfully maneuvers a red rail on a snowy slope, surrounded by other winter sports enthusiasts.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [37.38, 37.38, 37.38, 37.38, 42.51, 42.51, 42.51, 42.51, 42.51], "power_watts_avg": 40.23, "power_watts_peak": 42.51, "energy_joules_est": 33.89, "sample_count": 9, "duration_seconds": 0.842}, "timestamp": "2026-01-11T13:50:50.029463"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1340.376, "latencies_ms": [1340.376], "images_per_second": 0.746, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "red pipe: 1\nskier: 1\nsnowboarder: 1\nfence: 1\nski lift: 1\nsnow: 1\nskiers: 2\nclear sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.09, 42.09, 42.09, 42.09, 42.09, 42.79, 42.79, 42.79, 42.79, 42.79, 43.31, 43.31, 43.31, 43.31], "power_watts_avg": 42.69, "power_watts_peak": 43.31, "energy_joules_est": 57.24, "sample_count": 14, "duration_seconds": 1.341}, "timestamp": "2026-01-11T13:50:51.443251"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 873.036, "latencies_ms": [873.036], "images_per_second": 1.145, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The red object dominates the foreground, positioned to the left of the main subject. The background features more snow skiers and ski lifts, indicating a ski resort environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.31, 33.32, 33.32, 33.32, 33.32, 33.32, 42.99, 42.99, 42.99], "power_watts_avg": 37.65, "power_watts_peak": 43.31, "energy_joules_est": 32.89, "sample_count": 9, "duration_seconds": 0.874}, "timestamp": "2026-01-11T13:50:52.355540"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1109.916, "latencies_ms": [1109.916], "images_per_second": 0.901, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a snowy slope with several skiers and snowboarders enjoying winter sports. A prominent feature is a red, curved rail or ramp that serves as a challenging obstacle for participants to navigate and perform tricks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.99, 42.99, 48.77, 48.77, 48.77, 48.77, 48.77, 43.59, 43.59, 43.59, 43.59, 43.59], "power_watts_avg": 45.65, "power_watts_peak": 48.77, "energy_joules_est": 50.69, "sample_count": 12, "duration_seconds": 1.11}, "timestamp": "2026-01-11T13:50:53.567869"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1222.872, "latencies_ms": [1222.872], "images_per_second": 0.818, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The snow is bright white, indicative of clear, sunny weather. The red metal feature stands out against the snowy landscape, adding a pop of color to the scene. The overall lighting is bright and clear, enhancing the visibility of the snow and the skiers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.31, 39.31, 39.31, 39.31, 39.31, 42.19, 42.19, 42.19, 42.19, 42.19, 42.57, 42.57, 42.57], "power_watts_avg": 41.17, "power_watts_peak": 42.57, "energy_joules_est": 50.36, "sample_count": 13, "duration_seconds": 1.223}, "timestamp": "2026-01-11T13:50:54.882426"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 654.451, "latencies_ms": [654.451], "images_per_second": 1.528, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A parking meter with graffiti on its side is mounted on a metal pole against a graffiti-covered wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [42.57, 36.41, 36.41, 36.41, 36.41, 36.41, 42.11], "power_watts_avg": 38.1, "power_watts_peak": 42.57, "energy_joules_est": 24.96, "sample_count": 7, "duration_seconds": 0.655}, "timestamp": "2026-01-11T13:50:55.591718"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1184.367, "latencies_ms": [1184.367], "images_per_second": 0.844, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Parking meter: 2\nGraffiti: 5\nMetal fence: 1\nStreet sign: 1\nPole: 1\nBuilding: 1\nGround: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.11, 42.11, 42.11, 42.11, 50.06, 50.06, 50.06, 50.06, 50.06, 43.34, 43.34, 43.34], "power_watts_avg": 45.73, "power_watts_peak": 50.06, "energy_joules_est": 54.18, "sample_count": 12, "duration_seconds": 1.185}, "timestamp": "2026-01-11T13:50:56.804310"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 732.645, "latencies_ms": [732.645], "images_per_second": 1.365, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The parking meter is positioned in the foreground, slightly to the right of the graffiti wall. The graffiti wall extends into the background, creating a layered effect.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 41.13, 41.13, 41.13, 41.13, 41.13, 43.79], "power_watts_avg": 42.01, "power_watts_peak": 43.79, "energy_joules_est": 30.8, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:50:57.615592"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1146.605, "latencies_ms": [1146.605], "images_per_second": 0.872, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene is set in a graffitied urban area, likely near a building entrance. The walls are covered in vibrant graffiti art, showcasing various styles and colors. A parking meter is visible in the foreground, partially obscured by the graffiti.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.79, 43.79, 43.79, 43.79, 45.73, 45.73, 45.73, 45.73, 45.73, 42.62, 42.62, 42.62], "power_watts_avg": 44.3, "power_watts_peak": 45.73, "energy_joules_est": 50.82, "sample_count": 12, "duration_seconds": 1.147}, "timestamp": "2026-01-11T13:50:58.828159"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1140.43, "latencies_ms": [1140.43], "images_per_second": 0.877, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The building's exterior is covered in vibrant graffiti in shades of black, blue, yellow, and red. The lighting appears to be natural daylight, creating a contrast against the dark wall. The materials used are likely metal and paint, giving the structure an industrial look.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [42.62, 42.62, 39.79, 39.79, 39.79, 39.79, 39.79, 42.79, 42.79, 42.79, 42.79, 42.79], "power_watts_avg": 41.51, "power_watts_peak": 42.79, "energy_joules_est": 47.36, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-11T13:51:00.042035"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 752.71, "latencies_ms": [752.71], "images_per_second": 1.329, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A surfer in a black wetsuit rides a wave on a white surfboard, skillfully carving through the deep blue ocean.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [37.53, 37.53, 37.53, 37.53, 37.53, 42.56, 42.56, 42.56], "power_watts_avg": 39.41, "power_watts_peak": 42.56, "energy_joules_est": 29.69, "sample_count": 8, "duration_seconds": 0.753}, "timestamp": "2026-01-11T13:51:00.854899"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 910.265, "latencies_ms": [910.265], "images_per_second": 1.099, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "person: 1\nsurfboard: 1\nwave: 1\nwater: 1\nsky: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.56, 42.56, 47.85, 47.85, 47.85, 47.85, 47.85, 43.42, 43.42, 43.42], "power_watts_avg": 45.46, "power_watts_peak": 47.85, "energy_joules_est": 41.41, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:51:01.866957"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 907.253, "latencies_ms": [907.253], "images_per_second": 1.102, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The surfer is positioned near the center of the image, riding a wave that extends towards the right side of the frame. The ocean occupies the majority of the background, creating a sense of depth and vastness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [43.42, 43.42, 42.03, 42.03, 42.03, 42.03, 42.03, 42.6, 42.6, 42.6], "power_watts_avg": 42.48, "power_watts_peak": 43.42, "energy_joules_est": 38.57, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-11T13:51:02.879664"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 928.33, "latencies_ms": [928.33], "images_per_second": 1.077, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A surfer is riding a wave in the deep blue ocean. The scene is captured from a distance, emphasizing the vastness of the ocean and the surfer's skillful maneuver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.6, 42.6, 43.02, 43.02, 43.02, 43.02, 42.33, 42.33, 42.33, 42.33], "power_watts_avg": 42.66, "power_watts_peak": 43.02, "energy_joules_est": 39.63, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-11T13:51:03.891314"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 933.691, "latencies_ms": [933.691], "images_per_second": 1.071, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The ocean is a deep blue color, creating a striking contrast with the white foam of the waves. The lighting appears to be soft and diffused, possibly suggesting an overcast sky or twilight conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [42.33, 42.99, 42.99, 42.99, 42.99, 42.99, 42.75, 42.75, 42.75, 42.75], "power_watts_avg": 42.83, "power_watts_peak": 42.99, "energy_joules_est": 40.0, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:51:04.901454"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 597.015, "latencies_ms": [597.015], "images_per_second": 1.675, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A yellow double-decker bus is stopped at a bus stop, picking up passengers.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [42.75, 42.33, 42.33, 42.33, 42.33, 42.33], "power_watts_avg": 42.4, "power_watts_peak": 42.75, "energy_joules_est": 25.33, "sample_count": 6, "duration_seconds": 0.598}, "timestamp": "2026-01-11T13:51:05.512571"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1022.642, "latencies_ms": [1022.642], "images_per_second": 0.978, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bus: 2\nstreet: 2\nbuildings: 2\nbus stop: 1\nman: 2\nwoman: 1\nflowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.93, 42.93, 42.93, 42.93, 42.93, 51.61, 51.61, 51.61, 51.61, 51.61, 44.21], "power_watts_avg": 46.99, "power_watts_peak": 51.61, "energy_joules_est": 48.07, "sample_count": 11, "duration_seconds": 1.023}, "timestamp": "2026-01-11T13:51:06.625769"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1105.016, "latencies_ms": [1105.016], "images_per_second": 0.905, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The double-decker bus is positioned in the foreground, moving towards the viewer. The bus is situated near a bus stop, offering a clear view of the street and surrounding environment. The bus is relatively close to the viewer, emphasizing its proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.21, 44.21, 44.21, 44.21, 42.79, 42.79, 42.79, 42.79, 42.79, 42.67, 42.67], "power_watts_avg": 43.28, "power_watts_peak": 44.21, "energy_joules_est": 47.85, "sample_count": 11, "duration_seconds": 1.106}, "timestamp": "2026-01-11T13:51:07.738259"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1203.352, "latencies_ms": [1203.352], "images_per_second": 0.831, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "A yellow double-decker bus is stopped at a bus stop, picking up passengers. The bus is labeled \"Lytham\" and \"St Annes,\" indicating its route.  Two men are waiting at the bus stop, one near the front and the other near the back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [42.67, 42.67, 42.67, 44.47, 44.47, 44.47, 44.47, 44.47, 44.74, 44.74, 44.74, 44.74], "power_watts_avg": 44.11, "power_watts_peak": 44.74, "energy_joules_est": 53.1, "sample_count": 12, "duration_seconds": 1.204}, "timestamp": "2026-01-11T13:51:08.951838"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1062.164, "latencies_ms": [1062.164], "images_per_second": 0.941, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The bus is primarily yellow and black. The lighting appears to be overcast, creating a somewhat muted atmosphere. The bus is made of metal and glass, typical of modern public transportation. The overall scene suggests a typical urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.74, 34.55, 34.55, 34.55, 34.55, 34.55, 44.46, 44.46, 44.46, 44.46, 44.46], "power_watts_avg": 39.98, "power_watts_peak": 44.74, "energy_joules_est": 42.49, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:51:10.065347"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 840.643, "latencies_ms": [840.643], "images_per_second": 1.19, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A yellow and red single-engine propeller airplane with the registration SP-AWF is captured in mid-flight, moving from left to right with a slight downward tilt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.43, 44.43, 44.43, 44.43, 44.43, 43.43, 43.43, 43.43, 43.43], "power_watts_avg": 43.99, "power_watts_peak": 44.43, "energy_joules_est": 36.99, "sample_count": 9, "duration_seconds": 0.841}, "timestamp": "2026-01-11T13:51:10.974089"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1077.798, "latencies_ms": [1077.798], "images_per_second": 0.928, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "airplane: 1\npropeller: 1\nwings: 2\ntail: 1\nbody: 1\nwheel: 2\ntext: SP-AWF", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.43, 42.19, 42.19, 42.19, 42.19, 42.19, 43.36, 43.36, 43.36, 43.36, 43.36], "power_watts_avg": 42.83, "power_watts_peak": 43.43, "energy_joules_est": 46.19, "sample_count": 11, "duration_seconds": 1.078}, "timestamp": "2026-01-11T13:51:12.087041"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 865.024, "latencies_ms": [865.024], "images_per_second": 1.156, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main object is a yellow and red propeller plane flying in the sky. The plane is positioned in the foreground, slightly to the right of the viewer. The background is primarily a light gray sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [44.76, 44.76, 44.76, 44.76, 44.76, 44.14, 44.14, 44.14, 44.14], "power_watts_avg": 44.49, "power_watts_peak": 44.76, "energy_joules_est": 38.49, "sample_count": 9, "duration_seconds": 0.865}, "timestamp": "2026-01-11T13:51:12.998783"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 865.967, "latencies_ms": [865.967], "images_per_second": 1.155, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A yellow and blue propeller plane with the registration SP-AWF is flying through a cloudy sky. The plane appears to be in motion, moving from left to right across the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.9, "ram_available_mb": 109430.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [43.42, 43.42, 43.42, 43.42, 43.42, 43.83, 43.83, 43.83, 43.83], "power_watts_avg": 43.6, "power_watts_peak": 43.83, "energy_joules_est": 37.77, "sample_count": 9, "duration_seconds": 0.866}, "timestamp": "2026-01-11T13:51:13.908447"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 702.755, "latencies_ms": [702.755], "images_per_second": 1.423, "prompt_tokens": 18, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The plane is predominantly yellow with red and blue accents. The lighting conditions appear to be overcast, creating a muted atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [43.83, 46.25, 46.25, 46.25, 46.25, 46.25, 43.25], "power_watts_avg": 45.47, "power_watts_peak": 46.25, "energy_joules_est": 31.98, "sample_count": 7, "duration_seconds": 0.703}, "timestamp": "2026-01-11T13:51:14.618803"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 746.098, "latencies_ms": [746.098], "images_per_second": 1.34, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "An aerial view from an airplane window showcases a vast parking lot filled with numerous cars, with residential and commercial buildings scattered throughout the landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.25, 43.25, 43.25, 43.25, 51.46, 51.46, 51.46, 51.46], "power_watts_avg": 47.35, "power_watts_peak": 51.46, "energy_joules_est": 35.36, "sample_count": 8, "duration_seconds": 0.747}, "timestamp": "2026-01-11T13:51:15.431036"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1141.876, "latencies_ms": [1141.876], "images_per_second": 0.876, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "airplane wing: 1\nbuildings: 2\nparking lot: 10\ncars: 20\ntrees: 5\nfields: 2\nsky: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [51.46, 44.52, 44.52, 44.52, 44.52, 44.52, 42.32, 42.32, 42.32, 42.32, 42.32, 42.01], "power_watts_avg": 43.97, "power_watts_peak": 51.46, "energy_joules_est": 50.23, "sample_count": 12, "duration_seconds": 1.142}, "timestamp": "2026-01-11T13:51:16.645290"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1256.712, "latencies_ms": [1256.712], "images_per_second": 0.796, "prompt_tokens": 25, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The airplane wing is positioned to the left of the image, occupying a significant portion of the foreground. The parking lot and residential area are situated in the background, extending across the image's width. The vast expanse of the parking lot and the residential area suggest a considerable distance between the viewer and the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13075.8, "ram_available_mb": 109430.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [42.01, 42.01, 42.01, 42.01, 42.59, 42.59, 42.59, 42.59, 42.59, 42.57, 42.57, 42.57, 42.57], "power_watts_avg": 42.4, "power_watts_peak": 42.59, "energy_joules_est": 53.31, "sample_count": 13, "duration_seconds": 1.257}, "timestamp": "2026-01-11T13:51:17.960188"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1009.65, "latencies_ms": [1009.65], "images_per_second": 0.99, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts an aerial view of an airport runway with a large parking lot filled with cars. A portion of an airplane wing is visible in the top left corner. The parking lot is surrounded by residential areas and farmland.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.57, 33.23, 33.23, 33.23, 33.23, 33.23, 43.56, 43.56, 43.56, 43.56, 43.56], "power_watts_avg": 38.78, "power_watts_peak": 43.56, "energy_joules_est": 39.17, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-11T13:51:19.072861"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 990.077, "latencies_ms": [990.077], "images_per_second": 1.01, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The sky is blue with a few scattered clouds. The car parking lot is filled with various colored vehicles. The airplane wing is white with a blue tip. The overall scene suggests a bright, sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [44.31, 44.31, 44.31, 44.31, 44.31, 42.72, 42.72, 42.72, 42.72, 42.72], "power_watts_avg": 43.51, "power_watts_peak": 44.31, "energy_joules_est": 43.1, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-11T13:51:20.084828"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 481.464, "latencies_ms": [481.464], "images_per_second": 2.077, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A person is holding a pink flip phone with a picture of Disney Princess Aurora on the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [42.86, 42.86, 42.86, 42.86, 42.86], "power_watts_avg": 42.86, "power_watts_peak": 42.86, "energy_joules_est": 20.65, "sample_count": 5, "duration_seconds": 0.482}, "timestamp": "2026-01-11T13:51:20.593768"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1076.364, "latencies_ms": [1076.364], "images_per_second": 0.929, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Cell phone: 1\nGift bag: 1\nCup: 1\nChair: 1\nJeans: 2\nSweater: 1\nGift tag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.6, "ram_available_mb": 109429.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.68, 38.68, 38.68, 38.68, 43.28, 43.28, 43.28, 43.28, 43.28, 38.67, 38.67], "power_watts_avg": 40.77, "power_watts_peak": 43.28, "energy_joules_est": 43.9, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-11T13:51:21.705279"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 730.659, "latencies_ms": [730.659], "images_per_second": 1.369, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The pink flip phone is held in the foreground, positioned between the person's hands. The background includes a person's legs and a table with a cup and possibly a wrapped gift.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.67, 38.67, 38.67, 38.51, 38.51, 38.51, 38.51, 38.51], "power_watts_avg": 38.57, "power_watts_peak": 38.67, "energy_joules_est": 28.19, "sample_count": 8, "duration_seconds": 0.731}, "timestamp": "2026-01-11T13:51:22.516030"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 796.499, "latencies_ms": [796.499], "images_per_second": 1.255, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Two people are sitting on the floor, one holding a pink flip phone displaying a picture of Disney Princess Aurora. The scene appears to be casual and relaxed, with various items scattered around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.79, 37.79, 37.79, 37.79, 37.79, 36.94, 36.94, 36.94], "power_watts_avg": 37.47, "power_watts_peak": 37.79, "energy_joules_est": 29.87, "sample_count": 8, "duration_seconds": 0.797}, "timestamp": "2026-01-11T13:51:23.324591"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1171.893, "latencies_ms": [1171.893], "images_per_second": 0.853, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The pink flip phone is open, displaying a picture of Disney Princess Aurora. The phone appears to be made of plastic and has a small screen. The lighting in the image is dim, suggesting an indoor setting. The phone is held in a person's hand, indicating a casual, relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [36.94, 36.94, 41.78, 41.78, 41.78, 41.78, 41.78, 38.69, 38.69, 38.69, 38.69, 38.69], "power_watts_avg": 39.68, "power_watts_peak": 41.78, "energy_joules_est": 46.52, "sample_count": 12, "duration_seconds": 1.172}, "timestamp": "2026-01-11T13:51:24.533656"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 671.033, "latencies_ms": [671.033], "images_per_second": 1.49, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two zebras stand in a field of tall, dry grass, their black and white stripes contrasting with the golden hues.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.99, 33.99, 33.99, 33.99, 33.99, 43.27, 43.27], "power_watts_avg": 36.64, "power_watts_peak": 43.27, "energy_joules_est": 24.61, "sample_count": 7, "duration_seconds": 0.672}, "timestamp": "2026-01-11T13:51:25.243767"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 915.699, "latencies_ms": [915.699], "images_per_second": 1.092, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "zebra: 2\ntall grass: 2\ntree: 1\nleaves: 1\nsky: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.1, "ram_available_mb": 109430.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.27, 43.27, 43.27, 52.95, 52.95, 52.95, 52.95, 52.95, 43.91, 43.91], "power_watts_avg": 48.24, "power_watts_peak": 52.95, "energy_joules_est": 44.18, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-11T13:51:26.253793"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 827.065, "latencies_ms": [827.065], "images_per_second": 1.209, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The zebra on the left is positioned in the foreground, while the zebra on the right is further in the background. The foreground and background are relatively close together, while the zebra on the right is further away.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.91, 43.91, 43.91, 42.94, 42.94, 42.94, 42.94, 42.94, 42.68], "power_watts_avg": 43.24, "power_watts_peak": 43.91, "energy_joules_est": 35.77, "sample_count": 9, "duration_seconds": 0.827}, "timestamp": "2026-01-11T13:51:27.162814"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 798.452, "latencies_ms": [798.452], "images_per_second": 1.252, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two zebras stand in a field of tall, dry grass, facing the camera. The background features trees and shrubs, creating a natural habitat setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.68, 42.68, 42.68, 42.68, 43.23, 43.23, 43.23, 43.23], "power_watts_avg": 42.95, "power_watts_peak": 43.23, "energy_joules_est": 34.31, "sample_count": 8, "duration_seconds": 0.799}, "timestamp": "2026-01-11T13:51:27.974930"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 991.066, "latencies_ms": [991.066], "images_per_second": 1.009, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The zebras exhibit striking black and white stripes, creating a visually striking pattern. The grass is a golden-brown color, suggesting dry conditions. The lighting is soft and natural, enhancing the overall ambiance of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.23, 42.47, 42.47, 42.47, 42.47, 42.47, 44.46, 44.46, 44.46, 44.46], "power_watts_avg": 43.34, "power_watts_peak": 44.46, "energy_joules_est": 42.97, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-11T13:51:28.986281"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 623.8, "latencies_ms": [623.8], "images_per_second": 1.603, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man in black shorts carries a yellow surfboard towards the ocean, preparing to enter the waves.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [44.46, 44.47, 44.47, 44.47, 44.47, 44.47, 43.96], "power_watts_avg": 44.4, "power_watts_peak": 44.47, "energy_joules_est": 27.72, "sample_count": 7, "duration_seconds": 0.624}, "timestamp": "2026-01-11T13:51:29.696332"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1018.437, "latencies_ms": [1018.437], "images_per_second": 0.982, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "surfboard: 1\nperson: 1\nwater: 6\nwaves: 4\nsky: 1\nsand: 1\nocean: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.96, 43.96, 43.96, 53.04, 53.04, 53.04, 53.04, 53.04, 43.01, 43.01, 43.01], "power_watts_avg": 47.83, "power_watts_peak": 53.04, "energy_joules_est": 48.72, "sample_count": 11, "duration_seconds": 1.019}, "timestamp": "2026-01-11T13:51:30.807479"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 761.512, "latencies_ms": [761.512], "images_per_second": 1.313, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The man is walking towards the ocean with his surfboard, positioned in the foreground of the image. The ocean extends in the background, creating a sense of distance and space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 40.45, 40.45, 40.45, 40.45, 40.45, 42.78], "power_watts_avg": 41.39, "power_watts_peak": 43.01, "energy_joules_est": 31.53, "sample_count": 8, "duration_seconds": 0.762}, "timestamp": "2026-01-11T13:51:31.616065"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 876.988, "latencies_ms": [876.988], "images_per_second": 1.14, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A man is walking into the ocean carrying a yellow surfboard, preparing to surf the waves. The ocean is blue and choppy, with waves breaking around the man.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.78, 42.78, 42.78, 42.78, 45.91, 45.91, 45.91, 45.91, 45.91], "power_watts_avg": 44.52, "power_watts_peak": 45.91, "energy_joules_est": 39.07, "sample_count": 9, "duration_seconds": 0.878}, "timestamp": "2026-01-11T13:51:32.526235"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 788.507, "latencies_ms": [788.507], "images_per_second": 1.268, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The surfer is wearing a yellow shirt and dark shorts. The ocean is a dark blue, and the sky is light blue, suggesting fair weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.0, "ram_available_mb": 109430.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 43.52, 43.52, 43.52, 43.51, 43.51, 43.51], "power_watts_avg": 43.52, "power_watts_peak": 43.52, "energy_joules_est": 34.34, "sample_count": 8, "duration_seconds": 0.789}, "timestamp": "2026-01-11T13:51:33.336428"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 561.431, "latencies_ms": [561.431], "images_per_second": 1.781, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A black and white cow stands calmly on a sandy beach, gazing directly at the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.51, 43.51, 49.86, 49.86, 49.86, 49.86], "power_watts_avg": 47.74, "power_watts_peak": 49.86, "energy_joules_est": 26.82, "sample_count": 6, "duration_seconds": 0.562}, "timestamp": "2026-01-11T13:51:33.945576"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1124.465, "latencies_ms": [1124.465], "images_per_second": 0.889, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Cow: 1\nSand: 1\nWater: 1\nGround: 1\nPlant: 1\nBag: 1\nEar tag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [49.86, 43.52, 43.52, 43.52, 43.52, 43.52, 46.06, 46.06, 46.06, 46.06, 46.06, 42.82], "power_watts_avg": 45.05, "power_watts_peak": 49.86, "energy_joules_est": 50.68, "sample_count": 12, "duration_seconds": 1.125}, "timestamp": "2026-01-11T13:51:35.155516"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 820.404, "latencies_ms": [820.404], "images_per_second": 1.219, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The cow is positioned near the foreground, facing the viewer. The body of water in the background extends into the distance, creating a sense of depth and distance between the cow and the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.82, 42.82, 42.82, 42.82, 42.6, 42.6, 42.6, 42.6, 42.6], "power_watts_avg": 42.7, "power_watts_peak": 42.82, "energy_joules_est": 35.05, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-11T13:51:36.067019"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 673.226, "latencies_ms": [673.226], "images_per_second": 1.485, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A black and white cow stands on a sandy beach, facing the camera. The calm water in the background creates a serene and picturesque setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.53, 42.53, 42.53, 42.53, 42.53, 42.59, 42.59], "power_watts_avg": 42.55, "power_watts_peak": 42.59, "energy_joules_est": 28.67, "sample_count": 7, "duration_seconds": 0.674}, "timestamp": "2026-01-11T13:51:36.776703"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 803.661, "latencies_ms": [803.661], "images_per_second": 1.244, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The cow is black and white. The lighting is soft and diffused, creating a calm atmosphere. The cow is standing on a sandy beach next to a body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.2, "ram_available_mb": 109430.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 42.59, 51.08, 51.08, 51.08, 51.08, 51.08, 43.31], "power_watts_avg": 47.39, "power_watts_peak": 51.08, "energy_joules_est": 38.11, "sample_count": 9, "duration_seconds": 0.804}, "timestamp": "2026-01-11T13:51:37.686213"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 657.27, "latencies_ms": [657.27], "images_per_second": 1.521, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman, dressed in winter attire, stands confidently in the snow, holding skis and poles, smiling warmly at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.31, 43.31, 43.31, 43.31, 37.75, 37.75, 37.75], "power_watts_avg": 40.93, "power_watts_peak": 43.31, "energy_joules_est": 26.93, "sample_count": 7, "duration_seconds": 0.658}, "timestamp": "2026-01-11T13:51:38.395805"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1087.807, "latencies_ms": [1087.807], "images_per_second": 0.919, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "woman: 2\nskis: 1\nsnowboard: 1\ngloves: 1\nski poles: 1\nbelt: 1\nscarf: 1\ntree: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.75, 39.82, 39.82, 39.82, 39.82, 39.82, 38.17, 38.17, 38.17, 38.17, 38.17], "power_watts_avg": 38.88, "power_watts_peak": 39.82, "energy_joules_est": 42.31, "sample_count": 11, "duration_seconds": 1.088}, "timestamp": "2026-01-11T13:51:39.505559"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 738.517, "latencies_ms": [738.517], "images_per_second": 1.354, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, holding ski poles and standing near a pair of skis. The background features trees and a cloudy sky, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [35.49, 35.49, 35.49, 35.49, 35.49, 38.72, 38.72, 38.72], "power_watts_avg": 36.7, "power_watts_peak": 38.72, "energy_joules_est": 27.13, "sample_count": 8, "duration_seconds": 0.739}, "timestamp": "2026-01-11T13:51:40.317183"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 911.543, "latencies_ms": [911.543], "images_per_second": 1.097, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A woman is posing in a snowy setting, dressed in ski gear and holding skis and poles. She appears to be enjoying a winter activity, possibly skiing. The background includes pine trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.72, 38.72, 42.07, 42.07, 42.07, 42.07, 42.07, 37.46, 37.46, 37.46], "power_watts_avg": 40.02, "power_watts_peak": 42.07, "energy_joules_est": 36.49, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-11T13:51:41.330297"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 774.243, "latencies_ms": [774.243], "images_per_second": 1.292, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The woman is wearing black and white clothing. The lighting appears to be natural, possibly from the sky, creating a contrast against the darker background. The image also features pine trees, suggesting the snowy environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.46, 37.46, 36.78, 36.78, 36.78, 36.78, 36.78, 36.72], "power_watts_avg": 36.94, "power_watts_peak": 37.46, "energy_joules_est": 28.62, "sample_count": 8, "duration_seconds": 0.775}, "timestamp": "2026-01-11T13:51:42.138489"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 573.625, "latencies_ms": [573.625], "images_per_second": 1.743, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A black and white dog is standing on a sandy beach, holding a yellow frisbee in its mouth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.72, 36.72, 36.72, 36.72, 43.59, 43.59], "power_watts_avg": 39.01, "power_watts_peak": 43.59, "energy_joules_est": 22.39, "sample_count": 6, "duration_seconds": 0.574}, "timestamp": "2026-01-11T13:51:42.748500"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1085.504, "latencies_ms": [1085.504], "images_per_second": 0.921, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "yellow frisbee: 1\nsand: 6\nocean: 6\ndog: 1\npink nose: 1\nwaves: 2\nisland: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.59, 43.59, 43.59, 53.8, 53.8, 53.8, 53.8, 53.8, 43.72, 43.72, 43.72], "power_watts_avg": 48.27, "power_watts_peak": 53.8, "energy_joules_est": 52.42, "sample_count": 11, "duration_seconds": 1.086}, "timestamp": "2026-01-11T13:51:43.861493"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1012.04, "latencies_ms": [1012.04], "images_per_second": 0.988, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The dog is positioned in the foreground, facing the camera. The yellow frisbee is held in the dog's mouth, close to the dog's nose. The beach extends in the background, meeting the turquoise ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.4, "ram_available_mb": 109429.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.72, 43.72, 39.41, 39.41, 39.41, 39.41, 39.41, 44.16, 44.16, 44.16, 44.16], "power_watts_avg": 41.92, "power_watts_peak": 44.16, "energy_joules_est": 42.44, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-11T13:51:44.970133"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.795, "latencies_ms": [933.795], "images_per_second": 1.071, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set on a sandy beach near the ocean, where a dog is holding a yellow frisbee in its mouth. The ocean is visible in the background, with waves gently lapping at the shore.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13076.3, "ram_available_mb": 109430.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 13078.9, "ram_available_mb": 109427.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [44.16, 37.71, 37.71, 37.71, 37.71, 37.71, 42.23, 42.23, 42.23, 42.23], "power_watts_avg": 40.16, "power_watts_peak": 44.16, "energy_joules_est": 37.52, "sample_count": 10, "duration_seconds": 0.934}, "timestamp": "2026-01-11T13:51:45.978811"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1050.823, "latencies_ms": [1050.823], "images_per_second": 0.952, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The dog is primarily black and white with patches of gray. The beach is sandy and appears wet, suggesting recent rain or sun. The dog is holding a yellow frisbee in its mouth. The sky is overcast and gray.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.23, 43.36, 43.36, 43.36, 43.36, 43.36, 43.35, 43.35, 43.35, 43.35, 43.35], "power_watts_avg": 43.25, "power_watts_peak": 43.36, "energy_joules_est": 45.46, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-11T13:51:47.087296"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 462.991, "latencies_ms": [462.991], "images_per_second": 2.16, "prompt_tokens": 8, "response_tokens_est": 14, "n_tiles": 1, "output_text": "A group of people are gathered in a kitchen, preparing food together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.77, 44.77, 44.77, 44.77, 44.77], "power_watts_avg": 44.77, "power_watts_peak": 44.77, "energy_joules_est": 20.76, "sample_count": 5, "duration_seconds": 0.464}, "timestamp": "2026-01-11T13:51:47.596936"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1260.091, "latencies_ms": [1260.091], "images_per_second": 0.794, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Refrigerator: 2\nCountertop: 1\nPot: 1\nGlass: 1\nBowl: 1\nBox: 1\nLid: 1\nShelves: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 43.34, 43.34, 53.19, 53.19, 53.19, 53.19, 53.19, 43.63, 43.63, 43.63, 43.63], "power_watts_avg": 47.22, "power_watts_peak": 53.19, "energy_joules_est": 59.52, "sample_count": 13, "duration_seconds": 1.261}, "timestamp": "2026-01-11T13:51:48.910827"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 900.54, "latencies_ms": [900.54], "images_per_second": 1.11, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The large stainless steel refrigerator occupies the central foreground, positioned between the people and the countertop. The kitchen area extends beyond the refrigerator, occupying the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [43.63, 36.04, 36.04, 36.04, 36.04, 36.04, 43.06, 43.06, 43.06], "power_watts_avg": 39.23, "power_watts_peak": 43.63, "energy_joules_est": 35.33, "sample_count": 9, "duration_seconds": 0.901}, "timestamp": "2026-01-11T13:51:49.820135"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 752.37, "latencies_ms": [752.37], "images_per_second": 1.329, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of people are gathered in a kitchen, preparing food. A large stainless steel refrigerator is prominently visible, along with various kitchen items and utensils.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [43.06, 43.06, 49.35, 49.35, 49.35, 49.35, 49.35, 43.99], "power_watts_avg": 47.11, "power_watts_peak": 49.35, "energy_joules_est": 35.47, "sample_count": 8, "duration_seconds": 0.753}, "timestamp": "2026-01-11T13:51:50.630451"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 929.383, "latencies_ms": [929.383], "images_per_second": 1.076, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The kitchen is equipped with stainless steel appliances and features natural lighting, creating a bright and clean atmosphere. The walls are painted in a light color, contributing to the overall brightness of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.99, 43.99, 43.99, 43.99, 46.44, 46.44, 46.44, 46.44, 46.44, 43.54], "power_watts_avg": 45.17, "power_watts_peak": 46.44, "energy_joules_est": 42.01, "sample_count": 10, "duration_seconds": 0.93}, "timestamp": "2026-01-11T13:51:51.639816"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 713.186, "latencies_ms": [713.186], "images_per_second": 1.402, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A bathroom features a white toilet, neatly arranged toiletries on a shelf, and a towel rack with folded white towels.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 43.54, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 43.08, "power_watts_peak": 43.54, "energy_joules_est": 30.74, "sample_count": 8, "duration_seconds": 0.714}, "timestamp": "2026-01-11T13:51:52.450845"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1926.88, "latencies_ms": [1926.88], "images_per_second": 0.519, "prompt_tokens": 21, "response_tokens_est": 63, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper: 1\ntowel: 2\nsoap dispenser: 2\nshampoo bottle: 2\nshaving cream bottle: 2\nshaving cream dispenser: 1\nbathroom phone: 1\nbathroom mirror: 1\nbathroom towel rack: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.61, 42.67, 42.67, 42.67, 42.67, 42.67, 42.92, 42.92, 42.92, 42.92, 42.92, 44.07, 44.07, 44.07, 44.07, 44.07, 34.31, 34.31, 34.31, 34.31], "power_watts_avg": 41.41, "power_watts_peak": 44.07, "energy_joules_est": 79.81, "sample_count": 20, "duration_seconds": 1.927}, "timestamp": "2026-01-11T13:51:54.461652"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 697.451, "latencies_ms": [697.451], "images_per_second": 1.434, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, slightly to the right of the shelf. The shelf is situated in the background, slightly to the left of the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.31, 33.82, 33.82, 33.82, 33.82, 33.82, 43.01], "power_watts_avg": 35.2, "power_watts_peak": 43.01, "energy_joules_est": 24.57, "sample_count": 7, "duration_seconds": 0.698}, "timestamp": "2026-01-11T13:51:55.169427"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1206.977, "latencies_ms": [1206.977], "images_per_second": 0.829, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The bathroom features a modern design with beige tile walls, a white toilet, and a built-in shelf with toiletries. A towel rack holds two neatly folded white towels, and a telephone is mounted on the wall. The overall scene suggests a clean, organized, and comfortable space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.01, 54.62, 54.62, 54.62, 54.62, 54.62, 44.23, 44.23, 44.23], "power_watts_avg": 48.15, "power_watts_peak": 54.62, "energy_joules_est": 58.17, "sample_count": 12, "duration_seconds": 1.208}, "timestamp": "2026-01-11T13:51:56.383587"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1092.981, "latencies_ms": [1092.981], "images_per_second": 0.915, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The bathroom features a beige color scheme, creating a warm and inviting atmosphere. The lighting is soft and diffused, enhancing the cleanliness and comfort of the space. The materials appear to be modern and sleek, contributing to the overall sophisticated look.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.23, 44.23, 39.55, 39.55, 39.55, 39.55, 39.55, 44.11, 44.11, 44.11, 44.11], "power_watts_avg": 42.06, "power_watts_peak": 44.23, "energy_joules_est": 45.99, "sample_count": 11, "duration_seconds": 1.094}, "timestamp": "2026-01-11T13:51:57.495082"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 610.775, "latencies_ms": [610.775], "images_per_second": 1.637, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A woman in a green top hat sits in the driver's seat of a car, accompanied by her beagle wearing a green shamrock hat.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.11, 39.51, 39.51, 39.51, 39.51, 38.79, 38.79], "power_watts_avg": 39.96, "power_watts_peak": 44.11, "energy_joules_est": 24.42, "sample_count": 7, "duration_seconds": 0.611}, "timestamp": "2026-01-11T13:51:58.204194"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1154.782, "latencies_ms": [1154.782], "images_per_second": 0.866, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "woman: 1\ndog: 1\nhat: 1\nIrish flag: 1\nmirror: 1\nshamrock: 1\ntruck: 1\nwindshield wiper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [38.79, 38.79, 38.79, 42.43, 42.43, 42.43, 42.43, 42.43, 37.45, 37.45, 37.45, 37.45], "power_watts_avg": 39.86, "power_watts_peak": 42.43, "energy_joules_est": 46.05, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:51:59.414965"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 757.956, "latencies_ms": [757.956], "images_per_second": 1.319, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The woman and dog are positioned in the left foreground of the image. The Irish flag and shamrock decoration are placed near the back of the vehicle, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.45, 36.77, 36.77, 36.77, 36.77, 36.77, 38.2, 38.2], "power_watts_avg": 37.21, "power_watts_peak": 38.2, "energy_joules_est": 28.24, "sample_count": 8, "duration_seconds": 0.759}, "timestamp": "2026-01-11T13:52:00.226452"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 759.841, "latencies_ms": [759.841], "images_per_second": 1.316, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A woman and a beagle are sitting in the back of a truck decorated for St. Patrick's Day. The truck is adorned with green shamrocks and an Irish flag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.1, "ram_available_mb": 109425.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.2, 38.2, 38.2, 40.49, 40.49, 40.49, 40.49, 40.49], "power_watts_avg": 39.63, "power_watts_peak": 40.49, "energy_joules_est": 30.13, "sample_count": 8, "duration_seconds": 0.76}, "timestamp": "2026-01-11T13:52:01.033826"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 871.599, "latencies_ms": [871.599], "images_per_second": 1.147, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The vehicle is decorated with green and orange colors, reflecting the Irish flag. The lighting suggests an outdoor setting, likely during daytime. The materials appear to be metal and plastic, typical for vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.91, 37.91, 37.91, 37.91, 37.91, 38.08, 38.08, 38.08, 38.08], "power_watts_avg": 37.98, "power_watts_peak": 38.08, "energy_joules_est": 33.12, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-11T13:52:01.943817"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 664.954, "latencies_ms": [664.954], "images_per_second": 1.504, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "An adult elephant is walking through a shallow pool of water, surrounded by rocks and dirt, with several people observing in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13081.3, "ram_available_mb": 109425.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [38.08, 39.54, 39.54, 39.54, 39.54, 39.54, 43.49], "power_watts_avg": 39.89, "power_watts_peak": 43.49, "energy_joules_est": 26.55, "sample_count": 7, "duration_seconds": 0.665}, "timestamp": "2026-01-11T13:52:02.656331"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1333.212, "latencies_ms": [1333.212], "images_per_second": 0.75, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Elephant: 1\nLog: 1\nWater: 1\nRocks: 3\nGround: 2\nFence: 1\nGround: 1\nPlants: 2\nPeople: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.49, 43.49, 43.49, 43.49, 51.78, 51.78, 51.78, 51.78, 51.78, 43.14, 43.14, 43.14, 43.14, 43.14], "power_watts_avg": 46.33, "power_watts_peak": 51.78, "energy_joules_est": 61.78, "sample_count": 14, "duration_seconds": 1.334}, "timestamp": "2026-01-11T13:52:04.066852"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 877.078, "latencies_ms": [877.078], "images_per_second": 1.14, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The elephant is positioned in the foreground, facing the viewer. The background features other elements like rocks, trees, and people, suggesting the setting is a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.71, 33.71, 33.71, 33.71, 33.71, 42.98, 42.98, 42.98, 42.98], "power_watts_avg": 37.83, "power_watts_peak": 42.98, "energy_joules_est": 33.19, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-11T13:52:04.976587"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1090.94, "latencies_ms": [1090.94], "images_per_second": 0.917, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts an elephant in a zoo enclosure, walking through a shallow pool of water with rocks nearby. The enclosure is surrounded by dirt and features other elephant statues and logs. Several people are visible in the background, possibly observing the animals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.98, 42.6, 42.6, 42.6, 42.6, 42.6, 43.63, 43.63, 43.63, 43.63, 43.63], "power_watts_avg": 43.1, "power_watts_peak": 43.63, "energy_joules_est": 47.06, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-11T13:52:06.090546"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1062.622, "latencies_ms": [1062.622], "images_per_second": 0.941, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The elephant is gray and appears to be wet. The lighting is bright, likely from sunlight, creating a clear reflection on the wet ground. The enclosure features natural elements like rocks and grass, and includes artificial structures like a log and a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.85, 43.85, 43.85, 43.85, 43.85, 43.64, 43.64, 43.64, 43.64, 43.64, 44.11], "power_watts_avg": 43.78, "power_watts_peak": 44.11, "energy_joules_est": 46.54, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-11T13:52:07.202447"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 720.249, "latencies_ms": [720.249], "images_per_second": 1.388, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Four people in winter gear, including skis, stand on a snowy mountain slope, smiling and enjoying their skiing adventure.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 40.0}, "power_stats": {"power_watts_samples": [44.11, 44.11, 44.11, 43.35, 43.35, 43.35, 43.35, 43.35], "power_watts_avg": 43.64, "power_watts_peak": 44.11, "energy_joules_est": 31.44, "sample_count": 8, "duration_seconds": 0.721}, "timestamp": "2026-01-11T13:52:08.014077"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1212.821, "latencies_ms": [1212.821], "images_per_second": 0.825, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "person: 4\nski: 4\nsnow: 8\nmountain: 8\nsky: 1\ntrees: 2\nski poles: 4\ngloves: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.06, 42.06, 42.06, 42.06, 42.06, 42.65, 42.65, 42.65, 42.65, 42.65, 44.02, 44.02, 44.02], "power_watts_avg": 42.74, "power_watts_peak": 44.02, "energy_joules_est": 51.85, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-11T13:52:09.328012"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1027.149, "latencies_ms": [1027.149], "images_per_second": 0.974, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The four people are positioned in the foreground of the image, standing relatively close together. The snow-covered mountain forms the backdrop, extending into the distance. The ski lift and poles are located in the background, further away from the main group.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.02, 44.02, 39.62, 39.62, 39.62, 39.62, 39.62, 42.26, 42.26, 42.26, 42.26], "power_watts_avg": 41.38, "power_watts_peak": 44.02, "energy_joules_est": 42.52, "sample_count": 11, "duration_seconds": 1.028}, "timestamp": "2026-01-11T13:52:10.437685"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 884.656, "latencies_ms": [884.656], "images_per_second": 1.13, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A group of four people are standing on a snowy mountain slope, wearing skis and posing for a photo. They are likely enjoying a day of skiing in a scenic, snow-covered area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [42.26, 37.52, 37.52, 37.52, 37.52, 37.52, 43.19, 43.19, 43.19], "power_watts_avg": 39.94, "power_watts_peak": 43.19, "energy_joules_est": 35.34, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-11T13:52:11.347763"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1193.79, "latencies_ms": [1193.79], "images_per_second": 0.838, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The skiers are wearing bright, colorful winter clothing. The lighting is bright and sunny, creating a pleasant atmosphere. The snow appears to be well-groomed and smooth, typical of ski slopes. The weather appears to be clear and sunny, ideal for skiing activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 50.08, 50.08, 50.08, 50.08, 50.08, 43.84, 43.84, 43.84, 43.84, 43.84], "power_watts_avg": 46.33, "power_watts_peak": 50.08, "energy_joules_est": 55.33, "sample_count": 12, "duration_seconds": 1.194}, "timestamp": "2026-01-11T13:52:12.557236"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 561.52, "latencies_ms": [561.52], "images_per_second": 1.781, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A person is holding a black iPhone in their hand, displaying a photo of a tree on the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [38.02, 38.02, 38.02, 38.02, 38.02, 44.12], "power_watts_avg": 39.04, "power_watts_peak": 44.12, "energy_joules_est": 21.95, "sample_count": 6, "duration_seconds": 0.562}, "timestamp": "2026-01-11T13:52:13.166060"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1154.702, "latencies_ms": [1154.702], "images_per_second": 0.866, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "phone: 2\nkeyboard: 1\nmirror: 1\nhand: 1\ntree: 1\nsky: 1\nwindow: 1\nbutton: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.12, 44.12, 44.12, 44.12, 53.65, 53.65, 53.65, 53.65, 53.65, 43.34, 43.34, 43.34], "power_watts_avg": 47.9, "power_watts_peak": 53.65, "energy_joules_est": 55.32, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-11T13:52:14.374451"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 983.655, "latencies_ms": [983.655], "images_per_second": 1.017, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main object is a smartphone held in the left foreground of the image. The reflection in the phone's screen shows a portion of a keyboard and a hand. The background is blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.7, "ram_available_mb": 109424.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 39.0, 39.0, 39.0, 39.0, 39.0, 43.33, 43.33, 43.33], "power_watts_avg": 41.17, "power_watts_peak": 43.34, "energy_joules_est": 40.52, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-11T13:52:15.383222"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 896.065, "latencies_ms": [896.065], "images_per_second": 1.116, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A person is holding a black iPhone in their hand, displaying a photo of a tree and a clock showing 19:45. The photo appears to be taken indoors, near a keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.33, 43.33, 43.34, 43.34, 43.34, 43.34, 43.34, 43.49, 43.49], "power_watts_avg": 43.37, "power_watts_peak": 43.49, "energy_joules_est": 38.88, "sample_count": 9, "duration_seconds": 0.896}, "timestamp": "2026-01-11T13:52:16.291772"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1041.723, "latencies_ms": [1041.723], "images_per_second": 0.96, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The phone's screen displays a black and white image, likely taken in low light conditions. The reflection shows a person's hand and a keyboard, suggesting the phone is held in a dimly lit environment. The phone appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.49, 43.49, 43.49, 48.23, 48.23, 48.23, 48.23, 48.23, 44.18, 44.18, 44.18], "power_watts_avg": 45.84, "power_watts_peak": 48.23, "energy_joules_est": 47.76, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:52:17.402311"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 758.307, "latencies_ms": [758.307], "images_per_second": 1.319, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A Denver's Road Home parking meter is mounted on a metal pole beside a sidewalk, with a sign urging people to end homelessness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.6, "ram_available_mb": 109424.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.18, 37.74, 37.74, 37.74, 37.74, 37.74, 42.99, 42.99], "power_watts_avg": 39.85, "power_watts_peak": 44.18, "energy_joules_est": 30.24, "sample_count": 8, "duration_seconds": 0.759}, "timestamp": "2026-01-11T13:52:18.214636"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1122.242, "latencies_ms": [1122.242], "images_per_second": 0.891, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Parking meter: 1\nSign: 1\nPlants: 2\nFence: 1\nSidewalk: 1\nTrees: 2\nGrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.99, 42.99, 42.99, 50.05, 50.05, 50.05, 50.05, 50.05, 43.22, 43.22, 43.22, 43.22], "power_watts_avg": 46.01, "power_watts_peak": 50.05, "energy_joules_est": 51.65, "sample_count": 12, "duration_seconds": 1.123}, "timestamp": "2026-01-11T13:52:19.427767"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 888.986, "latencies_ms": [888.986], "images_per_second": 1.125, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The parking meter is positioned in the foreground, slightly to the right of the image. The sign is situated in the background, near the parking meter. The parking meter and sign are located close to the sidewalk.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.22, 35.41, 35.41, 35.41, 35.41, 35.41, 42.9, 42.9, 42.9], "power_watts_avg": 38.77, "power_watts_peak": 43.22, "energy_joules_est": 34.48, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-11T13:52:20.338329"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 825.516, "latencies_ms": [825.516], "images_per_second": 1.211, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A Denver's Road Home parking meter is situated on a sidewalk near a fence and trees. A sign on the meter promotes a campaign to end homelessness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.9, 42.9, 49.54, 49.54, 49.54, 49.54, 49.54, 44.08, 44.08], "power_watts_avg": 46.85, "power_watts_peak": 49.54, "energy_joules_est": 38.7, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:52:21.248714"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 764.691, "latencies_ms": [764.691], "images_per_second": 1.308, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The parking meter is primarily red and gray. The lighting appears to be natural daylight. The materials appear to be metal and plastic. The weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.08, 44.08, 44.08, 45.88, 45.88, 45.88, 45.88, 45.88], "power_watts_avg": 45.21, "power_watts_peak": 45.88, "energy_joules_est": 34.59, "sample_count": 8, "duration_seconds": 0.765}, "timestamp": "2026-01-11T13:52:22.059665"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 583.618, "latencies_ms": [583.618], "images_per_second": 1.713, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A group of zebras graze peacefully in a dry, grassy field surrounded by trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.01, 43.01, 43.01, 43.01, 43.01, 43.6], "power_watts_avg": 43.1, "power_watts_peak": 43.6, "energy_joules_est": 25.18, "sample_count": 6, "duration_seconds": 0.584}, "timestamp": "2026-01-11T13:52:22.671145"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 965.809, "latencies_ms": [965.809], "images_per_second": 1.035, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "zebra: 5\ngrass: 6\ntree: 1\nbush: 2\nground: 4\nsky: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 43.6, 52.72, 52.72, 52.72, 52.72, 52.72, 43.44], "power_watts_avg": 48.14, "power_watts_peak": 52.72, "energy_joules_est": 46.52, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-11T13:52:23.682557"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 987.242, "latencies_ms": [987.242], "images_per_second": 1.013, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main zebra is positioned in the foreground, grazing on grass. The background features more zebras, creating a sense of depth and space. The zebra is relatively close to the viewer, emphasizing its presence in the scene.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 43.44, 43.44, 43.78, 43.78, 43.78, 43.78, 43.78, 43.48], "power_watts_avg": 43.61, "power_watts_peak": 43.78, "energy_joules_est": 43.09, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-11T13:52:24.692055"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 891.246, "latencies_ms": [891.246], "images_per_second": 1.122, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of zebras grazes in a grassy field with scattered trees and shrubs in the background. The zebras are spread out across the field, engaged in their natural feeding behavior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.48, 43.48, 43.48, 43.48, 43.95, 43.95, 43.95, 43.95, 43.95], "power_watts_avg": 43.74, "power_watts_peak": 43.95, "energy_joules_est": 39.0, "sample_count": 9, "duration_seconds": 0.892}, "timestamp": "2026-01-11T13:52:25.601752"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1218.687, "latencies_ms": [1218.687], "images_per_second": 0.821, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The zebras exhibit striking black and white stripes, creating a visually striking pattern. The lighting in the image appears to be natural, illuminating the zebras and grass without harsh shadows. The zebras are grazing in a grassy field, suggesting they are in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [44.22, 44.22, 44.22, 44.22, 43.51, 43.51, 43.51, 43.51, 43.51, 43.76, 43.76, 43.76, 43.76], "power_watts_avg": 43.8, "power_watts_peak": 44.22, "energy_joules_est": 53.39, "sample_count": 13, "duration_seconds": 1.219}, "timestamp": "2026-01-11T13:52:26.911996"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 732.143, "latencies_ms": [732.143], "images_per_second": 1.366, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A surfer in a black wetsuit rides a wave on a surfboard, skillfully navigating the powerful ocean currents.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.0, "ram_available_mb": 109425.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [43.76, 36.28, 36.28, 36.28, 36.28, 36.28, 42.98, 42.98], "power_watts_avg": 38.89, "power_watts_peak": 43.76, "energy_joules_est": 28.5, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-11T13:52:27.725628"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 944.995, "latencies_ms": [944.995], "images_per_second": 1.058, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "surfboard: 1\nwetsuit: 1\nwater: 1\nwave: 1\nperson: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [42.98, 42.98, 42.98, 49.98, 49.98, 49.98, 49.98, 49.98, 43.22, 43.22], "power_watts_avg": 46.53, "power_watts_peak": 49.98, "energy_joules_est": 43.99, "sample_count": 10, "duration_seconds": 0.946}, "timestamp": "2026-01-11T13:52:28.737191"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 799.652, "latencies_ms": [799.652], "images_per_second": 1.251, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave near the center of the frame. The ocean extends in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.2, "ram_available_mb": 109425.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [43.22, 43.22, 43.22, 43.52, 43.52, 43.52, 43.52, 43.52], "power_watts_avg": 43.4, "power_watts_peak": 43.52, "energy_joules_est": 34.73, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-11T13:52:29.546320"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 975.732, "latencies_ms": [975.732], "images_per_second": 1.025, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a surfer skillfully riding a wave in the ocean. The surfer is wearing a black wetsuit and is positioned on a surfboard, demonstrating their expertise in surfing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.09, 43.09, 43.09, 43.09, 43.09, 44.0, 44.0, 44.0, 44.0, 44.0], "power_watts_avg": 43.55, "power_watts_peak": 44.0, "energy_joules_est": 42.5, "sample_count": 10, "duration_seconds": 0.976}, "timestamp": "2026-01-11T13:52:30.557291"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 710.284, "latencies_ms": [710.284], "images_per_second": 1.408, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The surfer is wearing a black wetsuit. The ocean appears dark blue-green, and the lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 13081.5, "ram_available_mb": 109424.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.07, 44.07, 44.07, 44.07, 44.07, 43.66, 43.66, 43.66], "power_watts_avg": 43.91, "power_watts_peak": 44.07, "energy_joules_est": 31.2, "sample_count": 8, "duration_seconds": 0.711}, "timestamp": "2026-01-11T13:52:31.366276"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 623.246, "latencies_ms": [623.246], "images_per_second": 1.605, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two individuals in white snowsuits are preparing to ski down a snowy mountain slope at sunset.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13081.4, "ram_available_mb": 109424.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.66, 43.66, 48.67, 48.67, 48.67, 48.67, 48.67], "power_watts_avg": 47.24, "power_watts_peak": 48.67, "energy_joules_est": 29.47, "sample_count": 7, "duration_seconds": 0.624}, "timestamp": "2026-01-11T13:52:32.075600"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1359.831, "latencies_ms": [1359.831], "images_per_second": 0.735, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "skis: 2\nbackpack: 1\ngloves: 1\nhelmet: 1\ngloves: 1\ngloves: 1\nhelmet: 1\ngloves: 1\nbackpack: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.87, 42.87, 42.87, 42.87, 42.87, 48.46, 48.46, 48.46, 48.46, 48.46, 43.57, 43.57, 43.57, 43.57], "power_watts_avg": 45.06, "power_watts_peak": 48.46, "energy_joules_est": 61.31, "sample_count": 14, "duration_seconds": 1.361}, "timestamp": "2026-01-11T13:52:33.487610"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 808.015, "latencies_ms": [808.015], "images_per_second": 1.238, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skis are positioned in the foreground, while the snowboarder is further back, near the sun. The snowboarder's position suggests they are moving away from the sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.57, 33.25, 33.25, 33.25, 33.25, 33.25, 43.95, 43.95, 43.95], "power_watts_avg": 37.96, "power_watts_peak": 43.95, "energy_joules_est": 30.69, "sample_count": 9, "duration_seconds": 0.808}, "timestamp": "2026-01-11T13:52:34.395932"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1066.508, "latencies_ms": [1066.508], "images_per_second": 0.938, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Two individuals in winter gear are on a snowy mountain slope, preparing for skiing or snowboarding. They are wearing backpacks and holding ski poles. The sun is setting, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 48.37, 48.37, 48.37, 48.37, 48.37, 42.4, 42.4, 42.4, 42.4], "power_watts_avg": 45.39, "power_watts_peak": 48.37, "energy_joules_est": 48.43, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-11T13:52:35.505461"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1201.438, "latencies_ms": [1201.438], "images_per_second": 0.832, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The snow is white and appears smooth, illuminated by the sun's rays, creating a bright and reflective scene. The skiers are wearing light-colored clothing, enhancing visibility against the snowy backdrop. The overall atmosphere conveys a sense of adventure and cold weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.53, 39.53, 39.53, 39.53, 39.53, 43.41, 43.41, 43.41, 43.41, 43.41, 43.98, 43.98], "power_watts_avg": 41.89, "power_watts_peak": 43.98, "energy_joules_est": 50.34, "sample_count": 12, "duration_seconds": 1.202}, "timestamp": "2026-01-11T13:52:36.715731"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 818.173, "latencies_ms": [818.173], "images_per_second": 1.222, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A youth baseball game is in progress, with a batter in a red uniform swinging a bat, while a catcher in black crouches behind him.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [43.98, 43.98, 43.98, 43.72, 43.72, 43.72, 43.72, 43.72, 44.16], "power_watts_avg": 43.86, "power_watts_peak": 44.16, "energy_joules_est": 35.89, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-11T13:52:37.626730"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1452.721, "latencies_ms": [1452.721], "images_per_second": 0.688, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball: 1\ncatcher: 1\numpire: 1\nbaseball field: 1\nfence: 2\ncars: 2\nspectators: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.16, 44.16, 44.16, 44.16, 42.74, 42.74, 42.74, 42.74, 42.74, 42.72, 42.72, 42.72, 42.72, 42.72, 34.26], "power_watts_avg": 42.54, "power_watts_peak": 44.16, "energy_joules_est": 61.82, "sample_count": 15, "duration_seconds": 1.453}, "timestamp": "2026-01-11T13:52:39.138697"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1044.559, "latencies_ms": [1044.559], "images_per_second": 0.957, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the catcher and glove. The catcher and glove are located in the background, behind the batter and slightly to the left. The spectators are situated in the background, behind the fence.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.26, 34.26, 34.26, 34.26, 43.71, 43.71, 43.71, 43.71, 43.71, 43.54, 43.54], "power_watts_avg": 40.24, "power_watts_peak": 43.71, "energy_joules_est": 42.05, "sample_count": 11, "duration_seconds": 1.045}, "timestamp": "2026-01-11T13:52:40.249284"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1213.638, "latencies_ms": [1213.638], "images_per_second": 0.824, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A youth baseball game is in progress. A batter in a red uniform is swinging at a pitch, while a catcher in a black uniform crouches behind home plate, ready to catch the ball. Spectators are watching from behind a chain-link fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 43.09, 43.09, 43.09, 43.09, 43.09, 43.19, 43.19, 43.19, 43.19, 43.19], "power_watts_avg": 43.23, "power_watts_peak": 43.54, "energy_joules_est": 52.49, "sample_count": 13, "duration_seconds": 1.214}, "timestamp": "2026-01-11T13:52:41.560225"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 903.576, "latencies_ms": [903.576], "images_per_second": 1.107, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The batter is wearing a red uniform. The field appears to be well-maintained and appears to be made of a hard, potentially synthetic material. The lighting suggests it's likely daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.33, 33.33, 33.33, 33.33, 33.33, 41.75, 41.75, 41.75, 41.75, 41.75], "power_watts_avg": 37.54, "power_watts_peak": 41.75, "energy_joules_est": 33.93, "sample_count": 10, "duration_seconds": 0.904}, "timestamp": "2026-01-11T13:52:42.569584"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1121.094, "latencies_ms": [1121.094], "images_per_second": 0.892, "prompt_tokens": 8, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A tall glass filled with a creamy beverage, possibly a milkshake or a smoothie, topped with whipped cream, sits next to a slice of layered vanilla cake on a white plate, accompanied by a fork and a napkin.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.31, 41.31, 41.31, 41.31, 41.31, 43.52, 43.52, 43.52, 43.52, 43.52, 44.46, 44.46], "power_watts_avg": 42.76, "power_watts_peak": 44.46, "energy_joules_est": 47.97, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-11T13:52:43.782844"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1334.041, "latencies_ms": [1334.041], "images_per_second": 0.75, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Coffee: 1\nMilkshake: 1\nCake: 1\nFork: 2\nNapkin: 1\nTable: 1\nDrink: 1\nChair: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.46, 44.46, 44.46, 42.55, 42.55, 42.55, 42.55, 42.55, 44.02, 44.02, 44.02, 44.02, 44.02, 35.86], "power_watts_avg": 43.0, "power_watts_peak": 44.46, "energy_joules_est": 57.4, "sample_count": 14, "duration_seconds": 1.335}, "timestamp": "2026-01-11T13:52:45.202462"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1035.514, "latencies_ms": [1035.514], "images_per_second": 0.966, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The cake and milkshake are placed in the foreground of the image, with the milkshake positioned slightly behind and to the left of the cake. The background of the image is blurred, indicating a focus on the foreground items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13082.0, "ram_available_mb": 109424.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [35.86, 35.86, 35.86, 35.86, 44.37, 44.37, 44.37, 44.37, 44.37, 44.35, 44.35], "power_watts_avg": 41.27, "power_watts_peak": 44.37, "energy_joules_est": 42.75, "sample_count": 11, "duration_seconds": 1.036}, "timestamp": "2026-01-11T13:52:46.315015"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1240.708, "latencies_ms": [1240.708], "images_per_second": 0.806, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a cozy setting with a table featuring a slice of layered cake, a tall glass of chocolate milkshake with whipped cream, and two forks. The table is situated in a restaurant or cafe, with other tables and chairs visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.35, 44.35, 41.84, 41.84, 41.84, 41.84, 41.84, 44.28, 44.28, 44.28, 44.28, 44.28, 37.6], "power_watts_avg": 42.84, "power_watts_peak": 44.35, "energy_joules_est": 53.17, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-11T13:52:47.627320"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 916.665, "latencies_ms": [916.665], "images_per_second": 1.091, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The milkshake is brown and appears creamy. The cake is light yellow and looks moist. The table is dark brown, and the lighting is soft and warm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.6, 37.6, 37.6, 37.6, 44.33, 44.33, 44.33, 44.33, 44.33, 44.36], "power_watts_avg": 41.65, "power_watts_peak": 44.36, "energy_joules_est": 38.19, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-11T13:52:48.635316"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 744.46, "latencies_ms": [744.46], "images_per_second": 1.343, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A three-tiered wedding cake, featuring white frosting, blue and gold accents, and floral decorations, sits on a table draped with a blue tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.36, 44.36, 44.36, 44.36, 37.61, 37.61, 37.61, 37.61], "power_watts_avg": 40.99, "power_watts_peak": 44.36, "energy_joules_est": 30.54, "sample_count": 8, "duration_seconds": 0.745}, "timestamp": "2026-01-11T13:52:49.444431"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1043.355, "latencies_ms": [1043.355], "images_per_second": 0.958, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "cake: 3\nfloral arrangement: 1\ndecorative top: 1\nchandelier: 1\ntablecloth: 1\nchairs: 2\nwater view: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [37.61, 38.77, 38.77, 38.77, 38.77, 38.77, 38.22, 38.22, 38.22, 38.22, 38.22], "power_watts_avg": 38.41, "power_watts_peak": 38.77, "energy_joules_est": 40.09, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-11T13:52:50.555685"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 918.207, "latencies_ms": [918.207], "images_per_second": 1.089, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The large three-tiered wedding cake dominates the foreground, positioned slightly to the right of the viewer. The dining area with tables, chairs, and umbrellas extends in the background, extending beyond the cake's immediate vicinity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.52, 37.52, 37.52, 37.52, 37.52, 38.03, 38.03, 38.03, 38.03, 38.03], "power_watts_avg": 37.78, "power_watts_peak": 38.03, "energy_joules_est": 34.7, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-11T13:52:51.565160"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1164.738, "latencies_ms": [1164.738], "images_per_second": 0.859, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a wedding reception held in a spacious room with large windows overlooking the ocean. A three-tiered wedding cake, featuring white and gold icing, is prominently displayed on a table covered with a blue tablecloth. The cake is adorned with flowers and has a figurine on top.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.58, 37.58, 37.58, 37.58, 37.58, 37.45, 37.45, 37.45, 37.45, 37.45, 37.77, 37.77], "power_watts_avg": 37.55, "power_watts_peak": 37.77, "energy_joules_est": 43.75, "sample_count": 12, "duration_seconds": 1.165}, "timestamp": "2026-01-11T13:52:52.775556"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 827.495, "latencies_ms": [827.495], "images_per_second": 1.208, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The wedding cake is predominantly white with gold accents. The lighting in the room is warm and inviting, creating a pleasant atmosphere. The cake appears to be made of edible materials, enhancing its visual appeal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [37.77, 37.77, 37.77, 38.0, 38.0, 38.0, 38.0, 38.0, 37.8], "power_watts_avg": 37.9, "power_watts_peak": 38.0, "energy_joules_est": 31.37, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-11T13:52:53.685490"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 626.173, "latencies_ms": [626.173], "images_per_second": 1.597, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A woman in a red and blue sweater is cooking on a stove, skillfully stirring food in a pot.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [37.8, 37.8, 37.8, 37.8, 42.39, 42.39, 42.39], "power_watts_avg": 39.77, "power_watts_peak": 42.39, "energy_joules_est": 24.94, "sample_count": 7, "duration_seconds": 0.627}, "timestamp": "2026-01-11T13:52:54.393738"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1392.991, "latencies_ms": [1392.991], "images_per_second": 0.718, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "pan: 2\nplate: 1\npot: 1\nstove: 1\nsaucepan: 1\nspices: 2\nshelves: 2\nutensils: 2\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.39, 42.39, 45.95, 45.95, 45.95, 45.95, 45.95, 42.97, 42.97, 42.97, 42.97, 42.97, 40.52, 40.52], "power_watts_avg": 43.6, "power_watts_peak": 45.95, "energy_joules_est": 60.75, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-11T13:52:55.805410"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 865.467, "latencies_ms": [865.467], "images_per_second": 1.155, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The woman is standing near the stove, preparing food. She is positioned in the foreground of the image, with the stove and pots behind her. The kitchen setting is partially visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.9, "ram_available_mb": 109424.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [40.52, 40.52, 40.52, 42.94, 42.94, 42.94, 42.94, 42.94, 44.1], "power_watts_avg": 42.26, "power_watts_peak": 44.1, "energy_joules_est": 36.59, "sample_count": 9, "duration_seconds": 0.866}, "timestamp": "2026-01-11T13:52:56.713862"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1004.535, "latencies_ms": [1004.535], "images_per_second": 0.995, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A woman is cooking in a kitchen, using a spoon to stir food on a plate. She is wearing a red and blue sweater and gray pants. The kitchen has various items and appliances, including a stove, pots, and bottles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.1, 44.1, 44.1, 46.04, 46.04, 46.04, 46.04, 46.04, 43.97, 43.97], "power_watts_avg": 45.04, "power_watts_peak": 46.04, "energy_joules_est": 45.26, "sample_count": 10, "duration_seconds": 1.005}, "timestamp": "2026-01-11T13:52:57.723920"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 734.793, "latencies_ms": [734.793], "images_per_second": 1.361, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The woman is wearing a red and blue sweater. The kitchen has warm lighting. The scene suggests a cozy, home-cooked meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.97, 43.97, 43.97, 44.35, 44.35, 44.35, 44.35, 44.35], "power_watts_avg": 44.2, "power_watts_peak": 44.35, "energy_joules_est": 32.5, "sample_count": 8, "duration_seconds": 0.735}, "timestamp": "2026-01-11T13:52:58.533494"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 703.403, "latencies_ms": [703.403], "images_per_second": 1.422, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a pink shirt and black pants is leading a white horse across a dirt field, holding the reins securely.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.72, 43.72, 43.72, 43.72, 43.72, 43.24, 43.24, 43.24], "power_watts_avg": 43.54, "power_watts_peak": 43.72, "energy_joules_est": 30.63, "sample_count": 8, "duration_seconds": 0.704}, "timestamp": "2026-01-11T13:52:59.343882"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1269.429, "latencies_ms": [1269.429], "images_per_second": 0.788, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "horse: 1\nrope: 1\nwoman: 1\npants: 1\nboots: 1\nbelt: 1\nshirt: 1\nfence: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 49.34, 49.34, 49.34, 49.34, 49.34, 42.42, 42.42, 42.42, 42.42, 42.42, 36.96], "power_watts_avg": 44.79, "power_watts_peak": 49.34, "energy_joules_est": 56.88, "sample_count": 13, "duration_seconds": 1.27}, "timestamp": "2026-01-11T13:53:00.655435"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1073.813, "latencies_ms": [1073.813], "images_per_second": 0.931, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The white horse is positioned to the left of the woman, who is positioned in the foreground. The horse and woman are relatively close together, with the horse being more prominent in the foreground. The background is slightly blurred, drawing focus to the woman and the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13081.8, "ram_available_mb": 109424.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [36.96, 36.96, 36.96, 36.96, 43.6, 43.6, 43.6, 43.6, 43.6, 43.51, 43.51], "power_watts_avg": 41.17, "power_watts_peak": 43.6, "energy_joules_est": 44.23, "sample_count": 11, "duration_seconds": 1.074}, "timestamp": "2026-01-11T13:53:01.762537"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1024.254, "latencies_ms": [1024.254], "images_per_second": 0.976, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A woman is leading a white horse across a dirt field. She is wearing a pink shirt, black pants, and brown boots. The setting appears to be a fenced-in area, possibly a horse farm or training facility.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 61.0}, "power_stats": {"power_watts_samples": [43.51, 43.51, 43.51, 42.73, 42.73, 42.73, 42.73, 42.73, 43.23, 43.23, 43.23], "power_watts_avg": 43.08, "power_watts_peak": 43.51, "energy_joules_est": 44.16, "sample_count": 11, "duration_seconds": 1.025}, "timestamp": "2026-01-11T13:53:02.876438"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1012.203, "latencies_ms": [1012.203], "images_per_second": 0.988, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The horse is light gray or white. The lighting is bright, likely from natural sunlight, creating a pleasant atmosphere. The woman is wearing brown boots and a pink shirt, suggesting an outdoor setting in sunny weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [43.23, 43.23, 38.69, 38.69, 38.69, 38.69, 38.69, 42.45, 42.45, 42.45, 42.45], "power_watts_avg": 40.88, "power_watts_peak": 43.23, "energy_joules_est": 41.39, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-11T13:53:03.985736"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 699.869, "latencies_ms": [699.869], "images_per_second": 1.429, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A city street is lined with tall buildings, cars, and trees, with traffic signs and streetlights visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 9.0}, "power_stats": {"power_watts_samples": [42.45, 37.28, 37.28, 37.28, 37.28, 37.28, 42.4], "power_watts_avg": 38.75, "power_watts_peak": 42.45, "energy_joules_est": 27.14, "sample_count": 7, "duration_seconds": 0.7}, "timestamp": "2026-01-11T13:53:04.693979"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1495.944, "latencies_ms": [1495.944], "images_per_second": 0.668, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "7AM-7PM: 2\nBicycle: 1\nTraffic light: 2\nStreet sign: 2\nBus: 1\nCars: 4\nTruck: 1\nTrees: 4\nBuildings: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.8, "ram_available_mb": 109426.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.4, 42.4, 42.4, 42.4, 54.63, 54.63, 54.63, 54.63, 54.63, 44.24, 44.24, 44.24, 44.24, 44.24, 34.35], "power_watts_avg": 46.55, "power_watts_peak": 54.63, "energy_joules_est": 69.66, "sample_count": 15, "duration_seconds": 1.496}, "timestamp": "2026-01-11T13:53:06.206039"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1123.706, "latencies_ms": [1123.706], "images_per_second": 0.89, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The foreground features a street with cars, trees, and street signs. The background showcases a city street with buildings, cars, and traffic lights. The perspective suggests a view from across the street, capturing both the foreground and the distant background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.35, 34.35, 34.35, 34.35, 43.95, 43.95, 43.95, 43.95, 43.95, 44.09, 44.09, 44.09], "power_watts_avg": 40.78, "power_watts_peak": 44.09, "energy_joules_est": 45.85, "sample_count": 12, "duration_seconds": 1.124}, "timestamp": "2026-01-11T13:53:07.419501"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 963.538, "latencies_ms": [963.538], "images_per_second": 1.038, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene depicts a city street on a foggy day, with cars driving down the road and buildings lining both sides. Traffic lights and street signs are visible, indicating a controlled urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.7, "ram_available_mb": 109426.6, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.09, 36.14, 36.14, 36.14, 36.14, 36.14, 42.78, 42.78, 42.78, 42.78], "power_watts_avg": 39.59, "power_watts_peak": 44.09, "energy_joules_est": 38.17, "sample_count": 10, "duration_seconds": 0.964}, "timestamp": "2026-01-11T13:53:08.432778"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1226.033, "latencies_ms": [1226.033], "images_per_second": 0.816, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene is dominated by muted colors due to the overcast sky and bare trees. The lighting is soft and diffused, typical of an overcast day. The buildings are constructed of concrete and glass, giving a modern and urban feel to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13079.9, "ram_available_mb": 109426.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.78, 43.81, 43.81, 43.81, 43.81, 43.81, 43.24, 43.24, 43.24, 43.24, 43.24, 42.26, 42.26], "power_watts_avg": 43.27, "power_watts_peak": 43.81, "energy_joules_est": 53.07, "sample_count": 13, "duration_seconds": 1.226}, "timestamp": "2026-01-11T13:53:09.744014"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 602.195, "latencies_ms": [602.195], "images_per_second": 1.661, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A stainless steel toilet with a visible hole in the bowl is situated in a tiled bathroom stall, accompanied by a blue toilet brush.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.3, "ram_available_mb": 109429.0, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [42.26, 42.26, 42.26, 37.15, 37.15, 37.15, 37.15], "power_watts_avg": 39.34, "power_watts_peak": 42.26, "energy_joules_est": 23.71, "sample_count": 7, "duration_seconds": 0.603}, "timestamp": "2026-01-11T13:53:10.450319"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1877.675, "latencies_ms": [1877.675], "images_per_second": 0.533, "prompt_tokens": 21, "response_tokens_est": 61, "n_tiles": 1, "output_text": "toilet: 1\ntoilet brush: 1\ntoilet cleaner: 1\ntoilet seat: 1\ntoilet bowl: 1\ntoilet lid: 1\ntoilet flushing mechanism: 1\ntoilet base: 1\ntoilet seat cover: 1\ntoilet seat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.15, 37.36, 37.36, 37.36, 37.36, 37.36, 36.91, 36.91, 36.91, 36.91, 36.91, 36.88, 36.88, 36.88, 36.88, 36.88, 34.22, 34.22, 34.22], "power_watts_avg": 36.61, "power_watts_peak": 37.36, "energy_joules_est": 68.76, "sample_count": 19, "duration_seconds": 1.878}, "timestamp": "2026-01-11T13:53:12.363685"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 766.89, "latencies_ms": [766.89], "images_per_second": 1.304, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, slightly to the right of the image. The toilet brush is situated near the toilet, closer to the viewer. The tiled floor extends from the toilet towards the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.2, "ram_available_mb": 109429.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.22, 36.3, 36.3, 36.3, 36.3, 36.3, 37.34, 37.34], "power_watts_avg": 36.3, "power_watts_peak": 37.34, "energy_joules_est": 27.86, "sample_count": 8, "duration_seconds": 0.768}, "timestamp": "2026-01-11T13:53:13.222159"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 871.071, "latencies_ms": [871.071], "images_per_second": 1.148, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a bathroom interior with a stainless steel toilet, tiled walls, and a metal frame. A toilet brush and a person's feet are visible, suggesting the bathroom is clean and ready for use.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13076.8, "ram_available_mb": 109429.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.9, "ram_available_mb": 109429.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.34, 37.34, 37.34, 39.08, 39.08, 39.08, 39.08, 39.08, 37.84], "power_watts_avg": 38.36, "power_watts_peak": 39.08, "energy_joules_est": 33.43, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-11T13:53:14.130475"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 687.526, "latencies_ms": [687.526], "images_per_second": 1.454, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The bathroom features a metallic toilet bowl and silver fixtures. The floor is tiled with beige tiles. The lighting is bright, likely from overhead fixtures.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13076.9, "ram_available_mb": 109429.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13076.9, "ram_available_mb": 109429.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.84, 37.84, 37.84, 37.84, 38.06, 38.06, 38.06], "power_watts_avg": 37.93, "power_watts_peak": 38.06, "energy_joules_est": 26.1, "sample_count": 7, "duration_seconds": 0.688}, "timestamp": "2026-01-11T13:53:14.841545"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 755.89, "latencies_ms": [755.89], "images_per_second": 1.323, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A pink bicycle with a flower garland on the handlebars is parked in a bike shop, surrounded by other bicycles of various colors and styles.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13076.9, "ram_available_mb": 109429.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.06, 38.06, 45.02, 45.02, 45.02, 45.02, 45.02, 43.95], "power_watts_avg": 43.15, "power_watts_peak": 45.02, "energy_joules_est": 32.64, "sample_count": 8, "duration_seconds": 0.756}, "timestamp": "2026-01-11T13:53:15.653678"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1602.742, "latencies_ms": [1602.742], "images_per_second": 0.624, "prompt_tokens": 21, "response_tokens_est": 54, "n_tiles": 1, "output_text": "bicycle: 5\nbicycle wheel: 4\nbicycle seat: 2\nbicycle handlebars: 2\nbicycle frame: 1\nbicycle seat: 1\nbicycle tire: 2\nbicycle wheel rim: 2\nbicycle pedals: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.1, "ram_available_mb": 109429.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 43.95, 47.32, 47.32, 47.32, 47.32, 47.32, 43.65, 43.65, 43.65, 43.65, 43.65, 34.33, 34.33], "power_watts_avg": 43.71, "power_watts_peak": 47.32, "energy_joules_est": 70.08, "sample_count": 16, "duration_seconds": 1.603}, "timestamp": "2026-01-11T13:53:17.269110"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1022.407, "latencies_ms": [1022.407], "images_per_second": 0.978, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main object, a pink bicycle, is positioned in the foreground of the image. The background features other bicycles and accessories, creating a sense of depth and space. The bicycle is situated close to the viewer, drawing attention to its color and design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.33, 34.33, 34.33, 44.8, 44.8, 44.8, 44.8, 44.8, 44.54, 44.54, 44.54], "power_watts_avg": 41.87, "power_watts_peak": 44.8, "energy_joules_est": 42.82, "sample_count": 11, "duration_seconds": 1.023}, "timestamp": "2026-01-11T13:53:18.381867"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1293.41, "latencies_ms": [1293.41], "images_per_second": 0.773, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene depicts a bike shop with a pink bicycle prominently featured in the foreground. Several other bicycles are lined up behind it, suggesting a selection of bikes for customers. The shop's interior features light-colored walls and a wooden floor, contributing to a clean and organized atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.54, 44.54, 38.16, 38.16, 38.16, 38.16, 38.16, 42.55, 42.55, 42.55, 42.55, 42.55, 38.46], "power_watts_avg": 40.85, "power_watts_peak": 44.54, "energy_joules_est": 52.86, "sample_count": 13, "duration_seconds": 1.294}, "timestamp": "2026-01-11T13:53:19.695814"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 857.68, "latencies_ms": [857.68], "images_per_second": 1.166, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The pink bicycle stands out against the light wood floor. The bicycle is adorned with a floral garland, adding a touch of color and festive flair to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.0, "ram_available_mb": 109429.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.46, 38.46, 38.46, 38.46, 44.43, 44.43, 44.43, 44.43, 44.43], "power_watts_avg": 41.78, "power_watts_peak": 44.43, "energy_joules_est": 35.85, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-11T13:53:20.607024"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 789.466, "latencies_ms": [789.466], "images_per_second": 1.267, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A majestic giraffe with a long neck and distinctive brown and tan spots stands tall in a dry savanna landscape, surrounded by sparse trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.24, 44.24, 44.24, 44.24, 44.24, 43.14, 43.14, 43.14], "power_watts_avg": 43.83, "power_watts_peak": 44.24, "energy_joules_est": 34.63, "sample_count": 8, "duration_seconds": 0.79}, "timestamp": "2026-01-11T13:53:21.418797"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 941.936, "latencies_ms": [941.936], "images_per_second": 1.062, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "giraffe: 1\ntrees: 2\nshrubs: 2\nsky: 1\nground: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.14, 46.47, 46.47, 46.47, 46.47, 46.47, 44.16, 44.16, 44.16, 44.16], "power_watts_avg": 45.21, "power_watts_peak": 46.47, "energy_joules_est": 42.61, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:53:22.428622"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 910.462, "latencies_ms": [910.462], "images_per_second": 1.098, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The giraffe is positioned to the right of the image, partially in the foreground. The background consists of trees, bushes, and a cloudy sky, suggesting the giraffe is in a natural, outdoor environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.16, 42.71, 42.71, 42.71, 42.71, 42.71, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 43.02, "power_watts_peak": 44.16, "energy_joules_est": 39.19, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-11T13:53:23.439391"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 806.335, "latencies_ms": [806.335], "images_per_second": 1.24, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A giraffe stands in a dry, grassy savanna, gazing towards the right side of the frame. The landscape is sparsely vegetated with scattered trees and bushes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.13, 42.24, 42.24, 42.24, 42.24, 42.24, 42.79, 42.79, 42.79], "power_watts_avg": 42.52, "power_watts_peak": 43.13, "energy_joules_est": 34.3, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-11T13:53:24.347521"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 941.394, "latencies_ms": [941.394], "images_per_second": 1.062, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The giraffe's coat is a distinctive pattern of brown and tan spots. The lighting in the image suggests an overcast sky, giving the scene a subdued and somewhat muted tone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.79, 42.79, 48.4, 48.4, 48.4, 48.4, 48.4, 42.31, 42.31, 42.31], "power_watts_avg": 45.45, "power_watts_peak": 48.4, "energy_joules_est": 42.81, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-11T13:53:25.356721"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 697.715, "latencies_ms": [697.715], "images_per_second": 1.433, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two young children are sitting atop luggage on a shopping cart, waiting in line at a busy budget car rental station.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.4, "ram_available_mb": 109428.9, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.6, "ram_available_mb": 109428.7, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.31, 42.31, 43.53, 43.53, 43.53, 43.53, 43.53], "power_watts_avg": 43.18, "power_watts_peak": 43.53, "energy_joules_est": 30.16, "sample_count": 7, "duration_seconds": 0.698}, "timestamp": "2026-01-11T13:53:26.066613"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 976.536, "latencies_ms": [976.536], "images_per_second": 1.024, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "car: 4\nsuitcase: 2\nluggage cart: 2\nchild: 2\nwoman: 1\nsign: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.6, "ram_available_mb": 109428.7, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.02, 43.02, 43.02, 43.02, 43.02, 48.38, 48.38, 48.38, 48.38, 48.38], "power_watts_avg": 45.7, "power_watts_peak": 48.38, "energy_joules_est": 44.64, "sample_count": 10, "duration_seconds": 0.977}, "timestamp": "2026-01-11T13:53:27.076306"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1271.165, "latencies_ms": [1271.165], "images_per_second": 0.787, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The foreground features two children sitting on luggage carts.  The background includes various cars parked in a lot, suggesting the location is near a parking area or roadside.  The cars are positioned at varying distances from the children, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.17, 44.17, 44.17, 44.17, 44.17, 43.79, 43.79, 43.79, 43.79, 43.79, 43.63, 43.63, 43.63], "power_watts_avg": 43.9, "power_watts_peak": 44.17, "energy_joules_est": 55.82, "sample_count": 13, "duration_seconds": 1.271}, "timestamp": "2026-01-11T13:53:28.387629"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1041.515, "latencies_ms": [1041.515], "images_per_second": 0.96, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Two young children are traveling in a luggage cart amidst a busy parking lot filled with various cars. The scene suggests a travel-related event or activity, possibly a family outing or a trip to a nearby destination.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.63, 43.63, 38.42, 38.42, 38.42, 38.42, 38.42, 43.25, 43.25, 43.25, 43.25], "power_watts_avg": 41.12, "power_watts_peak": 43.63, "energy_joules_est": 42.84, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-11T13:53:29.496666"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 961.825, "latencies_ms": [961.825], "images_per_second": 1.04, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The children appear to be wearing light-colored clothing. The scene is well-lit, suggesting sunny weather. The luggage is primarily dark gray or black. The overall atmosphere is bright and cheerful.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13077.5, "ram_available_mb": 109428.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.25, 38.56, 38.56, 38.56, 38.56, 38.56, 42.84, 42.84, 42.84, 42.84], "power_watts_avg": 40.74, "power_watts_peak": 43.25, "energy_joules_est": 39.2, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-11T13:53:30.505953"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 592.258, "latencies_ms": [592.258], "images_per_second": 1.688, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A blue and yellow bus travels down a road in a small town, passing a flower bed and passing a white van.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.84, 43.4, 43.4, 43.4, 43.4, 43.4], "power_watts_avg": 43.31, "power_watts_peak": 43.4, "energy_joules_est": 25.67, "sample_count": 6, "duration_seconds": 0.593}, "timestamp": "2026-01-11T13:53:31.113905"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1032.545, "latencies_ms": [1032.545], "images_per_second": 0.968, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bus: 1\nvan: 1\nstreet light: 2\nbuildings: 3\ntrees: 4\nhill: 5\ngrass: 6\nflowers: 7", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.89, 37.89, 37.89, 37.89, 37.89, 43.56, 43.56, 43.56, 43.56, 38.74, 38.74], "power_watts_avg": 40.11, "power_watts_peak": 43.56, "energy_joules_est": 41.43, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-11T13:53:32.224055"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 935.232, "latencies_ms": [935.232], "images_per_second": 1.069, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving towards the left side of the image. The street and buildings are in the background, creating a sense of depth and perspective. The bus is relatively close to the viewer, while the buildings and the street are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.74, 38.74, 38.74, 37.24, 37.24, 37.24, 37.24, 37.24, 37.2, 37.2], "power_watts_avg": 37.69, "power_watts_peak": 38.74, "energy_joules_est": 35.27, "sample_count": 10, "duration_seconds": 0.936}, "timestamp": "2026-01-11T13:53:33.236805"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1108.912, "latencies_ms": [1108.912], "images_per_second": 0.902, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The scene depicts a bus stop in a small town or village, with a yellow and blue bus parked on the side of the road. Several people are walking near the bus stop, and buildings with traditional architecture line the street. The setting is surrounded by hills and trees, creating a picturesque and peaceful atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.2, 37.2, 37.2, 37.44, 37.44, 37.44, 37.44, 37.44, 37.7, 37.7, 37.7, 37.7], "power_watts_avg": 37.47, "power_watts_peak": 37.7, "energy_joules_est": 41.57, "sample_count": 12, "duration_seconds": 1.109}, "timestamp": "2026-01-11T13:53:34.449546"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 689.992, "latencies_ms": [689.992], "images_per_second": 1.449, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bus is predominantly yellow and blue. The lighting is bright, likely from streetlights. The bus appears to be made of sturdy materials. The weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.7, 34.4, 34.4, 34.4, 34.4, 34.4, 37.16], "power_watts_avg": 35.27, "power_watts_peak": 37.7, "energy_joules_est": 24.35, "sample_count": 7, "duration_seconds": 0.691}, "timestamp": "2026-01-11T13:53:35.157936"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 662.46, "latencies_ms": [662.46], "images_per_second": 1.51, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A large brown bird, possibly a pelican, perches on a rocky outcropping overlooking the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [37.16, 37.16, 37.16, 37.16, 46.98, 46.98, 46.98], "power_watts_avg": 41.37, "power_watts_peak": 46.98, "energy_joules_est": 27.43, "sample_count": 7, "duration_seconds": 0.663}, "timestamp": "2026-01-11T13:53:35.868113"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1257.063, "latencies_ms": [1257.063], "images_per_second": 0.796, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "pelican: 1\nbeach: 1\nrocks: 1\nocean: 1\nhills: 1\nsky: 1\nclouds: 2\ntropical vegetation: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.98, 46.98, 49.73, 49.73, 49.73, 49.73, 49.73, 43.49, 43.49, 43.49, 43.49, 43.49, 37.73], "power_watts_avg": 45.98, "power_watts_peak": 49.73, "energy_joules_est": 57.83, "sample_count": 13, "duration_seconds": 1.258}, "timestamp": "2026-01-11T13:53:37.178887"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 822.614, "latencies_ms": [822.614], "images_per_second": 1.216, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The bird is positioned in the foreground, close to the rocky outcrop and beach. The beach extends in the background, separating the foreground from the distant hills and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [37.73, 37.73, 37.73, 37.73, 43.15, 43.15, 43.15, 43.15, 43.15], "power_watts_avg": 40.74, "power_watts_peak": 43.15, "energy_joules_est": 33.52, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-11T13:53:38.087250"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1335.783, "latencies_ms": [1335.783], "images_per_second": 0.749, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a coastal area with a rocky shore, a sandy beach, and calm ocean waters. A pelican is perched on a rock, gazing out at the water, while several beach umbrellas provide shade for beachgoers. The sky is partly cloudy, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [43.13, 43.13, 43.13, 43.13, 43.13, 42.16, 42.16, 42.16, 42.16, 42.16, 42.53, 42.53, 42.53, 42.53], "power_watts_avg": 42.62, "power_watts_peak": 43.13, "energy_joules_est": 56.94, "sample_count": 14, "duration_seconds": 1.336}, "timestamp": "2026-01-11T13:53:39.498822"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1007.633, "latencies_ms": [1007.633], "images_per_second": 0.992, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The sky is a mix of blue and white clouds. The water is a calm, light blue. The scene is illuminated by soft, diffused light, suggesting either early morning or late afternoon light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.53, 32.53, 32.53, 32.53, 32.53, 32.53, 42.25, 42.25, 42.25, 42.25, 42.25], "power_watts_avg": 37.86, "power_watts_peak": 42.53, "energy_joules_est": 38.17, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-11T13:53:40.607418"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 736.933, "latencies_ms": [736.933], "images_per_second": 1.357, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young man wearing glasses sits in a blue armchair, holding a toothbrush in his right hand and a brown paper bag in his left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.22, 43.22, 43.22, 43.22, 43.22, 42.32, 42.32, 42.32], "power_watts_avg": 42.89, "power_watts_peak": 43.22, "energy_joules_est": 31.63, "sample_count": 8, "duration_seconds": 0.738}, "timestamp": "2026-01-11T13:53:41.414632"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1070.203, "latencies_ms": [1070.203], "images_per_second": 0.934, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bag: 1\ntoothbrush: 1\nglasses: 1\nchair: 1\nman: 1\npaper: 1\nremotes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.32, 42.32, 46.27, 46.27, 46.27, 46.27, 46.27, 43.01, 43.01, 43.01, 43.01], "power_watts_avg": 44.37, "power_watts_peak": 46.27, "energy_joules_est": 47.49, "sample_count": 11, "duration_seconds": 1.07}, "timestamp": "2026-01-11T13:53:42.523934"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1065.171, "latencies_ms": [1065.171], "images_per_second": 0.939, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is sitting in a chair, holding the toothbrush in his right hand and reading a newspaper in his left hand. The newspaper is positioned in the foreground, while the toothbrush and newspaper are situated further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.91, 39.91, 39.91, 39.91, 39.91, 43.91, 43.91, 43.91, 43.91, 43.91, 44.46], "power_watts_avg": 42.14, "power_watts_peak": 44.46, "energy_joules_est": 44.9, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-11T13:53:43.630568"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1013.787, "latencies_ms": [1013.787], "images_per_second": 0.986, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A man is sitting in a blue armchair, holding a toothbrush in his right hand and a brown paper bag in his left. He is wearing glasses and a plaid shirt. Nearby, there are two remote controls on a surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.46, 44.46, 44.46, 44.46, 43.56, 43.56, 43.56, 43.56, 43.56, 43.32, 43.32], "power_watts_avg": 43.85, "power_watts_peak": 44.46, "energy_joules_est": 44.46, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-11T13:53:44.740333"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1503.934, "latencies_ms": [1503.934], "images_per_second": 0.665, "prompt_tokens": 18, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The room is dimly lit, creating a warm ambiance. The walls appear to be a light color, possibly white or off-white. The chair is upholstered in a textured fabric, likely velvet or corduroy. The man is holding a toothbrush and a brown paper bag, suggesting he might be preparing to eat or have just finished a meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.32, 43.32, 43.32, 42.4, 42.4, 42.4, 42.4, 42.4, 42.42, 42.42, 42.42, 42.42, 42.42, 33.85, 33.85], "power_watts_avg": 41.45, "power_watts_peak": 43.32, "energy_joules_est": 62.35, "sample_count": 15, "duration_seconds": 1.504}, "timestamp": "2026-01-11T13:53:46.249567"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 813.58, "latencies_ms": [813.58], "images_per_second": 1.229, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A tennis player in an orange shirt and black shorts is poised to strike a tennis ball with a blue racket on a green court.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [33.85, 33.85, 33.85, 43.56, 43.56, 43.56, 43.56, 43.56, 43.54], "power_watts_avg": 40.32, "power_watts_peak": 43.56, "energy_joules_est": 32.83, "sample_count": 9, "duration_seconds": 0.814}, "timestamp": "2026-01-11T13:53:47.161257"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1157.054, "latencies_ms": [1157.054], "images_per_second": 0.864, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis net: 1\nTennis shoes: 2\nTennis court: 4\nTennis player: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [43.54, 43.54, 43.54, 43.54, 42.28, 42.28, 42.28, 42.28, 42.28, 42.52, 42.52, 42.52], "power_watts_avg": 42.76, "power_watts_peak": 43.54, "energy_joules_est": 49.49, "sample_count": 12, "duration_seconds": 1.157}, "timestamp": "2026-01-11T13:53:48.371193"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 981.83, "latencies_ms": [981.83], "images_per_second": 1.019, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The tennis player is positioned near the net, preparing to hit the ball. The tennis ball is visible in the air, near the player's racket. The player's stance suggests they are actively engaged in the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.52, 42.52, 40.48, 40.48, 40.48, 40.48, 40.48, 43.17, 43.17, 43.17], "power_watts_avg": 41.69, "power_watts_peak": 43.17, "energy_joules_est": 40.95, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-11T13:53:49.380696"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 948.87, "latencies_ms": [948.87], "images_per_second": 1.054, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A tennis player is preparing to serve a tennis ball on a green court, wearing an orange shirt and cap. The player is focused on the incoming ball and is holding the tennis racket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 44.28, 44.28, 44.28, 44.28, 44.28, 44.24, 44.24, 44.24], "power_watts_avg": 44.04, "power_watts_peak": 44.28, "energy_joules_est": 41.81, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-11T13:53:50.393161"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 825.572, "latencies_ms": [825.572], "images_per_second": 1.211, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The tennis player is wearing an orange shirt and orange and white shoes. The green tennis court is well-lit, and the player appears to be focused on the incoming ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.24, 44.24, 42.62, 42.62, 42.62, 42.62, 42.62, 43.24, 43.24], "power_watts_avg": 43.12, "power_watts_peak": 44.24, "energy_joules_est": 35.61, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-11T13:53:51.305006"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 728.674, "latencies_ms": [728.674], "images_per_second": 1.372, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The kitchen is well-lit and features yellow walls, wooden cabinets, a sink, a stove, and a fire extinguisher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 43.24, 48.12, 48.12, 48.12, 48.12, 48.12], "power_watts_avg": 46.29, "power_watts_peak": 48.12, "energy_joules_est": 33.75, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-11T13:53:52.117795"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1212.504, "latencies_ms": [1212.504], "images_per_second": 0.825, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "fire extinguisher: 1\nsink: 1\noven: 1\ncountertop: 1\ncupboard: 2\nrug: 1\ntable: 1\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.0, 44.0, 44.0, 44.0, 44.0, 45.49, 45.49, 45.49, 45.49, 44.39, 44.39, 44.39, 44.39], "power_watts_avg": 44.58, "power_watts_peak": 45.49, "energy_joules_est": 54.07, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-11T13:53:53.430831"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 884.167, "latencies_ms": [884.167], "images_per_second": 1.131, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal arrangement, with the kitchen area on the left and the dining area on the right. The foreground is dominated by the kitchen counter, while the dining area is further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.39, 36.12, 36.12, 36.12, 36.12, 36.12, 44.07, 44.07, 44.07], "power_watts_avg": 39.69, "power_watts_peak": 44.39, "energy_joules_est": 35.11, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-11T13:53:54.342097"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1234.429, "latencies_ms": [1234.429], "images_per_second": 0.81, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene depicts a compact, well-lit kitchen or galley area, likely within a ship or vessel. The yellow walls and wooden cabinetry contribute to a warm and inviting atmosphere. Various appliances and utensils are visible, hinting at the functionality of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.07, 44.07, 50.97, 50.97, 50.97, 50.97, 50.97, 45.09, 45.09, 45.09, 45.09, 45.09, 37.03], "power_watts_avg": 46.57, "power_watts_peak": 50.97, "energy_joules_est": 57.52, "sample_count": 13, "duration_seconds": 1.235}, "timestamp": "2026-01-11T13:53:55.657168"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1135.594, "latencies_ms": [1135.594], "images_per_second": 0.881, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The kitchen is painted in a pale yellow color with dark brown trim, giving it a warm and inviting feel. The lighting is bright and artificial, illuminating the space effectively. The kitchen appears well-equipped with modern appliances and storage solutions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.03, 37.03, 37.03, 37.03, 43.94, 43.94, 43.94, 43.94, 43.94, 44.09, 44.09, 44.09], "power_watts_avg": 41.68, "power_watts_peak": 44.09, "energy_joules_est": 47.35, "sample_count": 12, "duration_seconds": 1.136}, "timestamp": "2026-01-11T13:53:56.871382"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 849.079, "latencies_ms": [849.079], "images_per_second": 1.178, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A large sandwich, filled with layers of meat, cheese, lettuce, tomato, and pickles, sits on a white paper plate on a wooden table, accompanied by a computer keyboard and a telephone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 109428.4, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13077.8, "ram_available_mb": 109428.5, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [44.09, 44.09, 39.59, 39.59, 39.59, 39.59, 39.59, 43.06, 43.06], "power_watts_avg": 41.36, "power_watts_peak": 44.09, "energy_joules_est": 35.14, "sample_count": 9, "duration_seconds": 0.85}, "timestamp": "2026-01-11T13:53:57.784130"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1200.126, "latencies_ms": [1200.126], "images_per_second": 0.833, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "sandwich: 2\npickles: 2\ntomato: 1\nlettuce: 2\ncheese: 1\nham: 1\nbread: 2\npepper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.8, "ram_available_mb": 109428.5, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.06, 43.06, 43.06, 46.58, 46.58, 46.58, 46.58, 46.58, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 44.55, "power_watts_peak": 46.58, "energy_joules_est": 53.49, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-11T13:53:58.996494"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1064.029, "latencies_ms": [1064.029], "images_per_second": 0.94, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main object is a large sandwich placed on a paper plate. The paper plate is positioned in the foreground, slightly to the right of the sandwich. The sandwich and plate are situated on a desk, with a computer keyboard and monitor in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.13, 34.8, 34.8, 34.8, 34.8, 34.8, 43.33, 43.33, 43.33, 43.33, 43.33], "power_watts_avg": 39.44, "power_watts_peak": 43.33, "energy_joules_est": 41.99, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-11T13:54:00.105645"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 859.14, "latencies_ms": [859.14], "images_per_second": 1.164, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A large sandwich, filled with layers of meat, cheese, lettuce, tomato, and pickles, is presented on a white plate on a desk next to a computer keyboard and a telephone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.22, 43.22, 43.22, 43.22, 43.22, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 43.25, "power_watts_peak": 43.28, "energy_joules_est": 37.17, "sample_count": 9, "duration_seconds": 0.859}, "timestamp": "2026-01-11T13:54:01.017061"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1290.93, "latencies_ms": [1290.93], "images_per_second": 0.775, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The sandwich is filled with vibrant colors, including red tomato slices, green lettuce, and yellow cheese. The sandwich appears freshly made and sits on a white paper plate. The lighting in the image is soft and diffused, creating a pleasant ambiance. The sandwich is cut in half, revealing layers of ingredients.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.28, 42.36, 42.36, 42.36, 42.36, 42.36, 43.49, 43.49, 43.49, 43.49, 44.72, 44.72, 44.72], "power_watts_avg": 43.32, "power_watts_peak": 44.72, "energy_joules_est": 55.95, "sample_count": 13, "duration_seconds": 1.291}, "timestamp": "2026-01-11T13:54:02.330640"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 717.652, "latencies_ms": [717.652], "images_per_second": 1.393, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The desk is equipped with two computer monitors, a keyboard, a mouse, a tablet, and various electronic devices, creating a well-equipped workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.72, 44.72, 42.68, 42.68, 42.68, 42.68, 42.68, 43.97], "power_watts_avg": 43.35, "power_watts_peak": 44.72, "energy_joules_est": 31.13, "sample_count": 8, "duration_seconds": 0.718}, "timestamp": "2026-01-11T13:54:03.142541"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1212.926, "latencies_ms": [1212.926], "images_per_second": 0.824, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "keyboard: 2\nmouse: 1\nmousepad: 1\ntablet: 1\nmonitor: 2\ncables: 4\nphones: 2\ncamera: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.97, 43.97, 43.97, 43.97, 45.26, 45.26, 45.26, 45.26, 45.26, 42.96, 42.96, 42.96, 42.96], "power_watts_avg": 44.15, "power_watts_peak": 45.26, "energy_joules_est": 53.58, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-11T13:54:04.455920"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 894.15, "latencies_ms": [894.15], "images_per_second": 1.118, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The left monitor is closer, while the right monitor is further away, emphasizing the spatial relationship between the devices.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.96, 35.02, 35.02, 35.02, 35.02, 35.02, 42.56, 42.56, 42.56], "power_watts_avg": 38.41, "power_watts_peak": 42.96, "energy_joules_est": 34.37, "sample_count": 9, "duration_seconds": 0.895}, "timestamp": "2026-01-11T13:54:05.364446"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1046.979, "latencies_ms": [1046.979], "images_per_second": 0.955, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a workspace with two computer monitors, a keyboard, a mouse, and various electronic devices arranged on a desk. The monitors display different content, suggesting active use for tasks like video editing or multitasking.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [42.56, 42.56, 50.02, 50.02, 50.02, 50.02, 50.02, 44.3, 44.3, 44.3, 44.3], "power_watts_avg": 46.59, "power_watts_peak": 50.02, "energy_joules_est": 48.79, "sample_count": 11, "duration_seconds": 1.047}, "timestamp": "2026-01-11T13:54:06.473530"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 898.456, "latencies_ms": [898.456], "images_per_second": 1.113, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The desk is primarily gray, reflecting the ambient lighting. The monitors display a mix of colors, including shades of blue, white, and red. The overall setup appears organized and functional.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.1, "ram_available_mb": 109428.2, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [44.3, 37.48, 37.48, 37.48, 37.48, 37.48, 43.24, 43.24, 43.24], "power_watts_avg": 40.16, "power_watts_peak": 44.3, "energy_joules_est": 36.1, "sample_count": 9, "duration_seconds": 0.899}, "timestamp": "2026-01-11T13:54:07.382492"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 754.254, "latencies_ms": [754.254], "images_per_second": 1.326, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The bathroom features a white toilet with a blue lid and seat, situated next to a large photograph of a family on a tiled floor.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 49.93, 49.93, 49.93, 49.93, 49.93, 45.37], "power_watts_avg": 47.69, "power_watts_peak": 49.93, "energy_joules_est": 36.0, "sample_count": 8, "duration_seconds": 0.755}, "timestamp": "2026-01-11T13:54:08.193692"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1137.837, "latencies_ms": [1137.837], "images_per_second": 0.879, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "toilet: 1\nfloor: 10\nwall: 1\ndoor: 1\nperson: 8\nchild: 2\nman: 2\nwoman: 4", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.37, 45.37, 45.37, 45.37, 50.65, 50.65, 50.65, 50.65, 50.65, 44.95, 44.95, 44.95], "power_watts_avg": 47.47, "power_watts_peak": 50.65, "energy_joules_est": 54.05, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-11T13:54:09.406351"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 766.095, "latencies_ms": [766.095], "images_per_second": 1.305, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The large group of people is positioned in the foreground, closer to the viewer. The toilet is situated in the background, further away and slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 109428.3, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.2, "ram_available_mb": 109428.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.95, 44.95, 38.11, 38.11, 38.11, 38.11, 38.11, 44.53], "power_watts_avg": 40.63, "power_watts_peak": 44.95, "energy_joules_est": 31.15, "sample_count": 8, "duration_seconds": 0.767}, "timestamp": "2026-01-11T13:54:10.219524"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 776.893, "latencies_ms": [776.893], "images_per_second": 1.287, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The scene depicts a public restroom with a large, colorful mural depicting a family. The mural is situated on the floor, covering most of the visible tiles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.2, "ram_available_mb": 109428.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.2, "ram_available_mb": 109428.1, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.53, 44.53, 44.53, 44.53, 51.56, 51.56, 51.56, 51.56], "power_watts_avg": 48.05, "power_watts_peak": 51.56, "energy_joules_est": 37.35, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-11T13:54:11.030265"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 956.739, "latencies_ms": [956.739], "images_per_second": 1.045, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The floor is tiled with light-colored tiles. The lighting in the image appears to be natural, possibly from overhead fixtures. The materials appear to be standard bathroom tiles. The weather is not explicitly visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.2, "ram_available_mb": 109428.1, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4233.6, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.53, 44.53, 44.53, 44.53, 44.53, 45.05, 45.05, 45.05, 45.05, 45.05], "power_watts_avg": 44.79, "power_watts_peak": 45.05, "energy_joules_est": 42.88, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-11T13:54:12.042088"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 612.953, "latencies_ms": [612.953], "images_per_second": 1.631, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A gray bird with a pointed beak perches on a thin branch, gazing upwards and to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [45.03, 45.03, 45.03, 45.03, 45.03, 43.44, 43.44], "power_watts_avg": 44.57, "power_watts_peak": 45.03, "energy_joules_est": 27.35, "sample_count": 7, "duration_seconds": 0.614}, "timestamp": "2026-01-11T13:54:12.753587"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1034.522, "latencies_ms": [1034.522], "images_per_second": 0.967, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "bird: 1\nbranch: 2\ntree: 2\nleaves: 2\nfeathers: 2\neye: 1\nbeak: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.44, 43.44, 43.44, 52.88, 52.88, 52.88, 52.88, 52.88, 42.61, 42.61, 42.61], "power_watts_avg": 47.5, "power_watts_peak": 52.88, "energy_joules_est": 49.17, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-11T13:54:13.865929"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 878.964, "latencies_ms": [878.964], "images_per_second": 1.138, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main object, a bird, occupies the foreground, perched on a branch. The background is blurred, drawing focus to the bird. The bird is positioned near the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 40.01, 40.01, 40.01, 40.01, 40.01, 43.05, 43.05], "power_watts_avg": 41.26, "power_watts_peak": 43.05, "energy_joules_est": 36.28, "sample_count": 9, "duration_seconds": 0.879}, "timestamp": "2026-01-11T13:54:14.777338"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 729.693, "latencies_ms": [729.693], "images_per_second": 1.37, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A gray bird perches on a branch in a natural setting with blurred green foliage in the background. The bird appears to be observing its surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 46.87, 46.87, 46.87, 46.87, 46.87], "power_watts_avg": 45.44, "power_watts_peak": 46.87, "energy_joules_est": 33.18, "sample_count": 8, "duration_seconds": 0.73}, "timestamp": "2026-01-11T13:54:15.587667"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 964.89, "latencies_ms": [964.89], "images_per_second": 1.036, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The bird is gray and appears to be perched on a branch. The lighting suggests an outdoor setting with natural light filtering through the leaves. The materials appear to be natural wood and possibly some bark or twigs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13078.5, "ram_available_mb": 109427.8, "ram_percent": 10.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4217.5, "gpu_max_mem_reserved_mb": 4538.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.43, 43.43, 43.43, 43.43, 43.43, 42.98, 42.98, 42.98, 42.98, 42.98], "power_watts_avg": 43.2, "power_watts_peak": 43.43, "energy_joules_est": 41.71, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-11T13:54:16.599500"}
