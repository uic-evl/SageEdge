{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1242.324, "latencies_ms": [1242.324], "images_per_second": 0.805, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there is a woman standing in a kitchen, with a dining table and chairs in front of her, and a television on the wall.", "error": null, "sys_before": {"cpu_percent": 3.0, "ram_used_mb": 15387.3, "ram_available_mb": 107119.0, "ram_percent": 12.6}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15377.6, "ram_available_mb": 107128.7, "ram_percent": 12.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 4956.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 4956.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.79, 43.79, 30.9, 30.9, 30.9, 30.9, 30.9, 43.34, 43.34, 43.34, 43.34, 43.34, 43.21], "power_watts_avg": 38.61, "power_watts_peak": 43.79, "energy_joules_est": 47.99, "sample_count": 13, "duration_seconds": 1.243}, "timestamp": "2026-01-12T09:30:12.625673"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3715.948, "latencies_ms": [3715.948], "images_per_second": 0.269, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " television: 1, dining table: 1, chairs: 4, vase: 1, flowers: 1, television stand: 1, window: 1, wall: 1, floor: 1, rug: 1, fireplace: 1, ceiling: 1, light: 1, wall art: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1,", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15377.6, "ram_available_mb": 107128.7, "ram_percent": 12.6}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 15337.4, "ram_available_mb": 107168.9, "ram_percent": 12.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 4956.0, "gpu_max_mem_alloc_mb": 4628.0, "gpu_max_mem_reserved_mb": 4956.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.21, 43.21, 43.21, 43.21, 37.47, 37.47, 37.47, 37.47, 37.47, 42.27, 42.27, 42.27, 42.27, 42.27, 35.19, 35.19, 35.19, 35.19, 35.19, 30.69, 30.69, 30.69, 30.69, 30.69, 30.66, 30.66, 30.66, 30.66, 30.66, 30.62, 30.62, 30.62, 30.62, 30.62, 30.78, 30.78, 30.78], "power_watts_avg": 35.13, "power_watts_peak": 43.21, "energy_joules_est": 130.54, "sample_count": 37, "duration_seconds": 3.716}, "timestamp": "2026-01-12T09:30:16.348321"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1909.241, "latencies_ms": [1909.241], "images_per_second": 0.524, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The dining table is located in the center of the room, with the woman standing near it. The television is on the left side of the room, while the fireplace is on the right side. The woman is standing near the dining table, which is in the center of the room.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15337.4, "ram_available_mb": 107168.9, "ram_percent": 12.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15374.9, "ram_available_mb": 107131.4, "ram_percent": 12.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 4956.0, "gpu_max_mem_alloc_mb": 4628.4, "gpu_max_mem_reserved_mb": 4956.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [30.78, 28.93, 28.93, 28.93, 28.93, 28.93, 42.46, 42.46, 42.46, 42.46, 42.46, 44.66, 44.66, 44.66, 44.66, 44.66, 30.86, 30.86, 30.86], "power_watts_avg": 37.03, "power_watts_peak": 44.66, "energy_joules_est": 70.73, "sample_count": 19, "duration_seconds": 1.91}, "timestamp": "2026-01-12T09:30:18.316759"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1017.581, "latencies_ms": [1017.581], "images_per_second": 0.983, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman is standing in a living room with a dining table and chairs, a fireplace, and a television.", "error": null, "sys_before": {"cpu_percent": 1.0, "ram_used_mb": 15374.8, "ram_available_mb": 107131.5, "ram_percent": 12.6}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15390.1, "ram_available_mb": 107116.2, "ram_percent": 12.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 4956.0, "gpu_max_mem_alloc_mb": 4627.8, "gpu_max_mem_reserved_mb": 4956.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [30.86, 28.06, 28.06, 28.06, 28.06, 28.06, 42.08, 42.08, 42.08, 42.08, 42.08], "power_watts_avg": 34.69, "power_watts_peak": 42.08, "energy_joules_est": 35.31, "sample_count": 11, "duration_seconds": 1.018}, "timestamp": "2026-01-12T09:30:19.475038"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1450.04, "latencies_ms": [1450.04], "images_per_second": 0.69, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with hardwood floors and a large window letting in natural light. The walls are painted a bright yellow, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15390.1, "ram_available_mb": 107116.2, "ram_percent": 12.6}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15366.7, "ram_available_mb": 107139.6, "ram_percent": 12.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 4956.0, "gpu_max_mem_alloc_mb": 4626.6, "gpu_max_mem_reserved_mb": 4956.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.74, 43.74, 43.74, 43.74, 43.74, 41.65, 41.65, 41.65, 41.65, 41.65, 42.74, 42.74, 42.74, 42.74, 42.74], "power_watts_avg": 42.71, "power_watts_peak": 43.74, "energy_joules_est": 61.94, "sample_count": 15, "duration_seconds": 1.45}, "timestamp": "2026-01-12T09:30:20.987782"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1252.69, "latencies_ms": [1252.69], "images_per_second": 0.798, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a large brown bear with a thick coat of fur, standing on a grassy field and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 15369.8, "ram_available_mb": 107136.5, "ram_percent": 12.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15638.5, "ram_available_mb": 106867.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4724.6, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [29.84, 29.84, 29.84, 29.84, 29.84, 41.57, 41.57, 41.57, 41.57, 41.57, 46.62, 46.62, 46.62], "power_watts_avg": 38.22, "power_watts_peak": 46.62, "energy_joules_est": 47.89, "sample_count": 13, "duration_seconds": 1.253}, "timestamp": "2026-01-12T09:30:22.302476"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2091.814, "latencies_ms": [2091.814], "images_per_second": 0.478, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 1\n2. grass: 1\n3. fur: 1\n4. nose: 1\n5. eyes: 1\n6. mouth: 1\n7. ears: 1\n8. fur texture: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15638.5, "ram_available_mb": 106867.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.2, "ram_used_mb": 15667.7, "ram_available_mb": 106838.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.62, 46.62, 33.81, 33.81, 33.81, 33.81, 33.81, 46.31, 46.31, 46.31, 46.31, 46.31, 48.29, 48.29, 48.29, 48.29, 48.29, 30.56, 30.56, 30.56, 30.56], "power_watts_avg": 40.83, "power_watts_peak": 48.29, "energy_joules_est": 85.43, "sample_count": 21, "duration_seconds": 2.092}, "timestamp": "2026-01-12T09:30:24.420095"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1367.643, "latencies_ms": [1367.643], "images_per_second": 0.731, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bear is in the foreground, with the grass in the background. The bear is facing the camera, with its head turned slightly to the right.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15667.5, "ram_available_mb": 106838.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15632.5, "ram_available_mb": 106873.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [29.78, 29.78, 29.78, 29.78, 29.78, 42.55, 42.55, 42.55, 42.55, 42.55, 47.19, 47.19, 47.19, 47.19], "power_watts_avg": 39.32, "power_watts_peak": 47.19, "energy_joules_est": 53.79, "sample_count": 14, "duration_seconds": 1.368}, "timestamp": "2026-01-12T09:30:25.887082"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1109.952, "latencies_ms": [1109.952], "images_per_second": 0.901, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " In the image, a large brown bear is sitting on a grassy field, looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15632.5, "ram_available_mb": 106873.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 15666.7, "ram_available_mb": 106839.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.19, 33.38, 33.38, 33.38, 33.38, 33.38, 46.84, 46.84, 46.84, 46.84, 46.84, 48.99], "power_watts_avg": 41.44, "power_watts_peak": 48.99, "energy_joules_est": 46.01, "sample_count": 12, "duration_seconds": 1.11}, "timestamp": "2026-01-12T09:30:27.097767"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 892.848, "latencies_ms": [892.848], "images_per_second": 1.12, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The bear has a brown fur, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15666.7, "ram_available_mb": 106839.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15648.3, "ram_available_mb": 106858.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.99, 48.99, 48.99, 48.99, 37.38, 37.38, 37.38, 37.38, 37.38], "power_watts_avg": 42.54, "power_watts_peak": 48.99, "energy_joules_est": 37.99, "sample_count": 9, "duration_seconds": 0.893}, "timestamp": "2026-01-12T09:30:28.008410"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1777.526, "latencies_ms": [1777.526], "images_per_second": 0.563, "prompt_tokens": 1432, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a blue comforter on the bed, a wooden dresser with a mirror, a bookshelf filled with books, and a window that offers a view of a lush green tree outside.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 15648.4, "ram_available_mb": 106857.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15636.9, "ram_available_mb": 106869.4, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.81, 45.81, 45.81, 45.81, 45.81, 50.52, 50.52, 50.52, 50.52, 50.52, 47.28, 47.28, 47.28, 47.28, 47.28, 37.0, 37.0, 37.0], "power_watts_avg": 46.06, "power_watts_peak": 50.52, "energy_joules_est": 81.9, "sample_count": 18, "duration_seconds": 1.778}, "timestamp": "2026-01-12T09:30:29.826799"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2234.016, "latencies_ms": [2234.016], "images_per_second": 0.448, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. bed: 1\n2. dresser: 1\n3. mirror: 1\n4. bookshelf: 1\n5. books: 100\n6. potted plant: 4\n7. window: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15636.6, "ram_available_mb": 106869.7, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15622.8, "ram_available_mb": 106883.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.0, 37.0, 29.02, 29.02, 29.02, 29.02, 29.02, 46.97, 46.97, 46.97, 46.97, 46.97, 49.11, 49.11, 49.11, 49.11, 49.11, 30.56, 30.56, 30.56, 30.56, 30.56, 30.82], "power_watts_avg": 38.4, "power_watts_peak": 49.11, "energy_joules_est": 85.8, "sample_count": 23, "duration_seconds": 2.235}, "timestamp": "2026-01-12T09:30:32.143830"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1584.417, "latencies_ms": [1584.417], "images_per_second": 0.631, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the window on the right side. The bookshelf is positioned in the background, while the dresser is situated near the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15622.8, "ram_available_mb": 106883.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15615.7, "ram_available_mb": 106890.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [30.82, 30.82, 30.82, 30.82, 35.62, 35.62, 35.62, 35.62, 35.62, 46.55, 46.55, 46.55, 46.55, 46.55, 42.16, 42.16], "power_watts_avg": 38.65, "power_watts_peak": 46.55, "energy_joules_est": 61.25, "sample_count": 16, "duration_seconds": 1.585}, "timestamp": "2026-01-12T09:30:33.755569"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1118.436, "latencies_ms": [1118.436], "images_per_second": 0.894, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A bedroom with a blue comforter, a window, a bookshelf, and a dresser.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15615.5, "ram_available_mb": 106890.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15612.8, "ram_available_mb": 106893.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [42.16, 42.16, 42.16, 32.21, 32.21, 32.21, 32.21, 32.21, 47.56, 47.56, 47.56, 47.56], "power_watts_avg": 39.81, "power_watts_peak": 47.56, "energy_joules_est": 44.54, "sample_count": 12, "duration_seconds": 1.119}, "timestamp": "2026-01-12T09:30:34.967150"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1294.985, "latencies_ms": [1294.985], "images_per_second": 0.772, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The room is bathed in natural light from a window, the walls are adorned with floral wallpaper, and the floor is carpeted.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15612.5, "ram_available_mb": 106893.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15601.6, "ram_available_mb": 106904.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [45.77, 45.77, 45.77, 45.77, 45.77, 43.79, 43.79, 43.79, 43.79, 43.79, 47.85, 47.85, 47.85], "power_watts_avg": 45.49, "power_watts_peak": 47.85, "energy_joules_est": 58.92, "sample_count": 13, "duration_seconds": 1.295}, "timestamp": "2026-01-12T09:30:36.279824"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 800.042, "latencies_ms": [800.042], "images_per_second": 1.25, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15601.6, "ram_available_mb": 106904.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15592.6, "ram_available_mb": 106913.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.85, 47.85, 36.57, 36.57, 36.57, 36.57, 36.57, 43.51], "power_watts_avg": 40.25, "power_watts_peak": 47.85, "energy_joules_est": 32.21, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-12T09:30:37.092670"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 566.592, "latencies_ms": [566.592], "images_per_second": 1.765, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " stop sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15592.6, "ram_available_mb": 106913.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15590.0, "ram_available_mb": 106916.3, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.51, 43.51, 43.51, 43.51, 51.34, 51.34], "power_watts_avg": 46.12, "power_watts_peak": 51.34, "energy_joules_est": 26.15, "sample_count": 6, "duration_seconds": 0.567}, "timestamp": "2026-01-12T09:30:37.701655"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1663.697, "latencies_ms": [1663.697], "images_per_second": 0.601, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The stop sign is in the foreground, to the left of the street. The street is in the middle of the image, with the stop sign on the right side. The background includes trees and buildings, with the sky visible above.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15590.0, "ram_available_mb": 106916.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15582.8, "ram_available_mb": 106923.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [51.34, 51.34, 51.34, 49.24, 49.24, 49.24, 49.24, 49.24, 46.54, 46.54, 46.54, 46.54, 46.54, 37.65, 37.65, 37.65, 37.65], "power_watts_avg": 46.09, "power_watts_peak": 51.34, "energy_joules_est": 76.69, "sample_count": 17, "duration_seconds": 1.664}, "timestamp": "2026-01-12T09:30:39.417324"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 783.827, "latencies_ms": [783.827], "images_per_second": 1.276, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15582.3, "ram_available_mb": 106924.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15588.9, "ram_available_mb": 106917.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.65, 29.02, 29.02, 29.02, 29.02, 29.02, 43.24, 43.24], "power_watts_avg": 33.66, "power_watts_peak": 43.24, "energy_joules_est": 26.39, "sample_count": 8, "duration_seconds": 0.784}, "timestamp": "2026-01-12T09:30:40.227730"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 786.913, "latencies_ms": [786.913], "images_per_second": 1.271, "prompt_tokens": 1110, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The stop sign is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15588.9, "ram_available_mb": 106917.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15675.0, "ram_available_mb": 106831.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.24, 43.24, 43.24, 50.37, 50.37, 50.37, 50.37, 50.37], "power_watts_avg": 47.7, "power_watts_peak": 50.37, "energy_joules_est": 37.55, "sample_count": 8, "duration_seconds": 0.787}, "timestamp": "2026-01-12T09:30:41.035486"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 885.841, "latencies_ms": [885.841], "images_per_second": 1.129, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three teddy bears of different sizes and colors are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 15675.0, "ram_available_mb": 106831.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15574.7, "ram_available_mb": 106931.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.78, 43.78, 43.78, 43.78, 43.78, 51.35, 51.35, 51.35, 51.35], "power_watts_avg": 47.14, "power_watts_peak": 51.35, "energy_joules_est": 41.78, "sample_count": 9, "duration_seconds": 0.886}, "timestamp": "2026-01-12T09:30:41.947323"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 555.667, "latencies_ms": [555.667], "images_per_second": 1.8, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " teddy bear: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15572.7, "ram_available_mb": 106933.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15599.0, "ram_available_mb": 106907.3, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [51.35, 42.71, 42.71, 42.71, 42.71, 42.71], "power_watts_avg": 44.15, "power_watts_peak": 51.35, "energy_joules_est": 24.55, "sample_count": 6, "duration_seconds": 0.556}, "timestamp": "2026-01-12T09:30:42.554801"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2116.071, "latencies_ms": [2116.071], "images_per_second": 0.473, "prompt_tokens": 1118, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The teddy bears are positioned in a close-knit arrangement, with the largest bear in the center and the smallest bear on the left. The largest bear is in the foreground, while the smallest bear is in the background. The teddy bears are arranged in a way that suggests they are huddled together for comfort or companionship.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15599.0, "ram_available_mb": 106907.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15581.7, "ram_available_mb": 106924.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 43.95, 43.95, 56.4, 56.4, 56.4, 56.4, 56.4, 43.32, 43.32, 43.32, 43.32, 43.32, 32.55, 32.55, 32.55, 32.55, 30.96, 30.96, 30.96], "power_watts_avg": 42.79, "power_watts_peak": 56.4, "energy_joules_est": 90.56, "sample_count": 22, "duration_seconds": 2.116}, "timestamp": "2026-01-12T09:30:44.768226"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 740.496, "latencies_ms": [740.496], "images_per_second": 1.35, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Three teddy bears are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15581.7, "ram_available_mb": 106924.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 15660.8, "ram_available_mb": 106845.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 22.0}, "power_stats": {"power_watts_samples": [30.96, 30.96, 29.45, 29.45, 29.45, 29.45, 29.45, 41.62], "power_watts_avg": 31.35, "power_watts_peak": 41.62, "energy_joules_est": 23.23, "sample_count": 8, "duration_seconds": 0.741}, "timestamp": "2026-01-12T09:30:45.628012"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1485.409, "latencies_ms": [1485.409], "images_per_second": 0.673, "prompt_tokens": 1110, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The teddy bears are in a variety of colors, including brown, orange, and beige. The lighting is soft and natural, and the teddy bears are made of a soft, plush material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15660.8, "ram_available_mb": 106845.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15644.2, "ram_available_mb": 106862.1, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.62, 41.62, 41.62, 41.62, 51.99, 51.99, 51.99, 51.99, 51.99, 43.11, 43.11, 43.11, 43.11, 43.11, 34.79], "power_watts_avg": 45.12, "power_watts_peak": 51.99, "energy_joules_est": 67.03, "sample_count": 15, "duration_seconds": 1.486}, "timestamp": "2026-01-12T09:30:47.138922"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 994.55, "latencies_ms": [994.55], "images_per_second": 1.005, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill with ski poles in her hands.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15644.2, "ram_available_mb": 106862.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 15550.3, "ram_available_mb": 106956.0, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.79, 34.79, 39.31, 39.31, 39.31, 39.31, 39.31, 43.63], "power_watts_avg": 37.93, "power_watts_peak": 43.63, "energy_joules_est": 37.75, "sample_count": 10, "duration_seconds": 0.995}, "timestamp": "2026-01-12T09:30:48.151988"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2314.635, "latencies_ms": [2314.635], "images_per_second": 0.432, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. Ski pole: 2\n2. Ski: 2\n3. Ski pole: 2\n4. Ski pole: 2\n5. Ski pole: 2\n6. Ski pole: 2\n7. Ski pole: 2\n8. Ski pole: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15550.3, "ram_available_mb": 106956.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15588.8, "ram_available_mb": 106917.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.63, 43.63, 43.63, 43.63, 43.99, 43.99, 43.99, 43.99, 43.99, 44.07, 44.07, 44.07, 44.07, 44.07, 36.48, 36.48, 36.48, 36.48, 31.18, 31.18, 31.18, 31.18, 31.18], "power_watts_avg": 39.85, "power_watts_peak": 44.07, "energy_joules_est": 92.27, "sample_count": 23, "duration_seconds": 2.315}, "timestamp": "2026-01-12T09:30:50.472077"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1550.618, "latencies_ms": [1550.618], "images_per_second": 0.645, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski slope stretching out into the background. The skier is to the left of the image, with the ski poles extending towards the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15588.8, "ram_available_mb": 106917.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15636.3, "ram_available_mb": 106870.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [31.02, 31.02, 31.02, 31.02, 31.02, 43.25, 43.25, 43.25, 43.25, 43.25, 43.22, 43.22, 43.22, 43.22, 43.22, 30.89], "power_watts_avg": 38.64, "power_watts_peak": 43.25, "energy_joules_est": 59.94, "sample_count": 16, "duration_seconds": 1.551}, "timestamp": "2026-01-12T09:30:52.137731"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 834.97, "latencies_ms": [834.97], "images_per_second": 1.198, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15628.4, "ram_available_mb": 106877.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15639.5, "ram_available_mb": 106866.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [30.89, 30.89, 30.89, 30.89, 38.84, 38.84, 38.84, 38.84, 38.84], "power_watts_avg": 35.31, "power_watts_peak": 38.84, "energy_joules_est": 29.49, "sample_count": 9, "duration_seconds": 0.835}, "timestamp": "2026-01-12T09:30:53.046803"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 948.06, "latencies_ms": [948.06], "images_per_second": 1.055, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a red jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15635.5, "ram_available_mb": 106870.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15623.0, "ram_available_mb": 106883.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.36, 43.36, 43.36, 43.36, 43.36, 47.45, 47.45, 47.45, 47.45, 47.45], "power_watts_avg": 45.4, "power_watts_peak": 47.45, "energy_joules_est": 43.05, "sample_count": 10, "duration_seconds": 0.948}, "timestamp": "2026-01-12T09:30:54.059900"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1167.463, "latencies_ms": [1167.463], "images_per_second": 0.857, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a kitchen with white appliances, including a refrigerator, oven, and stove, and wooden cabinets above and below the countertops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15623.0, "ram_available_mb": 106883.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15651.5, "ram_available_mb": 106854.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.04, 43.04, 43.04, 43.04, 43.04, 43.44, 43.44, 43.44, 43.44, 42.92, 42.92, 42.92], "power_watts_avg": 43.14, "power_watts_peak": 43.44, "energy_joules_est": 50.38, "sample_count": 12, "duration_seconds": 1.168}, "timestamp": "2026-01-12T09:30:55.271112"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2232.588, "latencies_ms": [2232.588], "images_per_second": 0.448, "prompt_tokens": 1114, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. white refrigerator: 1\n2. white stove: 1\n3. white oven: 1\n4. white cabinet: 2\n5. white cabinet door: 1\n6. white cabinet handle: 1\n7. white cabinet drawer: 1\n8. white cabinet knob: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15651.5, "ram_available_mb": 106854.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 15599.4, "ram_available_mb": 106906.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.92, 42.92, 34.02, 34.02, 34.02, 34.02, 34.02, 43.68, 43.68, 43.68, 43.68, 43.68, 42.03, 42.03, 42.03, 42.03, 42.03, 31.34, 31.34, 31.34, 31.34, 31.34, 31.17], "power_watts_avg": 37.93, "power_watts_peak": 43.68, "energy_joules_est": 84.69, "sample_count": 23, "duration_seconds": 2.233}, "timestamp": "2026-01-12T09:30:57.588181"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1392.698, "latencies_ms": [1392.698], "images_per_second": 0.718, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The stove is located to the left of the refrigerator, which is situated in the background. The sink is positioned near the stove, while the dishwasher is placed further back in the kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15599.4, "ram_available_mb": 106906.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15686.8, "ram_available_mb": 106819.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [31.17, 31.17, 31.17, 31.17, 37.23, 37.23, 37.23, 37.23, 37.23, 42.17, 42.17, 42.17, 42.17, 42.17], "power_watts_avg": 37.27, "power_watts_peak": 42.17, "energy_joules_est": 51.93, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-12T09:30:59.048448"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 814.692, "latencies_ms": [814.692], "images_per_second": 1.227, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A small kitchen with white appliances and wood cabinets is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15686.8, "ram_available_mb": 106819.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 15592.5, "ram_available_mb": 106913.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.97, 35.97, 35.97, 35.97, 35.97, 43.7, 43.7, 43.7, 43.7], "power_watts_avg": 39.4, "power_watts_peak": 43.7, "energy_joules_est": 32.12, "sample_count": 9, "duration_seconds": 0.815}, "timestamp": "2026-01-12T09:30:59.957958"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 891.924, "latencies_ms": [891.924], "images_per_second": 1.121, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15592.5, "ram_available_mb": 106913.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15644.1, "ram_available_mb": 106862.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 35.0}, "power_stats": {"power_watts_samples": [43.7, 42.25, 42.25, 42.25, 42.25, 42.25, 43.14, 43.14, 43.14], "power_watts_avg": 42.71, "power_watts_peak": 43.7, "energy_joules_est": 38.1, "sample_count": 9, "duration_seconds": 0.892}, "timestamp": "2026-01-12T09:31:00.869090"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1256.041, "latencies_ms": [1256.041], "images_per_second": 0.796, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two baseball players are running on the field, one of them is wearing a green shirt and the other is wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15644.1, "ram_available_mb": 106862.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15644.6, "ram_available_mb": 106861.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.14, 42.71, 42.71, 42.71, 42.71, 42.71, 48.3, 48.3, 48.3, 48.3, 48.3, 50.31, 50.31], "power_watts_avg": 46.06, "power_watts_peak": 50.31, "energy_joules_est": 57.86, "sample_count": 13, "duration_seconds": 1.256}, "timestamp": "2026-01-12T09:31:02.182183"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2357.221, "latencies_ms": [2357.221], "images_per_second": 0.424, "prompt_tokens": 1446, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. baseball glove: 1\n3. baseball bat: 1\n4. baseball cap: 1\n5. baseball helmet: 1\n6. baseball field: 1\n7. baseball player's pants: 1\n8. baseball player's shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15644.6, "ram_available_mb": 106861.7, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 15604.7, "ram_available_mb": 106901.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.31, 50.31, 50.31, 35.28, 35.28, 35.28, 35.28, 35.28, 47.0, 47.0, 47.0, 47.0, 47.0, 43.64, 43.64, 43.64, 43.64, 43.64, 31.94, 31.94, 31.94, 31.94, 31.94, 32.04], "power_watts_avg": 40.51, "power_watts_peak": 50.31, "energy_joules_est": 95.51, "sample_count": 24, "duration_seconds": 2.358}, "timestamp": "2026-01-12T09:31:04.602287"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1699.805, "latencies_ms": [1699.805], "images_per_second": 0.588, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The baseball player in the foreground is running towards the right side of the image, while the other player is running towards the left side. The baseball player in the foreground is closer to the camera than the other player.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15604.7, "ram_available_mb": 106901.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15576.2, "ram_available_mb": 106930.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.04, 32.04, 32.04, 32.04, 39.18, 39.18, 39.18, 39.18, 39.18, 47.12, 47.12, 47.12, 47.12, 47.12, 40.82, 40.82, 40.82], "power_watts_avg": 40.12, "power_watts_peak": 47.12, "energy_joules_est": 68.23, "sample_count": 17, "duration_seconds": 1.701}, "timestamp": "2026-01-12T09:31:06.319186"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1213.835, "latencies_ms": [1213.835], "images_per_second": 0.824, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a boy wearing a green shirt and a baseball glove running towards the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15576.2, "ram_available_mb": 106930.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15617.0, "ram_available_mb": 106889.3, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [40.82, 40.82, 31.19, 31.19, 31.19, 31.19, 31.19, 48.59, 48.59, 48.59, 48.59, 48.59, 49.26], "power_watts_avg": 40.75, "power_watts_peak": 49.26, "energy_joules_est": 49.48, "sample_count": 13, "duration_seconds": 1.214}, "timestamp": "2026-01-12T09:31:07.630736"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1628.502, "latencies_ms": [1628.502], "images_per_second": 0.614, "prompt_tokens": 1442, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a baseball game with two players running on the field, one wearing a green shirt and the other wearing a white shirt. The field is covered in green grass, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15608.8, "ram_available_mb": 106897.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15595.1, "ram_available_mb": 106911.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.26, 49.26, 49.26, 49.26, 37.74, 37.74, 37.74, 37.74, 37.74, 46.88, 46.88, 46.88, 46.88, 46.88, 41.16, 41.16, 41.16], "power_watts_avg": 43.74, "power_watts_peak": 49.26, "energy_joules_est": 71.27, "sample_count": 17, "duration_seconds": 1.629}, "timestamp": "2026-01-12T09:31:09.343778"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1040.751, "latencies_ms": [1040.751], "images_per_second": 0.961, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A tennis player is preparing to hit a ball on a court with a J.P. Morgan advertisement in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15595.1, "ram_available_mb": 106911.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15683.7, "ram_available_mb": 106822.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.16, 41.16, 30.46, 30.46, 30.46, 30.46, 30.46, 43.23, 43.23, 43.23, 43.23], "power_watts_avg": 37.05, "power_watts_peak": 43.23, "energy_joules_est": 38.57, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-12T09:31:10.456305"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1945.395, "latencies_ms": [1945.395], "images_per_second": 0.514, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. tennis player: 1\n2. ball: 1\n3. racket: 1\n4. person: 1\n5. wall: 1\n6. advertisement: 1\n7. spectator: 1\n8. court: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15683.7, "ram_available_mb": 106822.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15669.3, "ram_available_mb": 106837.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.23, 44.11, 44.11, 44.11, 44.11, 44.11, 43.37, 43.37, 43.37, 43.37, 43.37, 45.15, 45.15, 45.15, 45.15, 45.15, 31.9, 31.9, 31.9, 31.9], "power_watts_avg": 41.7, "power_watts_peak": 45.15, "energy_joules_est": 81.13, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T09:31:12.471584"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1477.875, "latencies_ms": [1477.875], "images_per_second": 0.677, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the ball and the umpire in the background. The player is closer to the camera than the umpire, who is standing behind the player.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15669.3, "ram_available_mb": 106837.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15663.6, "ram_available_mb": 106842.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [30.76, 30.76, 30.76, 30.76, 30.76, 42.7, 42.7, 42.7, 42.7, 42.7, 43.86, 43.86, 43.86, 43.86, 43.86], "power_watts_avg": 39.11, "power_watts_peak": 43.86, "energy_joules_est": 57.83, "sample_count": 15, "duration_seconds": 1.479}, "timestamp": "2026-01-12T09:31:14.034417"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 956.054, "latencies_ms": [956.054], "images_per_second": 1.046, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A tennis player is playing on a court with a J.P. Morgan advertisement in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15663.6, "ram_available_mb": 106842.7, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15568.0, "ram_available_mb": 106938.3, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.03, 32.03, 32.03, 32.03, 32.03, 44.09, 44.09, 44.09, 44.09, 44.09], "power_watts_avg": 38.06, "power_watts_peak": 44.09, "energy_joules_est": 36.41, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-12T09:31:15.043548"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2769.11, "latencies_ms": [2769.11], "images_per_second": 0.361, "prompt_tokens": 1109, "response_tokens_est": 90, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a vibrant blue tennis court, where a player in a crisp white outfit is in the midst of a powerful swing, his body leaning forward in anticipation. The court is bathed in bright sunlight, casting sharp shadows and highlighting the texture of the green surface. In the background, a large blue wall stands out, adorned with the logo of J.P. Morgan, adding a touch of corporate elegance to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15568.0, "ram_available_mb": 106938.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15597.1, "ram_available_mb": 106909.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.15, 44.15, 44.15, 44.15, 44.15, 44.69, 44.69, 44.69, 44.69, 44.69, 43.75, 43.75, 43.75, 43.75, 43.75, 31.63, 31.63, 31.63, 31.63, 31.63, 31.65, 31.65, 31.65, 31.65, 31.65, 31.86, 31.86, 31.86], "power_watts_avg": 38.39, "power_watts_peak": 44.69, "energy_joules_est": 106.33, "sample_count": 28, "duration_seconds": 2.77}, "timestamp": "2026-01-12T09:31:17.867158"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1063.91, "latencies_ms": [1063.91], "images_per_second": 0.94, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court, with one of the adults holding a trophy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15596.8, "ram_available_mb": 106909.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 15609.2, "ram_available_mb": 106897.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [31.86, 29.01, 29.01, 29.01, 29.01, 29.01, 42.86, 42.86, 42.86, 42.86, 42.86], "power_watts_avg": 35.56, "power_watts_peak": 42.86, "energy_joules_est": 37.85, "sample_count": 11, "duration_seconds": 1.064}, "timestamp": "2026-01-12T09:31:19.032010"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1885.209, "latencies_ms": [1885.209], "images_per_second": 0.53, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. boy: 3\n2. girl: 2\n3. boy: 2\n4. boy: 1\n5. boy: 1\n6. boy: 1\n7. boy: 1\n8. boy: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15608.9, "ram_available_mb": 106897.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15601.8, "ram_available_mb": 106904.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.95, 45.95, 45.95, 45.95, 45.95, 44.21, 44.21, 44.21, 44.21, 44.21, 44.19, 44.19, 44.19, 44.19, 44.19, 31.68, 31.68, 31.68, 31.68], "power_watts_avg": 42.03, "power_watts_peak": 45.95, "energy_joules_est": 79.24, "sample_count": 19, "duration_seconds": 1.886}, "timestamp": "2026-01-12T09:31:20.951330"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2268.117, "latencies_ms": [2268.117], "images_per_second": 0.441, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The group of children and adults are standing on a tennis court, with the tennis rackets held by the children and adults. The tennis rackets are positioned in the foreground, with the group of children and adults standing behind them. The tennis court is located in the middle of the image, with the group of children and adults standing in front of it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15597.9, "ram_available_mb": 106908.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15591.8, "ram_available_mb": 106914.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [30.83, 30.83, 30.83, 30.83, 30.83, 43.44, 43.44, 43.44, 43.44, 43.44, 44.36, 44.36, 44.36, 44.36, 44.36, 31.82, 31.82, 31.82, 31.82, 31.82, 31.86, 31.86, 31.86], "power_watts_avg": 36.86, "power_watts_peak": 44.36, "energy_joules_est": 83.64, "sample_count": 23, "duration_seconds": 2.269}, "timestamp": "2026-01-12T09:31:23.322067"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 837.886, "latencies_ms": [837.886], "images_per_second": 1.193, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court.", "error": null, "sys_before": {"cpu_percent": 1.0, "ram_used_mb": 15588.3, "ram_available_mb": 106918.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15591.7, "ram_available_mb": 106914.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [31.86, 29.2, 29.2, 29.2, 29.2, 29.2, 43.23, 43.23, 43.23], "power_watts_avg": 34.17, "power_watts_peak": 43.23, "energy_joules_est": 28.64, "sample_count": 9, "duration_seconds": 0.838}, "timestamp": "2026-01-12T09:31:24.281139"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1494.346, "latencies_ms": [1494.346], "images_per_second": 0.669, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a group of children and adults standing on a blue tennis court, with the children holding tennis rackets and wearing tennis attire. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15583.8, "ram_available_mb": 106922.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15588.4, "ram_available_mb": 106917.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.23, 43.23, 47.43, 47.43, 47.43, 47.43, 47.43, 43.47, 43.47, 43.47, 43.47, 43.47, 42.71, 42.71, 42.71], "power_watts_avg": 44.61, "power_watts_peak": 47.43, "energy_joules_est": 66.68, "sample_count": 15, "duration_seconds": 1.495}, "timestamp": "2026-01-12T09:31:25.792681"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1367.382, "latencies_ms": [1367.382], "images_per_second": 0.731, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a group of people are gathered on a bridge overlooking a river, with a bird perched on the ground nearby, and a woman taking a photo of the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15584.4, "ram_available_mb": 106921.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15508.8, "ram_available_mb": 106997.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.71, 42.71, 33.39, 33.39, 33.39, 33.39, 33.39, 44.62, 44.62, 44.62, 44.62, 44.62, 42.89, 42.89], "power_watts_avg": 40.09, "power_watts_peak": 44.62, "energy_joules_est": 54.83, "sample_count": 14, "duration_seconds": 1.368}, "timestamp": "2026-01-12T09:31:27.207628"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1883.977, "latencies_ms": [1883.977], "images_per_second": 0.531, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. people: 4\n3. birds: 1\n4. rocks: 2\n5. water: 1\n6. trees: 1\n7. buildings: 1\n8. bridge: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15508.8, "ram_available_mb": 106997.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15553.4, "ram_available_mb": 106952.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.89, 42.89, 42.89, 36.78, 36.78, 36.78, 36.78, 36.78, 44.1, 44.1, 44.1, 44.1, 44.1, 39.96, 39.96, 39.96, 39.96, 39.96, 31.96], "power_watts_avg": 40.26, "power_watts_peak": 44.1, "energy_joules_est": 75.86, "sample_count": 19, "duration_seconds": 1.884}, "timestamp": "2026-01-12T09:31:29.123838"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1900.657, "latencies_ms": [1900.657], "images_per_second": 0.526, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the bridge and the river in the background. The bridge is located to the left of the image, while the river is to the right. The people are sitting on the bridge, with the bird in the water closer to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15553.4, "ram_available_mb": 106952.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15562.0, "ram_available_mb": 106944.3, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [31.96, 31.96, 31.96, 31.96, 40.95, 40.95, 40.95, 40.95, 40.95, 44.57, 44.57, 44.57, 44.57, 44.57, 36.39, 36.39, 36.39, 36.39, 36.39], "power_watts_avg": 38.81, "power_watts_peak": 44.57, "energy_joules_est": 73.77, "sample_count": 19, "duration_seconds": 1.901}, "timestamp": "2026-01-12T09:31:31.037369"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1047.45, "latencies_ms": [1047.45], "images_per_second": 0.955, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting on a stone ledge by a river, watching a white bird swim in the water.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15562.0, "ram_available_mb": 106944.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15649.0, "ram_available_mb": 106857.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.08, 32.08, 32.08, 32.08, 41.95, 41.95, 41.95, 41.95, 41.95, 43.65, 43.65], "power_watts_avg": 38.67, "power_watts_peak": 43.65, "energy_joules_est": 40.53, "sample_count": 11, "duration_seconds": 1.048}, "timestamp": "2026-01-12T09:31:32.200492"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1990.454, "latencies_ms": [1990.454], "images_per_second": 0.502, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a bridge with a metal structure, a river with a white bird, and a group of people sitting on the bank. The lighting is natural, with the sun shining down on the scene, and the colors are vibrant, with the blue of the river and the green of the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15641.1, "ram_available_mb": 106865.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15644.9, "ram_available_mb": 106861.4, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.65, 43.65, 43.65, 39.86, 39.86, 39.86, 39.86, 39.86, 43.92, 43.92, 43.92, 43.92, 43.92, 38.82, 38.82, 38.82, 38.82, 38.82, 31.98, 31.98], "power_watts_avg": 40.4, "power_watts_peak": 43.92, "energy_joules_est": 80.43, "sample_count": 20, "duration_seconds": 1.991}, "timestamp": "2026-01-12T09:31:34.217748"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 786.93, "latencies_ms": [786.93], "images_per_second": 1.271, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is looking at her phone with a Hello Kitty case.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15637.0, "ram_available_mb": 106869.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15669.4, "ram_available_mb": 106836.9, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [31.98, 31.98, 31.98, 36.87, 36.87, 36.87, 36.87, 36.87], "power_watts_avg": 35.04, "power_watts_peak": 36.87, "energy_joules_est": 27.58, "sample_count": 8, "duration_seconds": 0.787}, "timestamp": "2026-01-12T09:31:35.029920"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2030.528, "latencies_ms": [2030.528], "images_per_second": 0.492, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. woman: 1\n2. hair: 1\n3. earrings: 1\n4. wristwatch: 1\n5. bracelet: 1\n6. phone: 1\n7. Hello Kitty: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15665.4, "ram_available_mb": 106840.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15636.5, "ram_available_mb": 106869.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.6, 44.6, 44.6, 44.6, 44.6, 52.99, 52.99, 52.99, 52.99, 52.99, 44.81, 44.81, 44.81, 44.81, 44.81, 32.03, 32.03, 32.03, 32.03, 32.03, 32.06], "power_watts_avg": 43.06, "power_watts_peak": 52.99, "energy_joules_est": 87.45, "sample_count": 21, "duration_seconds": 2.031}, "timestamp": "2026-01-12T09:31:37.147028"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1395.527, "latencies_ms": [1395.527], "images_per_second": 0.717, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The woman is in the foreground of the image, holding a Hello Kitty phone in her hand. The background is blurred, indicating that the focus is on the woman and her phone.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15636.5, "ram_available_mb": 106869.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15651.2, "ram_available_mb": 106855.1, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [32.06, 32.06, 32.06, 35.83, 35.83, 35.83, 35.83, 35.83, 42.26, 42.26, 42.26, 42.26, 42.26, 38.62], "power_watts_avg": 37.52, "power_watts_peak": 42.26, "energy_joules_est": 52.38, "sample_count": 14, "duration_seconds": 1.396}, "timestamp": "2026-01-12T09:31:38.609642"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 841.16, "latencies_ms": [841.16], "images_per_second": 1.189, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is taking a picture of herself with a Hello Kitty phone case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15651.2, "ram_available_mb": 106855.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15567.9, "ram_available_mb": 106938.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.62, 38.62, 38.62, 38.62, 41.94, 41.94, 41.94, 41.94, 41.94], "power_watts_avg": 40.46, "power_watts_peak": 41.94, "energy_joules_est": 34.05, "sample_count": 9, "duration_seconds": 0.841}, "timestamp": "2026-01-12T09:31:39.517328"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1352.456, "latencies_ms": [1352.456], "images_per_second": 0.739, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The woman is wearing a white shirt with a black and white print, and she is holding a Hello Kitty phone case. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15567.9, "ram_available_mb": 106938.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15566.2, "ram_available_mb": 106940.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [44.48, 44.48, 44.48, 44.48, 44.48, 46.96, 46.96, 46.96, 46.96, 46.96, 44.0, 44.0, 44.0, 44.0], "power_watts_avg": 45.23, "power_watts_peak": 46.96, "energy_joules_est": 61.18, "sample_count": 14, "duration_seconds": 1.353}, "timestamp": "2026-01-12T09:31:40.931932"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 970.361, "latencies_ms": [970.361], "images_per_second": 1.031, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of children are riding on a red and yellow train car in a room with a wooden floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15558.3, "ram_available_mb": 106948.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15561.1, "ram_available_mb": 106945.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 39.0}, "power_stats": {"power_watts_samples": [44.0, 29.97, 29.97, 29.97, 29.97, 29.97, 43.69, 43.69, 43.69, 43.69], "power_watts_avg": 36.86, "power_watts_peak": 44.0, "energy_joules_est": 35.79, "sample_count": 10, "duration_seconds": 0.971}, "timestamp": "2026-01-12T09:31:41.945155"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1806.076, "latencies_ms": [1806.076], "images_per_second": 0.554, "prompt_tokens": 1114, "response_tokens_est": 53, "n_tiles": 1, "output_text": " 1. children: 5\n2. train: 1\n3. track: 1\n4. wall: 1\n5. floor: 1\n6. children's clothing: 5\n7. children's hair: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15553.2, "ram_available_mb": 106953.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15570.5, "ram_available_mb": 106935.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.69, 44.03, 44.03, 44.03, 44.03, 44.03, 44.53, 44.53, 44.53, 44.53, 44.53, 45.68, 45.68, 45.68, 45.68, 45.68, 31.98, 31.98], "power_watts_avg": 43.27, "power_watts_peak": 45.68, "energy_joules_est": 78.17, "sample_count": 18, "duration_seconds": 1.806}, "timestamp": "2026-01-12T09:31:43.760065"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1528.978, "latencies_ms": [1528.978], "images_per_second": 0.654, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The children are in the foreground, riding on a train that is in the middle of the image. The train is moving towards the right side of the image, and the children are looking towards the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15568.5, "ram_available_mb": 106937.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15557.8, "ram_available_mb": 106948.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [31.98, 31.98, 31.98, 35.65, 35.65, 35.65, 35.65, 35.65, 45.05, 45.05, 45.05, 45.05, 45.05, 41.35, 41.35, 41.35], "power_watts_avg": 38.97, "power_watts_peak": 45.05, "energy_joules_est": 59.59, "sample_count": 16, "duration_seconds": 1.529}, "timestamp": "2026-01-12T09:31:45.375225"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1055.719, "latencies_ms": [1055.719], "images_per_second": 0.947, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of children are riding on a train car in a room with a wooden floor and a wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15550.0, "ram_available_mb": 106956.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15576.2, "ram_available_mb": 106930.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.35, 41.35, 29.17, 29.17, 29.17, 29.17, 43.52, 43.52, 43.52, 43.52, 43.52], "power_watts_avg": 37.91, "power_watts_peak": 43.52, "energy_joules_est": 40.03, "sample_count": 11, "duration_seconds": 1.056}, "timestamp": "2026-01-12T09:31:46.487413"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1774.243, "latencies_ms": [1774.243], "images_per_second": 0.564, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a group of children riding on a red and yellow train car, with the train car being the main focus of the image. The lighting in the image is dim, and the children are wearing jackets, indicating that it might be a cold day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15572.2, "ram_available_mb": 106934.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15558.8, "ram_available_mb": 106947.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.69, 45.69, 45.69, 45.69, 45.69, 43.95, 43.95, 43.95, 43.95, 43.95, 45.03, 45.03, 45.03, 45.03, 45.03, 32.14, 32.14, 32.14], "power_watts_avg": 42.77, "power_watts_peak": 45.69, "energy_joules_est": 75.89, "sample_count": 18, "duration_seconds": 1.775}, "timestamp": "2026-01-12T09:31:48.305155"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1059.414, "latencies_ms": [1059.414], "images_per_second": 0.944, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a plate with a slice of cake and a side of salad.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15558.8, "ram_available_mb": 106947.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15507.8, "ram_available_mb": 106998.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.14, 32.14, 31.4, 31.4, 31.4, 31.4, 31.4, 47.92, 47.92, 47.92, 47.92], "power_watts_avg": 37.54, "power_watts_peak": 47.92, "energy_joules_est": 39.78, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T09:31:49.419214"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2045.648, "latencies_ms": [2045.648], "images_per_second": 0.489, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. food: 1\n3. cup: 1\n4. table: 1\n5. glass: 1\n6. fork: 1\n7. knife: 1\n8. spoon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15507.8, "ram_available_mb": 106998.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15563.8, "ram_available_mb": 106942.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.92, 47.63, 47.63, 47.63, 47.63, 47.63, 48.34, 48.34, 48.34, 48.34, 48.34, 50.15, 50.15, 50.15, 50.15, 50.15, 32.99, 32.99, 32.99, 32.99, 32.99], "power_watts_avg": 44.93, "power_watts_peak": 50.15, "energy_joules_est": 91.92, "sample_count": 21, "duration_seconds": 2.046}, "timestamp": "2026-01-12T09:31:51.537188"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1751.341, "latencies_ms": [1751.341], "images_per_second": 0.571, "prompt_tokens": 1450, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main object, a slice of cake, is in the foreground, with a small dish of food in the background. The cake is to the left of the dish, and the dish is to the right of the cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15559.1, "ram_available_mb": 106947.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15569.8, "ram_available_mb": 106936.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [32.13, 32.13, 32.13, 32.13, 39.47, 39.47, 39.47, 39.47, 39.47, 47.03, 47.03, 47.03, 47.03, 47.03, 40.29, 40.29, 40.29, 40.29], "power_watts_avg": 40.12, "power_watts_peak": 47.03, "energy_joules_est": 70.29, "sample_count": 18, "duration_seconds": 1.752}, "timestamp": "2026-01-12T09:31:53.402031"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 978.71, "latencies_ms": [978.71], "images_per_second": 1.022, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate of food with a side of salad.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15569.8, "ram_available_mb": 106936.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 15563.9, "ram_available_mb": 106942.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [40.29, 29.75, 29.75, 29.75, 29.75, 29.75, 48.11, 48.11, 48.11, 48.11], "power_watts_avg": 38.15, "power_watts_peak": 48.11, "energy_joules_est": 37.35, "sample_count": 10, "duration_seconds": 0.979}, "timestamp": "2026-01-12T09:31:54.411193"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1477.321, "latencies_ms": [1477.321], "images_per_second": 0.677, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, with a focus on a plate of food. The lighting is soft and natural, and the food appears to be well-cooked.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15554.5, "ram_available_mb": 106951.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15590.1, "ram_available_mb": 106916.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [48.11, 48.21, 48.21, 48.21, 48.21, 48.21, 48.55, 48.55, 48.55, 48.55, 48.55, 50.22, 50.22, 50.22, 50.22], "power_watts_avg": 48.85, "power_watts_peak": 50.22, "energy_joules_est": 72.18, "sample_count": 15, "duration_seconds": 1.478}, "timestamp": "2026-01-12T09:31:55.926993"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 823.209, "latencies_ms": [823.209], "images_per_second": 1.215, "prompt_tokens": 766, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a wetsuit is standing on a surfboard in the ocean, holding a paddle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15590.1, "ram_available_mb": 106916.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15625.4, "ram_available_mb": 106880.9, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4528.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [50.22, 30.54, 30.54, 30.54, 30.54, 30.54, 39.88, 39.88, 39.88], "power_watts_avg": 35.84, "power_watts_peak": 50.22, "energy_joules_est": 29.52, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-12T09:31:56.835647"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1728.213, "latencies_ms": [1728.213], "images_per_second": 0.579, "prompt_tokens": 780, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. paddle: 1\n3. surfboard: 1\n4. water: 1\n5. land: 1\n6. sky: 1\n7. city: 1\n8. buildings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15625.4, "ram_available_mb": 106880.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 15603.1, "ram_available_mb": 106903.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.8, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.88, 39.88, 41.7, 41.7, 41.7, 41.7, 41.7, 39.3, 39.3, 39.3, 39.3, 39.3, 40.17, 40.17, 40.17, 40.17, 40.17, 32.32], "power_watts_avg": 39.88, "power_watts_peak": 41.7, "energy_joules_est": 68.96, "sample_count": 18, "duration_seconds": 1.729}, "timestamp": "2026-01-12T09:31:58.647025"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 947.423, "latencies_ms": [947.423], "images_per_second": 1.055, "prompt_tokens": 784, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The person is in the foreground, paddling a paddleboard on the water, while the shoreline and buildings are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15603.1, "ram_available_mb": 106903.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15654.2, "ram_available_mb": 106852.1, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4575.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [32.32, 32.32, 32.32, 32.32, 39.59, 39.59, 39.59, 39.59, 39.59, 39.56], "power_watts_avg": 36.68, "power_watts_peak": 39.59, "energy_joules_est": 34.77, "sample_count": 10, "duration_seconds": 0.948}, "timestamp": "2026-01-12T09:31:59.655048"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 698.098, "latencies_ms": [698.098], "images_per_second": 1.432, "prompt_tokens": 778, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is standing on a paddleboard in the water, holding a paddle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15654.2, "ram_available_mb": 106852.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15650.3, "ram_available_mb": 106856.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [39.56, 39.56, 39.56, 39.56, 39.84, 39.84, 39.84], "power_watts_avg": 39.68, "power_watts_peak": 39.84, "energy_joules_est": 27.73, "sample_count": 7, "duration_seconds": 0.699}, "timestamp": "2026-01-12T09:32:00.364556"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1351.733, "latencies_ms": [1351.733], "images_per_second": 0.74, "prompt_tokens": 776, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is in black and white, with the water appearing dark and the sky clear. The person is wearing a wetsuit, which is black, and is holding a paddle, which is also black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15650.3, "ram_available_mb": 106856.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15641.5, "ram_available_mb": 106864.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.84, 39.84, 40.3, 40.3, 40.3, 40.3, 40.3, 40.89, 40.89, 40.89, 40.89, 40.89, 41.39, 41.39], "power_watts_avg": 40.6, "power_watts_peak": 41.39, "energy_joules_est": 54.9, "sample_count": 14, "duration_seconds": 1.352}, "timestamp": "2026-01-12T09:32:01.773234"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1022.714, "latencies_ms": [1022.714], "images_per_second": 0.978, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A white computer desk with a laptop, keyboard, mouse, and computer monitor, and a lamp on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15641.2, "ram_available_mb": 106865.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15658.8, "ram_available_mb": 106847.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [41.39, 41.39, 41.39, 34.64, 34.64, 34.64, 34.64, 34.64, 44.59, 44.59, 44.59], "power_watts_avg": 39.19, "power_watts_peak": 44.59, "energy_joules_est": 40.1, "sample_count": 11, "duration_seconds": 1.023}, "timestamp": "2026-01-12T09:32:02.881598"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1298.636, "latencies_ms": [1298.636], "images_per_second": 0.77, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 1, monitor: 1, keyboard: 1, mouse: 1, speakers: 2, printer: 1, lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15658.8, "ram_available_mb": 106847.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15637.2, "ram_available_mb": 106869.1, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.59, 39.5, 39.5, 39.5, 39.5, 39.5, 44.12, 44.12, 44.12, 44.12, 44.12, 46.56, 46.56], "power_watts_avg": 42.76, "power_watts_peak": 46.56, "energy_joules_est": 55.55, "sample_count": 13, "duration_seconds": 1.299}, "timestamp": "2026-01-12T09:32:04.194209"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1212.807, "latencies_ms": [1212.807], "images_per_second": 0.825, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The laptop is to the left of the computer monitor, the keyboard is in front of the monitor, and the speakers are to the right of the monitor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15635.1, "ram_available_mb": 106871.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 15627.8, "ram_available_mb": 106878.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.56, 46.56, 46.56, 38.96, 38.96, 38.96, 38.96, 38.96, 45.53, 45.53, 45.53, 45.53, 45.53], "power_watts_avg": 43.24, "power_watts_peak": 46.56, "energy_joules_est": 52.46, "sample_count": 13, "duration_seconds": 1.213}, "timestamp": "2026-01-12T09:32:05.505167"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 781.09, "latencies_ms": [781.09], "images_per_second": 1.28, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A white desk with a computer, laptop, and speakers on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15623.9, "ram_available_mb": 106882.4, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15616.5, "ram_available_mb": 106889.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [38.53, 38.53, 38.53, 38.53, 38.53, 43.85, 43.85, 43.85], "power_watts_avg": 40.53, "power_watts_peak": 43.85, "energy_joules_est": 31.68, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-12T09:32:06.313767"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1010.931, "latencies_ms": [1010.931], "images_per_second": 0.989, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the desk is made of white wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15608.6, "ram_available_mb": 106897.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15607.5, "ram_available_mb": 106898.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.85, 43.85, 45.97, 45.97, 45.97, 45.97, 45.97, 44.98, 44.98, 44.98, 44.98], "power_watts_avg": 45.22, "power_watts_peak": 45.97, "energy_joules_est": 45.74, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-12T09:32:07.425078"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1035.594, "latencies_ms": [1035.594], "images_per_second": 0.966, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A highway with multiple lanes, a bridge with green signs pointing to different directions, and a few cars on the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15607.5, "ram_available_mb": 106898.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15618.8, "ram_available_mb": 106887.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [44.98, 42.14, 42.14, 42.14, 42.14, 42.14, 43.69, 43.69, 43.69, 43.69, 43.69], "power_watts_avg": 43.1, "power_watts_peak": 44.98, "energy_joules_est": 44.66, "sample_count": 11, "duration_seconds": 1.036}, "timestamp": "2026-01-12T09:32:08.541547"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1864.637, "latencies_ms": [1864.637], "images_per_second": 0.536, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sign: 4\n2. car: 3\n3. van: 1\n4. taxi: 1\n5. road: 1\n6. bridge: 1\n7. tree: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15614.9, "ram_available_mb": 106891.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15593.3, "ram_available_mb": 106913.0, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.45, 46.45, 46.45, 46.45, 46.45, 44.28, 44.28, 44.28, 44.28, 44.28, 43.98, 43.98, 43.98, 43.98, 43.98, 32.44, 32.44, 32.44, 32.44], "power_watts_avg": 42.28, "power_watts_peak": 46.45, "energy_joules_est": 78.85, "sample_count": 19, "duration_seconds": 1.865}, "timestamp": "2026-01-12T09:32:10.456353"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1322.276, "latencies_ms": [1322.276], "images_per_second": 0.756, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, while the vehicles are in the background. The sign is also above the vehicles, indicating that it is a traffic sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15592.8, "ram_available_mb": 106913.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15650.2, "ram_available_mb": 106856.1, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [31.38, 31.38, 31.38, 31.38, 31.38, 43.79, 43.79, 43.79, 43.79, 43.79, 45.34, 45.34, 45.34, 45.34], "power_watts_avg": 39.8, "power_watts_peak": 45.34, "energy_joules_est": 52.65, "sample_count": 14, "duration_seconds": 1.323}, "timestamp": "2026-01-12T09:32:11.915726"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 905.165, "latencies_ms": [905.165], "images_per_second": 1.105, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A busy highway with cars and trucks driving under a bridge with green signs pointing to different destinations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15633.3, "ram_available_mb": 106873.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15659.6, "ram_available_mb": 106846.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 4.0}, "power_stats": {"power_watts_samples": [45.34, 29.52, 29.52, 29.52, 29.52, 29.52, 43.83, 43.83, 43.83, 43.83], "power_watts_avg": 36.83, "power_watts_peak": 45.34, "energy_joules_est": 33.35, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-12T09:32:12.924777"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1445.552, "latencies_ms": [1445.552], "images_per_second": 0.692, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a busy highway with several vehicles, including a black SUV, under a bridge with green signs indicating directions to various locations. The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15645.3, "ram_available_mb": 106861.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15643.8, "ram_available_mb": 106862.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.83, 43.95, 43.95, 43.95, 43.95, 43.95, 43.51, 43.51, 43.51, 43.51, 43.51, 46.23, 46.23, 46.23, 46.23], "power_watts_avg": 44.41, "power_watts_peak": 46.23, "energy_joules_est": 64.23, "sample_count": 15, "duration_seconds": 1.446}, "timestamp": "2026-01-12T09:32:14.436194"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1265.175, "latencies_ms": [1265.175], "images_per_second": 0.79, "prompt_tokens": 1432, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street with a sign on the front that says \"15 Aldwych\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15635.9, "ram_available_mb": 106870.4, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15557.5, "ram_available_mb": 106948.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.23, 30.39, 30.39, 30.39, 30.39, 30.39, 48.07, 48.07, 48.07, 48.07, 48.07, 49.71, 49.71], "power_watts_avg": 41.38, "power_watts_peak": 49.71, "energy_joules_est": 52.36, "sample_count": 13, "duration_seconds": 1.265}, "timestamp": "2026-01-12T09:32:15.747803"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1591.124, "latencies_ms": [1591.124], "images_per_second": 0.628, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. red double decker bus\n2. people\n3. trees\n4. buildings\n5. street\n6. license plate\n7. bus number\n8. bus route", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15557.5, "ram_available_mb": 106948.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15614.8, "ram_available_mb": 106891.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.71, 49.71, 49.71, 35.49, 35.49, 35.49, 35.49, 35.49, 48.49, 48.49, 48.49, 48.49, 48.49, 46.28, 46.28, 46.28], "power_watts_avg": 44.24, "power_watts_peak": 49.71, "energy_joules_est": 70.42, "sample_count": 16, "duration_seconds": 1.592}, "timestamp": "2026-01-12T09:32:17.364367"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1671.881, "latencies_ms": [1671.881], "images_per_second": 0.598, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The red double-decker bus is in the foreground, moving towards the left side of the image. The building in the background is far away from the camera, while the trees are closer to the bus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15612.9, "ram_available_mb": 106893.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15617.8, "ram_available_mb": 106888.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.28, 46.28, 30.93, 30.93, 30.93, 30.93, 30.93, 49.21, 49.21, 49.21, 49.21, 49.21, 50.63, 50.63, 50.63, 50.63, 50.63], "power_watts_avg": 43.91, "power_watts_peak": 50.63, "energy_joules_est": 73.42, "sample_count": 17, "duration_seconds": 1.672}, "timestamp": "2026-01-12T09:32:19.079869"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1317.38, "latencies_ms": [1317.38], "images_per_second": 0.759, "prompt_tokens": 1444, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street in a city, passing by a park with trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15617.8, "ram_available_mb": 106888.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15628.6, "ram_available_mb": 106877.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.34, 32.34, 32.34, 32.34, 32.34, 42.52, 42.52, 42.52, 42.52, 48.93, 48.93, 48.93, 48.93, 48.93], "power_watts_avg": 41.17, "power_watts_peak": 48.93, "energy_joules_est": 54.25, "sample_count": 14, "duration_seconds": 1.318}, "timestamp": "2026-01-12T09:32:20.492103"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1431.106, "latencies_ms": [1431.106], "images_per_second": 0.699, "prompt_tokens": 1442, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image features a red double-decker bus with a yellow stripe on the side, driving on a street with a cloudy sky and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15620.8, "ram_available_mb": 106885.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15627.1, "ram_available_mb": 106879.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [37.58, 37.58, 37.58, 37.58, 37.58, 45.33, 45.33, 45.33, 45.33, 45.33, 49.34, 49.34, 49.34, 49.34, 49.34], "power_watts_avg": 44.08, "power_watts_peak": 49.34, "energy_joules_est": 63.1, "sample_count": 15, "duration_seconds": 1.431}, "timestamp": "2026-01-12T09:32:22.002818"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 775.658, "latencies_ms": [775.658], "images_per_second": 1.289, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15627.1, "ram_available_mb": 106879.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15701.9, "ram_available_mb": 106804.4, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.4, 34.4, 34.4, 34.4, 34.4, 44.44, 44.44, 44.44], "power_watts_avg": 38.17, "power_watts_peak": 44.44, "energy_joules_est": 29.61, "sample_count": 8, "duration_seconds": 0.776}, "timestamp": "2026-01-12T09:32:22.812065"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2151.237, "latencies_ms": [2151.237], "images_per_second": 0.465, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. black and white cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. white wall: 1\n5. white baseboard: 1\n6. white door frame: 1\n7. white door: 1\n8. white wall panel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15701.9, "ram_available_mb": 106804.4, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15673.1, "ram_available_mb": 106833.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.44, 44.44, 47.27, 47.27, 47.27, 47.27, 47.27, 45.16, 45.16, 45.16, 45.16, 45.16, 43.67, 43.67, 43.67, 43.67, 43.67, 32.58, 32.58, 32.58, 32.58, 32.58], "power_watts_avg": 42.38, "power_watts_peak": 47.27, "energy_joules_est": 91.18, "sample_count": 22, "duration_seconds": 2.152}, "timestamp": "2026-01-12T09:32:25.027498"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1462.892, "latencies_ms": [1462.892], "images_per_second": 0.684, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The black and white cat is positioned to the left of the laptop, which is situated in the middle of the image. The laptop is located in the foreground, while the cat is in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15672.8, "ram_available_mb": 106833.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15653.6, "ram_available_mb": 106852.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.09, 32.09, 32.09, 32.09, 32.09, 42.87, 42.87, 42.87, 42.87, 42.87, 43.92, 43.92, 43.92, 43.92, 43.92], "power_watts_avg": 39.63, "power_watts_peak": 43.92, "energy_joules_est": 58.0, "sample_count": 15, "duration_seconds": 1.464}, "timestamp": "2026-01-12T09:32:26.587858"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 791.042, "latencies_ms": [791.042], "images_per_second": 1.264, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15653.6, "ram_available_mb": 106852.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 15701.1, "ram_available_mb": 106805.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [32.95, 32.95, 32.95, 32.95, 43.81, 43.81, 43.81, 43.81], "power_watts_avg": 38.38, "power_watts_peak": 43.81, "energy_joules_est": 30.38, "sample_count": 8, "duration_seconds": 0.792}, "timestamp": "2026-01-12T09:32:27.397261"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 756.443, "latencies_ms": [756.443], "images_per_second": 1.322, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is black and white, and the laptop is silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15693.5, "ram_available_mb": 106812.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15689.0, "ram_available_mb": 106817.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.81, 43.31, 43.31, 43.31, 43.31, 43.31, 46.26, 46.26], "power_watts_avg": 44.11, "power_watts_peak": 46.26, "energy_joules_est": 33.39, "sample_count": 8, "duration_seconds": 0.757}, "timestamp": "2026-01-12T09:32:28.206699"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 948.842, "latencies_ms": [948.842], "images_per_second": 1.054, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two airplanes fly over a bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15689.0, "ram_available_mb": 106817.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15590.6, "ram_available_mb": 106915.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 46.26, 52.85, 52.85, 52.85, 52.85, 52.85, 44.71, 44.71], "power_watts_avg": 49.25, "power_watts_peak": 52.85, "energy_joules_est": 46.74, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-12T09:32:29.220974"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1900.963, "latencies_ms": [1900.963], "images_per_second": 0.526, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. Airplane: 2\n2. Bridge: 1\n3. Building: 1\n4. City: 1\n5. Ocean: 1\n6. Sky: 1\n7. Clouds: 1\n8. Flags: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15590.6, "ram_available_mb": 106915.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15634.6, "ram_available_mb": 106871.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.71, 44.71, 44.71, 44.77, 44.77, 44.77, 44.77, 44.77, 44.58, 44.58, 44.58, 44.58, 44.58, 39.37, 39.37, 39.37, 39.37, 39.37, 32.67], "power_watts_avg": 42.65, "power_watts_peak": 44.77, "energy_joules_est": 81.09, "sample_count": 19, "duration_seconds": 1.901}, "timestamp": "2026-01-12T09:32:31.135489"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1402.598, "latencies_ms": [1402.598], "images_per_second": 0.713, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The two airplanes are flying above the Sydney Harbour Bridge, which is positioned in the foreground of the image. The Sydney Opera House is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15619.1, "ram_available_mb": 106887.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15631.4, "ram_available_mb": 106874.9, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.67, 32.67, 32.67, 39.14, 39.14, 39.14, 39.14, 39.14, 44.17, 44.17, 44.17, 44.17, 44.17, 38.44], "power_watts_avg": 39.5, "power_watts_peak": 44.17, "energy_joules_est": 55.42, "sample_count": 14, "duration_seconds": 1.403}, "timestamp": "2026-01-12T09:32:32.599264"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 974.076, "latencies_ms": [974.076], "images_per_second": 1.027, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two airplanes fly over a large bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15631.4, "ram_available_mb": 106874.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15670.3, "ram_available_mb": 106836.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.44, 38.44, 38.44, 38.44, 43.53, 43.53, 43.53, 43.53, 43.53, 45.41], "power_watts_avg": 41.68, "power_watts_peak": 45.41, "energy_joules_est": 40.62, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-12T09:32:33.611076"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 950.169, "latencies_ms": [950.169], "images_per_second": 1.052, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the bridge is a dark brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15670.3, "ram_available_mb": 106836.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15670.1, "ram_available_mb": 106836.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.41, 45.41, 45.41, 45.41, 44.51, 44.51, 44.51, 44.51, 44.51, 44.76], "power_watts_avg": 44.9, "power_watts_peak": 45.41, "energy_joules_est": 42.67, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-12T09:32:34.624377"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 733.091, "latencies_ms": [733.091], "images_per_second": 1.364, "prompt_tokens": 1099, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A black and white photo of a zebra nursing its young.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15669.1, "ram_available_mb": 106837.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15648.6, "ram_available_mb": 106857.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.76, 44.76, 44.76, 44.76, 44.92, 44.92, 44.92, 44.92], "power_watts_avg": 44.84, "power_watts_peak": 44.92, "energy_joules_est": 32.89, "sample_count": 8, "duration_seconds": 0.733}, "timestamp": "2026-01-12T09:32:35.435070"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 818.954, "latencies_ms": [818.954], "images_per_second": 1.221, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " zebra: 1\nbaby zebra: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15644.7, "ram_available_mb": 106861.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15642.3, "ram_available_mb": 106864.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.92, 42.07, 42.07, 42.07, 42.07, 42.07, 46.99, 46.99, 46.99], "power_watts_avg": 44.03, "power_watts_peak": 46.99, "energy_joules_est": 36.07, "sample_count": 9, "duration_seconds": 0.819}, "timestamp": "2026-01-12T09:32:36.346564"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2151.475, "latencies_ms": [2151.475], "images_per_second": 0.465, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The zebra is positioned on the left side of the image, with its body facing towards the right side. The baby zebra is positioned on the right side of the image, with its body facing towards the left side. The baby zebra is positioned very close to the mother zebra, with its head near the mother's udder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15634.4, "ram_available_mb": 106871.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15616.1, "ram_available_mb": 106890.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.99, 46.99, 45.03, 45.03, 45.03, 45.03, 45.03, 43.77, 43.77, 43.77, 43.77, 43.77, 45.15, 45.15, 45.15, 45.15, 45.15, 32.49, 32.49, 32.49, 32.49, 32.49], "power_watts_avg": 42.1, "power_watts_peak": 46.99, "energy_joules_est": 90.6, "sample_count": 22, "duration_seconds": 2.152}, "timestamp": "2026-01-12T09:32:38.567487"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 766.058, "latencies_ms": [766.058], "images_per_second": 1.305, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A zebra is nursing its young in a field of tall grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15616.1, "ram_available_mb": 106890.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15613.1, "ram_available_mb": 106893.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [32.46, 32.46, 32.46, 32.46, 32.46, 44.04, 44.04, 44.04], "power_watts_avg": 36.8, "power_watts_peak": 44.04, "energy_joules_est": 28.2, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-12T09:32:39.378462"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1528.399, "latencies_ms": [1528.399], "images_per_second": 0.654, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is in black and white, with the zebra's stripes standing out against the white background. The lighting is natural, coming from the side, casting shadows and highlighting the texture of the zebra's fur.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15609.2, "ram_available_mb": 106897.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15606.7, "ram_available_mb": 106899.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [44.04, 44.04, 42.99, 42.99, 42.99, 42.99, 42.99, 45.19, 45.19, 45.19, 45.19, 45.19, 47.07, 47.07, 47.07, 47.07], "power_watts_avg": 44.83, "power_watts_peak": 47.07, "energy_joules_est": 68.53, "sample_count": 16, "duration_seconds": 1.529}, "timestamp": "2026-01-12T09:32:40.995016"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1295.707, "latencies_ms": [1295.707], "images_per_second": 0.772, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a room with a bed, a small round table, and a chair, all placed in front of a window with a view of a building outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15604.8, "ram_available_mb": 106901.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15604.5, "ram_available_mb": 106901.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [31.01, 31.01, 31.01, 31.01, 31.01, 43.7, 43.7, 43.7, 43.7, 43.7, 45.38, 45.38, 45.38], "power_watts_avg": 39.2, "power_watts_peak": 45.38, "energy_joules_est": 50.8, "sample_count": 13, "duration_seconds": 1.296}, "timestamp": "2026-01-12T09:32:42.309469"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1901.453, "latencies_ms": [1901.453], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. chair: 2\n3. table: 1\n4. window: 2\n5. door: 1\n6. floor: 1\n7. wall: 1\n8. rug: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15596.6, "ram_available_mb": 106909.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15514.3, "ram_available_mb": 106992.0, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.38, 45.38, 34.21, 34.21, 34.21, 34.21, 34.21, 45.31, 45.31, 45.31, 45.31, 45.31, 43.49, 43.49, 43.49, 43.49, 43.49, 32.41, 32.41], "power_watts_avg": 40.56, "power_watts_peak": 45.38, "energy_joules_est": 77.13, "sample_count": 19, "duration_seconds": 1.902}, "timestamp": "2026-01-12T09:32:44.226600"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1601.442, "latencies_ms": [1601.442], "images_per_second": 0.624, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the window and door to the left and right, respectively. The table and chairs are located in the foreground, while the purple wall and window are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15514.3, "ram_available_mb": 106992.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15564.3, "ram_available_mb": 106942.0, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.41, 32.41, 32.41, 34.97, 34.97, 34.97, 34.97, 34.97, 44.46, 44.46, 44.46, 44.46, 44.46, 41.87, 41.87, 41.87], "power_watts_avg": 38.75, "power_watts_peak": 44.46, "energy_joules_est": 62.09, "sample_count": 16, "duration_seconds": 1.602}, "timestamp": "2026-01-12T09:32:45.892739"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 791.181, "latencies_ms": [791.181], "images_per_second": 1.264, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A small room with a bed, a table, and a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15556.4, "ram_available_mb": 106949.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15580.2, "ram_available_mb": 106926.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 45.0}, "power_stats": {"power_watts_samples": [41.87, 31.14, 31.14, 31.14, 31.14, 31.14, 45.58, 45.58], "power_watts_avg": 36.09, "power_watts_peak": 45.58, "energy_joules_est": 28.57, "sample_count": 8, "duration_seconds": 0.791}, "timestamp": "2026-01-12T09:32:46.702648"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 786.629, "latencies_ms": [786.629], "images_per_second": 1.271, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The room is painted purple, and the bed has a colorful quilt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15580.2, "ram_available_mb": 106926.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15573.2, "ram_available_mb": 106933.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.58, 45.58, 45.58, 53.9, 53.9, 53.9, 53.9, 53.9], "power_watts_avg": 50.78, "power_watts_peak": 53.9, "energy_joules_est": 39.96, "sample_count": 8, "duration_seconds": 0.787}, "timestamp": "2026-01-12T09:32:47.512082"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 860.458, "latencies_ms": [860.458], "images_per_second": 1.162, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down the street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15569.3, "ram_available_mb": 106937.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15569.1, "ram_available_mb": 106937.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [45.3, 45.3, 45.3, 45.3, 45.3, 52.2, 52.2, 52.2, 52.2], "power_watts_avg": 48.37, "power_watts_peak": 52.2, "energy_joules_est": 41.63, "sample_count": 9, "duration_seconds": 0.861}, "timestamp": "2026-01-12T09:32:48.425135"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1886.67, "latencies_ms": [1886.67], "images_per_second": 0.53, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. person: 1\n3. pole: 1\n4. sign: 1\n5. tree: 1\n6. building: 1\n7. street: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15569.1, "ram_available_mb": 106937.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15574.9, "ram_available_mb": 106931.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [52.2, 43.27, 43.27, 43.27, 43.27, 43.27, 45.1, 45.1, 45.1, 45.1, 45.1, 47.18, 47.18, 47.18, 47.18, 47.18, 32.53, 32.53, 32.53], "power_watts_avg": 43.55, "power_watts_peak": 52.2, "energy_joules_est": 82.18, "sample_count": 19, "duration_seconds": 1.887}, "timestamp": "2026-01-12T09:32:50.341576"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1443.506, "latencies_ms": [1443.506], "images_per_second": 0.693, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The sidewalk is located in the foreground, while the background features a brick building and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15567.0, "ram_available_mb": 106939.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15578.3, "ram_available_mb": 106928.0, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [32.53, 30.29, 30.29, 30.29, 30.29, 30.29, 44.16, 44.16, 44.16, 44.16, 44.16, 47.13, 47.13, 47.13, 47.13], "power_watts_avg": 39.55, "power_watts_peak": 47.13, "energy_joules_est": 57.12, "sample_count": 15, "duration_seconds": 1.444}, "timestamp": "2026-01-12T09:32:51.907429"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 869.125, "latencies_ms": [869.125], "images_per_second": 1.151, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down a street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15574.4, "ram_available_mb": 106931.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15591.7, "ram_available_mb": 106914.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 11.0}, "power_stats": {"power_watts_samples": [47.13, 29.83, 29.83, 29.83, 29.83, 29.83, 44.42, 44.42, 44.42], "power_watts_avg": 36.61, "power_watts_peak": 47.13, "energy_joules_est": 31.83, "sample_count": 9, "duration_seconds": 0.869}, "timestamp": "2026-01-12T09:32:52.818226"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1167.975, "latencies_ms": [1167.975], "images_per_second": 0.856, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The bus is purple with a white roof and has a white license plate. The sky is clear and blue, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15591.7, "ram_available_mb": 106914.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15632.1, "ram_available_mb": 106874.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.42, 44.42, 48.84, 48.84, 48.84, 48.84, 48.84, 45.4, 45.4, 45.4, 45.4, 45.4], "power_watts_avg": 46.67, "power_watts_peak": 48.84, "energy_joules_est": 54.53, "sample_count": 12, "duration_seconds": 1.168}, "timestamp": "2026-01-12T09:32:54.028116"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1003.146, "latencies_ms": [1003.146], "images_per_second": 0.997, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image features a white bowl filled with green apples, with a few apples placed on top of the bowl.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15632.1, "ram_available_mb": 106874.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15612.8, "ram_available_mb": 106893.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.47, 44.47, 44.47, 44.47, 44.47, 45.07, 45.07, 45.07, 45.07, 45.07], "power_watts_avg": 44.77, "power_watts_peak": 45.07, "energy_joules_est": 44.93, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-12T09:32:55.037353"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 551.892, "latencies_ms": [551.892], "images_per_second": 1.812, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " apple: 10", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15612.8, "ram_available_mb": 106893.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 15614.7, "ram_available_mb": 106891.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.97, 44.97, 44.97, 44.97, 44.97, 45.59], "power_watts_avg": 45.07, "power_watts_peak": 45.59, "energy_joules_est": 24.88, "sample_count": 6, "duration_seconds": 0.552}, "timestamp": "2026-01-12T09:32:55.646671"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1312.931, "latencies_ms": [1312.931], "images_per_second": 0.762, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The apples are in the foreground, with the bowl placed in the middle of the image. The bowl is located in the foreground, and the apples are placed inside it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15614.7, "ram_available_mb": 106891.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15622.7, "ram_available_mb": 106883.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.59, 45.59, 45.59, 45.59, 54.31, 54.31, 54.31, 54.31, 54.31, 44.98, 44.98, 44.98, 44.98, 44.98], "power_watts_avg": 48.49, "power_watts_peak": 54.31, "energy_joules_est": 63.68, "sample_count": 14, "duration_seconds": 1.313}, "timestamp": "2026-01-12T09:32:57.059144"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1148.892, "latencies_ms": [1148.892], "images_per_second": 0.87, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a dimly lit room, a white bowl cradles a collection of vibrant green apples, their glossy skins reflecting the soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15618.8, "ram_available_mb": 106887.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15634.5, "ram_available_mb": 106871.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.41, 36.41, 36.41, 36.41, 36.41, 43.98, 43.98, 43.98, 43.98, 43.98, 44.59, 44.59], "power_watts_avg": 40.93, "power_watts_peak": 44.59, "energy_joules_est": 47.03, "sample_count": 12, "duration_seconds": 1.149}, "timestamp": "2026-01-12T09:32:58.270020"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 759.436, "latencies_ms": [759.436], "images_per_second": 1.317, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The apples are green and shiny, and the bowl is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15634.5, "ram_available_mb": 106871.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15664.8, "ram_available_mb": 106841.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.59, 44.59, 44.59, 36.21, 36.21, 36.21, 36.21, 36.21], "power_watts_avg": 39.35, "power_watts_peak": 44.59, "energy_joules_est": 29.9, "sample_count": 8, "duration_seconds": 0.76}, "timestamp": "2026-01-12T09:32:59.078497"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1280.258, "latencies_ms": [1280.258], "images_per_second": 0.781, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter, catcher, and umpire all in position, ready to react to the pitch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15664.8, "ram_available_mb": 106841.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15658.1, "ram_available_mb": 106848.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.66, 44.66, 44.66, 44.66, 44.66, 53.95, 53.95, 53.95, 53.95, 53.95, 45.21, 45.21, 45.21], "power_watts_avg": 48.36, "power_watts_peak": 53.95, "energy_joules_est": 61.96, "sample_count": 13, "duration_seconds": 1.281}, "timestamp": "2026-01-12T09:33:00.393863"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1981.381, "latencies_ms": [1981.381], "images_per_second": 0.505, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. grass: 1\n7. dirt: 1\n8. net: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15646.3, "ram_available_mb": 106860.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 15640.4, "ram_available_mb": 106865.9, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.21, 31.44, 31.44, 31.44, 31.44, 31.44, 45.4, 45.4, 45.4, 45.4, 45.4, 47.19, 47.19, 47.19, 47.19, 47.19, 32.79, 32.79, 32.79, 32.79], "power_watts_avg": 39.83, "power_watts_peak": 47.19, "energy_joules_est": 78.92, "sample_count": 20, "duration_seconds": 1.982}, "timestamp": "2026-01-12T09:33:02.413637"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1409.477, "latencies_ms": [1409.477], "images_per_second": 0.709, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The pitcher is standing on the mound, which is located in the middle of the field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15632.5, "ram_available_mb": 106873.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15641.7, "ram_available_mb": 106864.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [32.79, 30.64, 30.64, 30.64, 30.64, 30.64, 44.34, 44.34, 44.34, 44.34, 44.34, 45.83, 45.83, 45.83, 45.83], "power_watts_avg": 39.4, "power_watts_peak": 45.83, "energy_joules_est": 55.57, "sample_count": 15, "duration_seconds": 1.41}, "timestamp": "2026-01-12T09:33:03.976294"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2450.275, "latencies_ms": [2450.275], "images_per_second": 0.408, "prompt_tokens": 1111, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment in a baseball game, with the batter, wearing a red helmet and white uniform, in the midst of swinging his bat at a pitch. The umpire, dressed in a blue shirt and black pants, stands behind the catcher, who is crouched in anticipation. The field is a vibrant green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15625.9, "ram_available_mb": 106880.4, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15635.1, "ram_available_mb": 106871.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.83, 30.67, 30.67, 30.67, 30.67, 30.67, 44.22, 44.22, 44.22, 44.22, 44.22, 46.33, 46.33, 46.33, 46.33, 46.33, 32.72, 32.72, 32.72, 32.72, 32.72, 32.62, 32.62, 32.62, 32.62], "power_watts_avg": 37.84, "power_watts_peak": 46.33, "energy_joules_est": 92.74, "sample_count": 25, "duration_seconds": 2.451}, "timestamp": "2026-01-12T09:33:06.493410"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2246.703, "latencies_ms": [2246.703], "images_per_second": 0.445, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the lush green of the field contrasting against the brown dirt of the infield. The players are dressed in crisp white uniforms, their red helmets adding a pop of color to the scene. The lighting is natural, casting a warm glow over the field as the sun shines down on the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15631.1, "ram_available_mb": 106875.2, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15619.9, "ram_available_mb": 106886.4, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [31.59, 31.59, 31.59, 31.59, 31.59, 43.78, 43.78, 43.78, 43.78, 43.78, 44.85, 44.85, 44.85, 44.85, 44.85, 32.63, 32.63, 32.63, 32.63, 32.63, 32.69, 32.69, 32.69], "power_watts_avg": 37.49, "power_watts_peak": 44.85, "energy_joules_est": 84.24, "sample_count": 23, "duration_seconds": 2.247}, "timestamp": "2026-01-12T09:33:08.858823"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1228.945, "latencies_ms": [1228.945], "images_per_second": 0.814, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white cake with red and blue berries is on a table with a red tablecloth, surrounded by wine glasses, plates of cheese, and bread.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15612.9, "ram_available_mb": 106893.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 15624.8, "ram_available_mb": 106881.5, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.69, 28.98, 28.98, 28.98, 28.98, 28.98, 43.12, 43.12, 43.12, 43.12, 43.12, 47.02, 47.02], "power_watts_avg": 37.48, "power_watts_peak": 47.02, "energy_joules_est": 46.09, "sample_count": 13, "duration_seconds": 1.23}, "timestamp": "2026-01-12T09:33:10.223099"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1372.068, "latencies_ms": [1372.068], "images_per_second": 0.729, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cake: 1, glasses: 10, plates: 10, knives: 2, cups: 1, bowls: 1, grapes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15624.8, "ram_available_mb": 106881.5, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15683.7, "ram_available_mb": 106822.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.02, 47.02, 47.02, 37.01, 37.01, 37.01, 37.01, 37.01, 44.33, 44.33, 44.33, 44.33, 44.33, 39.7], "power_watts_avg": 41.96, "power_watts_peak": 47.02, "energy_joules_est": 57.59, "sample_count": 14, "duration_seconds": 1.372}, "timestamp": "2026-01-12T09:33:11.634908"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1977.403, "latencies_ms": [1977.403], "images_per_second": 0.506, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The cake is located in the foreground, to the left of the plates of cheese and grapes. The plates of cheese and grapes are positioned in the middle of the table, with the cake to the left of them. The glasses are located in the background, behind the plates of cheese and grapes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15683.7, "ram_available_mb": 106822.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15649.2, "ram_available_mb": 106857.1, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.7, 39.7, 39.7, 39.7, 41.43, 41.43, 41.43, 41.43, 41.43, 44.94, 44.94, 44.94, 44.94, 44.94, 36.16, 36.16, 36.16, 36.16, 36.16, 32.56], "power_watts_avg": 40.2, "power_watts_peak": 44.94, "energy_joules_est": 79.51, "sample_count": 20, "duration_seconds": 1.978}, "timestamp": "2026-01-12T09:33:13.650102"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 872.869, "latencies_ms": [872.869], "images_per_second": 1.146, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A table is set with a cake, plates of food, and glasses of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15649.2, "ram_available_mb": 106857.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15702.3, "ram_available_mb": 106804.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [32.56, 32.56, 32.56, 38.12, 38.12, 38.12, 38.12, 38.12, 44.2], "power_watts_avg": 36.94, "power_watts_peak": 44.2, "energy_joules_est": 32.28, "sample_count": 9, "duration_seconds": 0.874}, "timestamp": "2026-01-12T09:33:14.612621"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1211.385, "latencies_ms": [1211.385], "images_per_second": 0.826, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The table is covered with a red tablecloth, and the food is arranged on white plates. The lighting is natural, and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15698.6, "ram_available_mb": 106807.7, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15687.4, "ram_available_mb": 106818.9, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.2, 44.2, 44.2, 44.2, 48.55, 48.55, 48.55, 48.55, 48.55, 44.97, 44.97, 44.97, 44.97], "power_watts_avg": 46.11, "power_watts_peak": 48.55, "energy_joules_est": 55.87, "sample_count": 13, "duration_seconds": 1.212}, "timestamp": "2026-01-12T09:33:15.925451"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 822.404, "latencies_ms": [822.404], "images_per_second": 1.216, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is riding a wave on a blue surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15679.5, "ram_available_mb": 106826.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 15704.5, "ram_available_mb": 106801.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [44.97, 33.02, 33.02, 33.02, 33.02, 33.02, 43.74, 43.74, 43.74], "power_watts_avg": 37.92, "power_watts_peak": 44.97, "energy_joules_est": 31.19, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-12T09:33:16.838676"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1918.405, "latencies_ms": [1918.405], "images_per_second": 0.521, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. sand: 0\n7. sky: 0\n8. clouds: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15696.7, "ram_available_mb": 106809.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15674.1, "ram_available_mb": 106832.2, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.74, 43.74, 46.45, 46.45, 46.45, 46.45, 46.45, 44.12, 44.12, 44.12, 44.12, 44.12, 44.88, 44.88, 44.88, 44.88, 44.88, 32.62, 32.62, 32.62], "power_watts_avg": 43.13, "power_watts_peak": 46.45, "energy_joules_est": 82.76, "sample_count": 20, "duration_seconds": 1.919}, "timestamp": "2026-01-12T09:33:18.857896"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1474.155, "latencies_ms": [1474.155], "images_per_second": 0.678, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave in the background. The surfer is on the left side of the wave, and the wave is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15659.4, "ram_available_mb": 106846.9, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15697.0, "ram_available_mb": 106809.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.62, 28.31, 28.31, 28.31, 28.31, 28.31, 43.09, 43.09, 43.09, 43.09, 43.09, 47.46, 47.46, 47.46, 47.46], "power_watts_avg": 38.63, "power_watts_peak": 47.46, "energy_joules_est": 56.97, "sample_count": 15, "duration_seconds": 1.475}, "timestamp": "2026-01-12T09:33:20.422308"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 793.462, "latencies_ms": [793.462], "images_per_second": 1.26, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15697.3, "ram_available_mb": 106809.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15689.9, "ram_available_mb": 106816.4, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.46, 30.68, 30.68, 30.68, 30.68, 30.68, 44.9, 44.9], "power_watts_avg": 36.34, "power_watts_peak": 47.46, "energy_joules_est": 28.84, "sample_count": 8, "duration_seconds": 0.794}, "timestamp": "2026-01-12T09:33:21.231599"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1720.88, "latencies_ms": [1720.88], "images_per_second": 0.581, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a surfer in a black wetsuit riding a wave on a blue surfboard, with the ocean's green water and white foam of the wave in the background. The lighting is natural and bright, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15682.0, "ram_available_mb": 106824.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 15602.6, "ram_available_mb": 106903.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.9, 44.9, 44.9, 52.77, 52.77, 52.77, 52.77, 52.77, 45.67, 45.67, 45.67, 45.67, 45.67, 39.92, 39.92, 39.92, 39.92, 39.92], "power_watts_avg": 45.92, "power_watts_peak": 52.77, "energy_joules_est": 79.04, "sample_count": 18, "duration_seconds": 1.721}, "timestamp": "2026-01-12T09:33:23.045545"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 912.815, "latencies_ms": [912.815], "images_per_second": 1.096, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15602.2, "ram_available_mb": 106904.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15631.0, "ram_available_mb": 106875.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.03, 32.03, 32.03, 32.03, 32.03, 44.16, 44.16, 44.16, 44.16, 44.16], "power_watts_avg": 38.1, "power_watts_peak": 44.16, "energy_joules_est": 34.8, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-12T09:33:24.057164"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1641.433, "latencies_ms": [1641.433], "images_per_second": 0.609, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. group of children\n2. brick wall\n3. children's clothing\n4. children's shoes\n5. children's hair\n6. children's faces\n7. children's eyes\n8. children's noses", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15630.7, "ram_available_mb": 106875.6, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15622.6, "ram_available_mb": 106883.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.51, 44.51, 44.51, 44.51, 44.51, 43.95, 43.95, 43.95, 43.95, 43.95, 44.64, 44.64, 44.64, 44.64, 44.64, 33.08, 33.08], "power_watts_avg": 43.04, "power_watts_peak": 44.64, "energy_joules_est": 70.66, "sample_count": 17, "duration_seconds": 1.642}, "timestamp": "2026-01-12T09:33:25.768543"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1606.325, "latencies_ms": [1606.325], "images_per_second": 0.623, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The group of children is positioned in front of a brick building, with the children arranged in a grid-like formation. The children are standing and sitting in various poses, with some children positioned closer to the camera than others.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15614.7, "ram_available_mb": 106891.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15605.4, "ram_available_mb": 106900.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.08, 33.08, 33.08, 35.63, 35.63, 35.63, 35.63, 35.63, 44.62, 44.62, 44.62, 44.62, 44.62, 42.61, 42.61, 42.61], "power_watts_avg": 39.27, "power_watts_peak": 44.62, "energy_joules_est": 63.1, "sample_count": 16, "duration_seconds": 1.607}, "timestamp": "2026-01-12T09:33:27.381203"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.327, "latencies_ms": [933.327], "images_per_second": 1.071, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15601.4, "ram_available_mb": 106904.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15517.9, "ram_available_mb": 106988.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.61, 42.61, 31.54, 31.54, 31.54, 31.54, 31.54, 45.85, 45.85, 45.85], "power_watts_avg": 38.05, "power_watts_peak": 45.85, "energy_joules_est": 35.51, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T09:33:28.390444"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1992.309, "latencies_ms": [1992.309], "images_per_second": 0.502, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is a black and white photograph with a grainy texture, capturing a moment of unity among the children. The lighting is soft and diffused, creating a sense of nostalgia and warmth. The children are dressed in their school uniforms, which are predominantly white and black, suggesting a formal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15517.9, "ram_available_mb": 106988.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15563.7, "ram_available_mb": 106942.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.85, 45.85, 44.92, 44.92, 44.92, 44.92, 44.92, 44.43, 44.43, 44.43, 44.43, 44.43, 47.05, 47.05, 47.05, 47.05, 32.71, 32.71, 32.71, 32.71], "power_watts_avg": 42.87, "power_watts_peak": 47.05, "energy_joules_est": 85.42, "sample_count": 20, "duration_seconds": 1.992}, "timestamp": "2026-01-12T09:33:30.410199"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 898.539, "latencies_ms": [898.539], "images_per_second": 1.113, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate of bread and a knife on a table with a wine glass in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15564.4, "ram_available_mb": 106941.9, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15562.9, "ram_available_mb": 106943.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.71, 30.81, 30.81, 30.81, 30.81, 30.81, 45.19, 45.19, 45.19], "power_watts_avg": 35.81, "power_watts_peak": 45.19, "energy_joules_est": 32.2, "sample_count": 9, "duration_seconds": 0.899}, "timestamp": "2026-01-12T09:33:31.322157"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1380.482, "latencies_ms": [1380.482], "images_per_second": 0.724, "prompt_tokens": 1114, "response_tokens_est": 36, "n_tiles": 1, "output_text": " knife: 1, plate: 1, bread: 1, cup: 1, wine glass: 1, napkin: 1, butter: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15562.9, "ram_available_mb": 106943.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15565.0, "ram_available_mb": 106941.3, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.19, 45.19, 48.77, 48.77, 48.77, 48.77, 48.77, 45.71, 45.71, 45.71, 45.71, 45.71, 44.97, 44.97], "power_watts_avg": 46.62, "power_watts_peak": 48.77, "energy_joules_est": 64.37, "sample_count": 14, "duration_seconds": 1.381}, "timestamp": "2026-01-12T09:33:32.736654"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1943.869, "latencies_ms": [1943.869], "images_per_second": 0.514, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the bread, knife, and wine glass in the background. The bread is placed on the left side of the plate, while the knife is on the right side. The wine glass is located in the upper right corner of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15557.1, "ram_available_mb": 106949.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15563.3, "ram_available_mb": 106943.0, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.97, 44.97, 44.97, 37.22, 37.22, 37.22, 37.22, 37.22, 45.25, 45.25, 45.25, 45.25, 45.25, 40.41, 40.41, 40.41, 40.41, 40.41, 32.57, 32.57], "power_watts_avg": 40.72, "power_watts_peak": 45.25, "energy_joules_est": 79.17, "sample_count": 20, "duration_seconds": 1.944}, "timestamp": "2026-01-12T09:33:34.754915"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1090.281, "latencies_ms": [1090.281], "images_per_second": 0.917, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In a cozy restaurant, a plate of bread and cheese is served on a table, accompanied by a glass of red wine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15563.3, "ram_available_mb": 106943.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15650.3, "ram_available_mb": 106856.0, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 30.0}, "power_stats": {"power_watts_samples": [32.57, 32.57, 32.32, 32.32, 32.32, 32.32, 32.32, 43.23, 43.23, 43.23, 43.23], "power_watts_avg": 36.34, "power_watts_peak": 43.23, "energy_joules_est": 39.64, "sample_count": 11, "duration_seconds": 1.091}, "timestamp": "2026-01-12T09:33:35.915802"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1266.576, "latencies_ms": [1266.576], "images_per_second": 0.79, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a knife, and a wine glass. The lighting is natural, and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15650.3, "ram_available_mb": 106856.0, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15541.6, "ram_available_mb": 106964.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.23, 42.71, 42.71, 42.71, 42.71, 42.71, 45.32, 45.32, 45.32, 45.32, 45.32, 47.03, 47.03], "power_watts_avg": 44.42, "power_watts_peak": 47.03, "energy_joules_est": 56.28, "sample_count": 13, "duration_seconds": 1.267}, "timestamp": "2026-01-12T09:33:37.228015"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1159.576, "latencies_ms": [1159.576], "images_per_second": 0.862, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A skier in a colorful outfit is jumping in the air with skis attached, while another skier in a white outfit stands nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15541.6, "ram_available_mb": 106964.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15555.7, "ram_available_mb": 106950.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.03, 47.03, 47.03, 38.82, 38.82, 38.82, 38.82, 38.82, 44.84, 44.84, 44.84, 44.84], "power_watts_avg": 42.88, "power_watts_peak": 47.03, "energy_joules_est": 49.75, "sample_count": 12, "duration_seconds": 1.16}, "timestamp": "2026-01-12T09:33:38.441742"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1981.294, "latencies_ms": [1981.294], "images_per_second": 0.505, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snow: 1\n5. trees: 4\n6. person: 1\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15555.7, "ram_available_mb": 106950.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15559.5, "ram_available_mb": 106946.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.84, 37.7, 37.7, 37.7, 37.7, 37.7, 45.16, 45.16, 45.16, 45.16, 45.16, 47.31, 47.31, 47.31, 47.31, 47.31, 32.7, 32.7, 32.7, 32.7], "power_watts_avg": 41.32, "power_watts_peak": 47.31, "energy_joules_est": 81.89, "sample_count": 20, "duration_seconds": 1.982}, "timestamp": "2026-01-12T09:33:40.456970"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1314.794, "latencies_ms": [1314.794], "images_per_second": 0.761, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The skier is in the foreground, jumping over a snow ramp, while the trees are in the background. The skier is closer to the camera than the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15559.2, "ram_available_mb": 106947.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15637.6, "ram_available_mb": 106868.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [31.01, 31.01, 31.01, 31.01, 31.01, 44.3, 44.3, 44.3, 44.3, 44.3, 46.01, 46.01, 46.01, 46.01], "power_watts_avg": 40.05, "power_watts_peak": 46.01, "energy_joules_est": 52.68, "sample_count": 14, "duration_seconds": 1.315}, "timestamp": "2026-01-12T09:33:41.918752"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1178.872, "latencies_ms": [1178.872], "images_per_second": 0.848, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A skier is jumping in the air with skis attached to their feet, while another skier is standing on the snow-covered slope.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15637.6, "ram_available_mb": 106868.7, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15637.6, "ram_available_mb": 106868.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.01, 29.46, 29.46, 29.46, 29.46, 29.46, 43.99, 43.99, 43.99, 43.99, 43.99, 47.69], "power_watts_avg": 38.42, "power_watts_peak": 47.69, "energy_joules_est": 45.32, "sample_count": 12, "duration_seconds": 1.18}, "timestamp": "2026-01-12T09:33:43.129324"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1500.387, "latencies_ms": [1500.387], "images_per_second": 0.666, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a skier in mid-air against a backdrop of a clear blue sky and snow-covered trees. The skier is wearing a colorful jacket and pants, and is holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15637.6, "ram_available_mb": 106868.7, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15536.4, "ram_available_mb": 106969.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.69, 47.69, 47.69, 47.69, 43.14, 43.14, 43.14, 43.14, 43.14, 45.23, 45.23, 45.23, 45.23, 45.23, 35.01], "power_watts_avg": 44.51, "power_watts_peak": 47.69, "energy_joules_est": 66.79, "sample_count": 15, "duration_seconds": 1.501}, "timestamp": "2026-01-12T09:33:44.642332"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1179.182, "latencies_ms": [1179.182], "images_per_second": 0.848, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain with ski poles, wearing a green shirt and black pants, and the sky is blue with some clouds.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 15536.9, "ram_available_mb": 106969.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15614.7, "ram_available_mb": 106891.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 35.01, 35.01, 43.17, 43.17, 43.17, 43.17, 43.17, 45.6, 45.6, 45.6], "power_watts_avg": 41.06, "power_watts_peak": 45.6, "energy_joules_est": 48.42, "sample_count": 12, "duration_seconds": 1.179}, "timestamp": "2026-01-12T09:33:45.856990"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1907.745, "latencies_ms": [1907.745], "images_per_second": 0.524, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. ski poles: 2\n3. backpack: 1\n4. snow: 1\n5. rocks: 1\n6. trees: 1\n7. clouds: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15604.1, "ram_available_mb": 106902.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 15594.5, "ram_available_mb": 106911.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.6, 45.6, 36.96, 36.96, 36.96, 36.96, 36.96, 45.54, 45.54, 45.54, 45.54, 45.54, 44.72, 44.72, 44.72, 44.72, 44.72, 32.94, 32.94], "power_watts_avg": 41.75, "power_watts_peak": 45.6, "energy_joules_est": 79.65, "sample_count": 19, "duration_seconds": 1.908}, "timestamp": "2026-01-12T09:33:47.773158"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1467.62, "latencies_ms": [1467.62], "images_per_second": 0.681, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is in the foreground, with the snow-covered landscape stretching out into the background. The person is standing on a rocky outcropping, with the snow-covered mountains in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15586.6, "ram_available_mb": 106919.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15588.4, "ram_available_mb": 106917.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.94, 32.94, 34.64, 34.64, 34.64, 34.64, 34.64, 45.01, 45.01, 45.01, 45.01, 45.01, 43.38, 43.38, 43.38], "power_watts_avg": 39.62, "power_watts_peak": 45.01, "energy_joules_est": 58.18, "sample_count": 15, "duration_seconds": 1.469}, "timestamp": "2026-01-12T09:33:49.336698"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 981.477, "latencies_ms": [981.477], "images_per_second": 1.019, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain trail with ski poles, wearing a green jacket and black pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15580.5, "ram_available_mb": 106925.8, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15596.7, "ram_available_mb": 106909.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.38, 43.38, 33.99, 33.99, 33.99, 33.99, 33.99, 45.21, 45.21, 45.21], "power_watts_avg": 39.23, "power_watts_peak": 45.21, "energy_joules_est": 38.51, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T09:33:50.348921"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1657.654, "latencies_ms": [1657.654], "images_per_second": 0.603, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person wearing a green jacket and black pants, standing on a snowy mountain with a clear blue sky and white clouds in the background. The snow is pristine and untouched, with the person's footprints visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15596.7, "ram_available_mb": 106909.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15584.8, "ram_available_mb": 106921.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.21, 45.21, 45.7, 45.7, 45.7, 45.7, 45.7, 45.61, 45.61, 45.61, 45.61, 45.61, 44.54, 44.54, 44.54, 44.54, 44.54], "power_watts_avg": 45.27, "power_watts_peak": 45.7, "energy_joules_est": 75.06, "sample_count": 17, "duration_seconds": 1.658}, "timestamp": "2026-01-12T09:33:52.066238"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 787.58, "latencies_ms": [787.58], "images_per_second": 1.27, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A banana and a chocolate donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15576.9, "ram_available_mb": 106929.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15591.1, "ram_available_mb": 106915.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.81, 32.81, 32.81, 32.81, 32.81, 44.84, 44.84, 44.84], "power_watts_avg": 37.32, "power_watts_peak": 44.84, "energy_joules_est": 29.41, "sample_count": 8, "duration_seconds": 0.788}, "timestamp": "2026-01-12T09:33:52.878434"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 834.004, "latencies_ms": [834.004], "images_per_second": 1.199, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " banana: 1, donut: 1, plastic bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15583.2, "ram_available_mb": 106923.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15607.7, "ram_available_mb": 106898.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 27.0}, "power_stats": {"power_watts_samples": [44.84, 44.84, 45.27, 45.27, 45.27, 45.27, 45.27, 45.73, 45.73], "power_watts_avg": 45.28, "power_watts_peak": 45.73, "energy_joules_est": 37.79, "sample_count": 9, "duration_seconds": 0.835}, "timestamp": "2026-01-12T09:33:53.789031"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1387.674, "latencies_ms": [1387.674], "images_per_second": 0.721, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The banana is positioned to the left of the donut, which is in the center of the image. The banana is in the foreground, while the donut is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15607.7, "ram_available_mb": 106898.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15581.6, "ram_available_mb": 106924.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.73, 45.73, 45.73, 49.34, 49.34, 49.34, 49.34, 49.34, 44.88, 44.88, 44.88, 44.88, 44.88, 41.97], "power_watts_avg": 46.45, "power_watts_peak": 49.34, "energy_joules_est": 64.47, "sample_count": 14, "duration_seconds": 1.388}, "timestamp": "2026-01-12T09:33:55.202709"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 759.723, "latencies_ms": [759.723], "images_per_second": 1.316, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and a donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15573.7, "ram_available_mb": 106932.6, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15586.8, "ram_available_mb": 106919.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.97, 41.97, 41.97, 41.97, 40.73, 40.73, 40.73, 40.73], "power_watts_avg": 41.35, "power_watts_peak": 41.97, "energy_joules_est": 31.44, "sample_count": 8, "duration_seconds": 0.76}, "timestamp": "2026-01-12T09:33:56.012973"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1510.094, "latencies_ms": [1510.094], "images_per_second": 0.662, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a banana and a donut in a plastic bag, with the banana being yellow and the donut being brown. The lighting is dim, and the bag appears to be made of clear plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15578.9, "ram_available_mb": 106927.4, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15592.6, "ram_available_mb": 106913.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.89, 44.89, 44.89, 44.89, 44.89, 50.62, 50.62, 50.62, 50.62, 50.62, 46.28, 46.28, 46.28, 46.28, 46.28, 32.94], "power_watts_avg": 46.37, "power_watts_peak": 50.62, "energy_joules_est": 70.04, "sample_count": 16, "duration_seconds": 1.51}, "timestamp": "2026-01-12T09:33:57.628289"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1336.468, "latencies_ms": [1336.468], "images_per_second": 0.748, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design and the words \"PIRATE PICKLES\" is placed on a glass table next to a large knife.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15588.6, "ram_available_mb": 106917.7, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15585.5, "ram_available_mb": 106920.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.94, 32.94, 32.94, 32.94, 41.91, 41.91, 41.91, 41.91, 41.91, 44.02, 44.02, 44.02, 44.02, 44.02], "power_watts_avg": 40.1, "power_watts_peak": 44.02, "energy_joules_est": 53.61, "sample_count": 14, "duration_seconds": 1.337}, "timestamp": "2026-01-12T09:33:59.042307"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 816.802, "latencies_ms": [816.802], "images_per_second": 1.224, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " mug: 1, knife: 1, glass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15585.2, "ram_available_mb": 106921.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 15594.1, "ram_available_mb": 106912.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.44, 34.44, 34.44, 34.44, 34.44, 44.65, 44.65, 44.65, 44.65], "power_watts_avg": 38.98, "power_watts_peak": 44.65, "energy_joules_est": 31.85, "sample_count": 9, "duration_seconds": 0.817}, "timestamp": "2026-01-12T09:33:59.951535"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1312.221, "latencies_ms": [1312.221], "images_per_second": 0.762, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The mug is located in the foreground, to the left of the knife. The knife is positioned near the mug, with its blade pointing towards the mug.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15586.2, "ram_available_mb": 106920.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15591.5, "ram_available_mb": 106914.8, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.65, 42.18, 42.18, 42.18, 42.18, 42.18, 44.26, 44.26, 44.26, 44.26, 44.26, 47.34, 47.34, 47.34], "power_watts_avg": 44.2, "power_watts_peak": 47.34, "energy_joules_est": 58.03, "sample_count": 14, "duration_seconds": 1.313}, "timestamp": "2026-01-12T09:34:01.365452"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1287.423, "latencies_ms": [1287.423], "images_per_second": 0.777, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design is sitting on a glass table. Next to the mug is a large knife with a black handle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15591.8, "ram_available_mb": 106914.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15642.7, "ram_available_mb": 106863.6, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.34, 47.34, 31.75, 31.75, 31.75, 31.75, 31.75, 44.36, 44.36, 44.36, 44.36, 44.36, 45.53], "power_watts_avg": 40.06, "power_watts_peak": 47.34, "energy_joules_est": 51.59, "sample_count": 13, "duration_seconds": 1.288}, "timestamp": "2026-01-12T09:34:02.679840"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 956.836, "latencies_ms": [956.836], "images_per_second": 1.045, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The mug is white and the knife is black. The mug is on a glass table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15643.2, "ram_available_mb": 106863.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15686.4, "ram_available_mb": 106819.9, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.53, 45.53, 45.53, 45.53, 41.08, 41.08, 41.08, 41.08, 41.08, 45.41], "power_watts_avg": 43.29, "power_watts_peak": 45.53, "energy_joules_est": 41.44, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-12T09:34:03.691231"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1915.873, "latencies_ms": [1915.873], "images_per_second": 0.522, "prompt_tokens": 1432, "response_tokens_est": 51, "n_tiles": 1, "output_text": " In the image, a group of people are gathered around a wooden counter in a wine tasting room, with a man in a white shirt and cap standing behind the counter, while a woman in a black shirt and plaid shorts is standing next to him.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15686.2, "ram_available_mb": 106820.1, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15642.5, "ram_available_mb": 106863.8, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.41, 45.41, 45.41, 45.41, 42.72, 42.72, 42.72, 42.72, 42.72, 49.03, 49.03, 49.03, 49.03, 49.03, 44.43, 44.43, 44.43, 44.43, 44.43, 33.13], "power_watts_avg": 44.78, "power_watts_peak": 49.03, "energy_joules_est": 85.82, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T09:34:05.709865"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2066.829, "latencies_ms": [2066.829], "images_per_second": 0.484, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15642.5, "ram_available_mb": 106863.8, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 15677.6, "ram_available_mb": 106828.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.13, 33.13, 33.13, 33.74, 33.74, 33.74, 33.74, 33.74, 47.24, 47.24, 47.24, 47.24, 47.24, 46.54, 46.54, 46.54, 46.54, 46.54, 32.96, 32.96, 32.96], "power_watts_avg": 39.8, "power_watts_peak": 47.24, "energy_joules_est": 82.29, "sample_count": 21, "duration_seconds": 2.068}, "timestamp": "2026-01-12T09:34:07.877461"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2636.142, "latencies_ms": [2636.142], "images_per_second": 0.379, "prompt_tokens": 1450, "response_tokens_est": 77, "n_tiles": 1, "output_text": " The man in the white cap is standing to the left of the man in the blue shirt, who is standing in front of the counter. The woman in the black shirt is standing to the right of the man in the blue shirt, and the man in the white shirt is standing behind the counter. The wooden barrel is located in the background, behind the man in the white shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15663.9, "ram_available_mb": 106842.4, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 15622.0, "ram_available_mb": 106884.3, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.96, 29.51, 29.51, 29.51, 29.51, 29.51, 48.15, 48.15, 48.15, 48.15, 48.15, 51.58, 51.58, 51.58, 51.58, 51.58, 32.79, 32.79, 32.79, 32.79, 32.79, 32.86, 32.86, 32.86, 32.86, 32.86, 33.01], "power_watts_avg": 38.53, "power_watts_peak": 51.58, "energy_joules_est": 101.6, "sample_count": 27, "duration_seconds": 2.637}, "timestamp": "2026-01-12T09:34:10.651510"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1178.187, "latencies_ms": [1178.187], "images_per_second": 0.849, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are gathered in a wine tasting room, standing around a wooden counter with wine bottles on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15622.0, "ram_available_mb": 106884.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15601.6, "ram_available_mb": 106904.7, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.01, 33.01, 33.01, 33.01, 39.63, 39.63, 39.63, 39.63, 39.63, 48.48, 48.48, 48.48], "power_watts_avg": 39.64, "power_watts_peak": 48.48, "energy_joules_est": 46.71, "sample_count": 12, "duration_seconds": 1.179}, "timestamp": "2026-01-12T09:34:11.866381"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2170.731, "latencies_ms": [2170.731], "images_per_second": 0.461, "prompt_tokens": 1442, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm and inviting atmosphere. The wooden floor and walls give the space a rustic feel, while the wooden counter adds a touch of elegance. The lighting is soft and natural, coming from the windows in the background, creating a cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15593.8, "ram_available_mb": 106912.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15630.6, "ram_available_mb": 106875.7, "ram_percent": 12.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.48, 48.48, 41.06, 41.06, 41.06, 41.06, 41.06, 49.23, 49.23, 49.23, 49.23, 49.23, 50.99, 50.99, 50.99, 50.99, 50.99, 32.91, 32.91, 32.91, 32.91, 32.91], "power_watts_avg": 44.0, "power_watts_peak": 50.99, "energy_joules_est": 95.52, "sample_count": 22, "duration_seconds": 2.171}, "timestamp": "2026-01-12T09:34:14.082394"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1174.173, "latencies_ms": [1174.173], "images_per_second": 0.852, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " In the image, there are two white birds standing in a green field, with a large body of water and a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 15623.0, "ram_available_mb": 106883.3, "ram_percent": 12.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15613.1, "ram_available_mb": 106893.2, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.04, 33.04, 33.04, 33.04, 42.3, 42.3, 42.3, 42.3, 42.3, 44.29, 44.29, 44.29], "power_watts_avg": 39.71, "power_watts_peak": 44.29, "energy_joules_est": 46.67, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-12T09:34:15.347636"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1884.141, "latencies_ms": [1884.141], "images_per_second": 0.531, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. birds: 2\n2. grass: 1\n3. water: 1\n4. sky: 1\n5. clouds: 1\n6. boats: 1\n7. dock: 1\n8. pier: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15609.1, "ram_available_mb": 106897.2, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15592.2, "ram_available_mb": 106914.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.29, 44.29, 36.42, 36.42, 36.42, 36.42, 36.42, 45.54, 45.54, 45.54, 45.54, 45.54, 45.07, 45.07, 45.07, 45.07, 45.07, 32.91, 32.91], "power_watts_avg": 41.55, "power_watts_peak": 45.54, "energy_joules_est": 78.32, "sample_count": 19, "duration_seconds": 1.885}, "timestamp": "2026-01-12T09:34:17.267111"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1151.723, "latencies_ms": [1151.723], "images_per_second": 0.868, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The two white birds are in the foreground, while the boats are in the background. The birds are closer to the camera than the boats.", "error": null, "sys_before": {"cpu_percent": 1.9, "ram_used_mb": 15584.3, "ram_available_mb": 106922.0, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15604.2, "ram_available_mb": 106902.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.91, 32.91, 34.64, 34.64, 34.64, 34.64, 34.64, 44.55, 44.55, 44.55, 44.55, 44.55], "power_watts_avg": 38.48, "power_watts_peak": 44.55, "energy_joules_est": 44.37, "sample_count": 12, "duration_seconds": 1.153}, "timestamp": "2026-01-12T09:34:18.527726"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1366.025, "latencies_ms": [1366.025], "images_per_second": 0.732, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In this image, we can see a field with grass and two birds. In the background, there are boats and poles. At the top, there are clouds in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15604.2, "ram_available_mb": 106902.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15588.4, "ram_available_mb": 106917.9, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [43.19, 43.19, 43.19, 43.19, 43.19, 45.43, 45.43, 45.43, 45.43, 45.43, 45.92, 45.92, 45.92, 45.92], "power_watts_avg": 44.77, "power_watts_peak": 45.92, "energy_joules_est": 61.17, "sample_count": 14, "duration_seconds": 1.366}, "timestamp": "2026-01-12T09:34:19.939451"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1092.61, "latencies_ms": [1092.61], "images_per_second": 0.915, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a vibrant green field with two white birds, a cloudy sky, and a body of water in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15585.2, "ram_available_mb": 106921.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 15589.7, "ram_available_mb": 106916.6, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.92, 30.85, 30.85, 30.85, 30.85, 30.85, 45.2, 45.2, 45.2, 45.2, 45.2], "power_watts_avg": 38.74, "power_watts_peak": 45.92, "energy_joules_est": 42.34, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-12T09:34:21.052154"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1004.197, "latencies_ms": [1004.197], "images_per_second": 0.996, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom with a checkered tile wall and a window.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 15591.2, "ram_available_mb": 106915.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 15583.8, "ram_available_mb": 106922.5, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.48, 47.48, 47.48, 47.48, 47.48, 45.39, 45.39, 45.39, 45.39, 45.39], "power_watts_avg": 46.43, "power_watts_peak": 47.48, "energy_joules_est": 46.66, "sample_count": 10, "duration_seconds": 1.005}, "timestamp": "2026-01-12T09:34:22.066071"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2249.091, "latencies_ms": [2249.091], "images_per_second": 0.445, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. man: 1\n2. toilet: 1\n3. man's pants: 1\n4. man's shirt: 1\n5. man's shoes: 1\n6. man's socks: 1\n7. man's belt: 1\n8. man's belt buckle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15583.8, "ram_available_mb": 106922.5, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15584.9, "ram_available_mb": 106921.4, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.35, 45.35, 45.35, 45.35, 45.35, 46.33, 46.33, 46.33, 46.33, 46.33, 46.09, 46.09, 46.09, 46.09, 46.09, 33.35, 33.35, 33.35, 33.35, 33.35, 32.99, 32.99, 32.99], "power_watts_avg": 41.5, "power_watts_peak": 46.33, "energy_joules_est": 93.37, "sample_count": 23, "duration_seconds": 2.25}, "timestamp": "2026-01-12T09:34:24.386273"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1451.474, "latencies_ms": [1451.474], "images_per_second": 0.689, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the toilet, which is located in the foreground of the image. The sink is positioned to the left of the toilet, and the window is located above the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15577.0, "ram_available_mb": 106929.3, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 15597.2, "ram_available_mb": 106909.1, "ram_percent": 12.7}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [32.99, 29.27, 29.27, 29.27, 29.27, 29.27, 43.63, 43.63, 43.63, 43.63, 43.63, 47.34, 47.34, 47.34, 47.34], "power_watts_avg": 39.12, "power_watts_peak": 47.34, "energy_joules_est": 56.83, "sample_count": 15, "duration_seconds": 1.452}, "timestamp": "2026-01-12T09:34:25.951477"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 876.958, "latencies_ms": [876.958], "images_per_second": 1.14, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom, wearing a shirt and pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15597.2, "ram_available_mb": 106909.1, "ram_percent": 12.7}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14087.5, "ram_available_mb": 108418.8, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [47.34, 30.37, 30.37, 30.37, 30.37, 30.37, 44.61, 44.61, 44.61], "power_watts_avg": 37.0, "power_watts_peak": 47.34, "energy_joules_est": 32.46, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-12T09:34:26.860454"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 929.226, "latencies_ms": [929.226], "images_per_second": 1.076, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is in black and white, and the man is wearing a dark shirt and pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14087.5, "ram_available_mb": 108418.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14077.7, "ram_available_mb": 108428.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 3.0}, "power_stats": {"power_watts_samples": [44.61, 44.61, 47.28, 47.28, 47.28, 47.28, 47.28, 45.36, 45.36, 45.36], "power_watts_avg": 46.17, "power_watts_peak": 47.28, "energy_joules_est": 42.92, "sample_count": 10, "duration_seconds": 0.93}, "timestamp": "2026-01-12T09:34:27.871013"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1115.587, "latencies_ms": [1115.587], "images_per_second": 0.896, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a group of people are standing on a snow-covered mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.8, "ram_available_mb": 108436.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14097.4, "ram_available_mb": 108408.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.36, 45.36, 44.44, 44.44, 44.44, 44.44, 44.44, 44.78, 44.78, 44.78, 44.78, 44.78], "power_watts_avg": 44.74, "power_watts_peak": 45.36, "energy_joules_est": 49.93, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-12T09:34:29.084666"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2038.304, "latencies_ms": [2038.304], "images_per_second": 0.491, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. mountain: 1\n2. people: 4\n3. ski tracks: 1\n4. snow: 1\n5. rocks: 1\n6. sky: 1\n7. mountain peak: 1\n8. snow-covered slope: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14089.5, "ram_available_mb": 108416.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 14086.3, "ram_available_mb": 108420.0, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.24, 46.24, 46.24, 46.24, 46.24, 44.36, 44.36, 44.36, 44.36, 44.36, 44.71, 44.71, 44.71, 44.71, 44.71, 32.85, 32.85, 32.85, 32.85, 32.85, 32.89], "power_watts_avg": 41.6, "power_watts_peak": 46.24, "energy_joules_est": 84.81, "sample_count": 21, "duration_seconds": 2.039}, "timestamp": "2026-01-12T09:34:31.201101"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1546.75, "latencies_ms": [1546.75], "images_per_second": 0.647, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The group of people is positioned in the foreground of the image, with the mountain range in the background. The mountain range is located to the right of the group, and the sky is visible above the mountain range.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14086.3, "ram_available_mb": 108420.0, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14093.8, "ram_available_mb": 108412.5, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.89, 32.89, 32.89, 36.37, 36.37, 36.37, 36.37, 36.37, 43.58, 43.58, 43.58, 43.58, 43.58, 41.42, 41.42, 41.42], "power_watts_avg": 38.92, "power_watts_peak": 43.58, "energy_joules_est": 60.22, "sample_count": 16, "duration_seconds": 1.547}, "timestamp": "2026-01-12T09:34:32.868454"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 923.539, "latencies_ms": [923.539], "images_per_second": 1.083, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are standing on a snowy mountain with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14094.2, "ram_available_mb": 108412.1, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 14087.9, "ram_available_mb": 108418.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [41.42, 41.42, 32.69, 32.69, 32.69, 32.69, 32.69, 44.83, 44.83, 44.83], "power_watts_avg": 38.08, "power_watts_peak": 44.83, "energy_joules_est": 35.18, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-12T09:34:33.880444"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1507.058, "latencies_ms": [1507.058], "images_per_second": 0.664, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a group of people standing on a snow-covered mountain, with the sky above them being a clear blue. The snow is pristine white, and the mountain's surface is rugged and rocky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14085.8, "ram_available_mb": 108420.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14092.9, "ram_available_mb": 108413.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.83, 44.83, 43.84, 43.84, 43.84, 43.84, 43.84, 44.63, 44.63, 44.63, 44.63, 44.63, 46.91, 46.91, 46.91], "power_watts_avg": 44.85, "power_watts_peak": 46.91, "energy_joules_est": 67.6, "sample_count": 15, "duration_seconds": 1.507}, "timestamp": "2026-01-12T09:34:35.394428"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1112.441, "latencies_ms": [1112.441], "images_per_second": 0.899, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A white bowl filled with rice, broccoli, and a red bean dish is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14089.0, "ram_available_mb": 108417.3, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14122.7, "ram_available_mb": 108383.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.91, 46.91, 31.09, 31.09, 31.09, 31.09, 31.09, 49.77, 49.77, 49.77, 49.77, 49.77], "power_watts_avg": 41.51, "power_watts_peak": 49.77, "energy_joules_est": 46.19, "sample_count": 12, "duration_seconds": 1.113}, "timestamp": "2026-01-12T09:34:36.608945"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1050.732, "latencies_ms": [1050.732], "images_per_second": 0.952, "prompt_tokens": 1446, "response_tokens_est": 19, "n_tiles": 1, "output_text": " broccoli: 2, rice: 1, bean: 1, vegetable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14122.7, "ram_available_mb": 108383.6, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 14118.4, "ram_available_mb": 108387.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [52.06, 52.06, 52.06, 52.06, 52.06, 41.79, 41.79, 41.79, 41.79, 41.79, 48.49], "power_watts_avg": 47.07, "power_watts_peak": 52.06, "energy_joules_est": 49.46, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-12T09:34:37.719299"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1694.125, "latencies_ms": [1694.125], "images_per_second": 0.59, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The broccoli is located to the left of the rice, which is in the center of the bowl. The red bean dish is on top of the rice, and the white rice is on the bottom of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14118.4, "ram_available_mb": 108387.9, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14109.1, "ram_available_mb": 108397.2, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.49, 48.49, 48.49, 45.21, 45.21, 45.21, 45.21, 45.21, 49.41, 49.41, 49.41, 49.41, 49.41, 44.88, 44.88, 44.88, 44.88], "power_watts_avg": 46.95, "power_watts_peak": 49.41, "energy_joules_est": 79.55, "sample_count": 17, "duration_seconds": 1.694}, "timestamp": "2026-01-12T09:34:39.430051"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 794.276, "latencies_ms": [794.276], "images_per_second": 1.259, "prompt_tokens": 1444, "response_tokens_est": 9, "n_tiles": 1, "output_text": " A bowl of food is on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14109.1, "ram_available_mb": 108397.2, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 14124.6, "ram_available_mb": 108381.7, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [44.88, 31.63, 31.63, 31.63, 31.63, 31.63, 50.38, 50.38], "power_watts_avg": 37.97, "power_watts_peak": 50.38, "energy_joules_est": 30.17, "sample_count": 8, "duration_seconds": 0.795}, "timestamp": "2026-01-12T09:34:40.240593"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 820.869, "latencies_ms": [820.869], "images_per_second": 1.218, "prompt_tokens": 1442, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The bowl is white and the food is colorful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14120.7, "ram_available_mb": 108385.6, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 14127.9, "ram_available_mb": 108378.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.38, 50.38, 50.38, 56.55, 56.55, 56.55, 56.55, 56.55, 49.94], "power_watts_avg": 53.76, "power_watts_peak": 56.55, "energy_joules_est": 44.16, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-12T09:34:41.150798"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1157.267, "latencies_ms": [1157.267], "images_per_second": 0.864, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp, wearing black and white sneakers with a checkered pattern on the bottom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14127.9, "ram_available_mb": 108378.4, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 14120.8, "ram_available_mb": 108385.5, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [49.94, 49.94, 49.94, 49.94, 54.35, 54.35, 54.35, 54.35, 54.35, 44.59, 44.59, 44.59], "power_watts_avg": 50.44, "power_watts_peak": 54.35, "energy_joules_est": 58.38, "sample_count": 12, "duration_seconds": 1.158}, "timestamp": "2026-01-12T09:34:42.360922"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2238.043, "latencies_ms": [2238.043], "images_per_second": 0.447, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. wooden plank: 1\n4. grass: 1\n5. wooden board: 1\n6. white letters: 1\n7. black and white checkered pattern: 1\n8. black and white shoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14121.0, "ram_available_mb": 108385.3, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14098.3, "ram_available_mb": 108408.0, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.59, 44.59, 36.51, 36.51, 36.51, 36.51, 36.51, 45.58, 45.58, 45.58, 45.58, 45.58, 46.24, 46.24, 46.24, 46.24, 46.24, 33.21, 33.21, 33.21, 33.21, 33.21, 33.06], "power_watts_avg": 40.43, "power_watts_peak": 46.24, "energy_joules_est": 90.5, "sample_count": 23, "duration_seconds": 2.238}, "timestamp": "2026-01-12T09:34:44.677488"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1276.429, "latencies_ms": [1276.429], "images_per_second": 0.783, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The skateboard is in the foreground, with the person's feet on it. The person is wearing jeans, and the skateboard is on a wooden ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14098.3, "ram_available_mb": 108408.0, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14137.7, "ram_available_mb": 108368.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.06, 33.06, 33.06, 37.27, 37.27, 37.27, 37.27, 37.27, 43.7, 43.7, 43.7, 43.7, 43.7], "power_watts_avg": 38.77, "power_watts_peak": 43.7, "energy_joules_est": 49.53, "sample_count": 13, "duration_seconds": 1.277}, "timestamp": "2026-01-12T09:34:46.039976"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 842.919, "latencies_ms": [842.919], "images_per_second": 1.186, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp in a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14137.7, "ram_available_mb": 108368.6, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14145.2, "ram_available_mb": 108361.1, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.32, 40.32, 40.32, 40.32, 40.32, 45.74, 45.74, 45.74, 45.74], "power_watts_avg": 42.73, "power_watts_peak": 45.74, "energy_joules_est": 36.03, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-12T09:34:46.953440"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1582.853, "latencies_ms": [1582.853], "images_per_second": 0.632, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a person wearing black and white sneakers with a checkered pattern on the bottom, standing on a wooden ramp in a grassy area. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14136.5, "ram_available_mb": 108369.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14138.4, "ram_available_mb": 108367.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.74, 43.44, 43.44, 43.44, 43.44, 43.44, 45.09, 45.09, 45.09, 45.09, 45.09, 47.52, 47.52, 47.52, 47.52, 47.52], "power_watts_avg": 45.37, "power_watts_peak": 47.52, "energy_joules_est": 71.83, "sample_count": 16, "duration_seconds": 1.583}, "timestamp": "2026-01-12T09:34:48.563707"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 844.41, "latencies_ms": [844.41], "images_per_second": 1.184, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14138.4, "ram_available_mb": 108367.9, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14158.0, "ram_available_mb": 108348.3, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.02, 33.02, 33.02, 33.02, 33.02, 45.84, 45.84, 45.84, 45.84], "power_watts_avg": 38.72, "power_watts_peak": 45.84, "energy_joules_est": 32.72, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-12T09:34:49.477506"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 526.259, "latencies_ms": [526.259], "images_per_second": 1.9, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14158.0, "ram_available_mb": 108348.3, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14199.1, "ram_available_mb": 108307.2, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [45.84, 43.96, 43.96, 43.96, 43.96, 43.96], "power_watts_avg": 44.27, "power_watts_peak": 45.84, "energy_joules_est": 23.31, "sample_count": 6, "duration_seconds": 0.527}, "timestamp": "2026-01-12T09:34:50.085633"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1579.498, "latencies_ms": [1579.498], "images_per_second": 0.633, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The bananas are located in the foreground of the image, with the keyboard and computer monitor in the background. The bananas are positioned to the left of the keyboard, and the computer monitor is to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14199.1, "ram_available_mb": 108307.2, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14183.6, "ram_available_mb": 108322.7, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.31, 45.31, 45.31, 45.31, 45.31, 58.65, 58.65, 58.65, 58.65, 58.65, 45.03, 45.03, 45.03, 45.03, 45.03, 34.5], "power_watts_avg": 48.71, "power_watts_peak": 58.65, "energy_joules_est": 76.96, "sample_count": 16, "duration_seconds": 1.58}, "timestamp": "2026-01-12T09:34:51.700618"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 839.108, "latencies_ms": [839.108], "images_per_second": 1.192, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14183.6, "ram_available_mb": 108322.7, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 14199.1, "ram_available_mb": 108307.2, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.5, 34.5, 34.5, 34.5, 40.84, 40.84, 40.84, 40.84, 40.84], "power_watts_avg": 38.02, "power_watts_peak": 40.84, "energy_joules_est": 31.91, "sample_count": 9, "duration_seconds": 0.839}, "timestamp": "2026-01-12T09:34:52.610654"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 809.934, "latencies_ms": [809.934], "images_per_second": 1.235, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14195.2, "ram_available_mb": 108311.1, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 14182.5, "ram_available_mb": 108323.8, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.03, 46.03, 46.03, 46.03, 46.03, 49.75, 49.75, 49.75, 49.75], "power_watts_avg": 47.68, "power_watts_peak": 49.75, "energy_joules_est": 38.64, "sample_count": 9, "duration_seconds": 0.81}, "timestamp": "2026-01-12T09:34:53.518951"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 837.506, "latencies_ms": [837.506], "images_per_second": 1.194, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A plate of food with rice, vegetables, and chicken is on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14174.6, "ram_available_mb": 108331.7, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14172.1, "ram_available_mb": 108334.2, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [43.6, 43.6, 43.6, 43.6, 43.6, 46.01, 46.01, 46.01, 46.01], "power_watts_avg": 44.67, "power_watts_peak": 46.01, "energy_joules_est": 37.46, "sample_count": 9, "duration_seconds": 0.839}, "timestamp": "2026-01-12T09:34:54.430694"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1438.018, "latencies_ms": [1438.018], "images_per_second": 0.695, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " plate: 1, fork: 1, knife: 1, glass: 1, rice: 1, carrots: 1, broccoli: 1, cauliflower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14164.2, "ram_available_mb": 108342.1, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14151.4, "ram_available_mb": 108354.9, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [46.01, 43.03, 43.03, 43.03, 43.03, 43.03, 45.47, 45.47, 45.47, 45.47, 45.47, 48.22, 48.22, 48.22, 48.22], "power_watts_avg": 45.42, "power_watts_peak": 48.22, "energy_joules_est": 65.37, "sample_count": 15, "duration_seconds": 1.439}, "timestamp": "2026-01-12T09:34:55.941096"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1423.23, "latencies_ms": [1423.23], "images_per_second": 0.703, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The plate is located in the foreground, with the fork and spoon placed on the left side of the plate. The glass of water is positioned in the background, to the left of the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14147.5, "ram_available_mb": 108358.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14144.1, "ram_available_mb": 108362.2, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [48.22, 30.75, 30.75, 30.75, 30.75, 30.75, 45.41, 45.41, 45.41, 45.41, 45.41, 48.18, 48.18, 48.18, 48.18], "power_watts_avg": 41.45, "power_watts_peak": 48.22, "energy_joules_est": 59.02, "sample_count": 15, "duration_seconds": 1.424}, "timestamp": "2026-01-12T09:34:57.451707"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 784.746, "latencies_ms": [784.746], "images_per_second": 1.274, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food is on a table with a glass of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14136.2, "ram_available_mb": 108370.1, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 14142.7, "ram_available_mb": 108363.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [48.18, 30.86, 30.86, 30.86, 30.86, 30.86, 44.98, 44.98], "power_watts_avg": 36.55, "power_watts_peak": 48.18, "energy_joules_est": 28.7, "sample_count": 8, "duration_seconds": 0.785}, "timestamp": "2026-01-12T09:34:58.261928"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 942.832, "latencies_ms": [942.832], "images_per_second": 1.061, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The plate is white and has a red and blue pattern. The food is colorful and looks delicious.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14134.8, "ram_available_mb": 108371.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14141.4, "ram_available_mb": 108364.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.98, 44.98, 44.98, 53.12, 53.12, 53.12, 53.12, 53.12, 46.32, 46.32], "power_watts_avg": 49.31, "power_watts_peak": 53.12, "energy_joules_est": 46.51, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-12T09:34:59.273013"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1277.552, "latencies_ms": [1277.552], "images_per_second": 0.783, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A young girl in a colorful dress is playing with a Wii remote in a living room with a couch, a coffee table, and a staircase in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14137.5, "ram_available_mb": 108368.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14132.6, "ram_available_mb": 108373.7, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.32, 46.32, 46.32, 45.48, 45.48, 45.48, 45.48, 45.48, 45.3, 45.3, 45.3, 45.3, 45.3], "power_watts_avg": 45.6, "power_watts_peak": 46.32, "energy_joules_est": 58.27, "sample_count": 13, "duration_seconds": 1.278}, "timestamp": "2026-01-12T09:35:00.587112"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.907, "latencies_ms": [1902.907], "images_per_second": 0.526, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. couch: 1\n2. rug: 1\n3. chair: 1\n4. table: 1\n5. sofa: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14124.8, "ram_available_mb": 108381.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14105.5, "ram_available_mb": 108400.8, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [41.69, 41.69, 41.69, 41.69, 41.69, 46.19, 46.19, 46.19, 46.19, 46.19, 45.93, 45.93, 45.93, 45.93, 45.93, 33.24, 33.24, 33.24, 33.24], "power_watts_avg": 42.21, "power_watts_peak": 46.19, "energy_joules_est": 80.34, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T09:35:02.503022"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1497.385, "latencies_ms": [1497.385], "images_per_second": 0.668, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The couch is located in the background, with the girl standing in the foreground. The person in the white dress is standing near the couch, while the person in the green shirt is standing near the bar.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14105.5, "ram_available_mb": 108400.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14107.9, "ram_available_mb": 108398.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.24, 33.07, 33.07, 33.07, 33.07, 33.07, 46.32, 46.32, 46.32, 46.32, 46.32, 46.69, 46.69, 46.69, 46.69], "power_watts_avg": 41.13, "power_watts_peak": 46.69, "energy_joules_est": 61.61, "sample_count": 15, "duration_seconds": 1.498}, "timestamp": "2026-01-12T09:35:04.016593"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1107.384, "latencies_ms": [1107.384], "images_per_second": 0.903, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are gathered in a living room, with a young girl playing with a toy in the center of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14103.9, "ram_available_mb": 108402.4, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14108.7, "ram_available_mb": 108397.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.69, 33.22, 33.22, 33.22, 33.22, 33.22, 46.49, 46.49, 46.49, 46.49, 46.43], "power_watts_avg": 40.47, "power_watts_peak": 46.69, "energy_joules_est": 44.83, "sample_count": 11, "duration_seconds": 1.108}, "timestamp": "2026-01-12T09:35:05.129944"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1003.005, "latencies_ms": [1003.005], "images_per_second": 0.997, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from the windows, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14108.7, "ram_available_mb": 108397.6, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14109.7, "ram_available_mb": 108396.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 46.43, 46.43, 44.29, 44.29, 44.29, 44.29, 44.29, 46.3], "power_watts_avg": 45.35, "power_watts_peak": 46.43, "energy_joules_est": 45.49, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-12T09:35:06.138778"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1489.751, "latencies_ms": [1489.751], "images_per_second": 0.671, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a man in a suit and tie is shaking hands with another man in a patterned shirt, both standing in a room filled with other people and tables, suggesting a formal event or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14101.8, "ram_available_mb": 108404.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14035.1, "ram_available_mb": 108471.2, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.3, 46.3, 46.3, 46.3, 46.41, 46.41, 46.41, 46.41, 46.41, 46.6, 46.6, 46.6, 46.6, 46.6, 36.21], "power_watts_avg": 45.76, "power_watts_peak": 46.6, "energy_joules_est": 68.21, "sample_count": 15, "duration_seconds": 1.49}, "timestamp": "2026-01-12T09:35:07.653381"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1899.841, "latencies_ms": [1899.841], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. man: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14035.1, "ram_available_mb": 108471.2, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 14118.6, "ram_available_mb": 108387.7, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.21, 36.21, 36.21, 36.21, 42.92, 42.92, 42.92, 42.92, 42.92, 46.0, 46.0, 46.0, 46.0, 46.0, 37.25, 37.25, 37.25, 37.25, 37.25], "power_watts_avg": 40.82, "power_watts_peak": 46.0, "energy_joules_est": 77.57, "sample_count": 19, "duration_seconds": 1.9}, "timestamp": "2026-01-12T09:35:09.569206"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2206.738, "latencies_ms": [2206.738], "images_per_second": 0.453, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The man in the dark suit is standing to the right of the man in the patterned shirt, and the man in the dark suit is in the foreground of the image. The man in the patterned shirt is standing to the left of the man in the dark suit, and the man in the patterned shirt is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14118.0, "ram_available_mb": 108388.3, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 14107.4, "ram_available_mb": 108398.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.19, 33.19, 33.19, 33.19, 33.19, 43.15, 43.15, 43.15, 43.15, 45.42, 45.42, 45.42, 45.42, 45.42, 35.32, 35.32, 35.32, 35.32, 35.32, 33.36, 33.36, 33.36], "power_watts_avg": 38.29, "power_watts_peak": 45.42, "energy_joules_est": 84.51, "sample_count": 22, "duration_seconds": 2.207}, "timestamp": "2026-01-12T09:35:11.835249"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 789.575, "latencies_ms": [789.575], "images_per_second": 1.267, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with many other people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14099.5, "ram_available_mb": 108406.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14152.9, "ram_available_mb": 108353.4, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 1.0}, "power_stats": {"power_watts_samples": [33.36, 33.36, 32.17, 32.17, 32.17, 32.17, 32.17, 45.3], "power_watts_avg": 34.11, "power_watts_peak": 45.3, "energy_joules_est": 26.95, "sample_count": 8, "duration_seconds": 0.79}, "timestamp": "2026-01-12T09:35:12.692940"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1028.323, "latencies_ms": [1028.323], "images_per_second": 0.972, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with warm lighting, and the attendees are dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14152.9, "ram_available_mb": 108353.4, "ram_percent": 11.6}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14057.8, "ram_available_mb": 108448.5, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.3, 45.3, 45.3, 45.3, 54.83, 54.83, 54.83, 54.83, 54.83, 46.35, 46.35], "power_watts_avg": 49.82, "power_watts_peak": 54.83, "energy_joules_est": 51.26, "sample_count": 11, "duration_seconds": 1.029}, "timestamp": "2026-01-12T09:35:13.803332"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 873.22, "latencies_ms": [873.22], "images_per_second": 1.145, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a white shirt and a striped tie is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14057.8, "ram_available_mb": 108448.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 14077.1, "ram_available_mb": 108429.2, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.35, 46.35, 46.35, 41.01, 41.01, 41.01, 41.01, 41.01, 44.78], "power_watts_avg": 43.21, "power_watts_peak": 46.35, "energy_joules_est": 37.74, "sample_count": 9, "duration_seconds": 0.873}, "timestamp": "2026-01-12T09:35:14.714901"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1903.969, "latencies_ms": [1903.969], "images_per_second": 0.525, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tie: 1\n2. shirt: 1\n3. hand: 1\n4. person: 1\n5. tie: 1\n6. shirt: 1\n7. hand: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14077.1, "ram_available_mb": 108429.2, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14063.4, "ram_available_mb": 108442.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.78, 44.78, 44.78, 44.78, 50.45, 50.45, 50.45, 50.45, 50.45, 46.04, 46.04, 46.04, 46.04, 38.19, 38.19, 38.19, 38.19, 38.19, 33.1], "power_watts_avg": 44.19, "power_watts_peak": 50.45, "energy_joules_est": 84.15, "sample_count": 19, "duration_seconds": 1.904}, "timestamp": "2026-01-12T09:35:16.632763"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1422.475, "latencies_ms": [1422.475], "images_per_second": 0.703, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is standing in the foreground, wearing a white shirt and a striped tie. The background is dark and out of focus, suggesting that the man is in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.4, "ram_available_mb": 108442.9, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 14155.4, "ram_available_mb": 108350.9, "ram_percent": 11.6}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.1, 33.1, 33.1, 33.1, 41.36, 41.36, 41.36, 41.36, 41.36, 45.29, 45.29, 45.29, 45.29, 45.29, 37.13], "power_watts_avg": 40.19, "power_watts_peak": 45.29, "energy_joules_est": 57.19, "sample_count": 15, "duration_seconds": 1.423}, "timestamp": "2026-01-12T09:35:18.198548"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 826.606, "latencies_ms": [826.606], "images_per_second": 1.21, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a tie and a shirt is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14147.5, "ram_available_mb": 108358.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14147.4, "ram_available_mb": 108358.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.13, 37.13, 37.13, 37.13, 40.39, 40.39, 40.39, 40.39, 40.39], "power_watts_avg": 38.94, "power_watts_peak": 40.39, "energy_joules_est": 32.2, "sample_count": 9, "duration_seconds": 0.827}, "timestamp": "2026-01-12T09:35:19.109649"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1010.895, "latencies_ms": [1010.895], "images_per_second": 0.989, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The man is wearing a white shirt and a striped tie. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14143.5, "ram_available_mb": 108362.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14138.4, "ram_available_mb": 108367.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.76, 44.76, 44.76, 44.76, 44.76, 49.2, 49.2, 49.2, 49.2, 49.2, 44.79], "power_watts_avg": 46.78, "power_watts_peak": 49.2, "energy_joules_est": 47.31, "sample_count": 11, "duration_seconds": 1.011}, "timestamp": "2026-01-12T09:35:20.222173"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1097.15, "latencies_ms": [1097.15], "images_per_second": 0.911, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image shows a room with a television on a stand, a chair, and a couch, with a whiteboard on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14130.5, "ram_available_mb": 108375.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14136.4, "ram_available_mb": 108369.9, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.79, 44.79, 44.79, 40.15, 40.15, 40.15, 40.15, 40.15, 44.66, 44.66, 44.66], "power_watts_avg": 42.64, "power_watts_peak": 44.79, "energy_joules_est": 46.79, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-12T09:35:21.335537"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1040.931, "latencies_ms": [1040.931], "images_per_second": 0.961, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " chair: 1, couch: 2, television: 1, whiteboard: 1, poster: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14128.5, "ram_available_mb": 108377.8, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14122.0, "ram_available_mb": 108384.3, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.66, 44.66, 42.45, 42.45, 42.45, 42.45, 42.45, 46.31, 46.31, 46.31, 46.31], "power_watts_avg": 44.26, "power_watts_peak": 46.31, "energy_joules_est": 46.09, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-12T09:35:22.447078"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1934.976, "latencies_ms": [1934.976], "images_per_second": 0.517, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red armchair is positioned to the left of the television, which is placed on a wooden stand in the center of the room. The blue and red plaid couch is located to the right of the television, and the whiteboard is mounted on the wall to the left of the television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14122.0, "ram_available_mb": 108384.3, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14119.9, "ram_available_mb": 108386.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.31, 41.77, 41.77, 41.77, 41.77, 41.77, 45.73, 45.73, 45.73, 45.73, 45.73, 48.22, 48.22, 48.22, 48.22, 48.22, 33.4, 33.4, 33.4, 33.4], "power_watts_avg": 42.93, "power_watts_peak": 48.22, "energy_joules_est": 83.08, "sample_count": 20, "duration_seconds": 1.935}, "timestamp": "2026-01-12T09:35:24.459870"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 732.917, "latencies_ms": [732.917], "images_per_second": 1.364, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A room with a TV, chairs, and a whiteboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14116.0, "ram_available_mb": 108390.3, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 14121.0, "ram_available_mb": 108385.3, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [33.4, 30.69, 30.69, 30.69, 30.69, 30.69, 44.22, 44.22], "power_watts_avg": 34.41, "power_watts_peak": 44.22, "energy_joules_est": 25.25, "sample_count": 8, "duration_seconds": 0.734}, "timestamp": "2026-01-12T09:35:25.320534"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 740.839, "latencies_ms": [740.839], "images_per_second": 1.35, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The room is painted yellow and has a plaid couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14113.1, "ram_available_mb": 108393.2, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 14120.5, "ram_available_mb": 108385.8, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.22, 44.22, 44.22, 49.74, 49.74, 49.74, 49.74, 45.39], "power_watts_avg": 47.13, "power_watts_peak": 49.74, "energy_joules_est": 34.94, "sample_count": 8, "duration_seconds": 0.741}, "timestamp": "2026-01-12T09:35:26.131079"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1108.767, "latencies_ms": [1108.767], "images_per_second": 0.902, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14116.6, "ram_available_mb": 108389.7, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14027.6, "ram_available_mb": 108478.7, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.39, 45.39, 45.39, 45.39, 51.97, 51.97, 51.97, 51.97, 51.97, 49.09, 49.09, 49.09], "power_watts_avg": 49.06, "power_watts_peak": 51.97, "energy_joules_est": 54.4, "sample_count": 12, "duration_seconds": 1.109}, "timestamp": "2026-01-12T09:35:27.346322"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2595.414, "latencies_ms": [2595.414], "images_per_second": 0.385, "prompt_tokens": 1446, "response_tokens_est": 76, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wetsuit: 1\n4. Wetsuit sleeve: 1\n5. Wetsuit leg: 1\n6. Wetsuit arm: 1\n7. Wetsuit chest: 1\n8. Wetsuit back: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14027.6, "ram_available_mb": 108478.7, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 14082.6, "ram_available_mb": 108423.7, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.09, 49.09, 40.43, 40.43, 40.43, 40.43, 40.43, 48.62, 48.62, 48.62, 48.62, 48.62, 49.99, 49.99, 49.99, 49.99, 49.99, 33.42, 33.42, 33.42, 33.42, 33.42, 33.4, 33.4, 33.4, 33.4], "power_watts_avg": 42.08, "power_watts_peak": 49.99, "energy_joules_est": 109.23, "sample_count": 26, "duration_seconds": 2.596}, "timestamp": "2026-01-12T09:35:29.965708"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1731.303, "latencies_ms": [1731.303], "images_per_second": 0.578, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that is in the middle of the image. The surfer is wearing a yellow shirt and black pants, and is positioned on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14082.3, "ram_available_mb": 108424.0, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14097.8, "ram_available_mb": 108408.5, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.4, 31.74, 31.74, 31.74, 31.74, 31.74, 47.78, 47.78, 47.78, 47.78, 47.78, 51.09, 51.09, 51.09, 51.09, 51.09, 35.84, 35.84], "power_watts_avg": 42.12, "power_watts_peak": 51.09, "energy_joules_est": 72.96, "sample_count": 18, "duration_seconds": 1.732}, "timestamp": "2026-01-12T09:35:31.833181"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.87, "latencies_ms": [1116.87], "images_per_second": 0.895, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14086.9, "ram_available_mb": 108419.4, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 14126.9, "ram_available_mb": 108379.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 22.0}, "power_stats": {"power_watts_samples": [35.84, 35.84, 33.49, 33.49, 33.49, 33.49, 33.49, 48.9, 48.9, 48.9, 48.9, 48.9], "power_watts_avg": 40.3, "power_watts_peak": 48.9, "energy_joules_est": 45.03, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T09:35:33.044022"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1143.531, "latencies_ms": [1143.531], "images_per_second": 0.874, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a yellow shirt and black pants, and the water is a greenish-blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14126.9, "ram_available_mb": 108379.4, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14112.8, "ram_available_mb": 108393.5, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.53, 47.53, 47.53, 47.53, 47.53, 45.74, 45.74, 45.74, 45.74, 45.74, 50.4, 50.4], "power_watts_avg": 47.26, "power_watts_peak": 50.4, "energy_joules_est": 54.06, "sample_count": 12, "duration_seconds": 1.144}, "timestamp": "2026-01-12T09:35:34.254329"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 868.561, "latencies_ms": [868.561], "images_per_second": 1.151, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14112.8, "ram_available_mb": 108393.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 14109.0, "ram_available_mb": 108397.3, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [50.4, 50.4, 50.4, 43.15, 43.15, 43.15, 43.15, 43.15, 45.33], "power_watts_avg": 45.81, "power_watts_peak": 50.4, "energy_joules_est": 39.8, "sample_count": 9, "duration_seconds": 0.869}, "timestamp": "2026-01-12T09:35:35.167021"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1343.944, "latencies_ms": [1343.944], "images_per_second": 0.744, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. black cat\n2. laptop\n3. computer monitor\n4. keyboard\n5. mouse\n6. phone\n7. mousepad\n8. desk", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14101.1, "ram_available_mb": 108405.2, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14101.7, "ram_available_mb": 108404.6, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.33, 45.33, 45.33, 45.33, 49.5, 49.5, 49.5, 49.5, 49.5, 45.78, 45.78, 45.78, 45.78, 45.78], "power_watts_avg": 46.98, "power_watts_peak": 49.5, "energy_joules_est": 63.15, "sample_count": 14, "duration_seconds": 1.344}, "timestamp": "2026-01-12T09:35:36.578333"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1603.7, "latencies_ms": [1603.7], "images_per_second": 0.624, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at the computer screen. The laptop is on the left side of the cat, and the phone is on the right side. The cat is closer to the computer screen than the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14093.8, "ram_available_mb": 108412.5, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 14095.9, "ram_available_mb": 108410.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.69, 36.69, 36.69, 36.69, 36.69, 45.64, 45.64, 45.64, 45.64, 45.64, 45.45, 45.45, 45.45, 45.45, 45.45, 33.43], "power_watts_avg": 42.02, "power_watts_peak": 45.64, "energy_joules_est": 67.4, "sample_count": 16, "duration_seconds": 1.604}, "timestamp": "2026-01-12T09:35:38.192307"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 866.299, "latencies_ms": [866.299], "images_per_second": 1.154, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14093.9, "ram_available_mb": 108412.4, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 14109.9, "ram_available_mb": 108396.4, "ram_percent": 11.5}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.43, 33.43, 33.43, 33.43, 42.91, 42.91, 42.91, 42.91, 42.91], "power_watts_avg": 38.69, "power_watts_peak": 42.91, "energy_joules_est": 33.53, "sample_count": 9, "duration_seconds": 0.867}, "timestamp": "2026-01-12T09:35:39.102832"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1849.721, "latencies_ms": [1849.721], "images_per_second": 0.541, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image is a close-up of a black cat sitting in front of a computer screen, with the cat's head and part of its body visible. The lighting is natural, coming from the left side of the image, and the cat's fur is fluffy and dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14102.1, "ram_available_mb": 108404.2, "ram_percent": 11.5}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 13456.7, "ram_available_mb": 109049.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.75, 46.75, 46.75, 46.75, 46.75, 50.49, 50.49, 50.49, 50.49, 50.49, 46.39, 46.39, 46.39, 46.39, 46.39, 33.67, 33.67, 33.67, 33.67], "power_watts_avg": 44.88, "power_watts_peak": 50.49, "energy_joules_est": 83.04, "sample_count": 19, "duration_seconds": 1.85}, "timestamp": "2026-01-12T09:35:41.015858"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1370.137, "latencies_ms": [1370.137], "images_per_second": 0.73, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of people, including a man in a blue shirt and a child in a pink jacket, are cutting a red ribbon with a pair of scissors in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13457.1, "ram_available_mb": 109049.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13537.2, "ram_available_mb": 108969.1, "ram_percent": 11.1}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.67, 32.11, 32.11, 32.11, 32.11, 32.11, 45.6, 45.6, 45.6, 45.6, 45.6, 46.27, 46.27, 46.27], "power_watts_avg": 40.07, "power_watts_peak": 46.27, "energy_joules_est": 54.94, "sample_count": 14, "duration_seconds": 1.371}, "timestamp": "2026-01-12T09:35:42.433549"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2096.69, "latencies_ms": [2096.69], "images_per_second": 0.477, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. People: 10\n2. Balloons: 2\n3. Helmet: 2\n4. Helmet: 1\n5. Helmet: 1\n6. Helmet: 1\n7. Helmet: 1\n8. Helmet: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13537.2, "ram_available_mb": 108969.1, "ram_percent": 11.1}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13512.0, "ram_available_mb": 108994.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.27, 31.6, 31.6, 31.6, 31.6, 31.6, 46.07, 46.07, 46.07, 46.07, 46.07, 48.0, 48.0, 48.0, 48.0, 48.0, 33.53, 33.53, 33.53, 33.53, 33.53], "power_watts_avg": 40.11, "power_watts_peak": 48.0, "energy_joules_est": 84.11, "sample_count": 21, "duration_seconds": 2.097}, "timestamp": "2026-01-12T09:35:44.553101"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2138.183, "latencies_ms": [2138.183], "images_per_second": 0.468, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the people standing in front of the building. The ribbon is positioned in the center of the image, with the people standing on either side of it. The people are positioned in the background of the image, with the building being the main focus of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13504.2, "ram_available_mb": 109002.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13427.8, "ram_available_mb": 109078.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.48, 33.48, 33.48, 33.48, 33.48, 46.18, 46.18, 46.18, 46.18, 46.18, 46.38, 46.38, 46.38, 46.38, 46.38, 33.29, 33.29, 33.29, 33.29, 33.29, 33.3, 33.3], "power_watts_avg": 39.24, "power_watts_peak": 46.38, "energy_joules_est": 83.92, "sample_count": 22, "duration_seconds": 2.139}, "timestamp": "2026-01-12T09:35:46.772938"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 955.086, "latencies_ms": [955.086], "images_per_second": 1.047, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered outside a building, cutting a red ribbon with a pair of scissors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.8, "ram_available_mb": 109078.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13476.9, "ram_available_mb": 109029.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.3, 33.3, 33.3, 34.46, 34.46, 34.46, 34.46, 34.46, 43.86, 43.86], "power_watts_avg": 35.99, "power_watts_peak": 43.86, "energy_joules_est": 34.41, "sample_count": 10, "duration_seconds": 0.956}, "timestamp": "2026-01-12T09:35:47.833578"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1951.782, "latencies_ms": [1951.782], "images_per_second": 0.512, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a vibrant and lively scene with a mix of warm and cool colors, capturing the essence of a bustling city street. The lighting is natural, with the sun casting a soft glow on the scene, and the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13476.9, "ram_available_mb": 109029.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13564.5, "ram_available_mb": 108941.8, "ram_percent": 11.1}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.86, 43.86, 45.11, 45.11, 45.11, 45.11, 45.11, 45.66, 45.66, 45.66, 45.66, 45.66, 43.56, 43.56, 43.56, 43.56, 43.56, 33.45, 33.45, 33.45], "power_watts_avg": 42.99, "power_watts_peak": 45.66, "energy_joules_est": 83.92, "sample_count": 20, "duration_seconds": 1.952}, "timestamp": "2026-01-12T09:35:49.847553"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1318.427, "latencies_ms": [1318.427], "images_per_second": 0.758, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A white and pink bus with the number 65745 on the front is driving down a street with a sign that says \"First Group\" on top.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13564.5, "ram_available_mb": 108941.8, "ram_percent": 11.1}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13539.3, "ram_available_mb": 108967.0, "ram_percent": 11.1}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 31.23, 31.23, 31.23, 31.23, 31.23, 44.44, 44.44, 44.44, 44.44, 44.44, 46.73, 46.73], "power_watts_avg": 38.48, "power_watts_peak": 46.73, "energy_joules_est": 50.77, "sample_count": 14, "duration_seconds": 1.32}, "timestamp": "2026-01-12T09:35:51.316928"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.346, "latencies_ms": [1902.346], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 1\n3. buildings: 1\n4. flowers: 1\n5. road: 1\n6. sky: 1\n7. clouds: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13535.3, "ram_available_mb": 108971.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13423.4, "ram_available_mb": 109082.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.73, 46.73, 46.73, 34.92, 34.92, 34.92, 34.92, 34.92, 44.48, 44.48, 44.48, 44.48, 44.48, 43.93, 43.93, 43.93, 43.93, 33.37, 33.37], "power_watts_avg": 41.03, "power_watts_peak": 46.73, "energy_joules_est": 78.08, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T09:35:53.236006"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1905.821, "latencies_ms": [1905.821], "images_per_second": 0.525, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The bus is in the foreground, with the background showing a street and buildings. The bus is also near the sidewalk, as it is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.4, "ram_available_mb": 109082.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13424.1, "ram_available_mb": 109082.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.37, 33.37, 33.37, 37.0, 37.0, 37.0, 37.0, 37.0, 45.48, 45.48, 45.48, 45.48, 45.48, 41.65, 41.65, 41.65, 41.65, 41.65, 33.22], "power_watts_avg": 39.68, "power_watts_peak": 45.48, "energy_joules_est": 75.67, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T09:35:55.203903"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 900.25, "latencies_ms": [900.25], "images_per_second": 1.111, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A white and pink bus is driving down a street with buildings and people in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13416.2, "ram_available_mb": 109090.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13440.7, "ram_available_mb": 109065.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.22, 33.22, 33.22, 38.6, 38.6, 38.6, 38.6, 38.6, 45.26], "power_watts_avg": 37.55, "power_watts_peak": 45.26, "energy_joules_est": 33.83, "sample_count": 9, "duration_seconds": 0.901}, "timestamp": "2026-01-12T09:35:56.165403"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 860.214, "latencies_ms": [860.214], "images_per_second": 1.163, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bus is white, blue, and pink, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.7, "ram_available_mb": 109069.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.26, 45.26, 45.26, 45.26, 49.86, 49.86, 49.86, 49.86, 49.86], "power_watts_avg": 47.82, "power_watts_peak": 49.86, "energy_joules_est": 41.16, "sample_count": 9, "duration_seconds": 0.861}, "timestamp": "2026-01-12T09:35:57.076238"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1059.889, "latencies_ms": [1059.889], "images_per_second": 0.943, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, holding a cell phone, and looking at his reflection.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13413.8, "ram_available_mb": 109092.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.22, 46.22, 46.22, 46.22, 46.22, 49.15, 49.15, 49.15, 49.15, 49.15, 45.72], "power_watts_avg": 47.5, "power_watts_peak": 49.15, "energy_joules_est": 50.35, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T09:35:58.191182"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1905.282, "latencies_ms": [1905.282], "images_per_second": 0.525, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Mirror: 1\n3. Floor: 1\n4. Wall: 1\n5. Window: 1\n6. Door: 1\n7. Table: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.0, "ram_available_mb": 109100.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13423.3, "ram_available_mb": 109083.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.72, 45.72, 45.72, 45.72, 41.69, 41.69, 41.69, 41.69, 41.69, 45.88, 45.88, 45.88, 45.88, 45.88, 37.28, 37.28, 37.28, 37.28, 37.28], "power_watts_avg": 42.48, "power_watts_peak": 45.88, "energy_joules_est": 80.96, "sample_count": 19, "duration_seconds": 1.906}, "timestamp": "2026-01-12T09:36:00.108585"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1840.425, "latencies_ms": [1840.425], "images_per_second": 0.543, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is sitting in front of the mirror, which is positioned on the left side of the image. The mirror is reflecting the room behind him, which is located in the background. The man is sitting on the floor, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.3, "ram_available_mb": 109083.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13510.3, "ram_available_mb": 108996.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [33.27, 33.27, 33.27, 33.27, 42.86, 42.86, 42.86, 42.86, 42.86, 45.43, 45.43, 45.43, 45.43, 45.43, 35.95, 35.95, 35.95, 35.95, 35.95], "power_watts_avg": 39.7, "power_watts_peak": 45.43, "energy_joules_est": 73.1, "sample_count": 19, "duration_seconds": 1.842}, "timestamp": "2026-01-12T09:36:02.073377"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 921.78, "latencies_ms": [921.78], "images_per_second": 1.085, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, taking a picture of himself.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13510.3, "ram_available_mb": 108996.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13503.5, "ram_available_mb": 109002.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.92, 32.92, 32.92, 32.92, 32.92, 43.57, 43.57, 43.57, 43.57, 43.57], "power_watts_avg": 38.25, "power_watts_peak": 43.57, "energy_joules_est": 35.27, "sample_count": 10, "duration_seconds": 0.922}, "timestamp": "2026-01-12T09:36:03.132577"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 921.802, "latencies_ms": [921.802], "images_per_second": 1.085, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13503.5, "ram_available_mb": 109002.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13487.7, "ram_available_mb": 109018.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.91, 44.91, 44.91, 44.91, 45.83, 45.83, 45.83, 45.83, 45.83, 45.02], "power_watts_avg": 45.38, "power_watts_peak": 45.83, "energy_joules_est": 41.87, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-12T09:36:04.142801"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1162.296, "latencies_ms": [1162.296], "images_per_second": 0.86, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people, including a man holding a surfboard, are posing for a photo in a room with a door and a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13483.8, "ram_available_mb": 109022.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13437.8, "ram_available_mb": 109068.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.02, 45.02, 45.02, 45.02, 43.88, 43.88, 43.88, 43.88, 43.88, 44.82, 44.82, 44.82], "power_watts_avg": 44.49, "power_watts_peak": 45.02, "energy_joules_est": 51.73, "sample_count": 12, "duration_seconds": 1.163}, "timestamp": "2026-01-12T09:36:05.355656"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1928.258, "latencies_ms": [1928.258], "images_per_second": 0.519, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. surfboard: 4\n2. person: 4\n3. person: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.8, "ram_available_mb": 109068.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13449.8, "ram_available_mb": 109056.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.82, 44.82, 36.65, 36.65, 36.65, 36.65, 36.65, 45.92, 45.92, 45.92, 45.92, 45.92, 45.52, 45.52, 45.52, 45.52, 45.52, 33.35, 33.35, 33.35], "power_watts_avg": 41.51, "power_watts_peak": 45.92, "energy_joules_est": 80.08, "sample_count": 20, "duration_seconds": 1.929}, "timestamp": "2026-01-12T09:36:07.376386"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1858.482, "latencies_ms": [1858.482], "images_per_second": 0.538, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The group of people is standing in the foreground of the image, with the camera being held by the person on the left side of the group. The surfboards are positioned in the middle of the group, with the person holding the yellow surfboard closest to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13441.9, "ram_available_mb": 109064.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13436.2, "ram_available_mb": 109070.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.35, 33.35, 29.43, 29.43, 29.43, 29.43, 29.43, 43.9, 43.9, 43.9, 43.9, 43.9, 47.76, 47.76, 47.76, 47.76, 33.25, 33.25, 33.25], "power_watts_avg": 38.11, "power_watts_peak": 47.76, "energy_joules_est": 70.86, "sample_count": 19, "duration_seconds": 1.859}, "timestamp": "2026-01-12T09:36:09.345502"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 857.244, "latencies_ms": [857.244], "images_per_second": 1.167, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are posing for a picture in a room with surfboards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13432.3, "ram_available_mb": 109074.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13450.8, "ram_available_mb": 109055.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.25, 33.25, 34.36, 34.36, 34.36, 34.36, 34.36, 45.46, 45.46], "power_watts_avg": 36.58, "power_watts_peak": 45.46, "energy_joules_est": 31.38, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-12T09:36:10.256783"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1091.107, "latencies_ms": [1091.107], "images_per_second": 0.917, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the surfboards are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13442.9, "ram_available_mb": 109063.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13438.7, "ram_available_mb": 109067.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.46, 45.46, 45.46, 50.41, 50.41, 50.41, 50.41, 50.41, 45.54, 45.54, 45.54], "power_watts_avg": 47.73, "power_watts_peak": 50.41, "energy_joules_est": 52.09, "sample_count": 11, "duration_seconds": 1.091}, "timestamp": "2026-01-12T09:36:11.368864"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1578.22, "latencies_ms": [1578.22], "images_per_second": 0.634, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a large, golden-colored airplane with the words \"POLSKIE LOTNIE LOTNICZE\" written on its side, parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13438.7, "ram_available_mb": 109067.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13374.9, "ram_available_mb": 109131.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.54, 45.54, 41.23, 41.23, 41.23, 41.23, 41.23, 46.31, 46.31, 46.31, 46.31, 46.31, 46.14, 46.14, 46.14, 46.14], "power_watts_avg": 44.58, "power_watts_peak": 46.31, "energy_joules_est": 70.37, "sample_count": 16, "duration_seconds": 1.578}, "timestamp": "2026-01-12T09:36:12.985104"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1908.943, "latencies_ms": [1908.943], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. engine: 2\n5. wheels: 2\n6. clouds: 1\n7. runway: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.9, "ram_available_mb": 109131.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.14, 32.03, 32.03, 32.03, 32.03, 32.03, 46.0, 46.0, 46.0, 46.0, 46.0, 46.76, 46.76, 46.76, 46.76, 46.76, 33.21, 33.21, 33.21], "power_watts_avg": 40.51, "power_watts_peak": 46.76, "energy_joules_est": 77.35, "sample_count": 19, "duration_seconds": 1.909}, "timestamp": "2026-01-12T09:36:14.903694"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1523.861, "latencies_ms": [1523.861], "images_per_second": 0.656, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The airplane is positioned on the left side of the image, with the runway stretching out in front of it. In the background, there are other airplanes and a few buildings, suggesting that this is an airport.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13438.3, "ram_available_mb": 109068.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.21, 33.21, 33.27, 33.27, 33.27, 33.27, 33.27, 46.67, 46.67, 46.67, 46.67, 46.67, 46.7, 46.7, 46.7, 46.7], "power_watts_avg": 40.81, "power_watts_peak": 46.7, "energy_joules_est": 62.21, "sample_count": 16, "duration_seconds": 1.524}, "timestamp": "2026-01-12T09:36:16.519107"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2368.908, "latencies_ms": [2368.908], "images_per_second": 0.422, "prompt_tokens": 1111, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image captures a moment on an airport tarmac where a golden-colored airplane, adorned with a blue logo and the words \"Polskie LOTNIE LOTNICZE\" on its side, is parked. The sky above is a canvas of blue, dotted with fluffy white clouds, and the runway beneath the plane is a stark contrast of gray.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13434.4, "ram_available_mb": 109071.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13418.9, "ram_available_mb": 109087.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.7, 31.68, 31.68, 31.68, 31.68, 31.68, 45.0, 45.0, 45.0, 45.0, 45.0, 47.0, 47.0, 47.0, 47.0, 47.0, 33.33, 33.33, 33.33, 33.33, 33.33, 33.35, 33.35, 33.35], "power_watts_avg": 38.83, "power_watts_peak": 47.0, "energy_joules_est": 91.99, "sample_count": 24, "duration_seconds": 2.369}, "timestamp": "2026-01-12T09:36:18.941069"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 853.45, "latencies_ms": [853.45], "images_per_second": 1.172, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The airplane is gold and blue, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.0, "ram_available_mb": 109095.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13437.9, "ram_available_mb": 109068.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [33.35, 30.8, 30.8, 30.8, 30.8, 30.8, 44.58, 44.58, 44.58], "power_watts_avg": 35.68, "power_watts_peak": 44.58, "energy_joules_est": 30.48, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-12T09:36:19.902987"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 844.596, "latencies_ms": [844.596], "images_per_second": 1.184, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A toilet with a lid up and water in it is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.9, "ram_available_mb": 109068.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13435.4, "ram_available_mb": 109070.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 10.0}, "power_stats": {"power_watts_samples": [44.58, 44.58, 43.86, 43.86, 43.86, 43.86, 43.86, 45.07, 45.07], "power_watts_avg": 44.29, "power_watts_peak": 45.07, "energy_joules_est": 37.44, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-12T09:36:20.818036"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1498.226, "latencies_ms": [1498.226], "images_per_second": 0.667, "prompt_tokens": 1114, "response_tokens_est": 41, "n_tiles": 1, "output_text": " toilet: 1\ntoilet seat: 1\ntoilet lid: 1\ntoilet bowl: 1\nwater: 1\nwater pipe: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.4, "ram_available_mb": 109070.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13421.9, "ram_available_mb": 109084.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.07, 45.07, 45.07, 50.77, 50.77, 50.77, 50.77, 50.77, 45.48, 45.48, 45.48, 45.48, 45.48, 43.7, 43.7], "power_watts_avg": 46.93, "power_watts_peak": 50.77, "energy_joules_est": 70.35, "sample_count": 15, "duration_seconds": 1.499}, "timestamp": "2026-01-12T09:36:22.333834"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1578.651, "latencies_ms": [1578.651], "images_per_second": 0.633, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the sink and towel rack in the background. The person's legs are visible in the bottom left corner of the image, suggesting they are standing near the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.0, "ram_available_mb": 109092.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13413.3, "ram_available_mb": 109093.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.7, 43.7, 43.7, 36.13, 36.13, 36.13, 36.13, 46.32, 46.32, 46.32, 46.32, 46.32, 43.79, 43.79, 43.79, 43.79], "power_watts_avg": 42.65, "power_watts_peak": 46.32, "energy_joules_est": 67.35, "sample_count": 16, "duration_seconds": 1.579}, "timestamp": "2026-01-12T09:36:23.953175"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 716.249, "latencies_ms": [716.249], "images_per_second": 1.396, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A toilet with a lid up is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.3, "ram_available_mb": 109093.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13436.9, "ram_available_mb": 109069.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [43.79, 31.32, 31.32, 31.32, 31.32, 31.32, 46.12, 46.12], "power_watts_avg": 36.58, "power_watts_peak": 46.12, "energy_joules_est": 26.21, "sample_count": 8, "duration_seconds": 0.717}, "timestamp": "2026-01-12T09:36:24.763114"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 688.769, "latencies_ms": [688.769], "images_per_second": 1.452, "prompt_tokens": 1110, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The toilet is white and the water is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.9, "ram_available_mb": 109069.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13421.2, "ram_available_mb": 109085.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.12, 46.12, 46.12, 52.6, 52.6, 52.6, 52.6], "power_watts_avg": 49.82, "power_watts_peak": 52.6, "energy_joules_est": 34.34, "sample_count": 7, "duration_seconds": 0.689}, "timestamp": "2026-01-12T09:36:25.472553"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 956.915, "latencies_ms": [956.915], "images_per_second": 1.045, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person is skiing down a snowy slope, wearing a helmet and goggles, and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.2, "ram_available_mb": 109085.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13436.8, "ram_available_mb": 109069.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [52.6, 43.56, 43.56, 43.56, 43.56, 43.56, 53.77, 53.77, 53.77, 53.77], "power_watts_avg": 48.55, "power_watts_peak": 53.77, "energy_joules_est": 46.46, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-12T09:36:26.487277"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1990.583, "latencies_ms": [1990.583], "images_per_second": 0.502, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. goggles: 1\n4. ski poles: 2\n5. skis: 2\n6. snow: 1\n7. trees: 1\n8. snowboard: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13428.9, "ram_available_mb": 109077.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13436.9, "ram_available_mb": 109069.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [53.77, 46.0, 46.0, 46.0, 46.0, 46.0, 45.47, 45.47, 45.47, 45.47, 45.47, 47.51, 47.51, 47.51, 47.51, 47.51, 33.3, 33.3, 33.3, 33.3], "power_watts_avg": 44.09, "power_watts_peak": 53.77, "energy_joules_est": 87.8, "sample_count": 20, "duration_seconds": 1.991}, "timestamp": "2026-01-12T09:36:28.508249"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1657.262, "latencies_ms": [1657.262], "images_per_second": 0.603, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the snowy forest and trees in the background. The skier is skiing towards the left side of the image, with the trees and forest extending towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13433.0, "ram_available_mb": 109073.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.42, 32.42, 32.42, 32.42, 32.42, 45.07, 45.07, 45.07, 45.07, 45.07, 45.92, 45.92, 45.92, 45.92, 45.92, 33.2, 33.2], "power_watts_avg": 40.2, "power_watts_peak": 45.92, "energy_joules_est": 66.66, "sample_count": 17, "duration_seconds": 1.658}, "timestamp": "2026-01-12T09:36:30.275976"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 749.449, "latencies_ms": [749.449], "images_per_second": 1.334, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13422.3, "ram_available_mb": 109084.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13439.6, "ram_available_mb": 109066.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.2, 33.2, 33.2, 37.35, 37.35, 37.35, 37.35, 37.35], "power_watts_avg": 35.79, "power_watts_peak": 37.35, "energy_joules_est": 26.84, "sample_count": 8, "duration_seconds": 0.75}, "timestamp": "2026-01-12T09:36:31.087814"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 962.236, "latencies_ms": [962.236], "images_per_second": 1.039, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a blue jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.7, "ram_available_mb": 109070.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13434.4, "ram_available_mb": 109071.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.31, 45.31, 45.31, 45.31, 45.31, 53.68, 53.68, 53.68, 53.68, 53.68], "power_watts_avg": 49.5, "power_watts_peak": 53.68, "energy_joules_est": 47.66, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-12T09:36:32.097968"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1114.382, "latencies_ms": [1114.382], "images_per_second": 0.897, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court with a crowd of people watching in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.5, "ram_available_mb": 109079.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13435.3, "ram_available_mb": 109071.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.39, 45.39, 45.39, 45.39, 45.39, 46.27, 46.27, 46.27, 46.27, 46.27, 46.0, 46.0], "power_watts_avg": 45.86, "power_watts_peak": 46.27, "energy_joules_est": 51.12, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-12T09:36:33.310097"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2270.205, "latencies_ms": [2270.205], "images_per_second": 0.44, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. ball: 1\n4. blue court: 1\n5. white lines: 1\n6. white lines on court: 1\n7. white lines on court: 1\n8. white lines on court: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13429.8, "ram_available_mb": 109076.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.0, 46.0, 46.0, 36.2, 36.2, 36.2, 36.2, 36.2, 44.74, 44.74, 44.74, 44.74, 44.74, 42.48, 42.48, 42.48, 42.48, 42.48, 32.99, 32.99, 32.99, 32.99, 32.99], "power_watts_avg": 40.0, "power_watts_peak": 46.0, "energy_joules_est": 90.84, "sample_count": 23, "duration_seconds": 2.271}, "timestamp": "2026-01-12T09:36:35.629920"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1206.357, "latencies_ms": [1206.357], "images_per_second": 0.829, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the crowd in the background. The player is near the net, while the ball is in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13429.8, "ram_available_mb": 109076.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13491.3, "ram_available_mb": 109015.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [33.05, 33.05, 33.05, 33.05, 41.41, 41.41, 41.41, 41.41, 41.41, 44.88, 44.88, 44.88], "power_watts_avg": 39.49, "power_watts_peak": 44.88, "energy_joules_est": 47.65, "sample_count": 12, "duration_seconds": 1.207}, "timestamp": "2026-01-12T09:36:36.891902"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1148.693, "latencies_ms": [1148.693], "images_per_second": 0.871, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court, with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13491.3, "ram_available_mb": 109015.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13468.8, "ram_available_mb": 109037.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.88, 44.88, 37.41, 37.41, 37.41, 37.41, 37.41, 46.79, 46.79, 46.79, 46.79, 46.79], "power_watts_avg": 42.57, "power_watts_peak": 46.79, "energy_joules_est": 48.92, "sample_count": 12, "duration_seconds": 1.149}, "timestamp": "2026-01-12T09:36:38.104220"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1550.604, "latencies_ms": [1550.604], "images_per_second": 0.645, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a tennis court with a blue surface, white lines, and a man in a yellow shirt and black shorts playing tennis. The lighting is bright, and the court is surrounded by a crowd of spectators.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13468.8, "ram_available_mb": 109037.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13481.9, "ram_available_mb": 109024.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.2, 46.2, 46.2, 46.2, 46.2, 45.55, 45.55, 45.55, 45.55, 45.55, 45.63, 45.63, 45.63, 45.63, 45.63, 33.45], "power_watts_avg": 45.02, "power_watts_peak": 46.2, "energy_joules_est": 69.83, "sample_count": 16, "duration_seconds": 1.551}, "timestamp": "2026-01-12T09:36:39.718699"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1426.489, "latencies_ms": [1426.489], "images_per_second": 0.701, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image shows a plate with two bowls of food, one containing a reddish-brown dish and the other a bowl of orange and white round objects, possibly a type of fruit or dessert.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13478.0, "ram_available_mb": 109028.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13473.8, "ram_available_mb": 109032.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.45, 33.45, 40.31, 40.31, 40.31, 40.31, 40.31, 45.61, 45.61, 45.61, 45.61, 45.61, 39.47], "power_watts_avg": 40.19, "power_watts_peak": 45.61, "energy_joules_est": 57.34, "sample_count": 15, "duration_seconds": 1.427}, "timestamp": "2026-01-12T09:36:41.234213"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2060.246, "latencies_ms": [2060.246], "images_per_second": 0.485, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bowl: 2\n3. food: 2\n4. tablecloth: 1\n5. glass: 1\n6. napkin: 1\n7. bowl of food: 1\n8. bowl of fruit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13466.0, "ram_available_mb": 109040.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13481.6, "ram_available_mb": 109024.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.47, 39.47, 39.47, 39.47, 39.31, 39.31, 39.31, 39.31, 39.31, 45.0, 45.0, 45.0, 45.0, 39.2, 39.2, 39.2, 39.2, 39.2, 33.41, 33.41, 33.41], "power_watts_avg": 39.56, "power_watts_peak": 45.0, "energy_joules_est": 81.51, "sample_count": 21, "duration_seconds": 2.061}, "timestamp": "2026-01-12T09:36:43.353633"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1768.671, "latencies_ms": [1768.671], "images_per_second": 0.565, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The two bowls are placed on the left side of the plate, with the larger bowl containing the curry on the left and the smaller bowl with the fruit on the right. The plate is positioned in the foreground, with the bowls placed on top of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13473.7, "ram_available_mb": 109032.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13470.2, "ram_available_mb": 109036.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.41, 33.41, 31.35, 31.35, 31.35, 31.35, 31.35, 44.5, 44.5, 44.5, 44.5, 44.5, 47.45, 47.45, 47.45, 47.45, 47.45, 33.45], "power_watts_avg": 39.82, "power_watts_peak": 47.45, "energy_joules_est": 70.46, "sample_count": 18, "duration_seconds": 1.769}, "timestamp": "2026-01-12T09:36:45.218938"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 718.782, "latencies_ms": [718.782], "images_per_second": 1.391, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A plate with two bowls of food on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13470.2, "ram_available_mb": 109036.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13477.8, "ram_available_mb": 109028.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.45, 33.45, 41.5, 41.5, 41.5, 41.5], "power_watts_avg": 37.48, "power_watts_peak": 41.5, "energy_joules_est": 26.95, "sample_count": 8, "duration_seconds": 0.719}, "timestamp": "2026-01-12T09:36:46.029101"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1709.987, "latencies_ms": [1709.987], "images_per_second": 0.585, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a plate with two bowls of food, one containing a reddish-brown dish and the other a bowl of orange and white food. The food is placed on a white napkin, and the background is a dark green tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13470.0, "ram_available_mb": 109036.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13479.4, "ram_available_mb": 109026.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.5, 43.82, 43.82, 43.82, 43.82, 43.82, 49.6, 49.6, 49.6, 49.6, 49.6, 46.63, 46.63, 46.63, 46.63, 46.63, 33.51, 33.51], "power_watts_avg": 44.93, "power_watts_peak": 49.6, "energy_joules_est": 76.86, "sample_count": 18, "duration_seconds": 1.711}, "timestamp": "2026-01-12T09:36:47.843268"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1278.53, "latencies_ms": [1278.53], "images_per_second": 0.782, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there are several sheep standing in a grassy area, with one sheep looking directly at the camera, and the others facing away from it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13471.5, "ram_available_mb": 109034.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13425.6, "ram_available_mb": 109080.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.51, 33.51, 32.96, 32.96, 32.96, 32.96, 32.96, 44.03, 44.03, 44.03, 44.03, 44.03, 44.72], "power_watts_avg": 38.21, "power_watts_peak": 44.72, "energy_joules_est": 48.87, "sample_count": 13, "duration_seconds": 1.279}, "timestamp": "2026-01-12T09:36:49.163769"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.624, "latencies_ms": [1902.624], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 4\n2. grass: 1\n3. wall: 1\n4. fence: 1\n5. building: 1\n6. roof: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.6, "ram_available_mb": 109080.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13423.4, "ram_available_mb": 109082.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.72, 44.72, 44.72, 44.72, 44.01, 44.01, 44.01, 44.01, 44.01, 45.93, 45.93, 45.93, 45.93, 45.93, 35.53, 35.53, 35.53, 35.53, 35.53], "power_watts_avg": 42.43, "power_watts_peak": 45.93, "energy_joules_est": 80.74, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T09:36:51.078884"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1428.153, "latencies_ms": [1428.153], "images_per_second": 0.7, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the brick wall serving as a backdrop. The sheep are standing close to each other, suggesting a sense of companionship or social interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.6, "ram_available_mb": 109090.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13429.5, "ram_available_mb": 109076.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.45, 33.45, 33.45, 45.32, 45.32, 45.32, 45.32, 45.32, 45.75, 45.75, 45.75, 45.75, 45.75], "power_watts_avg": 41.51, "power_watts_peak": 45.75, "energy_joules_est": 59.33, "sample_count": 15, "duration_seconds": 1.429}, "timestamp": "2026-01-12T09:36:52.645516"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 955.172, "latencies_ms": [955.172], "images_per_second": 1.047, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " In a sunny day, a group of sheep are standing in a grassy area near a brick wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [33.69, 33.69, 33.69, 33.69, 43.72, 43.72, 43.72, 43.72, 43.72, 44.98], "power_watts_avg": 39.83, "power_watts_peak": 44.98, "energy_joules_est": 38.07, "sample_count": 10, "duration_seconds": 0.956}, "timestamp": "2026-01-12T09:36:53.658104"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1819.906, "latencies_ms": [1819.906], "images_per_second": 0.549, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a group of sheep with thick wool coats, standing in a grassy area with a brick wall in the background. The lighting is natural and bright, suggesting it is daytime. The sheep appear to be in a rural setting, possibly a farm or pasture.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.6, "ram_available_mb": 109086.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13419.6, "ram_available_mb": 109086.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.98, 44.98, 44.98, 44.98, 45.55, 45.55, 45.55, 45.55, 45.55, 45.63, 45.63, 45.63, 45.63, 45.63, 35.07, 35.07, 35.07, 35.07, 35.07], "power_watts_avg": 42.69, "power_watts_peak": 45.63, "energy_joules_est": 77.72, "sample_count": 19, "duration_seconds": 1.82}, "timestamp": "2026-01-12T09:36:55.577048"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1112.423, "latencies_ms": [1112.423], "images_per_second": 0.899, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " In the image, a bunch of bananas and an apple are placed on a blue and white patterned background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.6, "ram_available_mb": 109086.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13459.2, "ram_available_mb": 109047.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [32.31, 32.31, 32.31, 32.31, 32.31, 41.67, 41.67, 41.67, 41.67, 41.67, 49.3, 49.3], "power_watts_avg": 39.04, "power_watts_peak": 49.3, "energy_joules_est": 43.47, "sample_count": 12, "duration_seconds": 1.113}, "timestamp": "2026-01-12T09:36:56.842439"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 804.244, "latencies_ms": [804.244], "images_per_second": 1.243, "prompt_tokens": 1446, "response_tokens_est": 9, "n_tiles": 1, "output_text": " banana: 5, apple: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13455.2, "ram_available_mb": 109051.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13456.0, "ram_available_mb": 109050.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [49.3, 49.3, 49.3, 40.51, 40.51, 40.51, 40.51, 48.63], "power_watts_avg": 44.82, "power_watts_peak": 49.3, "energy_joules_est": 36.07, "sample_count": 8, "duration_seconds": 0.805}, "timestamp": "2026-01-12T09:36:57.651747"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2139.621, "latencies_ms": [2139.621], "images_per_second": 0.467, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red apple is positioned in the center of the image, with the bananas surrounding it. The bananas are arranged in a circular pattern, with the red apple placed in the middle. The background is a blue and white floral pattern, which provides a contrast to the vibrant colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13456.0, "ram_available_mb": 109050.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13432.4, "ram_available_mb": 109073.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.63, 48.63, 48.63, 48.63, 59.39, 59.39, 59.39, 59.39, 59.39, 50.83, 50.83, 50.83, 50.83, 50.83, 40.61, 40.61, 40.61, 40.61, 40.61, 33.51, 33.51, 33.51], "power_watts_avg": 47.69, "power_watts_peak": 59.39, "energy_joules_est": 102.05, "sample_count": 22, "duration_seconds": 2.14}, "timestamp": "2026-01-12T09:36:59.871246"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1075.502, "latencies_ms": [1075.502], "images_per_second": 0.93, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " In this image, we can see a bunch of bananas and an apple placed on a surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13432.4, "ram_available_mb": 109073.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13429.2, "ram_available_mb": 109077.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 1.0}, "power_stats": {"power_watts_samples": [33.51, 33.51, 29.01, 29.01, 29.01, 29.01, 29.01, 47.83, 47.83, 47.83, 47.83], "power_watts_avg": 36.67, "power_watts_peak": 47.83, "energy_joules_est": 39.47, "sample_count": 11, "duration_seconds": 1.076}, "timestamp": "2026-01-12T09:37:01.040866"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2099.079, "latencies_ms": [2099.079], "images_per_second": 0.476, "prompt_tokens": 1442, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a vibrant mix of colors, with the red and yellow apple standing out against the green bananas. The lighting is bright and even, highlighting the textures of the fruits and the background. The bananas are arranged in a circular pattern around the apple, creating a visually appealing composition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.2, "ram_available_mb": 109081.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13460.5, "ram_available_mb": 109045.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.83, 51.89, 51.89, 51.89, 51.89, 80.91, 47.56, 47.56, 47.56, 47.56, 50.82, 50.82, 50.82, 50.82, 50.82, 35.75, 35.75, 35.75, 35.75, 35.75, 33.6], "power_watts_avg": 47.29, "power_watts_peak": 80.91, "energy_joules_est": 99.27, "sample_count": 21, "duration_seconds": 2.099}, "timestamp": "2026-01-12T09:37:03.157615"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1009.063, "latencies_ms": [1009.063], "images_per_second": 0.991, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A blue and white train with red seats is parked at a station with trees and power lines in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13460.5, "ram_available_mb": 109045.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13443.8, "ram_available_mb": 109062.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.6, 33.6, 33.6, 33.6, 41.36, 41.36, 41.36, 41.36, 41.36, 45.34, 45.34], "power_watts_avg": 39.26, "power_watts_peak": 45.34, "energy_joules_est": 39.66, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-12T09:37:04.316164"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1983.735, "latencies_ms": [1983.735], "images_per_second": 0.504, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. windows: 12\n3. doors: 2\n4. seats: 12\n5. trolley: 1\n6. tracks: 2\n7. trees: 1\n8. wires: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13443.8, "ram_available_mb": 109062.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13494.6, "ram_available_mb": 109011.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.34, 45.34, 45.34, 41.16, 41.16, 41.16, 41.16, 41.16, 45.14, 45.14, 45.14, 45.14, 45.14, 42.24, 42.24, 42.24, 42.24, 42.24, 33.45, 33.45], "power_watts_avg": 42.28, "power_watts_peak": 45.34, "energy_joules_est": 83.9, "sample_count": 20, "duration_seconds": 1.984}, "timestamp": "2026-01-12T09:37:06.335908"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1484.91, "latencies_ms": [1484.91], "images_per_second": 0.673, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, with the tracks extending towards the right. The background features a clear blue sky and trees, while the foreground includes a fence and a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13490.7, "ram_available_mb": 109015.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13470.5, "ram_available_mb": 109035.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.44, 33.44, 33.44, 33.44, 33.44, 45.12, 45.12, 45.12, 45.12, 45.12, 45.27, 45.27, 45.27], "power_watts_avg": 39.7, "power_watts_peak": 45.27, "energy_joules_est": 58.98, "sample_count": 15, "duration_seconds": 1.485}, "timestamp": "2026-01-12T09:37:07.902952"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 959.692, "latencies_ms": [959.692], "images_per_second": 1.042, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue and white train is parked at a station, with trees and other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13470.5, "ram_available_mb": 109035.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13520.6, "ram_available_mb": 108985.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 34.0}, "power_stats": {"power_watts_samples": [45.27, 45.27, 33.41, 33.41, 33.41, 33.41, 33.41, 45.98, 45.98, 45.98], "power_watts_avg": 39.55, "power_watts_peak": 45.98, "energy_joules_est": 37.97, "sample_count": 10, "duration_seconds": 0.96}, "timestamp": "2026-01-12T09:37:08.914753"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 802.131, "latencies_ms": [802.131], "images_per_second": 1.247, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The train is blue and white, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13516.6, "ram_available_mb": 108989.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13532.1, "ram_available_mb": 108974.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 25.0}, "power_stats": {"power_watts_samples": [45.98, 45.98, 45.48, 45.48, 45.48, 45.48, 45.48, 45.64], "power_watts_avg": 45.62, "power_watts_peak": 45.98, "energy_joules_est": 36.62, "sample_count": 8, "duration_seconds": 0.803}, "timestamp": "2026-01-12T09:37:09.726198"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1069.851, "latencies_ms": [1069.851], "images_per_second": 0.935, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a bathroom with a shower area, a bathtub, and a double sink vanity with a mirror above it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13532.1, "ram_available_mb": 108974.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13462.3, "ram_available_mb": 109044.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.64, 45.64, 45.64, 45.64, 55.46, 55.46, 55.46, 55.46, 55.46, 46.52, 46.52], "power_watts_avg": 50.26, "power_watts_peak": 55.46, "energy_joules_est": 53.8, "sample_count": 11, "duration_seconds": 1.07}, "timestamp": "2026-01-12T09:37:10.840968"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2059.692, "latencies_ms": [2059.692], "images_per_second": 0.486, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Shower: 1\n3. Mirror: 2\n4. Sink: 1\n5. Cabinet: 1\n6. Towel: 1\n7. Rug: 1\n8. Light: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13462.3, "ram_available_mb": 109044.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13433.6, "ram_available_mb": 109072.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.52, 46.52, 46.52, 40.37, 40.37, 40.37, 40.37, 40.37, 45.77, 45.77, 45.77, 45.77, 43.74, 43.74, 43.74, 43.74, 43.74, 33.4, 33.4, 33.4, 33.4], "power_watts_avg": 41.75, "power_watts_peak": 46.52, "energy_joules_est": 86.02, "sample_count": 21, "duration_seconds": 2.06}, "timestamp": "2026-01-12T09:37:12.956574"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1497.423, "latencies_ms": [1497.423], "images_per_second": 0.668, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The shower is located to the left of the sink, and the bathtub is situated behind the shower curtain. The sink is positioned in the foreground, with the mirror above it reflecting the bathroom's interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13433.6, "ram_available_mb": 109072.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13465.4, "ram_available_mb": 109040.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.4, 30.77, 30.77, 30.77, 30.77, 30.77, 45.42, 45.42, 45.42, 45.42, 45.42, 48.23, 48.23, 48.23, 48.23], "power_watts_avg": 40.49, "power_watts_peak": 48.23, "energy_joules_est": 60.64, "sample_count": 15, "duration_seconds": 1.498}, "timestamp": "2026-01-12T09:37:14.470413"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 855.045, "latencies_ms": [855.045], "images_per_second": 1.17, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a shower, bathtub, and sink is shown in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13457.6, "ram_available_mb": 109048.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13473.9, "ram_available_mb": 109032.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.23, 31.65, 31.65, 31.65, 31.65, 31.65, 46.3, 46.3, 46.3], "power_watts_avg": 38.38, "power_watts_peak": 48.23, "energy_joules_est": 32.82, "sample_count": 9, "duration_seconds": 0.855}, "timestamp": "2026-01-12T09:37:15.380539"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1324.974, "latencies_ms": [1324.974], "images_per_second": 0.755, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The bathroom has a warm color scheme with beige walls and a red rug on the floor. The lighting is bright and natural, coming from a window in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13466.0, "ram_available_mb": 109040.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13477.3, "ram_available_mb": 109029.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.3, 46.3, 49.13, 49.13, 49.13, 49.13, 49.13, 45.98, 45.98, 45.98, 45.98, 45.98, 45.13, 45.13], "power_watts_avg": 47.03, "power_watts_peak": 49.13, "energy_joules_est": 62.32, "sample_count": 14, "duration_seconds": 1.325}, "timestamp": "2026-01-12T09:37:16.794291"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1194.377, "latencies_ms": [1194.377], "images_per_second": 0.837, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A black and white photo captures a surfer skillfully riding a wave, with the word \"STAR\" prominently displayed in the top right corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13473.3, "ram_available_mb": 109033.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13449.7, "ram_available_mb": 109056.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.13, 45.13, 45.13, 37.51, 37.51, 37.51, 37.51, 37.51, 45.23, 45.23, 45.23, 45.23], "power_watts_avg": 41.99, "power_watts_peak": 45.23, "energy_joules_est": 50.17, "sample_count": 12, "duration_seconds": 1.195}, "timestamp": "2026-01-12T09:37:18.007967"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2008.466, "latencies_ms": [2008.466], "images_per_second": 0.498, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. wave: 1\n3. surfboard: 1\n4. water: 1\n5. sky: 0\n6. clouds: 0\n7. land: 0\n8. surfboard logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13441.8, "ram_available_mb": 109064.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13446.5, "ram_available_mb": 109059.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.23, 40.89, 40.89, 40.89, 40.89, 40.89, 46.67, 46.67, 46.67, 46.67, 46.67, 47.69, 47.69, 47.69, 47.69, 47.69, 33.43, 33.43, 33.43, 33.43], "power_watts_avg": 42.76, "power_watts_peak": 47.69, "energy_joules_est": 85.91, "sample_count": 20, "duration_seconds": 2.009}, "timestamp": "2026-01-12T09:37:20.023519"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1650.22, "latencies_ms": [1650.22], "images_per_second": 0.606, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The surfer is in the center of the image, with the wave extending from the left to the right side of the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13438.6, "ram_available_mb": 109067.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13459.5, "ram_available_mb": 109046.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.08, 33.08, 33.08, 33.08, 33.08, 45.98, 45.98, 45.98, 45.98, 45.98, 46.3, 46.3, 46.3, 46.3, 46.3, 33.28, 33.28], "power_watts_avg": 40.78, "power_watts_peak": 46.3, "energy_joules_est": 67.33, "sample_count": 17, "duration_seconds": 1.651}, "timestamp": "2026-01-12T09:37:21.786814"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 936.696, "latencies_ms": [936.696], "images_per_second": 1.068, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13455.6, "ram_available_mb": 109050.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13456.2, "ram_available_mb": 109050.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.28, 33.28, 33.28, 38.41, 38.41, 38.41, 38.41, 38.41, 45.44, 45.44], "power_watts_avg": 38.28, "power_watts_peak": 45.44, "energy_joules_est": 35.87, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-12T09:37:22.797843"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1936.215, "latencies_ms": [1936.215], "images_per_second": 0.516, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image is in black and white, with the surfer's silhouette standing out against the white foam of the wave. The lighting is natural, with the sun reflecting off the water, creating a dramatic contrast between the dark silhouette of the surfer and the bright white of the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13456.2, "ram_available_mb": 109050.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13426.5, "ram_available_mb": 109079.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.44, 45.44, 45.44, 45.52, 45.52, 45.52, 45.52, 45.52, 45.36, 45.36, 45.36, 45.36, 45.36, 41.32, 41.32, 41.32, 41.32, 41.32, 33.35, 33.35], "power_watts_avg": 43.2, "power_watts_peak": 45.52, "energy_joules_est": 83.67, "sample_count": 20, "duration_seconds": 1.937}, "timestamp": "2026-01-12T09:37:24.814577"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1689.046, "latencies_ms": [1689.046], "images_per_second": 0.592, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " A baseball player in a white uniform with the number 10 on it is standing at home plate with a bat over his shoulder, while a catcher in a black uniform and a umpire in a blue shirt are behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.5, "ram_available_mb": 109079.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13425.2, "ram_available_mb": 109081.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.35, 33.35, 33.49, 33.49, 33.49, 33.49, 33.49, 44.25, 44.25, 44.25, 44.25, 44.25, 44.39, 44.39, 44.39, 44.39, 44.39], "power_watts_avg": 39.85, "power_watts_peak": 44.39, "energy_joules_est": 67.33, "sample_count": 17, "duration_seconds": 1.69}, "timestamp": "2026-01-12T09:37:26.580751"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2011.213, "latencies_ms": [2011.213], "images_per_second": 0.497, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. baseball: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.3, "ram_available_mb": 109089.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13428.3, "ram_available_mb": 109078.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.45, 33.45, 33.45, 46.55, 46.55, 46.55, 46.55, 46.55, 46.52, 46.52, 46.52, 46.52, 46.52, 33.44, 33.44, 33.44, 33.44, 33.44], "power_watts_avg": 39.99, "power_watts_peak": 46.55, "energy_joules_est": 80.45, "sample_count": 20, "duration_seconds": 2.012}, "timestamp": "2026-01-12T09:37:28.599489"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1375.781, "latencies_ms": [1375.781], "images_per_second": 0.727, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.4, "ram_available_mb": 109085.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13434.3, "ram_available_mb": 109072.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.48, 33.48, 33.48, 33.48, 44.75, 44.75, 44.75, 44.75, 44.75, 45.94, 45.94, 45.94, 45.94, 45.94], "power_watts_avg": 41.96, "power_watts_peak": 45.94, "energy_joules_est": 57.77, "sample_count": 14, "duration_seconds": 1.377}, "timestamp": "2026-01-12T09:37:30.064606"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 844.625, "latencies_ms": [844.625], "images_per_second": 1.184, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball game is taking place in a stadium with a crowd of people watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.3, "ram_available_mb": 109076.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13444.3, "ram_available_mb": 109062.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.21, 35.21, 35.21, 35.21, 35.21, 46.29, 46.29, 46.29, 46.29], "power_watts_avg": 40.13, "power_watts_peak": 46.29, "energy_joules_est": 33.91, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-12T09:37:30.976108"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2155.223, "latencies_ms": [2155.223], "images_per_second": 0.464, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white uniforms and the lush green grass of the field contrasting against the blue sky. The lighting is natural, casting a warm glow on the players and the field, and the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.5, "ram_available_mb": 109069.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13436.1, "ram_available_mb": 109070.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.29, 44.16, 44.16, 44.16, 44.16, 44.16, 45.49, 45.49, 45.49, 45.49, 45.49, 48.25, 48.25, 48.25, 48.25, 48.25, 33.44, 33.44, 33.44, 33.44, 33.44, 33.31], "power_watts_avg": 42.56, "power_watts_peak": 48.25, "energy_joules_est": 91.74, "sample_count": 22, "duration_seconds": 2.156}, "timestamp": "2026-01-12T09:37:33.194920"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1013.362, "latencies_ms": [1013.362], "images_per_second": 0.987, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13428.2, "ram_available_mb": 109078.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13460.2, "ram_available_mb": 109046.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.31, 33.31, 33.31, 33.31, 37.35, 37.35, 37.35, 37.35, 48.37, 48.37, 48.37], "power_watts_avg": 38.88, "power_watts_peak": 48.37, "energy_joules_est": 39.45, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-12T09:37:34.357456"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1602.016, "latencies_ms": [1602.016], "images_per_second": 0.624, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " apple: 2, grapes: 10, orange: 1, grapes: 10, grapes: 10, grapes: 10, grapes: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13455.6, "ram_available_mb": 109050.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13439.8, "ram_available_mb": 109066.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.37, 48.37, 45.3, 45.3, 45.3, 45.3, 45.3, 48.91, 48.91, 48.91, 48.91, 48.91, 49.27, 49.27, 49.27, 49.27], "power_watts_avg": 47.8, "power_watts_peak": 49.27, "energy_joules_est": 76.61, "sample_count": 16, "duration_seconds": 1.603}, "timestamp": "2026-01-12T09:37:35.972643"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2146.434, "latencies_ms": [2146.434], "images_per_second": 0.466, "prompt_tokens": 1450, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The main objects are arranged in a diagonal line from the top left to the bottom right, with the grapes and oranges placed in the foreground and the peanuts in the background. The objects are positioned in a way that the grapes and oranges are closer to the viewer, while the peanuts are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13439.8, "ram_available_mb": 109066.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13446.5, "ram_available_mb": 109059.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.27, 32.01, 32.01, 32.01, 32.01, 32.01, 50.57, 50.57, 50.57, 50.57, 50.57, 52.41, 52.41, 52.41, 52.41, 52.41, 33.58, 33.58, 33.58, 33.58, 33.58, 33.57], "power_watts_avg": 42.08, "power_watts_peak": 52.41, "energy_joules_est": 90.34, "sample_count": 22, "duration_seconds": 2.147}, "timestamp": "2026-01-12T09:37:38.183649"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1890.169, "latencies_ms": [1890.169], "images_per_second": 0.529, "prompt_tokens": 1444, "response_tokens_est": 50, "n_tiles": 1, "output_text": " In this black and white photo, we see a collection of fruits and nuts arranged in a visually appealing manner. The fruits, including a large orange, a bunch of grapes, and a pear, are placed on a bed of small, round nuts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.3, "ram_available_mb": 109069.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13454.0, "ram_available_mb": 109052.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.57, 33.57, 33.57, 33.57, 38.03, 38.03, 38.03, 38.03, 38.03, 48.52, 48.52, 48.52, 48.52, 48.52, 44.91, 44.91, 44.91, 44.91, 44.91], "power_watts_avg": 41.66, "power_watts_peak": 48.52, "energy_joules_est": 78.79, "sample_count": 19, "duration_seconds": 1.891}, "timestamp": "2026-01-12T09:37:40.149309"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1218.725, "latencies_ms": [1218.725], "images_per_second": 0.821, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a black and white photo with a white background, and the fruits are all in shades of white and gray.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13449.4, "ram_available_mb": 109056.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13455.1, "ram_available_mb": 109051.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.8, 33.8, 33.8, 33.8, 40.72, 40.72, 40.72, 40.72, 40.72, 49.68, 49.68, 49.68, 49.68], "power_watts_avg": 41.35, "power_watts_peak": 49.68, "energy_joules_est": 50.42, "sample_count": 13, "duration_seconds": 1.219}, "timestamp": "2026-01-12T09:37:41.513624"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1682.384, "latencies_ms": [1682.384], "images_per_second": 0.594, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where a variety of vehicles, including cars and a bus, are in motion, while pedestrians navigate the sidewalks, and buildings of different architectural styles line the street, creating a vibrant and dynamic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13445.9, "ram_available_mb": 109060.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13443.6, "ram_available_mb": 109062.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [49.68, 41.19, 41.19, 41.19, 41.19, 41.19, 45.3, 45.3, 45.3, 45.3, 45.3, 47.41, 47.41, 47.41, 47.41, 47.41, 33.71], "power_watts_avg": 44.29, "power_watts_peak": 49.68, "energy_joules_est": 74.52, "sample_count": 17, "duration_seconds": 1.683}, "timestamp": "2026-01-12T09:37:43.228494"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1976.542, "latencies_ms": [1976.542], "images_per_second": 0.506, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. street: 2 lanes\n2. car: 2\n3. building: 3\n4. sidewalk: 1\n5. streetlight: 2\n6. tree: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13443.6, "ram_available_mb": 109062.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13422.1, "ram_available_mb": 109084.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.71, 33.71, 33.71, 33.71, 41.51, 41.51, 41.51, 41.51, 41.51, 46.32, 46.32, 46.32, 46.32, 46.32, 39.34, 39.34, 39.34, 39.34, 39.34, 33.4], "power_watts_avg": 40.2, "power_watts_peak": 46.32, "energy_joules_est": 79.48, "sample_count": 20, "duration_seconds": 1.977}, "timestamp": "2026-01-12T09:37:45.244198"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2372.845, "latencies_ms": [2372.845], "images_per_second": 0.421, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The main objects in the image are positioned in a way that the street is in the foreground, with the buildings and trees in the background. The street is on the left side of the image, while the buildings and trees are on the right side. The buildings are located on both sides of the street, with the trees located on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.1, "ram_available_mb": 109084.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13477.5, "ram_available_mb": 109028.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.4, 33.4, 33.4, 33.4, 40.38, 40.38, 40.38, 40.38, 40.38, 46.01, 46.01, 46.01, 46.01, 46.01, 39.75, 39.75, 39.75, 39.75, 39.75, 33.36, 33.36, 33.36, 33.36, 33.36], "power_watts_avg": 38.8, "power_watts_peak": 46.01, "energy_joules_est": 92.08, "sample_count": 24, "duration_seconds": 2.373}, "timestamp": "2026-01-12T09:37:47.663384"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1827.258, "latencies_ms": [1827.258], "images_per_second": 0.547, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where modern buildings of varying heights and designs line the street. The buildings are predominantly white and red, with some featuring balconies and windows. The street is busy with cars and pedestrians, indicating a lively and active environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13469.6, "ram_available_mb": 109036.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13461.3, "ram_available_mb": 109045.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.42, 33.42, 33.42, 33.42, 40.8, 40.8, 40.8, 40.8, 40.8, 45.12, 45.12, 45.12, 45.12, 45.12, 38.34, 38.34, 38.34, 38.34, 38.34], "power_watts_avg": 39.73, "power_watts_peak": 45.12, "energy_joules_est": 72.64, "sample_count": 19, "duration_seconds": 1.828}, "timestamp": "2026-01-12T09:37:49.632937"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1265.949, "latencies_ms": [1265.949], "images_per_second": 0.79, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a street with a clear blue sky and a few clouds. The buildings are made of brick and concrete, and the road is paved with asphalt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13457.4, "ram_available_mb": 109048.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13474.5, "ram_available_mb": 109031.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.46, 33.46, 33.46, 33.46, 41.36, 41.36, 41.36, 41.36, 41.36, 44.32, 44.32, 44.32, 44.32], "power_watts_avg": 39.84, "power_watts_peak": 44.32, "energy_joules_est": 50.46, "sample_count": 13, "duration_seconds": 1.267}, "timestamp": "2026-01-12T09:37:50.997713"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1372.743, "latencies_ms": [1372.743], "images_per_second": 0.728, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, there are two people standing close to each other, with one person wearing a blue shirt and the other wearing a white shirt, both smiling and embracing each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13466.6, "ram_available_mb": 109039.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13471.7, "ram_available_mb": 109034.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.32, 35.42, 35.42, 35.42, 35.42, 35.42, 46.25, 46.25, 46.25, 46.25, 46.25, 47.9, 47.9, 47.9], "power_watts_avg": 42.6, "power_watts_peak": 47.9, "energy_joules_est": 58.5, "sample_count": 14, "duration_seconds": 1.373}, "timestamp": "2026-01-12T09:37:52.414936"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1903.109, "latencies_ms": [1903.109], "images_per_second": 0.525, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. tie: 1\n4. shirt: 1\n5. glasses: 1\n6. chair: 1\n7. television: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13467.7, "ram_available_mb": 109038.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13455.1, "ram_available_mb": 109051.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.9, 47.9, 33.27, 33.27, 33.27, 33.27, 33.27, 46.29, 46.29, 46.29, 46.29, 46.29, 46.51, 46.51, 46.51, 46.51, 46.51, 33.48, 33.48], "power_watts_avg": 41.74, "power_watts_peak": 47.9, "energy_joules_est": 79.45, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T09:37:54.332008"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1976.533, "latencies_ms": [1976.533], "images_per_second": 0.506, "prompt_tokens": 1118, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, with her arm around his shoulder. The man is standing in front of the woman, with his arm around her waist. The television is mounted on the wall behind them, and the clock is on the wall to the left of the television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13447.2, "ram_available_mb": 109059.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13458.0, "ram_available_mb": 109048.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.48, 33.48, 34.26, 34.26, 34.26, 34.26, 34.26, 45.84, 45.84, 45.84, 45.84, 45.84, 45.65, 45.65, 45.65, 45.65, 45.65, 33.59, 33.59, 33.59], "power_watts_avg": 39.82, "power_watts_peak": 45.84, "energy_joules_est": 78.75, "sample_count": 20, "duration_seconds": 1.978}, "timestamp": "2026-01-12T09:37:56.400792"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 717.35, "latencies_ms": [717.35], "images_per_second": 1.394, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " Two people are posing for a picture in a bar.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13458.0, "ram_available_mb": 109048.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13519.4, "ram_available_mb": 108986.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.59, 33.59, 30.76, 30.76, 30.76, 30.76, 30.76, 45.31], "power_watts_avg": 33.29, "power_watts_peak": 45.31, "energy_joules_est": 23.91, "sample_count": 8, "duration_seconds": 0.718}, "timestamp": "2026-01-12T09:37:57.263097"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1069.569, "latencies_ms": [1069.569], "images_per_second": 0.935, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the subjects are wearing formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13515.4, "ram_available_mb": 108990.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13520.2, "ram_available_mb": 108986.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [45.31, 45.31, 45.31, 53.57, 53.57, 53.57, 53.57, 53.57, 44.92, 44.92, 44.92], "power_watts_avg": 48.96, "power_watts_peak": 53.57, "energy_joules_est": 52.39, "sample_count": 11, "duration_seconds": 1.07}, "timestamp": "2026-01-12T09:37:58.376565"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 906.533, "latencies_ms": [906.533], "images_per_second": 1.103, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a costume is smiling at the camera while standing in a crowd of people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13520.2, "ram_available_mb": 108986.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13519.6, "ram_available_mb": 108986.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.92, 44.92, 40.72, 40.72, 40.72, 40.72, 40.72, 46.07, 46.07, 46.07], "power_watts_avg": 43.16, "power_watts_peak": 46.07, "energy_joules_est": 39.16, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-12T09:37:59.387557"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1985.127, "latencies_ms": [1985.127], "images_per_second": 0.504, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. headband: 1\n4. earring: 1\n5. necklace: 1\n6. bracelet: 1\n7. shirt: 1\n8. pants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13511.7, "ram_available_mb": 108994.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13492.0, "ram_available_mb": 109014.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.07, 46.07, 45.35, 45.35, 45.35, 45.35, 45.35, 45.04, 45.04, 45.04, 45.04, 45.04, 45.51, 45.51, 45.51, 45.51, 45.51, 33.48, 33.48, 33.48], "power_watts_avg": 43.6, "power_watts_peak": 46.07, "energy_joules_est": 86.58, "sample_count": 20, "duration_seconds": 1.986}, "timestamp": "2026-01-12T09:38:01.405481"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1430.326, "latencies_ms": [1430.326], "images_per_second": 0.699, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a black and gold costume, while the man is in the background, wearing a white hat. The woman is closer to the camera than the man.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13488.1, "ram_available_mb": 109018.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13479.7, "ram_available_mb": 109026.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.48, 33.48, 30.47, 30.47, 30.47, 30.47, 45.45, 45.45, 45.45, 45.45, 45.45, 48.43, 48.43, 48.43, 48.43], "power_watts_avg": 40.65, "power_watts_peak": 48.43, "energy_joules_est": 58.17, "sample_count": 15, "duration_seconds": 1.431}, "timestamp": "2026-01-12T09:38:02.972887"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 950.209, "latencies_ms": [950.209], "images_per_second": 1.052, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered in an outdoor setting, dressed in elaborate costumes and engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13471.9, "ram_available_mb": 109034.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13486.0, "ram_available_mb": 109020.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [48.43, 30.72, 30.72, 30.72, 30.72, 30.72, 45.37, 45.37, 45.37, 45.37], "power_watts_avg": 38.35, "power_watts_peak": 48.43, "energy_joules_est": 36.46, "sample_count": 10, "duration_seconds": 0.951}, "timestamp": "2026-01-12T09:38:03.983810"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 999.572, "latencies_ms": [999.572], "images_per_second": 1.0, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the woman is wearing a black and gold costume.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13478.1, "ram_available_mb": 109028.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13472.2, "ram_available_mb": 109034.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [45.37, 45.6, 45.6, 45.6, 45.6, 45.6, 46.01, 46.01, 46.01, 46.01], "power_watts_avg": 45.74, "power_watts_peak": 46.01, "energy_joules_est": 45.74, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-12T09:38:04.996881"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2113.904, "latencies_ms": [2113.904], "images_per_second": 0.473, "prompt_tokens": 1100, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image depicts a small bathroom with white tiled walls and floor, a white toilet, a white sink, a white shower head, a white pipe, a white toilet tank, a white soap dish, a white toilet paper holder, a green bucket, a red bucket, a white drain, and a white window.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13468.2, "ram_available_mb": 109038.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13381.6, "ram_available_mb": 109124.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.01, 47.27, 47.27, 47.27, 47.27, 47.27, 46.77, 46.77, 46.77, 46.77, 46.77, 47.87, 47.87, 47.87, 47.87, 47.87, 33.6, 33.6, 33.6, 33.6, 33.6], "power_watts_avg": 43.98, "power_watts_peak": 47.87, "energy_joules_est": 92.99, "sample_count": 21, "duration_seconds": 2.114}, "timestamp": "2026-01-12T09:38:07.117527"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1540.163, "latencies_ms": [1540.163], "images_per_second": 0.649, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. white pipe\n2. white toilet\n3. white shower head\n4. white sink\n5. white toilet tank\n6. white bathtub\n7. white window\n8. white bucket", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.6, "ram_available_mb": 109124.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13440.7, "ram_available_mb": 109065.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.56, 33.56, 33.56, 33.56, 43.58, 43.58, 43.58, 43.58, 43.58, 45.66, 45.66, 45.66, 45.66, 45.66, 35.89, 35.89], "power_watts_avg": 40.76, "power_watts_peak": 45.66, "energy_joules_est": 62.82, "sample_count": 16, "duration_seconds": 1.541}, "timestamp": "2026-01-12T09:38:08.783012"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1747.671, "latencies_ms": [1747.671], "images_per_second": 0.572, "prompt_tokens": 1118, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The green bucket is located in the foreground, near the wall, while the red bucket is positioned further back, near the sink. The white pipe runs vertically from the left side of the image to the right, with the toilet situated in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13432.8, "ram_available_mb": 109073.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.89, 35.89, 35.89, 38.21, 38.21, 38.21, 38.21, 38.21, 45.4, 45.4, 45.4, 45.4, 45.4, 41.74, 41.74, 41.74, 41.74, 41.74], "power_watts_avg": 40.8, "power_watts_peak": 45.4, "energy_joules_est": 71.33, "sample_count": 18, "duration_seconds": 1.748}, "timestamp": "2026-01-12T09:38:10.600370"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 985.484, "latencies_ms": [985.484], "images_per_second": 1.015, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A small bathroom with white walls and a white floor has a shower, a toilet, and a sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.2, "ram_available_mb": 109080.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13427.7, "ram_available_mb": 109078.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [33.32, 33.32, 33.32, 33.32, 33.32, 45.42, 45.42, 45.42, 45.42, 45.42], "power_watts_avg": 39.37, "power_watts_peak": 45.42, "energy_joules_est": 38.82, "sample_count": 10, "duration_seconds": 0.986}, "timestamp": "2026-01-12T09:38:11.612193"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 930.12, "latencies_ms": [930.12], "images_per_second": 1.075, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is white with a blue and green bucket, and a window with a black frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.8, "ram_available_mb": 109086.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13433.6, "ram_available_mb": 109072.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [45.86, 45.86, 45.86, 45.86, 45.86, 46.47, 46.47, 46.47, 46.47, 46.47], "power_watts_avg": 46.16, "power_watts_peak": 46.47, "energy_joules_est": 42.96, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-12T09:38:12.624925"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1100.454, "latencies_ms": [1100.454], "images_per_second": 0.909, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing glasses and a green shirt is standing next to a large gray elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13429.7, "ram_available_mb": 109076.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13432.4, "ram_available_mb": 109073.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.32, 46.32, 46.32, 46.32, 46.32, 45.88, 45.88, 45.88, 45.88, 45.88, 45.44], "power_watts_avg": 46.04, "power_watts_peak": 46.32, "energy_joules_est": 50.67, "sample_count": 11, "duration_seconds": 1.101}, "timestamp": "2026-01-12T09:38:13.736354"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1480.054, "latencies_ms": [1480.054], "images_per_second": 0.676, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " elephant: 1, man: 1, glasses: 1, shirt: 1, elephant's trunk: 1, elephant's ear: 1, man's hand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13424.5, "ram_available_mb": 109081.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13425.6, "ram_available_mb": 109080.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.44, 45.44, 45.44, 45.44, 42.3, 42.3, 42.3, 42.3, 42.3, 46.83, 46.83, 46.83, 46.83, 46.83, 38.34], "power_watts_avg": 44.38, "power_watts_peak": 46.83, "energy_joules_est": 65.71, "sample_count": 15, "duration_seconds": 1.481}, "timestamp": "2026-01-12T09:38:15.252516"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1374.634, "latencies_ms": [1374.634], "images_per_second": 0.727, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The man is standing to the right of the elephant, with the elephant's trunk reaching towards his face. The man is in the foreground, while the elephant is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.8, "ram_available_mb": 109088.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13426.9, "ram_available_mb": 109079.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.34, 38.34, 38.34, 38.34, 41.49, 41.49, 41.49, 41.49, 41.49, 46.21, 46.21, 46.21, 46.21, 33.32], "power_watts_avg": 41.36, "power_watts_peak": 46.21, "energy_joules_est": 56.87, "sample_count": 14, "duration_seconds": 1.375}, "timestamp": "2026-01-12T09:38:16.667972"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 973.862, "latencies_ms": [973.862], "images_per_second": 1.027, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing glasses is standing next to an elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.9, "ram_available_mb": 109079.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13421.6, "ram_available_mb": 109084.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [39.12, 39.12, 39.12, 39.12, 43.75, 43.75, 43.75, 43.75, 43.75, 45.79], "power_watts_avg": 42.1, "power_watts_peak": 45.79, "energy_joules_est": 41.02, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-12T09:38:17.679429"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1956.653, "latencies_ms": [1956.653], "images_per_second": 0.511, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a man wearing glasses and a green shirt standing next to a large gray elephant. The elephant's skin is wrinkled and rough, and the man's hand is gently touching the elephant's head. The background is a lush green forest with trees and hills visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.6, "ram_available_mb": 109084.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13421.8, "ram_available_mb": 109084.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.79, 45.79, 45.79, 45.79, 47.82, 47.82, 47.82, 47.82, 47.82, 46.6, 46.6, 46.6, 46.6, 46.6, 35.27, 35.27, 35.27, 35.27, 35.27, 33.54], "power_watts_avg": 43.26, "power_watts_peak": 47.82, "energy_joules_est": 84.66, "sample_count": 20, "duration_seconds": 1.957}, "timestamp": "2026-01-12T09:38:19.699082"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 943.662, "latencies_ms": [943.662], "images_per_second": 1.06, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Five children are sitting on the grass holding frisbees, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13413.9, "ram_available_mb": 109092.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13429.8, "ram_available_mb": 109076.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.54, 33.54, 33.54, 33.54, 40.29, 40.29, 40.29, 40.29, 40.29, 44.8], "power_watts_avg": 38.04, "power_watts_peak": 44.8, "energy_joules_est": 35.95, "sample_count": 10, "duration_seconds": 0.945}, "timestamp": "2026-01-12T09:38:20.764154"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 606.417, "latencies_ms": [606.417], "images_per_second": 1.649, "prompt_tokens": 1113, "response_tokens_est": 7, "n_tiles": 1, "output_text": " 1. boy: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13429.8, "ram_available_mb": 109076.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13413.8, "ram_available_mb": 109092.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.8, 44.8, 44.8, 45.35, 45.35, 45.35, 45.35], "power_watts_avg": 45.11, "power_watts_peak": 45.35, "energy_joules_est": 27.38, "sample_count": 7, "duration_seconds": 0.607}, "timestamp": "2026-01-12T09:38:21.474861"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1719.123, "latencies_ms": [1719.123], "images_per_second": 0.582, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The frisbees are positioned in the foreground of the image, with the children sitting in the background. The frisbees are held by the children, with one child holding a white frisbee and another holding a blue frisbee.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13413.8, "ram_available_mb": 109092.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13405.2, "ram_available_mb": 109101.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.35, 42.84, 42.84, 42.84, 42.84, 42.84, 50.95, 50.95, 50.95, 50.95, 50.95, 48.21, 48.21, 48.21, 48.21, 48.21, 33.6, 33.6], "power_watts_avg": 45.7, "power_watts_peak": 50.95, "energy_joules_est": 78.59, "sample_count": 18, "duration_seconds": 1.72}, "timestamp": "2026-01-12T09:38:23.287991"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 871.449, "latencies_ms": [871.449], "images_per_second": 1.148, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Five children are sitting on the grass in a grassy area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.4, "ram_available_mb": 109108.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13421.4, "ram_available_mb": 109084.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.6, 33.6, 33.6, 39.11, 39.11, 39.11, 39.11, 39.11, 45.49], "power_watts_avg": 37.98, "power_watts_peak": 45.49, "energy_joules_est": 33.11, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-12T09:38:24.198954"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1194.946, "latencies_ms": [1194.946], "images_per_second": 0.837, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a bright, sunny day with clear blue sky. The children are sitting on the grass, which is green and lush.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.4, "ram_available_mb": 109088.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13418.8, "ram_available_mb": 109087.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.49, 45.49, 45.49, 45.49, 50.81, 50.81, 50.81, 50.81, 50.81, 46.23, 46.23, 46.23], "power_watts_avg": 47.89, "power_watts_peak": 50.81, "energy_joules_est": 57.24, "sample_count": 12, "duration_seconds": 1.195}, "timestamp": "2026-01-12T09:38:25.411699"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1121.351, "latencies_ms": [1121.351], "images_per_second": 0.892, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young girl wearing a red coat and holding a black umbrella with pink designs stands on a wet sidewalk in front of a bush.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.0, "ram_available_mb": 109095.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13426.6, "ram_available_mb": 109079.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.23, 46.23, 36.79, 36.79, 36.79, 36.79, 36.79, 46.27, 46.27, 46.27, 46.27, 46.27], "power_watts_avg": 42.31, "power_watts_peak": 46.27, "energy_joules_est": 47.45, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-12T09:38:26.627539"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1319.922, "latencies_ms": [1319.922], "images_per_second": 0.758, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " umbrella: 1, child: 1, sidewalk: 1, house: 1, bush: 1, car: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.6, "ram_available_mb": 109079.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13425.5, "ram_available_mb": 109080.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [46.12, 46.12, 46.12, 46.12, 46.12, 45.36, 45.36, 45.36, 45.36, 45.36, 45.92, 45.92, 45.92, 45.92], "power_watts_avg": 45.79, "power_watts_peak": 46.12, "energy_joules_est": 60.46, "sample_count": 14, "duration_seconds": 1.32}, "timestamp": "2026-01-12T09:38:28.041555"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1457.562, "latencies_ms": [1457.562], "images_per_second": 0.686, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The child is standing in the foreground of the image, with the umbrella held above her head. The umbrella is positioned to the left of the child, and the background features a house and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.6, "ram_available_mb": 109084.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13431.2, "ram_available_mb": 109075.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.92, 31.88, 31.88, 31.88, 31.88, 31.88, 45.36, 45.36, 45.36, 45.36, 45.36, 47.52, 47.52, 47.52, 47.52], "power_watts_avg": 41.48, "power_watts_peak": 47.52, "energy_joules_est": 60.48, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-12T09:38:29.556627"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 800.872, "latencies_ms": [800.872], "images_per_second": 1.249, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A little girl is standing on a sidewalk with a black umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.2, "ram_available_mb": 109075.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13420.9, "ram_available_mb": 109085.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [47.52, 32.54, 32.54, 32.54, 32.54, 32.54, 45.51, 45.51], "power_watts_avg": 37.65, "power_watts_peak": 47.52, "energy_joules_est": 30.17, "sample_count": 8, "duration_seconds": 0.801}, "timestamp": "2026-01-12T09:38:30.365241"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1354.133, "latencies_ms": [1354.133], "images_per_second": 0.738, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image shows a young girl wearing a red coat and holding a black umbrella with pink patterns. The scene is set on a rainy day with wet pavement and a gray sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.9, "ram_available_mb": 109089.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13432.4, "ram_available_mb": 109073.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.51, 45.51, 49.71, 49.71, 49.71, 49.71, 49.71, 46.64, 46.64, 46.64, 46.64, 46.64, 43.82, 43.82], "power_watts_avg": 47.17, "power_watts_peak": 49.71, "energy_joules_est": 63.89, "sample_count": 14, "duration_seconds": 1.354}, "timestamp": "2026-01-12T09:38:31.777768"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1380.175, "latencies_ms": [1380.175], "images_per_second": 0.725, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a group of elephants, including a young one, are walking through a muddy area near a body of water, with the young elephant in the foreground prominently displayed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13424.6, "ram_available_mb": 109081.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13417.3, "ram_available_mb": 109089.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.82, 43.82, 43.82, 39.77, 39.77, 39.77, 39.77, 39.77, 46.0, 46.0, 46.0, 46.0, 46.0, 39.85], "power_watts_avg": 42.87, "power_watts_peak": 46.0, "energy_joules_est": 59.2, "sample_count": 14, "duration_seconds": 1.381}, "timestamp": "2026-01-12T09:38:33.191671"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1324.938, "latencies_ms": [1324.938], "images_per_second": 0.755, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 1, trunk: 1, ear: 1, eye: 1, tail: 1, leg: 1, water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13409.4, "ram_available_mb": 109096.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13421.0, "ram_available_mb": 109085.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [39.85, 39.85, 39.85, 39.85, 43.91, 43.91, 43.91, 43.91, 43.91, 46.69, 46.69, 46.69, 46.69, 46.69], "power_watts_avg": 43.74, "power_watts_peak": 46.69, "energy_joules_est": 57.97, "sample_count": 14, "duration_seconds": 1.325}, "timestamp": "2026-01-12T09:38:34.605517"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1374.589, "latencies_ms": [1374.589], "images_per_second": 0.727, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking towards the left side of the image, with the main elephant leading the way.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13417.1, "ram_available_mb": 109089.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13406.0, "ram_available_mb": 109100.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [36.15, 36.15, 36.15, 36.15, 36.15, 45.41, 45.41, 45.41, 45.41, 45.41, 46.33, 46.33, 46.33, 46.33], "power_watts_avg": 42.37, "power_watts_peak": 46.33, "energy_joules_est": 58.25, "sample_count": 14, "duration_seconds": 1.375}, "timestamp": "2026-01-12T09:38:36.019895"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 984.325, "latencies_ms": [984.325], "images_per_second": 1.016, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of elephants, including a baby, are walking through a muddy area near a body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.2, "ram_available_mb": 109108.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13417.9, "ram_available_mb": 109088.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 49.0}, "power_stats": {"power_watts_samples": [46.33, 32.17, 32.17, 32.17, 32.17, 32.17, 46.41, 46.41, 46.41, 46.41], "power_watts_avg": 39.28, "power_watts_peak": 46.41, "energy_joules_est": 38.68, "sample_count": 10, "duration_seconds": 0.985}, "timestamp": "2026-01-12T09:38:37.031475"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1911.876, "latencies_ms": [1911.876], "images_per_second": 0.523, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a group of elephants in a natural setting with a mix of earthy tones, including the brown of the elephants and the red of the dirt. The lighting appears to be natural, with the elephants casting shadows on the ground, and the sky is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.9, "ram_available_mb": 109088.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13407.0, "ram_available_mb": 109099.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.41, 46.27, 46.27, 46.27, 46.27, 46.27, 46.61, 46.61, 46.61, 46.61, 46.61, 47.67, 47.67, 47.67, 47.67, 47.67, 33.63, 33.63, 33.63, 33.63], "power_watts_avg": 44.18, "power_watts_peak": 47.67, "energy_joules_est": 84.49, "sample_count": 20, "duration_seconds": 1.912}, "timestamp": "2026-01-12T09:38:39.048380"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1066.784, "latencies_ms": [1066.784], "images_per_second": 0.937, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13405.2, "ram_available_mb": 109101.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13444.3, "ram_available_mb": 109062.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.63, 31.38, 31.38, 31.38, 31.38, 31.38, 47.26, 47.26, 47.26, 47.26, 47.26], "power_watts_avg": 38.8, "power_watts_peak": 47.26, "energy_joules_est": 41.4, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T09:38:40.163831"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2254.285, "latencies_ms": [2254.285], "images_per_second": 0.444, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. wave: 1\n3. surfboard: 1\n4. water: 1\n5. sky: 0\n6. surfboard deck: 1\n7. surfboard leash: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.5, "ram_available_mb": 109069.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13458.9, "ram_available_mb": 109047.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [51.25, 51.25, 51.25, 51.25, 45.87, 45.87, 45.87, 45.87, 45.87, 49.85, 49.85, 49.85, 49.85, 49.85, 41.24, 41.24, 41.24, 41.24, 41.24, 33.94, 33.94, 33.94, 33.94], "power_watts_avg": 44.59, "power_watts_peak": 51.25, "energy_joules_est": 100.53, "sample_count": 23, "duration_seconds": 2.255}, "timestamp": "2026-01-12T09:38:42.478265"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1659.424, "latencies_ms": [1659.424], "images_per_second": 0.603, "prompt_tokens": 1450, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the background, with the surfer's body and surfboard occupying the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13458.9, "ram_available_mb": 109047.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13450.9, "ram_available_mb": 109055.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.94, 31.23, 31.23, 31.23, 31.23, 31.23, 50.0, 50.0, 50.0, 50.0, 50.0, 52.64, 52.64, 52.64, 52.64, 52.64, 33.51], "power_watts_avg": 43.34, "power_watts_peak": 52.64, "energy_joules_est": 71.94, "sample_count": 17, "duration_seconds": 1.66}, "timestamp": "2026-01-12T09:38:44.196918"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 889.603, "latencies_ms": [889.603], "images_per_second": 1.124, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13450.9, "ram_available_mb": 109055.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13433.0, "ram_available_mb": 109073.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.51, 33.51, 33.51, 33.51, 41.05, 41.05, 41.05, 41.05, 41.05], "power_watts_avg": 37.7, "power_watts_peak": 41.05, "energy_joules_est": 33.55, "sample_count": 9, "duration_seconds": 0.89}, "timestamp": "2026-01-12T09:38:45.114105"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1154.813, "latencies_ms": [1154.813], "images_per_second": 0.866, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a red and green wetsuit, and the wave is a deep green color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13433.0, "ram_available_mb": 109073.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13429.0, "ram_available_mb": 109077.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [49.55, 49.55, 49.55, 49.55, 49.55, 55.05, 55.05, 55.05, 55.05, 55.05, 50.66, 50.66], "power_watts_avg": 52.03, "power_watts_peak": 55.05, "energy_joules_est": 60.11, "sample_count": 12, "duration_seconds": 1.155}, "timestamp": "2026-01-12T09:38:46.325027"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.194, "latencies_ms": [983.194], "images_per_second": 1.017, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean and a few people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.1, "ram_available_mb": 109085.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13416.4, "ram_available_mb": 109089.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [50.66, 50.66, 50.66, 42.82, 42.82, 42.82, 42.82, 42.82, 45.78, 45.78], "power_watts_avg": 45.76, "power_watts_peak": 50.66, "energy_joules_est": 45.02, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-12T09:38:47.335727"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1907.932, "latencies_ms": [1907.932], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. rider: 1\n4. rider: 1\n5. rider: 1\n6. rider: 1\n7. rider: 1\n8. rider: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.4, "ram_available_mb": 109089.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13398.0, "ram_available_mb": 109108.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.78, 45.78, 45.78, 46.29, 46.29, 46.29, 46.29, 46.29, 46.39, 46.39, 46.39, 46.39, 46.39, 43.4, 43.4, 43.4, 43.4, 43.4, 33.79], "power_watts_avg": 44.82, "power_watts_peak": 46.39, "energy_joules_est": 85.52, "sample_count": 19, "duration_seconds": 1.908}, "timestamp": "2026-01-12T09:38:49.249980"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2012.758, "latencies_ms": [2012.758], "images_per_second": 0.497, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The two men on horseback are positioned in the foreground, with the ocean and beach extending into the background. The man on the left is closer to the camera, while the man on the right is farther away. The man on the left is also closer to the camera than the man on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.0, "ram_available_mb": 109108.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13414.2, "ram_available_mb": 109092.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.79, 33.79, 33.79, 33.79, 42.3, 42.3, 42.3, 42.3, 42.3, 47.13, 47.13, 47.13, 47.13, 47.13, 38.66, 38.66, 38.66, 38.66, 38.66, 33.69, 33.69], "power_watts_avg": 40.14, "power_watts_peak": 47.13, "energy_joules_est": 80.81, "sample_count": 21, "duration_seconds": 2.013}, "timestamp": "2026-01-12T09:38:51.367174"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 874.466, "latencies_ms": [874.466], "images_per_second": 1.144, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.2, "ram_available_mb": 109096.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13425.7, "ram_available_mb": 109080.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.69, 33.69, 31.91, 31.91, 31.91, 31.91, 31.91, 43.94, 43.94], "power_watts_avg": 34.98, "power_watts_peak": 43.94, "energy_joules_est": 30.62, "sample_count": 9, "duration_seconds": 0.875}, "timestamp": "2026-01-12T09:38:52.331216"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1382.915, "latencies_ms": [1382.915], "images_per_second": 0.723, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a sandy beach with a clear blue sky and ocean in the background. The two men are dressed in white traditional clothing and are riding horses, which are also white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.9, "ram_available_mb": 109088.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13425.6, "ram_available_mb": 109080.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.94, 43.94, 43.94, 50.12, 50.12, 50.12, 50.12, 50.12, 46.47, 46.47, 46.47, 46.47, 46.47, 42.28], "power_watts_avg": 46.93, "power_watts_peak": 50.12, "energy_joules_est": 64.93, "sample_count": 14, "duration_seconds": 1.383}, "timestamp": "2026-01-12T09:38:53.745940"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 982.456, "latencies_ms": [982.456], "images_per_second": 1.018, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A motorcycle with a sidecar is parked in front of a garage, with a small dog standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.7, "ram_available_mb": 109088.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13430.9, "ram_available_mb": 109075.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.28, 42.28, 42.28, 42.28, 41.65, 41.65, 41.65, 41.65, 41.65, 46.29], "power_watts_avg": 42.37, "power_watts_peak": 46.29, "energy_joules_est": 41.63, "sample_count": 10, "duration_seconds": 0.983}, "timestamp": "2026-01-12T09:38:54.759144"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2005.162, "latencies_ms": [2005.162], "images_per_second": 0.499, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. dog: 1\n3. tire: 1\n4. handlebar: 1\n5. seat: 1\n6. front wheel: 1\n7. rear wheel: 1\n8. garage door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.0, "ram_available_mb": 109079.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13413.3, "ram_available_mb": 109093.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.29, 46.29, 46.29, 46.29, 46.29, 46.29, 46.29, 46.29, 46.29, 46.69, 46.69, 46.69, 46.69, 39.62, 39.62, 39.62, 39.62, 39.62, 33.78, 33.78], "power_watts_avg": 43.45, "power_watts_peak": 46.69, "energy_joules_est": 87.15, "sample_count": 20, "duration_seconds": 2.006}, "timestamp": "2026-01-12T09:38:56.778280"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1708.911, "latencies_ms": [1708.911], "images_per_second": 0.585, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The motorcycle is positioned to the left of the garage door, with the dog standing in front of it. The motorcycle is in the foreground, while the garage door is in the background. The dog is closer to the camera than the motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13405.4, "ram_available_mb": 109100.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13410.6, "ram_available_mb": 109095.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.78, 33.78, 33.78, 40.81, 40.81, 40.81, 40.81, 40.81, 46.81, 46.81, 46.81, 46.81, 46.81, 40.49, 40.49, 40.49, 40.49], "power_watts_avg": 41.26, "power_watts_peak": 46.81, "energy_joules_est": 70.53, "sample_count": 17, "duration_seconds": 1.709}, "timestamp": "2026-01-12T09:38:58.494819"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 820.948, "latencies_ms": [820.948], "images_per_second": 1.218, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A motorcycle is parked outside a garage with a dog standing next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.6, "ram_available_mb": 109095.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13405.0, "ram_available_mb": 109101.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.49, 32.21, 32.21, 32.21, 32.21, 32.21, 47.1, 47.1, 47.1], "power_watts_avg": 38.09, "power_watts_peak": 47.1, "energy_joules_est": 31.28, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-12T09:38:59.405614"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1066.225, "latencies_ms": [1066.225], "images_per_second": 0.938, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The motorcycle is red and silver, and the garage is beige. The sky is blue and the grass is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.0, "ram_available_mb": 109105.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.1, "ram_available_mb": 109094.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.1, 47.1, 48.74, 48.74, 48.74, 48.74, 48.74, 45.53, 45.53, 45.53, 45.53], "power_watts_avg": 47.28, "power_watts_peak": 48.74, "energy_joules_est": 50.41, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-12T09:39:00.518637"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 925.838, "latencies_ms": [925.838], "images_per_second": 1.08, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is flying a kite on the beach, with a lake and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.2, "ram_available_mb": 109102.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13414.4, "ram_available_mb": 109091.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.53, 44.29, 44.29, 44.29, 44.29, 44.29, 46.1, 46.1, 46.1, 46.1], "power_watts_avg": 45.14, "power_watts_peak": 46.1, "energy_joules_est": 41.82, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-12T09:39:01.531467"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1901.925, "latencies_ms": [1901.925], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. kite: 1\n3. sand: 1\n4. water: 1\n5. trees: 1\n6. buildings: 1\n7. clouds: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13406.5, "ram_available_mb": 109099.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13414.6, "ram_available_mb": 109091.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.1, 45.26, 45.26, 45.26, 45.26, 45.26, 45.64, 45.64, 45.64, 45.64, 45.64, 47.91, 47.91, 47.91, 47.91, 47.91, 33.75, 33.75, 33.75], "power_watts_avg": 44.28, "power_watts_peak": 47.91, "energy_joules_est": 84.25, "sample_count": 19, "duration_seconds": 1.902}, "timestamp": "2026-01-12T09:39:03.446580"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1576.397, "latencies_ms": [1576.397], "images_per_second": 0.634, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is in the foreground, flying the kite in the middle of the beach. The kite is in the background, flying high in the sky. The beach is in the background, with people and trees around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.7, "ram_available_mb": 109095.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13426.7, "ram_available_mb": 109079.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.75, 31.28, 31.28, 31.28, 31.28, 31.28, 45.77, 45.77, 45.77, 45.77, 45.77, 48.49, 48.49, 48.49, 48.49, 48.49], "power_watts_avg": 41.34, "power_watts_peak": 48.49, "energy_joules_est": 65.2, "sample_count": 16, "duration_seconds": 1.577}, "timestamp": "2026-01-12T09:39:05.114293"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 839.273, "latencies_ms": [839.273], "images_per_second": 1.192, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is flying a kite on a beach with a lake in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13426.7, "ram_available_mb": 109079.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13505.8, "ram_available_mb": 109000.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.07, 34.07, 34.07, 34.07, 34.07, 46.34, 46.34, 46.34, 46.34], "power_watts_avg": 39.53, "power_watts_peak": 46.34, "energy_joules_est": 33.19, "sample_count": 9, "duration_seconds": 0.84}, "timestamp": "2026-01-12T09:39:06.022877"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1049.884, "latencies_ms": [1049.884], "images_per_second": 0.952, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The sky is blue and the kite is blue and black. The beach is sandy and the people are wearing casual clothes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13505.8, "ram_available_mb": 109000.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13509.1, "ram_available_mb": 108997.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.34, 44.3, 44.3, 44.3, 44.3, 44.3, 46.1, 46.1, 46.1, 46.1, 46.1], "power_watts_avg": 45.31, "power_watts_peak": 46.34, "energy_joules_est": 47.57, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-12T09:39:07.134065"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1545.839, "latencies_ms": [1545.839], "images_per_second": 0.647, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a stainless steel refrigerator, and a black countertop, with various items such as a green bottle, a blue bottle, and a red bow placed on the countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13509.1, "ram_available_mb": 108997.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13499.0, "ram_available_mb": 109007.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.21, 48.21, 48.21, 48.21, 48.21, 46.24, 46.24, 46.24, 46.24, 46.24, 46.21, 46.21, 46.21, 46.21, 46.21, 34.04], "power_watts_avg": 46.08, "power_watts_peak": 48.21, "energy_joules_est": 71.25, "sample_count": 16, "duration_seconds": 1.546}, "timestamp": "2026-01-12T09:39:08.754886"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1306.909, "latencies_ms": [1306.909], "images_per_second": 0.765, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " sink: 1, bottle: 2, bowl: 1, cup: 1, dish: 1, bottle: 1, bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13499.0, "ram_available_mb": 109007.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13482.8, "ram_available_mb": 109023.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.04, 34.04, 34.04, 34.04, 41.14, 41.14, 41.14, 41.14, 41.14, 46.06, 46.06, 46.06, 46.06], "power_watts_avg": 40.47, "power_watts_peak": 46.06, "energy_joules_est": 52.9, "sample_count": 13, "duration_seconds": 1.307}, "timestamp": "2026-01-12T09:39:10.068592"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1839.892, "latencies_ms": [1839.892], "images_per_second": 0.544, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The green dish soap bottle is located near the sink, while the blue dish soap bottle is placed further back on the counter. The red bow is positioned in the middle of the counter, and the black and white tiled backsplash is located behind the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13475.0, "ram_available_mb": 109031.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13386.7, "ram_available_mb": 109119.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.06, 39.78, 39.78, 39.78, 39.78, 47.23, 47.23, 47.23, 47.23, 47.23, 46.94, 46.94, 46.94, 46.94, 46.94, 33.61, 33.61, 33.61, 33.61], "power_watts_avg": 42.66, "power_watts_peak": 47.23, "energy_joules_est": 78.5, "sample_count": 19, "duration_seconds": 1.84}, "timestamp": "2026-01-12T09:39:11.985308"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 870.191, "latencies_ms": [870.191], "images_per_second": 1.149, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A kitchen with wooden cabinets, a black countertop, and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.7, "ram_available_mb": 109119.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13426.4, "ram_available_mb": 109079.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [33.61, 30.8, 30.8, 30.8, 30.8, 30.8, 44.84, 44.84, 44.84], "power_watts_avg": 35.8, "power_watts_peak": 44.84, "energy_joules_est": 31.18, "sample_count": 9, "duration_seconds": 0.871}, "timestamp": "2026-01-12T09:39:12.947901"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 892.671, "latencies_ms": [892.671], "images_per_second": 1.12, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.5, "ram_available_mb": 109087.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13429.2, "ram_available_mb": 109077.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 3.0}, "power_stats": {"power_watts_samples": [44.84, 44.84, 47.31, 47.31, 47.31, 47.31, 47.31, 46.41, 46.41], "power_watts_avg": 46.56, "power_watts_peak": 47.31, "energy_joules_est": 41.59, "sample_count": 9, "duration_seconds": 0.893}, "timestamp": "2026-01-12T09:39:13.859568"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 794.199, "latencies_ms": [794.199], "images_per_second": 1.259, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.2, "ram_available_mb": 109081.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13433.9, "ram_available_mb": 109072.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.41, 46.41, 46.41, 51.37, 51.37, 51.37, 51.37, 51.37], "power_watts_avg": 49.51, "power_watts_peak": 51.37, "energy_joules_est": 39.33, "sample_count": 8, "duration_seconds": 0.795}, "timestamp": "2026-01-12T09:39:14.672457"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 532.434, "latencies_ms": [532.434], "images_per_second": 1.878, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " kite: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13433.9, "ram_available_mb": 109072.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13426.0, "ram_available_mb": 109080.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.01, 47.01, 47.01, 47.01, 47.01, 55.42], "power_watts_avg": 48.42, "power_watts_peak": 55.42, "energy_joules_est": 25.8, "sample_count": 6, "duration_seconds": 0.533}, "timestamp": "2026-01-12T09:39:15.282468"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1730.383, "latencies_ms": [1730.383], "images_per_second": 0.578, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The kite is in the foreground, flying in the sky, and the background is the clear blue sky. The kite is positioned to the left of the frame, and the strings are attached to the kite, which is the main object in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.1, "ram_available_mb": 109088.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13427.8, "ram_available_mb": 109078.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [55.42, 55.42, 55.42, 52.79, 52.79, 52.79, 52.79, 52.79, 47.38, 47.38, 47.38, 47.38, 47.38, 40.79, 40.79, 40.79, 40.79, 40.79], "power_watts_avg": 48.39, "power_watts_peak": 55.42, "energy_joules_est": 83.76, "sample_count": 18, "duration_seconds": 1.731}, "timestamp": "2026-01-12T09:39:17.097618"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 787.44, "latencies_ms": [787.44], "images_per_second": 1.27, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.8, "ram_available_mb": 109078.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13483.6, "ram_available_mb": 109022.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [33.04, 33.04, 33.04, 33.04, 33.04, 45.86, 45.86, 45.86], "power_watts_avg": 37.85, "power_watts_peak": 45.86, "energy_joules_est": 29.81, "sample_count": 8, "duration_seconds": 0.788}, "timestamp": "2026-01-12T09:39:17.904987"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 878.069, "latencies_ms": [878.069], "images_per_second": 1.139, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The kite is white with red and black patterns, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13483.6, "ram_available_mb": 109022.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13487.6, "ram_available_mb": 109018.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 33.0}, "power_stats": {"power_watts_samples": [45.86, 45.86, 47.23, 47.23, 47.23, 47.23, 47.23, 46.62, 46.62], "power_watts_avg": 46.79, "power_watts_peak": 47.23, "energy_joules_est": 41.12, "sample_count": 9, "duration_seconds": 0.879}, "timestamp": "2026-01-12T09:39:18.814819"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1692.104, "latencies_ms": [1692.104], "images_per_second": 0.591, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with two queen-sized beds, each adorned with white linens and a dark-colored bedspread, positioned side by side, with a window in the background allowing natural light to filter into the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13487.6, "ram_available_mb": 109018.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13477.8, "ram_available_mb": 109028.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.62, 46.62, 46.62, 50.98, 50.98, 50.98, 50.98, 50.98, 46.42, 46.42, 46.42, 46.42, 46.42, 41.94, 41.94, 41.94, 41.94], "power_watts_avg": 46.74, "power_watts_peak": 50.98, "energy_joules_est": 79.11, "sample_count": 17, "duration_seconds": 1.692}, "timestamp": "2026-01-12T09:39:20.532508"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1880.375, "latencies_ms": [1880.375], "images_per_second": 0.532, "prompt_tokens": 1113, "response_tokens_est": 55, "n_tiles": 1, "output_text": " 1. beds: 2\n2. pillows: 12\n3. lamps: 2\n4. paintings: 2\n5. window: 1\n6. door: 1\n7. floor: wooden\n8. ceiling: white", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13477.7, "ram_available_mb": 109028.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13485.6, "ram_available_mb": 109020.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.94, 32.92, 32.92, 32.92, 32.92, 32.92, 46.75, 46.75, 46.75, 46.75, 46.75, 47.91, 47.91, 47.91, 47.91, 47.91, 33.83, 33.83, 33.83], "power_watts_avg": 41.12, "power_watts_peak": 47.91, "energy_joules_est": 77.35, "sample_count": 19, "duration_seconds": 1.881}, "timestamp": "2026-01-12T09:39:22.452111"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2194.469, "latencies_ms": [2194.469], "images_per_second": 0.456, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The beds are positioned on the left side of the room, with the window and door located on the right side. The lamp on the left bedside table is positioned closer to the camera than the lamp on the right bedside table. The artwork is positioned above the beds, with the window and door being further away from the beds.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13477.7, "ram_available_mb": 109028.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13472.9, "ram_available_mb": 109033.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.83, 30.97, 30.97, 30.97, 30.97, 30.97, 45.28, 45.28, 45.28, 45.28, 45.28, 48.46, 48.46, 48.46, 48.46, 48.46, 33.81, 33.81, 33.81, 33.81, 33.81, 33.79], "power_watts_avg": 39.1, "power_watts_peak": 48.46, "energy_joules_est": 85.85, "sample_count": 22, "duration_seconds": 2.196}, "timestamp": "2026-01-12T09:39:24.723946"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2094.085, "latencies_ms": [2094.085], "images_per_second": 0.478, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a serene hotel room bathed in soft light, where two queen-sized beds rest against a wall adorned with a vibrant abstract painting. The room exudes a sense of tranquility, with each bed neatly made and a lamp perched on the nightstand, ready to bathe the room in a warm glow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13465.0, "ram_available_mb": 109041.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13459.1, "ram_available_mb": 109047.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.79, 33.79, 33.79, 33.79, 39.73, 39.73, 39.73, 39.73, 45.8, 45.8, 45.8, 45.8, 45.8, 39.84, 39.84, 39.84, 39.84, 39.84, 33.78, 33.78, 33.78], "power_watts_avg": 39.22, "power_watts_peak": 45.8, "energy_joules_est": 82.17, "sample_count": 21, "duration_seconds": 2.095}, "timestamp": "2026-01-12T09:39:26.893047"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1570.982, "latencies_ms": [1570.982], "images_per_second": 0.637, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a mix of natural and artificial light illuminating the space. The walls are painted in a soothing shade of green, and the wooden floor adds a touch of rustic charm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13455.2, "ram_available_mb": 109051.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13464.5, "ram_available_mb": 109041.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.78, 33.78, 32.41, 32.41, 32.41, 32.41, 32.41, 45.47, 45.47, 45.47, 45.47, 45.47, 46.97, 46.97, 46.97, 46.97], "power_watts_avg": 40.3, "power_watts_peak": 46.97, "energy_joules_est": 63.34, "sample_count": 16, "duration_seconds": 1.571}, "timestamp": "2026-01-12T09:39:28.558130"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1274.414, "latencies_ms": [1274.414], "images_per_second": 0.785, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road with a crowd of people watching from behind a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13464.5, "ram_available_mb": 109041.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [46.97, 32.78, 32.78, 32.78, 32.78, 32.78, 46.32, 46.32, 46.32, 46.32, 46.32, 47.27, 47.27], "power_watts_avg": 41.31, "power_watts_peak": 47.27, "energy_joules_est": 52.66, "sample_count": 13, "duration_seconds": 1.275}, "timestamp": "2026-01-12T09:39:29.869747"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1352.329, "latencies_ms": [1352.329], "images_per_second": 0.739, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. rider: 1\n3. helmet: 1\n4. fence: 2\n5. people: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13427.6, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.27, 47.27, 47.27, 36.27, 36.27, 36.27, 36.27, 36.27, 46.31, 46.31, 46.31, 46.31, 46.31, 44.72], "power_watts_avg": 42.82, "power_watts_peak": 47.27, "energy_joules_est": 57.92, "sample_count": 14, "duration_seconds": 1.353}, "timestamp": "2026-01-12T09:39:31.283373"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1559.657, "latencies_ms": [1559.657], "images_per_second": 0.641, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider leaning into a turn. The spectators are located in the background, behind a fence, and appear to be watching the motorcycle from a distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.7, "ram_available_mb": 109086.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13428.4, "ram_available_mb": 109077.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.72, 44.72, 44.72, 39.67, 39.67, 39.67, 39.67, 39.67, 46.04, 46.04, 46.04, 46.04, 46.04, 40.16, 40.16, 40.16], "power_watts_avg": 42.7, "power_watts_peak": 46.04, "energy_joules_est": 66.62, "sample_count": 16, "duration_seconds": 1.56}, "timestamp": "2026-01-12T09:39:32.901186"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1272.919, "latencies_ms": [1272.919], "images_per_second": 0.786, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road. There are people standing behind a fence watching him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.5, "ram_available_mb": 109085.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13441.3, "ram_available_mb": 109065.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.16, 40.16, 34.68, 34.68, 34.68, 34.68, 34.68, 46.3, 46.3, 46.3, 46.3, 46.3, 46.12], "power_watts_avg": 40.87, "power_watts_peak": 46.3, "energy_joules_est": 52.04, "sample_count": 13, "duration_seconds": 1.273}, "timestamp": "2026-01-12T09:39:34.214761"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2343.661, "latencies_ms": [2343.661], "images_per_second": 0.427, "prompt_tokens": 1109, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a motorcyclist wearing a white helmet and a white and green racing suit, riding a white motorcycle with green stripes. The motorcycle is moving on a road with a green grassy area on the left side and a crowd of people standing behind a fence on the right side. The lighting appears to be natural daylight, and the weather seems to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.3, "ram_available_mb": 109069.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.12, 46.12, 46.12, 46.12, 42.8, 42.8, 42.8, 42.8, 42.8, 46.47, 46.47, 46.47, 46.47, 46.47, 37.94, 37.94, 37.94, 37.94, 37.94, 33.91, 33.91, 33.91, 33.91, 33.91], "power_watts_avg": 41.25, "power_watts_peak": 46.47, "energy_joules_est": 96.7, "sample_count": 24, "duration_seconds": 2.344}, "timestamp": "2026-01-12T09:39:36.634516"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 924.835, "latencies_ms": [924.835], "images_per_second": 1.081, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A table set with a vase of white flowers and wine glasses is illuminated by a soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.3, "ram_available_mb": 109084.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13439.3, "ram_available_mb": 109067.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.87, 33.87, 33.87, 33.87, 42.95, 42.95, 42.95, 42.95, 42.95, 44.92], "power_watts_avg": 39.51, "power_watts_peak": 44.92, "energy_joules_est": 36.57, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-12T09:39:37.699528"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 823.281, "latencies_ms": [823.281], "images_per_second": 1.215, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " tablecloth: 1\nglass: 4\nflowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.5, "ram_available_mb": 109074.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13431.9, "ram_available_mb": 109074.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.92, 44.92, 44.92, 44.92, 45.52, 45.52, 45.52, 45.52, 45.52], "power_watts_avg": 45.25, "power_watts_peak": 45.52, "energy_joules_est": 37.28, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-12T09:39:38.611869"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1549.984, "latencies_ms": [1549.984], "images_per_second": 0.645, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The vase with flowers is placed in the center of the table, with the glasses arranged around it. The table is set against a dark background, with the lights reflecting off the glassware and the tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.8, "ram_available_mb": 109074.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13420.0, "ram_available_mb": 109086.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.67, 44.67, 44.67, 44.67, 44.67, 48.43, 48.43, 48.43, 48.43, 48.43, 46.4, 46.4, 46.4, 46.4, 46.4, 33.84], "power_watts_avg": 45.71, "power_watts_peak": 48.43, "energy_joules_est": 70.87, "sample_count": 16, "duration_seconds": 1.551}, "timestamp": "2026-01-12T09:39:40.228674"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 913.304, "latencies_ms": [913.304], "images_per_second": 1.095, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A table set for a dinner party with a centerpiece of white flowers and wine glasses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.0, "ram_available_mb": 109086.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13411.5, "ram_available_mb": 109094.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.84, 33.84, 33.84, 33.84, 41.34, 41.34, 41.34, 41.34, 41.34, 45.42], "power_watts_avg": 38.74, "power_watts_peak": 45.42, "energy_joules_est": 35.4, "sample_count": 10, "duration_seconds": 0.914}, "timestamp": "2026-01-12T09:39:41.238188"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1240.366, "latencies_ms": [1240.366], "images_per_second": 0.806, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The table is covered with a white tablecloth, and the glasses are clear. The lighting is dim, and the table is set for a formal dinner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.7, "ram_available_mb": 109102.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13435.6, "ram_available_mb": 109070.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.42, 45.42, 45.42, 45.42, 45.1, 45.1, 45.1, 45.1, 45.1, 45.27, 45.27, 45.27, 45.27], "power_watts_avg": 45.25, "power_watts_peak": 45.42, "energy_joules_est": 56.14, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-12T09:39:42.550107"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1092.053, "latencies_ms": [1092.053], "images_per_second": 0.916, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.6, "ram_available_mb": 109070.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13425.4, "ram_available_mb": 109080.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [45.27, 37.51, 37.51, 37.51, 37.51, 37.51, 46.49, 46.49, 46.49, 46.49, 46.49], "power_watts_avg": 42.3, "power_watts_peak": 46.49, "energy_joules_est": 46.23, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-12T09:39:43.664767"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1519.12, "latencies_ms": [1519.12], "images_per_second": 0.658, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. clock: 2\n2. pole: 1\n3. sky: 1\n4. clouds: 1\n5. bird: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13417.5, "ram_available_mb": 109088.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13460.6, "ram_available_mb": 109045.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [50.73, 50.73, 50.73, 50.73, 50.73, 46.92, 46.92, 46.92, 46.92, 46.92, 50.43, 50.43, 50.43, 50.43, 50.43, 40.84], "power_watts_avg": 48.83, "power_watts_peak": 50.73, "energy_joules_est": 74.19, "sample_count": 16, "duration_seconds": 1.519}, "timestamp": "2026-01-12T09:39:45.283324"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1634.42, "latencies_ms": [1634.42], "images_per_second": 0.612, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The clock is positioned in the center of the image, with the pole extending upwards and the sky occupying the background. The clock is relatively close to the camera, while the sky is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13460.6, "ram_available_mb": 109045.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13439.8, "ram_available_mb": 109066.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [40.84, 40.84, 40.84, 36.96, 36.96, 36.96, 36.96, 36.96, 49.08, 49.08, 49.08, 49.08, 49.08, 45.74, 45.74, 45.74, 45.74], "power_watts_avg": 43.27, "power_watts_peak": 49.08, "energy_joules_est": 70.74, "sample_count": 17, "duration_seconds": 1.635}, "timestamp": "2026-01-12T09:39:46.996677"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1080.865, "latencies_ms": [1080.865], "images_per_second": 0.925, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.9, "ram_available_mb": 109074.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13483.1, "ram_available_mb": 109023.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.74, 30.62, 30.62, 30.62, 30.62, 30.62, 49.47, 49.47, 49.47, 49.47, 49.47], "power_watts_avg": 40.56, "power_watts_peak": 49.47, "energy_joules_est": 43.85, "sample_count": 11, "duration_seconds": 1.081}, "timestamp": "2026-01-12T09:39:48.115765"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 915.824, "latencies_ms": [915.824], "images_per_second": 1.092, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The clock is black and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13475.3, "ram_available_mb": 109031.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13475.2, "ram_available_mb": 109031.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.63, 52.63, 52.63, 52.63, 52.63, 45.96, 45.96, 45.96, 45.96, 45.96], "power_watts_avg": 49.3, "power_watts_peak": 52.63, "energy_joules_est": 45.16, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-12T09:39:49.129471"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1107.308, "latencies_ms": [1107.308], "images_per_second": 0.903, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young man wearing a black t-shirt and a blue cap is performing a trick on his skateboard in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13471.3, "ram_available_mb": 109035.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13463.9, "ram_available_mb": 109042.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.21, 49.21, 49.21, 49.21, 49.21, 49.95, 49.95, 49.95, 49.95, 49.95, 45.4, 45.4], "power_watts_avg": 48.88, "power_watts_peak": 49.95, "energy_joules_est": 54.16, "sample_count": 12, "duration_seconds": 1.108}, "timestamp": "2026-01-12T09:39:50.344179"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1945.406, "latencies_ms": [1945.406], "images_per_second": 0.514, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. cap: 1\n4. pants: 1\n5. shoes: 1\n6. trees: 1\n7. ground: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13463.9, "ram_available_mb": 109042.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13453.4, "ram_available_mb": 109052.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.4, 45.4, 45.4, 36.43, 36.43, 36.43, 36.43, 36.43, 45.2, 45.2, 45.2, 45.2, 45.2, 42.32, 42.32, 42.32, 42.32, 42.32, 33.74, 33.74], "power_watts_avg": 41.17, "power_watts_peak": 45.4, "energy_joules_est": 80.11, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T09:39:52.357412"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1173.091, "latencies_ms": [1173.091], "images_per_second": 0.852, "prompt_tokens": 1118, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on the skateboard. The background features a park with trees and a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13453.4, "ram_available_mb": 109052.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13443.1, "ram_available_mb": 109063.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.74, 33.74, 33.74, 36.67, 36.67, 36.67, 36.67, 36.67, 45.83, 45.83, 45.83, 45.83], "power_watts_avg": 38.99, "power_watts_peak": 45.83, "energy_joules_est": 45.77, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-12T09:39:53.570436"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1174.76, "latencies_ms": [1174.76], "images_per_second": 0.851, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young man wearing a black t-shirt and a blue baseball cap is skateboarding on a red and gray concrete surface in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13443.1, "ram_available_mb": 109063.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13503.0, "ram_available_mb": 109003.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [45.83, 42.68, 42.68, 42.68, 42.68, 42.68, 46.28, 46.28, 46.28, 46.28, 46.28, 47.39], "power_watts_avg": 44.84, "power_watts_peak": 47.39, "energy_joules_est": 52.69, "sample_count": 12, "duration_seconds": 1.175}, "timestamp": "2026-01-12T09:39:54.782044"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1166.365, "latencies_ms": [1166.365], "images_per_second": 0.857, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a red and gray concrete surface, with a backdrop of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13495.1, "ram_available_mb": 109011.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13493.8, "ram_available_mb": 109012.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.39, 47.39, 47.39, 41.0, 41.0, 41.0, 41.0, 41.0, 46.32, 46.32, 46.32, 46.32], "power_watts_avg": 44.37, "power_watts_peak": 47.39, "energy_joules_est": 51.77, "sample_count": 12, "duration_seconds": 1.167}, "timestamp": "2026-01-12T09:39:55.995423"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 882.367, "latencies_ms": [882.367], "images_per_second": 1.133, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A white plate filled with orange carrots and green beans is placed on a kitchen counter.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13485.9, "ram_available_mb": 109020.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13497.4, "ram_available_mb": 109008.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 21.0}, "power_stats": {"power_watts_samples": [46.32, 36.89, 36.89, 36.89, 36.89, 36.89, 46.21, 46.21, 46.21], "power_watts_avg": 41.05, "power_watts_peak": 46.32, "energy_joules_est": 36.24, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T09:39:56.908717"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1679.93, "latencies_ms": [1679.93], "images_per_second": 0.595, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13497.1, "ram_available_mb": 109009.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13486.4, "ram_available_mb": 109019.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.21, 46.21, 49.85, 49.85, 49.85, 49.85, 49.85, 46.43, 46.43, 46.43, 46.43, 46.43, 45.0, 45.0, 45.0, 45.0, 45.0], "power_watts_avg": 46.99, "power_watts_peak": 49.85, "energy_joules_est": 78.97, "sample_count": 17, "duration_seconds": 1.68}, "timestamp": "2026-01-12T09:39:58.625465"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1654.11, "latencies_ms": [1654.11], "images_per_second": 0.605, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The plate of carrots is located in the foreground, with the blue scissors and the white container in the background. The carrots are arranged in a circular pattern on the plate, with the blue scissors placed to the right of the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13486.4, "ram_available_mb": 109019.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13494.1, "ram_available_mb": 109012.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.83, 33.83, 33.83, 33.83, 33.83, 46.38, 46.38, 46.38, 46.38, 46.38, 46.51, 46.51, 46.51, 46.51, 46.51, 33.72, 33.72], "power_watts_avg": 41.24, "power_watts_peak": 46.51, "energy_joules_est": 68.22, "sample_count": 17, "duration_seconds": 1.654}, "timestamp": "2026-01-12T09:40:00.339540"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 961.486, "latencies_ms": [961.486], "images_per_second": 1.04, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " In a kitchen, a white plate is filled with fresh carrots and beets, ready to be cooked.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13486.2, "ram_available_mb": 109020.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13488.5, "ram_available_mb": 109017.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.72, 33.72, 33.72, 37.83, 37.83, 37.83, 37.83, 37.83, 46.08, 46.08], "power_watts_avg": 38.25, "power_watts_peak": 46.08, "energy_joules_est": 36.79, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-12T09:40:01.351455"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1353.317, "latencies_ms": [1353.317], "images_per_second": 0.739, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a white plate filled with orange carrots and green beans, placed on a kitchen counter. The lighting is bright and natural, coming from the window in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13484.6, "ram_available_mb": 109021.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13492.5, "ram_available_mb": 109013.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.08, 46.08, 46.08, 46.03, 46.03, 46.03, 46.03, 46.03, 46.15, 46.15, 46.15, 46.15, 46.15, 42.33], "power_watts_avg": 45.82, "power_watts_peak": 46.15, "energy_joules_est": 62.02, "sample_count": 14, "duration_seconds": 1.354}, "timestamp": "2026-01-12T09:40:02.763233"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.115, "latencies_ms": [983.115], "images_per_second": 1.017, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit and tie is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13484.6, "ram_available_mb": 109021.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13481.7, "ram_available_mb": 109024.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.33, 42.33, 42.33, 42.33, 41.48, 41.48, 41.48, 41.48, 41.48, 46.14], "power_watts_avg": 42.28, "power_watts_peak": 46.14, "energy_joules_est": 41.58, "sample_count": 10, "duration_seconds": 0.983}, "timestamp": "2026-01-12T09:40:03.776776"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1904.617, "latencies_ms": [1904.617], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. head: 2\n4. hair: 1\n5. neck: 1\n6. suit: 1\n7. tie: 1\n8. shirt: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13481.7, "ram_available_mb": 109024.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13468.0, "ram_available_mb": 109038.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.14, 46.14, 46.14, 46.14, 47.04, 47.04, 47.04, 47.04, 47.04, 46.48, 46.48, 46.48, 46.48, 46.48, 38.83, 38.83, 38.83, 38.83, 33.91], "power_watts_avg": 44.28, "power_watts_peak": 47.04, "energy_joules_est": 84.36, "sample_count": 19, "duration_seconds": 1.905}, "timestamp": "2026-01-12T09:40:05.690846"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1408.461, "latencies_ms": [1408.461], "images_per_second": 0.71, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, while the audience is located on the right side. The man is in the foreground, while the audience is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13464.1, "ram_available_mb": 109042.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13466.2, "ram_available_mb": 109040.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.91, 33.91, 33.91, 33.91, 42.6, 42.6, 42.6, 42.6, 42.6, 45.94, 45.94, 45.94, 45.94, 45.94], "power_watts_avg": 41.31, "power_watts_peak": 45.94, "energy_joules_est": 58.22, "sample_count": 14, "duration_seconds": 1.409}, "timestamp": "2026-01-12T09:40:07.156217"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 926.009, "latencies_ms": [926.009], "images_per_second": 1.08, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man in a suit is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13458.4, "ram_available_mb": 109047.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13464.0, "ram_available_mb": 109042.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.25, 38.25, 38.25, 38.25, 38.25, 46.94, 46.94, 46.94, 46.94, 46.94], "power_watts_avg": 42.59, "power_watts_peak": 46.94, "energy_joules_est": 39.45, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-12T09:40:08.167147"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1804.266, "latencies_ms": [1804.266], "images_per_second": 0.554, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a man in a suit and tie standing on a stage, with a large screen behind him displaying a presentation. The lighting is bright and focused on the speaker, while the audience is seated in the foreground, with their heads visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13460.0, "ram_available_mb": 109046.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13448.4, "ram_available_mb": 109057.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.03, 47.03, 47.03, 47.03, 47.03, 45.5, 45.5, 45.5, 45.5, 45.5, 45.72, 45.72, 45.72, 45.72, 45.72, 35.04, 35.04, 35.04], "power_watts_avg": 44.24, "power_watts_peak": 47.03, "energy_joules_est": 79.86, "sample_count": 18, "duration_seconds": 1.805}, "timestamp": "2026-01-12T09:40:09.985400"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1199.582, "latencies_ms": [1199.582], "images_per_second": 0.834, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, with a motorcycle parked nearby, and a billboard with Chinese text in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13448.4, "ram_available_mb": 109057.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13368.5, "ram_available_mb": 109137.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.04, 32.09, 32.09, 32.09, 32.09, 32.09, 46.64, 46.64, 46.64, 46.64, 46.64, 48.69], "power_watts_avg": 39.78, "power_watts_peak": 48.69, "energy_joules_est": 47.75, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-12T09:40:11.200460"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2121.777, "latencies_ms": [2121.777], "images_per_second": 0.471, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Scooters: 3\n2. Motorcycles: 2\n3. Banners: 2\n4. Signboards: 2\n5. People: 3\n6. Banners: 1\n7. Banners: 1\n8. Banners: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.5, "ram_available_mb": 109137.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13414.6, "ram_available_mb": 109091.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.69, 48.69, 48.69, 48.69, 45.38, 45.38, 45.38, 45.38, 45.38, 46.88, 46.88, 46.88, 46.88, 46.88, 35.59, 35.59, 35.59, 35.59, 35.59, 33.78, 33.78, 33.78], "power_watts_avg": 42.52, "power_watts_peak": 48.69, "energy_joules_est": 90.23, "sample_count": 22, "duration_seconds": 2.122}, "timestamp": "2026-01-12T09:40:13.421307"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1856.873, "latencies_ms": [1856.873], "images_per_second": 0.539, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The three men are standing on the sidewalk, with the motorcycles parked on the left side of the image. The motorcycles are positioned in the foreground, while the men are in the middle ground. The men are standing near the motorcycles, and the motorcycles are near the wall.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13412.6, "ram_available_mb": 109093.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13413.3, "ram_available_mb": 109093.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.78, 33.78, 30.47, 30.47, 30.47, 30.47, 30.47, 44.35, 44.35, 44.35, 44.35, 44.35, 47.76, 47.76, 47.76, 47.76, 47.76, 33.81, 33.81], "power_watts_avg": 39.37, "power_watts_peak": 47.76, "energy_joules_est": 73.13, "sample_count": 19, "duration_seconds": 1.857}, "timestamp": "2026-01-12T09:40:15.390808"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 881.431, "latencies_ms": [881.431], "images_per_second": 1.135, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three men in blue uniforms are standing on a street corner, talking to each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.3, "ram_available_mb": 109093.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13453.6, "ram_available_mb": 109052.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.81, 33.81, 32.45, 32.45, 32.45, 32.45, 32.45, 44.97, 44.97], "power_watts_avg": 35.54, "power_watts_peak": 44.97, "energy_joules_est": 31.35, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T09:40:16.349468"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1140.667, "latencies_ms": [1140.667], "images_per_second": 0.877, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken during the day with natural light, and the colors are vibrant with a mix of blue, red, and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13445.7, "ram_available_mb": 109060.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13396.0, "ram_available_mb": 109110.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.97, 44.97, 44.97, 50.86, 50.86, 50.86, 50.86, 50.86, 46.85, 46.85, 46.85, 46.85], "power_watts_avg": 48.05, "power_watts_peak": 50.86, "energy_joules_est": 54.82, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-12T09:40:17.558821"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1439.396, "latencies_ms": [1439.396], "images_per_second": 0.695, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A black plastic container filled with a green and yellow mixture of vegetables and meat is placed on a white paper plate, which is also holding a pile of shredded chicken.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.0, "ram_available_mb": 109114.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13446.7, "ram_available_mb": 109059.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [46.85, 41.58, 41.58, 41.58, 41.58, 41.58, 48.74, 48.74, 48.74, 48.74, 48.74, 51.83, 51.83, 51.83, 51.83], "power_watts_avg": 47.05, "power_watts_peak": 51.83, "energy_joules_est": 67.73, "sample_count": 15, "duration_seconds": 1.44}, "timestamp": "2026-01-12T09:40:19.077064"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2130.814, "latencies_ms": [2130.814], "images_per_second": 0.469, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bowl: 1\n3. fork: 1\n4. shredded chicken: 1\n5. broccoli: 1\n6. mashed potatoes: 1\n7. sauce: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13446.7, "ram_available_mb": 109059.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13454.4, "ram_available_mb": 109051.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.83, 34.42, 34.42, 34.42, 34.42, 34.42, 47.43, 47.43, 47.43, 47.43, 47.43, 51.4, 51.4, 51.4, 51.4, 36.09, 36.09, 36.09, 36.09, 36.09, 33.93, 33.93], "power_watts_avg": 41.59, "power_watts_peak": 51.83, "energy_joules_est": 88.63, "sample_count": 22, "duration_seconds": 2.131}, "timestamp": "2026-01-12T09:40:21.299221"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2047.561, "latencies_ms": [2047.561], "images_per_second": 0.488, "prompt_tokens": 1450, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The black bowl of food is located in the upper left corner of the image, while the white plate with shredded chicken is situated in the lower right corner. The shredded chicken is placed in front of the bowl, and the plate is placed on a beige carpeted surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13454.4, "ram_available_mb": 109051.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13454.1, "ram_available_mb": 109052.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.93, 33.93, 33.93, 34.64, 34.64, 34.64, 34.64, 34.64, 48.59, 48.59, 48.59, 48.59, 48.59, 48.38, 48.38, 48.38, 48.38, 48.38, 33.84, 33.84, 33.84], "power_watts_avg": 41.02, "power_watts_peak": 48.59, "energy_joules_est": 84.01, "sample_count": 21, "duration_seconds": 2.048}, "timestamp": "2026-01-12T09:40:23.469632"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1045.608, "latencies_ms": [1045.608], "images_per_second": 0.956, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate with a bowl of food and a fork on it is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 1.0, "ram_used_mb": 13454.1, "ram_available_mb": 109052.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13461.7, "ram_available_mb": 109044.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.84, 30.43, 30.43, 30.43, 30.43, 30.43, 49.08, 49.08, 49.08, 49.08, 49.08], "power_watts_avg": 39.22, "power_watts_peak": 49.08, "energy_joules_est": 41.03, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-12T09:40:24.626180"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1910.851, "latencies_ms": [1910.851], "images_per_second": 0.523, "prompt_tokens": 1442, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a black plastic container filled with a green and yellow mixture of vegetables and chicken, placed on a white paper plate. The food is served on a beige carpeted floor, and the lighting is dim, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13461.7, "ram_available_mb": 109044.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13446.5, "ram_available_mb": 109059.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [51.41, 51.41, 51.41, 51.41, 51.41, 45.72, 45.72, 45.72, 45.72, 45.72, 50.72, 50.72, 50.72, 50.72, 50.72, 38.31, 38.31, 38.31, 38.31], "power_watts_avg": 46.97, "power_watts_peak": 51.41, "energy_joules_est": 89.77, "sample_count": 19, "duration_seconds": 1.911}, "timestamp": "2026-01-12T09:40:26.543019"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1031.269, "latencies_ms": [1031.269], "images_per_second": 0.97, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a blue shirt, red tie, and a plaid hat is standing in front of a building.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13446.5, "ram_available_mb": 109059.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13431.1, "ram_available_mb": 109075.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.31, 33.33, 33.33, 33.33, 33.33, 33.33, 47.35, 47.35, 47.35, 47.35, 47.35], "power_watts_avg": 40.15, "power_watts_peak": 47.35, "energy_joules_est": 41.42, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-12T09:40:27.657391"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1919.754, "latencies_ms": [1919.754], "images_per_second": 0.521, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. glasses: 1\n3. tie: 1\n4. shirt: 1\n5. cap: 1\n6. building: 1\n7. window: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.2, "ram_available_mb": 109083.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.35, 47.35, 47.35, 47.35, 47.35, 45.77, 45.77, 45.77, 45.77, 45.77, 45.87, 45.87, 45.87, 45.87, 45.87, 33.84, 33.84, 33.84, 33.84, 33.84], "power_watts_avg": 43.21, "power_watts_peak": 47.35, "energy_joules_est": 82.96, "sample_count": 20, "duration_seconds": 1.92}, "timestamp": "2026-01-12T09:40:29.675689"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1592.622, "latencies_ms": [1592.622], "images_per_second": 0.628, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the background consisting of a building and a pool. The man is wearing a blue shirt and a red tie, and he is also wearing a plaid hat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13422.6, "ram_available_mb": 109083.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.66, 33.66, 33.66, 33.66, 40.92, 40.92, 40.92, 40.92, 40.92, 44.19, 44.19, 44.19, 44.19, 44.19, 37.21, 37.21], "power_watts_avg": 39.66, "power_watts_peak": 44.19, "energy_joules_est": 63.2, "sample_count": 16, "duration_seconds": 1.593}, "timestamp": "2026-01-12T09:40:31.341945"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 886.399, "latencies_ms": [886.399], "images_per_second": 1.128, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a plaid hat and glasses is standing in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.7, "ram_available_mb": 109087.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13427.3, "ram_available_mb": 109079.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.21, 37.21, 37.21, 38.58, 38.58, 38.58, 38.58, 38.58, 46.77], "power_watts_avg": 39.03, "power_watts_peak": 46.77, "energy_joules_est": 34.61, "sample_count": 9, "duration_seconds": 0.887}, "timestamp": "2026-01-12T09:40:32.253687"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 986.007, "latencies_ms": [986.007], "images_per_second": 1.014, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and a red tie, and the picture was taken in bright daylight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.4, "ram_available_mb": 109086.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13430.7, "ram_available_mb": 109075.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.77, 46.77, 46.77, 46.77, 50.89, 50.89, 50.89, 50.89, 50.89, 46.56], "power_watts_avg": 48.81, "power_watts_peak": 50.89, "energy_joules_est": 48.13, "sample_count": 10, "duration_seconds": 0.986}, "timestamp": "2026-01-12T09:40:33.263190"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1448.069, "latencies_ms": [1448.069], "images_per_second": 0.691, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza, with the top left photo being the most detailed and the bottom right photo being the least detailed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.8, "ram_available_mb": 109083.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13458.1, "ram_available_mb": 109048.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.56, 46.56, 46.56, 46.56, 44.76, 44.76, 44.76, 44.76, 44.76, 50.95, 50.95, 50.95, 50.95, 50.95, 44.76], "power_watts_avg": 47.3, "power_watts_peak": 50.95, "energy_joules_est": 68.51, "sample_count": 15, "duration_seconds": 1.448}, "timestamp": "2026-01-12T09:40:34.778223"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 662.375, "latencies_ms": [662.375], "images_per_second": 1.51, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pizza: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13454.2, "ram_available_mb": 109052.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13439.9, "ram_available_mb": 109066.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.76, 44.76, 44.76, 44.76, 39.23, 39.23, 39.23], "power_watts_avg": 42.39, "power_watts_peak": 44.76, "energy_joules_est": 28.09, "sample_count": 7, "duration_seconds": 0.663}, "timestamp": "2026-01-12T09:40:35.487471"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1821.225, "latencies_ms": [1821.225], "images_per_second": 0.549, "prompt_tokens": 1450, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The main objects are arranged in a grid pattern, with the largest image in the top left corner and the smallest in the bottom right. The foreground objects are the slices of pizza, while the background objects are the plates and the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13439.9, "ram_available_mb": 109066.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13422.0, "ram_available_mb": 109084.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.23, 39.23, 47.48, 47.48, 47.48, 47.48, 61.39, 61.39, 61.39, 61.39, 61.39, 53.26, 53.26, 53.26, 53.26, 53.26, 33.99, 33.99, 33.99], "power_watts_avg": 49.66, "power_watts_peak": 61.39, "energy_joules_est": 90.46, "sample_count": 19, "duration_seconds": 1.822}, "timestamp": "2026-01-12T09:40:37.405881"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 934.242, "latencies_ms": [934.242], "images_per_second": 1.07, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.1, "ram_available_mb": 109092.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13449.4, "ram_available_mb": 109056.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [33.99, 33.99, 30.23, 30.23, 30.23, 30.23, 30.23, 48.59, 48.59, 48.59], "power_watts_avg": 36.49, "power_watts_peak": 48.59, "energy_joules_est": 34.12, "sample_count": 10, "duration_seconds": 0.935}, "timestamp": "2026-01-12T09:40:38.467998"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 958.933, "latencies_ms": [958.933], "images_per_second": 1.043, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The pizza has a yellow and orange color, and the lighting is bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13445.4, "ram_available_mb": 109060.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13437.6, "ram_available_mb": 109068.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [48.59, 48.59, 49.52, 49.52, 49.52, 49.52, 49.52, 49.62, 49.62, 49.62], "power_watts_avg": 49.36, "power_watts_peak": 49.62, "energy_joules_est": 47.35, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-12T09:40:39.479171"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 872.233, "latencies_ms": [872.233], "images_per_second": 1.146, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.6, "ram_available_mb": 109068.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13300.7, "ram_available_mb": 109205.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.62, 49.62, 51.49, 51.49, 51.49, 51.49, 51.49, 46.6, 46.6], "power_watts_avg": 49.99, "power_watts_peak": 51.49, "energy_joules_est": 43.63, "sample_count": 9, "duration_seconds": 0.873}, "timestamp": "2026-01-12T09:40:40.392291"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 935.986, "latencies_ms": [935.986], "images_per_second": 1.068, "prompt_tokens": 1113, "response_tokens_est": 19, "n_tiles": 1, "output_text": " goat: 2, girl: 2, fence: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.8, "ram_available_mb": 109213.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13303.0, "ram_available_mb": 109203.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.6, 46.6, 51.15, 51.15, 51.15, 51.15, 51.15, 46.62, 46.62, 46.62], "power_watts_avg": 48.88, "power_watts_peak": 51.15, "energy_joules_est": 45.78, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-12T09:40:41.403351"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2050.248, "latencies_ms": [2050.248], "images_per_second": 0.488, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The two girls are standing on the left side of the image, with the goat in the middle and the other goat on the right side. The goat on the left is being petted by the girl in the pink dress, while the girl in the blue dress is petting the goat on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.0, "ram_available_mb": 109203.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.1, "ram_available_mb": 109156.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.62, 46.62, 45.13, 45.13, 45.13, 45.13, 45.13, 45.92, 45.92, 45.92, 45.92, 45.92, 44.69, 44.69, 44.69, 44.69, 44.69, 33.82, 33.82, 33.82, 33.82], "power_watts_avg": 43.2, "power_watts_peak": 46.62, "energy_joules_est": 88.59, "sample_count": 21, "duration_seconds": 2.051}, "timestamp": "2026-01-12T09:40:43.517102"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 881.443, "latencies_ms": [881.443], "images_per_second": 1.135, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.2, "ram_available_mb": 109164.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [33.82, 31.45, 31.45, 31.45, 31.45, 31.45, 45.09, 45.09, 45.09], "power_watts_avg": 36.26, "power_watts_peak": 45.09, "energy_joules_est": 31.99, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T09:40:44.476292"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1680.845, "latencies_ms": [1680.845], "images_per_second": 0.595, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features two young girls petting a goat and a sheep in a fenced area. The lighting is bright and natural, suggesting it is daytime. The girls are wearing colorful clothing, and the animals have white and black fur.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13350.0, "ram_available_mb": 109156.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13264.2, "ram_available_mb": 109242.1, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.09, 45.09, 45.65, 45.65, 45.65, 45.65, 45.65, 46.54, 46.54, 46.54, 46.54, 46.54, 48.13, 48.13, 48.13, 48.13, 48.13], "power_watts_avg": 46.58, "power_watts_peak": 48.13, "energy_joules_est": 78.31, "sample_count": 17, "duration_seconds": 1.681}, "timestamp": "2026-01-12T09:40:46.189245"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1574.228, "latencies_ms": [1574.228], "images_per_second": 0.635, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a nighttime scene at a street intersection, where a traffic light is illuminated by a green light, and a street sign reading \"AVENUE OF THE GODS\" is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13265.5, "ram_available_mb": 109240.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13259.3, "ram_available_mb": 109247.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.87, 33.87, 33.87, 33.87, 33.87, 44.22, 44.22, 44.22, 44.22, 44.22, 46.23, 46.23, 46.23, 46.23, 35.87, 35.87], "power_watts_avg": 40.45, "power_watts_peak": 46.23, "energy_joules_est": 63.68, "sample_count": 16, "duration_seconds": 1.574}, "timestamp": "2026-01-12T09:40:47.805235"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2015.591, "latencies_ms": [2015.591], "images_per_second": 0.496, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. traffic light: 2\n2. street sign: 1\n3. street light: 1\n4. car: 1\n5. mountain: 1\n6. road: 1\n7. road sign: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13259.3, "ram_available_mb": 109247.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.87, 35.87, 35.87, 39.92, 39.92, 39.92, 39.92, 39.92, 46.6, 46.6, 46.6, 46.6, 46.6, 40.48, 40.48, 40.48, 40.48, 40.48, 33.98, 33.98, 33.98], "power_watts_avg": 40.22, "power_watts_peak": 46.6, "energy_joules_est": 81.07, "sample_count": 21, "duration_seconds": 2.016}, "timestamp": "2026-01-12T09:40:49.921392"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1914.628, "latencies_ms": [1914.628], "images_per_second": 0.522, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The traffic light is on the left side of the image, while the street sign is on the right side. The traffic light is closer to the viewer, while the street sign is farther away. The traffic light is in the foreground, while the street sign is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13313.6, "ram_available_mb": 109192.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.98, 33.98, 30.38, 30.38, 30.38, 30.38, 30.38, 44.32, 44.32, 44.32, 44.32, 44.32, 47.84, 47.84, 47.84, 47.84, 47.84, 33.83, 33.83, 33.83], "power_watts_avg": 39.11, "power_watts_peak": 47.84, "energy_joules_est": 74.92, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T09:40:51.988835"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1883.794, "latencies_ms": [1883.794], "images_per_second": 0.531, "prompt_tokens": 1111, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a night scene at a street intersection, where a traffic light is illuminated by a green light, signaling vehicles to proceed. The sky is dark, suggesting it is either early morning or late evening, and the street is lined with buildings and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13309.6, "ram_available_mb": 109196.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13313.9, "ram_available_mb": 109192.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.83, 30.23, 30.23, 30.23, 30.23, 30.23, 44.08, 44.08, 44.08, 44.08, 44.08, 47.4, 47.4, 47.4, 47.4, 47.4, 33.96, 33.96, 33.96], "power_watts_avg": 39.17, "power_watts_peak": 47.4, "energy_joules_est": 73.83, "sample_count": 19, "duration_seconds": 1.885}, "timestamp": "2026-01-12T09:40:53.958943"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2483.661, "latencies_ms": [2483.661], "images_per_second": 0.403, "prompt_tokens": 1109, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a serene night scene at a street intersection, where the sky is painted in hues of deep blue, and the moon casts a soft glow. The traffic lights, glowing in a vibrant green, stand as silent sentinels guiding the flow of vehicles. The street, lined with buildings and trees, is bathed in the warm light of street lamps, creating a tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.0, "ram_available_mb": 109200.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13308.5, "ram_available_mb": 109197.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.96, 31.01, 31.01, 31.01, 31.01, 31.01, 45.59, 45.59, 45.59, 45.59, 45.59, 48.64, 48.64, 48.64, 48.64, 48.64, 33.98, 33.98, 33.98, 33.98, 33.98, 34.0, 34.0, 34.0, 34.0], "power_watts_avg": 38.64, "power_watts_peak": 48.64, "energy_joules_est": 96.02, "sample_count": 25, "duration_seconds": 2.485}, "timestamp": "2026-01-12T09:40:56.533671"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1017.678, "latencies_ms": [1017.678], "images_per_second": 0.983, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a patterned dress stands in front of a building with a bunch of bananas in front of her.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13304.6, "ram_available_mb": 109201.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13309.9, "ram_available_mb": 109196.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [34.0, 32.32, 32.32, 32.32, 32.32, 32.32, 45.21, 45.21, 45.21, 45.21, 45.21], "power_watts_avg": 38.33, "power_watts_peak": 45.21, "energy_joules_est": 39.06, "sample_count": 11, "duration_seconds": 1.019}, "timestamp": "2026-01-12T09:40:57.700087"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1940.053, "latencies_ms": [1940.053], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. bananas: 2\n3. building: 1\n4. door: 1\n5. wall: 1\n6. window: 1\n7. sign: 1\n8. wall decoration: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.0, "ram_available_mb": 109204.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13298.8, "ram_available_mb": 109207.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.03, 47.03, 47.03, 47.03, 42.95, 42.95, 42.95, 42.95, 42.95, 45.4, 45.4, 45.4, 45.4, 45.4, 36.03, 36.03, 36.03, 36.03, 36.03, 33.96], "power_watts_avg": 42.2, "power_watts_peak": 47.03, "energy_joules_est": 81.89, "sample_count": 20, "duration_seconds": 1.941}, "timestamp": "2026-01-12T09:40:59.717907"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1303.061, "latencies_ms": [1303.061], "images_per_second": 0.767, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bananas are in the foreground, with the woman standing behind them. The woman is positioned to the right of the bananas, and the building is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13299.0, "ram_available_mb": 109207.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13336.3, "ram_available_mb": 109170.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.96, 33.96, 33.96, 33.96, 39.77, 39.77, 39.77, 39.77, 39.77, 44.81, 44.81, 44.81, 44.81], "power_watts_avg": 39.53, "power_watts_peak": 44.81, "energy_joules_est": 51.56, "sample_count": 13, "duration_seconds": 1.304}, "timestamp": "2026-01-12T09:41:01.082236"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 823.15, "latencies_ms": [823.15], "images_per_second": 1.215, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in front of a building with bananas on a table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13328.5, "ram_available_mb": 109177.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13329.6, "ram_available_mb": 109176.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.81, 39.49, 39.49, 39.49, 39.49, 39.49, 47.11, 47.11, 47.11], "power_watts_avg": 42.62, "power_watts_peak": 47.11, "energy_joules_est": 35.1, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-12T09:41:01.992264"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1822.064, "latencies_ms": [1822.064], "images_per_second": 0.549, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a woman standing in front of a building with a warm, earthy color palette. The lighting is natural and bright, casting a soft glow on the scene. The woman is wearing a colorful dress, and the bananas she is holding are ripe and yellow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.7, "ram_available_mb": 109184.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13327.1, "ram_available_mb": 109179.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.11, 47.11, 44.49, 44.49, 44.49, 44.49, 44.49, 45.47, 45.47, 45.47, 45.47, 48.63, 48.63, 48.63, 48.63, 48.63, 34.02, 34.02, 34.02], "power_watts_avg": 44.41, "power_watts_peak": 48.63, "energy_joules_est": 80.94, "sample_count": 19, "duration_seconds": 1.823}, "timestamp": "2026-01-12T09:41:03.911531"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2485.251, "latencies_ms": [2485.251], "images_per_second": 0.402, "prompt_tokens": 1432, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, featuring a red brick building adorned with a green awning and a green fire escape. The building's facade is a canvas of graffiti, with various tags and markings adorning the shuttered windows and doors. A fire hydrant stands guard on the sidewalk, adding a touch of urban charm to the scene.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13327.1, "ram_available_mb": 109179.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13302.7, "ram_available_mb": 109203.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.02, 34.02, 29.22, 29.22, 29.22, 29.22, 29.22, 47.96, 47.96, 47.96, 47.96, 47.96, 53.02, 53.02, 53.02, 53.02, 53.02, 33.82, 33.82, 33.82, 33.82, 33.82, 33.85, 33.85, 33.85], "power_watts_avg": 39.59, "power_watts_peak": 53.02, "energy_joules_est": 98.42, "sample_count": 25, "duration_seconds": 2.486}, "timestamp": "2026-01-12T09:41:06.484580"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1114.339, "latencies_ms": [1114.339], "images_per_second": 0.897, "prompt_tokens": 1446, "response_tokens_est": 20, "n_tiles": 1, "output_text": " fire hydrant: 1\nbike rack: 1\ngraffiti: 10", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13294.7, "ram_available_mb": 109211.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.0, "ram_available_mb": 109153.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [33.85, 31.54, 31.54, 31.54, 31.54, 31.54, 48.83, 48.83, 48.83, 48.83, 48.83, 52.03], "power_watts_avg": 40.64, "power_watts_peak": 52.03, "energy_joules_est": 45.31, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-12T09:41:07.749517"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2053.439, "latencies_ms": [2053.439], "images_per_second": 0.487, "prompt_tokens": 1450, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The fire hydrant is located on the left side of the image, in the foreground. The building is in the background, with the fire hydrant in front of it. The green door is in the middle of the image, between the fire hydrant and the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.0, "ram_available_mb": 109153.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.2, "ram_available_mb": 109175.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.03, 52.03, 52.03, 52.03, 39.59, 39.59, 39.59, 39.59, 39.59, 49.07, 49.07, 49.07, 49.07, 49.07, 44.78, 44.78, 44.78, 44.78, 44.78, 34.05, 34.05], "power_watts_avg": 44.93, "power_watts_peak": 52.03, "energy_joules_est": 92.27, "sample_count": 21, "duration_seconds": 2.054}, "timestamp": "2026-01-12T09:41:09.871782"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2043.234, "latencies_ms": [2043.234], "images_per_second": 0.489, "prompt_tokens": 1444, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a scene of urban decay, with a red brick building that has been tagged with graffiti. The building has a green fire escape and a green door, which is covered in graffiti. In front of the building, there is a fire hydrant and a tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.6, "ram_available_mb": 109186.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13333.0, "ram_available_mb": 109173.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.05, 34.05, 31.91, 31.91, 31.91, 31.91, 31.91, 49.12, 49.12, 49.12, 49.12, 49.12, 51.73, 51.73, 51.73, 51.73, 51.73, 33.97, 33.97, 33.97, 33.97], "power_watts_avg": 41.32, "power_watts_peak": 51.73, "energy_joules_est": 84.45, "sample_count": 21, "duration_seconds": 2.044}, "timestamp": "2026-01-12T09:41:12.038790"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1955.317, "latencies_ms": [1955.317], "images_per_second": 0.511, "prompt_tokens": 1442, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image depicts a red brick building with green shutters and a fire escape. The building is covered in graffiti, and there is a fire hydrant on the sidewalk in front of it. The weather appears to be overcast, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.0, "ram_available_mb": 109173.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13316.9, "ram_available_mb": 109189.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.97, 31.75, 31.75, 31.75, 31.75, 31.75, 49.2, 49.2, 49.2, 49.2, 49.2, 52.27, 52.27, 52.27, 52.27, 52.27, 34.67, 34.67, 34.67, 34.67], "power_watts_avg": 41.94, "power_watts_peak": 52.27, "energy_joules_est": 82.01, "sample_count": 20, "duration_seconds": 1.956}, "timestamp": "2026-01-12T09:41:14.054018"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1194.56, "latencies_ms": [1194.56], "images_per_second": 0.837, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man wearing a blue and white striped beanie is holding a yellow frisbee in his hand and appears to be preparing to throw it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13312.9, "ram_available_mb": 109193.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13301.7, "ram_available_mb": 109204.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.41, 32.41, 32.41, 32.41, 32.41, 45.18, 45.18, 45.18, 45.18, 45.18, 46.81, 46.81], "power_watts_avg": 40.13, "power_watts_peak": 46.81, "energy_joules_est": 47.99, "sample_count": 12, "duration_seconds": 1.196}, "timestamp": "2026-01-12T09:41:15.320240"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1961.156, "latencies_ms": [1961.156], "images_per_second": 0.51, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. head: 1\n3. hair: 1\n4. shirt: 1\n5. hand: 1\n6. frisbee: 1\n7. ceiling: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13293.9, "ram_available_mb": 109212.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13298.6, "ram_available_mb": 109207.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.81, 46.81, 46.81, 40.0, 40.0, 40.0, 40.0, 40.0, 47.0, 47.0, 47.0, 47.0, 47.0, 40.77, 40.77, 40.77, 40.77, 40.77, 33.88, 33.88], "power_watts_avg": 42.35, "power_watts_peak": 47.0, "energy_joules_est": 83.08, "sample_count": 20, "duration_seconds": 1.961}, "timestamp": "2026-01-12T09:41:17.339684"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1640.72, "latencies_ms": [1640.72], "images_per_second": 0.609, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee in his hand. The frisbee is in front of him, and he is looking at it. The background is dark, and there are people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13290.7, "ram_available_mb": 109215.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13302.3, "ram_available_mb": 109204.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.88, 33.88, 33.88, 35.08, 35.08, 35.08, 35.08, 35.08, 45.1, 45.1, 45.1, 45.1, 45.1, 44.01, 44.01, 44.01, 44.01], "power_watts_avg": 39.92, "power_watts_peak": 45.1, "energy_joules_est": 65.52, "sample_count": 17, "duration_seconds": 1.641}, "timestamp": "2026-01-12T09:41:19.107976"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 956.479, "latencies_ms": [956.479], "images_per_second": 1.046, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing a blue hat and a black shirt is playing frisbee in a dark room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13298.3, "ram_available_mb": 109208.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13306.9, "ram_available_mb": 109199.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.07, 33.07, 33.07, 33.07, 33.07, 45.93, 45.93, 45.93, 45.93, 45.93], "power_watts_avg": 39.5, "power_watts_peak": 45.93, "energy_joules_est": 37.8, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-12T09:41:20.120779"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1193.787, "latencies_ms": [1193.787], "images_per_second": 0.838, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is a black and white photo with a blue and white striped hat. The lighting is dim, and the subject is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13299.1, "ram_available_mb": 109207.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13309.6, "ram_available_mb": 109196.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.94, 45.94, 45.94, 45.94, 45.94, 46.35, 46.35, 46.35, 46.35, 46.35, 46.41, 46.41], "power_watts_avg": 46.19, "power_watts_peak": 46.41, "energy_joules_est": 55.16, "sample_count": 12, "duration_seconds": 1.194}, "timestamp": "2026-01-12T09:41:21.335318"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1180.676, "latencies_ms": [1180.676], "images_per_second": 0.847, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people are sitting around a table with laptops and books, and they are all looking at the screen of one of the laptops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.6, "ram_available_mb": 109196.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13309.8, "ram_available_mb": 109196.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.41, 46.41, 46.41, 39.96, 39.96, 39.96, 39.96, 39.96, 46.75, 46.75, 46.75, 46.75], "power_watts_avg": 43.83, "power_watts_peak": 46.75, "energy_joules_est": 51.76, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-12T09:41:22.550370"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1330.605, "latencies_ms": [1330.605], "images_per_second": 0.752, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 3, keyboard: 1, mouse: 1, cup: 1, bottle: 1, book: 1, person: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.8, "ram_available_mb": 109196.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13288.5, "ram_available_mb": 109217.8, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [46.75, 39.67, 39.67, 39.67, 39.67, 39.67, 46.47, 46.47, 46.47, 46.47, 46.47, 48.34, 48.34, 48.34], "power_watts_avg": 44.46, "power_watts_peak": 48.34, "energy_joules_est": 59.18, "sample_count": 14, "duration_seconds": 1.331}, "timestamp": "2026-01-12T09:41:23.962065"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1879.226, "latencies_ms": [1879.226], "images_per_second": 0.532, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the woman is on the right side of the table, and the man is in the middle of the table. The laptop is in the foreground, the woman is in the background, and the man is in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13280.7, "ram_available_mb": 109225.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13299.9, "ram_available_mb": 109206.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.34, 48.34, 33.36, 33.36, 33.36, 33.36, 33.36, 45.76, 45.76, 45.76, 45.76, 45.76, 46.62, 46.62, 46.62, 46.62, 46.62, 33.92, 33.92], "power_watts_avg": 41.75, "power_watts_peak": 48.34, "energy_joules_est": 78.46, "sample_count": 19, "duration_seconds": 1.88}, "timestamp": "2026-01-12T09:41:25.877896"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 909.139, "latencies_ms": [909.139], "images_per_second": 1.1, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, working on their laptops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.0, "ram_available_mb": 109214.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13310.8, "ram_available_mb": 109195.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 15.0}, "power_stats": {"power_watts_samples": [33.92, 33.92, 34.71, 34.71, 34.71, 34.71, 34.71, 45.65, 45.65, 45.65], "power_watts_avg": 37.83, "power_watts_peak": 45.65, "energy_joules_est": 34.42, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-12T09:41:26.940475"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1552.368, "latencies_ms": [1552.368], "images_per_second": 0.644, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm yellow light. The people are using laptops and computers, and there are various objects on the table, including a glass of water and a cup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.8, "ram_available_mb": 109199.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13307.1, "ram_available_mb": 109199.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.65, 45.65, 44.78, 44.78, 44.78, 44.78, 44.78, 45.17, 45.17, 45.17, 45.17, 45.17, 45.94, 45.94, 45.94, 45.94], "power_watts_avg": 45.3, "power_watts_peak": 45.94, "energy_joules_est": 70.35, "sample_count": 16, "duration_seconds": 1.553}, "timestamp": "2026-01-12T09:41:28.556392"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1130.525, "latencies_ms": [1130.525], "images_per_second": 0.885, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is holding a brown teddy bear and a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13307.1, "ram_available_mb": 109199.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13293.4, "ram_available_mb": 109212.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [45.94, 31.65, 31.65, 31.65, 31.65, 31.65, 48.43, 48.43, 48.43, 48.43, 48.43, 52.08], "power_watts_avg": 41.54, "power_watts_peak": 52.08, "energy_joules_est": 46.99, "sample_count": 12, "duration_seconds": 1.131}, "timestamp": "2026-01-12T09:41:29.781324"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2442.518, "latencies_ms": [2442.518], "images_per_second": 0.409, "prompt_tokens": 1446, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. girl: 1\n2. blue umbrella: 1\n3. girl's hand: 1\n4. girl's leg: 1\n5. girl's foot: 1\n6. girl's hand: 1\n7. girl's arm: 1\n8. girl's leg: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13289.4, "ram_available_mb": 109216.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13320.2, "ram_available_mb": 109186.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.08, 52.08, 52.08, 52.08, 40.3, 40.3, 40.3, 40.3, 40.3, 49.18, 49.18, 49.18, 49.18, 49.18, 44.15, 44.15, 44.15, 44.15, 44.15, 33.9, 33.9, 33.9, 33.9, 33.9, 33.91], "power_watts_avg": 43.19, "power_watts_peak": 52.08, "energy_joules_est": 105.52, "sample_count": 25, "duration_seconds": 2.443}, "timestamp": "2026-01-12T09:41:32.304394"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1681.131, "latencies_ms": [1681.131], "images_per_second": 0.595, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding the umbrella in her right hand. The umbrella is positioned above her, providing shade. The gravel ground is located in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13320.2, "ram_available_mb": 109186.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13306.2, "ram_available_mb": 109200.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.91, 33.91, 33.91, 34.56, 34.56, 34.56, 34.56, 34.56, 48.61, 48.61, 48.61, 48.61, 48.61, 48.5, 48.5, 48.5, 48.5], "power_watts_avg": 41.86, "power_watts_peak": 48.61, "energy_joules_est": 70.4, "sample_count": 17, "duration_seconds": 1.682}, "timestamp": "2026-01-12T09:41:34.066105"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1134.558, "latencies_ms": [1134.558], "images_per_second": 0.881, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is standing on a gravel surface holding a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.2, "ram_available_mb": 109200.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13325.6, "ram_available_mb": 109180.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.5, 32.7, 32.7, 32.7, 32.7, 32.7, 49.34, 49.34, 49.34, 49.34, 49.34, 51.9], "power_watts_avg": 42.55, "power_watts_peak": 51.9, "energy_joules_est": 48.29, "sample_count": 12, "duration_seconds": 1.135}, "timestamp": "2026-01-12T09:41:35.280468"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1291.986, "latencies_ms": [1291.986], "images_per_second": 0.774, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The girl is wearing a pink jacket and blue jeans, and the umbrella is blue. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13321.5, "ram_available_mb": 109184.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13337.1, "ram_available_mb": 109169.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [51.9, 51.9, 51.9, 51.9, 40.65, 40.65, 40.65, 40.65, 40.65, 49.46, 49.46, 49.46, 49.46], "power_watts_avg": 46.82, "power_watts_peak": 51.9, "energy_joules_est": 60.52, "sample_count": 13, "duration_seconds": 1.293}, "timestamp": "2026-01-12T09:41:36.593994"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 932.471, "latencies_ms": [932.471], "images_per_second": 1.072, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man in a suit stands in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.1, "ram_available_mb": 109177.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13323.9, "ram_available_mb": 109182.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [49.46, 44.4, 44.4, 44.4, 44.4, 44.4, 46.77, 46.77, 46.77, 46.77], "power_watts_avg": 45.85, "power_watts_peak": 49.46, "energy_joules_est": 42.76, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T09:41:37.606823"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1491.565, "latencies_ms": [1491.565], "images_per_second": 0.67, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " man: 1, chair: 1, computer: 2, monitor: 1, keyboard: 1, mouse: 1, tv: 1, tv screen: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13316.0, "ram_available_mb": 109190.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13317.4, "ram_available_mb": 109188.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.51, 45.51, 45.51, 45.51, 45.51, 45.97, 45.97, 45.97, 45.97, 45.97, 47.25, 47.25, 47.25, 47.25, 47.25], "power_watts_avg": 46.25, "power_watts_peak": 47.25, "energy_joules_est": 68.99, "sample_count": 15, "duration_seconds": 1.492}, "timestamp": "2026-01-12T09:41:39.122257"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2016.623, "latencies_ms": [2016.623], "images_per_second": 0.496, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The man is standing to the left of the desk, which is in the foreground of the image. The desk is located in the middle of the image, with the computer monitors placed on it. The window is located behind the desk, and the reflection of the man can be seen in the window.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13313.5, "ram_available_mb": 109192.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13309.9, "ram_available_mb": 109196.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.69, 33.69, 33.69, 33.69, 33.69, 47.04, 47.04, 47.04, 47.04, 47.04, 47.17, 47.17, 47.17, 47.17, 47.17, 34.0, 34.0, 34.0, 34.0, 34.0, 33.88], "power_watts_avg": 40.16, "power_watts_peak": 47.17, "energy_joules_est": 81.01, "sample_count": 21, "duration_seconds": 2.017}, "timestamp": "2026-01-12T09:41:41.241685"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 931.33, "latencies_ms": [931.33], "images_per_second": 1.074, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man in a suit stands in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.9, "ram_available_mb": 109196.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13325.9, "ram_available_mb": 109180.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.88, 33.88, 33.88, 33.88, 39.54, 39.54, 39.54, 39.54, 39.54, 44.29], "power_watts_avg": 37.75, "power_watts_peak": 44.29, "energy_joules_est": 35.18, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-12T09:41:42.304135"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1059.007, "latencies_ms": [1059.007], "images_per_second": 0.944, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from a window. The man is wearing a black suit and tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.1, "ram_available_mb": 109188.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13327.1, "ram_available_mb": 109179.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.29, 44.29, 44.29, 45.93, 45.93, 45.93, 45.93, 45.93, 45.7, 45.7, 45.7], "power_watts_avg": 45.42, "power_watts_peak": 45.93, "energy_joules_est": 48.13, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T09:41:43.417955"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1150.214, "latencies_ms": [1150.214], "images_per_second": 0.869, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A group of people are sitting around a table in a room with wooden walls and a clock on the wall, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.2, "ram_available_mb": 109183.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13323.9, "ram_available_mb": 109182.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.7, 45.7, 41.08, 41.08, 41.08, 41.08, 41.08, 46.2, 46.2, 46.2, 46.2, 46.2], "power_watts_avg": 43.98, "power_watts_peak": 46.2, "energy_joules_est": 50.61, "sample_count": 12, "duration_seconds": 1.151}, "timestamp": "2026-01-12T09:41:44.633162"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1546.055, "latencies_ms": [1546.055], "images_per_second": 0.647, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " table: 1\nclock: 1\nwindow: 1\ncurtain: 1\ncup: 1\nbottle: 1\nbowl: 1\nplate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.1, "ram_available_mb": 109190.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13318.0, "ram_available_mb": 109188.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.69, 44.69, 44.69, 44.69, 44.69, 45.95, 45.95, 45.95, 45.95, 45.95, 46.73, 46.73, 46.73, 46.73, 46.73, 33.87], "power_watts_avg": 45.04, "power_watts_peak": 46.73, "energy_joules_est": 69.66, "sample_count": 16, "duration_seconds": 1.547}, "timestamp": "2026-01-12T09:41:46.248087"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1514.935, "latencies_ms": [1514.935], "images_per_second": 0.66, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The window is in the background, and the clock is on the wall above the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.1, "ram_available_mb": 109196.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.87, 33.87, 33.87, 33.87, 42.38, 42.38, 42.38, 42.38, 42.38, 46.11, 46.11, 46.11, 46.11, 46.11, 38.06, 38.06], "power_watts_avg": 40.88, "power_watts_peak": 46.11, "energy_joules_est": 61.95, "sample_count": 16, "duration_seconds": 1.516}, "timestamp": "2026-01-12T09:41:47.865118"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1381.523, "latencies_ms": [1381.523], "images_per_second": 0.724, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of friends are gathered around a wooden table in a cozy room with a large window. They are enjoying a meal together, with plates of food and drinks on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13315.5, "ram_available_mb": 109190.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13324.1, "ram_available_mb": 109182.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [38.06, 38.06, 38.06, 37.2, 37.2, 37.2, 37.2, 37.2, 45.32, 45.32, 45.32, 45.32, 45.32, 42.99], "power_watts_avg": 40.7, "power_watts_peak": 45.32, "energy_joules_est": 56.23, "sample_count": 14, "duration_seconds": 1.382}, "timestamp": "2026-01-12T09:41:49.279323"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1016.117, "latencies_ms": [1016.117], "images_per_second": 0.984, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is dimly lit with wooden walls and ceiling, and the light is coming in from a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.2, "ram_available_mb": 109190.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13325.8, "ram_available_mb": 109180.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [42.99, 42.99, 42.99, 42.99, 42.2, 42.2, 42.2, 42.2, 42.2, 46.69, 46.69], "power_watts_avg": 43.3, "power_watts_peak": 46.69, "energy_joules_est": 44.03, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-12T09:41:50.393177"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1061.29, "latencies_ms": [1061.29], "images_per_second": 0.942, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A red truck with a snow plow attached to the front is driving down a snowy street, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.8, "ram_available_mb": 109182.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13312.3, "ram_available_mb": 109194.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.69, 46.69, 46.69, 40.63, 40.63, 40.63, 40.63, 40.63, 45.58, 45.58, 45.58], "power_watts_avg": 43.63, "power_watts_peak": 46.69, "energy_joules_est": 46.31, "sample_count": 11, "duration_seconds": 1.061}, "timestamp": "2026-01-12T09:41:51.509673"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1992.388, "latencies_ms": [1992.388], "images_per_second": 0.502, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. red truck: 1\n2. snowplow: 1\n3. snow: 1\n4. house: 1\n5. tree: 1\n6. person: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13312.3, "ram_available_mb": 109194.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13314.3, "ram_available_mb": 109192.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.58, 42.14, 42.14, 42.14, 42.14, 42.14, 46.5, 46.5, 46.5, 46.5, 46.5, 48.56, 48.56, 48.56, 48.56, 48.56, 33.93, 33.93, 33.93, 33.93], "power_watts_avg": 43.36, "power_watts_peak": 48.56, "energy_joules_est": 86.4, "sample_count": 20, "duration_seconds": 1.993}, "timestamp": "2026-01-12T09:41:53.529550"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1877.789, "latencies_ms": [1877.789], "images_per_second": 0.533, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The red truck is in the foreground, driving down the street. The snowplow is attached to the front of the truck, and it is in the middle of the image. The houses are in the background, and the trees are on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.4, "ram_available_mb": 109199.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13316.1, "ram_available_mb": 109190.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.93, 32.0, 32.0, 32.0, 32.0, 32.0, 45.83, 45.83, 45.83, 45.83, 45.83, 47.82, 47.82, 47.82, 47.82, 47.82, 34.04, 34.04, 34.04], "power_watts_avg": 40.23, "power_watts_peak": 47.82, "energy_joules_est": 75.59, "sample_count": 19, "duration_seconds": 1.879}, "timestamp": "2026-01-12T09:41:55.500108"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1239.672, "latencies_ms": [1239.672], "images_per_second": 0.807, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A red truck is driving down a snowy street with a snowplow attached to the front. The truck is passing by a row of houses and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13312.2, "ram_available_mb": 109194.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13312.4, "ram_available_mb": 109193.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.04, 31.38, 31.38, 31.38, 31.38, 31.38, 45.79, 45.79, 45.79, 45.79, 45.79, 48.55, 48.55], "power_watts_avg": 39.77, "power_watts_peak": 48.55, "energy_joules_est": 49.35, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-12T09:41:56.864691"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1480.169, "latencies_ms": [1480.169], "images_per_second": 0.676, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a red truck with a snow plow attached to the front, driving down a snowy street. The sky is overcast, and the snow is piled up on the sides of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13304.5, "ram_available_mb": 109201.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.3, "ram_available_mb": 109184.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.55, 48.55, 48.55, 38.35, 38.35, 38.35, 38.35, 38.35, 46.01, 46.01, 46.01, 46.01, 46.01, 41.87, 41.87], "power_watts_avg": 43.41, "power_watts_peak": 48.55, "energy_joules_est": 64.28, "sample_count": 15, "duration_seconds": 1.481}, "timestamp": "2026-01-12T09:41:58.379955"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 910.198, "latencies_ms": [910.198], "images_per_second": 1.099, "prompt_tokens": 1432, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is taking a picture of himself in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13314.5, "ram_available_mb": 109191.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.87, 41.87, 41.87, 35.8, 35.8, 35.8, 35.8, 35.8, 50.27, 50.27], "power_watts_avg": 40.52, "power_watts_peak": 50.27, "energy_joules_est": 36.9, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-12T09:41:59.395760"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2094.702, "latencies_ms": [2094.702], "images_per_second": 0.477, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. mirror: 2\n2. television: 1\n3. towel: 3\n4. bath tub: 1\n5. sink: 2\n6. counter: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13341.7, "ram_available_mb": 109164.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13317.6, "ram_available_mb": 109188.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.27, 50.27, 50.27, 49.09, 49.09, 49.09, 49.09, 49.09, 49.48, 49.48, 49.48, 49.48, 49.48, 49.83, 49.83, 49.83, 49.83, 49.83, 34.24, 34.24, 34.24], "power_watts_avg": 47.41, "power_watts_peak": 50.27, "energy_joules_est": 99.32, "sample_count": 21, "duration_seconds": 2.095}, "timestamp": "2026-01-12T09:42:01.512425"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2324.49, "latencies_ms": [2324.49], "images_per_second": 0.43, "prompt_tokens": 1450, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The sink is located in the center of the bathroom, with the mirror above it reflecting the person taking the photo. The towels are hanging on the wall to the left of the sink, while the television is mounted on the wall above the sink. The person is standing in front of the mirror, taking a photo of themselves.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13317.6, "ram_available_mb": 109188.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13295.8, "ram_available_mb": 109210.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.24, 31.94, 31.94, 31.94, 31.94, 31.94, 48.58, 48.58, 48.58, 48.58, 48.58, 52.02, 52.02, 52.02, 52.02, 52.02, 34.98, 34.98, 34.98, 34.98, 34.98, 34.01, 34.01, 34.01], "power_watts_avg": 40.58, "power_watts_peak": 52.02, "energy_joules_est": 94.36, "sample_count": 24, "duration_seconds": 2.325}, "timestamp": "2026-01-12T09:42:03.979940"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 922.389, "latencies_ms": [922.389], "images_per_second": 1.084, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is taking a picture of himself in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13295.8, "ram_available_mb": 109210.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.01, 29.86, 29.86, 29.86, 29.86, 29.86, 48.6, 48.6, 48.6, 48.6], "power_watts_avg": 37.77, "power_watts_peak": 48.6, "energy_joules_est": 34.87, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-12T09:42:05.043562"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1865.331, "latencies_ms": [1865.331], "images_per_second": 0.536, "prompt_tokens": 1442, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The bathroom is well-lit with warm lighting, and the walls are adorned with a mix of beige and white tiles. The countertop is made of dark green marble, and the floor is covered with a white and red patterned rug.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13317.0, "ram_available_mb": 109189.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.6, 49.0, 49.0, 49.0, 49.0, 49.0, 49.31, 49.31, 49.31, 49.31, 49.31, 52.42, 52.42, 52.42, 52.42, 52.42, 35.06, 35.06, 35.06], "power_watts_avg": 47.76, "power_watts_peak": 52.42, "energy_joules_est": 89.11, "sample_count": 19, "duration_seconds": 1.866}, "timestamp": "2026-01-12T09:42:06.966811"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 821.98, "latencies_ms": [821.98], "images_per_second": 1.217, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two men are unloading luggage from a cart in an airport parking garage.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13309.0, "ram_available_mb": 109197.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13327.4, "ram_available_mb": 109178.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [35.06, 30.55, 30.55, 30.55, 30.55, 30.55, 45.17, 45.17, 45.17], "power_watts_avg": 35.92, "power_watts_peak": 45.17, "energy_joules_est": 29.55, "sample_count": 9, "duration_seconds": 0.822}, "timestamp": "2026-01-12T09:42:07.931872"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1903.264, "latencies_ms": [1903.264], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. luggage: 4\n2. luggage: 1\n3. luggage: 1\n4. luggage: 1\n5. luggage: 1\n6. luggage: 1\n7. luggage: 1\n8. luggage: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.5, "ram_available_mb": 109182.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13311.9, "ram_available_mb": 109194.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.17, 45.17, 49.99, 49.99, 49.99, 49.99, 49.99, 45.67, 45.67, 45.67, 45.67, 45.67, 45.47, 45.47, 45.47, 45.47, 45.47, 33.94, 33.94], "power_watts_avg": 45.47, "power_watts_peak": 49.99, "energy_joules_est": 86.57, "sample_count": 19, "duration_seconds": 1.904}, "timestamp": "2026-01-12T09:42:09.850078"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1683.979, "latencies_ms": [1683.979], "images_per_second": 0.594, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The man in the foreground is pushing a luggage cart towards the white SUV, which is parked in the background. The luggage cart is positioned to the left of the SUV, and the man is standing to the right of the cart.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13304.0, "ram_available_mb": 109202.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13321.7, "ram_available_mb": 109184.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.94, 33.94, 33.94, 40.06, 40.06, 40.06, 40.06, 40.06, 47.32, 47.32, 47.32, 47.32, 47.32, 42.08, 42.08, 42.08, 42.08], "power_watts_avg": 41.59, "power_watts_peak": 47.32, "energy_joules_est": 70.05, "sample_count": 17, "duration_seconds": 1.684}, "timestamp": "2026-01-12T09:42:11.566173"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 788.915, "latencies_ms": [788.915], "images_per_second": 1.268, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are unloading luggage from a car in a parking garage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.7, "ram_available_mb": 109184.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13318.0, "ram_available_mb": 109188.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [42.08, 32.77, 32.77, 32.77, 32.77, 32.77, 46.68, 46.68], "power_watts_avg": 37.41, "power_watts_peak": 46.68, "energy_joules_est": 29.53, "sample_count": 8, "duration_seconds": 0.789}, "timestamp": "2026-01-12T09:42:12.377463"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1287.414, "latencies_ms": [1287.414], "images_per_second": 0.777, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a man in a parking garage with a white car and a black suitcase. The lighting is dim, and the man is wearing a brown shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.0, "ram_available_mb": 109188.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13318.3, "ram_available_mb": 109188.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.68, 46.68, 46.68, 53.07, 53.07, 53.07, 53.07, 53.07, 47.19, 47.19, 47.19, 47.19, 47.19], "power_watts_avg": 49.33, "power_watts_peak": 53.07, "energy_joules_est": 63.52, "sample_count": 13, "duration_seconds": 1.288}, "timestamp": "2026-01-12T09:42:13.691225"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 972.735, "latencies_ms": [972.735], "images_per_second": 1.028, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A plate with a sandwich, fries, and a small bowl of ketchup is on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.3, "ram_available_mb": 109188.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13312.5, "ram_available_mb": 109193.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 42.54, 42.54, 46.8, 46.8, 46.8, 46.8, 46.8], "power_watts_avg": 44.67, "power_watts_peak": 46.8, "energy_joules_est": 43.48, "sample_count": 10, "duration_seconds": 0.973}, "timestamp": "2026-01-12T09:42:14.704991"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1219.766, "latencies_ms": [1219.766], "images_per_second": 0.82, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " chicken sandwich: 2\nfries: 1\nlettuce: 1\nonion: 1\nketchup: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13304.6, "ram_available_mb": 109201.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13307.5, "ram_available_mb": 109198.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.82, 46.82, 46.82, 46.82, 46.82, 46.45, 46.45, 46.45, 46.45, 46.45, 46.81, 46.81, 46.81], "power_watts_avg": 46.68, "power_watts_peak": 46.82, "energy_joules_est": 56.96, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-12T09:42:16.019523"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1555.809, "latencies_ms": [1555.809], "images_per_second": 0.643, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the plate, with the fries and ketchup in the background. The lettuce and onion are placed near the sandwich, while the ketchup is located near the fries.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.5, "ram_available_mb": 109202.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13311.7, "ram_available_mb": 109194.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.81, 32.12, 32.12, 32.12, 32.12, 32.12, 45.55, 45.55, 45.55, 45.55, 45.55, 48.91, 48.91, 48.91, 48.91, 48.91], "power_watts_avg": 42.48, "power_watts_peak": 48.91, "energy_joules_est": 66.1, "sample_count": 16, "duration_seconds": 1.556}, "timestamp": "2026-01-12T09:42:17.636579"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 922.363, "latencies_ms": [922.363], "images_per_second": 1.084, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A plate of food with a sandwich, fries, and ketchup is on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.8, "ram_available_mb": 109202.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13314.6, "ram_available_mb": 109191.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.69, 33.69, 33.69, 33.69, 33.69, 46.49, 46.49, 46.49, 46.49, 46.49], "power_watts_avg": 40.09, "power_watts_peak": 46.49, "energy_joules_est": 36.98, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-12T09:42:18.647825"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1000.955, "latencies_ms": [1000.955], "images_per_second": 0.999, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The plate is white and the food is colorful. The lighting is bright and the food is well-lit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.8, "ram_available_mb": 109199.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13317.7, "ram_available_mb": 109188.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.14, 46.14, 46.14, 46.14, 46.14, 45.95, 45.95, 45.95, 45.95, 45.95], "power_watts_avg": 46.05, "power_watts_peak": 46.14, "energy_joules_est": 46.12, "sample_count": 10, "duration_seconds": 1.002}, "timestamp": "2026-01-12T09:42:19.661060"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1217.537, "latencies_ms": [1217.537], "images_per_second": 0.821, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed covered by a green mosquito net, a wooden table with a candle, and a window with curtains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.7, "ram_available_mb": 109192.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13303.5, "ram_available_mb": 109202.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [46.75, 46.75, 46.75, 46.75, 46.75, 47.11, 47.11, 47.11, 47.11, 47.11, 47.29, 47.29, 47.29], "power_watts_avg": 47.01, "power_watts_peak": 47.29, "energy_joules_est": 57.25, "sample_count": 13, "duration_seconds": 1.218}, "timestamp": "2026-01-12T09:42:20.977621"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1915.765, "latencies_ms": [1915.765], "images_per_second": 0.522, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. curtains: 2\n3. table: 1\n4. chair: 1\n5. floor: 1\n6. wall: 1\n7. candle: 1\n8. painting: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13295.7, "ram_available_mb": 109210.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13315.0, "ram_available_mb": 109191.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [47.29, 47.29, 32.41, 32.41, 32.41, 32.41, 32.41, 45.61, 45.61, 45.61, 45.61, 45.61, 46.99, 46.99, 46.99, 46.99, 46.99, 33.84, 33.84, 33.84], "power_watts_avg": 41.06, "power_watts_peak": 47.29, "energy_joules_est": 78.68, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T09:42:22.993012"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2291.508, "latencies_ms": [2291.508], "images_per_second": 0.436, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the mosquito net draped over it, creating a sense of intimacy and seclusion. The table and chairs are situated in the foreground, providing a comfortable seating area for guests. The windows and paintings are located in the background, allowing natural light to flood the room and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 13315.0, "ram_available_mb": 109191.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13370.6, "ram_available_mb": 109135.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.84, 30.2, 30.2, 30.2, 30.2, 30.2, 44.48, 44.48, 44.48, 44.48, 44.48, 48.65, 48.65, 48.65, 48.65, 48.65, 34.09, 34.09, 34.09, 34.09, 34.09, 34.11, 34.11], "power_watts_avg": 38.66, "power_watts_peak": 48.65, "energy_joules_est": 88.62, "sample_count": 23, "duration_seconds": 2.292}, "timestamp": "2026-01-12T09:42:25.357897"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2260.05, "latencies_ms": [2260.05], "images_per_second": 0.442, "prompt_tokens": 1111, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image captures a serene bedroom bathed in soft light, with a large bed draped in a green mosquito net, creating a sense of privacy and tranquility. The room is adorned with yellow walls and a thatched roof, adding to the tropical ambiance. A wooden table and chairs are positioned in the room, inviting relaxation and conversation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.6, "ram_available_mb": 109139.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13281.7, "ram_available_mb": 109224.6, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 35.7, 35.7, 35.7, 35.7, 35.7, 46.02, 46.02, 46.02, 46.02, 46.02, 45.02, 45.02, 45.02, 45.02, 45.02, 33.93, 33.93, 33.93, 33.93, 33.96], "power_watts_avg": 39.38, "power_watts_peak": 46.02, "energy_joules_est": 89.02, "sample_count": 23, "duration_seconds": 2.261}, "timestamp": "2026-01-12T09:42:27.725895"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1358.476, "latencies_ms": [1358.476], "images_per_second": 0.736, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with a canopy of green fabric draped over the bed, and the walls are adorned with paintings of trees and plants.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13281.7, "ram_available_mb": 109224.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13332.8, "ram_available_mb": 109173.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.96, 33.96, 33.96, 33.96, 40.38, 40.38, 40.38, 40.38, 40.38, 45.24, 45.24, 45.24, 45.24, 45.24], "power_watts_avg": 40.28, "power_watts_peak": 45.24, "energy_joules_est": 54.76, "sample_count": 14, "duration_seconds": 1.359}, "timestamp": "2026-01-12T09:42:29.190852"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1013.71, "latencies_ms": [1013.71], "images_per_second": 0.986, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A gray and white cat with a blue collar is standing on the hood of a black car in a garage.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13332.8, "ram_available_mb": 109173.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.74, 38.74, 38.74, 38.74, 38.74, 45.44, 45.44, 45.44, 45.44, 45.44, 46.02], "power_watts_avg": 42.45, "power_watts_peak": 46.02, "energy_joules_est": 43.04, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:42:30.306466"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1932.543, "latencies_ms": [1932.543], "images_per_second": 0.517, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. lamp: 1\n4. box: 1\n5. bicycle: 1\n6. gas cylinder: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.4, "ram_available_mb": 109164.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.2, "ram_available_mb": 109149.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.02, 46.02, 46.02, 46.02, 40.47, 40.47, 40.47, 40.47, 40.47, 45.53, 45.53, 45.53, 45.53, 45.53, 40.55, 40.55, 40.55, 40.55, 40.55, 34.11], "power_watts_avg": 42.55, "power_watts_peak": 46.02, "energy_joules_est": 82.24, "sample_count": 20, "duration_seconds": 1.933}, "timestamp": "2026-01-12T09:42:32.324177"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1318.412, "latencies_ms": [1318.412], "images_per_second": 0.758, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, near the front left corner of the car, and the lamp is located in the background, towards the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.2, "ram_available_mb": 109149.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13372.9, "ram_available_mb": 109133.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 39.16, 39.16, 39.16, 39.16, 39.16, 45.68, 45.68, 45.68, 45.68, 45.68, 40.73], "power_watts_avg": 40.52, "power_watts_peak": 45.68, "energy_joules_est": 53.43, "sample_count": 14, "duration_seconds": 1.319}, "timestamp": "2026-01-12T09:42:33.738028"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 882.636, "latencies_ms": [882.636], "images_per_second": 1.133, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A cat with a collar is standing on the hood of a car in a garage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.4, "ram_available_mb": 109152.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [40.73, 40.73, 40.73, 40.73, 42.61, 42.61, 42.61, 42.61, 42.61], "power_watts_avg": 41.78, "power_watts_peak": 42.61, "energy_joules_est": 36.89, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T09:42:34.650317"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1274.555, "latencies_ms": [1274.555], "images_per_second": 0.785, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The cat is gray and white, and the car is black. The room is well-lit, and the cat is standing on the hood of the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.4, "ram_available_mb": 109152.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13262.6, "ram_available_mb": 109243.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [45.54, 45.54, 45.54, 45.54, 45.54, 49.79, 49.79, 49.79, 49.79, 49.79, 46.96, 46.96, 46.96], "power_watts_avg": 47.5, "power_watts_peak": 49.79, "energy_joules_est": 60.57, "sample_count": 13, "duration_seconds": 1.275}, "timestamp": "2026-01-12T09:42:35.963369"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 931.009, "latencies_ms": [931.009], "images_per_second": 1.074, "prompt_tokens": 1432, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food with a knife on it is on a table.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13262.6, "ram_available_mb": 109243.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13317.4, "ram_available_mb": 109188.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 2.0}, "power_stats": {"power_watts_samples": [46.96, 46.96, 32.94, 32.94, 32.94, 32.94, 32.94, 50.79, 50.79, 50.79], "power_watts_avg": 41.1, "power_watts_peak": 50.79, "energy_joules_est": 38.27, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-12T09:42:36.978996"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2079.317, "latencies_ms": [2079.317], "images_per_second": 0.481, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. knife: 1\n3. food: 1\n4. table: 1\n5. fork: 1\n6. sandwich: 1\n7. sauce: 1\n8. bread: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.5, "ram_available_mb": 109192.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13298.0, "ram_available_mb": 109208.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.79, 50.79, 49.16, 49.16, 49.16, 49.16, 49.16, 49.89, 49.89, 49.89, 49.89, 49.89, 52.75, 52.75, 52.75, 52.75, 52.75, 34.11, 34.11, 34.11, 34.11], "power_watts_avg": 47.48, "power_watts_peak": 52.75, "energy_joules_est": 98.73, "sample_count": 21, "duration_seconds": 2.08}, "timestamp": "2026-01-12T09:42:39.099066"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1597.922, "latencies_ms": [1597.922], "images_per_second": 0.626, "prompt_tokens": 1450, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the knife is on the plate. The food is on the left side of the plate, and the table is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13290.1, "ram_available_mb": 109216.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13321.5, "ram_available_mb": 109184.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.23, 33.23, 33.23, 33.23, 33.23, 44.78, 44.78, 44.78, 44.78, 44.78, 50.61, 50.61, 50.61, 50.61, 50.61, 39.14], "power_watts_avg": 42.64, "power_watts_peak": 50.61, "energy_joules_est": 68.16, "sample_count": 16, "duration_seconds": 1.599}, "timestamp": "2026-01-12T09:42:40.766706"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1186.063, "latencies_ms": [1186.063], "images_per_second": 0.843, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A delicious meal is served on a plate with a knife, and there is a side of fries on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.5, "ram_available_mb": 109184.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13304.3, "ram_available_mb": 109202.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [39.14, 39.14, 39.14, 39.14, 41.08, 41.08, 41.08, 41.08, 41.08, 50.74, 50.74, 50.74], "power_watts_avg": 42.85, "power_watts_peak": 50.74, "energy_joules_est": 50.84, "sample_count": 12, "duration_seconds": 1.186}, "timestamp": "2026-01-12T09:42:41.978099"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1338.269, "latencies_ms": [1338.269], "images_per_second": 0.747, "prompt_tokens": 1442, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image has a warm and inviting atmosphere with natural lighting and a metal table. The colors are vibrant and the textures are smooth and appetizing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.5, "ram_available_mb": 109203.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13318.0, "ram_available_mb": 109188.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.74, 50.74, 42.01, 42.01, 42.01, 42.01, 42.01, 51.04, 51.04, 51.04, 51.04, 51.04, 53.04, 53.04], "power_watts_avg": 48.06, "power_watts_peak": 53.04, "energy_joules_est": 64.33, "sample_count": 14, "duration_seconds": 1.339}, "timestamp": "2026-01-12T09:42:43.392351"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1558.954, "latencies_ms": [1558.954], "images_per_second": 0.641, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the image, there are three men in a living room, with one man standing and the other two sitting on a couch. The standing man is holding a camera, while the two seated men are holding cans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.0, "ram_available_mb": 109188.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13295.4, "ram_available_mb": 109210.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [53.04, 53.04, 53.04, 37.04, 37.04, 37.04, 37.04, 37.04, 46.26, 46.26, 46.26, 46.26, 46.26, 43.96, 43.96, 43.96], "power_watts_avg": 44.22, "power_watts_peak": 53.04, "energy_joules_est": 68.97, "sample_count": 16, "duration_seconds": 1.56}, "timestamp": "2026-01-12T09:42:45.005930"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1402.583, "latencies_ms": [1402.583], "images_per_second": 0.713, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " table: 1\ncouch: 1\nwindow: 1\nlamp: 1\ntable: 1\nsofa: 1\nperson: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13291.5, "ram_available_mb": 109214.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13282.0, "ram_available_mb": 109224.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.96, 43.96, 32.35, 32.35, 32.35, 32.35, 32.35, 46.59, 46.59, 46.59, 46.59, 46.59, 48.33, 48.33], "power_watts_avg": 41.38, "power_watts_peak": 48.33, "energy_joules_est": 58.05, "sample_count": 14, "duration_seconds": 1.403}, "timestamp": "2026-01-12T09:42:46.418431"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2226.628, "latencies_ms": [2226.628], "images_per_second": 0.449, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The person in the white shirt is standing to the right of the person in the blue shirt, who is sitting on the couch. The person in the black shirt is sitting on the floor in front of the person in the blue shirt. The person in the white shirt is holding a camera, which is positioned in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13274.1, "ram_available_mb": 109232.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13282.3, "ram_available_mb": 109224.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.33, 48.33, 48.33, 36.91, 36.91, 36.91, 36.91, 47.14, 47.14, 47.14, 47.14, 47.14, 45.16, 45.16, 45.16, 45.16, 45.16, 34.05, 34.05, 34.05, 34.05, 34.05, 34.07], "power_watts_avg": 41.67, "power_watts_peak": 48.33, "energy_joules_est": 92.8, "sample_count": 23, "duration_seconds": 2.227}, "timestamp": "2026-01-12T09:42:48.737722"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1500.674, "latencies_ms": [1500.674], "images_per_second": 0.666, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " A group of friends are gathered in a living room, enjoying a casual get-together. The room is furnished with a comfortable couch, a coffee table, and a lamp, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13274.5, "ram_available_mb": 109231.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13277.3, "ram_available_mb": 109229.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.07, 34.07, 34.07, 34.07, 42.81, 42.81, 42.81, 42.81, 42.81, 45.56, 45.56, 45.56, 45.56, 45.56, 36.78], "power_watts_avg": 40.99, "power_watts_peak": 45.56, "energy_joules_est": 61.53, "sample_count": 15, "duration_seconds": 1.501}, "timestamp": "2026-01-12T09:42:50.250349"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1104.308, "latencies_ms": [1104.308], "images_per_second": 0.906, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is lit by a lamp and has a warm yellow light. The walls are painted white and the floor is wooden.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13277.3, "ram_available_mb": 109229.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13274.3, "ram_available_mb": 109232.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.78, 36.78, 36.78, 36.78, 43.41, 43.41, 43.41, 43.41, 43.41, 46.59, 46.59], "power_watts_avg": 41.58, "power_watts_peak": 46.59, "energy_joules_est": 45.93, "sample_count": 11, "duration_seconds": 1.105}, "timestamp": "2026-01-12T09:42:51.359847"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1115.816, "latencies_ms": [1115.816], "images_per_second": 0.896, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A baseball catcher in a black and white uniform is crouched in the batter's box, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13273.8, "ram_available_mb": 109232.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13282.4, "ram_available_mb": 109223.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.59, 46.59, 46.59, 42.46, 42.46, 42.46, 42.46, 42.46, 47.05, 47.05, 47.05, 47.05], "power_watts_avg": 45.02, "power_watts_peak": 47.05, "energy_joules_est": 50.27, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T09:42:52.578246"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2722.079, "latencies_ms": [2722.079], "images_per_second": 0.367, "prompt_tokens": 1113, "response_tokens_est": 86, "n_tiles": 1, "output_text": " 1. catcher's mitt: 1\n2. catcher's helmet: 1\n3. catcher's mask: 1\n4. catcher's chest protector: 1\n5. catcher's leg guards: 1\n6. catcher's leg pads: 1\n7. catcher's leg brace: 1\n8. catcher's leg support: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13282.4, "ram_available_mb": 109223.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13283.0, "ram_available_mb": 109223.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.05, 40.72, 40.72, 40.72, 40.72, 40.72, 45.4, 45.4, 45.4, 45.4, 45.4, 47.65, 47.65, 47.65, 47.65, 47.65, 34.11, 34.11, 34.11, 34.11, 34.11, 34.05, 34.05, 34.05, 34.05, 34.05, 33.76, 33.76], "power_watts_avg": 40.15, "power_watts_peak": 47.65, "energy_joules_est": 109.31, "sample_count": 28, "duration_seconds": 2.722}, "timestamp": "2026-01-12T09:42:55.402869"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1865.238, "latencies_ms": [1865.238], "images_per_second": 0.536, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The catcher is positioned in the foreground, squatting behind home plate, while the batter is in the background, standing in the batter's box. The catcher's glove is near the catcher, and the batter's bat is far away from the catcher.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13283.0, "ram_available_mb": 109223.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.76, 33.76, 32.46, 32.46, 32.46, 32.46, 32.46, 44.41, 44.41, 44.41, 44.41, 44.41, 46.32, 46.32, 46.32, 46.32, 46.32, 33.98, 33.98], "power_watts_avg": 39.55, "power_watts_peak": 46.32, "energy_joules_est": 73.8, "sample_count": 19, "duration_seconds": 1.866}, "timestamp": "2026-01-12T09:42:57.366627"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1282.387, "latencies_ms": [1282.387], "images_per_second": 0.78, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A baseball player is crouched in the batter's box, ready to catch the ball. The field is well-maintained and the grass is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13413.4, "ram_available_mb": 109092.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.98, 33.98, 33.98, 35.58, 35.58, 35.58, 35.58, 35.58, 45.5, 45.5, 45.5, 45.5, 45.5], "power_watts_avg": 39.03, "power_watts_peak": 45.5, "energy_joules_est": 50.08, "sample_count": 13, "duration_seconds": 1.283}, "timestamp": "2026-01-12T09:42:58.727290"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2505.426, "latencies_ms": [2505.426], "images_per_second": 0.399, "prompt_tokens": 1109, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment of intense focus and concentration, with the catcher crouched in the batter's box, his body poised and ready for action. The warm glow of the stadium lights illuminates the scene, casting long shadows and highlighting the vibrant colors of the catcher's uniform. The grass surrounding the field is a lush green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.4, "ram_available_mb": 109092.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13374.7, "ram_available_mb": 109131.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.61, 44.61, 44.61, 44.61, 44.82, 44.82, 44.82, 44.82, 44.82, 46.44, 46.44, 46.44, 46.44, 46.44, 36.65, 36.65, 36.65, 36.65, 36.65, 33.96, 33.96, 33.96, 33.96, 33.96, 34.0], "power_watts_avg": 40.87, "power_watts_peak": 46.44, "energy_joules_est": 102.43, "sample_count": 25, "duration_seconds": 2.506}, "timestamp": "2026-01-12T09:43:01.243655"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1220.742, "latencies_ms": [1220.742], "images_per_second": 0.819, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a bathroom with a pink and white color scheme, featuring a bathtub, a toilet, and a wooden vanity with a mirror above it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.7, "ram_available_mb": 109131.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13436.1, "ram_available_mb": 109070.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.0, 34.0, 34.0, 34.0, 41.87, 41.87, 41.87, 41.87, 41.87, 46.0, 46.0, 46.0, 46.0], "power_watts_avg": 40.72, "power_watts_peak": 46.0, "energy_joules_est": 49.77, "sample_count": 13, "duration_seconds": 1.222}, "timestamp": "2026-01-12T09:43:02.610958"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2073.538, "latencies_ms": [2073.538], "images_per_second": 0.482, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Toilet: 1\n3. Window: 1\n4. Shower curtain: 1\n5. Sink: 1\n6. Cabinet: 1\n7. Door: 1\n8. Tile: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.1, "ram_available_mb": 109070.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13458.3, "ram_available_mb": 109048.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.0, 37.06, 37.06, 37.06, 37.06, 37.06, 45.7, 45.7, 45.7, 45.7, 45.7, 47.72, 47.72, 47.72, 47.72, 47.72, 34.03, 34.03, 34.03, 34.03, 34.03], "power_watts_avg": 41.36, "power_watts_peak": 47.72, "energy_joules_est": 85.78, "sample_count": 21, "duration_seconds": 2.074}, "timestamp": "2026-01-12T09:43:04.726564"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1668.103, "latencies_ms": [1668.103], "images_per_second": 0.599, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The shower curtain is located in the middle of the bathroom, with the sink and toilet situated to the right of it. The bathtub is positioned on the left side of the room, while the door is located on the far left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13458.3, "ram_available_mb": 109048.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13431.4, "ram_available_mb": 109074.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.01, 34.01, 34.01, 34.01, 45.19, 45.19, 45.19, 45.19, 45.19, 46.68, 46.68, 46.68, 46.68, 46.68, 35.35, 35.35, 35.35], "power_watts_avg": 41.26, "power_watts_peak": 46.68, "energy_joules_est": 68.86, "sample_count": 17, "duration_seconds": 1.669}, "timestamp": "2026-01-12T09:43:06.444785"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 829.949, "latencies_ms": [829.949], "images_per_second": 1.205, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A bathroom with pink tiles and a white toilet is shown in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13423.5, "ram_available_mb": 109082.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13439.3, "ram_available_mb": 109067.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [35.35, 35.35, 35.65, 35.65, 35.65, 35.65, 35.65, 46.22, 46.22], "power_watts_avg": 37.93, "power_watts_peak": 46.22, "energy_joules_est": 31.5, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-12T09:43:07.355918"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1300.651, "latencies_ms": [1300.651], "images_per_second": 0.769, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bathroom is painted in a light blue color with pink tiles on the walls and floor. The lighting is bright and natural, coming from a window above the bathtub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.5, "ram_available_mb": 109074.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13435.8, "ram_available_mb": 109070.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [46.22, 46.22, 46.22, 50.11, 50.11, 50.11, 50.11, 50.11, 45.78, 45.78, 45.78, 45.78, 45.78], "power_watts_avg": 47.55, "power_watts_peak": 50.11, "energy_joules_est": 61.86, "sample_count": 13, "duration_seconds": 1.301}, "timestamp": "2026-01-12T09:43:08.670355"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1661.255, "latencies_ms": [1661.255], "images_per_second": 0.602, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid bedspread, positioned in the center of the room, and a window with a white curtain on the left side, allowing natural light to enter the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.8, "ram_available_mb": 109074.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13411.9, "ram_available_mb": 109094.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.78, 40.78, 40.78, 40.78, 40.78, 47.16, 47.16, 47.16, 47.16, 47.16, 47.18, 47.18, 47.18, 47.18, 47.18, 34.15, 34.15], "power_watts_avg": 43.76, "power_watts_peak": 47.18, "energy_joules_est": 72.7, "sample_count": 17, "duration_seconds": 1.661}, "timestamp": "2026-01-12T09:43:10.388496"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2043.469, "latencies_ms": [2043.469], "images_per_second": 0.489, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. bed: 1\n2. window: 1\n3. curtain: 2\n4. wall: 1\n5. lamp: 1\n6. bedside table: 1\n7. bed sheet: 1\n8. bed headboard: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13404.0, "ram_available_mb": 109102.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.1, "ram_available_mb": 109125.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 38.14, 38.14, 38.14, 38.14, 38.14, 46.44, 46.44, 46.44, 46.44, 46.44, 42.27, 42.27, 42.27, 42.27, 42.27, 33.95, 33.95, 33.95], "power_watts_avg": 39.93, "power_watts_peak": 46.44, "energy_joules_est": 81.62, "sample_count": 21, "duration_seconds": 2.044}, "timestamp": "2026-01-12T09:43:12.509203"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1435.132, "latencies_ms": [1435.132], "images_per_second": 0.697, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bed is positioned in the foreground, with the window and door located in the background. The window is on the left side of the bed, while the door is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.2, "ram_available_mb": 109133.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.4, "ram_available_mb": 109134.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.95, 30.42, 30.42, 30.42, 30.42, 30.42, 45.01, 45.01, 45.01, 45.01, 45.01, 48.05, 48.05, 48.05, 48.05], "power_watts_avg": 40.22, "power_watts_peak": 48.05, "energy_joules_est": 57.75, "sample_count": 15, "duration_seconds": 1.436}, "timestamp": "2026-01-12T09:43:14.073485"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2014.358, "latencies_ms": [2014.358], "images_per_second": 0.496, "prompt_tokens": 1111, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a serene bedroom scene, bathed in soft light filtering through a window adorned with red curtains. The bed, dressed in a plaid comforter, invites rest and relaxation. A nightstand stands guard beside the bed, its lamp casting a warm glow that dances on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.4, "ram_available_mb": 109134.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.4, "ram_available_mb": 109146.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [48.05, 31.73, 31.73, 31.73, 31.73, 31.73, 45.95, 45.95, 45.95, 45.95, 45.95, 48.42, 48.42, 48.42, 48.42, 48.42, 34.02, 34.02, 34.02, 34.02, 34.02], "power_watts_avg": 40.41, "power_watts_peak": 48.42, "energy_joules_est": 81.43, "sample_count": 21, "duration_seconds": 2.015}, "timestamp": "2026-01-12T09:43:16.192310"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1059.16, "latencies_ms": [1059.16], "images_per_second": 0.944, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is dimly lit with a yellow wall and a bed with a yellow and white plaid comforter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.6, "ram_available_mb": 109154.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.38, 33.38, 33.38, 33.38, 42.4, 42.4, 42.4, 42.4, 42.4, 45.16, 45.16], "power_watts_avg": 39.62, "power_watts_peak": 45.16, "energy_joules_est": 42.0, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T09:43:17.356129"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1077.163, "latencies_ms": [1077.163], "images_per_second": 0.928, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman in a black dress is pinning a white flower to a man's suit jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13267.3, "ram_available_mb": 109239.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.16, 45.16, 45.16, 39.63, 39.63, 39.63, 39.63, 39.63, 50.12, 50.12, 50.12], "power_watts_avg": 44.0, "power_watts_peak": 50.12, "energy_joules_est": 47.4, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-12T09:43:18.470189"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2140.554, "latencies_ms": [2140.554], "images_per_second": 0.467, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Woman: 1\n3. Flower: 1\n4. Tie: 1\n5. Suit: 1\n6. Dress: 1\n7. Shoes: 1\n8. Wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13267.3, "ram_available_mb": 109239.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13251.9, "ram_available_mb": 109254.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [50.12, 50.12, 46.12, 46.12, 46.12, 46.12, 46.12, 50.54, 50.54, 50.54, 50.54, 50.54, 52.01, 52.01, 52.01, 52.01, 52.01, 34.0, 34.0, 34.0, 34.0, 34.0], "power_watts_avg": 46.07, "power_watts_peak": 52.01, "energy_joules_est": 98.63, "sample_count": 22, "duration_seconds": 2.141}, "timestamp": "2026-01-12T09:43:20.694558"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1743.11, "latencies_ms": [1743.11], "images_per_second": 0.574, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, and she is closer to the camera than the man. The woman is holding the man's tie, and the tie is positioned in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13251.9, "ram_available_mb": 109254.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13223.0, "ram_available_mb": 109283.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.83, 33.83, 33.83, 33.83, 40.33, 40.33, 40.33, 40.33, 40.33, 48.78, 48.78, 48.78, 48.78, 48.78, 42.2, 42.2, 42.2, 42.2], "power_watts_avg": 41.65, "power_watts_peak": 48.78, "energy_joules_est": 72.64, "sample_count": 18, "duration_seconds": 1.744}, "timestamp": "2026-01-12T09:43:22.559329"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1324.578, "latencies_ms": [1324.578], "images_per_second": 0.755, "prompt_tokens": 1444, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a suit and tie is getting a boutonniere pinned to his lapel by a woman in a black dress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13223.0, "ram_available_mb": 109283.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13291.5, "ram_available_mb": 109214.8, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [42.2, 31.53, 31.53, 31.53, 31.53, 31.53, 49.75, 49.75, 49.75, 49.75, 49.75, 52.59, 52.59, 52.59], "power_watts_avg": 43.31, "power_watts_peak": 52.59, "energy_joules_est": 57.39, "sample_count": 14, "duration_seconds": 1.325}, "timestamp": "2026-01-12T09:43:23.974985"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1733.196, "latencies_ms": [1733.196], "images_per_second": 0.577, "prompt_tokens": 1442, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is well-lit with natural light, and the colors are vibrant and bright. The man is wearing a black suit and tie, while the woman is dressed in a black dress with a beige ribbon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13291.5, "ram_available_mb": 109214.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13314.9, "ram_available_mb": 109191.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [52.59, 52.59, 31.68, 31.68, 31.68, 31.68, 31.68, 49.26, 49.26, 49.26, 49.26, 49.26, 51.92, 51.92, 51.92, 51.92, 51.92, 34.09], "power_watts_avg": 44.64, "power_watts_peak": 52.59, "energy_joules_est": 77.39, "sample_count": 18, "duration_seconds": 1.734}, "timestamp": "2026-01-12T09:43:25.790397"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1230.56, "latencies_ms": [1230.56], "images_per_second": 0.813, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image shows a chain-link fence with a stop sign attached to it, situated in a grassy area with palm trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13305.3, "ram_available_mb": 109201.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13297.4, "ram_available_mb": 109208.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.09, 34.09, 34.09, 34.09, 41.67, 41.67, 41.67, 41.67, 41.67, 45.82, 45.82, 45.82, 45.82], "power_watts_avg": 40.62, "power_watts_peak": 45.82, "energy_joules_est": 50.0, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-12T09:43:27.104026"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1381.627, "latencies_ms": [1381.627], "images_per_second": 0.724, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " 1. chain link fence\n2. stop sign\n3. palm tree\n4. building\n5. trash\n6. grass\n7. sidewalk\n8. fence post", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13297.4, "ram_available_mb": 109208.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13377.9, "ram_available_mb": 109128.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.82, 37.45, 37.45, 37.45, 37.45, 37.45, 45.98, 45.98, 45.98, 45.98, 45.98, 48.17, 48.17, 48.17], "power_watts_avg": 43.39, "power_watts_peak": 48.17, "energy_joules_est": 59.97, "sample_count": 14, "duration_seconds": 1.382}, "timestamp": "2026-01-12T09:43:28.516792"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1416.015, "latencies_ms": [1416.015], "images_per_second": 0.706, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The stop sign is located in the foreground of the image, on the right side of the chain link fence. The background of the image features a grassy area with palm trees and a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.9, "ram_available_mb": 109128.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13368.2, "ram_available_mb": 109138.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.17, 48.17, 33.42, 33.42, 33.42, 33.42, 33.42, 47.2, 47.2, 47.2, 47.2, 47.2, 48.8, 48.8, 48.8], "power_watts_avg": 43.06, "power_watts_peak": 48.8, "energy_joules_est": 60.99, "sample_count": 15, "duration_seconds": 1.417}, "timestamp": "2026-01-12T09:43:30.030028"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1390.322, "latencies_ms": [1390.322], "images_per_second": 0.719, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a scene of a chain-link fence with a stop sign attached to it, set against a backdrop of a grassy area with palm trees and a building in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.3, "ram_available_mb": 109146.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13355.1, "ram_available_mb": 109151.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.8, 31.36, 31.36, 31.36, 31.36, 31.36, 45.84, 45.84, 45.84, 45.84, 45.84, 48.84, 48.84, 48.84], "power_watts_avg": 41.52, "power_watts_peak": 48.84, "energy_joules_est": 57.75, "sample_count": 14, "duration_seconds": 1.391}, "timestamp": "2026-01-12T09:43:31.443110"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1356.276, "latencies_ms": [1356.276], "images_per_second": 0.737, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a red and white stop sign, a chain link fence, and a grassy area with palm trees. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.1, "ram_available_mb": 109151.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13347.7, "ram_available_mb": 109158.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.84, 48.84, 36.48, 36.48, 36.48, 36.48, 36.48, 46.95, 46.95, 46.95, 46.95, 46.95, 44.89, 44.89], "power_watts_avg": 43.19, "power_watts_peak": 48.84, "energy_joules_est": 58.6, "sample_count": 14, "duration_seconds": 1.357}, "timestamp": "2026-01-12T09:43:32.854349"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1352.093, "latencies_ms": [1352.093], "images_per_second": 0.74, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A man wearing a helmet is riding a motorcycle next to a black bicycle with a basket on the back, while a man in a gray shirt and khaki shorts stands nearby.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13339.8, "ram_available_mb": 109166.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13363.4, "ram_available_mb": 109142.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.89, 44.89, 44.89, 39.6, 39.6, 39.6, 39.6, 39.6, 46.58, 46.58, 46.58, 46.58, 46.58, 41.71], "power_watts_avg": 43.38, "power_watts_peak": 46.58, "energy_joules_est": 58.68, "sample_count": 14, "duration_seconds": 1.353}, "timestamp": "2026-01-12T09:43:34.268780"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1546.965, "latencies_ms": [1546.965], "images_per_second": 0.646, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. yellow bicycle\n2. black bicycle\n3. motorcycle\n4. person\n5. person's hand\n6. person's leg\n7. person's foot\n8. person's shoe", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.4, "ram_available_mb": 109142.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13361.7, "ram_available_mb": 109144.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.71, 41.71, 41.71, 41.71, 43.24, 43.24, 43.24, 43.24, 43.24, 46.14, 46.14, 46.14, 46.14, 46.14, 36.83, 36.83], "power_watts_avg": 42.97, "power_watts_peak": 46.14, "energy_joules_est": 66.48, "sample_count": 16, "duration_seconds": 1.547}, "timestamp": "2026-01-12T09:43:35.881959"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1708.82, "latencies_ms": [1708.82], "images_per_second": 0.585, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The yellow bicycle is positioned to the left of the black bicycle, which is in the foreground of the image. The person standing next to the black bicycle is positioned in the background, while the motorcycle is positioned to the left of the yellow bicycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.7, "ram_available_mb": 109144.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13370.3, "ram_available_mb": 109136.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.83, 36.83, 36.83, 38.15, 38.15, 38.15, 38.15, 38.15, 46.17, 46.17, 46.17, 46.17, 46.17, 42.14, 42.14, 42.14, 42.14], "power_watts_avg": 41.21, "power_watts_peak": 46.17, "energy_joules_est": 70.44, "sample_count": 17, "duration_seconds": 1.709}, "timestamp": "2026-01-12T09:43:37.596609"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 745.909, "latencies_ms": [745.909], "images_per_second": 1.341, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A man is standing next to a bike and a motorcycle.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13280.4, "ram_available_mb": 109225.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.14, 33.64, 33.64, 33.64, 33.64, 33.64, 47.51, 47.51], "power_watts_avg": 38.17, "power_watts_peak": 47.51, "energy_joules_est": 28.47, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-12T09:43:38.408332"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1955.043, "latencies_ms": [1955.043], "images_per_second": 0.511, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a man wearing a helmet and a black leather jacket, standing next to a black bicycle with a brown basket on the back. The bicycle is parked on a street with a yellow bicycle and a motorcycle parked nearby. The weather appears to be sunny, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13276.5, "ram_available_mb": 109229.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13289.1, "ram_available_mb": 109217.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.51, 47.51, 47.51, 51.25, 51.25, 51.25, 51.25, 51.25, 46.16, 46.16, 46.16, 46.16, 46.16, 43.22, 43.22, 43.22, 43.22, 43.22, 34.08, 34.08], "power_watts_avg": 45.69, "power_watts_peak": 51.25, "energy_joules_est": 89.36, "sample_count": 20, "duration_seconds": 1.956}, "timestamp": "2026-01-12T09:43:40.428943"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1092.677, "latencies_ms": [1092.677], "images_per_second": 0.915, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In the image, a man and a woman are standing on a sidewalk, with a traffic light and a street sign nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13281.2, "ram_available_mb": 109225.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13295.2, "ram_available_mb": 109211.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.08, 34.08, 32.79, 32.79, 32.79, 32.79, 32.79, 45.07, 45.07, 45.07, 45.07], "power_watts_avg": 37.49, "power_watts_peak": 45.07, "energy_joules_est": 41.01, "sample_count": 11, "duration_seconds": 1.094}, "timestamp": "2026-01-12T09:43:41.594685"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1627.823, "latencies_ms": [1627.823], "images_per_second": 0.614, "prompt_tokens": 1113, "response_tokens_est": 45, "n_tiles": 1, "output_text": " 1. black pole\n2. yellow sign\n3. black trash can\n4. traffic light\n5. street sign\n6. pedestrian crossing\n7. man in blue jeans\n8. man in black shirt", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13287.3, "ram_available_mb": 109219.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13296.1, "ram_available_mb": 109210.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.07, 45.62, 45.62, 45.62, 45.62, 45.62, 47.02, 47.02, 47.02, 47.02, 47.02, 47.83, 47.83, 47.83, 47.83, 47.83, 33.96], "power_watts_avg": 45.96, "power_watts_peak": 47.83, "energy_joules_est": 74.83, "sample_count": 17, "duration_seconds": 1.628}, "timestamp": "2026-01-12T09:43:43.308836"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1550.289, "latencies_ms": [1550.289], "images_per_second": 0.645, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The two individuals are standing on the sidewalk, which is located in the foreground of the image. The traffic light is positioned in the background, and the street sign is situated to the left of the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13296.0, "ram_available_mb": 109210.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13289.0, "ram_available_mb": 109217.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.96, 33.96, 33.96, 33.96, 40.57, 40.57, 40.57, 40.57, 40.57, 45.75, 45.75, 45.75, 45.75, 45.75, 39.96, 39.96], "power_watts_avg": 40.46, "power_watts_peak": 45.75, "energy_joules_est": 62.74, "sample_count": 16, "duration_seconds": 1.551}, "timestamp": "2026-01-12T09:43:44.919959"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1959.736, "latencies_ms": [1959.736], "images_per_second": 0.51, "prompt_tokens": 1111, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures a bustling city street corner with a pedestrian crossing, where two individuals are standing on the sidewalk, seemingly engaged in a conversation. The street is lined with buildings, and a red car is parked on the side of the road, adding a pop of color to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13289.0, "ram_available_mb": 109217.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.4, "ram_available_mb": 109171.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.96, 39.96, 39.96, 36.28, 36.28, 36.28, 36.28, 36.28, 46.29, 46.29, 46.29, 46.29, 46.29, 44.02, 44.02, 44.02, 44.02, 44.02, 34.11, 34.11], "power_watts_avg": 41.05, "power_watts_peak": 46.29, "energy_joules_est": 80.46, "sample_count": 20, "duration_seconds": 1.96}, "timestamp": "2026-01-12T09:43:46.937046"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1776.644, "latencies_ms": [1776.644], "images_per_second": 0.563, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image depicts a bustling city street with a mix of pedestrians and vehicles, under a clear blue sky. The buildings are made of concrete and glass, reflecting the sunlight. The street is lined with trees and street lamps, providing a green and welcoming atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.4, "ram_available_mb": 109171.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13376.5, "ram_available_mb": 109129.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 35.6, 35.6, 35.6, 35.6, 35.6, 46.43, 46.43, 46.43, 46.43, 46.43, 45.61, 45.61, 45.61, 45.61, 45.61, 34.08], "power_watts_avg": 41.14, "power_watts_peak": 46.43, "energy_joules_est": 73.1, "sample_count": 18, "duration_seconds": 1.777}, "timestamp": "2026-01-12T09:43:48.752353"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1215.003, "latencies_ms": [1215.003], "images_per_second": 0.823, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A bronze statue of two people sitting on a bench with a handbag in front of them is in a public place with people standing in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.5, "ram_available_mb": 109129.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.2, "ram_available_mb": 109113.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [34.08, 34.08, 34.08, 34.08, 43.98, 43.98, 43.98, 43.98, 43.98, 46.8, 46.8, 46.8, 46.8], "power_watts_avg": 41.8, "power_watts_peak": 46.8, "energy_joules_est": 50.8, "sample_count": 13, "duration_seconds": 1.215}, "timestamp": "2026-01-12T09:43:50.066650"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1904.332, "latencies_ms": [1904.332], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. statue: 2\n2. bench: 1\n3. bag: 1\n4. person: 1\n5. pole: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.3, "ram_available_mb": 109121.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.8, 34.69, 34.69, 34.69, 34.69, 34.69, 45.52, 45.52, 45.52, 45.52, 45.52, 48.7, 48.7, 48.7, 48.7, 48.7, 34.18, 34.18, 34.18], "power_watts_avg": 41.78, "power_watts_peak": 48.7, "energy_joules_est": 79.6, "sample_count": 19, "duration_seconds": 1.905}, "timestamp": "2026-01-12T09:43:51.982461"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1734.424, "latencies_ms": [1734.424], "images_per_second": 0.577, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The statue of two people is positioned on the left side of the image, with the bench and handbag placed in the foreground. The background features a group of people standing near a closed shop, with the statue's shadow cast on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.9, "ram_available_mb": 109145.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 31.43, 31.43, 31.43, 31.43, 31.43, 45.98, 45.98, 45.98, 45.98, 48.97, 48.97, 48.97, 48.97, 48.97, 34.0, 34.0], "power_watts_avg": 40.13, "power_watts_peak": 48.97, "energy_joules_est": 69.63, "sample_count": 18, "duration_seconds": 1.735}, "timestamp": "2026-01-12T09:43:53.849445"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1022.583, "latencies_ms": [1022.583], "images_per_second": 0.978, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A bronze statue of two people sitting on a bench, with a handbag on the ground next to them.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13360.9, "ram_available_mb": 109145.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13343.6, "ram_available_mb": 109162.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.0, 34.0, 34.0, 38.46, 38.46, 38.46, 38.46, 38.46, 45.78, 45.78, 45.78], "power_watts_avg": 39.24, "power_watts_peak": 45.78, "energy_joules_est": 40.14, "sample_count": 11, "duration_seconds": 1.023}, "timestamp": "2026-01-12T09:43:54.959248"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1097.826, "latencies_ms": [1097.826], "images_per_second": 0.911, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The statue is made of bronze and is located in a public square. The lighting is natural and the weather is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.6, "ram_available_mb": 109162.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13372.6, "ram_available_mb": 109133.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [45.78, 45.78, 41.7, 41.7, 41.7, 41.7, 41.7, 45.4, 45.4, 45.4, 45.4], "power_watts_avg": 43.79, "power_watts_peak": 45.78, "energy_joules_est": 48.08, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-12T09:43:56.069742"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1740.376, "latencies_ms": [1740.376], "images_per_second": 0.575, "prompt_tokens": 1100, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image shows a collection of road signs, including a blue sign with white text and symbols, a green sign with white text and symbols, a red and white circular sign with a truck symbol, and a blue and white sign with a parking symbol.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13299.9, "ram_available_mb": 109206.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.4, 45.29, 45.29, 45.29, 45.29, 45.29, 47.3, 47.3, 47.3, 47.3, 47.3, 48.58, 48.58, 48.58, 48.58, 48.58, 34.21, 34.21], "power_watts_avg": 45.54, "power_watts_peak": 48.58, "energy_joules_est": 79.27, "sample_count": 18, "duration_seconds": 1.741}, "timestamp": "2026-01-12T09:43:57.887344"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1542.933, "latencies_ms": [1542.933], "images_per_second": 0.648, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. signpost\n2. blue sign\n3. green sign\n4. white sign\n5. red and blue sign\n6. white arrow\n7. blue arrow\n8. white text", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13298.5, "ram_available_mb": 109207.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.4, "ram_available_mb": 109148.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.21, 34.21, 34.21, 37.67, 37.67, 37.67, 37.67, 37.67, 45.79, 45.79, 45.79, 45.79, 45.79, 42.43, 42.43, 42.43], "power_watts_avg": 40.45, "power_watts_peak": 45.79, "energy_joules_est": 62.43, "sample_count": 16, "duration_seconds": 1.543}, "timestamp": "2026-01-12T09:43:59.502890"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1902.089, "latencies_ms": [1902.089], "images_per_second": 0.526, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The blue sign is on the left, the green sign is in the middle, and the red and blue signs are on the right. The blue sign is in the foreground, while the green sign is in the middle ground, and the red and blue signs are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.4, "ram_available_mb": 109152.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13328.9, "ram_available_mb": 109177.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.43, 42.43, 32.82, 32.82, 32.82, 32.82, 32.82, 45.95, 45.95, 45.95, 45.95, 45.95, 47.5, 47.5, 47.5, 47.5, 47.5, 34.13, 34.13], "power_watts_avg": 41.29, "power_watts_peak": 47.5, "energy_joules_est": 78.55, "sample_count": 19, "duration_seconds": 1.902}, "timestamp": "2026-01-12T09:44:01.418881"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1643.003, "latencies_ms": [1643.003], "images_per_second": 0.609, "prompt_tokens": 1112, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a scene of a road signpost, standing tall against the backdrop of a cloudy sky. The signpost is adorned with four distinct signs, each with its own unique color and symbol, guiding travelers on their journey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.0, "ram_available_mb": 109185.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.8, "ram_available_mb": 109165.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [34.13, 34.13, 34.4, 34.4, 34.4, 34.4, 34.4, 46.38, 46.38, 46.38, 46.38, 46.38, 46.07, 46.07, 46.07, 46.07, 46.07], "power_watts_avg": 41.32, "power_watts_peak": 46.38, "energy_joules_est": 67.95, "sample_count": 17, "duration_seconds": 1.644}, "timestamp": "2026-01-12T09:44:03.187251"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2026.986, "latencies_ms": [2026.986], "images_per_second": 0.493, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a collection of road signs with various colors and symbols, including a blue sign with white text, a green sign with white text, and a red and blue sign with a white symbol. The signs are attached to a metal pole and are set against a backdrop of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.0, "ram_available_mb": 109173.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13333.5, "ram_available_mb": 109172.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.89, 33.89, 33.89, 33.89, 33.89, 46.21, 46.21, 46.21, 46.21, 46.21, 46.41, 46.41, 46.41, 46.41, 46.41, 34.16, 34.16, 34.16, 34.16, 34.16, 34.18], "power_watts_avg": 39.88, "power_watts_peak": 46.41, "energy_joules_est": 80.86, "sample_count": 21, "duration_seconds": 2.027}, "timestamp": "2026-01-12T09:44:05.305717"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1298.344, "latencies_ms": [1298.344], "images_per_second": 0.77, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " Two women, one in a red shirt and the other in a blue shirt, are standing on a train platform with their luggage, with a woman in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13333.5, "ram_available_mb": 109172.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.2, "ram_available_mb": 109166.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 34.18, 37.88, 37.88, 37.88, 37.88, 37.88, 44.48, 44.48, 44.48, 44.48, 44.48], "power_watts_avg": 39.57, "power_watts_peak": 44.48, "energy_joules_est": 51.41, "sample_count": 13, "duration_seconds": 1.299}, "timestamp": "2026-01-12T09:44:06.672548"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2009.752, "latencies_ms": [2009.752], "images_per_second": 0.498, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. woman: 2\n3. girl: 1\n4. backpack: 1\n5. handbag: 1\n6. suitcase tag: 1\n7. platform: 1\n8. train: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13329.6, "ram_available_mb": 109176.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.76, 41.76, 41.76, 41.76, 41.76, 47.37, 47.37, 47.37, 47.37, 47.37, 47.0, 47.0, 47.0, 47.0, 47.0, 34.11, 34.11, 34.11, 34.11, 34.11, 34.12], "power_watts_avg": 42.16, "power_watts_peak": 47.37, "energy_joules_est": 84.74, "sample_count": 21, "duration_seconds": 2.01}, "timestamp": "2026-01-12T09:44:08.785484"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1695.733, "latencies_ms": [1695.733], "images_per_second": 0.59, "prompt_tokens": 1118, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The woman in the red shirt is standing to the left of the woman in the blue shirt, who is standing to the right of her. The woman in the blue shirt is standing closer to the camera than the woman in the red shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.7, "ram_available_mb": 109184.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13320.5, "ram_available_mb": 109185.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.12, 34.12, 34.12, 34.12, 38.4, 38.4, 38.4, 38.4, 44.59, 44.59, 44.59, 44.59, 44.59, 40.24, 40.24, 40.24, 40.24], "power_watts_avg": 39.65, "power_watts_peak": 44.59, "energy_joules_est": 67.28, "sample_count": 17, "duration_seconds": 1.697}, "timestamp": "2026-01-12T09:44:10.553669"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 904.614, "latencies_ms": [904.614], "images_per_second": 1.105, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two women are standing on a train platform, one of them is holding a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.6, "ram_available_mb": 109189.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13322.8, "ram_available_mb": 109183.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [40.24, 32.39, 32.39, 32.39, 32.39, 32.39, 46.82, 46.82, 46.82, 46.82], "power_watts_avg": 38.95, "power_watts_peak": 46.82, "energy_joules_est": 35.25, "sample_count": 10, "duration_seconds": 0.905}, "timestamp": "2026-01-12T09:44:11.564918"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1537.176, "latencies_ms": [1537.176], "images_per_second": 0.651, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is taken during daytime with natural light illuminating the scene. The colors in the image are vibrant, with the red of the woman's shirt standing out against the blue of the girl's t-shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13314.9, "ram_available_mb": 109191.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13313.3, "ram_available_mb": 109193.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [46.82, 45.72, 45.72, 45.72, 45.72, 45.72, 45.56, 45.56, 45.56, 45.56, 45.56, 48.37, 48.37, 48.37, 48.37, 48.37], "power_watts_avg": 46.57, "power_watts_peak": 48.37, "energy_joules_est": 71.61, "sample_count": 16, "duration_seconds": 1.538}, "timestamp": "2026-01-12T09:44:13.181437"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 981.032, "latencies_ms": [981.032], "images_per_second": 1.019, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Three zebras with black and white stripes are walking on a dirt path in a forest with purple flowers.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13309.4, "ram_available_mb": 109196.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13315.2, "ram_available_mb": 109191.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.73, 33.73, 33.73, 33.73, 33.73, 45.69, 45.69, 45.69, 45.69, 45.69], "power_watts_avg": 39.71, "power_watts_peak": 45.69, "energy_joules_est": 38.98, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T09:44:14.195948"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 539.587, "latencies_ms": [539.587], "images_per_second": 1.853, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13307.3, "ram_available_mb": 109199.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13238.6, "ram_available_mb": 109267.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.76, 46.76, 46.76, 46.76, 46.76, 46.76], "power_watts_avg": 46.76, "power_watts_peak": 46.76, "energy_joules_est": 25.26, "sample_count": 6, "duration_seconds": 0.54}, "timestamp": "2026-01-12T09:44:14.805724"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1697.994, "latencies_ms": [1697.994], "images_per_second": 0.589, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the trees and bushes serving as a backdrop in the background. The zebras are facing the camera, with the tree with purple flowers located to the right of the zebras.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13238.6, "ram_available_mb": 109267.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13288.1, "ram_available_mb": 109218.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.76, 46.76, 46.76, 46.76, 54.58, 54.58, 54.58, 54.58, 54.58, 46.06, 46.06, 46.06, 46.06, 46.06, 38.21, 38.21, 38.21], "power_watts_avg": 47.35, "power_watts_peak": 54.58, "energy_joules_est": 80.41, "sample_count": 17, "duration_seconds": 1.698}, "timestamp": "2026-01-12T09:44:16.520894"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 957.844, "latencies_ms": [957.844], "images_per_second": 1.044, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Three zebras are walking in a line on a dirt path, surrounded by trees with purple flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13288.1, "ram_available_mb": 109218.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13278.3, "ram_available_mb": 109228.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.21, 38.21, 33.62, 33.62, 33.62, 33.62, 33.62, 46.91, 46.91, 46.91], "power_watts_avg": 38.52, "power_watts_peak": 46.91, "energy_joules_est": 36.91, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-12T09:44:17.532322"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1389.815, "latencies_ms": [1389.815], "images_per_second": 0.72, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features three zebras with black and white stripes walking on a dirt path. The zebras are surrounded by trees with purple flowers, and the lighting is bright and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13278.3, "ram_available_mb": 109228.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13272.6, "ram_available_mb": 109233.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.91, 46.91, 45.8, 45.8, 45.8, 45.8, 45.8, 46.53, 46.53, 46.53, 46.53, 46.53, 48.69, 48.69], "power_watts_avg": 46.63, "power_watts_peak": 48.69, "energy_joules_est": 64.83, "sample_count": 14, "duration_seconds": 1.39}, "timestamp": "2026-01-12T09:44:18.943159"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1045.176, "latencies_ms": [1045.176], "images_per_second": 0.957, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A camera is mounted on a tripod in a room with a vending machine and a laptop on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13272.6, "ram_available_mb": 109233.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13267.1, "ram_available_mb": 109239.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.69, 48.69, 36.49, 36.49, 36.49, 36.49, 36.49, 46.92, 46.92, 46.92, 46.92], "power_watts_avg": 42.5, "power_watts_peak": 48.69, "energy_joules_est": 44.46, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-12T09:44:20.056666"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 560.965, "latencies_ms": [560.965], "images_per_second": 1.783, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " tripod: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13263.2, "ram_available_mb": 109243.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13298.9, "ram_available_mb": 109207.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [46.92, 42.52, 42.52, 42.52, 42.52, 42.52], "power_watts_avg": 43.26, "power_watts_peak": 46.92, "energy_joules_est": 24.28, "sample_count": 6, "duration_seconds": 0.561}, "timestamp": "2026-01-12T09:44:20.665122"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1665.799, "latencies_ms": [1665.799], "images_per_second": 0.6, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The camera is positioned to the right of the tripod, which is in the foreground of the image. The laptop is placed on the tripod, and the vending machine is located in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13298.9, "ram_available_mb": 109207.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13283.8, "ram_available_mb": 109222.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.68, 45.68, 45.68, 45.68, 45.68, 61.0, 61.0, 61.0, 61.0, 61.0, 47.26, 47.26, 47.26, 47.26, 47.26, 34.17, 34.17], "power_watts_avg": 49.3, "power_watts_peak": 61.0, "energy_joules_est": 82.14, "sample_count": 17, "duration_seconds": 1.666}, "timestamp": "2026-01-12T09:44:22.381038"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1163.667, "latencies_ms": [1163.667], "images_per_second": 0.859, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a room with a vending machine and tables, a camera on a tripod is set up, and a laptop is placed nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13275.9, "ram_available_mb": 109230.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13299.9, "ram_available_mb": 109206.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.17, 34.17, 34.17, 39.31, 39.31, 39.31, 39.31, 39.31, 46.47, 46.47, 46.47, 46.47], "power_watts_avg": 40.41, "power_watts_peak": 46.47, "energy_joules_est": 47.05, "sample_count": 12, "duration_seconds": 1.164}, "timestamp": "2026-01-12T09:44:23.592813"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1336.039, "latencies_ms": [1336.039], "images_per_second": 0.748, "prompt_tokens": 1110, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a room with a white wall and a blue and white vending machine in the background. The lighting is natural and the colors are muted.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13296.0, "ram_available_mb": 109210.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13295.3, "ram_available_mb": 109211.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.47, 39.66, 39.66, 39.66, 39.66, 39.66, 46.71, 46.71, 46.71, 46.71, 46.71, 48.56, 48.56, 48.56], "power_watts_avg": 44.57, "power_watts_peak": 48.56, "energy_joules_est": 59.56, "sample_count": 14, "duration_seconds": 1.336}, "timestamp": "2026-01-12T09:44:25.006528"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1253.845, "latencies_ms": [1253.845], "images_per_second": 0.798, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A sheep with a white wool coat is standing in a pen with a pile of wool on the ground, and there is a metal fence in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13295.3, "ram_available_mb": 109211.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13285.6, "ram_available_mb": 109220.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.56, 48.56, 32.72, 32.72, 32.72, 32.72, 32.72, 45.53, 45.53, 45.53, 45.53, 45.53, 47.25], "power_watts_avg": 41.2, "power_watts_peak": 48.56, "energy_joules_est": 51.68, "sample_count": 13, "duration_seconds": 1.254}, "timestamp": "2026-01-12T09:44:26.321350"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2042.632, "latencies_ms": [2042.632], "images_per_second": 0.49, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. fence: 1\n3. metal: 1\n4. ground: 1\n5. sheep's wool: 1\n6. ball: 1\n7. metal fence: 1\n8. sheep's wool: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13285.6, "ram_available_mb": 109220.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13293.5, "ram_available_mb": 109212.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.25, 47.25, 47.25, 47.25, 41.78, 41.78, 41.78, 41.78, 41.78, 46.05, 46.05, 46.05, 46.05, 46.05, 38.51, 38.51, 38.51, 38.51, 38.51, 34.24, 34.24], "power_watts_avg": 42.34, "power_watts_peak": 47.25, "energy_joules_est": 86.5, "sample_count": 21, "duration_seconds": 2.043}, "timestamp": "2026-01-12T09:44:28.438142"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1509.324, "latencies_ms": [1509.324], "images_per_second": 0.663, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The sheep is located in the foreground of the image, with the metal fence in the background. The sheep is eating the wool, which is in the foreground, while the metal fence is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13293.4, "ram_available_mb": 109212.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13289.4, "ram_available_mb": 109216.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.24, 34.24, 33.08, 33.08, 33.08, 33.08, 33.08, 45.08, 45.08, 45.08, 45.08, 45.08, 47.02, 47.02, 47.02, 47.02], "power_watts_avg": 40.46, "power_watts_peak": 47.02, "energy_joules_est": 61.11, "sample_count": 16, "duration_seconds": 1.51}, "timestamp": "2026-01-12T09:44:30.102628"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 825.003, "latencies_ms": [825.003], "images_per_second": 1.212, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A sheep is standing in a pen with a pile of wool around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13289.4, "ram_available_mb": 109216.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.4, "ram_available_mb": 109158.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [47.02, 31.63, 31.63, 31.63, 31.63, 31.63, 45.55, 45.55, 45.55], "power_watts_avg": 37.98, "power_watts_peak": 47.02, "energy_joules_est": 31.34, "sample_count": 9, "duration_seconds": 0.825}, "timestamp": "2026-01-12T09:44:31.012588"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 966.725, "latencies_ms": [966.725], "images_per_second": 1.034, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sheep is white and the wool is gray. The lighting is natural and the weather is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.5, "ram_available_mb": 109166.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 23.0}, "power_stats": {"power_watts_samples": [45.55, 45.55, 46.9, 46.9, 46.9, 46.9, 46.9, 45.89, 45.89, 45.89], "power_watts_avg": 46.33, "power_watts_peak": 46.9, "energy_joules_est": 44.8, "sample_count": 10, "duration_seconds": 0.967}, "timestamp": "2026-01-12T09:44:32.022884"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2369.259, "latencies_ms": [2369.259], "images_per_second": 0.422, "prompt_tokens": 1099, "response_tokens_est": 73, "n_tiles": 1, "output_text": " In the image, a tennis match is taking place on a blue court, with a player in a pink outfit serving the ball, while a player in a red outfit is preparing to return the serve. The court is surrounded by a crowd of spectators, and there are advertisements for brands such as Lexus, Mirvac, and Sony Ericsson visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.9, "ram_available_mb": 109162.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13325.8, "ram_available_mb": 109180.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.89, 45.89, 46.71, 46.71, 46.71, 46.71, 46.71, 46.43, 46.43, 46.43, 46.43, 46.43, 47.84, 47.84, 47.84, 47.84, 47.84, 34.07, 34.07, 34.07, 34.07, 34.07, 34.05, 34.05], "power_watts_avg": 43.13, "power_watts_peak": 47.84, "energy_joules_est": 102.2, "sample_count": 24, "duration_seconds": 2.37}, "timestamp": "2026-01-12T09:44:34.443845"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1492.519, "latencies_ms": [1492.519], "images_per_second": 0.67, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. tennis court\n2. net\n3. ball\n4. racket\n5. player\n6. player's outfit\n7. player's shoes\n8. player's hair", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.9, "ram_available_mb": 109188.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.7, "ram_available_mb": 109183.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.05, 34.05, 33.04, 33.04, 33.04, 33.04, 33.04, 45.48, 45.48, 45.48, 45.48, 45.48, 47.13, 47.13, 47.13], "power_watts_avg": 40.14, "power_watts_peak": 47.13, "energy_joules_est": 59.96, "sample_count": 15, "duration_seconds": 1.494}, "timestamp": "2026-01-12T09:44:36.010306"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1811.77, "latencies_ms": [1811.77], "images_per_second": 0.552, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the net and the ball in the middle ground, and the crowd in the background. The player is near the net, while the ball is in the air, and the crowd is far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.7, "ram_available_mb": 109183.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.13, 47.13, 34.1, 34.1, 34.1, 34.1, 34.1, 46.82, 46.82, 46.82, 46.82, 46.82, 47.13, 47.13, 47.13, 47.13, 47.13, 34.15], "power_watts_avg": 42.7, "power_watts_peak": 47.13, "energy_joules_est": 77.39, "sample_count": 18, "duration_seconds": 1.812}, "timestamp": "2026-01-12T09:44:37.829874"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 981.809, "latencies_ms": [981.809], "images_per_second": 1.019, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A tennis match is taking place in a large stadium with a blue court, surrounded by spectators and advertisements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.0, "ram_available_mb": 109152.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.8, "ram_available_mb": 109147.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 34.15, 42.27, 42.27, 42.27, 42.27, 42.27, 47.18], "power_watts_avg": 39.51, "power_watts_peak": 47.18, "energy_joules_est": 38.81, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T09:44:38.842923"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 964.736, "latencies_ms": [964.736], "images_per_second": 1.037, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The court is blue, the players are wearing red and pink, and the crowd is watching intently.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.0, "ram_available_mb": 109155.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.6, "ram_available_mb": 109154.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.18, 47.18, 47.18, 47.18, 46.42, 46.42, 46.42, 46.42, 46.81, 46.81], "power_watts_avg": 46.8, "power_watts_peak": 47.18, "energy_joules_est": 45.17, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-12T09:44:39.854475"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1117.154, "latencies_ms": [1117.154], "images_per_second": 0.895, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase, and the terminal has a glass door and a staircase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.2, "ram_available_mb": 109155.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.81, 46.81, 46.81, 44.9, 44.9, 44.9, 44.9, 44.9, 46.33, 46.33, 46.33, 46.33], "power_watts_avg": 45.85, "power_watts_peak": 46.81, "energy_joules_est": 51.24, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T09:44:41.070868"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1956.173, "latencies_ms": [1956.173], "images_per_second": 0.511, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. suitcase: 1\n3. glass door: 1\n4. pillar: 1\n5. sign: 1\n6. wall: 1\n7. floor: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.9, "ram_available_mb": 109097.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.33, 38.56, 38.56, 38.56, 38.56, 38.56, 45.41, 45.41, 45.41, 45.41, 45.41, 49.04, 49.04, 49.04, 49.04, 49.04, 34.2, 34.2, 34.2, 34.2], "power_watts_avg": 42.41, "power_watts_peak": 49.04, "energy_joules_est": 82.98, "sample_count": 20, "duration_seconds": 1.957}, "timestamp": "2026-01-12T09:44:43.089470"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1801.529, "latencies_ms": [1801.529], "images_per_second": 0.555, "prompt_tokens": 1118, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main object, a person, is positioned in the foreground, walking towards the camera. The glass door is located in the middle ground, slightly to the right of the person. The escalator is situated in the background, to the left of the person.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13408.9, "ram_available_mb": 109097.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13394.2, "ram_available_mb": 109112.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.2, 31.94, 31.94, 31.94, 31.94, 31.94, 45.45, 45.45, 45.45, 45.45, 45.45, 47.73, 47.73, 47.73, 47.73, 34.23, 34.23, 34.23], "power_watts_avg": 39.71, "power_watts_peak": 47.73, "energy_joules_est": 71.57, "sample_count": 18, "duration_seconds": 1.802}, "timestamp": "2026-01-12T09:44:44.952913"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 815.523, "latencies_ms": [815.523], "images_per_second": 1.226, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.2, "ram_available_mb": 109116.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13290.9, "ram_available_mb": 109215.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.23, 34.23, 36.56, 36.56, 36.56, 36.56, 36.56, 47.23, 47.23], "power_watts_avg": 38.41, "power_watts_peak": 47.23, "energy_joules_est": 31.35, "sample_count": 9, "duration_seconds": 0.816}, "timestamp": "2026-01-12T09:44:45.863723"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1269.912, "latencies_ms": [1269.912], "images_per_second": 0.787, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken in a well-lit indoor space with a grey floor and white walls. The lighting is bright and natural, coming from the ceiling lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13290.9, "ram_available_mb": 109215.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13377.7, "ram_available_mb": 109128.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 49.73, 49.73, 49.73, 49.73, 49.73, 45.48, 45.48, 45.48, 45.48, 45.48], "power_watts_avg": 47.52, "power_watts_peak": 49.73, "energy_joules_est": 60.36, "sample_count": 13, "duration_seconds": 1.27}, "timestamp": "2026-01-12T09:44:47.175698"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1099.433, "latencies_ms": [1099.433], "images_per_second": 0.91, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A dining table is set with two large pizzas, a few glasses of water, and a few forks and knives.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.7, "ram_available_mb": 109128.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13280.9, "ram_available_mb": 109225.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.41, 41.41, 41.41, 41.41, 41.41, 46.76, 46.76, 46.76, 46.76, 46.76, 46.78], "power_watts_avg": 44.33, "power_watts_peak": 46.78, "energy_joules_est": 48.78, "sample_count": 11, "duration_seconds": 1.1}, "timestamp": "2026-01-12T09:44:48.289448"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1331.47, "latencies_ms": [1331.47], "images_per_second": 0.751, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " pizza: 2, glasses: 2, fork: 1, knife: 1, spoon: 1, television: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13280.9, "ram_available_mb": 109225.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.5, "ram_available_mb": 109178.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.78, 46.78, 46.78, 46.78, 43.64, 43.64, 43.64, 43.64, 43.64, 47.11, 47.11, 47.11, 47.11, 47.11], "power_watts_avg": 45.77, "power_watts_peak": 47.11, "energy_joules_est": 60.98, "sample_count": 14, "duration_seconds": 1.332}, "timestamp": "2026-01-12T09:44:49.703073"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2273.529, "latencies_ms": [2273.529], "images_per_second": 0.44, "prompt_tokens": 1118, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The large pizza boxes are placed on the table, with one box in the foreground and the other in the background. The glasses of water are positioned near the pizza boxes, with one glass closer to the foreground and the other further back. The fork and knife are placed on the table, with the fork closer to the foreground and the knife further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.7, "ram_available_mb": 109186.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13313.0, "ram_available_mb": 109193.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.66, 37.66, 37.66, 37.66, 37.66, 46.1, 46.1, 46.1, 46.1, 46.1, 46.49, 46.49, 46.49, 46.49, 46.49, 34.2, 34.2, 34.2, 34.2, 34.2, 34.17, 34.17, 34.17], "power_watts_avg": 40.21, "power_watts_peak": 46.49, "energy_joules_est": 91.43, "sample_count": 23, "duration_seconds": 2.274}, "timestamp": "2026-01-12T09:44:52.026020"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 882.704, "latencies_ms": [882.704], "images_per_second": 1.133, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of people are gathered around a table with pizza boxes and glasses of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.0, "ram_available_mb": 109197.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.17, 31.02, 31.02, 31.02, 31.02, 31.02, 45.37, 45.37, 45.37], "power_watts_avg": 36.15, "power_watts_peak": 45.37, "energy_joules_est": 31.94, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T09:44:52.989682"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1679.076, "latencies_ms": [1679.076], "images_per_second": 0.596, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm and cozy atmosphere. The colors in the image are vibrant and inviting, with the red of the pizza boxes standing out against the blue of the television screen in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.0, "ram_available_mb": 109181.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.37, 45.37, 49.46, 49.46, 49.46, 49.46, 49.46, 47.01, 47.01, 47.01, 47.01, 47.01, 47.02, 47.02, 47.02, 47.02, 47.02], "power_watts_avg": 47.54, "power_watts_peak": 49.46, "energy_joules_est": 79.85, "sample_count": 17, "duration_seconds": 1.68}, "timestamp": "2026-01-12T09:44:54.705393"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1717.697, "latencies_ms": [1717.697], "images_per_second": 0.582, "prompt_tokens": 1100, "response_tokens_est": 49, "n_tiles": 1, "output_text": " A young boy wearing a helmet and a gray shirt is standing at home plate, holding a baseball bat, while a catcher in a red shirt and a catcher's mitt is crouched behind him, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.0, "ram_available_mb": 109181.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13310.0, "ram_available_mb": 109196.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.07, 34.07, 34.07, 34.07, 34.07, 46.52, 46.52, 46.52, 46.52, 46.52, 46.87, 46.87, 46.87, 46.87, 46.87, 34.18, 34.18, 34.18], "power_watts_avg": 41.1, "power_watts_peak": 46.87, "energy_joules_est": 70.6, "sample_count": 18, "duration_seconds": 1.718}, "timestamp": "2026-01-12T09:44:56.525891"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2261.745, "latencies_ms": [2261.745], "images_per_second": 0.442, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball glove: 1\n3. baseball: 1\n4. baseball player: 1\n5. catcher's mitt: 1\n6. catcher: 1\n7. umpire's shirt: 1\n8. spectator: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.0, "ram_available_mb": 109196.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13310.0, "ram_available_mb": 109196.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 32.28, 32.28, 32.28, 32.28, 32.28, 45.48, 45.48, 45.48, 45.48, 45.48, 47.62, 47.62, 47.62, 47.62, 47.62, 34.15, 34.15, 34.15, 34.15, 34.15, 34.1], "power_watts_avg": 39.13, "power_watts_peak": 47.62, "energy_joules_est": 88.53, "sample_count": 23, "duration_seconds": 2.262}, "timestamp": "2026-01-12T09:44:58.846154"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1380.924, "latencies_ms": [1380.924], "images_per_second": 0.724, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.1, "ram_available_mb": 109204.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13310.1, "ram_available_mb": 109196.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.1, 34.1, 34.1, 37.37, 37.37, 37.37, 37.37, 37.37, 45.42, 45.42, 45.42, 45.42, 45.42, 42.07], "power_watts_avg": 39.88, "power_watts_peak": 45.42, "energy_joules_est": 55.1, "sample_count": 14, "duration_seconds": 1.382}, "timestamp": "2026-01-12T09:45:00.311766"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 851.559, "latencies_ms": [851.559], "images_per_second": 1.174, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young boy is playing baseball in a park with a group of people watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.2, "ram_available_mb": 109204.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13321.6, "ram_available_mb": 109184.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.07, 42.07, 42.07, 42.07, 42.83, 42.83, 42.83, 42.83, 42.83], "power_watts_avg": 42.49, "power_watts_peak": 42.83, "energy_joules_est": 36.2, "sample_count": 9, "duration_seconds": 0.852}, "timestamp": "2026-01-12T09:45:01.223271"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1407.185, "latencies_ms": [1407.185], "images_per_second": 0.711, "prompt_tokens": 1110, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken during a sunny day with clear blue skies. The colors in the image are vibrant, with the green of the grass and trees contrasting against the blue of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.6, "ram_available_mb": 109188.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13315.1, "ram_available_mb": 109191.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.0, 47.0, 47.0, 47.0, 47.0, 50.24, 50.24, 50.24, 50.24, 50.24, 46.28, 46.28, 46.28, 46.28], "power_watts_avg": 47.95, "power_watts_peak": 50.24, "energy_joules_est": 67.5, "sample_count": 14, "duration_seconds": 1.408}, "timestamp": "2026-01-12T09:45:02.639488"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 778.731, "latencies_ms": [778.731], "images_per_second": 1.284, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana is on top of a black phone on a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13307.2, "ram_available_mb": 109199.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13228.1, "ram_available_mb": 109278.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [46.28, 35.19, 35.19, 35.19, 35.19, 35.19, 47.38, 47.38], "power_watts_avg": 39.62, "power_watts_peak": 47.38, "energy_joules_est": 30.87, "sample_count": 8, "duration_seconds": 0.779}, "timestamp": "2026-01-12T09:45:03.451540"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 531.566, "latencies_ms": [531.566], "images_per_second": 1.881, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13228.1, "ram_available_mb": 109278.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13296.1, "ram_available_mb": 109210.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [47.38, 47.38, 49.58, 49.58, 49.58, 49.58], "power_watts_avg": 48.85, "power_watts_peak": 49.58, "energy_joules_est": 25.99, "sample_count": 6, "duration_seconds": 0.532}, "timestamp": "2026-01-12T09:45:04.060206"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1433.98, "latencies_ms": [1433.98], "images_per_second": 0.697, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is located in the foreground, to the right of the phone, and the phone is on the desk. The banana is near the phone, and the desk is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.1, "ram_available_mb": 109214.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13298.0, "ram_available_mb": 109208.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [49.58, 44.03, 44.03, 44.03, 44.03, 44.03, 56.65, 56.65, 56.65, 56.65, 56.65, 49.1, 49.1, 49.1, 49.1], "power_watts_avg": 49.96, "power_watts_peak": 56.65, "energy_joules_est": 71.65, "sample_count": 15, "duration_seconds": 1.434}, "timestamp": "2026-01-12T09:45:05.575539"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 848.995, "latencies_ms": [848.995], "images_per_second": 1.178, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A banana is on top of a phone and a computer is on a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13291.9, "ram_available_mb": 109214.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13348.1, "ram_available_mb": 109158.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.1, 31.42, 31.42, 31.42, 31.42, 31.42, 46.04, 46.04, 46.04], "power_watts_avg": 38.26, "power_watts_peak": 49.1, "energy_joules_est": 32.49, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-12T09:45:06.484447"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1147.806, "latencies_ms": [1147.806], "images_per_second": 0.871, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image has a white desk with a black phone and a yellow banana on it. The lighting is natural and the banana is ripe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.1, "ram_available_mb": 109160.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13355.1, "ram_available_mb": 109151.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.04, 46.04, 49.5, 49.5, 49.5, 49.5, 49.5, 46.29, 46.29, 46.29, 46.29, 46.29], "power_watts_avg": 47.59, "power_watts_peak": 49.5, "energy_joules_est": 54.66, "sample_count": 12, "duration_seconds": 1.149}, "timestamp": "2026-01-12T09:45:07.699161"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2206.217, "latencies_ms": [2206.217], "images_per_second": 0.453, "prompt_tokens": 1099, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures a bustling scene of a crowd of people gathered in a public space, with individuals of various ages and attires, including a woman in a green jacket and a man in a red shirt, among others, all engaged in different activities, with a prominent presence of a woman with red hair and a man with a beard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.1, "ram_available_mb": 109155.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.33, 46.33, 46.33, 46.33, 46.33, 46.11, 46.11, 46.11, 46.11, 46.11, 46.39, 46.39, 46.39, 46.39, 46.39, 34.84, 34.84, 34.84, 34.84, 34.84, 34.24, 34.24], "power_watts_avg": 42.58, "power_watts_peak": 46.39, "energy_joules_est": 93.95, "sample_count": 22, "duration_seconds": 2.206}, "timestamp": "2026-01-12T09:45:09.921421"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2140.606, "latencies_ms": [2140.606], "images_per_second": 0.467, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. People: 10\n2. Green bag: 1\n3. Red bag: 1\n4. Blue scarf: 1\n5. Red shirt: 1\n6. Green jacket: 1\n7. Black jacket: 1\n8. Gray jacket: 1", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.8, "ram_available_mb": 109178.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [34.24, 34.24, 35.19, 35.19, 35.19, 35.19, 35.19, 46.41, 46.41, 46.41, 46.41, 46.41, 46.03, 46.03, 46.03, 46.03, 46.03, 34.2, 34.2, 34.2, 34.2, 34.2], "power_watts_avg": 39.89, "power_watts_peak": 46.41, "energy_joules_est": 85.43, "sample_count": 22, "duration_seconds": 2.142}, "timestamp": "2026-01-12T09:45:12.190022"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2012.192, "latencies_ms": [2012.192], "images_per_second": 0.497, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The main objects are the crowd of people, the bus stop sign, and the trees in the background. The crowd of people is in the foreground, with the bus stop sign and trees in the background. The crowd of people is near the bus stop sign, and the trees are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.8, "ram_available_mb": 109178.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.2, "ram_available_mb": 109145.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.7, 33.7, 33.7, 33.7, 33.7, 46.25, 46.25, 46.25, 46.25, 46.25, 46.8, 46.8, 46.8, 46.8, 46.8, 34.28, 34.28, 34.28, 34.28, 34.28, 34.19], "power_watts_avg": 39.97, "power_watts_peak": 46.8, "energy_joules_est": 80.44, "sample_count": 21, "duration_seconds": 2.013}, "timestamp": "2026-01-12T09:45:14.302413"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1199.793, "latencies_ms": [1199.793], "images_per_second": 0.833, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A large crowd of people are gathered in a public space, possibly a park or plaza, and they are all looking in the same direction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.3, "ram_available_mb": 109153.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.5, "ram_available_mb": 109132.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.19, 34.19, 34.19, 34.19, 38.56, 38.56, 38.56, 38.56, 44.39, 44.39, 44.39, 44.39], "power_watts_avg": 39.05, "power_watts_peak": 44.39, "energy_joules_est": 46.88, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-12T09:45:15.565676"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 936.79, "latencies_ms": [936.79], "images_per_second": 1.067, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the colors are vibrant and varied.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.5, "ram_available_mb": 109134.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13293.8, "ram_available_mb": 109212.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.39, 39.15, 39.15, 39.15, 39.15, 39.15, 47.3, 47.3, 47.3, 47.3], "power_watts_avg": 42.93, "power_watts_peak": 47.3, "energy_joules_est": 40.23, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-12T09:45:16.576490"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1029.672, "latencies_ms": [1029.672], "images_per_second": 0.971, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a red shirt is holding a baby in his arms while a horse nuzzles the baby's hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13293.8, "ram_available_mb": 109212.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13331.3, "ram_available_mb": 109175.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.3, 45.73, 45.73, 45.73, 45.73, 45.73, 45.98, 45.98, 45.98, 45.98, 45.98], "power_watts_avg": 45.99, "power_watts_peak": 47.3, "energy_joules_est": 47.36, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-12T09:45:17.692425"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2173.07, "latencies_ms": [2173.07], "images_per_second": 0.46, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. horse: 1\n2. man: 1\n3. baby: 1\n4. man's shirt: 1\n5. man's pants: 1\n6. man's shoes: 1\n7. man's hair: 1\n8. man's face: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.4, "ram_available_mb": 109182.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13321.4, "ram_available_mb": 109184.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.34, 48.34, 48.34, 48.34, 48.34, 45.93, 45.93, 45.93, 45.93, 45.93, 46.72, 46.72, 46.72, 46.72, 46.72, 34.09, 34.09, 34.09, 34.09, 34.09, 34.1, 34.1], "power_watts_avg": 42.89, "power_watts_peak": 48.34, "energy_joules_est": 93.22, "sample_count": 22, "duration_seconds": 2.173}, "timestamp": "2026-01-12T09:45:19.912545"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1619.357, "latencies_ms": [1619.357], "images_per_second": 0.618, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The man is standing to the left of the horse, and the baby is in the man's arms, which are positioned in the foreground. The horse is in the background, and the man is in front of the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.4, "ram_available_mb": 109184.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13403.2, "ram_available_mb": 109103.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.1, 34.1, 35.06, 35.06, 35.06, 35.06, 35.06, 45.57, 45.57, 45.57, 45.57, 45.57, 44.79, 44.79, 44.79, 44.79, 44.79], "power_watts_avg": 40.9, "power_watts_peak": 45.57, "energy_joules_est": 66.26, "sample_count": 17, "duration_seconds": 1.62}, "timestamp": "2026-01-12T09:45:21.674715"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1034.15, "latencies_ms": [1034.15], "images_per_second": 0.967, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man in a red shirt is holding a baby in his arms while a horse nuzzles the baby's hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.2, "ram_available_mb": 109103.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.6, "ram_available_mb": 109112.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [33.0, 33.0, 33.0, 33.0, 33.0, 45.61, 45.61, 45.61, 45.61, 45.61, 47.01], "power_watts_avg": 40.01, "power_watts_peak": 47.01, "energy_joules_est": 41.39, "sample_count": 11, "duration_seconds": 1.035}, "timestamp": "2026-01-12T09:45:22.785007"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1860.126, "latencies_ms": [1860.126], "images_per_second": 0.538, "prompt_tokens": 1110, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a man wearing a red shirt and a baby in his arms. The man is holding the baby close to a brown horse, which is standing in front of a brick wall. The lighting in the image is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.4, "ram_available_mb": 109142.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.01, 47.01, 47.01, 47.01, 43.12, 43.12, 43.12, 43.12, 43.12, 45.99, 45.99, 45.99, 45.99, 45.99, 37.59, 37.59, 37.59, 37.59, 37.59], "power_watts_avg": 43.24, "power_watts_peak": 47.01, "energy_joules_est": 80.45, "sample_count": 19, "duration_seconds": 1.861}, "timestamp": "2026-01-12T09:45:24.699259"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 847.116, "latencies_ms": [847.116], "images_per_second": 1.18, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A white plate with a banana and a small amount of peanut butter on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13345.6, "ram_available_mb": 109160.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.07, 34.07, 34.07, 34.07, 34.07, 43.98, 43.98, 43.98, 43.98], "power_watts_avg": 38.48, "power_watts_peak": 43.98, "energy_joules_est": 32.61, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-12T09:45:25.661999"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 822.005, "latencies_ms": [822.005], "images_per_second": 1.217, "prompt_tokens": 1114, "response_tokens_est": 15, "n_tiles": 1, "output_text": " banana: 1, plate: 1, peanut butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.6, "ram_available_mb": 109160.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.59, 44.59, 44.59, 44.59, 44.59, 47.87, 47.87, 47.87, 47.87], "power_watts_avg": 46.05, "power_watts_peak": 47.87, "energy_joules_est": 37.86, "sample_count": 9, "duration_seconds": 0.822}, "timestamp": "2026-01-12T09:45:26.571218"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1358.049, "latencies_ms": [1358.049], "images_per_second": 0.736, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The banana is on the left side of the plate, and the peanut butter is in the center. The plate is in the foreground, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.87, 44.27, 44.27, 44.27, 44.27, 44.27, 46.01, 46.01, 46.01, 46.01, 46.01, 49.02, 49.02, 49.02], "power_watts_avg": 46.17, "power_watts_peak": 49.02, "energy_joules_est": 62.72, "sample_count": 14, "duration_seconds": 1.359}, "timestamp": "2026-01-12T09:45:27.986354"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 854.3, "latencies_ms": [854.3], "images_per_second": 1.171, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A banana and a bowl of peanut butter are on a plate on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.1, "ram_available_mb": 109168.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.1, "ram_available_mb": 109165.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [49.02, 49.02, 34.62, 34.62, 34.62, 34.62, 34.62, 46.26, 46.26], "power_watts_avg": 40.41, "power_watts_peak": 49.02, "energy_joules_est": 34.54, "sample_count": 9, "duration_seconds": 0.855}, "timestamp": "2026-01-12T09:45:28.898540"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1064.97, "latencies_ms": [1064.97], "images_per_second": 0.939, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image shows a white plate with a banana and peanut butter on it. The plate is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.3, "ram_available_mb": 109173.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.6, "ram_available_mb": 109166.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 46.26, 50.94, 50.94, 50.94, 50.94, 50.94, 46.56, 46.56, 46.56], "power_watts_avg": 48.47, "power_watts_peak": 50.94, "energy_joules_est": 51.65, "sample_count": 11, "duration_seconds": 1.066}, "timestamp": "2026-01-12T09:45:30.012301"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1013.63, "latencies_ms": [1013.63], "images_per_second": 0.987, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a green shirt and glasses is working on a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.8, "ram_available_mb": 109174.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13332.2, "ram_available_mb": 109174.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 22.0}, "power_stats": {"power_watts_samples": [46.56, 46.56, 41.34, 41.34, 41.34, 41.34, 41.34, 46.55, 46.55, 46.55, 46.55], "power_watts_avg": 44.18, "power_watts_peak": 46.56, "energy_joules_est": 44.81, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:45:31.127430"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1910.884, "latencies_ms": [1910.884], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. motorcycle: 1\n3. bicycle: 1\n4. wheel: 1\n5. tire: 1\n6. tool: 1\n7. chain: 1\n8. lock: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13328.3, "ram_available_mb": 109178.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13325.3, "ram_available_mb": 109181.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.55, 45.9, 45.9, 45.9, 45.9, 45.9, 45.58, 45.58, 45.58, 45.58, 45.58, 47.93, 47.93, 47.93, 47.93, 47.93, 34.2, 34.2, 34.2], "power_watts_avg": 44.53, "power_watts_peak": 47.93, "energy_joules_est": 85.11, "sample_count": 19, "duration_seconds": 1.911}, "timestamp": "2026-01-12T09:45:33.046876"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1441.272, "latencies_ms": [1441.272], "images_per_second": 0.694, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is kneeling on the ground, which is in the foreground of the image. The motorcycle is parked on the left side of the image, while the bicycle is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.4, "ram_available_mb": 109188.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13236.2, "ram_available_mb": 109270.1, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.2, 34.2, 32.76, 32.76, 32.76, 32.76, 32.76, 47.41, 47.41, 47.41, 47.41, 47.41, 48.84, 48.84, 48.84], "power_watts_avg": 41.05, "power_watts_peak": 48.84, "energy_joules_est": 59.18, "sample_count": 15, "duration_seconds": 1.442}, "timestamp": "2026-01-12T09:45:34.562189"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 829.772, "latencies_ms": [829.772], "images_per_second": 1.205, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man is fixing a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13236.2, "ram_available_mb": 109270.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13300.5, "ram_available_mb": 109205.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.84, 31.36, 31.36, 31.36, 31.36, 31.36, 46.06, 46.06, 46.06], "power_watts_avg": 38.2, "power_watts_peak": 48.84, "energy_joules_est": 31.72, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-12T09:45:35.473386"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1439.2, "latencies_ms": [1439.2], "images_per_second": 0.695, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a man in a green shirt and blue pants working on a bicycle wheel, with a motorcycle parked nearby. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13296.6, "ram_available_mb": 109209.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13281.8, "ram_available_mb": 109224.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.06, 46.06, 49.56, 49.56, 49.56, 49.56, 49.56, 46.1, 46.1, 46.1, 46.1, 46.1, 45.65, 45.65, 45.65], "power_watts_avg": 47.16, "power_watts_peak": 49.56, "energy_joules_est": 67.88, "sample_count": 15, "duration_seconds": 1.44}, "timestamp": "2026-01-12T09:45:36.989788"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 853.584, "latencies_ms": [853.584], "images_per_second": 1.172, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man with long hair is riding a skateboard and jumping in the air.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13281.8, "ram_available_mb": 109224.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13282.6, "ram_available_mb": 109223.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [45.65, 45.65, 33.76, 33.76, 33.76, 33.76, 33.76, 45.98, 45.98], "power_watts_avg": 39.12, "power_watts_peak": 45.98, "energy_joules_est": 33.4, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-12T09:45:37.902264"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1950.23, "latencies_ms": [1950.23], "images_per_second": 0.513, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. grass: 1\n4. fence: 1\n5. building: 1\n6. tree: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13282.6, "ram_available_mb": 109223.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.98, 45.98, 45.98, 51.27, 51.27, 51.27, 51.27, 51.27, 46.65, 46.65, 46.65, 46.65, 46.65, 42.22, 42.22, 42.22, 42.22, 42.22, 33.98, 33.98], "power_watts_avg": 45.33, "power_watts_peak": 51.27, "energy_joules_est": 88.42, "sample_count": 20, "duration_seconds": 1.951}, "timestamp": "2026-01-12T09:45:39.921122"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1775.757, "latencies_ms": [1775.757], "images_per_second": 0.563, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on a ramp. The ramp is in the middle ground, with the skateboarder's shadow on the ground. The background features a fence and trees, which are far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.1, "ram_available_mb": 109184.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.98, 33.98, 34.09, 34.09, 34.09, 34.09, 34.09, 45.4, 45.4, 45.4, 45.4, 45.4, 45.42, 45.42, 45.42, 45.42, 45.42, 34.2], "power_watts_avg": 40.37, "power_watts_peak": 45.42, "energy_joules_est": 71.74, "sample_count": 18, "duration_seconds": 1.777}, "timestamp": "2026-01-12T09:45:41.789154"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 832.271, "latencies_ms": [832.271], "images_per_second": 1.202, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.1, "ram_available_mb": 109184.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13264.9, "ram_available_mb": 109241.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.2, 34.2, 34.2, 34.2, 43.12, 43.12, 43.12, 43.12, 43.12], "power_watts_avg": 39.15, "power_watts_peak": 43.12, "energy_joules_est": 32.61, "sample_count": 9, "duration_seconds": 0.833}, "timestamp": "2026-01-12T09:45:42.699997"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1568.506, "latencies_ms": [1568.506], "images_per_second": 0.638, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with the skateboarder wearing a black t-shirt and black pants. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13264.9, "ram_available_mb": 109241.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13279.6, "ram_available_mb": 109226.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.4, 46.4, 46.4, 46.4, 46.4, 49.32, 49.32, 49.32, 49.32, 49.32, 46.5, 46.5, 46.5, 46.5, 46.5, 34.21], "power_watts_avg": 46.58, "power_watts_peak": 49.32, "energy_joules_est": 73.09, "sample_count": 16, "duration_seconds": 1.569}, "timestamp": "2026-01-12T09:45:44.315479"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1167.441, "latencies_ms": [1167.441], "images_per_second": 0.857, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of five people are posing for a photo on a grassy field at sunset, each holding a frisbee with different colored designs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13275.7, "ram_available_mb": 109230.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13284.8, "ram_available_mb": 109221.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.21, 34.21, 34.21, 34.21, 43.13, 43.13, 43.13, 43.13, 43.13, 46.75, 46.75, 46.75], "power_watts_avg": 41.06, "power_watts_peak": 46.75, "energy_joules_est": 47.96, "sample_count": 12, "duration_seconds": 1.168}, "timestamp": "2026-01-12T09:45:45.530815"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2044.085, "latencies_ms": [2044.085], "images_per_second": 0.489, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. person: 5\n2. frisbee: 5\n3. headband: 1\n4. shorts: 4\n5. shoes: 4\n6. grass: 1\n7. frisbee: 1\n8. white: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13284.8, "ram_available_mb": 109221.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13359.0, "ram_available_mb": 109147.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.75, 46.75, 37.23, 37.23, 37.23, 37.23, 37.23, 46.52, 46.52, 46.52, 46.52, 46.52, 47.81, 47.81, 47.81, 47.81, 47.81, 34.24, 34.24, 34.24, 34.24], "power_watts_avg": 42.3, "power_watts_peak": 47.81, "energy_joules_est": 86.47, "sample_count": 21, "duration_seconds": 2.044}, "timestamp": "2026-01-12T09:45:47.650366"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2413.985, "latencies_ms": [2413.985], "images_per_second": 0.414, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The frisbee players are positioned in the foreground of the image, with the frisbee in the center of the frame. The frisbee is held by the players, with the player in the front holding the frisbee closest to the camera. The frisbee is positioned in the center of the image, with the players arranged in a line behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.0, "ram_available_mb": 109147.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13335.6, "ram_available_mb": 109170.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.61, 32.61, 32.61, 32.61, 32.61, 45.24, 45.24, 45.24, 45.24, 45.24, 46.87, 46.87, 46.87, 46.87, 46.87, 34.16, 34.16, 34.16, 34.16, 34.16, 34.16, 34.16, 34.16, 34.16], "power_watts_avg": 38.79, "power_watts_peak": 46.87, "energy_joules_est": 93.68, "sample_count": 24, "duration_seconds": 2.415}, "timestamp": "2026-01-12T09:45:50.124330"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1013.315, "latencies_ms": [1013.315], "images_per_second": 0.987, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Five young men are posing for a photo on a grassy field at sunset, each holding a frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.6, "ram_available_mb": 109174.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.4, "ram_available_mb": 109164.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.37, 33.37, 33.37, 33.37, 33.37, 46.18, 46.18, 46.18, 46.18, 46.18, 47.35], "power_watts_avg": 40.47, "power_watts_peak": 47.35, "energy_joules_est": 41.04, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:45:51.289560"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1912.127, "latencies_ms": [1912.127], "images_per_second": 0.523, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a group of five people posing for a photo on a grassy field at sunset. The sky is painted with hues of orange and blue, and the sun is setting behind the horizon. The people are holding frisbees, which are white with green and red designs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.5, "ram_available_mb": 109172.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.35, 47.35, 47.35, 47.35, 43.03, 43.03, 43.03, 43.03, 43.03, 45.63, 45.63, 45.63, 45.63, 45.63, 36.83, 36.83, 36.83, 36.83, 36.83, 34.14], "power_watts_avg": 42.55, "power_watts_peak": 47.35, "energy_joules_est": 81.38, "sample_count": 20, "duration_seconds": 1.913}, "timestamp": "2026-01-12T09:45:53.306847"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1408.945, "latencies_ms": [1408.945], "images_per_second": 0.71, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A large white airplane with red and black accents is parked at an airport gate, surrounded by a few vehicles and equipment, with a clear blue sky and a few clouds in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13326.2, "ram_available_mb": 109180.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13329.8, "ram_available_mb": 109176.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.14, 34.14, 34.14, 34.14, 39.18, 39.18, 39.18, 39.18, 44.24, 44.24, 44.24, 44.24, 44.24, 40.21, 40.21], "power_watts_avg": 39.66, "power_watts_peak": 44.24, "energy_joules_est": 55.9, "sample_count": 15, "duration_seconds": 1.41}, "timestamp": "2026-01-12T09:45:54.873089"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1380.406, "latencies_ms": [1380.406], "images_per_second": 0.724, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " airplane: 1, clouds: 1, runway: 1, terminal: 1, luggage cart: 1, palm tree: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.5, "ram_available_mb": 109196.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13324.7, "ram_available_mb": 109181.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.21, 40.21, 40.21, 39.68, 39.68, 39.68, 39.68, 39.68, 45.39, 45.39, 45.39, 45.39, 45.39, 40.06], "power_watts_avg": 41.86, "power_watts_peak": 45.39, "energy_joules_est": 57.81, "sample_count": 14, "duration_seconds": 1.381}, "timestamp": "2026-01-12T09:45:56.285774"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1728.086, "latencies_ms": [1728.086], "images_per_second": 0.579, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The airplane is positioned on the left side of the image, with the terminal building located in the background. The airplane is situated in the foreground, with the terminal building in the background. The airplane is closer to the viewer than the terminal building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.9, "ram_available_mb": 109189.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13238.1, "ram_available_mb": 109268.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.06, 40.06, 40.06, 40.06, 44.34, 44.34, 44.34, 44.34, 44.34, 46.94, 46.94, 46.94, 46.94, 46.94, 36.59, 36.59, 36.59, 36.59], "power_watts_avg": 42.39, "power_watts_peak": 46.94, "energy_joules_est": 73.27, "sample_count": 18, "duration_seconds": 1.728}, "timestamp": "2026-01-12T09:45:58.100826"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2157.199, "latencies_ms": [2157.199], "images_per_second": 0.464, "prompt_tokens": 1111, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a moment at an airport where a large airplane, adorned with the red and white logo of Japan Airlines, is parked at a gate. The sky above is a clear blue, dotted with fluffy white clouds, and the ground below is marked with yellow arrows and lines, indicating the path for the airplane's movement.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13238.1, "ram_available_mb": 109268.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13277.5, "ram_available_mb": 109228.8, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.59, 31.41, 31.41, 31.41, 31.41, 31.41, 45.7, 45.7, 45.7, 45.7, 45.7, 48.67, 48.67, 48.67, 48.67, 48.67, 34.09, 34.09, 34.09, 34.09, 34.09, 34.01], "power_watts_avg": 39.54, "power_watts_peak": 48.67, "energy_joules_est": 85.31, "sample_count": 22, "duration_seconds": 2.157}, "timestamp": "2026-01-12T09:46:00.318297"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 938.009, "latencies_ms": [938.009], "images_per_second": 1.066, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The airplane is white with red and black accents, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13277.5, "ram_available_mb": 109228.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.01, 34.01, 34.01, 39.31, 39.31, 39.31, 39.31, 39.31, 45.2, 45.2], "power_watts_avg": 38.9, "power_watts_peak": 45.2, "energy_joules_est": 36.52, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-12T09:46:01.380236"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 938.671, "latencies_ms": [938.671], "images_per_second": 1.065, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is skateboarding on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.2, 45.2, 45.2, 45.6, 45.6, 45.6, 45.6, 45.6, 45.8, 45.8], "power_watts_avg": 45.52, "power_watts_peak": 45.8, "energy_joules_est": 42.73, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-12T09:46:02.393889"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1967.135, "latencies_ms": [1967.135], "images_per_second": 0.508, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. bench: 1\n4. trash can: 1\n5. fence: 1\n6. bench: 1\n7. person: 1\n8. graffiti: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13348.4, "ram_available_mb": 109157.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.8, 45.8, 45.8, 45.55, 45.55, 45.55, 45.55, 45.55, 46.13, 46.13, 46.13, 46.13, 46.13, 41.95, 41.95, 41.95, 41.95, 41.95, 34.24, 34.24], "power_watts_avg": 43.7, "power_watts_peak": 46.13, "energy_joules_est": 85.99, "sample_count": 20, "duration_seconds": 1.968}, "timestamp": "2026-01-12T09:46:04.411733"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1516.684, "latencies_ms": [1516.684], "images_per_second": 0.659, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, performing a trick on a ramp, while the bench is located in the background, and the trash can is situated to the left of the skateboarder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.5, "ram_available_mb": 109165.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13325.7, "ram_available_mb": 109180.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.24, 34.24, 34.24, 35.74, 35.74, 35.74, 35.74, 45.34, 45.34, 45.34, 45.34, 45.34, 44.69, 44.69, 44.69, 44.69], "power_watts_avg": 40.69, "power_watts_peak": 45.34, "energy_joules_est": 61.75, "sample_count": 16, "duration_seconds": 1.517}, "timestamp": "2026-01-12T09:46:06.078342"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.975, "latencies_ms": [828.975], "images_per_second": 1.206, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.7, "ram_available_mb": 109184.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [44.69, 30.7, 30.7, 30.7, 30.7, 30.7, 45.59, 45.59, 45.59], "power_watts_avg": 37.22, "power_watts_peak": 45.59, "energy_joules_est": 30.87, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-12T09:46:06.990414"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2181.492, "latencies_ms": [2181.492], "images_per_second": 0.458, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with a vibrant green grass field in the background. The lighting is bright and sunny, casting a clear shadow of the skateboarder on the ramp. The skateboarder is wearing a yellow shirt and black pants, and the ramp is covered in graffiti.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.2, "ram_available_mb": 109183.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13318.3, "ram_available_mb": 109188.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.59, 45.59, 48.96, 48.96, 48.96, 48.96, 48.96, 45.77, 45.77, 45.77, 45.77, 45.77, 45.49, 45.49, 45.49, 45.49, 45.49, 34.1, 34.1, 34.1, 34.1, 34.1], "power_watts_avg": 43.76, "power_watts_peak": 48.96, "energy_joules_est": 95.49, "sample_count": 22, "duration_seconds": 2.182}, "timestamp": "2026-01-12T09:46:09.210525"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 989.107, "latencies_ms": [989.107], "images_per_second": 1.011, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle and chocolate drizzle on a white plate with gold designs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.4, "ram_available_mb": 109195.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.9, "ram_available_mb": 109177.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 34.15, 44.2, 44.2, 44.2, 44.2, 44.2, 45.82], "power_watts_avg": 40.34, "power_watts_peak": 45.82, "energy_joules_est": 39.91, "sample_count": 10, "duration_seconds": 0.989}, "timestamp": "2026-01-12T09:46:10.274732"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2027.719, "latencies_ms": [2027.719], "images_per_second": 0.493, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. plate: 1\n2. cake: 1\n3. syrup: 1\n4. chocolate: 1\n5. chocolate syrup: 1\n6. caramel: 1\n7. caramel sauce: 1\n8. chocolate drizzle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.0, "ram_available_mb": 109181.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13233.8, "ram_available_mb": 109272.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.82, 45.82, 45.82, 45.82, 47.07, 47.07, 47.07, 47.07, 47.07, 46.85, 46.85, 46.85, 46.85, 46.85, 36.22, 36.22, 36.22, 36.22, 36.22, 34.12, 34.12], "power_watts_avg": 42.96, "power_watts_peak": 47.07, "energy_joules_est": 87.13, "sample_count": 21, "duration_seconds": 2.028}, "timestamp": "2026-01-12T09:46:12.390960"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1380.505, "latencies_ms": [1380.505], "images_per_second": 0.724, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The slice of chocolate cake is positioned in the foreground, with the plate and the background being blurred. The cake is placed on the plate, which is resting on a wooden surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13233.8, "ram_available_mb": 109272.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13281.1, "ram_available_mb": 109225.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.12, 34.12, 34.12, 35.57, 35.57, 35.57, 35.57, 35.57, 44.76, 44.76, 44.76, 44.76, 44.76, 43.35], "power_watts_avg": 39.1, "power_watts_peak": 44.76, "energy_joules_est": 54.02, "sample_count": 14, "duration_seconds": 1.382}, "timestamp": "2026-01-12T09:46:13.856512"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 903.569, "latencies_ms": [903.569], "images_per_second": 1.107, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle is on a white plate with gold designs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13273.3, "ram_available_mb": 109233.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13281.3, "ram_available_mb": 109225.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.35, 43.35, 43.35, 43.35, 41.86, 41.86, 41.86, 41.86, 41.86], "power_watts_avg": 42.52, "power_watts_peak": 43.35, "energy_joules_est": 38.44, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-12T09:46:14.767313"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1431.185, "latencies_ms": [1431.185], "images_per_second": 0.699, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The slice of chocolate cake is on a white plate with gold designs, and the plate is on a wooden table. The lighting is bright and natural, and the cake is shiny and moist.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13281.3, "ram_available_mb": 109225.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13273.6, "ram_available_mb": 109232.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.97, 46.97, 46.97, 46.97, 51.82, 51.82, 51.82, 51.82, 51.82, 47.3, 47.3, 47.3, 47.3, 47.3, 35.64], "power_watts_avg": 47.94, "power_watts_peak": 51.82, "energy_joules_est": 68.64, "sample_count": 15, "duration_seconds": 1.432}, "timestamp": "2026-01-12T09:46:16.282852"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 896.846, "latencies_ms": [896.846], "images_per_second": 1.115, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting at a desk with a laptop and a computer in front of him.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13265.7, "ram_available_mb": 109240.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13297.6, "ram_available_mb": 109208.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.64, 35.64, 35.64, 35.64, 44.01, 44.01, 44.01, 44.01, 44.01], "power_watts_avg": 40.29, "power_watts_peak": 44.01, "energy_joules_est": 36.14, "sample_count": 9, "duration_seconds": 0.897}, "timestamp": "2026-01-12T09:46:17.195534"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1905.016, "latencies_ms": [1905.016], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. laptop: 2\n3. chair: 3\n4. person: 2\n5. table: 2\n6. box: 1\n7. bottle: 1\n8. chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13289.7, "ram_available_mb": 109216.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13297.9, "ram_available_mb": 109208.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.1, 46.1, 46.1, 46.1, 46.1, 49.44, 49.44, 49.44, 49.44, 49.44, 47.42, 47.42, 47.42, 47.42, 47.42, 34.02, 34.02, 34.02, 34.02], "power_watts_avg": 44.78, "power_watts_peak": 49.44, "energy_joules_est": 85.33, "sample_count": 19, "duration_seconds": 1.906}, "timestamp": "2026-01-12T09:46:19.110970"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1172.61, "latencies_ms": [1172.61], "images_per_second": 0.853, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The man is sitting in the foreground, working on his laptop. The boxes are in the background, and the people are standing around the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13297.9, "ram_available_mb": 109208.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.7, "ram_available_mb": 109129.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.02, 33.11, 33.11, 33.11, 33.11, 33.11, 46.8, 46.8, 46.8, 46.8, 47.99, 47.99], "power_watts_avg": 40.23, "power_watts_peak": 47.99, "energy_joules_est": 47.22, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-12T09:46:20.374262"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 858.246, "latencies_ms": [858.246], "images_per_second": 1.165, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are working in a cluttered office with computers and laptops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.7, "ram_available_mb": 109129.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.3, "ram_available_mb": 109139.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.99, 47.99, 47.99, 41.0, 41.0, 41.0, 41.0, 41.0, 46.93], "power_watts_avg": 43.99, "power_watts_peak": 47.99, "energy_joules_est": 37.79, "sample_count": 9, "duration_seconds": 0.859}, "timestamp": "2026-01-12T09:46:21.284650"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1032.348, "latencies_ms": [1032.348], "images_per_second": 0.969, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is lit with fluorescent lighting, and the walls are painted white. The floor is covered with yellow paint.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.3, "ram_available_mb": 109139.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13434.8, "ram_available_mb": 109071.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.93, 46.93, 46.93, 46.93, 51.4, 51.4, 51.4, 51.4, 51.4, 46.49, 46.49], "power_watts_avg": 48.88, "power_watts_peak": 51.4, "energy_joules_est": 50.5, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-12T09:46:22.397473"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1293.501, "latencies_ms": [1293.501], "images_per_second": 0.773, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room, with a woman holding a Wii remote and a man holding a Wii nunchuck.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13434.8, "ram_available_mb": 109071.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13474.9, "ram_available_mb": 109031.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.49, 46.49, 46.49, 41.19, 41.19, 41.19, 41.19, 41.19, 46.23, 46.23, 46.23, 46.23, 46.23], "power_watts_avg": 44.35, "power_watts_peak": 46.49, "energy_joules_est": 57.39, "sample_count": 13, "duration_seconds": 1.294}, "timestamp": "2026-01-12T09:46:23.710938"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2450.257, "latencies_ms": [2450.257], "images_per_second": 0.408, "prompt_tokens": 1113, "response_tokens_est": 77, "n_tiles": 1, "output_text": " 1. Wii remote: 2\n2. Wii controller: 1\n3. Wii game: 1\n4. Wii console: 1\n5. Wii remote holder: 1\n6. Wii game case: 1\n7. Wii game disc: 1\n8. Wii game disc case: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13470.9, "ram_available_mb": 109035.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13429.2, "ram_available_mb": 109077.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.91, 41.91, 41.91, 41.91, 41.91, 47.46, 47.46, 47.46, 47.46, 47.46, 47.45, 47.45, 47.45, 47.45, 47.45, 34.37, 34.37, 34.37, 34.37, 34.37, 34.37, 34.37, 34.37, 34.37, 34.37], "power_watts_avg": 41.11, "power_watts_peak": 47.46, "energy_joules_est": 100.76, "sample_count": 25, "duration_seconds": 2.451}, "timestamp": "2026-01-12T09:46:26.231596"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2458.288, "latencies_ms": [2458.288], "images_per_second": 0.407, "prompt_tokens": 1117, "response_tokens_est": 77, "n_tiles": 1, "output_text": " The woman is standing to the left of the man in the blue shirt, who is standing to the right of the man in the white shirt. The woman is in the foreground, while the man in the blue shirt is in the background. The man in the green shirt is standing in the middle of the room, with the woman and the man in the white shirt to his left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.2, "ram_available_mb": 109081.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13402.6, "ram_available_mb": 109103.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.35, 34.35, 34.35, 34.35, 43.41, 43.41, 43.41, 43.41, 43.41, 45.35, 45.35, 45.35, 45.35, 45.35, 37.1, 37.1, 37.1, 37.1, 37.1, 34.26, 34.26, 34.26, 34.26, 34.26, 34.23], "power_watts_avg": 38.89, "power_watts_peak": 45.35, "energy_joules_est": 95.63, "sample_count": 25, "duration_seconds": 2.459}, "timestamp": "2026-01-12T09:46:28.806581"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 793.812, "latencies_ms": [793.812], "images_per_second": 1.26, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.2, "ram_available_mb": 109108.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13394.9, "ram_available_mb": 109111.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.23, 34.23, 34.23, 34.23, 40.5, 40.5, 40.5, 40.5], "power_watts_avg": 37.36, "power_watts_peak": 40.5, "energy_joules_est": 29.69, "sample_count": 8, "duration_seconds": 0.795}, "timestamp": "2026-01-12T09:46:29.667030"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1008.214, "latencies_ms": [1008.214], "images_per_second": 0.992, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well lit with natural light coming from the windows, and the carpet is a light gray color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.9, "ram_available_mb": 109111.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13389.7, "ram_available_mb": 109116.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [40.5, 45.12, 45.12, 45.12, 45.12, 53.04, 53.04, 53.04, 53.04, 53.04, 47.63], "power_watts_avg": 48.53, "power_watts_peak": 53.04, "energy_joules_est": 48.96, "sample_count": 11, "duration_seconds": 1.009}, "timestamp": "2026-01-12T09:46:30.780437"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 973.859, "latencies_ms": [973.859], "images_per_second": 1.027, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person stands on a frozen lake at sunset, with a frisbee in the air above them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.63, 47.63, 47.63, 47.63, 43.83, 43.83, 43.83, 43.83, 43.83, 45.71], "power_watts_avg": 45.54, "power_watts_peak": 47.63, "energy_joules_est": 44.36, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-12T09:46:31.794936"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1944.769, "latencies_ms": [1944.769], "images_per_second": 0.514, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. sun: 1\n3. sky: 2\n4. water: 1\n5. ice: 1\n6. frisbee: 1\n7. shadow: 1\n8. reflection: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.71, 45.71, 45.71, 45.71, 47.19, 47.19, 47.19, 47.19, 47.19, 46.93, 46.93, 46.93, 46.93, 46.93, 36.88, 36.88, 36.88, 36.88, 36.88, 34.28], "power_watts_avg": 43.61, "power_watts_peak": 47.19, "energy_joules_est": 84.83, "sample_count": 20, "duration_seconds": 1.945}, "timestamp": "2026-01-12T09:46:33.813808"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1456.661, "latencies_ms": [1456.661], "images_per_second": 0.687, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The main object, a person, is located in the foreground of the image, with the sun in the background. The person is standing on the beach, with the water and ice surrounding them.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13332.8, "ram_available_mb": 109173.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.28, 34.28, 34.28, 34.28, 39.63, 39.63, 39.63, 39.63, 39.63, 45.3, 45.3, 45.3, 45.3, 39.77, 39.77], "power_watts_avg": 39.74, "power_watts_peak": 45.3, "energy_joules_est": 57.93, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-12T09:46:35.380773"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1820.827, "latencies_ms": [1820.827], "images_per_second": 0.549, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a serene beach scene at sunrise, where a lone figure stands on the shore, silhouetted against the brightening sky. The sun casts a warm glow on the wet sand, creating a shimmering effect that reflects the figure and the surrounding water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.8, "ram_available_mb": 109177.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [39.77, 39.77, 39.77, 40.41, 40.41, 40.41, 40.41, 40.41, 46.6, 46.6, 46.6, 46.6, 46.6, 41.03, 41.03, 41.03, 41.03, 41.03, 34.21], "power_watts_avg": 41.78, "power_watts_peak": 46.6, "energy_joules_est": 76.08, "sample_count": 19, "duration_seconds": 1.821}, "timestamp": "2026-01-12T09:46:37.296433"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1670.664, "latencies_ms": [1670.664], "images_per_second": 0.599, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person standing on a frozen lake at sunset, with the sun casting a warm glow on the ice and the person's shadow. The sky is a gradient of orange and blue, with the sun positioned near the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.9, "ram_available_mb": 109124.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.21, 34.21, 34.21, 34.21, 40.14, 40.14, 40.14, 40.14, 40.14, 44.67, 44.67, 44.67, 44.67, 44.67, 38.82, 38.82, 38.82], "power_watts_avg": 39.84, "power_watts_peak": 44.67, "energy_joules_est": 66.58, "sample_count": 17, "duration_seconds": 1.671}, "timestamp": "2026-01-12T09:46:39.063533"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1405.238, "latencies_ms": [1405.238], "images_per_second": 0.712, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a modern living room with a white sofa, a dining table with chairs, a television on a stand, and a variety of decorative items on the walls and shelves.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13381.9, "ram_available_mb": 109124.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13372.0, "ram_available_mb": 109134.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.82, 38.82, 32.11, 32.11, 32.11, 32.11, 32.11, 46.36, 46.36, 46.36, 46.36, 46.36, 48.76, 48.76], "power_watts_avg": 40.54, "power_watts_peak": 48.76, "energy_joules_est": 57.0, "sample_count": 14, "duration_seconds": 1.406}, "timestamp": "2026-01-12T09:46:40.479128"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2190.851, "latencies_ms": [2190.851], "images_per_second": 0.456, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. white sofa: 1\n2. red chair: 2\n3. white table: 1\n4. vase with flowers: 1\n5. television: 1\n6. black and white rug: 1\n7. wall art: 4\n8. window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.2, "ram_available_mb": 109142.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13305.3, "ram_available_mb": 109201.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.76, 48.76, 36.71, 36.71, 36.71, 36.71, 36.71, 47.59, 47.59, 47.59, 47.59, 47.59, 45.03, 45.03, 45.03, 45.03, 45.03, 34.12, 34.12, 34.12, 34.12, 34.12], "power_watts_avg": 41.58, "power_watts_peak": 48.76, "energy_joules_est": 91.12, "sample_count": 22, "duration_seconds": 2.191}, "timestamp": "2026-01-12T09:46:42.698944"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1918.22, "latencies_ms": [1918.22], "images_per_second": 0.521, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The white sofa is positioned to the left of the television, which is situated in the center of the room. The dining table is located in the foreground, with the red chairs placed around it. The living room extends into the background, with the large window providing natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13305.3, "ram_available_mb": 109201.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13269.2, "ram_available_mb": 109237.1, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.92, 33.92, 33.92, 33.92, 33.92, 44.51, 44.51, 44.51, 44.51, 44.51, 45.75, 45.75, 45.75, 45.75, 45.75, 35.24, 35.24, 35.24, 35.24, 35.24], "power_watts_avg": 39.85, "power_watts_peak": 45.75, "energy_joules_est": 76.48, "sample_count": 20, "duration_seconds": 1.919}, "timestamp": "2026-01-12T09:46:44.766338"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1037.222, "latencies_ms": [1037.222], "images_per_second": 0.964, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A living room with a white couch, red chairs, and a dining table with a vase of flowers on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13269.2, "ram_available_mb": 109237.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13280.9, "ram_available_mb": 109225.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.19, 34.19, 34.19, 34.19, 41.04, 41.04, 41.04, 41.04, 41.04, 44.73, 44.73], "power_watts_avg": 39.22, "power_watts_peak": 44.73, "energy_joules_est": 40.71, "sample_count": 11, "duration_seconds": 1.038}, "timestamp": "2026-01-12T09:46:45.929085"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1173.804, "latencies_ms": [1173.804], "images_per_second": 0.852, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the windows. The walls are painted white and the furniture is mostly black and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13273.0, "ram_available_mb": 109233.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13304.4, "ram_available_mb": 109201.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.73, 44.73, 44.73, 41.41, 41.41, 41.41, 41.41, 41.41, 45.9, 45.9, 45.9, 45.9], "power_watts_avg": 43.74, "power_watts_peak": 45.9, "energy_joules_est": 51.35, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-12T09:46:47.141739"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 847.891, "latencies_ms": [847.891], "images_per_second": 1.179, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A cat is standing on top of a blue refrigerator, looking out the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13296.5, "ram_available_mb": 109209.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13305.5, "ram_available_mb": 109200.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [45.9, 42.22, 42.22, 42.22, 42.22, 42.22, 46.62, 46.62, 46.62], "power_watts_avg": 44.1, "power_watts_peak": 46.62, "energy_joules_est": 37.4, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-12T09:46:48.056042"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1901.201, "latencies_ms": [1901.201], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. refrigerator: 1\n3. cabinet: 1\n4. shelf: 1\n5. light: 1\n6. door: 1\n7. wall: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13305.5, "ram_available_mb": 109200.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13300.6, "ram_available_mb": 109205.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.62, 46.62, 46.12, 46.12, 46.12, 46.12, 46.12, 46.48, 46.48, 46.48, 46.48, 46.48, 48.41, 48.41, 48.41, 48.41, 48.41, 34.33, 34.33], "power_watts_avg": 45.63, "power_watts_peak": 48.41, "energy_joules_est": 86.78, "sample_count": 19, "duration_seconds": 1.902}, "timestamp": "2026-01-12T09:46:49.972197"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1708.728, "latencies_ms": [1708.728], "images_per_second": 0.585, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The cat is positioned on the right side of the refrigerator, which is located in the foreground of the image. The refrigerator is situated in the middle of the image, with the cat's head and body occupying a significant portion of the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.7, "ram_available_mb": 109213.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13311.7, "ram_available_mb": 109194.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.33, 34.33, 33.67, 33.67, 33.67, 33.67, 33.67, 46.32, 46.32, 46.32, 46.32, 46.32, 46.98, 46.98, 46.98, 46.98, 46.98], "power_watts_avg": 41.38, "power_watts_peak": 46.98, "energy_joules_est": 70.73, "sample_count": 17, "duration_seconds": 1.709}, "timestamp": "2026-01-12T09:46:51.737937"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 810.526, "latencies_ms": [810.526], "images_per_second": 1.234, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is standing on top of a blue refrigerator in a kitchen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13303.8, "ram_available_mb": 109202.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13230.3, "ram_available_mb": 109276.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.17, 34.17, 34.17, 34.17, 34.17, 47.0, 47.0, 47.0, 47.0], "power_watts_avg": 39.87, "power_watts_peak": 47.0, "energy_joules_est": 32.33, "sample_count": 9, "duration_seconds": 0.811}, "timestamp": "2026-01-12T09:46:52.647263"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1703.25, "latencies_ms": [1703.25], "images_per_second": 0.587, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a cat standing on top of a blue refrigerator, with a white wall in the background. The cat is wearing a blue collar, and the refrigerator has various items on it, including a bottle of water and some other objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13230.3, "ram_available_mb": 109276.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13279.4, "ram_available_mb": 109226.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.0, 45.03, 45.03, 45.03, 45.03, 45.03, 46.73, 46.73, 46.73, 46.73, 46.73, 47.88, 47.88, 47.88, 47.88, 47.88, 34.27], "power_watts_avg": 45.85, "power_watts_peak": 47.88, "energy_joules_est": 78.13, "sample_count": 17, "duration_seconds": 1.704}, "timestamp": "2026-01-12T09:46:54.361538"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1485.438, "latencies_ms": [1485.438], "images_per_second": 0.673, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a room with a wooden floor, a white ceiling, and a yellow balloon hanging from the ceiling, with a white refrigerator, a wooden table, and a black chair in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13271.5, "ram_available_mb": 109234.8, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13300.4, "ram_available_mb": 109205.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.27, 34.27, 34.27, 34.27, 41.81, 41.81, 41.81, 41.81, 41.81, 47.33, 47.33, 47.33, 47.33, 47.33, 39.8], "power_watts_avg": 41.51, "power_watts_peak": 47.33, "energy_joules_est": 61.67, "sample_count": 15, "duration_seconds": 1.486}, "timestamp": "2026-01-12T09:46:55.876896"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2105.978, "latencies_ms": [2105.978], "images_per_second": 0.475, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Balloons: 4\n2. Balloons: 2\n3. Balloons: 1\n4. Balloons: 1\n5. Balloons: 1\n6. Balloons: 1\n7. Balloons: 1\n8. Balloons: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13290.8, "ram_available_mb": 109215.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13299.9, "ram_available_mb": 109206.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.8, 39.8, 39.8, 40.83, 40.83, 40.83, 40.83, 40.83, 46.93, 46.93, 46.93, 46.93, 46.93, 40.52, 40.52, 40.52, 40.52, 40.52, 34.46, 34.46, 34.46], "power_watts_avg": 41.15, "power_watts_peak": 46.93, "energy_joules_est": 86.67, "sample_count": 21, "duration_seconds": 2.106}, "timestamp": "2026-01-12T09:46:57.993649"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2173.57, "latencies_ms": [2173.57], "images_per_second": 0.46, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the refrigerator on the left and the desk on the right. The balloons are scattered throughout the room, with some near the desk and others near the refrigerator. The wall decorations are located in the background, with the bookshelves and framed pictures on the right side of the room.", "error": null, "sys_before": {"cpu_percent": 1.9, "ram_used_mb": 13299.9, "ram_available_mb": 109206.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13338.5, "ram_available_mb": 109167.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.46, 34.46, 33.01, 33.01, 33.01, 33.01, 33.01, 46.43, 46.43, 46.43, 46.43, 46.43, 48.69, 48.69, 48.69, 48.69, 48.69, 34.34, 34.34, 34.34, 34.34, 34.34], "power_watts_avg": 40.06, "power_watts_peak": 48.69, "energy_joules_est": 87.1, "sample_count": 22, "duration_seconds": 2.174}, "timestamp": "2026-01-12T09:47:00.259591"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 829.994, "latencies_ms": [829.994], "images_per_second": 1.205, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A room with balloons and a smiley face balloon hanging from the ceiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.5, "ram_available_mb": 109167.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13380.0, "ram_available_mb": 109126.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.38, 34.38, 34.38, 34.38, 42.27, 42.27, 42.27, 42.27, 42.27], "power_watts_avg": 38.76, "power_watts_peak": 42.27, "energy_joules_est": 32.19, "sample_count": 9, "duration_seconds": 0.83}, "timestamp": "2026-01-12T09:47:01.218279"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 805.971, "latencies_ms": [805.971], "images_per_second": 1.241, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The room is lit by a chandelier and has wooden floors.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13376.0, "ram_available_mb": 109130.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13379.7, "ram_available_mb": 109126.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.21, 45.21, 45.21, 45.21, 45.21, 49.6, 49.6, 49.6, 49.6], "power_watts_avg": 47.16, "power_watts_peak": 49.6, "energy_joules_est": 38.04, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-12T09:47:02.128780"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1114.876, "latencies_ms": [1114.876], "images_per_second": 0.897, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing headphones is sitting at a table with a laptop in front of him, and there is a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.9, "ram_available_mb": 109134.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13388.2, "ram_available_mb": 109118.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.6, 43.31, 43.31, 43.31, 43.31, 43.31, 45.56, 45.56, 45.56, 45.56, 45.56, 48.3], "power_watts_avg": 45.19, "power_watts_peak": 49.6, "energy_joules_est": 50.39, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-12T09:47:03.342913"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1962.766, "latencies_ms": [1962.766], "images_per_second": 0.509, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. laptop: 1\n3. chair: 1\n4. window: 1\n5. train: 1\n6. train tracks: 1\n7. headset: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13380.3, "ram_available_mb": 109126.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.4, "ram_available_mb": 109141.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.3, 48.3, 48.3, 48.3, 41.4, 41.4, 41.4, 41.4, 41.4, 45.7, 45.7, 45.7, 45.7, 45.7, 38.65, 38.65, 38.65, 38.65, 38.65, 34.17], "power_watts_avg": 42.81, "power_watts_peak": 48.3, "energy_joules_est": 84.04, "sample_count": 20, "duration_seconds": 1.963}, "timestamp": "2026-01-12T09:47:05.363768"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1750.926, "latencies_ms": [1750.926], "images_per_second": 0.571, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, with the laptop in front of him. The laptop is on the right side of the image, and the window is on the left side. The man is closer to the window than the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13356.2, "ram_available_mb": 109150.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.17, 34.17, 34.17, 37.97, 37.97, 37.97, 37.97, 37.97, 45.42, 45.42, 45.42, 45.42, 45.42, 42.8, 42.8, 42.8, 42.8, 42.8], "power_watts_avg": 40.75, "power_watts_peak": 45.42, "energy_joules_est": 71.36, "sample_count": 18, "duration_seconds": 1.751}, "timestamp": "2026-01-12T09:47:07.230578"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 792.219, "latencies_ms": [792.219], "images_per_second": 1.262, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man wearing headphones is sitting in a train and using a laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.3, "ram_available_mb": 109158.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 34.7, 34.7, 46.5, 46.5, 46.5], "power_watts_avg": 39.13, "power_watts_peak": 46.5, "energy_joules_est": 31.03, "sample_count": 8, "duration_seconds": 0.793}, "timestamp": "2026-01-12T09:47:08.040015"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1057.714, "latencies_ms": [1057.714], "images_per_second": 0.945, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The man is wearing a green shirt and has red hair. The laptop is silver and has an apple logo on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13407.1, "ram_available_mb": 109099.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 6.0}, "power_stats": {"power_watts_samples": [46.5, 46.5, 46.44, 46.44, 46.44, 46.44, 46.44, 47.63, 47.63, 47.63, 47.63], "power_watts_avg": 46.88, "power_watts_peak": 47.63, "energy_joules_est": 49.61, "sample_count": 11, "duration_seconds": 1.058}, "timestamp": "2026-01-12T09:47:09.150874"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2166.911, "latencies_ms": [2166.911], "images_per_second": 0.461, "prompt_tokens": 1099, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures a striking white cable-stayed bridge with a unique, pointed design, spanning across a bustling train station with multiple tracks and platforms. The sky above is a clear blue, dotted with fluffy white clouds, and the cityscape in the background is a mix of buildings and trees, adding depth and context to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.1, "ram_available_mb": 109099.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.63, 46.83, 46.83, 46.83, 46.83, 46.83, 46.76, 46.76, 46.76, 46.76, 46.76, 48.18, 48.18, 48.18, 48.18, 48.18, 34.6, 34.6, 34.6, 34.6, 34.6, 34.43], "power_watts_avg": 43.82, "power_watts_peak": 48.18, "energy_joules_est": 94.97, "sample_count": 22, "duration_seconds": 2.168}, "timestamp": "2026-01-12T09:47:11.367810"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1999.76, "latencies_ms": [1999.76], "images_per_second": 0.5, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. train tracks: 4\n3. train: 1\n4. train station: 1\n5. platform: 1\n6. platform sign: 1\n7. fence: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13395.5, "ram_available_mb": 109110.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.43, 34.43, 34.43, 37.81, 37.81, 37.81, 37.81, 37.81, 45.77, 45.77, 45.77, 45.77, 45.77, 42.19, 42.19, 42.19, 42.19, 42.19, 34.16, 34.16], "power_watts_avg": 40.02, "power_watts_peak": 45.77, "energy_joules_est": 80.05, "sample_count": 20, "duration_seconds": 2.0}, "timestamp": "2026-01-12T09:47:13.434447"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1869.146, "latencies_ms": [1869.146], "images_per_second": 0.535, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The train station is located in the foreground, with the bridge stretching across the image, and the city skyline is visible in the background. The train tracks are parallel to each other, and the bridge is positioned above them, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.5, "ram_available_mb": 109110.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.2, "ram_available_mb": 109142.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.16, 34.16, 34.76, 34.76, 34.76, 34.76, 34.76, 45.94, 45.94, 45.94, 45.94, 45.94, 46.2, 46.2, 46.2, 46.2, 46.2, 34.14, 34.14], "power_watts_avg": 40.59, "power_watts_peak": 46.2, "energy_joules_est": 75.89, "sample_count": 19, "duration_seconds": 1.87}, "timestamp": "2026-01-12T09:47:15.400707"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1868.269, "latencies_ms": [1868.269], "images_per_second": 0.535, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a modern white cable-stayed bridge with a unique, pointed design, spanning over a bustling train station. The sky above is a clear blue, dotted with fluffy white clouds, and the cityscape in the background is a mix of buildings and trees.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13364.2, "ram_available_mb": 109142.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.14, 34.14, 34.14, 36.07, 36.07, 36.07, 36.07, 36.07, 45.49, 45.49, 45.49, 45.49, 45.49, 43.73, 43.73, 43.73, 43.73, 43.73, 34.09], "power_watts_avg": 40.16, "power_watts_peak": 45.49, "energy_joules_est": 75.05, "sample_count": 19, "duration_seconds": 1.869}, "timestamp": "2026-01-12T09:47:17.368944"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 991.413, "latencies_ms": [991.413], "images_per_second": 1.009, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image features a white bridge with a unique design, and the sky is filled with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.0, "ram_available_mb": 109147.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13375.2, "ram_available_mb": 109131.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.09, 34.09, 34.09, 37.31, 37.31, 37.31, 37.31, 37.31, 45.51, 45.51], "power_watts_avg": 37.99, "power_watts_peak": 45.51, "energy_joules_est": 37.68, "sample_count": 10, "duration_seconds": 0.992}, "timestamp": "2026-01-12T09:47:18.430994"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1045.578, "latencies_ms": [1045.578], "images_per_second": 0.956, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are flying a large kite with a purple and yellow design on a sunny day in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.3, "ram_available_mb": 109135.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13274.6, "ram_available_mb": 109231.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.51, 45.51, 45.51, 47.0, 47.0, 47.0, 47.0, 47.0, 46.9, 46.9, 46.9], "power_watts_avg": 46.57, "power_watts_peak": 47.0, "energy_joules_est": 48.7, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-12T09:47:19.546545"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1333.754, "latencies_ms": [1333.754], "images_per_second": 0.75, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " kite: 1, person: 2, ball: 1, chair: 1, backpack: 1, person: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13274.6, "ram_available_mb": 109231.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13313.7, "ram_available_mb": 109192.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.9, 46.9, 42.17, 42.17, 42.17, 42.17, 42.17, 46.36, 46.36, 46.36, 46.36, 46.36, 48.76, 48.76], "power_watts_avg": 45.28, "power_watts_peak": 48.76, "energy_joules_est": 60.42, "sample_count": 14, "duration_seconds": 1.334}, "timestamp": "2026-01-12T09:47:20.961161"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1735.725, "latencies_ms": [1735.725], "images_per_second": 0.576, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the people are in the background, walking and standing on the grass. The kite is to the left of the people, and the people are to the right of the kite.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13305.8, "ram_available_mb": 109200.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.2, "ram_available_mb": 109184.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.76, 48.76, 48.76, 35.86, 35.86, 35.86, 35.86, 35.86, 45.99, 45.99, 45.99, 45.99, 45.99, 44.35, 44.35, 44.35, 44.35, 44.35], "power_watts_avg": 43.18, "power_watts_peak": 48.76, "energy_joules_est": 74.97, "sample_count": 18, "duration_seconds": 1.736}, "timestamp": "2026-01-12T09:47:22.779465"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 779.324, "latencies_ms": [779.324], "images_per_second": 1.283, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are flying a large kite in a park.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13318.3, "ram_available_mb": 109188.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13306.1, "ram_available_mb": 109200.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 34.15, 43.52, 43.52, 43.52, 43.52], "power_watts_avg": 38.84, "power_watts_peak": 43.52, "energy_joules_est": 30.29, "sample_count": 8, "duration_seconds": 0.78}, "timestamp": "2026-01-12T09:47:23.590125"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1614.035, "latencies_ms": [1614.035], "images_per_second": 0.62, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The kite is a vibrant mix of blue, purple, and yellow, with a long tail that trails behind it. The sky is clear and blue, and the sun is shining brightly, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.1, "ram_available_mb": 109200.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13305.0, "ram_available_mb": 109201.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.52, 43.8, 43.8, 43.8, 43.8, 43.8, 49.02, 49.02, 49.02, 49.02, 49.02, 49.12, 49.12, 49.12, 49.12, 49.12, 34.38], "power_watts_avg": 46.33, "power_watts_peak": 49.12, "energy_joules_est": 74.8, "sample_count": 17, "duration_seconds": 1.615}, "timestamp": "2026-01-12T09:47:25.306068"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1653.528, "latencies_ms": [1653.528], "images_per_second": 0.605, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a miniature model of a train station with a red and black train, a red and white train, and a red and black train on the tracks, with workers in orange uniforms and white helmets walking along the tracks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13305.0, "ram_available_mb": 109201.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.38, 34.38, 34.38, 34.38, 42.25, 42.25, 42.25, 42.25, 42.25, 45.66, 45.66, 45.66, 45.66, 45.66, 36.63, 36.63, 36.63], "power_watts_avg": 40.41, "power_watts_peak": 45.66, "energy_joules_est": 66.83, "sample_count": 17, "duration_seconds": 1.654}, "timestamp": "2026-01-12T09:47:27.025182"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1339.078, "latencies_ms": [1339.078], "images_per_second": 0.747, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " train: 1, workers: 4, tracks: 3, wires: 2, fence: 1, grass: 1, hills: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.5, "ram_available_mb": 109166.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.2, "ram_available_mb": 109154.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.63, 36.63, 33.26, 33.26, 33.26, 33.26, 33.26, 46.05, 46.05, 46.05, 46.05, 46.05, 47.75, 47.75], "power_watts_avg": 40.38, "power_watts_peak": 47.75, "energy_joules_est": 54.09, "sample_count": 14, "duration_seconds": 1.34}, "timestamp": "2026-01-12T09:47:28.441248"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1617.974, "latencies_ms": [1617.974], "images_per_second": 0.618, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The train is positioned on the right side of the image, with the workers on the left. The train is in the foreground, while the workers are in the background. The train is closer to the viewer than the workers.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13352.2, "ram_available_mb": 109154.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.75, 47.75, 47.75, 37.9, 37.9, 37.9, 37.9, 37.9, 45.97, 45.97, 45.97, 45.97, 45.97, 43.32, 43.32, 43.32, 43.32], "power_watts_avg": 43.29, "power_watts_peak": 47.75, "energy_joules_est": 70.05, "sample_count": 17, "duration_seconds": 1.618}, "timestamp": "2026-01-12T09:47:30.157688"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1318.533, "latencies_ms": [1318.533], "images_per_second": 0.758, "prompt_tokens": 1111, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A model train is traveling on a track, passing by a group of workers in orange uniforms. The train is red and black, and the workers are wearing white helmets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.32, 31.97, 31.97, 31.97, 31.97, 31.97, 45.87, 45.87, 45.87, 45.87, 45.87, 47.59, 47.59, 47.59], "power_watts_avg": 41.09, "power_watts_peak": 47.59, "energy_joules_est": 54.2, "sample_count": 14, "duration_seconds": 1.319}, "timestamp": "2026-01-12T09:47:31.573887"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1091.435, "latencies_ms": [1091.435], "images_per_second": 0.916, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The train is red and black, and the workers are wearing orange. The lighting is natural, and the weather is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.7, "ram_available_mb": 109161.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13355.2, "ram_available_mb": 109151.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.59, 47.59, 31.93, 31.93, 31.93, 31.93, 31.93, 45.85, 45.85, 45.85, 45.85], "power_watts_avg": 39.84, "power_watts_peak": 47.59, "energy_joules_est": 43.5, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-12T09:47:32.687055"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1398.493, "latencies_ms": [1398.493], "images_per_second": 0.715, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image shows a close-up view of a cat's fur, which is a mix of brown and white colors, and the background is a textured fabric with a diamond pattern.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13347.3, "ram_available_mb": 109159.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13350.1, "ram_available_mb": 109156.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [48.63, 48.63, 48.63, 48.63, 48.63, 47.29, 47.29, 47.29, 47.29, 47.29, 46.88, 46.88, 46.88, 46.88], "power_watts_avg": 47.65, "power_watts_peak": 48.63, "energy_joules_est": 66.65, "sample_count": 14, "duration_seconds": 1.399}, "timestamp": "2026-01-12T09:47:34.103605"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1914.833, "latencies_ms": [1914.833], "images_per_second": 0.522, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. fur: 1\n3. blanket: 1\n4. fabric: 1\n5. pattern: 1\n6. texture: 1\n7. surface: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.1, "ram_available_mb": 109156.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.88, 32.2, 32.2, 32.2, 32.2, 32.2, 47.16, 47.16, 47.16, 47.16, 47.16, 49.15, 49.15, 49.15, 49.15, 49.15, 34.2, 34.2, 34.2, 34.2], "power_watts_avg": 41.31, "power_watts_peak": 49.15, "energy_joules_est": 79.11, "sample_count": 20, "duration_seconds": 1.915}, "timestamp": "2026-01-12T09:47:36.118539"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1494.536, "latencies_ms": [1494.536], "images_per_second": 0.669, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The cat's fur is in the foreground, while the patterned fabric is in the background. The cat's fur is on the left side of the image, and the fabric is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.0, "ram_available_mb": 109112.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.2, 31.13, 31.13, 31.13, 31.13, 31.13, 45.61, 45.61, 45.61, 45.61, 45.61, 48.85, 48.85, 48.85, 48.85], "power_watts_avg": 40.89, "power_watts_peak": 48.85, "energy_joules_est": 61.12, "sample_count": 15, "duration_seconds": 1.495}, "timestamp": "2026-01-12T09:47:37.632890"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 824.776, "latencies_ms": [824.776], "images_per_second": 1.212, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is laying on a bed with a brown and white fur coat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.2, "ram_available_mb": 109120.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13376.4, "ram_available_mb": 109129.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.85, 32.79, 32.79, 32.79, 32.79, 32.79, 47.05, 47.05, 47.05], "power_watts_avg": 39.33, "power_watts_peak": 48.85, "energy_joules_est": 32.46, "sample_count": 9, "duration_seconds": 0.825}, "timestamp": "2026-01-12T09:47:38.543948"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1776.431, "latencies_ms": [1776.431], "images_per_second": 0.563, "prompt_tokens": 1110, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a close-up of a cat's fur, which is a mix of brown and white colors. The lighting appears to be natural, coming from the top left corner of the image, and the material of the fur is soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.5, "ram_available_mb": 109133.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.7, "ram_available_mb": 109153.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.05, 47.05, 47.81, 47.81, 47.81, 47.81, 47.81, 45.87, 45.87, 45.87, 45.87, 45.87, 46.95, 46.95, 46.95, 46.95, 46.95, 34.24], "power_watts_avg": 46.19, "power_watts_peak": 47.81, "energy_joules_est": 82.07, "sample_count": 18, "duration_seconds": 1.777}, "timestamp": "2026-01-12T09:47:40.360173"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1456.812, "latencies_ms": [1456.812], "images_per_second": 0.686, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a close-up view of a cow's udder, which is attached to a black and yellow label, with the cow's legs and a black object in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.7, "ram_available_mb": 109153.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.24, 34.24, 34.24, 34.24, 42.6, 42.6, 42.6, 42.6, 42.6, 47.05, 47.05, 47.05, 47.05, 47.05, 38.49], "power_watts_avg": 41.58, "power_watts_peak": 47.05, "energy_joules_est": 60.6, "sample_count": 15, "duration_seconds": 1.457}, "timestamp": "2026-01-12T09:47:41.873170"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1518.727, "latencies_ms": [1518.727], "images_per_second": 0.658, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " cow: 1, black: 1, white: 1, red: 1, black and white: 1, metal: 1, yellow: 1, plastic: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13377.4, "ram_available_mb": 109128.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.49, 38.49, 38.49, 38.49, 41.41, 41.41, 41.41, 41.41, 41.41, 46.41, 46.41, 46.41, 46.41, 46.41, 40.24, 40.24], "power_watts_avg": 42.1, "power_watts_peak": 46.41, "energy_joules_est": 63.95, "sample_count": 16, "duration_seconds": 1.519}, "timestamp": "2026-01-12T09:47:43.487291"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1906.809, "latencies_ms": [1906.809], "images_per_second": 0.524, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The cow's udder is positioned in the foreground, with the black and white cow's body extending into the background. The red and white tubes are attached to the cow's udder, and the black and yellow label is visible on the black object in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.4, "ram_available_mb": 109128.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13369.9, "ram_available_mb": 109136.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.24, 40.24, 35.85, 35.85, 35.85, 35.85, 35.85, 45.62, 45.62, 45.62, 45.62, 45.62, 44.35, 44.35, 44.35, 44.35, 44.35, 34.3, 34.3], "power_watts_avg": 40.95, "power_watts_peak": 45.62, "energy_joules_est": 78.1, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T09:47:45.401559"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 973.213, "latencies_ms": [973.213], "images_per_second": 1.028, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cow is milking itself in a barn, with a black and white cow standing next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.9, "ram_available_mb": 109136.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13429.9, "ram_available_mb": 109076.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.3, 34.3, 34.3, 37.99, 37.99, 37.99, 37.99, 37.99, 46.68, 46.68], "power_watts_avg": 38.62, "power_watts_peak": 46.68, "energy_joules_est": 37.63, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-12T09:47:46.464397"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1715.097, "latencies_ms": [1715.097], "images_per_second": 0.583, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a black and white cow with red and white tubes attached to its udder, standing on a dirty floor. The lighting is dim, and the cow is positioned in a stall with a black and yellow label on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.9, "ram_available_mb": 109080.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13393.5, "ram_available_mb": 109112.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.68, 46.68, 46.68, 46.81, 46.81, 46.81, 46.81, 46.81, 46.91, 46.91, 46.91, 46.91, 46.91, 44.09, 44.09, 44.09, 44.09, 44.09], "power_watts_avg": 46.06, "power_watts_peak": 46.91, "energy_joules_est": 79.03, "sample_count": 18, "duration_seconds": 1.716}, "timestamp": "2026-01-12T09:47:48.282402"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 925.812, "latencies_ms": [925.812], "images_per_second": 1.08, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A sandwich with a bite taken out of it is on a plate with a knife beside it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.6, "ram_available_mb": 109120.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.33, 34.33, 34.33, 34.33, 44.48, 44.48, 44.48, 44.48, 44.48, 45.8], "power_watts_avg": 40.56, "power_watts_peak": 45.8, "energy_joules_est": 37.55, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-12T09:47:49.297026"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1066.468, "latencies_ms": [1066.468], "images_per_second": 0.938, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " plate: 1, knife: 1, sandwich: 1, bread: 2, butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.2, "ram_available_mb": 109125.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13391.1, "ram_available_mb": 109115.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.8, 45.8, 45.8, 45.8, 45.39, 45.39, 45.39, 45.39, 45.39, 45.97, 45.97], "power_watts_avg": 45.65, "power_watts_peak": 45.97, "energy_joules_est": 48.71, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T09:47:50.410254"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1562.728, "latencies_ms": [1562.728], "images_per_second": 0.64, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the image, with the knife placed to the right of it. The plate is situated in the middle of the image, with the sandwich and knife placed on top of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.1, "ram_available_mb": 109115.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.97, 45.97, 45.97, 42.83, 42.83, 42.83, 42.83, 42.83, 46.66, 46.66, 46.66, 46.66, 46.66, 41.04, 41.04, 41.04], "power_watts_avg": 44.28, "power_watts_peak": 46.66, "energy_joules_est": 69.23, "sample_count": 16, "duration_seconds": 1.563}, "timestamp": "2026-01-12T09:47:52.026022"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 799.78, "latencies_ms": [799.78], "images_per_second": 1.25, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate with a sandwich and a knife on a green tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.8, "ram_available_mb": 109142.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13382.6, "ram_available_mb": 109123.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 11.0}, "power_stats": {"power_watts_samples": [41.04, 41.04, 34.73, 34.73, 34.73, 34.73, 34.73, 46.53], "power_watts_avg": 37.78, "power_watts_peak": 46.53, "energy_joules_est": 30.24, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-12T09:47:52.835927"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1249.168, "latencies_ms": [1249.168], "images_per_second": 0.801, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The sandwich is on a plate with a knife and the plate is on a green tablecloth. The lighting is dim and the sandwich is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.6, "ram_available_mb": 109123.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13287.8, "ram_available_mb": 109218.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.53, 46.53, 46.53, 46.53, 56.52, 56.52, 56.52, 56.52, 56.52, 47.58, 47.58, 47.58, 47.58], "power_watts_avg": 50.69, "power_watts_peak": 56.52, "energy_joules_est": 63.34, "sample_count": 13, "duration_seconds": 1.249}, "timestamp": "2026-01-12T09:47:54.149942"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1519.386, "latencies_ms": [1519.386], "images_per_second": 0.658, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image shows a colorful and well-organized meal in a purple divided container, featuring a variety of food items such as a salad, pasta with cheese, and grapes, all neatly arranged in separate compartments.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13287.8, "ram_available_mb": 109218.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.2, "ram_available_mb": 109172.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.58, 36.89, 36.89, 36.89, 36.89, 36.89, 46.16, 46.16, 46.16, 46.16, 46.16, 48.16, 48.16, 48.16, 48.16, 48.16], "power_watts_avg": 43.97, "power_watts_peak": 48.16, "energy_joules_est": 66.84, "sample_count": 16, "duration_seconds": 1.52}, "timestamp": "2026-01-12T09:47:55.768199"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1417.376, "latencies_ms": [1417.376], "images_per_second": 0.706, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " 1. purple tray\n2. orange container\n3. green container\n4. red container\n5. blue container\n6. carrots\n7. grapes\n8. salad", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.3, "ram_available_mb": 109180.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13329.0, "ram_available_mb": 109177.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.0, 34.0, 34.0, 34.0, 34.0, 44.93, 44.93, 44.93, 44.93, 44.93, 45.56, 45.56, 45.56, 45.56, 45.56], "power_watts_avg": 41.49, "power_watts_peak": 45.56, "energy_joules_est": 58.84, "sample_count": 15, "duration_seconds": 1.418}, "timestamp": "2026-01-12T09:47:57.285446"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2377.207, "latencies_ms": [2377.207], "images_per_second": 0.421, "prompt_tokens": 1117, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The main objects are arranged in a specific spatial relationship, with the salad in the top left, the pasta in the bottom left, the carrots in the top right, and the grapes in the bottom right. The carrots are positioned near the top right, while the grapes are near the bottom right. The salad is in the foreground, while the pasta is in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13321.1, "ram_available_mb": 109185.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13313.7, "ram_available_mb": 109192.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 34.9, 44.25, 44.25, 44.25, 44.25, 44.25, 45.85, 45.85, 45.85, 45.85, 45.85, 35.71, 35.71, 35.71, 35.71, 35.71, 34.36, 34.36, 34.36, 34.36, 34.36], "power_watts_avg": 39.18, "power_watts_peak": 45.85, "energy_joules_est": 93.17, "sample_count": 24, "duration_seconds": 2.378}, "timestamp": "2026-01-12T09:47:59.706134"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1096.978, "latencies_ms": [1096.978], "images_per_second": 0.912, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A colorful meal is served in a purple divided container, with a variety of food items including pasta, vegetables, and fruit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.7, "ram_available_mb": 109192.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13327.4, "ram_available_mb": 109178.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.03, 34.03, 34.03, 34.03, 34.03, 45.62, 45.62, 45.62, 45.62, 45.62, 46.15], "power_watts_avg": 40.4, "power_watts_peak": 46.15, "energy_joules_est": 44.35, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-12T09:48:00.870583"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2289.17, "latencies_ms": [2289.17], "images_per_second": 0.437, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image features a vibrant and colorful meal in a purple divided container, with a variety of food items including pasta, vegetables, and fruits. The lighting is bright and even, illuminating the food items and creating a visually appealing presentation. The container is made of plastic, and the food is fresh and healthy, suggesting a well-balanced and nutritious meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.4, "ram_available_mb": 109178.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13314.0, "ram_available_mb": 109192.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.15, 46.15, 46.15, 46.15, 43.21, 43.21, 43.21, 43.21, 43.21, 47.2, 47.2, 47.2, 47.2, 47.2, 39.34, 39.34, 39.34, 39.34, 39.34, 34.4, 34.4, 34.4, 34.4], "power_watts_avg": 42.22, "power_watts_peak": 47.2, "energy_joules_est": 96.66, "sample_count": 23, "duration_seconds": 2.29}, "timestamp": "2026-01-12T09:48:03.185548"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 806.021, "latencies_ms": [806.021], "images_per_second": 1.241, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A traffic light hangs above a street with cherry blossoms in full bloom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13314.0, "ram_available_mb": 109192.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13300.6, "ram_available_mb": 109205.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.97, 33.97, 33.97, 33.97, 33.97, 46.13, 46.13, 46.13, 46.13], "power_watts_avg": 39.37, "power_watts_peak": 46.13, "energy_joules_est": 31.77, "sample_count": 9, "duration_seconds": 0.807}, "timestamp": "2026-01-12T09:48:04.148808"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 646.364, "latencies_ms": [646.364], "images_per_second": 1.547, "prompt_tokens": 1114, "response_tokens_est": 8, "n_tiles": 1, "output_text": " 1. traffic light: 3", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13292.8, "ram_available_mb": 109213.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13336.1, "ram_available_mb": 109170.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 20.0}, "power_stats": {"power_watts_samples": [46.13, 43.31, 43.31, 43.31, 43.31, 43.31, 45.74], "power_watts_avg": 44.06, "power_watts_peak": 46.13, "energy_joules_est": 28.51, "sample_count": 7, "duration_seconds": 0.647}, "timestamp": "2026-01-12T09:48:04.860748"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1612.958, "latencies_ms": [1612.958], "images_per_second": 0.62, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The traffic light is positioned to the left of the cherry blossoms, and the traffic light is in the foreground of the image. The cherry blossoms are in the background of the image, and they are positioned behind the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.3, "ram_available_mb": 109180.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13320.6, "ram_available_mb": 109185.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.74, 45.74, 45.74, 45.74, 56.06, 56.06, 56.06, 56.06, 56.06, 46.28, 46.28, 46.28, 46.28, 46.28, 38.93, 38.93, 38.93], "power_watts_avg": 47.74, "power_watts_peak": 56.06, "energy_joules_est": 77.02, "sample_count": 17, "duration_seconds": 1.613}, "timestamp": "2026-01-12T09:48:06.576970"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1839.577, "latencies_ms": [1839.577], "images_per_second": 0.544, "prompt_tokens": 1112, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a serene scene of a cherry blossom tree in full bloom, with its branches adorned with delicate pink and white flowers. The tree stands in front of a traffic light, which is currently displaying a red signal, indicating a halt in the flow of traffic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.7, "ram_available_mb": 109189.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13327.5, "ram_available_mb": 109178.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.93, 38.93, 31.56, 31.56, 31.56, 31.56, 31.56, 45.43, 45.43, 45.43, 45.43, 45.43, 48.54, 48.54, 48.54, 48.54, 34.36, 34.36, 34.36], "power_watts_avg": 40.0, "power_watts_peak": 48.54, "energy_joules_est": 73.61, "sample_count": 19, "duration_seconds": 1.84}, "timestamp": "2026-01-12T09:48:08.493484"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1156.681, "latencies_ms": [1156.681], "images_per_second": 0.865, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a cherry blossom tree with pink flowers, a traffic light with red and green lights, and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.5, "ram_available_mb": 109178.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13406.4, "ram_available_mb": 109099.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [34.36, 34.36, 32.24, 32.24, 32.24, 32.24, 32.24, 45.18, 45.18, 45.18, 45.18, 45.18], "power_watts_avg": 37.99, "power_watts_peak": 45.18, "energy_joules_est": 43.96, "sample_count": 12, "duration_seconds": 1.157}, "timestamp": "2026-01-12T09:48:09.753768"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1142.316, "latencies_ms": [1142.316], "images_per_second": 0.875, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a plate with a serving of broccoli and a piece of salmon, with the broccoli being the main focus of the dish.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13406.4, "ram_available_mb": 109099.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.8, "ram_available_mb": 109129.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [47.77, 47.77, 47.77, 47.77, 47.77, 46.38, 46.38, 46.38, 46.38, 46.38, 46.77, 46.77], "power_watts_avg": 47.02, "power_watts_peak": 47.77, "energy_joules_est": 53.72, "sample_count": 12, "duration_seconds": 1.142}, "timestamp": "2026-01-12T09:48:10.967416"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1994.135, "latencies_ms": [1994.135], "images_per_second": 0.501, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Broccoli: 12\n2. Salmon: 1\n3. Plate: 1\n4. Sauce: 1\n5. Cheese: 1\n6. Pepper: 1\n7. Garlic: 1\n8. Oil: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.8, "ram_available_mb": 109129.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.77, 46.77, 46.77, 38.0, 38.0, 38.0, 38.0, 38.0, 46.35, 46.35, 46.35, 46.35, 46.35, 43.43, 43.43, 43.43, 43.43, 43.43, 34.23, 34.23], "power_watts_avg": 42.39, "power_watts_peak": 46.77, "energy_joules_est": 84.56, "sample_count": 20, "duration_seconds": 1.995}, "timestamp": "2026-01-12T09:48:12.983647"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1091.496, "latencies_ms": [1091.496], "images_per_second": 0.916, "prompt_tokens": 1117, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The broccoli is in the foreground, while the salmon is in the background. The broccoli is to the left of the salmon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.1, "ram_available_mb": 109161.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13357.6, "ram_available_mb": 109148.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 6.0}, "power_stats": {"power_watts_samples": [34.23, 34.23, 34.22, 34.22, 34.22, 34.22, 34.22, 46.17, 46.17, 46.17, 46.17], "power_watts_avg": 38.57, "power_watts_peak": 46.17, "energy_joules_est": 42.12, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-12T09:48:14.144997"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1411.882, "latencies_ms": [1411.882], "images_per_second": 0.708, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, there is a plate of food that includes broccoli and salmon. The broccoli is green and appears to be cooked, while the salmon is orange and appears to be grilled.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.7, "ram_available_mb": 109156.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13262.7, "ram_available_mb": 109243.6, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.17, 46.06, 46.06, 46.06, 46.06, 46.06, 47.08, 47.08, 47.08, 47.08, 47.08, 48.44, 48.44, 48.44, 48.44], "power_watts_avg": 47.04, "power_watts_peak": 48.44, "energy_joules_est": 66.44, "sample_count": 15, "duration_seconds": 1.412}, "timestamp": "2026-01-12T09:48:15.657626"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2255.636, "latencies_ms": [2255.636], "images_per_second": 0.443, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a plate of food with a vibrant green broccoli dish and a piece of grilled salmon. The broccoli is cooked to a tender consistency, and the salmon is seasoned with a light glaze. The plate is white, and the food is placed on a white tablecloth. The lighting is bright and even, highlighting the colors of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13262.7, "ram_available_mb": 109243.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13303.9, "ram_available_mb": 109202.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.44, 31.85, 31.85, 31.85, 31.85, 31.85, 45.74, 45.74, 45.74, 45.74, 45.74, 48.17, 48.17, 48.17, 48.17, 48.17, 34.27, 34.27, 34.27, 34.27, 34.27, 34.28, 34.28], "power_watts_avg": 39.88, "power_watts_peak": 48.44, "energy_joules_est": 89.96, "sample_count": 23, "duration_seconds": 2.256}, "timestamp": "2026-01-12T09:48:17.974872"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1113.795, "latencies_ms": [1113.795], "images_per_second": 0.898, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are sitting on a bench in a restaurant, with a woman eating a sandwich and a man eating a sandwich.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.9, "ram_available_mb": 109202.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.28, 34.28, 33.63, 33.63, 33.63, 33.63, 33.63, 45.49, 45.49, 45.49, 45.49, 45.49], "power_watts_avg": 38.68, "power_watts_peak": 45.49, "energy_joules_est": 43.11, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-12T09:48:19.241818"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1913.173, "latencies_ms": [1913.173], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 3\n2. chair: 1\n3. table: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.2, "ram_available_mb": 109158.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.01, 46.01, 46.01, 46.01, 46.01, 45.52, 45.52, 45.52, 45.52, 45.52, 46.53, 46.53, 46.53, 46.53, 46.53, 34.25, 34.25, 34.25, 34.25, 34.25], "power_watts_avg": 43.08, "power_watts_peak": 46.53, "energy_joules_est": 82.44, "sample_count": 20, "duration_seconds": 1.914}, "timestamp": "2026-01-12T09:48:21.260879"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1974.551, "latencies_ms": [1974.551], "images_per_second": 0.506, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The person on the left is sitting next to the person in the middle, who is sitting next to the person on the right. The person on the left is closer to the camera than the person in the middle. The person on the right is sitting in front of the person in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.1, "ram_available_mb": 109175.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13326.8, "ram_available_mb": 109179.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.76, 33.76, 33.76, 33.76, 33.76, 45.84, 45.84, 45.84, 45.84, 45.84, 45.83, 45.83, 45.83, 45.83, 45.83, 35.21, 35.21, 35.21, 35.21, 35.21], "power_watts_avg": 40.16, "power_watts_peak": 45.84, "energy_joules_est": 79.3, "sample_count": 20, "duration_seconds": 1.975}, "timestamp": "2026-01-12T09:48:23.279002"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 763.736, "latencies_ms": [763.736], "images_per_second": 1.309, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A family of three is sitting at a table in a restaurant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.8, "ram_available_mb": 109179.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13377.1, "ram_available_mb": 109129.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.37, 34.37, 34.37, 34.37, 43.15, 43.15, 43.15, 43.15], "power_watts_avg": 38.76, "power_watts_peak": 43.15, "energy_joules_est": 29.62, "sample_count": 8, "duration_seconds": 0.764}, "timestamp": "2026-01-12T09:48:24.139000"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1477.082, "latencies_ms": [1477.082], "images_per_second": 0.677, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image is taken in a dimly lit restaurant with warm lighting. The colors in the image are mostly warm tones, with the red of the wall and the black of the tablecloth standing out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.2, "ram_available_mb": 109133.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13362.5, "ram_available_mb": 109143.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.15, 44.41, 44.41, 44.41, 44.41, 44.41, 50.41, 50.41, 50.41, 50.41, 50.41, 48.73, 48.73, 48.73, 48.73], "power_watts_avg": 47.48, "power_watts_peak": 50.41, "energy_joules_est": 70.15, "sample_count": 15, "duration_seconds": 1.478}, "timestamp": "2026-01-12T09:48:25.655691"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1529.258, "latencies_ms": [1529.258], "images_per_second": 0.654, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a bustling city street with a yellow bus parked on the side of the road, a white van and a white bus in the background, and a large building with numerous windows in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.7, "ram_available_mb": 109151.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13340.4, "ram_available_mb": 109165.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.73, 33.14, 33.14, 33.14, 33.14, 33.14, 46.87, 46.87, 46.87, 46.87, 46.87, 47.45, 47.45, 47.45, 47.45, 47.45], "power_watts_avg": 42.88, "power_watts_peak": 48.73, "energy_joules_est": 65.57, "sample_count": 16, "duration_seconds": 1.529}, "timestamp": "2026-01-12T09:48:27.273724"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2073.028, "latencies_ms": [2073.028], "images_per_second": 0.482, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Bus: 2\n2. Street: 1\n3. Building: 1\n4. Trees: 3\n5. Benches: 1\n6. Streetlamp: 1\n7. Sidewalk: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.4, "ram_available_mb": 109165.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13322.6, "ram_available_mb": 109183.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 34.11, 34.11, 44.74, 44.74, 44.74, 44.74, 44.74, 46.03, 46.03, 46.03, 46.03, 46.03, 36.33, 36.33, 36.33, 36.33, 36.33, 34.32], "power_watts_avg": 40.02, "power_watts_peak": 46.03, "energy_joules_est": 82.97, "sample_count": 21, "duration_seconds": 2.073}, "timestamp": "2026-01-12T09:48:29.390261"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1435.79, "latencies_ms": [1435.79], "images_per_second": 0.696, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The yellow bus is parked on the side of the road, while the white bus is driving down the road. The building is located in the background, and the trees are in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13322.6, "ram_available_mb": 109183.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13360.3, "ram_available_mb": 109146.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.32, 34.32, 34.32, 37.45, 37.45, 37.45, 37.45, 37.45, 45.65, 45.65, 45.65, 45.65, 45.65, 42.73, 42.73], "power_watts_avg": 40.26, "power_watts_peak": 45.65, "energy_joules_est": 57.84, "sample_count": 15, "duration_seconds": 1.437}, "timestamp": "2026-01-12T09:48:30.957167"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1783.334, "latencies_ms": [1783.334], "images_per_second": 0.561, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a bustling city street with a large building in the background. A bus is driving down the road, while a yellow bus is parked on the side of the road. The street is lined with trees and buildings, creating a vibrant urban atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.3, "ram_available_mb": 109146.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 37.22, 37.22, 37.22, 37.22, 37.22, 46.17, 46.17, 46.17, 46.17, 46.17, 43.96, 43.96, 43.96, 43.96, 43.96], "power_watts_avg": 42.5, "power_watts_peak": 46.17, "energy_joules_est": 75.81, "sample_count": 18, "duration_seconds": 1.784}, "timestamp": "2026-01-12T09:48:32.775900"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1356.271, "latencies_ms": [1356.271], "images_per_second": 0.737, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a vibrant yellow bus parked on the side of the road, with a white building in the background. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.5, "ram_available_mb": 109149.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.26, 34.26, 34.26, 34.26, 34.26, 45.92, 45.92, 45.92, 45.92, 45.92, 47.0, 47.0, 47.0, 47.0], "power_watts_avg": 42.06, "power_watts_peak": 47.0, "energy_joules_est": 57.07, "sample_count": 14, "duration_seconds": 1.357}, "timestamp": "2026-01-12T09:48:34.192115"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1194.301, "latencies_ms": [1194.301], "images_per_second": 0.837, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image captures a stop sign standing tall on a pole, with a sunbeam filtering through the trees, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.6, "ram_available_mb": 109157.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13370.2, "ram_available_mb": 109136.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.0, 35.24, 35.24, 35.24, 35.24, 46.54, 46.54, 46.54, 46.54, 46.54, 47.46, 47.46], "power_watts_avg": 42.97, "power_watts_peak": 47.46, "energy_joules_est": 51.34, "sample_count": 12, "duration_seconds": 1.195}, "timestamp": "2026-01-12T09:48:35.408305"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1976.258, "latencies_ms": [1976.258], "images_per_second": 0.506, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. stop sign: 1\n2. pole: 1\n3. railing: 1\n4. building: 1\n5. car: 1\n6. street: 1\n7. sidewalk: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13274.9, "ram_available_mb": 109231.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.46, 47.46, 47.46, 40.5, 40.5, 40.5, 40.5, 40.5, 47.37, 47.37, 47.37, 47.37, 47.37, 41.07, 41.07, 41.07, 41.07, 41.07, 34.29, 34.29], "power_watts_avg": 42.78, "power_watts_peak": 47.46, "energy_joules_est": 84.56, "sample_count": 20, "duration_seconds": 1.977}, "timestamp": "2026-01-12T09:48:37.428410"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1909.188, "latencies_ms": [1909.188], "images_per_second": 0.524, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The stop sign is located in the foreground on the left side of the image, with the sun positioned behind it, casting a warm glow and creating a lens flare effect. In the background, there is a parking lot with several cars parked, and a building with multiple windows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13274.9, "ram_available_mb": 109231.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13269.6, "ram_available_mb": 109236.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.29, 34.29, 34.29, 34.04, 34.04, 34.04, 34.04, 34.04, 45.19, 45.19, 45.19, 45.19, 45.19, 46.03, 46.03, 46.03, 46.03, 46.03, 34.31, 34.31], "power_watts_avg": 39.89, "power_watts_peak": 46.03, "energy_joules_est": 76.2, "sample_count": 20, "duration_seconds": 1.91}, "timestamp": "2026-01-12T09:48:39.490764"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2315.245, "latencies_ms": [2315.245], "images_per_second": 0.432, "prompt_tokens": 1112, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a serene urban scene during sunset, where a stop sign stands prominently in the foreground, casting a warm glow on the surroundings. In the background, a parking lot is visible, with a few cars parked neatly, and a building with a sign that reads \"\u041c\u0410\u0420\u041a\u0415\u0422\" can be seen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13269.3, "ram_available_mb": 109237.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13303.5, "ram_available_mb": 109202.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.31, 34.31, 31.97, 31.97, 31.97, 31.97, 31.97, 44.66, 44.66, 44.66, 44.66, 44.66, 47.42, 47.42, 47.42, 47.42, 47.42, 34.14, 34.14, 34.14, 34.14, 34.14, 34.42, 34.42], "power_watts_avg": 38.68, "power_watts_peak": 47.42, "energy_joules_est": 89.59, "sample_count": 24, "duration_seconds": 2.316}, "timestamp": "2026-01-12T09:48:41.960488"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1408.286, "latencies_ms": [1408.286], "images_per_second": 0.71, "prompt_tokens": 1110, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a red stop sign with a white \"STOP\" written on it, standing on a metal pole. The sun is shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.5, "ram_available_mb": 109202.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.2, "ram_available_mb": 109165.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.42, 34.42, 33.17, 33.17, 33.17, 33.17, 33.17, 44.42, 44.42, 44.42, 44.42, 44.42, 46.57, 46.57, 46.57], "power_watts_avg": 39.77, "power_watts_peak": 46.57, "energy_joules_est": 56.02, "sample_count": 15, "duration_seconds": 1.409}, "timestamp": "2026-01-12T09:48:43.522557"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 980.779, "latencies_ms": [980.779], "images_per_second": 1.02, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cat with a white and brown coat is lying on a black surface next to a white computer mouse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.2, "ram_available_mb": 109165.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13338.7, "ram_available_mb": 109167.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.57, 46.57, 34.27, 34.27, 34.27, 34.27, 34.27, 45.71, 45.71, 45.71], "power_watts_avg": 40.16, "power_watts_peak": 46.57, "energy_joules_est": 39.39, "sample_count": 10, "duration_seconds": 0.981}, "timestamp": "2026-01-12T09:48:44.534886"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1364.376, "latencies_ms": [1364.376], "images_per_second": 0.733, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cat: 1, mouse: 1, cord: 1, black: 1, white: 1, brown: 1, black and white: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.8, "ram_available_mb": 109175.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.71, 45.71, 47.26, 47.26, 47.26, 47.26, 47.26, 47.01, 47.01, 47.01, 47.01, 47.01, 46.63, 46.63], "power_watts_avg": 46.86, "power_watts_peak": 47.26, "energy_joules_est": 63.95, "sample_count": 14, "duration_seconds": 1.365}, "timestamp": "2026-01-12T09:48:45.945196"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1513.031, "latencies_ms": [1513.031], "images_per_second": 0.661, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The cat is in the foreground, lying on a black surface. The mouse is in the foreground, to the left of the cat. The cord is in the foreground, to the right of the cat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13389.9, "ram_available_mb": 109116.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.63, 46.63, 46.63, 38.97, 38.97, 38.97, 38.97, 38.97, 46.65, 46.65, 46.65, 46.65, 46.65, 42.38, 42.38, 42.38], "power_watts_avg": 43.45, "power_watts_peak": 46.65, "energy_joules_est": 65.75, "sample_count": 16, "duration_seconds": 1.513}, "timestamp": "2026-01-12T09:48:47.559072"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 826.535, "latencies_ms": [826.535], "images_per_second": 1.21, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is lying on a bed with a computer mouse next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.0, "ram_available_mb": 109124.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.38, 42.38, 32.63, 32.63, 32.63, 32.63, 32.63, 45.84, 45.84], "power_watts_avg": 37.73, "power_watts_peak": 45.84, "energy_joules_est": 31.2, "sample_count": 9, "duration_seconds": 0.827}, "timestamp": "2026-01-12T09:48:48.469263"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 848.567, "latencies_ms": [848.567], "images_per_second": 1.178, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The cat is white and brown with green eyes, and the mouse is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.0, "ram_available_mb": 109115.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13399.2, "ram_available_mb": 109107.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.84, 45.84, 45.84, 50.72, 50.72, 50.72, 50.72, 50.72, 46.2], "power_watts_avg": 48.59, "power_watts_peak": 50.72, "energy_joules_est": 41.25, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-12T09:48:49.378264"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1244.251, "latencies_ms": [1244.251], "images_per_second": 0.804, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large parking lot filled with buses, a prominent white building, and a red and white tower in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.3, "ram_available_mb": 109111.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13395.5, "ram_available_mb": 109110.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.2, 46.2, 46.2, 46.2, 51.04, 51.04, 51.04, 51.04, 51.04, 46.36, 46.36, 46.36, 46.36], "power_watts_avg": 48.11, "power_watts_peak": 51.04, "energy_joules_est": 59.89, "sample_count": 13, "duration_seconds": 1.245}, "timestamp": "2026-01-12T09:48:50.693639"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1903.19, "latencies_ms": [1903.19], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Bus: 3\n2. Bus: 2\n3. Bus: 1\n4. Bus: 1\n5. Bus: 1\n6. Bus: 1\n7. Bus: 1\n8. Bus: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.7, "ram_available_mb": 109118.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.2, "ram_available_mb": 109142.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.36, 39.43, 39.43, 39.43, 39.43, 39.43, 46.32, 46.32, 46.32, 46.32, 47.61, 47.61, 47.61, 47.61, 47.61, 34.26, 34.26, 34.26, 34.26], "power_watts_avg": 42.31, "power_watts_peak": 47.61, "energy_joules_est": 80.54, "sample_count": 19, "duration_seconds": 1.904}, "timestamp": "2026-01-12T09:48:52.611434"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1272.651, "latencies_ms": [1272.651], "images_per_second": 0.786, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The buses are positioned in the foreground, with the buildings in the background. The trees are located near the buses, while the overpass is situated further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.2, "ram_available_mb": 109142.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13354.1, "ram_available_mb": 109152.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.26, 32.68, 32.68, 32.68, 32.68, 32.68, 47.5, 47.5, 47.5, 47.5, 47.5, 49.1, 49.1], "power_watts_avg": 41.03, "power_watts_peak": 49.1, "energy_joules_est": 52.23, "sample_count": 13, "duration_seconds": 1.273}, "timestamp": "2026-01-12T09:48:53.924749"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1167.32, "latencies_ms": [1167.32], "images_per_second": 0.857, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large parking lot filled with buses and cars, surrounded by tall buildings and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13411.6, "ram_available_mb": 109094.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [49.1, 49.1, 49.1, 39.72, 39.72, 39.72, 39.72, 39.72, 46.7, 46.7, 46.7, 46.7], "power_watts_avg": 44.39, "power_watts_peak": 49.1, "energy_joules_est": 51.83, "sample_count": 12, "duration_seconds": 1.168}, "timestamp": "2026-01-12T09:48:55.138444"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1317.596, "latencies_ms": [1317.596], "images_per_second": 0.759, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features a vibrant cityscape with a mix of green and white buildings, a clear blue sky with white clouds, and a bustling street with several buses and cars.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.6, "ram_available_mb": 109094.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13414.5, "ram_available_mb": 109091.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.7, 40.73, 40.73, 40.73, 40.73, 40.73, 47.1, 47.1, 47.1, 47.1, 47.1, 48.68, 48.68, 48.68], "power_watts_avg": 45.14, "power_watts_peak": 48.68, "energy_joules_est": 59.49, "sample_count": 14, "duration_seconds": 1.318}, "timestamp": "2026-01-12T09:48:56.554574"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1164.329, "latencies_ms": [1164.329], "images_per_second": 0.859, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man wearing a cowboy hat and shorts is skateboarding on a ramp in a skate park, with a large tent in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.7, "ram_available_mb": 109099.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13395.3, "ram_available_mb": 109111.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.68, 48.68, 32.79, 32.79, 32.79, 32.79, 32.79, 45.68, 45.68, 45.68, 45.68, 45.68], "power_watts_avg": 40.81, "power_watts_peak": 48.68, "energy_joules_est": 47.52, "sample_count": 12, "duration_seconds": 1.164}, "timestamp": "2026-01-12T09:48:57.769944"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1932.955, "latencies_ms": [1932.955], "images_per_second": 0.517, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. shorts: 1\n4. skateboard: 1\n5. ramp: 1\n6. shadow: 1\n7. tent: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.3, "ram_available_mb": 109115.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.11, 48.11, 48.11, 48.11, 48.11, 46.15, 46.15, 46.15, 46.15, 46.15, 46.65, 46.65, 46.65, 46.65, 46.65, 34.85, 34.85, 34.85, 34.85, 34.85], "power_watts_avg": 43.94, "power_watts_peak": 48.11, "energy_joules_est": 84.96, "sample_count": 20, "duration_seconds": 1.934}, "timestamp": "2026-01-12T09:48:59.790443"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1931.639, "latencies_ms": [1931.639], "images_per_second": 0.518, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, performing a trick on the ramp, while the tents are located in the background, providing a contrast between the foreground and background elements. The shadow of the skateboarder is cast on the ramp, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.0, "ram_available_mb": 109141.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13332.5, "ram_available_mb": 109173.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.32, 34.32, 34.32, 34.32, 42.05, 42.05, 42.05, 42.05, 42.05, 45.04, 45.04, 45.04, 45.04, 45.04, 37.31, 37.31, 37.31, 37.31, 37.31, 34.41], "power_watts_avg": 39.68, "power_watts_peak": 45.04, "energy_joules_est": 76.68, "sample_count": 20, "duration_seconds": 1.932}, "timestamp": "2026-01-12T09:49:01.859480"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1043.283, "latencies_ms": [1043.283], "images_per_second": 0.959, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is riding a skateboard on a ramp. There are tents in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13336.4, "ram_available_mb": 109169.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13398.8, "ram_available_mb": 109107.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.41, 34.41, 34.41, 38.98, 38.98, 38.98, 38.98, 38.98, 45.04, 45.04, 45.04], "power_watts_avg": 39.39, "power_watts_peak": 45.04, "energy_joules_est": 41.11, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-12T09:49:03.023750"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1535.38, "latencies_ms": [1535.38], "images_per_second": 0.651, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a ramp, with a clear blue sky in the background. The skateboarder is wearing a hat and shorts, and the ramp is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.9, "ram_available_mb": 109115.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13388.6, "ram_available_mb": 109117.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.04, 45.04, 42.13, 42.13, 42.13, 42.13, 42.13, 46.16, 46.16, 46.16, 46.16, 46.16, 45.3, 45.3, 45.3, 45.3], "power_watts_avg": 44.55, "power_watts_peak": 46.16, "energy_joules_est": 68.41, "sample_count": 16, "duration_seconds": 1.536}, "timestamp": "2026-01-12T09:49:04.638779"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1199.75, "latencies_ms": [1199.75], "images_per_second": 0.834, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is standing on a surfboard with a windsurfing board attached to it, and there are several kites flying in the sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13380.7, "ram_available_mb": 109125.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13374.5, "ram_available_mb": 109131.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.3, 31.65, 31.65, 31.65, 31.65, 31.65, 45.91, 45.91, 45.91, 45.91, 45.91, 48.88], "power_watts_avg": 40.17, "power_watts_peak": 48.88, "energy_joules_est": 48.2, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-12T09:49:05.853350"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2104.997, "latencies_ms": [2104.997], "images_per_second": 0.475, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. person: 1\n2. windsurf board: 1\n3. kite: 2\n4. ocean: 1\n5. kiteboarder: 1\n6. kite: 1\n7. kiteboarder: 1\n8. kite: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.5, "ram_available_mb": 109135.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.88, 48.88, 48.88, 48.88, 43.79, 43.79, 43.79, 43.79, 43.79, 47.21, 47.21, 47.21, 47.21, 47.21, 37.81, 37.81, 37.81, 37.81, 37.81, 34.22, 34.22], "power_watts_avg": 43.24, "power_watts_peak": 48.88, "energy_joules_est": 91.03, "sample_count": 21, "duration_seconds": 2.105}, "timestamp": "2026-01-12T09:49:07.973619"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1636.211, "latencies_ms": [1636.211], "images_per_second": 0.611, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The kiteboarder is positioned in the foreground, with the ocean and kites in the background. The kites are flying at varying heights, with some closer to the kiteboarder and others higher up in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.9, "ram_available_mb": 109146.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13378.6, "ram_available_mb": 109127.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.22, 34.22, 35.15, 35.15, 35.15, 35.15, 35.15, 46.39, 46.39, 46.39, 46.39, 46.39, 45.98, 45.98, 45.98, 45.98, 45.98], "power_watts_avg": 41.53, "power_watts_peak": 46.39, "energy_joules_est": 67.98, "sample_count": 17, "duration_seconds": 1.637}, "timestamp": "2026-01-12T09:49:09.740126"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1109.664, "latencies_ms": [1109.664], "images_per_second": 0.901, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man is windsurfing in the ocean with a kite. The sky is blue and there are other people in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.6, "ram_available_mb": 109127.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13448.6, "ram_available_mb": 109057.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [33.31, 33.31, 33.31, 33.31, 33.31, 46.07, 46.07, 46.07, 46.07, 46.07, 47.08, 47.08], "power_watts_avg": 40.92, "power_watts_peak": 47.08, "energy_joules_est": 45.42, "sample_count": 12, "duration_seconds": 1.11}, "timestamp": "2026-01-12T09:49:10.949465"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2122.033, "latencies_ms": [2122.033], "images_per_second": 0.471, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image features a vibrant scene with a clear blue sky and a vast ocean. The water is a deep blue, and the sky is a bright blue with a few white clouds scattered across it. The kiteboarder is wearing a red shirt and black shorts, and the windsurfer is wearing a black wetsuit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13444.6, "ram_available_mb": 109061.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13403.1, "ram_available_mb": 109103.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.08, 47.08, 47.08, 38.25, 38.25, 38.25, 38.25, 38.25, 45.78, 45.78, 45.78, 45.78, 45.78, 42.23, 42.23, 42.23, 42.23, 42.23, 34.58, 34.58, 34.58, 34.58], "power_watts_avg": 41.4, "power_watts_peak": 47.08, "energy_joules_est": 87.87, "sample_count": 22, "duration_seconds": 2.122}, "timestamp": "2026-01-12T09:49:13.163828"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 990.078, "latencies_ms": [990.078], "images_per_second": 1.01, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " An old red fire hydrant is sitting in a grassy area in front of a house with purple flowers.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13403.1, "ram_available_mb": 109103.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13326.2, "ram_available_mb": 109180.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.06, 32.06, 32.06, 32.06, 32.06, 44.74, 44.74, 44.74, 44.74, 44.74], "power_watts_avg": 38.4, "power_watts_peak": 44.74, "energy_joules_est": 38.05, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-12T09:49:14.227887"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1125.384, "latencies_ms": [1125.384], "images_per_second": 0.889, "prompt_tokens": 1114, "response_tokens_est": 26, "n_tiles": 1, "output_text": " fire hydrant: 1\ngrass: 1\ntree: 1\nhouse: 1\nflowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.2, "ram_available_mb": 109180.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13302.6, "ram_available_mb": 109203.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.32, 47.32, 47.32, 47.32, 47.32, 47.3, 47.3, 47.3, 47.3, 47.3, 47.25, 47.25], "power_watts_avg": 47.3, "power_watts_peak": 47.32, "energy_joules_est": 53.24, "sample_count": 12, "duration_seconds": 1.126}, "timestamp": "2026-01-12T09:49:15.441406"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1544.221, "latencies_ms": [1544.221], "images_per_second": 0.648, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with the house and trees in the background. The hydrant is positioned to the left of the house, and the grass is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.6, "ram_available_mb": 109203.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13309.3, "ram_available_mb": 109197.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.25, 47.25, 47.25, 38.7, 38.7, 38.7, 38.7, 38.7, 46.09, 46.09, 46.09, 46.09, 46.09, 42.34, 42.34, 42.34], "power_watts_avg": 43.29, "power_watts_peak": 47.25, "energy_joules_est": 66.87, "sample_count": 16, "duration_seconds": 1.545}, "timestamp": "2026-01-12T09:49:17.056325"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 831.803, "latencies_ms": [831.803], "images_per_second": 1.202, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A red fire hydrant is in the grass in front of a house.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13301.4, "ram_available_mb": 109204.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [42.34, 42.34, 33.84, 33.84, 33.84, 33.84, 33.84, 46.37, 46.37], "power_watts_avg": 38.51, "power_watts_peak": 46.37, "energy_joules_est": 32.05, "sample_count": 9, "duration_seconds": 0.832}, "timestamp": "2026-01-12T09:49:17.967497"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 968.61, "latencies_ms": [968.61], "images_per_second": 1.032, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The fire hydrant is red and black, and it is in a grassy area with dandelions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.0, "ram_available_mb": 109193.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13321.5, "ram_available_mb": 109184.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [46.37, 46.37, 46.37, 50.61, 50.61, 50.61, 50.61, 50.61, 46.05, 46.05], "power_watts_avg": 48.43, "power_watts_peak": 50.61, "energy_joules_est": 46.93, "sample_count": 10, "duration_seconds": 0.969}, "timestamp": "2026-01-12T09:49:18.979861"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 992.413, "latencies_ms": [992.413], "images_per_second": 1.008, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A bird is flying over a roof with a blue hue, while other birds are on the ground nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.5, "ram_available_mb": 109188.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13311.3, "ram_available_mb": 109195.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [46.05, 46.05, 46.05, 46.23, 46.23, 46.23, 46.23, 46.23, 46.61, 46.61], "power_watts_avg": 46.25, "power_watts_peak": 46.61, "energy_joules_est": 45.93, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-12T09:49:19.993443"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1335.574, "latencies_ms": [1335.574], "images_per_second": 0.749, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bird: 1, roof: 1, wing: 1, tail: 1, beak: 1, eye: 1, beak: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13303.4, "ram_available_mb": 109202.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13315.4, "ram_available_mb": 109190.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.61, 46.61, 46.61, 47.38, 47.38, 47.38, 47.38, 47.38, 47.23, 47.23, 47.23, 47.23, 47.23, 43.88], "power_watts_avg": 46.91, "power_watts_peak": 47.38, "energy_joules_est": 62.67, "sample_count": 14, "duration_seconds": 1.336}, "timestamp": "2026-01-12T09:49:21.409277"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1415.399, "latencies_ms": [1415.399], "images_per_second": 0.707, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bird is flying towards the right side of the image, with the roof of the shed in the background. The bird is in the foreground, while the roof is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13307.5, "ram_available_mb": 109198.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13311.0, "ram_available_mb": 109195.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.88, 43.88, 43.88, 40.16, 40.16, 40.16, 40.16, 40.16, 45.93, 45.93, 45.93, 45.93, 45.93, 40.09, 40.09], "power_watts_avg": 42.82, "power_watts_peak": 45.93, "energy_joules_est": 60.63, "sample_count": 15, "duration_seconds": 1.416}, "timestamp": "2026-01-12T09:49:22.925783"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 859.739, "latencies_ms": [859.739], "images_per_second": 1.163, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is flying over a roof, while other birds are on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.0, "ram_available_mb": 109195.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13311.8, "ram_available_mb": 109194.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [40.09, 40.09, 40.09, 39.21, 39.21, 39.21, 39.21, 39.21, 45.77], "power_watts_avg": 40.23, "power_watts_peak": 45.77, "energy_joules_est": 34.6, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-12T09:49:23.836507"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1372.146, "latencies_ms": [1372.146], "images_per_second": 0.729, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a bird with a blue and black body, flying over a wooden surface with a blue hue. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.8, "ram_available_mb": 109194.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13309.8, "ram_available_mb": 109196.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.77, 45.77, 45.77, 45.77, 49.86, 49.86, 49.86, 49.86, 49.86, 46.4, 46.4, 46.4, 46.4, 46.4], "power_watts_avg": 47.45, "power_watts_peak": 49.86, "energy_joules_est": 65.13, "sample_count": 14, "duration_seconds": 1.373}, "timestamp": "2026-01-12T09:49:25.248632"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1118.903, "latencies_ms": [1118.903], "images_per_second": 0.894, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a person is walking a horse in a barn, with a red door and a ladder visible in the background.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 13305.8, "ram_available_mb": 109200.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13325.9, "ram_available_mb": 109180.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.42, 37.42, 37.42, 37.42, 37.42, 46.74, 46.74, 46.74, 46.74, 46.74, 46.64, 46.64], "power_watts_avg": 42.84, "power_watts_peak": 46.74, "energy_joules_est": 47.94, "sample_count": 12, "duration_seconds": 1.119}, "timestamp": "2026-01-12T09:49:26.463390"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1317.585, "latencies_ms": [1317.585], "images_per_second": 0.759, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " horse: 1, person: 1, door: 1, ladder: 1, bucket: 1, wall: 1, window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.9, "ram_available_mb": 109180.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13396.8, "ram_available_mb": 109109.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.64, 46.64, 46.64, 37.6, 37.6, 37.6, 37.6, 37.6, 45.88, 45.88, 45.88, 45.88, 45.88, 42.91], "power_watts_avg": 42.87, "power_watts_peak": 46.64, "energy_joules_est": 56.52, "sample_count": 14, "duration_seconds": 1.318}, "timestamp": "2026-01-12T09:49:27.874177"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1645.765, "latencies_ms": [1645.765], "images_per_second": 0.608, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, with the person walking beside it. The person is standing in the middle of the image, with the horse to their left. The horse is in the background, with the person in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.9, "ram_available_mb": 109117.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13362.2, "ram_available_mb": 109144.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.91, 42.91, 42.91, 42.91, 41.97, 41.97, 41.97, 41.97, 41.97, 46.06, 46.06, 46.06, 46.06, 46.06, 38.77, 38.77, 38.77], "power_watts_avg": 42.83, "power_watts_peak": 46.06, "energy_joules_est": 70.51, "sample_count": 17, "duration_seconds": 1.646}, "timestamp": "2026-01-12T09:49:29.587325"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 686.434, "latencies_ms": [686.434], "images_per_second": 1.457, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is walking a horse in a barn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.77, 38.77, 33.35, 33.35, 33.35, 33.35, 33.35], "power_watts_avg": 34.9, "power_watts_peak": 38.77, "energy_joules_est": 23.98, "sample_count": 7, "duration_seconds": 0.687}, "timestamp": "2026-01-12T09:49:30.296281"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1560.051, "latencies_ms": [1560.051], "images_per_second": 0.641, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is taken in a stable with a brown horse and a woman walking in it. The horse is wearing a red harness and the woman is wearing blue jeans. The lighting is natural and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.7, "ram_available_mb": 109153.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13290.8, "ram_available_mb": 109215.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.78, 46.78, 46.78, 46.78, 46.78, 60.55, 60.55, 60.55, 60.55, 60.55, 47.25, 47.25, 47.25, 47.25, 47.25, 35.35], "power_watts_avg": 50.51, "power_watts_peak": 60.55, "energy_joules_est": 78.82, "sample_count": 16, "duration_seconds": 1.56}, "timestamp": "2026-01-12T09:49:31.911031"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1343.682, "latencies_ms": [1343.682], "images_per_second": 0.744, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a group of animals, including zebras and sheep, are grazing in a grassy field, with a tree trunk and a fence visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13291.1, "ram_available_mb": 109215.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13328.8, "ram_available_mb": 109177.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.35, 35.35, 35.35, 40.23, 40.23, 40.23, 40.23, 40.23, 46.19, 46.19, 46.19, 46.19, 46.19, 40.48], "power_watts_avg": 41.33, "power_watts_peak": 46.19, "energy_joules_est": 55.56, "sample_count": 14, "duration_seconds": 1.344}, "timestamp": "2026-01-12T09:49:33.326454"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1927.321, "latencies_ms": [1927.321], "images_per_second": 0.519, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tree: 1\n2. grass: 1\n3. zebra: 2\n4. sheep: 3\n5. rocks: 1\n6. fence: 1\n7. water: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.8, "ram_available_mb": 109177.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13360.4, "ram_available_mb": 109145.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.48, 40.48, 40.48, 40.48, 43.55, 43.55, 43.55, 43.55, 43.55, 46.02, 46.02, 46.02, 46.02, 46.02, 36.91, 36.91, 36.91, 36.91, 36.91, 34.18], "power_watts_avg": 41.42, "power_watts_peak": 46.02, "energy_joules_est": 79.85, "sample_count": 20, "duration_seconds": 1.928}, "timestamp": "2026-01-12T09:49:35.343232"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1776.185, "latencies_ms": [1776.185], "images_per_second": 0.563, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground, with the sheep grazing in the background. The zebras are closer to the camera than the sheep, which are further away. The zebras are near the pond, while the sheep are grazing on the grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.5, "ram_available_mb": 109149.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 34.18, 34.18, 39.49, 39.49, 39.49, 39.49, 39.49, 44.82, 44.82, 44.82, 44.82, 44.82, 39.66, 39.66, 39.66, 39.66], "power_watts_avg": 39.83, "power_watts_peak": 44.82, "energy_joules_est": 70.76, "sample_count": 18, "duration_seconds": 1.777}, "timestamp": "2026-01-12T09:49:37.209593"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1388.929, "latencies_ms": [1388.929], "images_per_second": 0.72, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In this image, we can see a herd of animals, including zebras and sheep, grazing in a grassy field. In the background, we can see trees and a pond.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13365.9, "ram_available_mb": 109140.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.99, 33.99, 33.99, 33.99, 33.99, 46.87, 46.87, 46.87, 46.87, 46.87, 46.82, 46.82, 46.82, 46.82], "power_watts_avg": 42.25, "power_watts_peak": 46.87, "energy_joules_est": 58.7, "sample_count": 14, "duration_seconds": 1.389}, "timestamp": "2026-01-12T09:49:38.622614"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1490.292, "latencies_ms": [1490.292], "images_per_second": 0.671, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a grassy field with a variety of animals, including zebras, sheep, and deer. The sky is blue with some clouds, and the trees in the background are tall and green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.9, "ram_available_mb": 109140.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13398.4, "ram_available_mb": 109107.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [46.82, 32.31, 32.31, 32.31, 32.31, 32.31, 47.26, 47.26, 47.26, 47.26, 47.26, 49.22, 49.22, 49.22, 49.22], "power_watts_avg": 42.77, "power_watts_peak": 49.22, "energy_joules_est": 63.75, "sample_count": 15, "duration_seconds": 1.491}, "timestamp": "2026-01-12T09:49:40.136905"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1122.032, "latencies_ms": [1122.032], "images_per_second": 0.891, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A vintage trolley car with a green and gold body and a red roof is being pulled by two white horses in a park.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13390.5, "ram_available_mb": 109115.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13397.5, "ram_available_mb": 109108.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.22, 32.64, 32.64, 32.64, 32.64, 32.64, 47.27, 47.27, 47.27, 47.27, 47.27, 48.89], "power_watts_avg": 41.47, "power_watts_peak": 49.22, "energy_joules_est": 46.54, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-12T09:49:41.351590"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1360.417, "latencies_ms": [1360.417], "images_per_second": 0.735, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " trolley: 1, horse: 2, carriage: 1, people: 1, bench: 1, trees: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.5, "ram_available_mb": 109112.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13375.4, "ram_available_mb": 109130.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.89, 48.89, 48.89, 48.89, 42.3, 42.3, 42.3, 42.3, 42.3, 45.73, 45.73, 45.73, 45.73, 45.73], "power_watts_avg": 45.41, "power_watts_peak": 48.89, "energy_joules_est": 61.79, "sample_count": 14, "duration_seconds": 1.361}, "timestamp": "2026-01-12T09:49:42.766105"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1912.406, "latencies_ms": [1912.406], "images_per_second": 0.523, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The horse-drawn trolley is positioned in the foreground of the image, with the passengers seated inside. The trolley is moving towards the right side of the image, while the people are standing on the left side. The background features a park with trees and a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.4, "ram_available_mb": 109130.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13420.6, "ram_available_mb": 109085.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.74, 37.74, 37.74, 37.74, 37.74, 46.73, 46.73, 46.73, 46.73, 46.73, 46.52, 46.52, 46.52, 46.52, 46.52, 34.7, 34.7, 34.7, 34.7, 34.7], "power_watts_avg": 41.42, "power_watts_peak": 46.73, "energy_joules_est": 79.24, "sample_count": 20, "duration_seconds": 1.913}, "timestamp": "2026-01-12T09:49:44.779551"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1099.619, "latencies_ms": [1099.619], "images_per_second": 0.909, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A horse-drawn trolley car is driving down a street in a park, with people walking around and sitting on benches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.8, "ram_available_mb": 109093.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.8, "ram_available_mb": 109095.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.85, 33.85, 33.85, 33.85, 41.84, 41.84, 41.84, 41.84, 41.84, 45.08, 45.08], "power_watts_avg": 39.52, "power_watts_peak": 45.08, "energy_joules_est": 43.49, "sample_count": 11, "duration_seconds": 1.1}, "timestamp": "2026-01-12T09:49:45.942031"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1990.3, "latencies_ms": [1990.3], "images_per_second": 0.502, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features a vibrant scene with a green and red trolley car, white horses pulling it, and a yellow canopy overhead. The trolley car is adorned with gold accents and has a sign that reads \"DINING CAR\". The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.9, "ram_available_mb": 109099.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.08, 45.08, 45.08, 43.4, 43.4, 43.4, 43.4, 43.4, 47.21, 47.21, 47.21, 47.21, 47.21, 41.56, 41.56, 41.56, 41.56, 41.56, 34.25, 34.25], "power_watts_avg": 43.23, "power_watts_peak": 47.21, "energy_joules_est": 86.05, "sample_count": 20, "duration_seconds": 1.991}, "timestamp": "2026-01-12T09:49:47.957217"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1099.898, "latencies_ms": [1099.898], "images_per_second": 0.909, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " An elderly man sits on a green bench reading a newspaper while a group of people sit on benches in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13311.3, "ram_available_mb": 109195.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 20.0}, "power_stats": {"power_watts_samples": [34.25, 34.25, 35.5, 35.5, 35.5, 35.5, 35.5, 46.18, 46.18, 46.18, 46.18], "power_watts_avg": 39.16, "power_watts_peak": 46.18, "energy_joules_est": 43.11, "sample_count": 11, "duration_seconds": 1.101}, "timestamp": "2026-01-12T09:49:49.121295"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1910.387, "latencies_ms": [1910.387], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. bench: 4\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.3, "ram_available_mb": 109195.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13282.1, "ram_available_mb": 109224.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.18, 43.92, 43.92, 43.92, 43.92, 43.92, 47.26, 47.26, 47.26, 47.26, 47.26, 49.24, 49.24, 49.24, 49.24, 49.24, 34.27, 34.27, 34.27], "power_watts_avg": 44.79, "power_watts_peak": 49.24, "energy_joules_est": 85.61, "sample_count": 19, "duration_seconds": 1.911}, "timestamp": "2026-01-12T09:49:51.040522"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2307.554, "latencies_ms": [2307.554], "images_per_second": 0.433, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The man on the left is sitting on a green bench, while the man on the right is sitting on a black bench. The man on the left is closer to the camera than the man on the right. The man on the left is sitting near the man on the right, and the man on the right is sitting near the man on the left.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13282.1, "ram_available_mb": 109224.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13332.6, "ram_available_mb": 109173.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.27, 34.27, 32.63, 32.63, 32.63, 32.63, 32.63, 46.63, 46.63, 46.63, 46.63, 46.63, 48.28, 48.28, 48.28, 48.28, 48.28, 34.34, 34.34, 34.34, 34.34, 34.34, 34.35], "power_watts_avg": 39.67, "power_watts_peak": 48.28, "energy_joules_est": 91.57, "sample_count": 23, "duration_seconds": 2.309}, "timestamp": "2026-01-12T09:49:53.409310"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2126.54, "latencies_ms": [2126.54], "images_per_second": 0.47, "prompt_tokens": 1111, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a serene scene of a group of people enjoying a sunny day on a city sidewalk. The individuals are seated on green metal benches, each engrossed in their own world. The backdrop is a bustling cityscape with a prominent building adorned with a maroon sign that reads \"S.C.C.C.\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.6, "ram_available_mb": 109173.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13403.8, "ram_available_mb": 109102.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.35, 34.35, 34.35, 38.24, 38.24, 38.24, 38.24, 38.24, 46.54, 46.54, 46.54, 46.54, 46.54, 43.41, 43.41, 43.41, 43.41, 43.41, 34.28, 34.28, 34.28, 34.28], "power_watts_avg": 40.05, "power_watts_peak": 46.54, "energy_joules_est": 85.19, "sample_count": 22, "duration_seconds": 2.127}, "timestamp": "2026-01-12T09:49:55.674340"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1624.484, "latencies_ms": [1624.484], "images_per_second": 0.616, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image is taken during the day, with natural light illuminating the scene. The colors in the image are vibrant, with the green of the benches contrasting against the red of the metal railing and the white of the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.8, "ram_available_mb": 109102.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.2, "ram_available_mb": 109133.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.28, 32.05, 32.05, 32.05, 32.05, 32.05, 45.98, 45.98, 45.98, 45.98, 45.98, 48.25, 48.25, 48.25, 48.25, 48.25, 34.33], "power_watts_avg": 41.18, "power_watts_peak": 48.25, "energy_joules_est": 66.9, "sample_count": 17, "duration_seconds": 1.625}, "timestamp": "2026-01-12T09:49:57.388630"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 931.353, "latencies_ms": [931.353], "images_per_second": 1.074, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black desk with a laptop, a lamp, and a glass of orange juice on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.3, "ram_available_mb": 109141.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13380.7, "ram_available_mb": 109125.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.33, 34.33, 34.33, 34.33, 41.0, 41.0, 41.0, 41.0, 41.0, 45.88], "power_watts_avg": 38.82, "power_watts_peak": 45.88, "energy_joules_est": 36.18, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-12T09:49:58.402935"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1507.136, "latencies_ms": [1507.136], "images_per_second": 0.664, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. black laptop\n2. white telephone\n3. black lamp\n4. glass of orange juice\n5. book\n6. white paper\n7. black pen\n8. black chair", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.9, "ram_available_mb": 109133.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13375.7, "ram_available_mb": 109130.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.88, 45.88, 45.88, 45.88, 46.56, 46.56, 46.56, 46.56, 46.56, 46.08, 46.08, 46.08, 46.08, 46.08, 40.45], "power_watts_avg": 45.81, "power_watts_peak": 46.56, "energy_joules_est": 69.06, "sample_count": 15, "duration_seconds": 1.507}, "timestamp": "2026-01-12T09:49:59.916878"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1402.489, "latencies_ms": [1402.489], "images_per_second": 0.713, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The laptop is positioned to the left of the desk, with the lamp and telephone to its right. The desk is situated in the foreground, with the wall and painting in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13279.9, "ram_available_mb": 109226.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.45, 40.45, 40.45, 41.36, 41.36, 41.36, 41.36, 41.36, 47.78, 47.78, 47.78, 47.78, 47.78, 40.71], "power_watts_avg": 43.41, "power_watts_peak": 47.78, "energy_joules_est": 60.89, "sample_count": 14, "duration_seconds": 1.403}, "timestamp": "2026-01-12T09:50:01.331692"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1143.9, "latencies_ms": [1143.9], "images_per_second": 0.874, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A desk with a laptop computer, a lamp, and a glass of orange juice is in a room with a painting on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13279.9, "ram_available_mb": 109226.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13327.6, "ram_available_mb": 109178.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.71, 40.71, 40.71, 40.71, 45.22, 45.22, 45.22, 45.22, 45.22, 47.68, 47.68, 47.68], "power_watts_avg": 44.33, "power_watts_peak": 47.68, "energy_joules_est": 50.73, "sample_count": 12, "duration_seconds": 1.144}, "timestamp": "2026-01-12T09:50:02.543228"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 951.86, "latencies_ms": [951.86], "images_per_second": 1.051, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is well-lit with a warm yellow light, and the desk is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.6, "ram_available_mb": 109178.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13336.8, "ram_available_mb": 109169.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.68, 47.68, 38.41, 38.41, 38.41, 38.41, 38.41, 46.65, 46.65, 46.65], "power_watts_avg": 42.73, "power_watts_peak": 47.68, "energy_joules_est": 40.69, "sample_count": 10, "duration_seconds": 0.952}, "timestamp": "2026-01-12T09:50:03.553865"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1921.453, "latencies_ms": [1921.453], "images_per_second": 0.52, "prompt_tokens": 1432, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a blue and white striped towel, a pink and white surfboard, and a blue surfboard resting on the sand, with a beach umbrella and chairs nearby, and a person enjoying the ocean waves in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.8, "ram_available_mb": 109173.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.65, 46.65, 44.62, 44.62, 44.62, 44.62, 44.62, 50.73, 50.73, 50.73, 50.73, 50.73, 52.69, 52.69, 52.69, 52.69, 52.69, 34.53, 34.53, 34.53], "power_watts_avg": 46.86, "power_watts_peak": 52.69, "energy_joules_est": 90.04, "sample_count": 20, "duration_seconds": 1.922}, "timestamp": "2026-01-12T09:50:05.574320"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1652.352, "latencies_ms": [1652.352], "images_per_second": 0.605, "prompt_tokens": 1446, "response_tokens_est": 41, "n_tiles": 1, "output_text": " beach chair: 2\nsurfboard: 3\nbag: 1\numbrella: 1\ntowel: 1\nbag: 1\nsurfboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.53, 30.2, 30.2, 30.2, 30.2, 30.2, 48.8, 48.8, 48.8, 48.8, 48.8, 52.66, 52.66, 52.66, 52.66, 52.66, 34.6], "power_watts_avg": 42.79, "power_watts_peak": 52.66, "energy_joules_est": 70.73, "sample_count": 17, "duration_seconds": 1.653}, "timestamp": "2026-01-12T09:50:07.340813"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2371.806, "latencies_ms": [2371.806], "images_per_second": 0.422, "prompt_tokens": 1450, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The blue and white striped towel is positioned to the left of the blue surfboard, which is closer to the camera than the pink and white surfboard. The red cooler is located in the foreground, near the beach chairs and umbrellas, while the person in the water is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13331.3, "ram_available_mb": 109175.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.6, 34.6, 34.6, 34.6, 42.27, 42.27, 42.27, 42.27, 42.27, 50.65, 50.65, 50.65, 50.65, 50.65, 43.75, 43.75, 43.75, 43.75, 43.75, 34.52, 34.52, 34.52, 34.52, 34.52], "power_watts_avg": 41.43, "power_watts_peak": 50.65, "energy_joules_est": 98.28, "sample_count": 24, "duration_seconds": 2.372}, "timestamp": "2026-01-12T09:50:09.758403"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1498.197, "latencies_ms": [1498.197], "images_per_second": 0.667, "prompt_tokens": 1444, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a clear blue sky and calm ocean waves. People are enjoying the beach, with some sitting on chairs and others walking along the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.8, "ram_available_mb": 109175.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.4, "ram_available_mb": 109179.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.45, 34.45, 34.45, 34.45, 34.45, 43.09, 43.09, 43.09, 43.09, 43.09, 49.74, 49.74, 49.74, 49.74, 41.17], "power_watts_avg": 41.86, "power_watts_peak": 49.74, "energy_joules_est": 62.74, "sample_count": 15, "duration_seconds": 1.499}, "timestamp": "2026-01-12T09:50:11.323537"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1048.321, "latencies_ms": [1048.321], "images_per_second": 0.954, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The beach is covered in sand, the sky is blue, and the ocean is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.1, "ram_available_mb": 109189.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13336.6, "ram_available_mb": 109169.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.17, 41.17, 41.17, 41.17, 43.96, 43.96, 43.96, 43.96, 43.96, 51.54, 51.54], "power_watts_avg": 44.32, "power_watts_peak": 51.54, "energy_joules_est": 46.48, "sample_count": 11, "duration_seconds": 1.049}, "timestamp": "2026-01-12T09:50:12.437470"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 948.697, "latencies_ms": [948.697], "images_per_second": 1.054, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A sheep with a black face is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.6, "ram_available_mb": 109173.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13321.0, "ram_available_mb": 109185.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [51.54, 51.54, 51.54, 48.08, 48.08, 48.08, 48.08, 48.08, 46.53, 46.53], "power_watts_avg": 48.81, "power_watts_peak": 51.54, "energy_joules_est": 46.32, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-12T09:50:13.451206"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2008.065, "latencies_ms": [2008.065], "images_per_second": 0.498, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. rock: 1\n3. grass: 1\n4. sky: 1\n5. clouds: 1\n6. cloud: 1\n7. sheep's head: 1\n8. sheep's body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.0, "ram_available_mb": 109185.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13354.6, "ram_available_mb": 109151.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.53, 46.53, 46.53, 45.69, 45.69, 45.69, 45.69, 45.69, 46.38, 46.38, 46.38, 46.38, 46.38, 42.86, 42.86, 42.86, 42.86, 42.86, 34.49, 34.49], "power_watts_avg": 44.16, "power_watts_peak": 46.53, "energy_joules_est": 88.69, "sample_count": 20, "duration_seconds": 2.008}, "timestamp": "2026-01-12T09:50:15.464797"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1454.856, "latencies_ms": [1454.856], "images_per_second": 0.687, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The sheep is positioned on the left side of the image, with the sky occupying the majority of the background. The sheep is situated in the foreground, with the grass and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.6, "ram_available_mb": 109151.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.49, 34.49, 34.49, 36.16, 36.16, 36.16, 36.16, 46.56, 46.56, 46.56, 46.56, 46.56, 45.16, 45.16, 45.16], "power_watts_avg": 41.1, "power_watts_peak": 46.56, "energy_joules_est": 59.8, "sample_count": 15, "duration_seconds": 1.455}, "timestamp": "2026-01-12T09:50:17.027336"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 953.154, "latencies_ms": [953.154], "images_per_second": 1.049, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A sheep with a black face is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13437.1, "ram_available_mb": 109069.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 12.0}, "power_stats": {"power_watts_samples": [45.16, 45.16, 35.75, 35.75, 35.75, 35.75, 35.75, 46.77, 46.77, 46.77], "power_watts_avg": 40.94, "power_watts_peak": 46.77, "energy_joules_est": 39.04, "sample_count": 10, "duration_seconds": 0.954}, "timestamp": "2026-01-12T09:50:18.037988"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1032.793, "latencies_ms": [1032.793], "images_per_second": 0.968, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The sheep is white with a black face and is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13429.2, "ram_available_mb": 109077.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13440.1, "ram_available_mb": 109066.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 3.0}, "power_stats": {"power_watts_samples": [46.77, 46.77, 46.29, 46.29, 46.29, 46.29, 46.29, 46.58, 46.58, 46.58, 46.58], "power_watts_avg": 46.49, "power_watts_peak": 46.77, "energy_joules_est": 48.04, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-12T09:50:19.148771"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 809.617, "latencies_ms": [809.617], "images_per_second": 1.235, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person with blue hair is taking a selfie in the mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13441.4, "ram_available_mb": 109064.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13436.8, "ram_available_mb": 109069.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 42.0}, "power_stats": {"power_watts_samples": [46.58, 44.14, 44.14, 44.14, 44.14, 44.14, 45.86, 45.86, 45.86], "power_watts_avg": 44.99, "power_watts_peak": 46.58, "energy_joules_est": 36.43, "sample_count": 9, "duration_seconds": 0.81}, "timestamp": "2026-01-12T09:50:20.062207"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1912.913, "latencies_ms": [1912.913], "images_per_second": 0.523, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. phone: 1\n3. shirt: 1\n4. tie: 1\n5. wall: 1\n6. ring: 1\n7. mirror: 1\n8. blue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.8, "ram_available_mb": 109069.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13443.0, "ram_available_mb": 109063.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.86, 45.86, 46.66, 46.66, 46.66, 46.66, 46.66, 45.68, 45.68, 45.68, 45.68, 45.68, 47.15, 47.15, 47.15, 47.15, 47.15, 34.26, 34.26, 34.26], "power_watts_avg": 44.6, "power_watts_peak": 47.15, "energy_joules_est": 85.34, "sample_count": 20, "duration_seconds": 1.914}, "timestamp": "2026-01-12T09:50:22.079659"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1829.754, "latencies_ms": [1829.754], "images_per_second": 0.547, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The person is in the foreground of the image, taking a selfie with a phone. The phone is held up to the camera, and the person's reflection is visible in the mirror. The mirror is located in the background, reflecting the person and the phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.1, "ram_available_mb": 109071.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13359.7, "ram_available_mb": 109146.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.26, 30.06, 30.06, 30.06, 30.06, 30.06, 44.46, 44.46, 44.46, 44.46, 44.46, 49.08, 49.08, 49.08, 49.08, 49.08, 34.46, 34.46, 34.46], "power_watts_avg": 39.77, "power_watts_peak": 49.08, "energy_joules_est": 72.79, "sample_count": 19, "duration_seconds": 1.83}, "timestamp": "2026-01-12T09:50:24.046366"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 810.522, "latencies_ms": [810.522], "images_per_second": 1.234, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman with blue hair is taking a selfie in the mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.7, "ram_available_mb": 109146.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13416.7, "ram_available_mb": 109089.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.46, 34.46, 30.83, 30.83, 30.83, 30.83, 30.83, 45.02, 45.02], "power_watts_avg": 34.79, "power_watts_peak": 45.02, "energy_joules_est": 28.22, "sample_count": 9, "duration_seconds": 0.811}, "timestamp": "2026-01-12T09:50:25.008348"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1008.901, "latencies_ms": [1008.901], "images_per_second": 0.991, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The woman has blue hair and is wearing a blue shirt. The lighting is bright and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13417.0, "ram_available_mb": 109089.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 26.0}, "power_stats": {"power_watts_samples": [45.02, 45.02, 45.02, 49.72, 49.72, 49.72, 49.72, 49.72, 45.69, 45.69, 45.69], "power_watts_avg": 47.34, "power_watts_peak": 49.72, "energy_joules_est": 47.79, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-12T09:50:26.121425"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1095.506, "latencies_ms": [1095.506], "images_per_second": 0.913, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden cabinet, a table, and chairs, with paintings on the walls.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13409.2, "ram_available_mb": 109097.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13414.1, "ram_available_mb": 109092.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.69, 42.09, 42.09, 42.09, 42.09, 42.09, 45.73, 45.73, 45.73, 45.73, 45.73], "power_watts_avg": 44.07, "power_watts_peak": 45.73, "energy_joules_est": 48.3, "sample_count": 11, "duration_seconds": 1.096}, "timestamp": "2026-01-12T09:50:27.236808"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1366.322, "latencies_ms": [1366.322], "images_per_second": 0.732, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " fireplace: 1, table: 1, chair: 2, bookshelf: 1, painting: 2, vase: 2, floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.3, "ram_available_mb": 109100.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.1, "ram_available_mb": 109178.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.16, 49.16, 49.16, 49.16, 49.16, 47.34, 47.34, 47.34, 47.34, 47.34, 47.02, 47.02, 47.02, 47.02], "power_watts_avg": 47.9, "power_watts_peak": 49.16, "energy_joules_est": 65.45, "sample_count": 14, "duration_seconds": 1.366}, "timestamp": "2026-01-12T09:50:28.651863"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1583.354, "latencies_ms": [1583.354], "images_per_second": 0.632, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The fireplace is located on the left side of the room, with the wooden cabinet positioned against the right wall. The round wooden table is situated in the foreground, while the chairs are placed further back in the room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13328.1, "ram_available_mb": 109178.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.1, "ram_available_mb": 109162.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.02, 32.4, 32.4, 32.4, 32.4, 32.4, 46.65, 46.65, 46.65, 46.65, 46.65, 48.63, 48.63, 48.63, 48.63, 48.63], "power_watts_avg": 42.84, "power_watts_peak": 48.63, "energy_joules_est": 67.85, "sample_count": 16, "duration_seconds": 1.584}, "timestamp": "2026-01-12T09:50:30.268753"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 942.175, "latencies_ms": [942.175], "images_per_second": 1.061, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden cabinet, and a table with chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.1, "ram_available_mb": 109166.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 34.15, 34.15, 47.08, 47.08, 47.08, 47.08, 47.08], "power_watts_avg": 40.62, "power_watts_peak": 47.08, "energy_joules_est": 38.29, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-12T09:50:31.281283"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1341.507, "latencies_ms": [1341.507], "images_per_second": 0.745, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white. The furniture is made of wood, and the floor is covered with a patterned carpet.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13421.7, "ram_available_mb": 109084.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.78, 46.78, 46.78, 46.78, 46.78, 46.17, 46.17, 46.17, 46.17, 46.17, 46.03, 46.03, 46.03, 46.03], "power_watts_avg": 46.35, "power_watts_peak": 46.78, "energy_joules_est": 62.2, "sample_count": 14, "duration_seconds": 1.342}, "timestamp": "2026-01-12T09:50:32.693384"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1013.719, "latencies_ms": [1013.719], "images_per_second": 0.986, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A brown dog is jumping up in the air to catch a red frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.7, "ram_available_mb": 109084.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13340.1, "ram_available_mb": 109166.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.03, 33.2, 33.2, 33.2, 33.2, 33.2, 48.42, 48.42, 48.42, 48.42, 48.42], "power_watts_avg": 41.29, "power_watts_peak": 48.42, "energy_joules_est": 41.86, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:50:33.809953"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1382.141, "latencies_ms": [1382.141], "images_per_second": 0.724, "prompt_tokens": 1446, "response_tokens_est": 31, "n_tiles": 1, "output_text": " dog: 1, frisbee: 1, car: 1, tree: 1, grass: 1, mulch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.1, "ram_available_mb": 109166.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [51.97, 51.97, 51.97, 51.97, 51.97, 45.94, 45.94, 45.94, 45.94, 45.94, 49.92, 49.92, 49.92, 49.92], "power_watts_avg": 49.23, "power_watts_peak": 51.97, "energy_joules_est": 68.07, "sample_count": 14, "duration_seconds": 1.383}, "timestamp": "2026-01-12T09:50:35.222103"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1657.437, "latencies_ms": [1657.437], "images_per_second": 0.603, "prompt_tokens": 1450, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The dog is in the foreground, jumping up to catch the frisbee, which is in the middle ground. The frisbee is in the air, and the car is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13353.5, "ram_available_mb": 109152.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.38, 41.38, 41.38, 41.38, 41.38, 49.03, 49.03, 49.03, 49.03, 49.03, 51.04, 51.04, 51.04, 51.04, 51.04, 37.16, 37.16], "power_watts_avg": 45.97, "power_watts_peak": 51.04, "energy_joules_est": 76.21, "sample_count": 17, "duration_seconds": 1.658}, "timestamp": "2026-01-12T09:50:36.936272"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1136.979, "latencies_ms": [1136.979], "images_per_second": 0.88, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog is playing frisbee in a yard with a tree and a car in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13323.8, "ram_available_mb": 109182.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [37.16, 37.16, 37.16, 38.75, 38.75, 38.75, 38.75, 38.75, 50.33, 50.33, 50.33, 50.33], "power_watts_avg": 42.21, "power_watts_peak": 50.33, "energy_joules_est": 48.0, "sample_count": 12, "duration_seconds": 1.137}, "timestamp": "2026-01-12T09:50:38.150573"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1575.356, "latencies_ms": [1575.356], "images_per_second": 0.635, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a black dog with a red frisbee in its mouth, jumping in the air in a grassy yard. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13315.9, "ram_available_mb": 109190.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.7, "ram_available_mb": 109154.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.33, 44.05, 44.05, 44.05, 44.05, 44.05, 50.41, 50.41, 50.41, 50.41, 50.41, 53.36, 53.36, 53.36, 53.36, 53.36], "power_watts_avg": 49.34, "power_watts_peak": 53.36, "energy_joules_est": 77.74, "sample_count": 16, "duration_seconds": 1.576}, "timestamp": "2026-01-12T09:50:39.763605"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1111.1, "latencies_ms": [1111.1], "images_per_second": 0.9, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image captures a giraffe in a natural setting, with its head and neck prominently displayed, and the background filled with lush greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.0, "ram_available_mb": 109156.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13319.4, "ram_available_mb": 109186.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 34.72, 34.72, 34.72, 47.09, 47.09, 47.09, 47.09, 47.09, 47.02, 47.02], "power_watts_avg": 41.93, "power_watts_peak": 47.09, "energy_joules_est": 46.61, "sample_count": 12, "duration_seconds": 1.112}, "timestamp": "2026-01-12T09:50:40.975267"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1328.071, "latencies_ms": [1328.071], "images_per_second": 0.753, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " giraffe: 1, ear: 2, eye: 2, nose: 1, mouth: 1, horn: 1, tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.5, "ram_available_mb": 109194.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13318.2, "ram_available_mb": 109188.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.02, 47.02, 47.02, 38.19, 38.19, 38.19, 38.19, 38.19, 45.84, 45.84, 45.84, 45.84, 45.84, 42.33], "power_watts_avg": 43.11, "power_watts_peak": 47.02, "energy_joules_est": 57.27, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-12T09:50:42.387851"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1284.517, "latencies_ms": [1284.517], "images_per_second": 0.779, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The giraffe is in the foreground, with its head and neck prominently displayed. The background is filled with lush green foliage, providing a natural habitat for the giraffe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.4, "ram_available_mb": 109195.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13317.1, "ram_available_mb": 109189.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.33, 42.33, 42.33, 42.33, 42.16, 42.16, 42.16, 42.16, 42.16, 46.01, 46.01, 46.01, 46.01], "power_watts_avg": 43.4, "power_watts_peak": 46.01, "energy_joules_est": 55.76, "sample_count": 13, "duration_seconds": 1.285}, "timestamp": "2026-01-12T09:50:43.700200"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1751.444, "latencies_ms": [1751.444], "images_per_second": 0.571, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " In the heart of a verdant forest, a majestic giraffe stands tall and proud, its long neck reaching towards the sky. The giraffe's coat, a beautiful mosaic of brown and white spots, contrasts beautifully with the lush greenery of the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.1, "ram_available_mb": 109189.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13316.9, "ram_available_mb": 109189.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.01, 38.36, 38.36, 38.36, 38.36, 38.36, 47.31, 47.31, 47.31, 47.31, 47.31, 48.29, 48.29, 48.29, 48.29, 48.29, 34.43, 34.43], "power_watts_avg": 43.59, "power_watts_peak": 48.29, "energy_joules_est": 76.37, "sample_count": 18, "duration_seconds": 1.752}, "timestamp": "2026-01-12T09:50:45.515624"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1200.065, "latencies_ms": [1200.065], "images_per_second": 0.833, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The giraffe's coat is a rich brown with white spots, and the sunlight filters through the green leaves above, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13309.0, "ram_available_mb": 109197.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13328.0, "ram_available_mb": 109178.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.43, 34.43, 34.43, 36.59, 36.59, 36.59, 36.59, 36.59, 46.6, 46.6, 46.6, 46.6], "power_watts_avg": 39.39, "power_watts_peak": 46.6, "energy_joules_est": 47.29, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-12T09:50:46.727945"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1071.665, "latencies_ms": [1071.665], "images_per_second": 0.933, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two zebras with black and white stripes are standing in a fenced area with a chain link fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.1, "ram_available_mb": 109186.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13323.0, "ram_available_mb": 109183.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.97, 44.97, 44.97, 44.97, 44.97, 47.24, 47.24, 47.24, 47.24, 47.24, 47.61], "power_watts_avg": 46.24, "power_watts_peak": 47.61, "energy_joules_est": 49.58, "sample_count": 11, "duration_seconds": 1.072}, "timestamp": "2026-01-12T09:50:47.844398"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 535.746, "latencies_ms": [535.746], "images_per_second": 1.867, "prompt_tokens": 1114, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.0, "ram_available_mb": 109183.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13320.6, "ram_available_mb": 109185.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [47.61, 47.61, 47.61, 47.61, 44.7, 44.7], "power_watts_avg": 46.64, "power_watts_peak": 47.61, "energy_joules_est": 25.02, "sample_count": 6, "duration_seconds": 0.536}, "timestamp": "2026-01-12T09:50:48.453808"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1712.767, "latencies_ms": [1712.767], "images_per_second": 0.584, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the fence serving as a boundary between them and the background. The zebras are facing away from the camera, with their tails prominently displayed, suggesting a sense of curiosity or alertness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.6, "ram_available_mb": 109185.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13315.6, "ram_available_mb": 109190.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 39.0}, "power_stats": {"power_watts_samples": [44.7, 44.7, 44.7, 51.75, 51.75, 51.75, 51.75, 51.75, 49.46, 49.46, 49.46, 49.46, 49.46, 42.03, 42.03, 42.03, 42.03, 42.03], "power_watts_avg": 47.24, "power_watts_peak": 51.75, "energy_joules_est": 80.94, "sample_count": 18, "duration_seconds": 1.713}, "timestamp": "2026-01-12T09:50:50.269131"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1036.609, "latencies_ms": [1036.609], "images_per_second": 0.965, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two zebras are standing in a fenced enclosure, their black and white stripes contrasting against the brown dirt ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13315.6, "ram_available_mb": 109190.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13325.7, "ram_available_mb": 109180.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.93, 33.93, 33.93, 33.93, 33.93, 45.8, 45.8, 45.8, 45.8, 45.8, 47.0], "power_watts_avg": 40.52, "power_watts_peak": 47.0, "energy_joules_est": 42.02, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-12T09:50:51.378054"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1621.756, "latencies_ms": [1621.756], "images_per_second": 0.617, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features two zebras with their backs to the camera, standing in a grassy area with a chain link fence in the background. The zebras have black and white stripes, and the lighting appears to be natural daylight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.7, "ram_available_mb": 109180.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13363.2, "ram_available_mb": 109143.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.0, 47.0, 47.0, 47.0, 42.48, 42.48, 42.48, 42.48, 42.48, 46.38, 46.38, 46.38, 46.38, 46.38, 38.33, 38.33, 38.33], "power_watts_avg": 43.96, "power_watts_peak": 47.0, "energy_joules_est": 71.3, "sample_count": 17, "duration_seconds": 1.622}, "timestamp": "2026-01-12T09:50:53.093846"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1252.921, "latencies_ms": [1252.921], "images_per_second": 0.798, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of horses is walking down a road, with a car parked on the side, and a pile of poop on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.3, "ram_available_mb": 109147.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [38.33, 38.33, 32.79, 32.79, 32.79, 32.79, 32.79, 45.91, 45.91, 45.91, 45.91, 45.91, 47.6], "power_watts_avg": 39.83, "power_watts_peak": 47.6, "energy_joules_est": 49.93, "sample_count": 13, "duration_seconds": 1.254}, "timestamp": "2026-01-12T09:50:54.407118"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1909.599, "latencies_ms": [1909.599], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 4\n2. car: 1\n3. horse: 2\n4. horse: 1\n5. horse: 1\n6. horse: 1\n7. horse: 1\n8. horse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13339.8, "ram_available_mb": 109166.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.6, 47.6, 47.6, 47.6, 41.65, 41.65, 41.65, 41.65, 41.65, 46.6, 46.6, 46.6, 46.6, 46.6, 39.42, 39.42, 39.42, 39.42, 39.42], "power_watts_avg": 43.62, "power_watts_peak": 47.6, "energy_joules_est": 83.3, "sample_count": 19, "duration_seconds": 1.91}, "timestamp": "2026-01-12T09:50:56.323327"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1862.683, "latencies_ms": [1862.683], "images_per_second": 0.537, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The horses are positioned in the middle of the road, with the car parked on the right side of the street. The car is relatively close to the camera, while the horses are farther away. The horses are near the car, but not directly in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13272.3, "ram_available_mb": 109234.0, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [34.38, 34.38, 34.38, 34.38, 46.23, 46.23, 46.23, 46.23, 46.23, 47.81, 47.81, 47.81, 47.81, 47.81, 35.74, 35.74, 35.74, 35.74, 35.74], "power_watts_avg": 41.39, "power_watts_peak": 47.81, "energy_joules_est": 77.11, "sample_count": 19, "duration_seconds": 1.863}, "timestamp": "2026-01-12T09:50:58.239997"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1938.278, "latencies_ms": [1938.278], "images_per_second": 0.516, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " In a serene suburban setting, a group of horses, their coats a mix of brown and black, are peacefully grazing on the lush green grass along a quiet street. A silver car is parked on the side of the road, its presence adding a touch of modernity to the tranquil scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13272.3, "ram_available_mb": 109234.0, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13312.4, "ram_available_mb": 109193.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.66, 33.66, 33.66, 33.66, 33.66, 45.43, 45.43, 45.43, 45.43, 45.43, 46.49, 46.49, 46.49, 46.49, 46.49, 34.49, 34.49, 34.49, 34.49, 34.49], "power_watts_avg": 40.02, "power_watts_peak": 46.49, "energy_joules_est": 77.6, "sample_count": 20, "duration_seconds": 1.939}, "timestamp": "2026-01-12T09:51:00.309337"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1618.772, "latencies_ms": [1618.772], "images_per_second": 0.618, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a group of horses walking down a tree-lined street, with a silver car parked on the side of the road. The horses are brown and black, and the trees are green, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13308.5, "ram_available_mb": 109197.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13310.2, "ram_available_mb": 109196.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.39, 34.39, 34.39, 34.39, 41.72, 41.72, 41.72, 41.72, 41.72, 45.01, 45.01, 45.01, 45.01, 45.01, 38.53, 38.53, 38.53], "power_watts_avg": 40.4, "power_watts_peak": 45.01, "energy_joules_est": 65.42, "sample_count": 17, "duration_seconds": 1.619}, "timestamp": "2026-01-12T09:51:02.076395"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1151.522, "latencies_ms": [1151.522], "images_per_second": 0.868, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In the image, there is a wooden desk with a blue book and a red apple on it, and a blackboard behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.3, "ram_available_mb": 109204.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13326.8, "ram_available_mb": 109179.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.53, 38.53, 33.28, 33.28, 33.28, 33.28, 33.28, 45.64, 45.64, 45.64, 45.64, 45.64], "power_watts_avg": 39.31, "power_watts_peak": 45.64, "energy_joules_est": 45.27, "sample_count": 12, "duration_seconds": 1.152}, "timestamp": "2026-01-12T09:51:03.292114"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1226.651, "latencies_ms": [1226.651], "images_per_second": 0.815, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " desk: 1\nbooks: 1\napple: 1\nblackboard: 1\nchair: 1\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13318.9, "ram_available_mb": 109187.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13322.0, "ram_available_mb": 109184.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.09, 47.09, 47.09, 47.09, 47.09, 46.39, 46.39, 46.39, 46.39, 46.39, 46.39, 46.39, 46.39], "power_watts_avg": 46.66, "power_watts_peak": 47.09, "energy_joules_est": 57.26, "sample_count": 13, "duration_seconds": 1.227}, "timestamp": "2026-01-12T09:51:04.607938"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2079.268, "latencies_ms": [2079.268], "images_per_second": 0.481, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The desk is located in the foreground of the image, with the chalkboard behind it. The books are placed on the desk, with the apple on the right side of the desk. The chalkboard is positioned to the left of the desk, and the door is located in the background, behind the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.0, "ram_available_mb": 109184.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13324.6, "ram_available_mb": 109181.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.39, 46.39, 33.03, 33.03, 33.03, 33.03, 33.03, 46.05, 46.05, 46.05, 46.05, 46.05, 48.38, 48.38, 48.38, 48.38, 48.38, 34.34, 34.34, 34.34, 34.34], "power_watts_avg": 41.31, "power_watts_peak": 48.38, "energy_joules_est": 85.91, "sample_count": 21, "duration_seconds": 2.08}, "timestamp": "2026-01-12T09:51:06.727997"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1309.203, "latencies_ms": [1309.203], "images_per_second": 0.764, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In a classroom setting, a wooden desk is positioned in front of a blackboard, with a chair to the left and a picture on the wall to the right.", "error": null, "sys_before": {"cpu_percent": 5.7, "ram_used_mb": 13317.1, "ram_available_mb": 109189.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13317.8, "ram_available_mb": 109188.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [33.75, 33.75, 33.75, 33.75, 33.75, 45.74, 45.74, 45.74, 45.74, 45.74, 45.95, 45.95, 45.95], "power_watts_avg": 41.18, "power_watts_peak": 45.95, "energy_joules_est": 53.93, "sample_count": 13, "duration_seconds": 1.31}, "timestamp": "2026-01-12T09:51:08.091390"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 992.456, "latencies_ms": [992.456], "images_per_second": 1.008, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted in a warm brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.8, "ram_available_mb": 109192.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.5, "ram_available_mb": 109183.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [45.95, 45.95, 34.83, 34.83, 34.83, 34.83, 34.83, 47.78, 47.78, 47.78], "power_watts_avg": 40.94, "power_watts_peak": 47.78, "energy_joules_est": 40.64, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-12T09:51:09.105575"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1000.99, "latencies_ms": [1000.99], "images_per_second": 0.999, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A yellow and white bus with the number 475 on the back is parked on the street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13314.6, "ram_available_mb": 109191.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13327.7, "ram_available_mb": 109178.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 31.0}, "power_stats": {"power_watts_samples": [47.78, 47.78, 46.81, 46.81, 46.81, 46.81, 46.81, 46.87, 46.87, 46.87], "power_watts_avg": 47.02, "power_watts_peak": 47.78, "energy_joules_est": 47.09, "sample_count": 10, "duration_seconds": 1.002}, "timestamp": "2026-01-12T09:51:10.119457"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1081.323, "latencies_ms": [1081.323], "images_per_second": 0.925, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " bus: 1, car: 1, truck: 1, road: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.7, "ram_available_mb": 109178.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13317.8, "ram_available_mb": 109188.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 16.0}, "power_stats": {"power_watts_samples": [46.87, 46.87, 47.28, 47.28, 47.28, 47.28, 47.28, 47.32, 47.32, 47.32, 47.32], "power_watts_avg": 47.22, "power_watts_peak": 47.32, "energy_joules_est": 51.07, "sample_count": 11, "duration_seconds": 1.082}, "timestamp": "2026-01-12T09:51:11.228876"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1435.019, "latencies_ms": [1435.019], "images_per_second": 0.697, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bus is parked on the left side of the road, while the white van is parked on the right side. The bus is in the foreground, while the van is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.8, "ram_available_mb": 109188.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.6, "ram_available_mb": 109164.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.19, 48.19, 48.19, 48.19, 48.19, 47.03, 47.03, 47.03, 47.03, 47.03, 47.72, 47.72, 47.72, 47.72, 47.72], "power_watts_avg": 47.65, "power_watts_peak": 48.19, "energy_joules_est": 68.4, "sample_count": 15, "duration_seconds": 1.436}, "timestamp": "2026-01-12T09:51:12.740377"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 879.257, "latencies_ms": [879.257], "images_per_second": 1.137, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A yellow bus is driving down a busy street with other cars and a white van.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.6, "ram_available_mb": 109164.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.2, "ram_available_mb": 109148.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [33.47, 33.47, 33.47, 33.47, 33.47, 46.26, 46.26, 46.26, 46.26], "power_watts_avg": 39.16, "power_watts_peak": 46.26, "energy_joules_est": 34.45, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-12T09:51:13.653028"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1193.766, "latencies_ms": [1193.766], "images_per_second": 0.838, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken during the day with a lot of traffic on the road. The colors in the image are vibrant and the lighting is bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.6, "ram_available_mb": 109147.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.26, 45.59, 45.59, 45.59, 45.59, 45.59, 47.23, 47.23, 47.23, 47.23, 47.23, 49.27], "power_watts_avg": 46.64, "power_watts_peak": 49.27, "energy_joules_est": 55.7, "sample_count": 12, "duration_seconds": 1.194}, "timestamp": "2026-01-12T09:51:14.866160"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1419.022, "latencies_ms": [1419.022], "images_per_second": 0.705, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image shows a bathroom with a large mirror that reflects a television screen, which is playing a sports game, and two sinks with faucets, one of which is a double sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.6, "ram_available_mb": 109147.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13277.8, "ram_available_mb": 109228.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.27, 49.27, 49.27, 49.27, 43.8, 43.8, 43.8, 43.8, 43.8, 47.05, 47.05, 47.05, 47.05, 47.05, 37.84], "power_watts_avg": 45.94, "power_watts_peak": 49.27, "energy_joules_est": 65.2, "sample_count": 15, "duration_seconds": 1.419}, "timestamp": "2026-01-12T09:51:16.384313"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1974.823, "latencies_ms": [1974.823], "images_per_second": 0.506, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. television: 1\n2. mirror: 1\n3. sink: 2\n4. door: 1\n5. trash can: 1\n6. wall: 1\n7. countertop: 1\n8. tile: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13277.8, "ram_available_mb": 109228.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13332.7, "ram_available_mb": 109173.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [37.84, 37.84, 37.84, 37.84, 41.48, 41.48, 41.48, 41.48, 41.48, 45.66, 45.66, 45.66, 45.66, 45.66, 38.72, 38.72, 38.72, 38.72, 38.72, 34.4], "power_watts_avg": 40.75, "power_watts_peak": 45.66, "energy_joules_est": 80.5, "sample_count": 20, "duration_seconds": 1.975}, "timestamp": "2026-01-12T09:51:18.404157"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1518.196, "latencies_ms": [1518.196], "images_per_second": 0.659, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The television is positioned above the sink, with the mirror reflecting the television's image. The sink is located to the right of the television, and the trash can is situated to the left of the television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.7, "ram_available_mb": 109173.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.8, "ram_available_mb": 109122.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.4, 34.4, 34.4, 38.44, 38.44, 38.44, 38.44, 38.44, 45.87, 45.87, 45.87, 45.87, 45.87, 41.88, 41.88, 41.88], "power_watts_avg": 40.65, "power_watts_peak": 45.87, "energy_joules_est": 61.75, "sample_count": 16, "duration_seconds": 1.519}, "timestamp": "2026-01-12T09:51:20.067908"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1008.777, "latencies_ms": [1008.777], "images_per_second": 0.991, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A bathroom with a large mirror and two sinks, a television mounted on the wall, and a trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.8, "ram_available_mb": 109126.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13403.2, "ram_available_mb": 109103.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [41.88, 41.88, 33.85, 33.85, 33.85, 33.85, 33.85, 46.04, 46.04, 46.04, 46.04], "power_watts_avg": 39.74, "power_watts_peak": 46.04, "energy_joules_est": 40.1, "sample_count": 11, "duration_seconds": 1.009}, "timestamp": "2026-01-12T09:51:21.179607"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1141.214, "latencies_ms": [1141.214], "images_per_second": 0.876, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The bathroom has a beige tiled wall and a brown countertop. The television is turned on and is showing a football game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.3, "ram_available_mb": 109111.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13395.5, "ram_available_mb": 109110.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.04, 43.99, 43.99, 43.99, 43.99, 43.99, 45.84, 45.84, 45.84, 45.84, 45.84, 48.61], "power_watts_avg": 45.32, "power_watts_peak": 48.61, "energy_joules_est": 51.73, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-12T09:51:22.391648"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.323, "latencies_ms": [983.323], "images_per_second": 1.017, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man sits on a bench in a park with a church in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.6, "ram_available_mb": 109118.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13418.8, "ram_available_mb": 109087.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.61, 48.61, 48.61, 48.61, 40.66, 40.66, 40.66, 40.66, 40.66, 50.6], "power_watts_avg": 44.83, "power_watts_peak": 50.6, "energy_joules_est": 44.09, "sample_count": 10, "duration_seconds": 0.983}, "timestamp": "2026-01-12T09:51:23.404484"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1589.96, "latencies_ms": [1589.96], "images_per_second": 0.629, "prompt_tokens": 1446, "response_tokens_est": 38, "n_tiles": 1, "output_text": " 1. man sitting on bench\n2. bench\n3. street lamp\n4. tree\n5. building\n6. clock on tower\n7. bushes\n8. clouds", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.0, "ram_available_mb": 109092.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.6, "ram_available_mb": 109112.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [50.6, 50.6, 50.6, 50.6, 51.2, 51.2, 51.2, 51.2, 51.2, 50.97, 50.97, 50.97, 50.97, 50.97, 45.06, 45.06], "power_watts_avg": 50.21, "power_watts_peak": 51.2, "energy_joules_est": 79.85, "sample_count": 16, "duration_seconds": 1.59}, "timestamp": "2026-01-12T09:51:25.019529"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1542.224, "latencies_ms": [1542.224], "images_per_second": 0.648, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The man is sitting on the left side of the bench, which is located in the foreground of the image. The church steeple is in the background, towering over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.6, "ram_available_mb": 109112.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13410.3, "ram_available_mb": 109096.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.06, 45.06, 45.06, 35.47, 35.47, 35.47, 35.47, 35.47, 51.27, 51.27, 51.27, 51.27, 50.32, 50.32, 50.32, 50.32], "power_watts_avg": 44.93, "power_watts_peak": 51.27, "energy_joules_est": 69.31, "sample_count": 16, "duration_seconds": 1.543}, "timestamp": "2026-01-12T09:51:26.635591"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 993.052, "latencies_ms": [993.052], "images_per_second": 1.007, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man sits on a bench in a park with a church in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.6, "ram_available_mb": 109105.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13416.1, "ram_available_mb": 109090.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [50.32, 31.61, 31.61, 31.61, 31.61, 31.61, 50.14, 50.14, 50.14, 50.14], "power_watts_avg": 40.89, "power_watts_peak": 50.32, "energy_joules_est": 40.62, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-12T09:51:27.648168"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1490.506, "latencies_ms": [1490.506], "images_per_second": 0.671, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the man and the background. The sky is filled with clouds, and the trees are lush and green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.2, "ram_available_mb": 109095.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13395.7, "ram_available_mb": 109110.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [50.14, 51.74, 51.74, 51.74, 51.74, 51.74, 51.46, 51.46, 51.46, 51.46, 51.46, 53.3, 53.3, 53.3, 53.3], "power_watts_avg": 51.96, "power_watts_peak": 53.3, "energy_joules_est": 77.47, "sample_count": 15, "duration_seconds": 1.491}, "timestamp": "2026-01-12T09:51:29.163124"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1619.181, "latencies_ms": [1619.181], "images_per_second": 0.618, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a city, with a variety of vehicles parked and moving along the road, including cars, buses, and trucks, all under the watchful eye of a large stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.9, "ram_available_mb": 109120.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.0, "ram_available_mb": 109133.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [53.3, 33.35, 33.35, 33.35, 33.35, 33.35, 47.26, 47.26, 47.26, 47.26, 47.26, 49.1, 49.1, 49.1, 49.1, 49.1, 34.43], "power_watts_avg": 43.31, "power_watts_peak": 53.3, "energy_joules_est": 70.13, "sample_count": 17, "duration_seconds": 1.619}, "timestamp": "2026-01-12T09:51:30.879862"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1331.064, "latencies_ms": [1331.064], "images_per_second": 0.751, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " 1. street light\n2. car\n3. person\n4. building\n5. sign\n6. tree\n7. street sign\n8. bus", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.1, "ram_available_mb": 109137.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [34.43, 34.43, 34.43, 34.43, 42.39, 42.39, 42.39, 42.39, 42.39, 45.85, 45.85, 45.85, 45.85, 45.85], "power_watts_avg": 41.35, "power_watts_peak": 45.85, "energy_joules_est": 55.05, "sample_count": 14, "duration_seconds": 1.331}, "timestamp": "2026-01-12T09:51:32.293294"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1416.438, "latencies_ms": [1416.438], "images_per_second": 0.706, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The cars are parked on the right side of the street, while the street is on the left side. The cars are parked near the sidewalk, and the street is near the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13374.2, "ram_available_mb": 109132.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.69, 38.69, 38.69, 38.69, 38.69, 46.21, 46.21, 46.21, 46.21, 46.21, 46.69, 46.69, 46.69, 46.69, 46.69], "power_watts_avg": 43.86, "power_watts_peak": 46.69, "energy_joules_est": 62.14, "sample_count": 15, "duration_seconds": 1.417}, "timestamp": "2026-01-12T09:51:33.804355"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1619.784, "latencies_ms": [1619.784], "images_per_second": 0.617, "prompt_tokens": 1111, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a city, with a variety of vehicles parked and moving along the road. The buildings in the background suggest an urban setting, and the presence of a bus stop indicates public transportation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.2, "ram_available_mb": 109132.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13441.6, "ram_available_mb": 109064.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.79, 34.79, 34.79, 45.51, 45.51, 45.51, 45.51, 45.51, 46.13, 46.13, 46.13, 46.13, 46.13, 34.36, 34.36], "power_watts_avg": 41.22, "power_watts_peak": 46.13, "energy_joules_est": 66.79, "sample_count": 17, "duration_seconds": 1.62}, "timestamp": "2026-01-12T09:51:35.516587"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1365.019, "latencies_ms": [1365.019], "images_per_second": 0.733, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a clear blue sky with a few clouds, and the sun is shining brightly. The cars are parked in a row, and the buildings are made of stone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13441.6, "ram_available_mb": 109064.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13413.4, "ram_available_mb": 109092.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.36, 34.36, 34.36, 36.25, 36.25, 36.25, 36.25, 36.25, 45.82, 45.82, 45.82, 45.82, 45.82, 44.63], "power_watts_avg": 39.86, "power_watts_peak": 45.82, "energy_joules_est": 54.43, "sample_count": 14, "duration_seconds": 1.366}, "timestamp": "2026-01-12T09:51:36.927516"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1654.27, "latencies_ms": [1654.27], "images_per_second": 0.604, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a top-down view of a wooden table adorned with a white plate holding a half-eaten omelette, a cup of tea, a small bowl of sugar, and a plate of sliced fruit.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13405.5, "ram_available_mb": 109100.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13401.9, "ram_available_mb": 109104.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [44.63, 44.63, 44.63, 44.63, 40.87, 40.87, 40.87, 40.87, 46.72, 46.72, 46.72, 46.72, 46.72, 39.82, 39.82, 39.82, 39.82], "power_watts_avg": 43.23, "power_watts_peak": 46.72, "energy_joules_est": 71.55, "sample_count": 17, "duration_seconds": 1.655}, "timestamp": "2026-01-12T09:51:38.650445"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1544.534, "latencies_ms": [1544.534], "images_per_second": 0.647, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " plate: 1, cup: 1, fork: 1, knife: 1, banana: 1, watermelon: 1, apple: 1, cup of tea: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.9, "ram_available_mb": 109104.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13449.8, "ram_available_mb": 109056.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [39.82, 31.46, 31.46, 31.46, 31.46, 31.46, 46.36, 46.36, 46.36, 46.36, 46.36, 48.94, 48.94, 48.94, 48.94, 48.94], "power_watts_avg": 42.1, "power_watts_peak": 48.94, "energy_joules_est": 65.04, "sample_count": 16, "duration_seconds": 1.545}, "timestamp": "2026-01-12T09:51:40.265788"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1622.652, "latencies_ms": [1622.652], "images_per_second": 0.616, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The plate of food is located in the foreground, with the cup of tea and sugar bowl placed in the middle ground. The shadow of the table is cast on the floor, indicating the light source is coming from above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13445.8, "ram_available_mb": 109060.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13415.8, "ram_available_mb": 109090.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.63, 33.63, 33.63, 33.63, 33.63, 46.34, 46.34, 46.34, 46.34, 46.34, 46.77, 46.77, 46.77, 46.77, 46.77, 34.17, 34.17], "power_watts_avg": 41.29, "power_watts_peak": 46.77, "energy_joules_est": 67.03, "sample_count": 17, "duration_seconds": 1.623}, "timestamp": "2026-01-12T09:51:41.983005"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1180.745, "latencies_ms": [1180.745], "images_per_second": 0.847, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A wooden table with a plate of food, a cup of coffee, and a bowl of fruit is set on a white tiled floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.9, "ram_available_mb": 109098.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13423.3, "ram_available_mb": 109083.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.17, 34.17, 34.17, 37.31, 37.31, 37.31, 37.31, 37.31, 45.78, 45.78, 45.78, 45.78], "power_watts_avg": 39.35, "power_watts_peak": 45.78, "energy_joules_est": 46.48, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-12T09:51:43.196650"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2185.996, "latencies_ms": [2185.996], "images_per_second": 0.457, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a cup of tea, and a bowl of fruit. The table is set in a room with white tiled floors and a window with a view of trees outside. The lighting is natural, coming from the window, and the colors are vibrant and bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.4, "ram_available_mb": 109090.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [45.78, 41.58, 41.58, 41.58, 41.58, 41.58, 47.07, 47.07, 47.07, 47.07, 47.07, 47.98, 47.98, 47.98, 47.98, 47.98, 33.79, 33.79, 33.79, 33.79, 33.79, 33.66], "power_watts_avg": 42.34, "power_watts_peak": 47.98, "energy_joules_est": 92.58, "sample_count": 22, "duration_seconds": 2.187}, "timestamp": "2026-01-12T09:51:45.416028"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1394.819, "latencies_ms": [1394.819], "images_per_second": 0.717, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " An elderly woman wearing a green and white striped shirt and a pink apron is preparing food on a table with a variety of baked goods, including cookies, bread, and pastries.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.2, "ram_available_mb": 109130.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [33.66, 33.66, 33.66, 38.15, 38.15, 38.15, 38.15, 38.15, 46.05, 46.05, 46.05, 46.05, 46.05, 42.54], "power_watts_avg": 40.32, "power_watts_peak": 46.05, "energy_joules_est": 56.3, "sample_count": 14, "duration_seconds": 1.396}, "timestamp": "2026-01-12T09:51:46.885003"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1929.618, "latencies_ms": [1929.618], "images_per_second": 0.518, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. apron: 1\n3. table: 1\n4. chair: 1\n5. door: 1\n6. glass: 1\n7. cup: 1\n8. food: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.2, "ram_available_mb": 109130.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13414.5, "ram_available_mb": 109091.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.54, 42.54, 42.54, 42.54, 43.51, 43.51, 43.51, 43.51, 43.51, 47.53, 47.53, 47.53, 47.53, 47.53, 38.15, 38.15, 38.15, 38.15, 38.15, 34.49], "power_watts_avg": 42.53, "power_watts_peak": 47.53, "energy_joules_est": 82.09, "sample_count": 20, "duration_seconds": 1.93}, "timestamp": "2026-01-12T09:51:48.903071"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1240.334, "latencies_ms": [1240.334], "images_per_second": 0.806, "prompt_tokens": 1118, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The person is standing to the left of the table, with the table in the foreground. The person is near the door, which is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.7, "ram_available_mb": 109101.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.9, "ram_available_mb": 109095.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [34.49, 34.49, 34.49, 38.48, 38.48, 38.48, 38.48, 38.48, 45.1, 45.1, 45.1, 45.1, 45.1], "power_watts_avg": 40.1, "power_watts_peak": 45.1, "energy_joules_est": 49.78, "sample_count": 13, "duration_seconds": 1.241}, "timestamp": "2026-01-12T09:51:50.269378"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1013.705, "latencies_ms": [1013.705], "images_per_second": 0.986, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " An elderly woman wearing a green and white striped shirt and a pink apron is preparing food on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.9, "ram_available_mb": 109095.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13474.3, "ram_available_mb": 109032.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.72, 40.72, 40.72, 40.72, 40.72, 46.52, 46.52, 46.52, 46.52, 46.52, 47.02], "power_watts_avg": 43.93, "power_watts_peak": 47.02, "energy_joules_est": 44.54, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:51:51.381528"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1426.688, "latencies_ms": [1426.688], "images_per_second": 0.701, "prompt_tokens": 1110, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming through the window. The table is covered with a colorful tablecloth, and the food is arranged on a cooling rack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13466.5, "ram_available_mb": 109039.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13436.8, "ram_available_mb": 109069.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.02, 47.02, 47.02, 47.02, 42.49, 42.49, 42.49, 42.49, 42.49, 46.14, 46.14, 46.14, 46.14, 46.14, 37.99], "power_watts_avg": 44.61, "power_watts_peak": 47.02, "energy_joules_est": 63.67, "sample_count": 15, "duration_seconds": 1.427}, "timestamp": "2026-01-12T09:51:52.897733"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1406.781, "latencies_ms": [1406.781], "images_per_second": 0.711, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A man stands in front of a traffic light with a sign that says \"AUSTRALIA MOST BAD TRAFFIC LIGHT\" and a red fire hydrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13432.8, "ram_available_mb": 109073.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13439.7, "ram_available_mb": 109066.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [37.99, 37.99, 37.99, 37.99, 41.58, 41.58, 41.58, 41.58, 41.58, 46.21, 46.21, 46.21, 46.21, 46.21], "power_watts_avg": 42.21, "power_watts_peak": 46.21, "energy_joules_est": 59.38, "sample_count": 14, "duration_seconds": 1.407}, "timestamp": "2026-01-12T09:51:54.317124"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1355.324, "latencies_ms": [1355.324], "images_per_second": 0.738, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " person: 1, sign: 1, traffic light: 1, pole: 1, tree: 1, flower: 1, road: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.8, "ram_available_mb": 109074.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13416.6, "ram_available_mb": 109089.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.88, 38.88, 38.88, 38.88, 38.88, 46.9, 46.9, 46.9, 46.9, 46.9, 47.78, 47.78, 47.78, 47.78], "power_watts_avg": 44.29, "power_watts_peak": 47.78, "energy_joules_est": 60.03, "sample_count": 14, "duration_seconds": 1.355}, "timestamp": "2026-01-12T09:51:55.731417"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1984.303, "latencies_ms": [1984.303], "images_per_second": 0.504, "prompt_tokens": 1118, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The man is standing to the left of the traffic light, which is positioned in the middle of the image. The traffic light is in front of a sign that reads \"AUSTRALIA MOST BAD TRAFFIC LIGHT,\" which is located to the right of the man.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.6, "ram_available_mb": 109089.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13396.5, "ram_available_mb": 109109.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.78, 35.09, 35.09, 35.09, 35.09, 35.09, 46.63, 46.63, 46.63, 46.63, 46.63, 47.87, 47.87, 47.87, 47.87, 34.51, 34.51, 34.51, 34.51, 34.51], "power_watts_avg": 41.02, "power_watts_peak": 47.87, "energy_joules_est": 81.42, "sample_count": 20, "duration_seconds": 1.985}, "timestamp": "2026-01-12T09:51:57.747814"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 960.186, "latencies_ms": [960.186], "images_per_second": 1.041, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man stands in front of a traffic light and a sign that says \"Australia Most Dangerous Road\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.6, "ram_available_mb": 109113.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13393.2, "ram_available_mb": 109113.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.32, 34.32, 34.32, 34.32, 34.32, 45.96, 45.96, 45.96, 45.96, 45.96], "power_watts_avg": 40.14, "power_watts_peak": 45.96, "energy_joules_est": 38.58, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-12T09:51:58.811293"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1254.479, "latencies_ms": [1254.479], "images_per_second": 0.797, "prompt_tokens": 1110, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The man is wearing a white t-shirt and khaki shorts. The traffic light is red, yellow, and green. The sky is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.2, "ram_available_mb": 109113.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13377.1, "ram_available_mb": 109129.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.37, 46.37, 46.37, 46.37, 46.37, 47.07, 47.07, 47.07, 47.07, 47.07, 46.89, 46.89, 46.89], "power_watts_avg": 46.76, "power_watts_peak": 47.07, "energy_joules_est": 58.69, "sample_count": 13, "duration_seconds": 1.255}, "timestamp": "2026-01-12T09:52:00.126271"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1151.654, "latencies_ms": [1151.654], "images_per_second": 0.868, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A large group of people are gathered in a park to fly a variety of kites, including a large red and white fish kite.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.2, "ram_available_mb": 109137.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13299.2, "ram_available_mb": 109207.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.89, 46.89, 32.29, 32.29, 32.29, 32.29, 32.29, 46.53, 46.53, 46.53, 46.53, 46.53], "power_watts_avg": 40.66, "power_watts_peak": 46.89, "energy_joules_est": 46.84, "sample_count": 12, "duration_seconds": 1.152}, "timestamp": "2026-01-12T09:52:01.341146"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2079.212, "latencies_ms": [2079.212], "images_per_second": 0.481, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Kites: 12\n2. People: 10\n3. Trees: 10\n4. Buildings: 1\n5. Kite String: 1\n6. Grass: 1\n7. Clouds: 1\n8. Sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13299.2, "ram_available_mb": 109207.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.5, "ram_available_mb": 109151.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.46, 48.46, 48.46, 48.46, 44.3, 44.3, 44.3, 44.3, 44.3, 46.37, 46.37, 46.37, 46.37, 46.37, 35.85, 35.85, 35.85, 35.85, 35.85, 34.37, 34.37], "power_watts_avg": 42.63, "power_watts_peak": 48.46, "energy_joules_est": 88.65, "sample_count": 21, "duration_seconds": 2.08}, "timestamp": "2026-01-12T09:52:03.460164"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2377.467, "latencies_ms": [2377.467], "images_per_second": 0.421, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The kites are positioned in the foreground, with the largest and most prominent one being in the center. The kites are arranged in a semi-circle formation, with the largest one at the front and the smaller ones behind it. The kites are flying at varying heights, with the largest one being at the highest point and the smaller ones at lower levels.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.6, "ram_available_mb": 109159.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.4, "ram_available_mb": 109171.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.37, 34.37, 34.37, 38.63, 38.63, 38.63, 38.63, 38.63, 46.74, 46.74, 46.74, 46.74, 46.74, 42.2, 42.2, 42.2, 42.2, 42.2, 34.35, 34.35, 34.35, 34.35, 34.35, 34.41], "power_watts_avg": 39.46, "power_watts_peak": 46.74, "energy_joules_est": 93.84, "sample_count": 24, "duration_seconds": 2.378}, "timestamp": "2026-01-12T09:52:05.895527"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1223.52, "latencies_ms": [1223.52], "images_per_second": 0.817, "prompt_tokens": 1111, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A large group of people are gathered in a park to fly kites. The kites are shaped like fish and are flying high in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.6, "ram_available_mb": 109176.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13343.5, "ram_available_mb": 109162.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 40.0}, "power_stats": {"power_watts_samples": [34.41, 34.41, 34.41, 40.29, 40.29, 40.29, 40.29, 40.29, 45.76, 45.76, 45.76, 45.76, 45.76], "power_watts_avg": 41.04, "power_watts_peak": 45.76, "energy_joules_est": 50.24, "sample_count": 13, "duration_seconds": 1.224}, "timestamp": "2026-01-12T09:52:07.252154"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 881.373, "latencies_ms": [881.373], "images_per_second": 1.135, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The sky is overcast, and the kite is red, orange, and purple.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.5, "ram_available_mb": 109162.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13443.8, "ram_available_mb": 109062.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 40.0}, "power_stats": {"power_watts_samples": [39.56, 39.56, 39.56, 39.56, 39.56, 46.3, 46.3, 46.3, 46.3], "power_watts_avg": 42.56, "power_watts_peak": 46.3, "energy_joules_est": 37.53, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T09:52:08.164216"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 958.966, "latencies_ms": [958.966], "images_per_second": 1.043, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a blue jacket is giving a slice of pizza to a young boy with curly hair.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13443.8, "ram_available_mb": 109062.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13431.8, "ram_available_mb": 109074.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 12.0}, "power_stats": {"power_watts_samples": [46.3, 45.53, 45.53, 45.53, 45.53, 45.53, 47.07, 47.07, 47.07, 47.07], "power_watts_avg": 46.23, "power_watts_peak": 47.07, "energy_joules_est": 44.34, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-12T09:52:09.177853"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1907.176, "latencies_ms": [1907.176], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. boy: 1\n3. pizza: 1\n4. box: 1\n5. blanket: 1\n6. chair: 1\n7. window: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.8, "ram_available_mb": 109074.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.07, 47.18, 47.18, 47.18, 47.18, 47.18, 46.7, 46.7, 46.7, 46.7, 46.7, 49.23, 49.23, 49.23, 49.23, 49.23, 34.49, 34.49, 34.49], "power_watts_avg": 45.58, "power_watts_peak": 49.23, "energy_joules_est": 86.96, "sample_count": 19, "duration_seconds": 1.908}, "timestamp": "2026-01-12T09:52:11.096334"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1883.037, "latencies_ms": [1883.037], "images_per_second": 0.531, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, while the child is on the right side. The pizza is in the middle of the image, and the man is holding it with his right hand. The child is holding a slice of pizza with his left hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13415.6, "ram_available_mb": 109090.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.49, 32.34, 32.34, 32.34, 32.34, 32.34, 46.72, 46.72, 46.72, 46.72, 46.72, 49.08, 49.08, 49.08, 49.08, 49.08, 34.43, 34.43, 34.43], "power_watts_avg": 40.97, "power_watts_peak": 49.08, "energy_joules_est": 77.18, "sample_count": 19, "duration_seconds": 1.884}, "timestamp": "2026-01-12T09:52:13.064943"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 979.256, "latencies_ms": [979.256], "images_per_second": 1.021, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man and a child are sitting on the floor in a living room, sharing a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.8, "ram_available_mb": 109098.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13429.8, "ram_available_mb": 109076.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 27.0}, "power_stats": {"power_watts_samples": [34.43, 34.43, 33.43, 33.43, 33.43, 33.43, 33.43, 46.43, 46.43, 46.43], "power_watts_avg": 37.53, "power_watts_peak": 46.43, "energy_joules_est": 36.78, "sample_count": 10, "duration_seconds": 0.98}, "timestamp": "2026-01-12T09:52:14.125869"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1190.64, "latencies_ms": [1190.64], "images_per_second": 0.84, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a room with orange walls and a tiled floor. The lighting is natural, coming from a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.8, "ram_available_mb": 109080.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13419.0, "ram_available_mb": 109087.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 46.95, 46.95, 46.95, 46.95, 46.95, 47.49, 47.49, 47.49, 47.49, 47.49], "power_watts_avg": 47.09, "power_watts_peak": 47.49, "energy_joules_est": 56.09, "sample_count": 12, "duration_seconds": 1.191}, "timestamp": "2026-01-12T09:52:15.339893"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 872.285, "latencies_ms": [872.285], "images_per_second": 1.146, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman wearing a striped shirt is eating a hot dog while sitting in a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.1, "ram_available_mb": 109095.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13409.0, "ram_available_mb": 109097.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [48.53, 48.53, 48.53, 48.53, 46.32, 46.32, 46.32, 46.32, 46.32], "power_watts_avg": 47.3, "power_watts_peak": 48.53, "energy_joules_est": 41.27, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-12T09:52:16.252998"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1931.319, "latencies_ms": [1931.319], "images_per_second": 0.518, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. chair: 1\n3. plate: 1\n4. food: 1\n5. bag: 1\n6. chair leg: 1\n7. ground: 1\n8. rock: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13409.0, "ram_available_mb": 109097.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13391.5, "ram_available_mb": 109114.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [46.88, 46.88, 46.88, 46.88, 46.88, 48.4, 48.4, 48.4, 48.4, 48.4, 47.91, 47.91, 47.91, 47.91, 47.91, 34.53, 34.53, 34.53, 34.53, 34.53], "power_watts_avg": 44.43, "power_watts_peak": 48.4, "energy_joules_est": 85.83, "sample_count": 20, "duration_seconds": 1.932}, "timestamp": "2026-01-12T09:52:18.268866"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1851.147, "latencies_ms": [1851.147], "images_per_second": 0.54, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The person is sitting on the left side of the image, with the plate of food placed in front of them on the right side. The plate of food is positioned closer to the camera than the person, and the person is eating the food while sitting on the chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.6, "ram_available_mb": 109118.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.8, "ram_available_mb": 109118.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.33, 33.33, 33.33, 33.33, 33.33, 45.07, 45.07, 45.07, 45.07, 45.07, 46.47, 46.47, 46.47, 46.47, 46.47, 34.56, 34.56, 34.56, 34.56], "power_watts_avg": 40.14, "power_watts_peak": 46.47, "energy_joules_est": 74.35, "sample_count": 19, "duration_seconds": 1.852}, "timestamp": "2026-01-12T09:52:20.240434"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 820.682, "latencies_ms": [820.682], "images_per_second": 1.218, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is sitting in a chair and eating a hot dog while camping.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.1, "ram_available_mb": 109134.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13391.1, "ram_available_mb": 109115.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 41.0}, "power_stats": {"power_watts_samples": [33.24, 33.24, 33.24, 33.24, 33.24, 45.53, 45.53, 45.53, 45.53], "power_watts_avg": 38.7, "power_watts_peak": 45.53, "energy_joules_est": 31.8, "sample_count": 9, "duration_seconds": 0.822}, "timestamp": "2026-01-12T09:52:21.202435"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1321.466, "latencies_ms": [1321.466], "images_per_second": 0.757, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken at night, with the subject illuminated by a flashlight. The subject is wearing a green and white striped shirt and is seated on a blue camping chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.1, "ram_available_mb": 109119.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13379.5, "ram_available_mb": 109126.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.53, 44.59, 44.59, 44.59, 44.59, 44.59, 46.34, 46.34, 46.34, 46.34, 46.34, 48.81, 48.81, 48.81], "power_watts_avg": 46.19, "power_watts_peak": 48.81, "energy_joules_est": 61.06, "sample_count": 14, "duration_seconds": 1.322}, "timestamp": "2026-01-12T09:52:22.618293"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1013.674, "latencies_ms": [1013.674], "images_per_second": 0.987, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A family of 12 is gathered around a long table in a dining room, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13377.1, "ram_available_mb": 109129.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.81, 48.81, 32.56, 32.56, 32.56, 32.56, 32.56, 46.0, 46.0, 46.0, 46.0], "power_watts_avg": 40.41, "power_watts_peak": 48.81, "energy_joules_est": 40.97, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:52:23.734231"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1478.096, "latencies_ms": [1478.096], "images_per_second": 0.677, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " tablecloth: 1, plates: 10, cups: 10, glasses: 10, food: 10, chairs: 4, people: 14", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13360.6, "ram_available_mb": 109145.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [46.0, 46.53, 46.53, 46.53, 46.53, 46.53, 45.85, 45.85, 45.85, 45.85, 45.85, 48.19, 48.19, 48.19, 48.19], "power_watts_avg": 46.71, "power_watts_peak": 48.19, "energy_joules_est": 69.07, "sample_count": 15, "duration_seconds": 1.479}, "timestamp": "2026-01-12T09:52:25.250092"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2079.174, "latencies_ms": [2079.174], "images_per_second": 0.481, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The people are positioned in the middle of the image, with the table being the central focus. The background includes a doorway and a painting on the wall, which are relatively far from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.7, "ram_available_mb": 109149.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13275.8, "ram_available_mb": 109230.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.06, 34.06, 34.06, 34.06, 34.06, 47.0, 47.0, 47.0, 47.0, 47.0, 47.74, 47.74, 47.74, 47.74, 47.74, 34.54, 34.54, 34.54, 34.54, 34.54, 34.42], "power_watts_avg": 40.53, "power_watts_peak": 47.74, "energy_joules_est": 84.28, "sample_count": 21, "duration_seconds": 2.079}, "timestamp": "2026-01-12T09:52:27.369741"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 961.359, "latencies_ms": [961.359], "images_per_second": 1.04, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered around a long table in a dining room, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13275.8, "ram_available_mb": 109230.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.42, 34.42, 34.42, 34.42, 41.34, 41.34, 41.34, 41.34, 41.34, 45.87], "power_watts_avg": 39.02, "power_watts_peak": 45.87, "energy_joules_est": 37.54, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-12T09:52:28.433443"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1414.084, "latencies_ms": [1414.084], "images_per_second": 0.707, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is well-lit with natural light coming from the windows, and the colors are vibrant and warm. The tablecloth is purple, and the food is colorful and appetizing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.1, "ram_available_mb": 109187.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.87, 45.87, 45.87, 45.87, 46.01, 46.01, 46.01, 46.01, 46.01, 46.6, 46.6, 46.6, 46.6, 46.6, 40.77], "power_watts_avg": 45.82, "power_watts_peak": 46.6, "energy_joules_est": 64.82, "sample_count": 15, "duration_seconds": 1.415}, "timestamp": "2026-01-12T09:52:29.949178"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1248.913, "latencies_ms": [1248.913], "images_per_second": 0.801, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A baseball game is taking place with players on the field, including a player sliding into a base, and a catcher and umpire standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.1, "ram_available_mb": 109183.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13415.7, "ram_available_mb": 109090.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [40.77, 40.77, 40.77, 40.05, 40.05, 40.05, 40.05, 40.05, 45.85, 45.85, 45.85, 45.85, 45.85], "power_watts_avg": 42.45, "power_watts_peak": 45.85, "energy_joules_est": 53.04, "sample_count": 13, "duration_seconds": 1.249}, "timestamp": "2026-01-12T09:52:31.263945"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2010.224, "latencies_ms": [2010.224], "images_per_second": 0.497, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. catcher: 1\n3. umpire: 1\n4. batter: 1\n5. field: 1\n6. fence: 1\n7. bench: 1\n8. spectators: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.7, "ram_available_mb": 109090.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13385.0, "ram_available_mb": 109121.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [39.62, 39.62, 39.62, 39.62, 39.62, 46.78, 46.78, 46.78, 46.78, 46.78, 47.56, 47.56, 47.56, 47.56, 47.56, 34.58, 34.58, 34.58, 34.58, 34.58], "power_watts_avg": 42.13, "power_watts_peak": 47.56, "energy_joules_est": 84.72, "sample_count": 20, "duration_seconds": 2.011}, "timestamp": "2026-01-12T09:52:33.282111"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1616.96, "latencies_ms": [1616.96], "images_per_second": 0.618, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The baseball player is in the foreground, sliding into the base, while the catcher and umpire are in the background. The player is near the base, while the catcher and umpire are far away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13276.6, "ram_available_mb": 109229.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.5, 34.5, 34.5, 34.5, 34.5, 47.79, 47.79, 47.79, 47.79, 47.79, 47.81, 47.81, 47.81, 47.81, 47.81, 34.59, 34.59], "power_watts_avg": 42.33, "power_watts_peak": 47.81, "energy_joules_est": 68.48, "sample_count": 17, "duration_seconds": 1.618}, "timestamp": "2026-01-12T09:52:34.997908"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1114.859, "latencies_ms": [1114.859], "images_per_second": 0.897, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a fence in the background, and a group of people are watching the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13276.6, "ram_available_mb": 109229.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.59, 34.59, 34.59, 38.08, 38.08, 38.08, 38.08, 38.08, 46.1, 46.1, 46.1, 46.1], "power_watts_avg": 39.88, "power_watts_peak": 46.1, "energy_joules_est": 44.48, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-12T09:52:36.212098"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1215.127, "latencies_ms": [1215.127], "images_per_second": 0.823, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with players in action on a field bathed in sunlight, and spectators seated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13339.1, "ram_available_mb": 109167.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.1, 40.13, 40.13, 40.13, 40.13, 40.13, 46.15, 46.15, 46.15, 46.15, 46.15, 48.02, 48.02], "power_watts_avg": 44.12, "power_watts_peak": 48.02, "energy_joules_est": 53.63, "sample_count": 13, "duration_seconds": 1.215}, "timestamp": "2026-01-12T09:52:37.525436"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1206.992, "latencies_ms": [1206.992], "images_per_second": 0.829, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person wearing a black helmet and black clothing is skateboarding on a ramp, with their shadow visible on the ramp.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13331.2, "ram_available_mb": 109175.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [48.02, 48.02, 48.02, 35.09, 35.09, 35.09, 35.09, 35.09, 49.97, 49.97, 49.97, 49.97], "power_watts_avg": 43.28, "power_watts_peak": 49.97, "energy_joules_est": 52.25, "sample_count": 12, "duration_seconds": 1.207}, "timestamp": "2026-01-12T09:52:38.742756"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2160.133, "latencies_ms": [2160.133], "images_per_second": 0.463, "prompt_tokens": 1446, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. knee pads: 2\n4. elbow pads: 1\n5. skateboard: 1\n6. rail: 1\n7. shadow: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.97, 49.9, 49.9, 49.9, 49.9, 48.88, 48.88, 48.88, 48.88, 48.88, 51.76, 51.76, 51.76, 51.76, 51.76, 37.14, 37.14, 37.14, 37.14, 37.14, 34.85, 34.85], "power_watts_avg": 45.82, "power_watts_peak": 51.76, "energy_joules_est": 99.0, "sample_count": 22, "duration_seconds": 2.16}, "timestamp": "2026-01-12T09:52:40.960983"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2092.239, "latencies_ms": [2092.239], "images_per_second": 0.478, "prompt_tokens": 1450, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on the ramp, while the background features a grassy area with trees and a fence. The shadow of the skateboarder is cast on the ramp, indicating the sun is positioned to the left of the skateboarder.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13310.7, "ram_available_mb": 109195.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 35.27, 35.27, 35.27, 35.27, 35.27, 49.44, 49.44, 49.44, 49.44, 49.44, 49.76, 49.76, 49.76, 49.76, 49.76, 34.69, 34.69, 34.69], "power_watts_avg": 41.95, "power_watts_peak": 49.76, "energy_joules_est": 87.81, "sample_count": 21, "duration_seconds": 2.093}, "timestamp": "2026-01-12T09:52:43.135261"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1000.404, "latencies_ms": [1000.404], "images_per_second": 1.0, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.7, "ram_available_mb": 109195.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13295.1, "ram_available_mb": 109211.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.69, 31.84, 31.84, 31.84, 31.84, 31.84, 49.38, 49.38, 49.38, 49.38], "power_watts_avg": 39.14, "power_watts_peak": 49.38, "energy_joules_est": 39.19, "sample_count": 10, "duration_seconds": 1.001}, "timestamp": "2026-01-12T09:52:44.196012"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2908.724, "latencies_ms": [2908.724], "images_per_second": 0.344, "prompt_tokens": 1442, "response_tokens_est": 87, "n_tiles": 1, "output_text": " The image features a skateboarder in action, wearing a black helmet and protective gear, with a concrete ramp in the foreground. The skateboarder is captured mid-air, performing a trick, and the shadow of the skateboarder is visible on the ramp. The lighting suggests it is a sunny day, and the colors are vibrant, with the green grass and trees in the background providing a natural contrast to the urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13295.1, "ram_available_mb": 109211.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13305.2, "ram_available_mb": 109201.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.38, 51.76, 51.76, 51.76, 51.76, 51.76, 51.57, 51.57, 51.57, 51.57, 51.57, 52.84, 52.84, 52.84, 52.84, 52.84, 35.05, 35.05, 35.05, 35.05, 35.05, 34.63, 34.63, 34.63, 34.63, 34.63, 34.74, 34.74, 34.74], "power_watts_avg": 44.24, "power_watts_peak": 52.84, "energy_joules_est": 128.69, "sample_count": 29, "duration_seconds": 2.909}, "timestamp": "2026-01-12T09:52:47.120979"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1373.766, "latencies_ms": [1373.766], "images_per_second": 0.728, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image displays a dining table with a variety of food items, including a plate of fries, a sandwich, a salad, and a drink, all arranged neatly on white plates.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13305.2, "ram_available_mb": 109201.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13309.6, "ram_available_mb": 109196.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.74, 32.09, 32.09, 32.09, 32.09, 32.09, 46.47, 46.47, 46.47, 46.47, 46.47, 49.27, 49.27, 49.27], "power_watts_avg": 41.1, "power_watts_peak": 49.27, "energy_joules_est": 56.52, "sample_count": 14, "duration_seconds": 1.375}, "timestamp": "2026-01-12T09:52:48.588778"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1950.287, "latencies_ms": [1950.287], "images_per_second": 0.513, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 2\n2. fries: 1\n3. burger: 1\n4. tomato: 1\n5. lettuce: 1\n6. pickles: 2\n7. condiment: 1\n8. glass: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13305.7, "ram_available_mb": 109200.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13300.7, "ram_available_mb": 109205.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.27, 49.27, 35.49, 35.49, 35.49, 35.49, 35.49, 47.15, 47.15, 47.15, 47.15, 47.15, 46.51, 46.51, 46.51, 46.51, 46.51, 34.58, 34.58, 34.58], "power_watts_avg": 42.4, "power_watts_peak": 49.27, "energy_joules_est": 82.71, "sample_count": 20, "duration_seconds": 1.951}, "timestamp": "2026-01-12T09:52:50.607405"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2406.966, "latencies_ms": [2406.966], "images_per_second": 0.415, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The plate of fries is located to the left of the plate with the sandwich, which is in the foreground. The salad is positioned in the background, behind the plate with the sandwich. The glass of iced tea is located to the right of the plate with the sandwich, and the salt and pepper shakers are located to the right of the glass of iced tea.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13300.7, "ram_available_mb": 109205.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.0, "ram_available_mb": 109163.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.58, 30.87, 30.87, 30.87, 30.87, 30.87, 45.76, 45.76, 45.76, 45.76, 45.76, 49.43, 49.43, 49.43, 49.43, 49.43, 34.48, 34.48, 34.48, 34.48, 34.48, 34.54, 34.54, 34.54], "power_watts_avg": 39.2, "power_watts_peak": 49.43, "energy_joules_est": 94.39, "sample_count": 24, "duration_seconds": 2.408}, "timestamp": "2026-01-12T09:52:53.079166"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 821.118, "latencies_ms": [821.118], "images_per_second": 1.218, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A meal is set on a table with a drink and condiments.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.1, "ram_available_mb": 109167.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13372.4, "ram_available_mb": 109133.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 13.0}, "power_stats": {"power_watts_samples": [34.54, 34.54, 33.17, 33.17, 33.17, 33.17, 33.17, 46.53, 46.53], "power_watts_avg": 36.44, "power_watts_peak": 46.53, "energy_joules_est": 29.94, "sample_count": 9, "duration_seconds": 0.822}, "timestamp": "2026-01-12T09:52:54.040552"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2364.743, "latencies_ms": [2364.743], "images_per_second": 0.423, "prompt_tokens": 1109, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image features a white plate with a variety of food items, including a sandwich, fries, and a salad. The food is arranged on a table with a white tablecloth, and there is a glass of water and a glass of soda on the table. The lighting in the image is bright and natural, and the overall atmosphere appears to be a casual dining setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.5, "ram_available_mb": 109141.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13369.7, "ram_available_mb": 109136.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.53, 46.53, 46.53, 50.93, 50.93, 50.93, 50.93, 50.93, 46.41, 46.41, 46.41, 46.41, 44.17, 44.17, 44.17, 44.17, 44.17, 34.56, 34.56, 34.56, 34.56, 34.56, 34.62, 34.62], "power_watts_avg": 43.45, "power_watts_peak": 50.93, "energy_joules_est": 102.77, "sample_count": 24, "duration_seconds": 2.365}, "timestamp": "2026-01-12T09:52:56.461664"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 850.426, "latencies_ms": [850.426], "images_per_second": 1.176, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red motorcycle is parked on a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13361.9, "ram_available_mb": 109144.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.7, "ram_available_mb": 109139.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 37.13, 37.13, 37.13, 37.13, 37.13, 45.89], "power_watts_avg": 37.27, "power_watts_peak": 45.89, "energy_joules_est": 31.7, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-12T09:52:57.421999"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2279.818, "latencies_ms": [2279.818], "images_per_second": 0.439, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. Motorcycle: 1\n2. Tires: 2\n3. Seat: 1\n4. Handlebars: 1\n5. Windshield: 1\n6. Rearview mirror: 1\n7. Rear fender: 1\n8. Rear storage compartment: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.6, "ram_available_mb": 109139.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13336.5, "ram_available_mb": 109169.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.89, 45.89, 45.89, 45.89, 51.27, 51.27, 51.27, 51.27, 51.27, 46.72, 46.72, 46.72, 46.72, 46.72, 39.23, 39.23, 39.23, 39.23, 39.23, 34.5, 34.5, 34.5, 34.5], "power_watts_avg": 43.81, "power_watts_peak": 51.27, "energy_joules_est": 99.91, "sample_count": 23, "duration_seconds": 2.28}, "timestamp": "2026-01-12T09:52:59.738374"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1461.332, "latencies_ms": [1461.332], "images_per_second": 0.684, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the beach and palm trees in the background. The motorcycle is in the foreground, with the beach and palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.6, "ram_available_mb": 109177.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.8, "ram_available_mb": 109166.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.78, 33.78, 33.78, 33.78, 33.78, 46.21, 46.21, 46.21, 46.21, 46.21, 46.95, 46.95, 46.95, 46.95, 46.95], "power_watts_avg": 42.31, "power_watts_peak": 46.95, "energy_joules_est": 61.86, "sample_count": 15, "duration_seconds": 1.462}, "timestamp": "2026-01-12T09:53:01.300105"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 857.999, "latencies_ms": [857.999], "images_per_second": 1.166, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red motorcycle is parked on a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.8, "ram_available_mb": 109166.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13382.9, "ram_available_mb": 109123.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.55, 34.55, 34.55, 34.55, 34.55, 46.92, 46.92, 46.92, 46.92], "power_watts_avg": 40.05, "power_watts_peak": 46.92, "energy_joules_est": 34.37, "sample_count": 9, "duration_seconds": 0.858}, "timestamp": "2026-01-12T09:53:02.209110"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 778.079, "latencies_ms": [778.079], "images_per_second": 1.285, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The motorcycle is red and black, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.0, "ram_available_mb": 109127.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13373.9, "ram_available_mb": 109132.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 30.0}, "power_stats": {"power_watts_samples": [46.92, 45.03, 45.03, 45.03, 45.03, 45.03, 46.95, 46.95], "power_watts_avg": 45.75, "power_watts_peak": 46.95, "energy_joules_est": 35.61, "sample_count": 8, "duration_seconds": 0.778}, "timestamp": "2026-01-12T09:53:03.019092"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 964.296, "latencies_ms": [964.296], "images_per_second": 1.037, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a suit and tie is standing in front of a dark wall with a white switch.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13370.3, "ram_available_mb": 109136.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.95, 46.95, 46.95, 51.95, 51.95, 51.95, 51.95, 51.95, 47.23, 47.23], "power_watts_avg": 49.51, "power_watts_peak": 51.95, "energy_joules_est": 47.75, "sample_count": 10, "duration_seconds": 0.964}, "timestamp": "2026-01-12T09:53:04.030634"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1947.434, "latencies_ms": [1947.434], "images_per_second": 0.513, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. suit: 1\n3. tie: 1\n4. shirt: 1\n5. wall: 1\n6. light switch: 1\n7. door: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13355.7, "ram_available_mb": 109150.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 46.51, 46.51, 46.51, 46.51, 46.51, 46.71, 46.71, 46.71, 46.71, 46.71, 44.24, 44.24, 44.24, 44.24, 44.24, 34.49, 34.49], "power_watts_avg": 44.9, "power_watts_peak": 47.23, "energy_joules_est": 87.45, "sample_count": 20, "duration_seconds": 1.948}, "timestamp": "2026-01-12T09:53:06.046258"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1296.075, "latencies_ms": [1296.075], "images_per_second": 0.772, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The man is positioned to the left of the wall, with the wall being the background. The man is in the foreground, with the wall being the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.8, "ram_available_mb": 109154.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13338.6, "ram_available_mb": 109167.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.49, 34.49, 34.49, 36.21, 36.21, 36.21, 36.21, 36.21, 46.51, 46.51, 46.51, 46.51, 46.51], "power_watts_avg": 39.78, "power_watts_peak": 46.51, "energy_joules_est": 51.58, "sample_count": 13, "duration_seconds": 1.297}, "timestamp": "2026-01-12T09:53:07.359996"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 834.093, "latencies_ms": [834.093], "images_per_second": 1.199, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man in a suit and tie is standing in front of a wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.6, "ram_available_mb": 109167.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13342.1, "ram_available_mb": 109164.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [45.16, 45.16, 45.16, 45.16, 44.51, 44.51, 44.51, 44.51, 44.51], "power_watts_avg": 44.8, "power_watts_peak": 45.16, "energy_joules_est": 37.39, "sample_count": 9, "duration_seconds": 0.835}, "timestamp": "2026-01-12T09:53:08.269570"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1212.011, "latencies_ms": [1212.011], "images_per_second": 0.825, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The man is wearing a black suit with a white shirt and a black tie. The lighting is dim and the man's face is not visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.1, "ram_available_mb": 109164.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13355.2, "ram_available_mb": 109151.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.63, 46.63, 46.63, 46.63, 46.63, 49.05, 49.05, 49.05, 49.05, 49.05, 47.22, 47.22, 47.22], "power_watts_avg": 47.7, "power_watts_peak": 49.05, "energy_joules_est": 57.83, "sample_count": 13, "duration_seconds": 1.212}, "timestamp": "2026-01-12T09:53:09.583201"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 970.754, "latencies_ms": [970.754], "images_per_second": 1.03, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A cat is sleeping on a pair of shoes, with its head resting on one of the shoes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.2, "ram_available_mb": 109151.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13342.3, "ram_available_mb": 109164.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.22, 47.22, 33.4, 33.4, 33.4, 33.4, 33.4, 45.79, 45.79, 45.79], "power_watts_avg": 39.88, "power_watts_peak": 47.22, "energy_joules_est": 38.74, "sample_count": 10, "duration_seconds": 0.971}, "timestamp": "2026-01-12T09:53:10.595685"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2043.292, "latencies_ms": [2043.292], "images_per_second": 0.489, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Cat: 1\n2. Sneakers: 2\n3. Wall: 1\n4. Floor: 1\n5. Shoe: 1\n6. Laces: 1\n7. Nose: 1\n8. Paw: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.3, "ram_available_mb": 109164.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13372.7, "ram_available_mb": 109133.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.79, 45.79, 46.8, 46.8, 46.8, 46.8, 46.8, 47.1, 47.1, 47.1, 47.1, 47.1, 47.7, 47.7, 47.7, 47.7, 47.7, 34.59, 34.59, 34.59, 34.59], "power_watts_avg": 44.66, "power_watts_peak": 47.7, "energy_joules_est": 91.28, "sample_count": 21, "duration_seconds": 2.044}, "timestamp": "2026-01-12T09:53:12.714904"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1410.383, "latencies_ms": [1410.383], "images_per_second": 0.709, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The cat is sleeping on the left side of the shoe, which is on the right side of the image. The cat is in the foreground, while the shoe is in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13372.7, "ram_available_mb": 109133.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13406.0, "ram_available_mb": 109100.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [32.69, 32.69, 32.69, 32.69, 32.69, 45.45, 45.45, 45.45, 45.45, 45.45, 47.46, 47.46, 47.46, 47.46, 47.46], "power_watts_avg": 41.87, "power_watts_peak": 47.46, "energy_joules_est": 59.07, "sample_count": 15, "duration_seconds": 1.411}, "timestamp": "2026-01-12T09:53:14.279168"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 699.795, "latencies_ms": [699.795], "images_per_second": 1.429, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A cat is sleeping on a pair of shoes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13402.0, "ram_available_mb": 109104.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13402.0, "ram_available_mb": 109104.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [33.24, 33.24, 33.24, 33.24, 33.24, 45.53, 45.53], "power_watts_avg": 36.75, "power_watts_peak": 45.53, "energy_joules_est": 25.73, "sample_count": 7, "duration_seconds": 0.7}, "timestamp": "2026-01-12T09:53:14.988749"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 967.318, "latencies_ms": [967.318], "images_per_second": 1.034, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The cat is brown and white, the shoes are white and blue, and the wall is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.1, "ram_available_mb": 109108.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13323.3, "ram_available_mb": 109183.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.53, 45.53, 45.53, 52.46, 52.46, 52.46, 52.46, 52.46, 47.73, 47.73], "power_watts_avg": 49.43, "power_watts_peak": 52.46, "energy_joules_est": 47.83, "sample_count": 10, "duration_seconds": 0.968}, "timestamp": "2026-01-12T09:53:16.001268"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1383.464, "latencies_ms": [1383.464], "images_per_second": 0.723, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A green Isuzu truck with a red and white striped front is parked on the side of the road, with two workers in green uniforms standing on the back of the truck.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.3, "ram_available_mb": 109183.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13353.9, "ram_available_mb": 109152.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.73, 47.73, 47.73, 47.4, 47.4, 47.4, 47.4, 47.4, 47.17, 47.17, 47.17, 47.17, 47.17, 42.59], "power_watts_avg": 47.05, "power_watts_peak": 47.73, "energy_joules_est": 65.09, "sample_count": 14, "duration_seconds": 1.384}, "timestamp": "2026-01-12T09:53:17.417497"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2177.406, "latencies_ms": [2177.406], "images_per_second": 0.459, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. truck: 1\n2. people: 2\n3. building: 1\n4. license plate: 1\n5. truck's front: 1\n6. truck's side: 1\n7. truck's back: 1\n8. truck's rear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.9, "ram_available_mb": 109152.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13330.7, "ram_available_mb": 109175.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 42.59, 42.59, 41.48, 41.48, 41.48, 41.48, 41.48, 47.12, 47.12, 47.12, 47.12, 47.12, 39.79, 39.79, 39.79, 39.79, 39.79, 34.42, 34.42, 34.42], "power_watts_avg": 41.62, "power_watts_peak": 47.12, "energy_joules_est": 90.63, "sample_count": 22, "duration_seconds": 2.178}, "timestamp": "2026-01-12T09:53:19.637828"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1592.595, "latencies_ms": [1592.595], "images_per_second": 0.628, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The green truck is in the foreground, parked on the street. The two men are sitting on the back of the truck, which is parked on the street. The building in the background is far away from the truck.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.7, "ram_available_mb": 109175.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13335.3, "ram_available_mb": 109171.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.42, 31.7, 31.7, 31.7, 31.7, 31.7, 46.2, 46.2, 46.2, 46.2, 46.2, 49.06, 49.06, 49.06, 49.06, 49.06], "power_watts_avg": 41.83, "power_watts_peak": 49.06, "energy_joules_est": 66.66, "sample_count": 16, "duration_seconds": 1.594}, "timestamp": "2026-01-12T09:53:21.303567"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 851.132, "latencies_ms": [851.132], "images_per_second": 1.175, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A green truck with a white logo on the front is driving down a street.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13344.3, "ram_available_mb": 109162.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.46, 34.46, 34.46, 34.46, 34.46, 47.26, 47.26, 47.26, 47.26], "power_watts_avg": 40.15, "power_watts_peak": 47.26, "energy_joules_est": 34.2, "sample_count": 9, "duration_seconds": 0.852}, "timestamp": "2026-01-12T09:53:22.215017"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 770.939, "latencies_ms": [770.939], "images_per_second": 1.297, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The truck is green and white, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.4, "ram_available_mb": 109169.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 29.0}, "power_stats": {"power_watts_samples": [47.26, 45.73, 45.73, 45.73, 45.73, 45.73, 46.98, 46.98], "power_watts_avg": 46.24, "power_watts_peak": 47.26, "energy_joules_est": 35.65, "sample_count": 8, "duration_seconds": 0.771}, "timestamp": "2026-01-12T09:53:23.025296"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 941.13, "latencies_ms": [941.13], "images_per_second": 1.063, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A person is standing on a rocky riverbank, with a bridge and greenery in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13339.4, "ram_available_mb": 109166.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13334.0, "ram_available_mb": 109172.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.98, 46.98, 46.98, 51.7, 51.7, 51.7, 51.7, 51.7, 47.04, 47.04], "power_watts_avg": 49.35, "power_watts_peak": 51.7, "energy_joules_est": 46.47, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-12T09:53:24.039797"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1937.035, "latencies_ms": [1937.035], "images_per_second": 0.516, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. rocks: 20\n3. water: 1\n4. bridge: 1\n5. trees: 1\n6. bushes: 1\n7. grass: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.1, "ram_available_mb": 109176.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13337.9, "ram_available_mb": 109168.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.04, 47.04, 47.04, 46.0, 46.0, 46.0, 46.0, 46.0, 46.38, 46.38, 46.38, 46.38, 46.38, 44.62, 44.62, 44.62, 44.62, 44.62, 34.51, 34.51], "power_watts_avg": 44.76, "power_watts_peak": 47.04, "energy_joules_est": 86.72, "sample_count": 20, "duration_seconds": 1.938}, "timestamp": "2026-01-12T09:53:26.056716"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1501.354, "latencies_ms": [1501.354], "images_per_second": 0.666, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is standing on the left side of the river, with the bridge and greenery in the background. The rocks are scattered throughout the river, with the person standing near the middle of the river.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.1, "ram_available_mb": 109176.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13334.1, "ram_available_mb": 109172.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.51, 34.51, 34.51, 35.53, 35.53, 35.53, 35.53, 46.24, 46.24, 46.24, 46.24, 46.24, 45.83, 45.83, 45.83], "power_watts_avg": 40.96, "power_watts_peak": 46.24, "energy_joules_est": 61.51, "sample_count": 15, "duration_seconds": 1.502}, "timestamp": "2026-01-12T09:53:27.572147"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1304.549, "latencies_ms": [1304.549], "images_per_second": 0.767, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A person is standing on a rocky riverbank, looking at the water. The river is flowing over the rocks, and there is a bridge in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.1, "ram_available_mb": 109172.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13326.0, "ram_available_mb": 109180.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.83, 45.83, 35.76, 35.76, 35.76, 35.76, 35.76, 47.26, 47.26, 47.26, 47.26, 47.26, 46.04], "power_watts_avg": 42.52, "power_watts_peak": 47.26, "energy_joules_est": 55.49, "sample_count": 13, "duration_seconds": 1.305}, "timestamp": "2026-01-12T09:53:28.883815"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1229.28, "latencies_ms": [1229.28], "images_per_second": 0.813, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image features a river with a person standing on the rocks, the water is clear and blue, and the sky is clear with a few clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.0, "ram_available_mb": 109180.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13321.3, "ram_available_mb": 109185.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.04, 46.04, 46.04, 46.04, 43.78, 43.78, 43.78, 43.78, 43.78, 47.26, 47.26, 47.26, 47.26], "power_watts_avg": 45.55, "power_watts_peak": 47.26, "energy_joules_est": 56.02, "sample_count": 13, "duration_seconds": 1.23}, "timestamp": "2026-01-12T09:53:30.197109"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1036.438, "latencies_ms": [1036.438], "images_per_second": 0.965, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A row of parked motorcycles in front of a building with a red awning and a green dome on top.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.3, "ram_available_mb": 109185.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13335.4, "ram_available_mb": 109170.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.26, 35.67, 35.67, 35.67, 35.67, 35.67, 46.39, 46.39, 46.39, 46.39, 46.39], "power_watts_avg": 41.6, "power_watts_peak": 47.26, "energy_joules_est": 43.12, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-12T09:53:31.312154"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2071.113, "latencies_ms": [2071.113], "images_per_second": 0.483, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Motorcycles: 12\n2. People: 4\n3. Street: 1\n4. Building: 1\n5. Sign: 1\n6. Poster: 1\n7. Awning: 1\n8. Streetlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.4, "ram_available_mb": 109170.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.78, 48.78, 48.78, 48.78, 48.78, 46.65, 46.65, 46.65, 46.65, 46.65, 47.05, 47.05, 47.05, 47.05, 47.05, 34.53, 34.53, 34.53, 34.53, 34.53, 34.5], "power_watts_avg": 43.79, "power_watts_peak": 48.78, "energy_joules_est": 90.7, "sample_count": 21, "duration_seconds": 2.071}, "timestamp": "2026-01-12T09:53:33.428484"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1278.477, "latencies_ms": [1278.477], "images_per_second": 0.782, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The motorcycles are parked on the right side of the street, while the buildings are on the left side. The motorcycles are closer to the viewer than the buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13372.8, "ram_available_mb": 109133.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.5, 34.5, 34.5, 39.85, 39.85, 39.85, 39.85, 39.85, 45.86, 45.86, 45.86, 45.86, 45.86], "power_watts_avg": 40.93, "power_watts_peak": 45.86, "energy_joules_est": 52.36, "sample_count": 13, "duration_seconds": 1.279}, "timestamp": "2026-01-12T09:53:34.795170"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2658.55, "latencies_ms": [2658.55], "images_per_second": 0.376, "prompt_tokens": 1111, "response_tokens_est": 84, "n_tiles": 1, "output_text": " The image captures a bustling street scene in Paris, France, where a row of parked scooters lines the sidewalk in front of a row of shops. The scooters, mostly black and silver, are parked in front of a variety of shops, including a barber shop and a pharmacy. The buildings are adorned with ornate details, and the street is lined with trees, adding a touch of greenery to the urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.0, "ram_available_mb": 109141.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.66, 40.66, 40.66, 40.66, 40.66, 47.3, 47.3, 47.3, 47.3, 47.3, 47.19, 47.19, 47.19, 47.19, 47.19, 34.5, 34.5, 34.5, 34.5, 34.5, 34.71, 34.71, 34.71, 34.71, 34.71, 34.68, 34.68], "power_watts_avg": 40.41, "power_watts_peak": 47.3, "energy_joules_est": 107.45, "sample_count": 27, "duration_seconds": 2.659}, "timestamp": "2026-01-12T09:53:37.518571"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2106.953, "latencies_ms": [2106.953], "images_per_second": 0.475, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a vibrant scene on a sunny day, with the motorbikes parked in front of the building bathed in the warm glow of the sunlight. The motorbikes, in their various shades of black and silver, stand out against the backdrop of the building's red awning and green roof.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.8, "ram_available_mb": 109164.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13335.8, "ram_available_mb": 109170.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 37.35, 37.35, 37.35, 37.35, 37.35, 46.08, 46.08, 46.08, 46.08, 46.08, 43.4, 43.4, 43.4, 43.4, 43.4, 34.45, 34.45, 34.45], "power_watts_avg": 40.07, "power_watts_peak": 46.08, "energy_joules_est": 84.47, "sample_count": 21, "duration_seconds": 2.108}, "timestamp": "2026-01-12T09:53:39.652846"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 848.152, "latencies_ms": [848.152], "images_per_second": 1.179, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is holding a piece of broccoli with a small brown seed on it.", "error": null, "sys_before": {"cpu_percent": 1.8, "ram_used_mb": 13327.9, "ram_available_mb": 109178.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13333.3, "ram_available_mb": 109173.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.45, 32.23, 32.23, 32.23, 32.23, 32.23, 46.42, 46.42, 46.42], "power_watts_avg": 37.2, "power_watts_peak": 46.42, "energy_joules_est": 31.61, "sample_count": 9, "duration_seconds": 0.85}, "timestamp": "2026-01-12T09:53:40.615992"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 543.022, "latencies_ms": [543.022], "images_per_second": 1.842, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " broccoli: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.4, "ram_available_mb": 109180.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13338.7, "ram_available_mb": 109167.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.42, 46.42, 48.66, 48.66, 48.66, 48.66], "power_watts_avg": 47.92, "power_watts_peak": 48.66, "energy_joules_est": 26.04, "sample_count": 6, "duration_seconds": 0.543}, "timestamp": "2026-01-12T09:53:41.224605"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 997.779, "latencies_ms": [997.779], "images_per_second": 1.002, "prompt_tokens": 1117, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The broccoli is in the foreground, held by a hand, and the background is a tiled wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.8, "ram_available_mb": 109171.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.9, "ram_available_mb": 109111.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 33.0}, "power_stats": {"power_watts_samples": [48.66, 44.65, 44.65, 44.65, 44.65, 44.65, 59.24, 59.24, 59.24, 59.24], "power_watts_avg": 50.89, "power_watts_peak": 59.24, "energy_joules_est": 50.82, "sample_count": 10, "duration_seconds": 0.999}, "timestamp": "2026-01-12T09:53:42.235607"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 858.347, "latencies_ms": [858.347], "images_per_second": 1.165, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is holding a piece of broccoli with a small brown seed on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.1, "ram_available_mb": 109119.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13325.9, "ram_available_mb": 109180.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [59.24, 47.18, 47.18, 47.18, 47.18, 47.18, 47.4, 47.4, 47.4], "power_watts_avg": 48.59, "power_watts_peak": 59.24, "energy_joules_est": 41.74, "sample_count": 9, "duration_seconds": 0.859}, "timestamp": "2026-01-12T09:53:43.143379"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 758.355, "latencies_ms": [758.355], "images_per_second": 1.319, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The broccoli is green and the person's hand is pink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.9, "ram_available_mb": 109180.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13314.7, "ram_available_mb": 109191.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [47.4, 47.4, 46.32, 46.32, 46.32, 46.32, 46.32, 46.96], "power_watts_avg": 46.67, "power_watts_peak": 47.4, "energy_joules_est": 35.41, "sample_count": 8, "duration_seconds": 0.759}, "timestamp": "2026-01-12T09:53:43.952027"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1297.245, "latencies_ms": [1297.245], "images_per_second": 0.771, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " Two people are standing close to each other, one of them is wearing a black jacket with a fur hood, and they are both looking up with their mouths open.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13314.7, "ram_available_mb": 109191.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.96, 46.96, 46.96, 46.96, 55.84, 55.84, 55.84, 55.84, 55.84, 47.08, 47.08, 47.08, 47.08], "power_watts_avg": 50.41, "power_watts_peak": 55.84, "energy_joules_est": 65.4, "sample_count": 13, "duration_seconds": 1.297}, "timestamp": "2026-01-12T09:53:45.267535"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1908.262, "latencies_ms": [1908.262], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. jacket: 2\n3. hood: 1\n4. hat: 1\n5. face: 1\n6. eyes: 1\n7. mouth: 1\n8. nose: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13321.3, "ram_available_mb": 109185.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13334.8, "ram_available_mb": 109171.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 45.0}, "power_stats": {"power_watts_samples": [39.61, 39.61, 39.61, 39.61, 39.61, 47.91, 47.91, 47.91, 47.91, 47.91, 47.48, 47.48, 47.48, 47.48, 47.48, 34.45, 34.45, 34.45, 34.45, 34.45], "power_watts_avg": 42.36, "power_watts_peak": 47.91, "energy_joules_est": 80.85, "sample_count": 20, "duration_seconds": 1.909}, "timestamp": "2026-01-12T09:53:47.281772"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1874.369, "latencies_ms": [1874.369], "images_per_second": 0.534, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The person on the left is closer to the camera than the person on the right. The person on the right is in the background, while the person on the left is in the foreground. The person on the left is closer to the camera than the person on the right.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13334.8, "ram_available_mb": 109171.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13409.7, "ram_available_mb": 109096.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.09, 33.09, 33.09, 33.09, 33.09, 45.15, 45.15, 45.15, 45.15, 45.15, 46.66, 46.66, 46.66, 46.66, 46.66, 35.13, 35.13, 35.13, 35.13], "power_watts_avg": 40.26, "power_watts_peak": 46.66, "energy_joules_est": 75.53, "sample_count": 19, "duration_seconds": 1.876}, "timestamp": "2026-01-12T09:53:49.250697"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1077.987, "latencies_ms": [1077.987], "images_per_second": 0.928, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " Two people are standing close together in a dimly lit room, one of them wearing a black jacket with a fur hood.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13409.7, "ram_available_mb": 109096.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13404.4, "ram_available_mb": 109101.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.65, 33.65, 33.65, 33.65, 33.65, 46.38, 46.38, 46.38, 46.38, 46.38, 47.42], "power_watts_avg": 40.69, "power_watts_peak": 47.42, "energy_joules_est": 43.89, "sample_count": 11, "duration_seconds": 1.079}, "timestamp": "2026-01-12T09:53:50.411277"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1025.614, "latencies_ms": [1025.614], "images_per_second": 0.975, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a dimly lit environment with a yellowish hue, and the subjects are wearing winter clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.5, "ram_available_mb": 109109.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13385.0, "ram_available_mb": 109121.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.42, 47.42, 47.42, 47.42, 44.2, 44.2, 44.2, 44.2, 44.2, 47.64, 47.64], "power_watts_avg": 45.99, "power_watts_peak": 47.64, "energy_joules_est": 47.2, "sample_count": 11, "duration_seconds": 1.026}, "timestamp": "2026-01-12T09:53:51.522599"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 838.987, "latencies_ms": [838.987], "images_per_second": 1.192, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man with long hair is playing tennis on a blue court with white lines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13375.1, "ram_available_mb": 109131.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.64, 47.64, 47.64, 41.42, 41.42, 41.42, 41.42, 41.42, 46.33], "power_watts_avg": 44.04, "power_watts_peak": 47.64, "energy_joules_est": 36.97, "sample_count": 9, "duration_seconds": 0.84}, "timestamp": "2026-01-12T09:53:52.435395"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2087.941, "latencies_ms": [2087.941], "images_per_second": 0.479, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. chair: 1\n5. tennis court: 1\n6. white chair: 1\n7. white wall: 1\n8. green fence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.0, "ram_available_mb": 109131.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13436.7, "ram_available_mb": 109069.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.33, 46.33, 46.33, 46.33, 51.61, 51.61, 51.61, 51.61, 51.61, 46.64, 46.64, 46.64, 46.64, 46.64, 38.77, 38.77, 38.77, 38.77, 38.77, 34.61, 34.61], "power_watts_avg": 44.75, "power_watts_peak": 51.61, "energy_joules_est": 93.45, "sample_count": 21, "duration_seconds": 2.088}, "timestamp": "2026-01-12T09:53:54.549763"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1745.857, "latencies_ms": [1745.857], "images_per_second": 0.573, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball in the center and the empty chairs on the right side. The player is closer to the camera than the chairs, and the ball is in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.7, "ram_available_mb": 109069.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13468.2, "ram_available_mb": 109038.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.61, 34.61, 35.27, 35.27, 35.27, 35.27, 35.27, 46.53, 46.53, 46.53, 46.53, 46.53, 46.2, 46.2, 46.2, 46.2, 46.2, 34.97], "power_watts_avg": 41.34, "power_watts_peak": 46.53, "energy_joules_est": 72.22, "sample_count": 18, "duration_seconds": 1.747}, "timestamp": "2026-01-12T09:53:56.413448"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1027.546, "latencies_ms": [1027.546], "images_per_second": 0.973, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is playing tennis on a blue court with white lines. He is wearing a white shirt and black shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13468.2, "ram_available_mb": 109038.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13437.1, "ram_available_mb": 109069.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 34.97, 43.65, 43.65, 43.65, 43.65, 43.65, 46.92, 46.92], "power_watts_avg": 41.09, "power_watts_peak": 46.92, "energy_joules_est": 42.23, "sample_count": 11, "duration_seconds": 1.028}, "timestamp": "2026-01-12T09:53:57.525533"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 949.883, "latencies_ms": [949.883], "images_per_second": 1.053, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The tennis court is blue, the man is wearing a white shirt, and the sun is shining.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.1, "ram_available_mb": 109069.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13428.9, "ram_available_mb": 109077.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.92, 46.92, 46.92, 41.91, 41.91, 41.91, 41.91, 41.91, 46.3, 46.3], "power_watts_avg": 44.29, "power_watts_peak": 46.92, "energy_joules_est": 42.09, "sample_count": 10, "duration_seconds": 0.95}, "timestamp": "2026-01-12T09:53:58.535892"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 872.322, "latencies_ms": [872.322], "images_per_second": 1.146, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red glass vase with a white candle and string lights on a wooden shelf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13428.9, "ram_available_mb": 109077.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.3, 46.3, 46.3, 46.52, 46.52, 46.52, 46.52, 46.52, 46.79], "power_watts_avg": 46.48, "power_watts_peak": 46.79, "energy_joules_est": 40.56, "sample_count": 9, "duration_seconds": 0.873}, "timestamp": "2026-01-12T09:53:59.446713"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1972.218, "latencies_ms": [1972.218], "images_per_second": 0.507, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. candle: 1\n2. glass: 1\n3. vase: 1\n4. wooden frame: 1\n5. string lights: 1\n6. mirror: 1\n7. table: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13353.5, "ram_available_mb": 109152.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.79, 46.79, 46.79, 46.79, 51.55, 51.55, 51.55, 51.55, 51.55, 46.83, 46.83, 46.83, 46.83, 46.83, 39.64, 39.64, 39.64, 39.64, 39.64, 34.56], "power_watts_avg": 45.59, "power_watts_peak": 51.55, "energy_joules_est": 89.94, "sample_count": 20, "duration_seconds": 1.973}, "timestamp": "2026-01-12T09:54:01.460534"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1388.601, "latencies_ms": [1388.601], "images_per_second": 0.72, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The candle is positioned to the left of the vase, which is placed in the center of the image. The vase is situated in the background, with the candle in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.5, "ram_available_mb": 109152.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13297.4, "ram_available_mb": 109208.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.56, 34.56, 34.56, 38.2, 38.2, 38.2, 38.2, 38.2, 46.03, 46.03, 46.03, 46.03, 46.03, 42.56], "power_watts_avg": 40.53, "power_watts_peak": 46.03, "energy_joules_est": 56.3, "sample_count": 14, "duration_seconds": 1.389}, "timestamp": "2026-01-12T09:54:02.922375"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1093.948, "latencies_ms": [1093.948], "images_per_second": 0.914, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A red glass vase with a white candle on a glass coaster sits on a wooden shelf, surrounded by white string lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13297.4, "ram_available_mb": 109208.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13296.0, "ram_available_mb": 109210.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.56, 42.56, 42.56, 42.56, 43.34, 43.34, 43.34, 43.34, 43.34, 47.18, 47.18], "power_watts_avg": 43.75, "power_watts_peak": 47.18, "energy_joules_est": 47.88, "sample_count": 11, "duration_seconds": 1.094}, "timestamp": "2026-01-12T09:54:04.034243"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 694.389, "latencies_ms": [694.389], "images_per_second": 1.44, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The vase is orange and the candle is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13296.0, "ram_available_mb": 109210.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.8, "ram_available_mb": 109147.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [47.18, 47.18, 47.18, 42.72, 42.72, 42.72, 42.72], "power_watts_avg": 44.63, "power_watts_peak": 47.18, "energy_joules_est": 31.01, "sample_count": 7, "duration_seconds": 0.695}, "timestamp": "2026-01-12T09:54:04.743755"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1166.81, "latencies_ms": [1166.81], "images_per_second": 0.857, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a gray shirt and jeans is bending over in front of a camera, while another man in a green shirt stands behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.8, "ram_available_mb": 109147.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.6, "ram_available_mb": 109177.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.72, 47.22, 47.22, 47.22, 47.22, 47.22, 56.82, 56.82, 56.82, 56.82, 56.82, 48.44], "power_watts_avg": 50.95, "power_watts_peak": 56.82, "energy_joules_est": 59.48, "sample_count": 12, "duration_seconds": 1.167}, "timestamp": "2026-01-12T09:54:05.957905"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1933.782, "latencies_ms": [1933.782], "images_per_second": 0.517, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 2\n2. suitcase: 1\n3. laptop: 1\n4. couch: 1\n5. jacket: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13335.4, "ram_available_mb": 109170.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.44, 48.44, 48.44, 48.44, 41.95, 41.95, 41.95, 41.95, 41.95, 47.3, 47.3, 47.3, 47.3, 40.68, 40.68, 40.68, 40.68, 40.68, 34.54, 34.54], "power_watts_avg": 43.26, "power_watts_peak": 48.44, "energy_joules_est": 83.68, "sample_count": 20, "duration_seconds": 1.934}, "timestamp": "2026-01-12T09:54:07.977945"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2040.796, "latencies_ms": [2040.796], "images_per_second": 0.49, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The man in the gray shirt is standing in the foreground, bending over to look at the camera. The man in the green shirt is standing in the background, with a brown jacket hanging on a coat rack behind him. The silver suitcase is located on the floor near the man in the gray shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.5, "ram_available_mb": 109174.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13328.0, "ram_available_mb": 109178.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.54, 34.54, 34.54, 40.11, 40.11, 40.11, 40.11, 40.11, 46.25, 46.25, 46.25, 46.25, 46.25, 40.76, 40.76, 40.76, 40.76, 40.76, 34.53, 34.53, 34.53], "power_watts_avg": 40.13, "power_watts_peak": 46.25, "energy_joules_est": 81.93, "sample_count": 21, "duration_seconds": 2.041}, "timestamp": "2026-01-12T09:54:10.098925"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1199.818, "latencies_ms": [1199.818], "images_per_second": 0.833, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " Two men are in a room with a couch and a laptop. One man is holding a camera and the other is standing in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.0, "ram_available_mb": 109178.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13330.4, "ram_available_mb": 109175.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.53, 34.53, 34.98, 34.98, 34.98, 34.98, 34.98, 46.49, 46.49, 46.49, 46.49, 46.49], "power_watts_avg": 39.7, "power_watts_peak": 46.49, "energy_joules_est": 47.66, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-12T09:54:11.312637"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1932.57, "latencies_ms": [1932.57], "images_per_second": 0.517, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a man wearing a gray shirt and jeans, standing in a room with a brown couch and a silver suitcase nearby. The lighting in the room is bright, and the colors are warm, with the brown couch and the gray suitcase adding to the overall color scheme.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.5, "ram_available_mb": 109183.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13329.5, "ram_available_mb": 109176.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.03, 46.03, 46.03, 46.03, 46.03, 47.6, 47.6, 47.6, 47.6, 47.6, 47.64, 47.64, 47.64, 47.64, 47.64, 34.59, 34.59, 34.59, 34.59, 34.59], "power_watts_avg": 43.96, "power_watts_peak": 47.64, "energy_joules_est": 84.99, "sample_count": 20, "duration_seconds": 1.933}, "timestamp": "2026-01-12T09:54:13.332012"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1016.127, "latencies_ms": [1016.127], "images_per_second": 0.984, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman wearing a hat and a striped shirt is holding a cigarette in her hand.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13325.6, "ram_available_mb": 109180.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13364.1, "ram_available_mb": 109142.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.25, 34.25, 34.25, 34.25, 41.17, 41.17, 41.17, 41.17, 41.17, 49.44, 49.44], "power_watts_avg": 40.16, "power_watts_peak": 49.44, "energy_joules_est": 40.84, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-12T09:54:14.499398"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2101.502, "latencies_ms": [2101.502], "images_per_second": 0.476, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. hat: 1\n2. woman: 1\n3. cigarette: 1\n4. necklace: 1\n5. bracelet: 1\n6. necklace: 1\n7. necklace: 1\n8. necklace: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.7, "ram_available_mb": 109151.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.0, "ram_available_mb": 109154.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.44, 49.44, 49.44, 45.74, 45.74, 45.74, 45.74, 45.74, 50.17, 50.17, 50.17, 50.17, 50.17, 47.52, 47.52, 47.52, 47.52, 47.52, 34.67, 34.67, 34.67], "power_watts_avg": 46.16, "power_watts_peak": 50.17, "energy_joules_est": 97.03, "sample_count": 21, "duration_seconds": 2.102}, "timestamp": "2026-01-12T09:54:16.619798"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1474.127, "latencies_ms": [1474.127], "images_per_second": 0.678, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a hat and a striped shirt. The cigarette is in her hand, and she is smiling. The background is plain and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.3, "ram_available_mb": 109159.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.9, "ram_available_mb": 109149.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [34.67, 31.66, 31.66, 31.66, 31.66, 31.66, 50.7, 50.7, 50.7, 50.7, 50.7, 53.88, 53.88, 53.88, 53.88], "power_watts_avg": 44.13, "power_watts_peak": 53.88, "energy_joules_est": 65.09, "sample_count": 15, "duration_seconds": 1.475}, "timestamp": "2026-01-12T09:54:18.186633"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 993.096, "latencies_ms": [993.096], "images_per_second": 1.007, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a hat and a striped shirt is holding a cigarette and smiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.0, "ram_available_mb": 109157.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13364.5, "ram_available_mb": 109141.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 22.0}, "power_stats": {"power_watts_samples": [53.88, 32.5, 32.5, 32.5, 32.5, 32.5, 51.21, 51.21, 51.21, 51.21], "power_watts_avg": 42.12, "power_watts_peak": 53.88, "energy_joules_est": 41.85, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-12T09:54:19.199548"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2035.061, "latencies_ms": [2035.061], "images_per_second": 0.491, "prompt_tokens": 1442, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image is in black and white, with a high contrast of light and dark tones. The lighting is soft and diffused, creating a moody atmosphere. The subject is wearing a black hat and a striped shirt, which adds a sense of casual elegance to the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13364.5, "ram_available_mb": 109141.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.0, "ram_available_mb": 109157.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.21, 51.2, 51.2, 51.2, 51.2, 51.2, 51.35, 51.35, 51.35, 51.35, 51.35, 53.34, 53.34, 53.34, 53.34, 53.34, 34.81, 34.81, 34.81, 34.81, 34.81], "power_watts_avg": 47.84, "power_watts_peak": 53.34, "energy_joules_est": 97.39, "sample_count": 21, "duration_seconds": 2.036}, "timestamp": "2026-01-12T09:54:21.318968"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 871.038, "latencies_ms": [871.038], "images_per_second": 1.148, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two zebras are grazing on a grassy field with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13345.1, "ram_available_mb": 109161.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13337.7, "ram_available_mb": 109168.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.29, 34.29, 34.29, 34.29, 43.7, 43.7, 43.7, 43.7, 43.7], "power_watts_avg": 39.52, "power_watts_peak": 43.7, "energy_joules_est": 34.46, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-12T09:54:22.284818"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 536.214, "latencies_ms": [536.214], "images_per_second": 1.865, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.8, "ram_available_mb": 109176.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.0, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.11, 45.11, 45.11, 45.11, 45.11, 49.01], "power_watts_avg": 45.76, "power_watts_peak": 49.01, "energy_joules_est": 24.56, "sample_count": 6, "duration_seconds": 0.537}, "timestamp": "2026-01-12T09:54:22.894884"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2408.314, "latencies_ms": [2408.314], "images_per_second": 0.415, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The zebra on the left is positioned slightly behind the one on the right, creating a sense of depth in the image. The foreground zebra is closer to the camera, while the background zebra is farther away, giving a sense of distance. The zebra on the right is positioned near the center of the image, while the one on the left is positioned more towards the left side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13326.3, "ram_available_mb": 109180.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [49.01, 49.01, 49.01, 49.01, 56.93, 56.93, 56.93, 56.93, 56.93, 46.51, 46.51, 46.51, 46.51, 46.51, 38.12, 38.12, 38.12, 38.12, 38.12, 34.67, 34.67, 34.67, 34.67, 34.67], "power_watts_avg": 44.88, "power_watts_peak": 56.93, "energy_joules_est": 108.11, "sample_count": 24, "duration_seconds": 2.409}, "timestamp": "2026-01-12T09:54:25.316555"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 874.455, "latencies_ms": [874.455], "images_per_second": 1.144, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two zebras are grazing in a grassy enclosure with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.4, "ram_available_mb": 109183.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13338.9, "ram_available_mb": 109167.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.6, 34.6, 34.6, 34.6, 34.6, 45.12, 45.12, 45.12, 45.12], "power_watts_avg": 39.27, "power_watts_peak": 45.12, "energy_joules_est": 34.4, "sample_count": 9, "duration_seconds": 0.876}, "timestamp": "2026-01-12T09:54:26.277671"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1635.982, "latencies_ms": [1635.982], "images_per_second": 0.611, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features two zebras grazing in a grassy enclosure with a rocky wall in the background. The zebras are black and white, and the grass is green. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.1, "ram_available_mb": 109180.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.32, 46.32, 46.32, 46.32, 46.32, 48.99, 48.99, 48.99, 48.99, 48.99, 47.82, 47.82, 47.82, 47.82, 47.82, 34.7, 34.7], "power_watts_avg": 46.18, "power_watts_peak": 48.99, "energy_joules_est": 75.57, "sample_count": 17, "duration_seconds": 1.636}, "timestamp": "2026-01-12T09:54:27.990449"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 936.241, "latencies_ms": [936.241], "images_per_second": 1.068, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " An old, rusted fire hydrant with a chain on top is sitting on a sidewalk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13318.2, "ram_available_mb": 109188.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13334.2, "ram_available_mb": 109172.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 39.66, 39.66, 39.66, 39.66, 39.66, 46.55, 46.55], "power_watts_avg": 39.55, "power_watts_peak": 46.55, "energy_joules_est": 37.05, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-12T09:54:29.002209"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 879.254, "latencies_ms": [879.254], "images_per_second": 1.137, "prompt_tokens": 1114, "response_tokens_est": 17, "n_tiles": 1, "output_text": " hydrant: 1\nchain: 2\npink flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.2, "ram_available_mb": 109172.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.55, 46.55, 46.55, 46.76, 46.76, 46.76, 46.76, 46.76, 46.37], "power_watts_avg": 46.65, "power_watts_peak": 46.76, "energy_joules_est": 41.02, "sample_count": 9, "duration_seconds": 0.879}, "timestamp": "2026-01-12T09:54:29.913739"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1685.687, "latencies_ms": [1685.687], "images_per_second": 0.593, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with the wall and plants in the background. The fire hydrant is positioned to the left of the wall, and the plants are located to the right of the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.1, "ram_available_mb": 109183.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13333.6, "ram_available_mb": 109172.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.37, 46.37, 46.37, 46.37, 51.93, 51.93, 51.93, 51.93, 51.93, 47.49, 47.49, 47.49, 47.49, 47.49, 38.19, 38.19, 38.19], "power_watts_avg": 46.89, "power_watts_peak": 51.93, "energy_joules_est": 79.06, "sample_count": 17, "duration_seconds": 1.686}, "timestamp": "2026-01-12T09:54:31.626822"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 871.401, "latencies_ms": [871.401], "images_per_second": 1.148, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A rusted fire hydrant sits on the ground next to a stone wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.6, "ram_available_mb": 109172.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.19, 38.19, 34.08, 34.08, 34.08, 34.08, 34.08, 47.07, 47.07], "power_watts_avg": 37.88, "power_watts_peak": 47.07, "energy_joules_est": 33.03, "sample_count": 9, "duration_seconds": 0.872}, "timestamp": "2026-01-12T09:54:32.537633"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 880.946, "latencies_ms": [880.946], "images_per_second": 1.135, "prompt_tokens": 1110, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The fire hydrant is rusted and dirty, with a chain attached to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13324.9, "ram_available_mb": 109181.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.07, 47.07, 47.07, 51.74, 51.74, 51.74, 51.74, 51.74, 47.01], "power_watts_avg": 49.66, "power_watts_peak": 51.74, "energy_joules_est": 43.77, "sample_count": 9, "duration_seconds": 0.881}, "timestamp": "2026-01-12T09:54:33.447300"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1002.588, "latencies_ms": [1002.588], "images_per_second": 0.997, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " In the image, there are two brown bears walking on a road, one of them is a cub.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13324.9, "ram_available_mb": 109181.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13312.7, "ram_available_mb": 109193.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [47.01, 47.01, 47.01, 47.01, 51.49, 51.49, 51.49, 51.49, 51.49, 47.2, 47.2], "power_watts_avg": 49.08, "power_watts_peak": 51.49, "energy_joules_est": 49.24, "sample_count": 11, "duration_seconds": 1.003}, "timestamp": "2026-01-12T09:54:34.556402"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1936.763, "latencies_ms": [1936.763], "images_per_second": 0.516, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 2\n2. road: 1\n3. grass: 1\n4. dirt: 1\n5. road surface: 1\n6. bear: 1\n7. bear: 1\n8. bear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13312.7, "ram_available_mb": 109193.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13295.5, "ram_available_mb": 109210.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.2, 47.2, 47.2, 40.5, 40.5, 40.5, 40.5, 40.5, 45.9, 45.9, 45.9, 45.9, 45.9, 45.75, 45.75, 45.75, 45.75, 45.75, 34.8, 34.8], "power_watts_avg": 43.6, "power_watts_peak": 47.2, "energy_joules_est": 84.46, "sample_count": 20, "duration_seconds": 1.937}, "timestamp": "2026-01-12T09:54:36.574203"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1621.338, "latencies_ms": [1621.338], "images_per_second": 0.617, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The brown bear in the foreground is walking towards the camera, while the brown bear in the background is walking away from the camera. The brown bear in the foreground is closer to the camera than the brown bear in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13295.5, "ram_available_mb": 109210.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.7, "ram_available_mb": 109164.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 32.46, 32.46, 32.46, 32.46, 32.46, 45.47, 45.47, 45.47, 45.47, 45.47, 48.3, 48.3, 48.3, 48.3, 48.3], "power_watts_avg": 41.22, "power_watts_peak": 48.3, "energy_joules_est": 66.87, "sample_count": 17, "duration_seconds": 1.622}, "timestamp": "2026-01-12T09:54:38.340316"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 885.67, "latencies_ms": [885.67], "images_per_second": 1.129, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two brown bears are walking on a dirt road, one of them is a cub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.8, "ram_available_mb": 109172.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.4, "ram_available_mb": 109177.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.42, 34.42, 34.42, 34.42, 34.42, 45.47, 45.47, 45.47, 45.47], "power_watts_avg": 39.33, "power_watts_peak": 45.47, "energy_joules_est": 34.85, "sample_count": 9, "duration_seconds": 0.886}, "timestamp": "2026-01-12T09:54:39.251826"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1834.028, "latencies_ms": [1834.028], "images_per_second": 0.545, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features two brown bears walking on a dirt road, with one bear having a lighter coat than the other. The lighting is natural and bright, suggesting it is daytime. The bears appear to be in a natural habitat, possibly a forest or a mountainous area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.4, "ram_available_mb": 109177.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13270.0, "ram_available_mb": 109236.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.47, 45.81, 45.81, 45.81, 45.81, 45.81, 48.13, 48.13, 48.13, 48.13, 48.13, 48.12, 48.12, 48.12, 48.12, 48.12, 34.56, 34.56, 34.56], "power_watts_avg": 45.23, "power_watts_peak": 48.13, "energy_joules_est": 82.98, "sample_count": 19, "duration_seconds": 1.835}, "timestamp": "2026-01-12T09:54:41.167814"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1012.633, "latencies_ms": [1012.633], "images_per_second": 0.988, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young child with blonde hair is kneeling on the ground next to a metal bucket filled with dirt.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13270.0, "ram_available_mb": 109236.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13314.0, "ram_available_mb": 109192.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.56, 34.56, 31.79, 31.79, 31.79, 31.79, 31.79, 46.2, 46.2, 46.2, 46.2], "power_watts_avg": 37.53, "power_watts_peak": 46.2, "energy_joules_est": 38.01, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-12T09:54:42.281281"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1897.697, "latencies_ms": [1897.697], "images_per_second": 0.527, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. child: 1\n2. shirt: 1\n3. tie: 1\n4. pants: 1\n5. shoes: 1\n6. bucket: 1\n7. dirt: 1\n8. leaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.1, "ram_available_mb": 109200.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13311.9, "ram_available_mb": 109194.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.63, 47.63, 47.63, 47.63, 47.63, 46.22, 46.22, 46.22, 46.22, 46.22, 47.82, 47.82, 47.82, 47.82, 47.82, 34.84, 34.84, 34.84, 34.84], "power_watts_avg": 44.62, "power_watts_peak": 47.82, "energy_joules_est": 84.69, "sample_count": 19, "duration_seconds": 1.898}, "timestamp": "2026-01-12T09:54:44.198288"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1440.025, "latencies_ms": [1440.025], "images_per_second": 0.694, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The child is in the foreground, kneeling on the ground, and the bucket is in the middle ground. The child is looking at the bucket, and the bucket is on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13308.0, "ram_available_mb": 109198.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.0, "ram_available_mb": 109178.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.84, 33.18, 33.18, 33.18, 33.18, 33.18, 46.65, 46.65, 46.65, 46.65, 46.65, 48.21, 48.21, 48.21, 48.21], "power_watts_avg": 41.79, "power_watts_peak": 48.21, "energy_joules_est": 60.21, "sample_count": 15, "duration_seconds": 1.441}, "timestamp": "2026-01-12T09:54:45.764412"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1008.943, "latencies_ms": [1008.943], "images_per_second": 0.991, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young child is playing in a dirt area with a bucket, wearing a white shirt and a colorful tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.1, "ram_available_mb": 109186.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13321.0, "ram_available_mb": 109185.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [48.21, 33.34, 33.34, 33.34, 33.34, 33.34, 46.56, 46.56, 46.56, 46.56, 46.56], "power_watts_avg": 40.7, "power_watts_peak": 48.21, "energy_joules_est": 41.09, "sample_count": 11, "duration_seconds": 1.009}, "timestamp": "2026-01-12T09:54:46.875960"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1225.09, "latencies_ms": [1225.09], "images_per_second": 0.816, "prompt_tokens": 1110, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image is a black and white photo with a child wearing a white shirt and a colorful tie, and the child is kneeling on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.2, "ram_available_mb": 109193.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13332.2, "ram_available_mb": 109174.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [48.04, 48.04, 48.04, 48.04, 43.85, 43.85, 43.85, 43.85, 43.85, 45.86, 45.86, 45.86, 45.86], "power_watts_avg": 45.76, "power_watts_peak": 48.04, "energy_joules_est": 56.08, "sample_count": 13, "duration_seconds": 1.226}, "timestamp": "2026-01-12T09:54:48.191121"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1343.316, "latencies_ms": [1343.316], "images_per_second": 0.744, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A collection of stuffed animals, including a teddy bear, are placed on a makeshift bed, surrounded by various items such as bottles and flowers, in a barren, sandy landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13329.0, "ram_available_mb": 109177.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.86, 34.64, 34.64, 34.64, 34.64, 34.64, 46.33, 46.33, 46.33, 46.33, 46.33, 49.52, 49.52, 49.52], "power_watts_avg": 42.81, "power_watts_peak": 49.52, "energy_joules_est": 57.51, "sample_count": 14, "duration_seconds": 1.343}, "timestamp": "2026-01-12T09:54:49.604558"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1249.266, "latencies_ms": [1249.266], "images_per_second": 0.8, "prompt_tokens": 1113, "response_tokens_est": 31, "n_tiles": 1, "output_text": " teddy bear: 2\nbottle: 3\nflowers: 2\ntable: 1\nbed: 1\ncloth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.0, "ram_available_mb": 109177.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.5, "ram_available_mb": 109174.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.52, 49.52, 35.07, 35.07, 35.07, 35.07, 35.07, 46.66, 46.66, 46.66, 46.66, 46.66, 46.57], "power_watts_avg": 42.64, "power_watts_peak": 49.52, "energy_joules_est": 53.29, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-12T09:54:50.919071"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1592.002, "latencies_ms": [1592.002], "images_per_second": 0.628, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The teddy bear is positioned to the left of the table, which is situated in the foreground of the image. The table is located near the center of the image, with the teddy bear and other objects arranged around it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13323.6, "ram_available_mb": 109182.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13330.3, "ram_available_mb": 109176.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.57, 46.57, 46.57, 46.57, 43.34, 43.34, 43.34, 43.34, 43.34, 46.67, 46.67, 46.67, 46.67, 46.67, 38.13, 38.13], "power_watts_avg": 44.53, "power_watts_peak": 46.67, "energy_joules_est": 70.91, "sample_count": 16, "duration_seconds": 1.592}, "timestamp": "2026-01-12T09:54:52.537007"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1170.307, "latencies_ms": [1170.307], "images_per_second": 0.854, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a barren, dry landscape, a makeshift bed is set up with a teddy bear and other stuffed animals, surrounded by bottles and flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.4, "ram_available_mb": 109179.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13327.2, "ram_available_mb": 109179.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [38.13, 38.13, 38.13, 38.65, 38.65, 38.65, 38.65, 38.65, 47.41, 47.41, 47.41, 47.41], "power_watts_avg": 41.44, "power_watts_peak": 47.41, "energy_joules_est": 48.52, "sample_count": 12, "duration_seconds": 1.171}, "timestamp": "2026-01-12T09:54:53.751633"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1409.616, "latencies_ms": [1409.616], "images_per_second": 0.709, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a table with a red cross on it, surrounded by a variety of stuffed animals and bottles. The ground is covered in dirt, and the lighting suggests it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.4, "ram_available_mb": 109186.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.6, "ram_available_mb": 109183.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [47.41, 43.26, 43.26, 43.26, 43.26, 43.26, 46.99, 46.99, 46.99, 46.99, 46.99, 48.64, 48.64, 48.64, 48.64], "power_watts_avg": 46.22, "power_watts_peak": 48.64, "energy_joules_est": 65.16, "sample_count": 15, "duration_seconds": 1.41}, "timestamp": "2026-01-12T09:54:55.266058"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3358.889, "latencies_ms": [3358.889], "images_per_second": 0.298, "prompt_tokens": 1432, "response_tokens_est": 103, "n_tiles": 1, "output_text": " The image captures a serene harbor scene where several fishing boats are docked, their vibrant colors contrasting with the tranquil water and the overcast sky. The boats, adorned with various equipment and lifebuoys, are moored to a sturdy wooden pier, which is marked with a sign bearing the number 9. In the distance, the lush green hills rise, adding a touch of nature's beauty to the scene. The overall atmosphere is one of quiet anticipation, as if the boats are waiting for their next catch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.6, "ram_available_mb": 109187.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13333.7, "ram_available_mb": 109172.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.64, 32.4, 32.4, 32.4, 32.4, 32.4, 47.37, 47.37, 47.37, 47.37, 47.37, 52.14, 52.14, 52.14, 52.14, 52.14, 36.94, 36.94, 36.94, 36.94, 34.58, 34.58, 34.58, 34.58, 34.58, 34.59, 34.59, 34.59, 34.59, 34.59, 34.7, 34.7, 34.7, 34.7], "power_watts_avg": 39.43, "power_watts_peak": 52.14, "energy_joules_est": 132.45, "sample_count": 34, "duration_seconds": 3.359}, "timestamp": "2026-01-12T09:54:58.696489"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2086.049, "latencies_ms": [2086.049], "images_per_second": 0.479, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Boat: 3\n2. Boat: 2\n3. Boat: 1\n4. Boat: 1\n5. Boat: 1\n6. Boat: 1\n7. Boat: 1\n8. Boat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.7, "ram_available_mb": 109172.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13301.2, "ram_available_mb": 109205.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.7, 31.77, 31.77, 31.77, 31.77, 31.77, 48.0, 48.0, 48.0, 48.0, 48.0, 52.47, 52.47, 52.47, 52.47, 52.47, 35.93, 35.93, 35.93, 35.93, 35.93], "power_watts_avg": 41.69, "power_watts_peak": 52.47, "energy_joules_est": 87.0, "sample_count": 21, "duration_seconds": 2.087}, "timestamp": "2026-01-12T09:55:00.869281"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2252.235, "latencies_ms": [2252.235], "images_per_second": 0.444, "prompt_tokens": 1450, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the fishing boats and the dock being the closest to the viewer. The boats are on the left side of the image, while the dock extends into the right side. The background features a calm body of water, with hills and other boats visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13301.1, "ram_available_mb": 109205.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13348.3, "ram_available_mb": 109158.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 34.68, 41.59, 41.59, 41.59, 41.59, 41.59, 50.14, 50.14, 50.14, 50.14, 50.14, 43.9, 43.9, 43.9, 43.9, 43.9, 34.79, 34.79, 34.79, 34.79], "power_watts_avg": 41.57, "power_watts_peak": 50.14, "energy_joules_est": 93.65, "sample_count": 23, "duration_seconds": 2.253}, "timestamp": "2026-01-12T09:55:03.236684"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2194.822, "latencies_ms": [2194.822], "images_per_second": 0.456, "prompt_tokens": 1444, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a serene harbor scene where several fishing boats are docked at a pier. The boats, painted in hues of green and white, are adorned with various equipment and equipment, suggesting a day of fishing. The harbor is nestled amidst lush green hills, providing a picturesque backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.3, "ram_available_mb": 109158.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13334.3, "ram_available_mb": 109172.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.61, 32.61, 32.61, 32.61, 32.61, 45.76, 45.76, 45.76, 45.76, 45.76, 51.74, 51.74, 51.74, 51.74, 51.74, 39.04, 39.04, 39.04, 39.04, 39.04, 34.51, 34.51], "power_watts_avg": 41.58, "power_watts_peak": 51.74, "energy_joules_est": 91.3, "sample_count": 22, "duration_seconds": 2.196}, "timestamp": "2026-01-12T09:55:05.514347"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1276.828, "latencies_ms": [1276.828], "images_per_second": 0.783, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a harbor with boats docked at the pier, the water is a deep blue, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.4, "ram_available_mb": 109179.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13353.8, "ram_available_mb": 109152.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.51, 34.51, 34.51, 35.5, 35.5, 35.5, 35.5, 35.5, 50.26, 50.26, 50.26, 50.26, 50.26], "power_watts_avg": 40.95, "power_watts_peak": 50.26, "energy_joules_est": 52.32, "sample_count": 13, "duration_seconds": 1.278}, "timestamp": "2026-01-12T09:55:06.877973"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 825.901, "latencies_ms": [825.901], "images_per_second": 1.211, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman with a black scarf is eating a hot dog at night.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13349.8, "ram_available_mb": 109156.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13350.3, "ram_available_mb": 109156.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [49.75, 49.75, 49.75, 49.75, 46.45, 46.45, 46.45, 46.45, 46.45], "power_watts_avg": 47.91, "power_watts_peak": 49.75, "energy_joules_est": 39.6, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-12T09:55:07.791002"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1931.037, "latencies_ms": [1931.037], "images_per_second": 0.518, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. hand: 1\n3. food: 1\n4. mouth: 1\n5. nose: 1\n6. eyes: 1\n7. hair: 1\n8. scarf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.3, "ram_available_mb": 109156.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13318.6, "ram_available_mb": 109187.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.76, 45.76, 45.76, 45.76, 45.76, 48.14, 48.14, 48.14, 48.14, 48.14, 47.84, 47.84, 47.84, 47.84, 47.84, 34.68, 34.68, 34.68, 34.68, 34.68], "power_watts_avg": 44.11, "power_watts_peak": 48.14, "energy_joules_est": 85.2, "sample_count": 20, "duration_seconds": 1.932}, "timestamp": "2026-01-12T09:55:09.806284"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1325.76, "latencies_ms": [1325.76], "images_per_second": 0.754, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The woman is in the foreground, with the hot dog in her mouth, and the background is blurred, indicating that the focus is on the woman and the hot dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.5, "ram_available_mb": 109187.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13386.0, "ram_available_mb": 109120.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [33.74, 33.74, 33.74, 33.74, 33.74, 45.43, 45.43, 45.43, 45.43, 45.43, 46.67, 46.67, 46.67, 46.67], "power_watts_avg": 41.61, "power_watts_peak": 46.67, "energy_joules_est": 55.19, "sample_count": 14, "duration_seconds": 1.326}, "timestamp": "2026-01-12T09:55:11.267136"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 705.073, "latencies_ms": [705.073], "images_per_second": 1.418, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is eating a hot dog at night.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13382.1, "ram_available_mb": 109124.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13310.6, "ram_available_mb": 109195.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [46.67, 33.92, 33.92, 33.92, 33.92, 33.92, 46.28, 46.28], "power_watts_avg": 38.61, "power_watts_peak": 46.67, "energy_joules_est": 27.24, "sample_count": 8, "duration_seconds": 0.706}, "timestamp": "2026-01-12T09:55:12.076637"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1496.326, "latencies_ms": [1496.326], "images_per_second": 0.668, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image is taken at night, with a warm yellow light illuminating the scene. The woman is wearing a black scarf and a black jacket, and she is holding a hot dog in her mouth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.6, "ram_available_mb": 109195.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13310.7, "ram_available_mb": 109195.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.28, 46.28, 46.28, 49.14, 49.14, 49.14, 49.14, 49.14, 45.72, 45.72, 45.72, 45.72, 45.0, 45.0, 45.0], "power_watts_avg": 46.83, "power_watts_peak": 49.14, "energy_joules_est": 70.13, "sample_count": 15, "duration_seconds": 1.498}, "timestamp": "2026-01-12T09:55:13.588636"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1165.807, "latencies_ms": [1165.807], "images_per_second": 0.858, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man and a woman are standing in a room, the man is holding a glass of wine and the woman is wearing a dress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.7, "ram_available_mb": 109195.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13306.3, "ram_available_mb": 109200.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.0, 45.0, 36.71, 36.71, 36.71, 36.71, 36.71, 47.45, 47.45, 47.45, 47.45, 47.45], "power_watts_avg": 42.56, "power_watts_peak": 47.45, "energy_joules_est": 49.66, "sample_count": 12, "duration_seconds": 1.167}, "timestamp": "2026-01-12T09:55:14.801540"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1930.541, "latencies_ms": [1930.541], "images_per_second": 0.518, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. glass: 1\n4. curtain: 1\n5. door: 1\n6. wall: 1\n7. shelf: 1\n8. vase: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13306.3, "ram_available_mb": 109200.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13292.9, "ram_available_mb": 109213.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.54, 45.54, 45.54, 45.54, 45.54, 46.89, 46.89, 46.89, 46.89, 46.89, 47.35, 47.35, 47.35, 47.35, 47.35, 34.57, 34.57, 34.57, 34.57, 34.57], "power_watts_avg": 43.59, "power_watts_peak": 47.35, "energy_joules_est": 84.16, "sample_count": 20, "duration_seconds": 1.931}, "timestamp": "2026-01-12T09:55:16.816733"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2563.262, "latencies_ms": [2563.262], "images_per_second": 0.39, "prompt_tokens": 1118, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The man is standing to the right of the woman, and the woman is standing to the left of the man. The man is holding a glass of wine in his right hand, and the woman is holding a glass of wine in her left hand. The man is wearing a black suit with a white shirt and a black tie, and the woman is wearing a black dress with a long sleeve.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.9, "ram_available_mb": 109213.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13282.6, "ram_available_mb": 109223.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.72, 33.72, 33.72, 33.72, 33.72, 42.31, 42.31, 42.31, 42.31, 42.31, 45.67, 45.67, 45.67, 45.67, 45.67, 36.87, 36.87, 36.87, 36.87, 36.87, 34.58, 34.58, 34.58, 34.58, 34.58, 34.6], "power_watts_avg": 38.48, "power_watts_peak": 45.67, "energy_joules_est": 98.63, "sample_count": 26, "duration_seconds": 2.564}, "timestamp": "2026-01-12T09:55:19.489326"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1174.001, "latencies_ms": [1174.001], "images_per_second": 0.852, "prompt_tokens": 1112, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man and a woman are standing in a room, the man is holding a glass of wine and the woman is looking at him.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13282.6, "ram_available_mb": 109223.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13282.2, "ram_available_mb": 109224.1, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.6, 34.6, 34.6, 35.38, 35.38, 35.38, 35.38, 35.38, 45.06, 45.06, 45.06, 45.06], "power_watts_avg": 38.41, "power_watts_peak": 45.06, "energy_joules_est": 45.11, "sample_count": 12, "duration_seconds": 1.174}, "timestamp": "2026-01-12T09:55:20.751802"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1672.274, "latencies_ms": [1672.274], "images_per_second": 0.598, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm and inviting atmosphere. The man is wearing a black suit with a white shirt and a black tie, while the woman is dressed in a black dress with a long sleeve.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13282.2, "ram_available_mb": 109224.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13328.3, "ram_available_mb": 109178.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.06, 43.99, 43.99, 43.99, 43.99, 43.99, 47.36, 47.36, 47.36, 47.36, 47.36, 48.7, 48.7, 48.7, 48.7, 48.7, 34.67], "power_watts_avg": 45.88, "power_watts_peak": 48.7, "energy_joules_est": 76.74, "sample_count": 17, "duration_seconds": 1.673}, "timestamp": "2026-01-12T09:55:22.465010"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2624.278, "latencies_ms": [2624.278], "images_per_second": 0.381, "prompt_tokens": 1099, "response_tokens_est": 83, "n_tiles": 1, "output_text": " The image captures a scene of a blue wooden cabinet with a white top, adorned with various items such as a silver teapot, a vase, and several small cups, all arranged on its shelves. The cabinet is situated in a room with a concrete floor, and in the background, there are other furniture pieces, including a chair and a table, suggesting a setting that could be a store or a home.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.4, "ram_available_mb": 109185.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13317.0, "ram_available_mb": 109189.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.67, 34.67, 34.67, 34.67, 42.02, 42.02, 42.02, 42.02, 42.02, 47.16, 47.16, 47.16, 47.16, 47.16, 39.58, 39.58, 39.58, 39.58, 39.58, 34.66, 34.66, 34.66, 34.66, 34.66, 34.61, 34.61, 34.61], "power_watts_avg": 39.25, "power_watts_peak": 47.16, "energy_joules_est": 103.0, "sample_count": 27, "duration_seconds": 2.625}, "timestamp": "2026-01-12T09:55:25.187407"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1531.322, "latencies_ms": [1531.322], "images_per_second": 0.653, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. blue cabinet\n2. silver teapot\n3. silver vase\n4. silver pitcher\n5. green tag\n6. orange tag\n7. white tag\n8. blue shelf", "error": null, "sys_before": {"cpu_percent": 1.8, "ram_used_mb": 13315.3, "ram_available_mb": 109191.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13331.5, "ram_available_mb": 109174.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.61, 30.95, 30.95, 30.95, 30.95, 30.95, 45.01, 45.01, 45.01, 45.01, 45.01, 48.98, 48.98, 48.98, 48.98, 48.98], "power_watts_avg": 41.21, "power_watts_peak": 48.98, "energy_joules_est": 63.14, "sample_count": 16, "duration_seconds": 1.532}, "timestamp": "2026-01-12T09:55:26.854352"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2017.696, "latencies_ms": [2017.696], "images_per_second": 0.496, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The blue cabinet is positioned in the foreground, with the green and white table to its right. The silver teapot is placed on the left side of the cabinet, while the white vase is situated on the right side. The green and white table is located in the background, behind the cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13370.5, "ram_available_mb": 109135.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.55, 34.55, 34.55, 34.55, 34.55, 46.39, 46.39, 46.39, 46.39, 46.39, 46.68, 46.68, 46.68, 46.68, 46.68, 34.63, 34.63, 34.63, 34.63, 34.63, 34.65], "power_watts_avg": 40.28, "power_watts_peak": 46.68, "energy_joules_est": 81.28, "sample_count": 21, "duration_seconds": 2.018}, "timestamp": "2026-01-12T09:55:28.972714"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2090.838, "latencies_ms": [2090.838], "images_per_second": 0.478, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a scene of a vintage blue cabinet, adorned with various items, including a silver teapot, a vase, and several small containers. The cabinet is situated in a room with a concrete floor, and the items on it are arranged in a seemingly random manner, creating a sense of disarray.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.5, "ram_available_mb": 109135.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13355.4, "ram_available_mb": 109150.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.65, 34.65, 34.65, 37.95, 37.95, 37.95, 37.95, 37.95, 45.23, 45.23, 45.23, 45.23, 45.23, 41.62, 41.62, 41.62, 41.62, 41.62, 34.48, 34.48, 34.48], "power_watts_avg": 39.59, "power_watts_peak": 45.23, "energy_joules_est": 82.82, "sample_count": 21, "duration_seconds": 2.092}, "timestamp": "2026-01-12T09:55:31.143252"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2441.924, "latencies_ms": [2441.924], "images_per_second": 0.41, "prompt_tokens": 1109, "response_tokens_est": 77, "n_tiles": 1, "output_text": " The image depicts a blue wooden cabinet with a white top, situated in a room with a concrete floor. The cabinet is adorned with various objects, including a silver teapot, a silver vase, and several small metal cups. The lighting in the room is natural, coming from a window out of frame, and the objects are arranged in a way that suggests they are for sale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13413.1, "ram_available_mb": 109093.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.48, 31.77, 31.77, 31.77, 31.77, 31.77, 46.36, 46.36, 46.36, 46.36, 46.36, 49.56, 49.56, 49.56, 49.56, 49.56, 34.74, 34.74, 34.74, 34.74, 34.74, 34.84, 34.84, 34.84, 34.84], "power_watts_avg": 39.44, "power_watts_peak": 49.56, "energy_joules_est": 96.33, "sample_count": 25, "duration_seconds": 2.442}, "timestamp": "2026-01-12T09:55:33.708133"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 765.298, "latencies_ms": [765.298], "images_per_second": 1.307, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A plate of bread with butter on it is on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13405.2, "ram_available_mb": 109101.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13410.9, "ram_available_mb": 109095.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [34.84, 32.03, 32.03, 32.03, 32.03, 32.03, 45.44, 45.44], "power_watts_avg": 35.73, "power_watts_peak": 45.44, "energy_joules_est": 27.37, "sample_count": 8, "duration_seconds": 0.766}, "timestamp": "2026-01-12T09:55:34.572077"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1183.215, "latencies_ms": [1183.215], "images_per_second": 0.845, "prompt_tokens": 1113, "response_tokens_est": 29, "n_tiles": 1, "output_text": " bread: 6, butter: 6, plate: 1, remote: 1, keyboard: 1, jar: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.0, "ram_available_mb": 109099.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13390.8, "ram_available_mb": 109115.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.44, 45.44, 45.44, 51.67, 51.67, 51.67, 51.67, 51.67, 47.48, 47.48, 47.48, 47.48], "power_watts_avg": 48.72, "power_watts_peak": 51.67, "energy_joules_est": 57.67, "sample_count": 12, "duration_seconds": 1.184}, "timestamp": "2026-01-12T09:55:35.787765"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1419.717, "latencies_ms": [1419.717], "images_per_second": 0.704, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The plate of bread and butter is located in the foreground, with the keyboard and remote control in the background. The butter is spread on the bread slices, which are placed on the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.9, "ram_available_mb": 109123.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.4, "ram_available_mb": 109118.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [44.46, 44.46, 44.46, 44.46, 44.46, 47.63, 47.63, 47.63, 47.63, 47.63, 48.15, 48.15, 48.15, 48.15, 48.15], "power_watts_avg": 46.75, "power_watts_peak": 48.15, "energy_joules_est": 66.39, "sample_count": 15, "duration_seconds": 1.42}, "timestamp": "2026-01-12T09:55:37.302812"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 900.797, "latencies_ms": [900.797], "images_per_second": 1.11, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate of cheese and bread is on a desk with a keyboard and a remote control.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.4, "ram_available_mb": 109118.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13453.9, "ram_available_mb": 109052.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [33.39, 33.39, 33.39, 33.39, 33.39, 46.13, 46.13, 46.13, 46.13], "power_watts_avg": 39.05, "power_watts_peak": 46.13, "energy_joules_est": 35.2, "sample_count": 9, "duration_seconds": 0.901}, "timestamp": "2026-01-12T09:55:38.215564"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1478.487, "latencies_ms": [1478.487], "images_per_second": 0.676, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a plate of bread with butter on it, placed on a table with a yellow and green background. The lighting is bright and natural, suggesting that the photo was taken during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13449.9, "ram_available_mb": 109056.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.0, "ram_available_mb": 109149.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.13, 46.28, 46.28, 46.28, 46.28, 46.28, 48.0, 48.0, 48.0, 48.0, 48.0, 49.39, 49.39, 49.39, 49.39], "power_watts_avg": 47.67, "power_watts_peak": 49.39, "energy_joules_est": 70.5, "sample_count": 15, "duration_seconds": 1.479}, "timestamp": "2026-01-12T09:55:39.732536"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1251.754, "latencies_ms": [1251.754], "images_per_second": 0.799, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a suit and tie is adjusting his tie, which has a pattern of red lights along the length of the tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.0, "ram_available_mb": 109149.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13412.9, "ram_available_mb": 109093.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [49.39, 33.13, 33.13, 33.13, 33.13, 33.13, 51.15, 51.15, 51.15, 51.15, 51.15, 53.03, 53.03], "power_watts_avg": 44.37, "power_watts_peak": 53.03, "energy_joules_est": 55.57, "sample_count": 13, "duration_seconds": 1.252}, "timestamp": "2026-01-12T09:55:41.047600"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1509.372, "latencies_ms": [1509.372], "images_per_second": 0.663, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " tie: 1, glasses: 1, suit: 1, shirt: 1, tie clip: 1, tie: 1, man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.9, "ram_available_mb": 109093.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13392.9, "ram_available_mb": 109113.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [53.03, 53.03, 53.03, 36.88, 36.88, 36.88, 36.88, 36.88, 50.51, 50.51, 50.51, 50.51, 50.51, 49.35, 49.35, 49.35], "power_watts_avg": 46.5, "power_watts_peak": 53.03, "energy_joules_est": 70.21, "sample_count": 16, "duration_seconds": 1.51}, "timestamp": "2026-01-12T09:55:42.660889"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2353.078, "latencies_ms": [2353.078], "images_per_second": 0.425, "prompt_tokens": 1450, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the tie being the central object. The tie is located in the middle ground, with the man's face and glasses being the closest objects to the camera. The background is a dark, neutral color, providing a contrast to the man's tie and making it stand out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.8, "ram_available_mb": 109112.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.6, "ram_available_mb": 109140.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.35, 49.35, 31.05, 31.05, 31.05, 31.05, 31.05, 49.67, 49.67, 49.67, 49.67, 49.67, 53.45, 53.45, 53.45, 53.45, 53.45, 34.64, 34.64, 34.64, 34.64, 34.64, 34.71, 34.71], "power_watts_avg": 42.17, "power_watts_peak": 53.45, "energy_joules_est": 99.24, "sample_count": 24, "duration_seconds": 2.353}, "timestamp": "2026-01-12T09:55:45.084129"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1101.293, "latencies_ms": [1101.293], "images_per_second": 0.908, "prompt_tokens": 1444, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man is adjusting his tie with a tie light that has red, green, and yellow lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13385.2, "ram_available_mb": 109121.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 31.99, 31.99, 31.99, 31.99, 31.99, 49.36, 49.36, 49.36, 49.36], "power_watts_avg": 38.8, "power_watts_peak": 49.36, "energy_joules_est": 42.75, "sample_count": 11, "duration_seconds": 1.102}, "timestamp": "2026-01-12T09:55:46.248436"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1293.074, "latencies_ms": [1293.074], "images_per_second": 0.773, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The man is wearing a black suit with a tie that has red and green lights. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.7, "ram_available_mb": 109130.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13390.6, "ram_available_mb": 109115.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.36, 52.21, 52.21, 52.21, 52.21, 52.21, 50.89, 50.89, 50.89, 50.89, 50.89, 52.69, 52.69], "power_watts_avg": 51.56, "power_watts_peak": 52.69, "energy_joules_est": 66.7, "sample_count": 13, "duration_seconds": 1.294}, "timestamp": "2026-01-12T09:55:47.563708"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1032.488, "latencies_ms": [1032.488], "images_per_second": 0.969, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is walking across the street in front of a building with a sign that says \"TAFARINA\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.9, "ram_available_mb": 109120.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [52.69, 52.69, 52.69, 40.88, 40.88, 40.88, 40.88, 40.88, 47.62, 47.62, 47.62], "power_watts_avg": 45.94, "power_watts_peak": 52.69, "energy_joules_est": 47.45, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-12T09:55:48.679404"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1971.74, "latencies_ms": [1971.74], "images_per_second": 0.507, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. traffic light: 1\n3. street light: 1\n4. building: 1\n5. sign: 1\n6. car: 1\n7. sidewalk: 1\n8. street: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.62, 47.62, 42.26, 42.26, 42.26, 42.26, 42.26, 46.73, 46.73, 46.73, 46.73, 46.73, 48.79, 48.79, 48.79, 48.79, 48.79, 34.45, 34.45, 34.45], "power_watts_avg": 44.37, "power_watts_peak": 48.79, "energy_joules_est": 87.52, "sample_count": 20, "duration_seconds": 1.972}, "timestamp": "2026-01-12T09:55:50.697836"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1399.161, "latencies_ms": [1399.161], "images_per_second": 0.715, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The person is in the foreground, walking on the sidewalk, while the building is in the background. The traffic light is also in the background, and the street is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13388.7, "ram_available_mb": 109117.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [34.45, 32.03, 32.03, 32.03, 32.03, 32.03, 46.0, 46.0, 46.0, 46.0, 46.0, 48.91, 48.91, 48.91], "power_watts_avg": 40.81, "power_watts_peak": 48.91, "energy_joules_est": 57.11, "sample_count": 14, "duration_seconds": 1.4}, "timestamp": "2026-01-12T09:55:52.159727"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1091.297, "latencies_ms": [1091.297], "images_per_second": 0.916, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man is walking across the street at night in front of a building with a sign that says \"TAFARINA\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13380.8, "ram_available_mb": 109125.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13297.4, "ram_available_mb": 109208.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 21.0}, "power_stats": {"power_watts_samples": [48.91, 48.91, 34.35, 34.35, 34.35, 34.35, 34.35, 47.62, 47.62, 47.62, 47.62], "power_watts_avg": 41.82, "power_watts_peak": 48.91, "energy_joules_est": 45.67, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-12T09:55:53.270664"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 958.065, "latencies_ms": [958.065], "images_per_second": 1.044, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The picture is taken at night, the sky is blue and the street is lit by streetlights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13297.4, "ram_available_mb": 109208.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13321.2, "ram_available_mb": 109185.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.62, 48.36, 48.36, 48.36, 48.36, 48.36, 47.92, 47.92, 47.92, 47.92], "power_watts_avg": 48.11, "power_watts_peak": 48.36, "energy_joules_est": 46.11, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-12T09:55:54.281523"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1906.987, "latencies_ms": [1906.987], "images_per_second": 0.524, "prompt_tokens": 1099, "response_tokens_est": 56, "n_tiles": 1, "output_text": " In the image, a young girl is skillfully riding a wave on a blue surfboard, while a man in a black wetsuit and a woman in a black bikini are also enjoying the water, with a man in a red and black wetsuit swimming nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.3, "ram_available_mb": 109189.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13306.4, "ram_available_mb": 109199.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.92, 46.8, 46.8, 46.8, 46.8, 46.8, 47.04, 47.04, 47.04, 47.04, 47.04, 48.06, 48.06, 48.06, 48.06, 48.06, 34.7, 34.7, 34.7], "power_watts_avg": 45.34, "power_watts_peak": 48.06, "energy_joules_est": 86.5, "sample_count": 19, "duration_seconds": 1.908}, "timestamp": "2026-01-12T09:55:56.200071"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2000.838, "latencies_ms": [2000.838], "images_per_second": 0.5, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. girl: 1\n2. surfboard: 1\n3. wave: 1\n4. person: 2\n5. surfboard: 2\n6. person: 1\n7. surfboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13298.5, "ram_available_mb": 109207.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13312.6, "ram_available_mb": 109193.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.7, 32.98, 32.98, 32.98, 32.98, 32.98, 46.98, 46.98, 46.98, 46.98, 46.98, 48.59, 48.59, 48.59, 48.59, 48.59, 34.5, 34.5, 34.5, 34.5], "power_watts_avg": 40.77, "power_watts_peak": 48.59, "energy_joules_est": 81.61, "sample_count": 20, "duration_seconds": 2.002}, "timestamp": "2026-01-12T09:55:58.269148"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2652.935, "latencies_ms": [2652.935], "images_per_second": 0.377, "prompt_tokens": 1117, "response_tokens_est": 84, "n_tiles": 1, "output_text": " The main object, a girl, is in the foreground, riding a wave on a blue surfboard. The surfboard is positioned in the middle of the image, with the girl's body and the surfboard being the central focus. In the background, there are other people, including a man in a black wetsuit and a woman in a red and black swimsuit, who are also engaged in surfing.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13304.7, "ram_available_mb": 109201.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13300.4, "ram_available_mb": 109205.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.97, 33.97, 33.97, 33.97, 33.97, 46.49, 46.49, 46.49, 46.49, 46.49, 47.32, 47.32, 47.32, 47.32, 47.32, 34.64, 34.64, 34.64, 34.64, 34.64, 34.66, 34.66, 34.66, 34.66, 34.66, 34.59, 34.59], "power_watts_avg": 39.06, "power_watts_peak": 47.32, "energy_joules_est": 103.67, "sample_count": 27, "duration_seconds": 2.654}, "timestamp": "2026-01-12T09:56:01.043809"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2338.84, "latencies_ms": [2338.84], "images_per_second": 0.428, "prompt_tokens": 1111, "response_tokens_est": 72, "n_tiles": 1, "output_text": " In the vast expanse of the ocean, a young girl in a vibrant bikini is skillfully riding a wave on a blue surfboard. Nearby, two other surfers are enjoying the water, one of them lying on his board, while the other is paddling. The scene is a perfect blend of adventure and tranquility, capturing the essence of surfing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13300.4, "ram_available_mb": 109205.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.59, 34.59, 34.9, 34.9, 34.9, 34.9, 34.9, 45.41, 45.41, 45.41, 45.41, 45.41, 45.99, 45.99, 45.99, 45.99, 45.99, 34.63, 34.63, 34.63, 34.63, 34.63, 34.58, 34.58], "power_watts_avg": 39.29, "power_watts_peak": 45.99, "energy_joules_est": 91.93, "sample_count": 24, "duration_seconds": 2.34}, "timestamp": "2026-01-12T09:56:03.517769"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1733.293, "latencies_ms": [1733.293], "images_per_second": 0.577, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a young girl surfing on a blue surfboard in the ocean. The water is a deep blue, reflecting the clear sky above. The sunlight filters through the water, creating a shimmering effect on the waves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13361.9, "ram_available_mb": 109144.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.58, 34.58, 34.58, 35.96, 35.96, 35.96, 35.96, 35.96, 45.48, 45.48, 45.48, 45.48, 45.48, 44.16, 44.16, 44.16, 44.16, 44.16], "power_watts_avg": 40.65, "power_watts_peak": 45.48, "energy_joules_est": 70.5, "sample_count": 18, "duration_seconds": 1.734}, "timestamp": "2026-01-12T09:56:05.386579"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1182.325, "latencies_ms": [1182.325], "images_per_second": 0.846, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a white shirt and beige pants is feeding an elephant with a stick in a fenced area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13361.9, "ram_available_mb": 109144.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13423.2, "ram_available_mb": 109083.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.37, 34.37, 34.37, 34.37, 34.37, 44.67, 44.67, 44.67, 44.67, 44.67, 45.92, 45.92], "power_watts_avg": 40.59, "power_watts_peak": 45.92, "energy_joules_est": 48.01, "sample_count": 12, "duration_seconds": 1.183}, "timestamp": "2026-01-12T09:56:06.602710"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1046.442, "latencies_ms": [1046.442], "images_per_second": 0.956, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " elephant: 1, man: 1, fence: 1, tree: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13415.4, "ram_available_mb": 109090.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13490.8, "ram_available_mb": 109015.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [45.92, 45.92, 37.47, 37.47, 37.47, 37.47, 37.47, 47.37, 47.37, 47.37, 47.37], "power_watts_avg": 42.61, "power_watts_peak": 47.37, "energy_joules_est": 44.61, "sample_count": 11, "duration_seconds": 1.047}, "timestamp": "2026-01-12T09:56:07.713035"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1915.041, "latencies_ms": [1915.041], "images_per_second": 0.522, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, while the elephant is on the right side. The man is in the foreground, while the elephant is in the background. The man is holding the food out to the elephant, which is reaching out to take it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13486.6, "ram_available_mb": 109019.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13471.0, "ram_available_mb": 109035.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.37, 44.23, 44.23, 44.23, 44.23, 44.23, 47.09, 47.09, 47.09, 47.09, 47.09, 49.25, 49.25, 49.25, 49.25, 49.25, 34.2, 34.2, 34.2, 34.2], "power_watts_avg": 44.35, "power_watts_peak": 49.25, "energy_joules_est": 84.95, "sample_count": 20, "duration_seconds": 1.915}, "timestamp": "2026-01-12T09:56:09.731870"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 879.224, "latencies_ms": [879.224], "images_per_second": 1.137, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is feeding an elephant in a fenced area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13467.1, "ram_available_mb": 109039.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13465.1, "ram_available_mb": 109041.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.2, 31.38, 31.38, 31.38, 31.38, 31.38, 45.98, 45.98, 45.98], "power_watts_avg": 36.56, "power_watts_peak": 45.98, "energy_joules_est": 32.17, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-12T09:56:10.643510"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 888.692, "latencies_ms": [888.692], "images_per_second": 1.125, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephant is gray, the man is wearing white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13457.2, "ram_available_mb": 109049.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13452.1, "ram_available_mb": 109054.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.98, 45.98, 49.18, 49.18, 49.18, 49.18, 49.18, 47.29, 47.29], "power_watts_avg": 48.05, "power_watts_peak": 49.18, "energy_joules_est": 42.73, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-12T09:56:11.554176"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 996.9, "latencies_ms": [996.9], "images_per_second": 1.003, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog sits on a bed covered in clothes and other items, with a box of tissues nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13452.1, "ram_available_mb": 109054.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13400.0, "ram_available_mb": 109106.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.29, 47.29, 47.29, 51.85, 51.85, 51.85, 51.85, 51.85, 47.21, 47.21], "power_watts_avg": 49.55, "power_watts_peak": 51.85, "energy_joules_est": 49.41, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-12T09:56:12.566039"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1341.101, "latencies_ms": [1341.101], "images_per_second": 0.746, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " dog: 1, box: 1, clothes: 1, bag: 1, blanket: 1, pillow: 1, curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.3, "ram_available_mb": 109106.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13422.9, "ram_available_mb": 109083.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.21, 47.21, 47.21, 47.22, 47.22, 47.22, 47.22, 47.22, 47.59, 47.59, 47.59, 47.59, 47.59, 43.8], "power_watts_avg": 47.11, "power_watts_peak": 47.59, "energy_joules_est": 63.2, "sample_count": 14, "duration_seconds": 1.342}, "timestamp": "2026-01-12T09:56:13.979650"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1671.621, "latencies_ms": [1671.621], "images_per_second": 0.598, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The dog is sitting on the bed, which is in the foreground of the image. The bed is covered with clothes and a box, which are in the middle of the image. The curtain is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.0, "ram_available_mb": 109091.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13416.0, "ram_available_mb": 109090.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.8, 43.8, 43.8, 43.8, 40.96, 40.96, 40.96, 40.96, 40.96, 46.26, 46.26, 46.26, 46.26, 46.26, 39.67, 39.67, 39.67], "power_watts_avg": 42.96, "power_watts_peak": 46.26, "energy_joules_est": 71.82, "sample_count": 17, "duration_seconds": 1.672}, "timestamp": "2026-01-12T09:56:15.694321"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.37, "latencies_ms": [828.37], "images_per_second": 1.207, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A brown dog sits on a bed with clothes and a box on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.1, "ram_available_mb": 109094.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13403.4, "ram_available_mb": 109102.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.67, 39.67, 32.08, 32.08, 32.08, 32.08, 32.08, 47.13, 47.13], "power_watts_avg": 37.11, "power_watts_peak": 47.13, "energy_joules_est": 30.75, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-12T09:56:16.603636"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1348.254, "latencies_ms": [1348.254], "images_per_second": 0.742, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The dog is sitting on a bed with a white curtain in the background. The dog is brown and white, and the bed is covered with a white comforter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.4, "ram_available_mb": 109106.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13383.8, "ram_available_mb": 109122.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.13, 47.13, 50.44, 50.44, 50.44, 50.44, 50.44, 46.08, 46.08, 46.08, 46.08, 46.08, 45.44, 45.44], "power_watts_avg": 47.7, "power_watts_peak": 50.44, "energy_joules_est": 64.32, "sample_count": 14, "duration_seconds": 1.349}, "timestamp": "2026-01-12T09:56:18.013926"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1433.123, "latencies_ms": [1433.123], "images_per_second": 0.698, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man wearing a blue tie and a white shirt is sitting at a desk with a laptop and a pen in his hand, and he is looking at the laptop screen with a thoughtful expression.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.8, "ram_available_mb": 109122.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13389.0, "ram_available_mb": 109117.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.44, 45.44, 45.44, 39.58, 39.58, 39.58, 39.58, 39.58, 46.54, 46.54, 46.54, 46.54, 46.54, 42.73, 42.73], "power_watts_avg": 43.49, "power_watts_peak": 46.54, "energy_joules_est": 62.37, "sample_count": 15, "duration_seconds": 1.434}, "timestamp": "2026-01-12T09:56:19.529083"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1346.513, "latencies_ms": [1346.513], "images_per_second": 0.743, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 1, pen: 1, paper: 1, glasses: 1, shirt: 1, tie: 1, man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.0, "ram_available_mb": 109117.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13411.3, "ram_available_mb": 109095.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [42.73, 42.73, 42.73, 38.97, 38.97, 38.97, 38.97, 38.97, 46.26, 46.26, 46.26, 46.26, 46.26, 42.12], "power_watts_avg": 42.61, "power_watts_peak": 46.26, "energy_joules_est": 57.41, "sample_count": 14, "duration_seconds": 1.347}, "timestamp": "2026-01-12T09:56:20.944727"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2306.128, "latencies_ms": [2306.128], "images_per_second": 0.434, "prompt_tokens": 1117, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The man is seated at a desk with a laptop in front of him, which is positioned to his left. The laptop is in front of him, and the man is holding a pen in his right hand, which is positioned near the laptop. The man is also holding a pair of glasses in his left hand, which is positioned near his face.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.3, "ram_available_mb": 109099.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13413.5, "ram_available_mb": 109092.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.12, 42.12, 42.12, 42.12, 42.36, 42.36, 42.36, 42.36, 42.36, 46.42, 46.42, 46.42, 46.42, 46.42, 38.48, 38.48, 38.48, 38.48, 38.48, 34.3, 34.3, 34.3, 34.3], "power_watts_avg": 40.96, "power_watts_peak": 46.42, "energy_joules_est": 94.48, "sample_count": 23, "duration_seconds": 2.307}, "timestamp": "2026-01-12T09:56:23.267503"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1410.894, "latencies_ms": [1410.894], "images_per_second": 0.709, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A man wearing a blue tie and a white shirt is sitting at a desk with a laptop and a pen in his hand. He is looking at the laptop screen with a thoughtful expression.", "error": null, "sys_before": {"cpu_percent": 1.9, "ram_used_mb": 13413.5, "ram_available_mb": 109092.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13414.8, "ram_available_mb": 109091.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.83, 33.83, 33.83, 33.83, 33.83, 46.51, 46.51, 46.51, 46.51, 46.51, 47.67, 47.67, 47.67, 47.67, 47.67], "power_watts_avg": 42.67, "power_watts_peak": 47.67, "energy_joules_est": 60.23, "sample_count": 15, "duration_seconds": 1.411}, "timestamp": "2026-01-12T09:56:24.832899"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 959.973, "latencies_ms": [959.973], "images_per_second": 1.042, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The man is wearing a blue tie and a white shirt. The background is a light blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.9, "ram_available_mb": 109095.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13383.2, "ram_available_mb": 109123.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [33.36, 33.36, 33.36, 33.36, 33.36, 46.1, 46.1, 46.1, 46.1, 46.1], "power_watts_avg": 39.73, "power_watts_peak": 46.1, "energy_joules_est": 38.15, "sample_count": 10, "duration_seconds": 0.96}, "timestamp": "2026-01-12T09:56:25.845633"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 957.396, "latencies_ms": [957.396], "images_per_second": 1.044, "prompt_tokens": 1432, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large airplane is flying in the sky with a moon in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13328.6, "ram_available_mb": 109177.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.33, 47.33, 47.33, 47.33, 47.33, 46.06, 46.06, 46.06, 46.06, 46.06], "power_watts_avg": 46.69, "power_watts_peak": 47.33, "energy_joules_est": 44.71, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-12T09:56:26.860328"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 673.268, "latencies_ms": [673.268], "images_per_second": 1.485, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " airplane: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.3, "ram_available_mb": 109181.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13408.6, "ram_available_mb": 109097.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [51.27, 51.27, 51.27, 51.27, 51.27, 50.42, 50.42], "power_watts_avg": 51.03, "power_watts_peak": 51.27, "energy_joules_est": 34.37, "sample_count": 7, "duration_seconds": 0.674}, "timestamp": "2026-01-12T09:56:27.573062"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1821.845, "latencies_ms": [1821.845], "images_per_second": 0.549, "prompt_tokens": 1450, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The airplane is in the background, flying high in the sky, while the moon is in the foreground, closer to the camera. The airplane is to the right of the moon, and both are in the upper part of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13408.6, "ram_available_mb": 109097.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13384.9, "ram_available_mb": 109121.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.42, 50.42, 50.42, 53.19, 53.19, 53.19, 53.19, 53.19, 56.97, 56.97, 56.97, 56.97, 56.97, 49.04, 49.04, 49.04, 49.04, 49.04, 34.91], "power_watts_avg": 51.69, "power_watts_peak": 56.97, "energy_joules_est": 94.19, "sample_count": 19, "duration_seconds": 1.822}, "timestamp": "2026-01-12T09:56:29.492042"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 966.205, "latencies_ms": [966.205], "images_per_second": 1.035, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A plane is flying in the sky and a moon is in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.1, "ram_available_mb": 109129.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13405.2, "ram_available_mb": 109101.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 34.91, 34.91, 39.24, 39.24, 39.24, 39.24, 39.24, 50.3], "power_watts_avg": 38.61, "power_watts_peak": 50.3, "energy_joules_est": 37.33, "sample_count": 10, "duration_seconds": 0.967}, "timestamp": "2026-01-12T09:56:30.506548"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1043.849, "latencies_ms": [1043.849], "images_per_second": 0.958, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The airplane is white with red and blue on the tail, and the moon is orange.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13405.2, "ram_available_mb": 109101.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13385.4, "ram_available_mb": 109120.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [50.3, 50.3, 50.3, 51.28, 51.28, 51.28, 51.28, 51.28, 51.35, 51.35, 51.35], "power_watts_avg": 51.03, "power_watts_peak": 51.35, "energy_joules_est": 53.3, "sample_count": 11, "duration_seconds": 1.044}, "timestamp": "2026-01-12T09:56:31.624210"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1260.541, "latencies_ms": [1260.541], "images_per_second": 0.793, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young man wearing a tie-dye shirt and black pants is performing a trick on a skateboard in a skate park.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13385.4, "ram_available_mb": 109120.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13365.0, "ram_available_mb": 109141.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [51.35, 51.35, 45.74, 45.74, 45.74, 45.74, 45.74, 50.45, 50.45, 50.45, 50.45, 50.45, 51.53], "power_watts_avg": 48.86, "power_watts_peak": 51.53, "energy_joules_est": 61.6, "sample_count": 13, "duration_seconds": 1.261}, "timestamp": "2026-01-12T09:56:32.942133"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2246.122, "latencies_ms": [2246.122], "images_per_second": 0.445, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. palm tree: 2\n4. building: 1\n5. playground equipment: 1\n6. skateboard ramp: 1\n7. street light: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.7, "ram_available_mb": 109150.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13383.9, "ram_available_mb": 109122.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [51.53, 51.53, 51.53, 51.53, 42.21, 42.21, 42.21, 42.21, 42.21, 50.88, 50.88, 50.88, 50.88, 50.88, 44.2, 44.2, 44.2, 44.2, 44.2, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 44.85, "power_watts_peak": 51.53, "energy_joules_est": 100.75, "sample_count": 23, "duration_seconds": 2.246}, "timestamp": "2026-01-12T09:56:35.267469"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1703.442, "latencies_ms": [1703.442], "images_per_second": 0.587, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the air, while the skate park and palm trees are in the background. The skateboarder is closer to the camera than the palm trees.", "error": null, "sys_before": {"cpu_percent": 1.9, "ram_used_mb": 13374.6, "ram_available_mb": 109131.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13388.3, "ram_available_mb": 109118.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.7, 32.7, 32.7, 32.7, 32.7, 45.89, 45.89, 45.89, 45.89, 45.89, 51.72, 51.72, 51.72, 51.72, 51.72, 39.38, 39.38], "power_watts_avg": 42.96, "power_watts_peak": 51.72, "energy_joules_est": 73.21, "sample_count": 17, "duration_seconds": 1.704}, "timestamp": "2026-01-12T09:56:37.034902"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 997.541, "latencies_ms": [997.541], "images_per_second": 1.002, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young man wearing a tie dye shirt is skateboarding in a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13398.6, "ram_available_mb": 109107.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [39.38, 39.38, 39.38, 38.87, 38.87, 38.87, 38.87, 38.87, 51.87, 51.87], "power_watts_avg": 41.62, "power_watts_peak": 51.87, "energy_joules_est": 41.54, "sample_count": 10, "duration_seconds": 0.998}, "timestamp": "2026-01-12T09:56:38.048251"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1296.158, "latencies_ms": [1296.158], "images_per_second": 0.772, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The skateboarder is wearing a tie-dye shirt and black pants. The skate park is surrounded by palm trees and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.3, "ram_available_mb": 109117.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13384.6, "ram_available_mb": 109121.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.87, 51.87, 51.87, 51.9, 51.9, 51.9, 51.9, 51.9, 51.5, 51.5, 51.5, 51.5, 51.5], "power_watts_avg": 51.74, "power_watts_peak": 51.9, "energy_joules_est": 67.1, "sample_count": 13, "duration_seconds": 1.297}, "timestamp": "2026-01-12T09:56:39.364120"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1087.099, "latencies_ms": [1087.099], "images_per_second": 0.92, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In the image, a sheep with a fluffy coat is standing in a grassy field, surrounded by trees and a wire fence.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13375.2, "ram_available_mb": 109131.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.32, 48.32, 48.32, 48.32, 48.32, 47.91, 47.91, 47.91, 47.91, 47.91, 47.6], "power_watts_avg": 48.07, "power_watts_peak": 48.32, "energy_joules_est": 52.28, "sample_count": 11, "duration_seconds": 1.088}, "timestamp": "2026-01-12T09:56:40.479980"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1928.618, "latencies_ms": [1928.618], "images_per_second": 0.519, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. wire: 1\n3. grass: 1\n4. trees: 1\n5. fence: 1\n6. wire: 1\n7. grass: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.9, "ram_available_mb": 109142.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13356.3, "ram_available_mb": 109150.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.6, 47.6, 47.6, 47.6, 43.81, 43.81, 43.81, 43.81, 43.81, 47.89, 47.89, 47.89, 47.89, 47.89, 39.19, 39.19, 39.19, 39.19, 39.19, 34.52], "power_watts_avg": 43.97, "power_watts_peak": 47.89, "energy_joules_est": 84.82, "sample_count": 20, "duration_seconds": 1.929}, "timestamp": "2026-01-12T09:56:42.499380"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1461.547, "latencies_ms": [1461.547], "images_per_second": 0.684, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The sheep is in the foreground, with the wire fence in the middle ground, and the trees in the background. The sheep is looking directly at the camera, while the trees are behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.3, "ram_available_mb": 109150.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.5, "ram_available_mb": 109112.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.52, 34.52, 34.52, 37.48, 37.48, 37.48, 37.48, 37.48, 45.41, 45.41, 45.41, 45.41, 45.41, 43.26, 43.26], "power_watts_avg": 40.3, "power_watts_peak": 45.41, "energy_joules_est": 58.94, "sample_count": 15, "duration_seconds": 1.462}, "timestamp": "2026-01-12T09:56:44.061060"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 986.322, "latencies_ms": [986.322], "images_per_second": 1.014, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A sheep with a fluffy coat is standing in a fenced-in area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13409.2, "ram_available_mb": 109097.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [43.26, 43.26, 43.26, 38.95, 38.95, 38.95, 38.95, 38.95, 47.26, 47.26], "power_watts_avg": 41.9, "power_watts_peak": 47.26, "energy_joules_est": 41.35, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-12T09:56:45.070091"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 883.655, "latencies_ms": [883.655], "images_per_second": 1.132, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The sheep is white and fluffy, and the photo was taken on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13405.2, "ram_available_mb": 109101.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13335.8, "ram_available_mb": 109170.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [47.26, 47.26, 47.26, 47.92, 47.92, 47.92, 47.92, 47.92, 47.73], "power_watts_avg": 47.68, "power_watts_peak": 47.92, "energy_joules_est": 42.16, "sample_count": 9, "duration_seconds": 0.884}, "timestamp": "2026-01-12T09:56:45.979318"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1348.397, "latencies_ms": [1348.397], "images_per_second": 0.742, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image shows a close-up of a silver electronic device with a red button and a white button, with the word \"Wii\" written in red on the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.8, "ram_available_mb": 109170.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.4, "ram_available_mb": 109095.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.73, 47.73, 47.73, 47.73, 52.23, 52.23, 52.23, 52.23, 52.23, 47.63, 47.63, 47.63, 47.63, 47.63], "power_watts_avg": 49.3, "power_watts_peak": 52.23, "energy_joules_est": 66.49, "sample_count": 14, "duration_seconds": 1.349}, "timestamp": "2026-01-12T09:56:47.390915"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2226.764, "latencies_ms": [2226.764], "images_per_second": 0.449, "prompt_tokens": 1113, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. white button: 2\n2. red button: 1\n3. silver button: 1\n4. black button: 1\n5. white arrow button: 1\n6. white circle button: 1\n7. silver circle button: 1\n8. red circle button: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13402.5, "ram_available_mb": 109103.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13380.9, "ram_available_mb": 109125.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.95, 39.95, 39.95, 39.95, 39.95, 46.51, 46.51, 46.51, 46.51, 46.51, 46.96, 46.96, 46.96, 46.96, 46.96, 35.17, 35.17, 35.17, 35.17, 35.17, 34.72, 34.72, 34.72], "power_watts_avg": 41.18, "power_watts_peak": 46.96, "energy_joules_est": 91.71, "sample_count": 23, "duration_seconds": 2.227}, "timestamp": "2026-01-12T09:56:49.708004"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2099.913, "latencies_ms": [2099.913], "images_per_second": 0.476, "prompt_tokens": 1117, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the left side of the device being closer to the camera than the right side. The buttons are arranged in a circular pattern around the center of the device, with the \"Wi-Fi\" button being the most prominent and closest to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.9, "ram_available_mb": 109129.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.6, "ram_available_mb": 109145.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.72, 31.24, 31.24, 31.24, 31.24, 31.24, 45.42, 45.42, 45.42, 45.42, 45.42, 48.34, 48.34, 48.34, 48.34, 48.34, 34.69, 34.69, 34.69, 34.69, 34.69], "power_watts_avg": 39.67, "power_watts_peak": 48.34, "energy_joules_est": 83.34, "sample_count": 21, "duration_seconds": 2.101}, "timestamp": "2026-01-12T09:56:51.879856"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 802.707, "latencies_ms": [802.707], "images_per_second": 1.246, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A close up of a silver device with buttons and a red button.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13386.4, "ram_available_mb": 109119.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 34.68, 44.06, 44.06, 44.06, 44.06], "power_watts_avg": 39.37, "power_watts_peak": 44.06, "energy_joules_est": 31.64, "sample_count": 8, "duration_seconds": 0.804}, "timestamp": "2026-01-12T09:56:52.741865"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1013.177, "latencies_ms": [1013.177], "images_per_second": 0.987, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The device is silver with a red button and a white button. The device is illuminated by a light source.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.4, "ram_available_mb": 109119.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [44.06, 45.34, 45.34, 45.34, 45.34, 45.34, 50.66, 50.66, 50.66, 50.66, 50.66], "power_watts_avg": 47.64, "power_watts_peak": 50.66, "energy_joules_est": 48.29, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T09:56:53.854594"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1205.882, "latencies_ms": [1205.882], "images_per_second": 0.829, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A woman in a black dress and high heels is standing in a kitchen with a glass of orange juice in her hand.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13365.4, "ram_available_mb": 109140.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13288.4, "ram_available_mb": 109217.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.88, 47.88, 47.88, 47.88, 47.88, 44.65, 44.65, 44.65, 44.65, 44.65, 51.05, 51.05], "power_watts_avg": 47.06, "power_watts_peak": 51.05, "energy_joules_est": 56.76, "sample_count": 12, "duration_seconds": 1.206}, "timestamp": "2026-01-12T09:56:55.073122"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2109.187, "latencies_ms": [2109.187], "images_per_second": 0.474, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. glass: 1\n3. refrigerator: 1\n4. bottle: 1\n5. cupboard: 1\n6. floor: 1\n7. wall: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13288.4, "ram_available_mb": 109217.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.05, 51.05, 51.05, 42.79, 42.79, 42.79, 42.79, 42.79, 51.73, 51.73, 51.73, 51.73, 51.73, 50.07, 50.07, 50.07, 50.07, 50.07, 34.87, 34.87, 34.87], "power_watts_avg": 46.7, "power_watts_peak": 51.73, "energy_joules_est": 98.53, "sample_count": 21, "duration_seconds": 2.11}, "timestamp": "2026-01-12T09:56:57.195309"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1685.782, "latencies_ms": [1685.782], "images_per_second": 0.593, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the refrigerator in the background. The woman is holding a glass of orange juice in her right hand, and the refrigerator is positioned to her left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.5, "ram_available_mb": 109165.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [34.87, 32.52, 32.52, 32.52, 32.52, 32.52, 50.96, 50.96, 50.96, 50.96, 50.96, 53.05, 53.05, 53.05, 53.05, 53.05, 34.57], "power_watts_avg": 44.24, "power_watts_peak": 53.05, "energy_joules_est": 74.61, "sample_count": 17, "duration_seconds": 1.687}, "timestamp": "2026-01-12T09:56:58.962472"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1050.079, "latencies_ms": [1050.079], "images_per_second": 0.952, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a black dress is standing in a kitchen holding a glass of champagne.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13340.1, "ram_available_mb": 109166.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.57, 34.57, 34.57, 34.57, 41.8, 41.8, 41.8, 41.8, 41.8, 51.32, 51.32], "power_watts_avg": 40.9, "power_watts_peak": 51.32, "energy_joules_est": 42.97, "sample_count": 11, "duration_seconds": 1.05}, "timestamp": "2026-01-12T09:57:00.080241"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1230.838, "latencies_ms": [1230.838], "images_per_second": 0.812, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The woman is wearing a black dress with sparkles and black shoes. The kitchen has wooden cabinets and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.9, "ram_available_mb": 109175.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [51.32, 51.32, 51.32, 46.3, 46.3, 46.3, 46.3, 46.3, 51.07, 51.07, 51.07, 51.07, 51.07], "power_watts_avg": 49.29, "power_watts_peak": 51.32, "energy_joules_est": 60.69, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-12T09:57:01.392513"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1165.728, "latencies_ms": [1165.728], "images_per_second": 0.858, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a round mirror reflecting a yellow school bus and a car on a road, with a building and a sign in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13336.2, "ram_available_mb": 109170.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.15, 50.15, 50.15, 50.15, 50.15, 45.94, 45.94, 45.94, 45.94, 45.94, 46.42, 46.42], "power_watts_avg": 47.77, "power_watts_peak": 50.15, "energy_joules_est": 55.72, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-12T09:57:02.606583"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1190.279, "latencies_ms": [1190.279], "images_per_second": 0.84, "prompt_tokens": 1113, "response_tokens_est": 29, "n_tiles": 1, "output_text": " mirror: 1\nbus: 1\npole: 1\nsign: 1\nbuilding: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13336.2, "ram_available_mb": 109170.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13340.3, "ram_available_mb": 109166.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.42, 46.42, 38.82, 38.82, 38.82, 38.82, 38.82, 47.28, 47.28, 47.28, 47.28, 47.28], "power_watts_avg": 43.61, "power_watts_peak": 47.28, "energy_joules_est": 51.93, "sample_count": 12, "duration_seconds": 1.191}, "timestamp": "2026-01-12T09:57:03.819460"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1426.623, "latencies_ms": [1426.623], "images_per_second": 0.701, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The mirror is positioned in the foreground, reflecting the yellow school bus in the background. The bus is located to the left of the mirror, while the traffic light is situated to the right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13334.0, "ram_available_mb": 109172.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [45.24, 45.24, 45.24, 45.24, 45.24, 47.74, 47.74, 47.74, 47.74, 47.74, 47.79, 47.79, 47.79, 47.79, 47.79], "power_watts_avg": 46.92, "power_watts_peak": 47.79, "energy_joules_est": 66.97, "sample_count": 15, "duration_seconds": 1.427}, "timestamp": "2026-01-12T09:57:05.333679"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1777.486, "latencies_ms": [1777.486], "images_per_second": 0.563, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a scene of a yellow school bus parked on the side of a road, with its reflection visible in a convex mirror. The background features a storefront with a sign that reads \"Harley-Davidson\" and a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.0, "ram_available_mb": 109176.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13330.8, "ram_available_mb": 109175.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.94, 33.94, 33.94, 33.94, 33.94, 46.51, 46.51, 46.51, 46.51, 46.51, 47.5, 47.5, 47.5, 47.5, 47.5, 34.9, 34.9, 34.9], "power_watts_avg": 41.36, "power_watts_peak": 47.5, "energy_joules_est": 73.53, "sample_count": 18, "duration_seconds": 1.778}, "timestamp": "2026-01-12T09:57:07.148142"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1210.88, "latencies_ms": [1210.88], "images_per_second": 0.826, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image features a round mirror with a yellow school bus reflected in it, set against a backdrop of a cloudy sky and a building with a sign.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13346.9, "ram_available_mb": 109159.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 35.39, 35.39, 35.39, 35.39, 35.39, 47.38, 47.38, 47.38, 47.38, 47.38, 47.24], "power_watts_avg": 40.84, "power_watts_peak": 47.38, "energy_joules_est": 49.46, "sample_count": 13, "duration_seconds": 1.211}, "timestamp": "2026-01-12T09:57:08.458695"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 933.021, "latencies_ms": [933.021], "images_per_second": 1.072, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A gray cat is sitting on a table next to a window, looking at a dog outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.9, "ram_available_mb": 109159.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13372.4, "ram_available_mb": 109133.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.24, 47.24, 47.24, 47.24, 42.38, 42.38, 42.38, 42.38, 42.38, 46.26], "power_watts_avg": 44.71, "power_watts_peak": 47.24, "energy_joules_est": 41.73, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T09:57:09.471405"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1117.958, "latencies_ms": [1117.958], "images_per_second": 0.894, "prompt_tokens": 1113, "response_tokens_est": 26, "n_tiles": 1, "output_text": " cat: 1, dog: 1, potted plant: 2, window: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13372.4, "ram_available_mb": 109133.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13396.6, "ram_available_mb": 109109.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 46.26, 46.26, 47.02, 47.02, 47.02, 47.02, 47.02, 46.55, 46.55, 46.55], "power_watts_avg": 46.65, "power_watts_peak": 47.02, "energy_joules_est": 52.17, "sample_count": 12, "duration_seconds": 1.118}, "timestamp": "2026-01-12T09:57:10.679644"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1412.713, "latencies_ms": [1412.713], "images_per_second": 0.708, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at the dog, which is in the background. The dog is standing on the grass outside, while the cat is sitting on the windowsill.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.7, "ram_available_mb": 109117.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13381.2, "ram_available_mb": 109125.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.55, 46.55, 38.17, 38.17, 38.17, 38.17, 38.17, 46.34, 46.34, 46.34, 46.34, 46.34, 48.37, 48.37, 48.37], "power_watts_avg": 44.05, "power_watts_peak": 48.37, "energy_joules_est": 62.26, "sample_count": 15, "duration_seconds": 1.413}, "timestamp": "2026-01-12T09:57:12.195518"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 981.705, "latencies_ms": [981.705], "images_per_second": 1.019, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A gray cat is sitting on a table next to a window, looking out at a dog standing outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13385.5, "ram_available_mb": 109120.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [48.37, 48.37, 32.18, 32.18, 32.18, 32.18, 32.18, 46.16, 46.16, 46.16], "power_watts_avg": 39.61, "power_watts_peak": 48.37, "energy_joules_est": 38.91, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T09:57:13.208046"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1913.685, "latencies_ms": [1913.685], "images_per_second": 0.523, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a gray cat and a brown dog, with the cat sitting on a wooden table and the dog standing outside the window. The lighting is natural, coming from the outside, and the colors are vibrant, with the green plants adding a touch of color to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.5, "ram_available_mb": 109120.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13366.6, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.16, 46.16, 47.83, 47.83, 47.83, 47.83, 47.43, 47.43, 47.43, 47.43, 47.43, 49.36, 49.36, 49.36, 49.36, 49.36, 34.73, 34.73, 34.73, 34.73], "power_watts_avg": 45.33, "power_watts_peak": 49.36, "energy_joules_est": 86.77, "sample_count": 20, "duration_seconds": 1.914}, "timestamp": "2026-01-12T09:57:15.226094"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1457.017, "latencies_ms": [1457.017], "images_per_second": 0.686, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A female soccer player in a blue jersey with the word \"Acronis\" on it is dribbling a soccer ball while another player in a yellow jersey is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.9, "ram_available_mb": 109147.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13376.3, "ram_available_mb": 109130.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.73, 31.32, 31.32, 31.32, 31.32, 31.32, 44.99, 44.99, 44.99, 44.99, 44.99, 48.66, 48.66, 48.66, 48.66], "power_watts_avg": 40.73, "power_watts_peak": 48.66, "energy_joules_est": 59.38, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-12T09:57:16.793803"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2068.516, "latencies_ms": [2068.516], "images_per_second": 0.483, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. person: 1\n2. jersey: 1\n3. ball: 1\n4. headband: 1\n5. shorts: 1\n6. socks: 1\n7. jersey logo: 1\n8. jersey number: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13376.3, "ram_available_mb": 109130.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.66, 33.54, 33.54, 33.54, 33.54, 33.54, 46.97, 46.97, 46.97, 46.97, 46.97, 48.49, 48.49, 48.49, 48.49, 48.49, 34.79, 34.79, 34.79, 34.79, 34.79], "power_watts_avg": 41.31, "power_watts_peak": 48.66, "energy_joules_est": 85.48, "sample_count": 21, "duration_seconds": 2.069}, "timestamp": "2026-01-12T09:57:18.911788"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1800.567, "latencies_ms": [1800.567], "images_per_second": 0.555, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main object is a woman wearing a blue jersey, positioned in the foreground of the image. The woman is holding a blue and white ball, which is in the foreground as well. In the background, there is another woman wearing a yellow jersey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 34.62, 42.48, 42.48, 42.48, 42.48, 42.48, 46.43, 46.43, 46.43, 46.43, 46.43, 38.39, 38.39, 38.39, 38.39], "power_watts_avg": 40.92, "power_watts_peak": 46.43, "energy_joules_est": 73.71, "sample_count": 18, "duration_seconds": 1.801}, "timestamp": "2026-01-12T09:57:20.778293"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1325.842, "latencies_ms": [1325.842], "images_per_second": 0.754, "prompt_tokens": 1111, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A female soccer player in a blue jersey is dribbling a ball on a field. In the background, another female player in a yellow jersey is visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [38.39, 33.96, 33.96, 33.96, 33.96, 33.96, 47.75, 47.75, 47.75, 47.75, 47.75, 48.66, 48.66, 48.66], "power_watts_avg": 42.35, "power_watts_peak": 48.66, "energy_joules_est": 56.18, "sample_count": 14, "duration_seconds": 1.326}, "timestamp": "2026-01-12T09:57:22.190921"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2193.427, "latencies_ms": [2193.427], "images_per_second": 0.456, "prompt_tokens": 1109, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a grassy field, where a female athlete in a vibrant blue jersey is in the midst of a powerful kick, her body language suggesting a sense of urgency and athleticism. The lighting is natural and bright, casting a warm glow on the scene and highlighting the texture of the grass beneath her feet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.6, "ram_available_mb": 109179.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.66, 48.66, 32.7, 32.7, 32.7, 32.7, 32.7, 46.56, 46.56, 46.56, 46.56, 46.56, 48.52, 48.52, 48.52, 48.52, 48.52, 34.73, 34.73, 34.73, 34.73, 34.73], "power_watts_avg": 41.36, "power_watts_peak": 48.66, "energy_joules_est": 90.72, "sample_count": 22, "duration_seconds": 2.194}, "timestamp": "2026-01-12T09:57:24.408119"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 979.392, "latencies_ms": [979.392], "images_per_second": 1.021, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two giraffes are standing in a fenced-in area, one eating grass and the other looking around.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13326.6, "ram_available_mb": 109179.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13330.0, "ram_available_mb": 109176.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 34.92, 43.35, 43.35, 43.35, 43.35, 43.35, 46.6], "power_watts_avg": 40.3, "power_watts_peak": 46.6, "energy_joules_est": 39.5, "sample_count": 10, "duration_seconds": 0.98}, "timestamp": "2026-01-12T09:57:25.468943"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2014.564, "latencies_ms": [2014.564], "images_per_second": 0.496, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. giraffe: 2\n2. fence: 1\n3. tree: 1\n4. grass: 1\n5. dirt: 1\n6. dirt patch: 1\n7. fence post: 1\n8. giraffe's tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.1, "ram_available_mb": 109180.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13318.6, "ram_available_mb": 109187.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.6, 46.6, 46.6, 46.6, 47.08, 47.08, 47.08, 47.08, 47.08, 47.67, 47.67, 47.67, 47.67, 47.67, 39.69, 39.69, 39.69, 39.69, 39.69, 34.73, 34.73], "power_watts_avg": 44.19, "power_watts_peak": 47.67, "energy_joules_est": 89.05, "sample_count": 21, "duration_seconds": 2.015}, "timestamp": "2026-01-12T09:57:27.586834"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2175.937, "latencies_ms": [2175.937], "images_per_second": 0.46, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The giraffe on the left is positioned closer to the camera than the one on the right, which is farther away. The giraffe on the right is standing in the background, while the one on the left is in the foreground. The giraffe on the left is eating grass, while the one on the right is standing and looking around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.8, "ram_available_mb": 109195.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13317.5, "ram_available_mb": 109188.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 33.79, 33.79, 33.79, 33.79, 33.79, 45.23, 45.23, 45.23, 45.23, 45.23, 46.08, 46.08, 46.08, 46.08, 46.08, 34.74, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 39.49, "power_watts_peak": 46.08, "energy_joules_est": 85.95, "sample_count": 22, "duration_seconds": 2.177}, "timestamp": "2026-01-12T09:57:29.855770"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 931.548, "latencies_ms": [931.548], "images_per_second": 1.073, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two giraffes are in a fenced-in area, one eating grass and the other standing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.6, "ram_available_mb": 109196.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 34.71, 34.71, 34.71, 44.91, 44.91, 44.91, 44.91, 44.91], "power_watts_avg": 39.81, "power_watts_peak": 44.91, "energy_joules_est": 37.13, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T09:57:30.918727"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1085.107, "latencies_ms": [1085.107], "images_per_second": 0.922, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The giraffes are brown and white, and the grass is green. The giraffes are standing in a fenced-in area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.1, "ram_available_mb": 109168.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13335.4, "ram_available_mb": 109170.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.38, 46.38, 46.38, 46.38, 47.0, 47.0, 47.0, 47.0, 47.0, 46.7, 46.7], "power_watts_avg": 46.72, "power_watts_peak": 47.0, "energy_joules_est": 50.73, "sample_count": 11, "duration_seconds": 1.086}, "timestamp": "2026-01-12T09:57:32.030959"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1179.777, "latencies_ms": [1179.777], "images_per_second": 0.848, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A suitcase, a plastic bag, and a black bag are placed on the floor in front of a curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.5, "ram_available_mb": 109178.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13259.1, "ram_available_mb": 109247.2, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [46.7, 46.7, 46.7, 41.47, 41.47, 41.47, 41.47, 41.47, 51.24, 51.24, 51.24, 51.24], "power_watts_avg": 46.04, "power_watts_peak": 51.24, "energy_joules_est": 54.35, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-12T09:57:33.246942"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 685.009, "latencies_ms": [685.009], "images_per_second": 1.46, "prompt_tokens": 1446, "response_tokens_est": 5, "n_tiles": 1, "output_text": " suitcase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13259.1, "ram_available_mb": 109247.2, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13353.4, "ram_available_mb": 109152.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [51.24, 45.88, 45.88, 45.88, 45.88, 45.88, 51.74], "power_watts_avg": 47.48, "power_watts_peak": 51.74, "energy_joules_est": 32.55, "sample_count": 7, "duration_seconds": 0.686}, "timestamp": "2026-01-12T09:57:33.959028"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1854.958, "latencies_ms": [1854.958], "images_per_second": 0.539, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The suitcase is on the left, the plastic bag is in the middle, and the backpack is on the right. The suitcase is in the foreground, the plastic bag is in the middle, and the backpack is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.5, "ram_available_mb": 109156.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.7, "ram_available_mb": 109164.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.74, 51.74, 51.74, 51.74, 60.32, 60.32, 60.32, 60.32, 60.32, 51.9, 51.9, 51.9, 51.9, 51.9, 44.84, 44.84, 44.84, 44.84, 44.84], "power_watts_avg": 52.22, "power_watts_peak": 60.32, "energy_joules_est": 96.9, "sample_count": 19, "duration_seconds": 1.855}, "timestamp": "2026-01-12T09:57:35.877316"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1138.68, "latencies_ms": [1138.68], "images_per_second": 0.878, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A suitcase, a plastic bag, and a backpack are on the floor in front of a curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.8, "ram_available_mb": 109172.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.6, "ram_available_mb": 109143.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.78, 34.78, 34.78, 34.78, 42.2, 42.2, 42.2, 42.2, 42.2, 49.75, 49.75, 49.75], "power_watts_avg": 41.62, "power_watts_peak": 49.75, "energy_joules_est": 47.4, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-12T09:57:37.137309"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1178.035, "latencies_ms": [1178.035], "images_per_second": 0.849, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is in black and white, and the lighting is dim. The materials of the objects are not clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.9, "ram_available_mb": 109147.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.75, 49.75, 42.2, 42.2, 42.2, 42.2, 42.2, 50.76, 50.76, 50.76, 50.76, 50.76], "power_watts_avg": 47.02, "power_watts_peak": 50.76, "energy_joules_est": 55.41, "sample_count": 12, "duration_seconds": 1.178}, "timestamp": "2026-01-12T09:57:38.348601"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1140.475, "latencies_ms": [1140.475], "images_per_second": 0.877, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a blue shirt and a red bandana is standing on a rocky trail in the woods, observing two people riding horses.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13355.0, "ram_available_mb": 109151.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [51.97, 51.97, 51.97, 51.97, 51.97, 47.7, 47.7, 47.7, 47.7, 47.7, 47.33, 47.33], "power_watts_avg": 49.42, "power_watts_peak": 51.97, "energy_joules_est": 56.39, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-12T09:57:39.563743"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1889.277, "latencies_ms": [1889.277], "images_per_second": 0.529, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. horse: 2\n3. saddle: 1\n4. backpack: 1\n5. rock: 1\n6. tree: 1\n7. man: 1\n8. hat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13327.7, "ram_available_mb": 109178.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.33, 47.33, 47.33, 38.1, 38.1, 38.1, 38.1, 38.1, 46.93, 46.93, 46.93, 46.93, 46.93, 44.43, 44.43, 44.43, 44.43, 44.43, 35.16], "power_watts_avg": 43.39, "power_watts_peak": 47.33, "energy_joules_est": 82.01, "sample_count": 19, "duration_seconds": 1.89}, "timestamp": "2026-01-12T09:57:41.478632"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1927.984, "latencies_ms": [1927.984], "images_per_second": 0.519, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The man in the blue shirt is standing to the right of the man on the horse, and the man on the horse is in the foreground of the image. The man in the blue shirt is also in the foreground, but closer to the camera than the man on the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.7, "ram_available_mb": 109178.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.5, "ram_available_mb": 109147.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.16, 35.16, 35.16, 39.73, 39.73, 39.73, 39.73, 39.73, 46.7, 46.7, 46.7, 46.7, 46.7, 41.77, 41.77, 41.77, 41.77, 41.77, 34.62, 34.62], "power_watts_avg": 40.78, "power_watts_peak": 46.7, "energy_joules_est": 78.67, "sample_count": 20, "duration_seconds": 1.929}, "timestamp": "2026-01-12T09:57:43.545116"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 986.287, "latencies_ms": [986.287], "images_per_second": 1.014, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a blue shirt and a man in a red bandana are riding horses through a forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13366.2, "ram_available_mb": 109140.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 35.7, 35.7, 35.7, 35.7, 35.7, 45.29, 45.29], "power_watts_avg": 37.29, "power_watts_peak": 45.29, "energy_joules_est": 36.82, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-12T09:57:44.607568"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1970.376, "latencies_ms": [1970.376], "images_per_second": 0.508, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a man wearing a blue shirt and a red bandana, standing on a rocky trail surrounded by trees. The lighting is natural, and the colors are vibrant, with the blue of the man's shirt standing out against the green of the trees and the brown of the rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13353.6, "ram_available_mb": 109152.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.29, 45.29, 45.29, 48.08, 48.08, 48.08, 48.08, 48.08, 47.59, 47.59, 47.59, 47.59, 47.59, 44.85, 44.85, 44.85, 44.85, 34.61, 34.61, 34.61], "power_watts_avg": 44.87, "power_watts_peak": 48.08, "energy_joules_est": 88.44, "sample_count": 20, "duration_seconds": 1.971}, "timestamp": "2026-01-12T09:57:46.625602"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1091.608, "latencies_ms": [1091.608], "images_per_second": 0.916, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing a sweater with the word \"Russia\" on it is riding a horse in a black and white photo.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.7, "ram_available_mb": 109156.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13368.0, "ram_available_mb": 109138.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.61, 34.61, 32.72, 32.72, 32.72, 32.72, 32.72, 45.88, 45.88, 45.88, 45.88], "power_watts_avg": 37.85, "power_watts_peak": 45.88, "energy_joules_est": 41.36, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-12T09:57:47.790514"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2090.368, "latencies_ms": [2090.368], "images_per_second": 0.478, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. man: 1\n2. horse: 1\n3. saddle: 1\n4. bridle: 1\n5. reins: 1\n6. man's hand: 1\n7. man's leg: 1\n8. man's foot: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13273.7, "ram_available_mb": 109232.6, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.88, 48.2, 48.2, 48.2, 48.2, 48.2, 47.9, 47.9, 47.9, 47.9, 47.9, 48.47, 48.47, 48.47, 48.47, 48.47, 34.91, 34.91, 34.91, 34.91, 34.91], "power_watts_avg": 44.92, "power_watts_peak": 48.47, "energy_joules_est": 93.92, "sample_count": 21, "duration_seconds": 2.091}, "timestamp": "2026-01-12T09:57:49.910304"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1772.789, "latencies_ms": [1772.789], "images_per_second": 0.564, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The man is positioned in the foreground, riding a horse that is in motion, while the background features a blurred building. The man is holding the reins of the horse, which is moving forward, and the horse is positioned in the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13273.7, "ram_available_mb": 109232.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13312.6, "ram_available_mb": 109193.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 43.19, 43.19, 43.19, 43.19, 43.19, 46.51, 46.51, 46.51, 46.51, 46.51, 39.11, 39.11, 39.11, 39.11], "power_watts_avg": 41.36, "power_watts_peak": 46.51, "energy_joules_est": 73.35, "sample_count": 18, "duration_seconds": 1.774}, "timestamp": "2026-01-12T09:57:51.778872"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1038.912, "latencies_ms": [1038.912], "images_per_second": 0.963, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is riding a horse in a race, wearing a sweater with the word \"Russia\" on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13308.7, "ram_available_mb": 109197.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13303.0, "ram_available_mb": 109203.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [39.11, 33.5, 33.5, 33.5, 33.5, 33.5, 47.45, 47.45, 47.45, 47.45, 47.45], "power_watts_avg": 40.35, "power_watts_peak": 47.45, "energy_joules_est": 41.94, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-12T09:57:52.891669"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1601.644, "latencies_ms": [1601.644], "images_per_second": 0.624, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image is in black and white, with a blurred background that suggests motion. The lighting is natural, likely from the sun, and the material of the horse and rider is not clearly visible due to the motion blur.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.0, "ram_available_mb": 109203.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13376.9, "ram_available_mb": 109129.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.61, 48.61, 48.61, 48.61, 48.61, 45.65, 45.65, 45.65, 45.65, 45.65, 46.76, 46.76, 46.76, 46.76, 46.76, 36.41], "power_watts_avg": 46.34, "power_watts_peak": 48.61, "energy_joules_est": 74.25, "sample_count": 16, "duration_seconds": 1.602}, "timestamp": "2026-01-12T09:57:54.508685"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 844.153, "latencies_ms": [844.153], "images_per_second": 1.185, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of geese are swimming in a pond surrounded by tall grass and trees.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13376.9, "ram_available_mb": 109129.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13376.6, "ram_available_mb": 109129.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [36.41, 36.41, 36.41, 36.41, 42.14, 42.14, 42.14, 42.14, 42.14], "power_watts_avg": 39.59, "power_watts_peak": 42.14, "energy_joules_est": 33.44, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-12T09:57:55.422879"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 529.672, "latencies_ms": [529.672], "images_per_second": 1.888, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " goose: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.7, "ram_available_mb": 109133.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13365.2, "ram_available_mb": 109141.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.0, 48.0, 48.0, 48.0, 50.73, 50.73], "power_watts_avg": 48.91, "power_watts_peak": 50.73, "energy_joules_est": 25.93, "sample_count": 6, "duration_seconds": 0.53}, "timestamp": "2026-01-12T09:57:56.032936"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1657.408, "latencies_ms": [1657.408], "images_per_second": 0.603, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The geese are positioned in the middle of the pond, with the vegetation on the left side of the image and the trees on the right side. The geese are relatively close to the camera, while the vegetation and trees are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.3, "ram_available_mb": 109149.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13362.1, "ram_available_mb": 109144.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [50.73, 50.73, 50.73, 52.07, 52.07, 52.07, 52.07, 52.07, 49.53, 49.53, 49.53, 49.53, 49.53, 41.69, 41.69, 41.69, 41.69], "power_watts_avg": 48.64, "power_watts_peak": 52.07, "energy_joules_est": 80.64, "sample_count": 17, "duration_seconds": 1.658}, "timestamp": "2026-01-12T09:57:57.748619"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 843.948, "latencies_ms": [843.948], "images_per_second": 1.185, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of geese are swimming in a lake surrounded by tall grass and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.3, "ram_available_mb": 109152.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.3, "ram_available_mb": 109153.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.69, 32.83, 32.83, 32.83, 32.83, 32.83, 47.11, 47.11, 47.11], "power_watts_avg": 38.57, "power_watts_peak": 47.11, "energy_joules_est": 32.57, "sample_count": 9, "duration_seconds": 0.844}, "timestamp": "2026-01-12T09:57:58.658177"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2380.504, "latencies_ms": [2380.504], "images_per_second": 0.42, "prompt_tokens": 1109, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image features a serene scene of a group of geese swimming in a body of water, with the geese displaying a variety of colors including shades of brown, white, and black. The lighting in the image is natural and bright, suggesting that the photo was taken during the daytime. The water appears calm and reflective, with the geese creating ripples as they move through it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13324.7, "ram_available_mb": 109181.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.11, 47.11, 49.31, 49.31, 49.31, 49.31, 49.31, 46.83, 46.83, 46.83, 46.83, 46.83, 47.18, 47.18, 47.18, 47.18, 47.18, 34.88, 34.88, 34.88, 34.88, 34.88, 34.81, 34.81], "power_watts_avg": 43.95, "power_watts_peak": 49.31, "energy_joules_est": 104.65, "sample_count": 24, "duration_seconds": 2.381}, "timestamp": "2026-01-12T09:58:01.079163"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1168.639, "latencies_ms": [1168.639], "images_per_second": 0.856, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A cat is sitting on the hood of a black Mercedes-Benz car, with its reflection visible in the car's shiny surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.8, "ram_available_mb": 109189.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.96, 34.96, 34.96, 34.96, 34.96, 46.16, 46.16, 46.16, 46.16, 46.16], "power_watts_avg": 39.6, "power_watts_peak": 46.16, "energy_joules_est": 46.33, "sample_count": 12, "duration_seconds": 1.17}, "timestamp": "2026-01-12T09:58:02.350059"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1912.086, "latencies_ms": [1912.086], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. house: 1\n4. window: 1\n5. door: 1\n6. fence: 1\n7. plant: 1\n8. flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.4, "ram_available_mb": 109179.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.14, 46.14, 46.14, 46.14, 46.14, 47.23, 47.23, 47.23, 47.23, 47.23, 47.77, 47.77, 47.77, 47.77, 47.77, 34.54, 34.54, 34.54, 34.54], "power_watts_avg": 44.41, "power_watts_peak": 47.77, "energy_joules_est": 84.95, "sample_count": 19, "duration_seconds": 1.913}, "timestamp": "2026-01-12T09:58:04.267879"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2045.187, "latencies_ms": [2045.187], "images_per_second": 0.489, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The cat is sitting on the hood of the car, which is in the foreground of the image. The car is parked in front of a house, which is in the background of the image. The cat is positioned to the left of the car, and the house is to the right of the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.4, "ram_available_mb": 109179.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13323.7, "ram_available_mb": 109182.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.54, 33.46, 33.46, 33.46, 33.46, 46.9, 46.9, 46.9, 46.9, 46.9, 48.26, 48.26, 48.26, 48.26, 48.26, 34.63, 34.63, 34.63, 34.63, 34.63, 34.62], "power_watts_avg": 40.57, "power_watts_peak": 48.26, "energy_joules_est": 82.99, "sample_count": 21, "duration_seconds": 2.046}, "timestamp": "2026-01-12T09:58:06.436954"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 936.209, "latencies_ms": [936.209], "images_per_second": 1.068, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A cat is sitting on top of a car, which is parked in front of a house.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.7, "ram_available_mb": 109182.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13332.4, "ram_available_mb": 109173.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 34.62, 41.78, 41.78, 41.78, 41.78, 41.78, 45.51], "power_watts_avg": 39.29, "power_watts_peak": 45.51, "energy_joules_est": 36.82, "sample_count": 10, "duration_seconds": 0.937}, "timestamp": "2026-01-12T09:58:07.498889"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1292.777, "latencies_ms": [1292.777], "images_per_second": 0.774, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The car is black and the cat is orange and white. The car is parked in front of a house and the cat is sitting on the hood of the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.3, "ram_available_mb": 109174.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.9, "ram_used_mb": 13331.9, "ram_available_mb": 109174.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.51, 45.51, 45.51, 45.51, 46.75, 46.75, 46.75, 46.75, 46.75, 46.92, 46.92, 46.92, 46.92], "power_watts_avg": 46.42, "power_watts_peak": 46.92, "energy_joules_est": 60.03, "sample_count": 13, "duration_seconds": 1.293}, "timestamp": "2026-01-12T09:58:08.810722"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1200.295, "latencies_ms": [1200.295], "images_per_second": 0.833, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man is snowboarding in the air with his arms outstretched, wearing a brown jacket and yellow pants, against a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.8, "ram_available_mb": 109174.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13235.9, "ram_available_mb": 109270.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.92, 38.86, 38.86, 38.86, 38.86, 38.86, 47.59, 47.59, 47.59, 47.59, 47.59, 48.32], "power_watts_avg": 43.96, "power_watts_peak": 48.32, "energy_joules_est": 52.78, "sample_count": 12, "duration_seconds": 1.201}, "timestamp": "2026-01-12T09:58:10.023501"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1940.678, "latencies_ms": [1940.678], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " snowboard: 1, snowboarder: 1, snowboarder's pants: 1, snowboarder's jacket: 1, snowboarder's hat: 1, snowboarder's gloves: 1, snowboarder's boots: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13235.9, "ram_available_mb": 109270.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13296.1, "ram_available_mb": 109210.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.32, 48.32, 48.32, 42.15, 42.15, 42.15, 42.15, 42.15, 47.71, 47.71, 47.71, 47.71, 47.71, 41.26, 41.26, 41.26, 41.26, 41.26, 34.68, 34.68], "power_watts_avg": 43.5, "power_watts_peak": 48.32, "energy_joules_est": 84.44, "sample_count": 20, "duration_seconds": 1.941}, "timestamp": "2026-01-12T09:58:12.039287"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1380.055, "latencies_ms": [1380.055], "images_per_second": 0.725, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The snowboarder is in the foreground, jumping over a snow-covered slope. The snowboarder is in the middle of the image, with the sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.2, "ram_available_mb": 109214.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13295.1, "ram_available_mb": 109211.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 36.98, 36.98, 36.98, 36.98, 36.98, 45.6, 45.6, 45.6, 45.6, 45.6, 43.52], "power_watts_avg": 40.03, "power_watts_peak": 45.6, "energy_joules_est": 55.27, "sample_count": 14, "duration_seconds": 1.381}, "timestamp": "2026-01-12T09:58:13.504646"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 881.993, "latencies_ms": [881.993], "images_per_second": 1.134, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air against a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13291.2, "ram_available_mb": 109215.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13287.6, "ram_available_mb": 109218.7, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.52, 43.52, 43.52, 43.52, 42.62, 42.62, 42.62, 42.62, 42.62], "power_watts_avg": 43.02, "power_watts_peak": 43.52, "energy_joules_est": 37.97, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T09:58:14.416044"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 984.069, "latencies_ms": [984.069], "images_per_second": 1.016, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The snowboarder is wearing a brown jacket and yellow pants, and the sky is a clear blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13287.6, "ram_available_mb": 109218.7, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13303.4, "ram_available_mb": 109202.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.51, 47.51, 47.51, 47.51, 47.51, 52.14, 52.14, 52.14, 52.14, 52.14], "power_watts_avg": 49.82, "power_watts_peak": 52.14, "energy_joules_est": 49.04, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-12T09:58:15.428862"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 903.103, "latencies_ms": [903.103], "images_per_second": 1.107, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A small bathroom with a toilet, a bathtub, and a pipe hanging from the ceiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13299.5, "ram_available_mb": 109206.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13312.3, "ram_available_mb": 109194.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.46, 47.46, 47.46, 47.46, 47.16, 47.16, 47.16, 47.16, 47.16], "power_watts_avg": 47.29, "power_watts_peak": 47.46, "energy_joules_est": 42.73, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-12T09:58:16.343353"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1327.149, "latencies_ms": [1327.149], "images_per_second": 0.753, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " toilet: 1, bathtub: 1, pipe: 1, towel: 1, door: 1, wall: 1, floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13304.5, "ram_available_mb": 109201.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13320.6, "ram_available_mb": 109185.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.71, 47.71, 47.71, 47.71, 47.71, 50.38, 50.38, 50.38, 50.38, 50.38, 47.91, 47.91, 47.91, 47.91], "power_watts_avg": 48.72, "power_watts_peak": 50.38, "energy_joules_est": 64.69, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-12T09:58:17.759665"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1444.944, "latencies_ms": [1444.944], "images_per_second": 0.692, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the bathtub situated in the background. The pipes run vertically from the ceiling to the floor, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13312.7, "ram_available_mb": 109193.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13312.9, "ram_available_mb": 109193.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.91, 32.05, 32.05, 32.05, 32.05, 32.05, 46.4, 46.4, 46.4, 46.4, 46.4, 49.44, 49.44, 49.44, 49.44], "power_watts_avg": 42.53, "power_watts_peak": 49.44, "energy_joules_est": 61.47, "sample_count": 15, "duration_seconds": 1.446}, "timestamp": "2026-01-12T09:58:19.272456"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 898.809, "latencies_ms": [898.809], "images_per_second": 1.113, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small bathroom with a toilet and a bathtub, with pipes running along the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13312.9, "ram_available_mb": 109193.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13310.4, "ram_available_mb": 109195.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [49.44, 32.44, 32.44, 32.44, 32.44, 32.44, 46.43, 46.43, 46.43], "power_watts_avg": 38.99, "power_watts_peak": 49.44, "energy_joules_est": 35.06, "sample_count": 9, "duration_seconds": 0.899}, "timestamp": "2026-01-12T09:58:20.184071"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 719.916, "latencies_ms": [719.916], "images_per_second": 1.389, "prompt_tokens": 1110, "response_tokens_est": 11, "n_tiles": 1, "output_text": " The bathroom is painted white and has a wooden floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13302.6, "ram_available_mb": 109203.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13326.7, "ram_available_mb": 109179.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 49.42, 49.42, 49.42, 49.42, 49.42, 47.88], "power_watts_avg": 48.48, "power_watts_peak": 49.42, "energy_joules_est": 34.93, "sample_count": 8, "duration_seconds": 0.72}, "timestamp": "2026-01-12T09:58:20.995720"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 928.527, "latencies_ms": [928.527], "images_per_second": 1.077, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A statue of two people holding a kite with a colorful pattern is on top of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.7, "ram_available_mb": 109181.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13314.1, "ram_available_mb": 109192.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.88, 47.88, 47.88, 47.88, 55.38, 55.38, 55.38, 55.38, 55.38, 46.48], "power_watts_avg": 51.49, "power_watts_peak": 55.38, "energy_joules_est": 47.84, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-12T09:58:22.009078"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 698.899, "latencies_ms": [698.899], "images_per_second": 1.431, "prompt_tokens": 1114, "response_tokens_est": 10, "n_tiles": 1, "output_text": " kite: 1\nstatue: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.2, "ram_available_mb": 109200.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13330.0, "ram_available_mb": 109176.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.48, 46.48, 46.48, 46.48, 46.22, 46.22, 46.22], "power_watts_avg": 46.37, "power_watts_peak": 46.48, "energy_joules_est": 32.42, "sample_count": 7, "duration_seconds": 0.699}, "timestamp": "2026-01-12T09:58:22.718132"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1761.356, "latencies_ms": [1761.356], "images_per_second": 0.568, "prompt_tokens": 1118, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the statue is in the background, situated on a building. The kite is positioned to the left of the statue, and the statue is located on the right side of the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.0, "ram_available_mb": 109176.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13301.5, "ram_available_mb": 109204.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.22, 46.22, 45.44, 45.44, 45.44, 45.44, 45.44, 52.83, 52.83, 52.83, 52.83, 49.12, 49.12, 49.12, 49.12, 49.12, 34.77, 34.77], "power_watts_avg": 47.01, "power_watts_peak": 52.83, "energy_joules_est": 82.82, "sample_count": 18, "duration_seconds": 1.762}, "timestamp": "2026-01-12T09:58:24.535353"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 937.02, "latencies_ms": [937.02], "images_per_second": 1.067, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A kite with a colorful pattern is flying high in the sky above a statue of two people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13301.5, "ram_available_mb": 109204.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 40.87, 40.87, 40.87, 40.87, 40.87, 47.07, 47.07], "power_watts_avg": 40.28, "power_watts_peak": 47.07, "energy_joules_est": 37.76, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-12T09:58:25.547522"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1356.392, "latencies_ms": [1356.392], "images_per_second": 0.737, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The kite is colorful and has a long tail, while the statue is made of metal and has a shiny surface. The sky is cloudy and the building is made of glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.0, "ram_available_mb": 109193.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13315.9, "ram_available_mb": 109190.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.07, 47.07, 47.07, 46.77, 46.77, 46.77, 46.77, 46.77, 46.82, 46.82, 46.82, 46.82, 46.82, 41.63], "power_watts_avg": 46.48, "power_watts_peak": 47.07, "energy_joules_est": 63.08, "sample_count": 14, "duration_seconds": 1.357}, "timestamp": "2026-01-12T09:58:26.962955"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1228.087, "latencies_ms": [1228.087], "images_per_second": 0.814, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image displays a variety of fresh vegetables, including strawberries, broccoli, radishes, carrots, and green beans, arranged in a visually appealing manner.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13308.0, "ram_available_mb": 109198.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13320.4, "ram_available_mb": 109185.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [41.63, 41.63, 41.63, 41.63, 43.42, 43.42, 43.42, 43.42, 43.42, 46.85, 46.85, 46.85, 46.85], "power_watts_avg": 43.92, "power_watts_peak": 46.85, "energy_joules_est": 53.97, "sample_count": 13, "duration_seconds": 1.229}, "timestamp": "2026-01-12T09:58:28.278385"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1412.633, "latencies_ms": [1412.633], "images_per_second": 0.708, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " strawberries: 10, broccoli: 1, radishes: 1, carrots: 1, green beans: 1, asparagus: 1, parsley: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.5, "ram_available_mb": 109189.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13316.7, "ram_available_mb": 109189.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.85, 35.82, 35.82, 35.82, 35.82, 35.82, 46.6, 46.6, 46.6, 46.6, 46.6, 48.99, 48.99, 48.99, 48.99], "power_watts_avg": 43.66, "power_watts_peak": 48.99, "energy_joules_est": 61.7, "sample_count": 15, "duration_seconds": 1.413}, "timestamp": "2026-01-12T09:58:29.793532"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1548.456, "latencies_ms": [1548.456], "images_per_second": 0.646, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The strawberries are located in the left foreground, while the broccoli is situated in the upper left background. The radishes are positioned in the upper right background, and the carrots are located in the lower right foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.7, "ram_available_mb": 109189.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13333.9, "ram_available_mb": 109172.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.99, 32.29, 32.29, 32.29, 32.29, 32.29, 46.14, 46.14, 46.14, 46.14, 46.14, 48.74, 48.74, 48.74, 48.74, 48.74], "power_watts_avg": 42.8, "power_watts_peak": 48.99, "energy_joules_est": 66.29, "sample_count": 16, "duration_seconds": 1.549}, "timestamp": "2026-01-12T09:58:31.405406"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1948.292, "latencies_ms": [1948.292], "images_per_second": 0.513, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce, including strawberries, broccoli, radishes, carrots, and green beans, arranged in a rustic wooden crate. The setting appears to be a market or a farm stand, where the produce is being sold or displayed for customers to purchase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.9, "ram_available_mb": 109172.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13371.6, "ram_available_mb": 109134.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 34.68, 34.68, 46.05, 46.05, 46.05, 46.05, 46.05, 46.63, 46.63, 46.63, 46.63, 46.63, 35.53, 35.53, 35.53, 35.53, 35.53], "power_watts_avg": 40.72, "power_watts_peak": 46.63, "energy_joules_est": 79.35, "sample_count": 20, "duration_seconds": 1.949}, "timestamp": "2026-01-12T09:58:33.420202"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2022.75, "latencies_ms": [2022.75], "images_per_second": 0.494, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a variety of fresh vegetables, including strawberries, broccoli, radishes, carrots, and potatoes, all displayed in a rustic wooden crate. The lighting is natural and bright, highlighting the vibrant colors of the produce. The vegetables are arranged in a way that showcases their freshness and abundance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.6, "ram_available_mb": 109134.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.75, 34.75, 34.75, 34.75, 42.29, 42.29, 42.29, 42.29, 42.29, 45.69, 45.69, 45.69, 45.69, 45.69, 38.23, 38.23, 38.23, 38.23, 38.23, 34.69, 34.69], "power_watts_avg": 39.97, "power_watts_peak": 45.69, "energy_joules_est": 80.88, "sample_count": 21, "duration_seconds": 2.024}, "timestamp": "2026-01-12T09:58:35.592241"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 940.179, "latencies_ms": [940.179], "images_per_second": 1.064, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " In the image, there are three people sitting on a couch, playing a video game together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13385.0, "ram_available_mb": 109121.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.69, 34.69, 33.88, 33.88, 33.88, 33.88, 33.88, 44.89, 44.89, 44.89], "power_watts_avg": 37.35, "power_watts_peak": 44.89, "energy_joules_est": 35.16, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-12T09:58:36.656196"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 805.567, "latencies_ms": [805.567], "images_per_second": 1.241, "prompt_tokens": 1113, "response_tokens_est": 14, "n_tiles": 1, "output_text": " projector: 1, couch: 1, person: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.0, "ram_available_mb": 109121.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13439.0, "ram_available_mb": 109067.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.89, 44.89, 46.32, 46.32, 46.32, 46.32, 46.32, 46.7, 46.7], "power_watts_avg": 46.09, "power_watts_peak": 46.7, "energy_joules_est": 37.14, "sample_count": 9, "duration_seconds": 0.806}, "timestamp": "2026-01-12T09:58:37.566177"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2376.082, "latencies_ms": [2376.082], "images_per_second": 0.421, "prompt_tokens": 1117, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the person on the left being closest to the camera, the person in the middle being slightly farther away, and the person on the right being the farthest from the camera. The projector is located above the couch, and the person on the right is holding a game controller, which is positioned in the middle of the couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.2, "ram_available_mb": 109075.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13410.4, "ram_available_mb": 109095.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.7, 46.7, 46.7, 50.76, 50.76, 50.76, 50.76, 50.76, 45.99, 45.99, 45.99, 45.99, 45.99, 42.37, 42.37, 42.37, 42.37, 42.37, 34.88, 34.88, 34.88, 34.88, 34.88, 34.89], "power_watts_avg": 43.54, "power_watts_peak": 50.76, "energy_joules_est": 103.48, "sample_count": 24, "duration_seconds": 2.377}, "timestamp": "2026-01-12T09:58:39.987638"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 746.408, "latencies_ms": [746.408], "images_per_second": 1.34, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Three men are sitting on a couch playing a video game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13402.5, "ram_available_mb": 109103.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 43.27, 43.27, 43.27, 43.27], "power_watts_avg": 39.08, "power_watts_peak": 43.27, "energy_joules_est": 29.19, "sample_count": 8, "duration_seconds": 0.747}, "timestamp": "2026-01-12T09:58:40.796134"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1274.88, "latencies_ms": [1274.88], "images_per_second": 0.784, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is a black and white photo with a blue and white projector on a black table. The room is dimly lit with a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13385.8, "ram_available_mb": 109120.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.27, 45.49, 45.49, 45.49, 45.49, 45.49, 51.56, 51.56, 51.56, 51.56, 51.56, 48.74, 48.74], "power_watts_avg": 48.15, "power_watts_peak": 51.56, "energy_joules_est": 61.4, "sample_count": 13, "duration_seconds": 1.275}, "timestamp": "2026-01-12T09:58:42.107622"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1309.646, "latencies_ms": [1309.646], "images_per_second": 0.764, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a group of sheep are resting in a lush green field, with a tree providing shade and a distant herd of cows grazing peacefully in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.9, "ram_available_mb": 109128.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13315.2, "ram_available_mb": 109191.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.74, 48.74, 48.74, 37.92, 37.92, 37.92, 37.92, 37.92, 47.46, 47.46, 47.46, 47.46, 47.46, 44.9], "power_watts_avg": 44.15, "power_watts_peak": 48.74, "energy_joules_est": 57.85, "sample_count": 14, "duration_seconds": 1.31}, "timestamp": "2026-01-12T09:58:43.521393"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 539.312, "latencies_ms": [539.312], "images_per_second": 1.854, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13315.2, "ram_available_mb": 109191.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13367.5, "ram_available_mb": 109138.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.9, 44.9, 44.9, 44.9, 40.55, 40.55], "power_watts_avg": 43.45, "power_watts_peak": 44.9, "energy_joules_est": 23.45, "sample_count": 6, "duration_seconds": 0.54}, "timestamp": "2026-01-12T09:58:44.129754"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1533.627, "latencies_ms": [1533.627], "images_per_second": 0.652, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground, with the tree trunk to their right. The cows are located in the background, further away from the camera. The sheep are closer to the tree trunk than the cows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.5, "ram_available_mb": 109138.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.9, "ram_available_mb": 109147.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.55, 40.55, 47.97, 47.97, 47.97, 47.97, 47.97, 53.17, 53.17, 53.17, 53.17, 53.17, 45.86, 45.86, 45.86, 45.86], "power_watts_avg": 48.14, "power_watts_peak": 53.17, "energy_joules_est": 73.84, "sample_count": 16, "duration_seconds": 1.534}, "timestamp": "2026-01-12T09:58:45.744454"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2043.257, "latencies_ms": [2043.257], "images_per_second": 0.489, "prompt_tokens": 1111, "response_tokens_est": 61, "n_tiles": 1, "output_text": " In a serene rural setting, a group of sheep are peacefully grazing in a lush green field. The sheep, varying in shades of white and brown, are scattered across the field, some lying down while others are standing. In the background, a tree stands tall, providing a natural boundary to the field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.9, "ram_available_mb": 109147.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.86, 31.93, 31.93, 31.93, 31.93, 31.93, 46.67, 46.67, 46.67, 46.67, 46.67, 49.66, 49.66, 49.66, 49.66, 49.66, 34.7, 34.7, 34.7, 34.7, 34.7], "power_watts_avg": 40.98, "power_watts_peak": 49.66, "energy_joules_est": 83.75, "sample_count": 21, "duration_seconds": 2.044}, "timestamp": "2026-01-12T09:58:47.859843"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2053.824, "latencies_ms": [2053.824], "images_per_second": 0.487, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a lush green field with a tree trunk in the foreground, and a herd of cows grazing peacefully in the background. The lighting is natural and bright, suggesting it is daytime. The colors are vibrant and the materials appear to be natural, with the grass being green and the tree trunk being brown.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13360.0, "ram_available_mb": 109146.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.22, 34.22, 34.22, 34.22, 34.22, 45.43, 45.43, 45.43, 45.43, 45.43, 46.66, 46.66, 46.66, 46.66, 46.66, 35.33, 35.33, 35.33, 35.33, 35.33, 34.92], "power_watts_avg": 40.15, "power_watts_peak": 46.66, "energy_joules_est": 82.49, "sample_count": 21, "duration_seconds": 2.055}, "timestamp": "2026-01-12T09:58:50.030604"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1194.733, "latencies_ms": [1194.733], "images_per_second": 0.837, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is a black and white photograph of a large group of people, including both boys and men, posing together in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.7, "ram_available_mb": 109122.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 37.74, 37.74, 37.74, 37.74, 37.74, 45.73, 45.73, 45.73, 45.73], "power_watts_avg": 39.7, "power_watts_peak": 45.73, "energy_joules_est": 47.46, "sample_count": 12, "duration_seconds": 1.196}, "timestamp": "2026-01-12T09:58:51.296079"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1459.231, "latencies_ms": [1459.231], "images_per_second": 0.685, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. group of boys\n2. building\n3. windows\n4. brick\n5. brick building\n6. brick wall\n7. brick arch\n8. brick archway", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.8, "ram_available_mb": 109130.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.7, "ram_available_mb": 109129.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.73, 42.06, 42.06, 42.06, 42.06, 42.06, 47.83, 47.83, 47.83, 47.83, 47.83, 48.81, 48.81, 48.81, 48.81], "power_watts_avg": 46.03, "power_watts_peak": 48.81, "energy_joules_est": 67.19, "sample_count": 15, "duration_seconds": 1.46}, "timestamp": "2026-01-12T09:58:52.810615"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1458.961, "latencies_ms": [1458.961], "images_per_second": 0.685, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The group of boys is positioned in the foreground of the image, with the building in the background. The boys are arranged in rows, with some sitting on the ground and others standing behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.7, "ram_available_mb": 109133.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.3, "ram_available_mb": 109141.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.81, 33.58, 33.58, 33.58, 33.58, 33.58, 46.92, 46.92, 46.92, 46.92, 46.92, 48.49, 48.49, 48.49, 48.49], "power_watts_avg": 43.02, "power_watts_peak": 48.81, "energy_joules_est": 62.78, "sample_count": 15, "duration_seconds": 1.46}, "timestamp": "2026-01-12T09:58:54.325727"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1005.146, "latencies_ms": [1005.146], "images_per_second": 0.995, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A large group of people, both boys and men, are posing for a picture in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.4, "ram_available_mb": 109148.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 40.0}, "power_stats": {"power_watts_samples": [48.49, 33.86, 33.86, 33.86, 33.86, 33.86, 47.25, 47.25, 47.25, 47.25], "power_watts_avg": 40.68, "power_watts_peak": 48.49, "energy_joules_est": 40.91, "sample_count": 10, "duration_seconds": 1.006}, "timestamp": "2026-01-12T09:58:55.338522"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1343.132, "latencies_ms": [1343.132], "images_per_second": 0.745, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, and the lighting is even, with no shadows or highlights. The material of the photograph is paper, and the weather is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13282.7, "ram_available_mb": 109223.6, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.23, 48.23, 48.23, 48.23, 48.23, 48.11, 48.11, 48.11, 48.11, 48.11, 47.79, 47.79, 47.79, 47.79], "power_watts_avg": 48.06, "power_watts_peak": 48.23, "energy_joules_est": 64.58, "sample_count": 14, "duration_seconds": 1.344}, "timestamp": "2026-01-12T09:58:56.753013"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1035.445, "latencies_ms": [1035.445], "images_per_second": 0.966, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A colorful kite with a long tail is flying high in the sky, with a building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13282.7, "ram_available_mb": 109223.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.5, "ram_available_mb": 109161.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.79, 31.96, 31.96, 31.96, 31.96, 31.96, 46.33, 46.33, 46.33, 46.33, 46.33], "power_watts_avg": 39.93, "power_watts_peak": 47.79, "energy_joules_est": 41.36, "sample_count": 11, "duration_seconds": 1.036}, "timestamp": "2026-01-12T09:58:57.867452"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2038.209, "latencies_ms": [2038.209], "images_per_second": 0.491, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Kite: 1\n2. Sky: 2\n3. Clouds: 2\n4. Trees: 2\n5. Buildings: 1\n6. People: 1\n7. Kite string: 1\n8. Kite tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.5, "ram_available_mb": 109161.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.9, 48.9, 48.9, 48.9, 48.9, 46.51, 46.51, 46.51, 46.51, 46.51, 47.35, 47.35, 47.35, 47.35, 47.35, 34.8, 34.8, 34.8, 34.8, 34.8, 34.84], "power_watts_avg": 43.93, "power_watts_peak": 48.9, "energy_joules_est": 89.57, "sample_count": 21, "duration_seconds": 2.039}, "timestamp": "2026-01-12T09:58:59.987893"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1481.354, "latencies_ms": [1481.354], "images_per_second": 0.675, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the buildings are in the background. The kite is positioned to the left of the buildings, and the sky is to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.3, "ram_available_mb": 109185.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.0, "ram_available_mb": 109125.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.84, 39.6, 39.6, 39.6, 39.6, 39.6, 45.45, 45.45, 45.45, 45.45, 45.45, 40.83, 40.83], "power_watts_avg": 40.76, "power_watts_peak": 45.45, "energy_joules_est": 60.41, "sample_count": 15, "duration_seconds": 1.482}, "timestamp": "2026-01-12T09:59:01.550339"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 957.483, "latencies_ms": [957.483], "images_per_second": 1.044, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A colorful kite is flying high in the sky over a park with trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13377.0, "ram_available_mb": 109129.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.83, 40.83, 40.83, 40.63, 40.63, 40.63, 40.63, 40.63, 47.65, 47.65], "power_watts_avg": 42.09, "power_watts_peak": 47.65, "energy_joules_est": 40.34, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-12T09:59:02.561054"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1645.153, "latencies_ms": [1645.153], "images_per_second": 0.608, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The kite is a vibrant mix of colors, with a long tail that trails behind it. The sky is a clear blue with fluffy white clouds, and the kite is flying high above a park with trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.65, 47.65, 47.65, 47.72, 47.72, 47.72, 47.72, 47.72, 47.19, 47.19, 47.19, 47.19, 47.19, 42.47, 42.47, 42.47, 42.47], "power_watts_avg": 46.32, "power_watts_peak": 47.72, "energy_joules_est": 76.21, "sample_count": 17, "duration_seconds": 1.645}, "timestamp": "2026-01-12T09:59:04.276590"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 931.106, "latencies_ms": [931.106], "images_per_second": 1.074, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A large pizza with a generous amount of cheese and tomato sauce is placed in a cardboard box.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.5, "ram_available_mb": 109168.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13330.6, "ram_available_mb": 109175.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [42.47, 32.59, 32.59, 32.59, 32.59, 32.59, 46.83, 46.83, 46.83, 46.83], "power_watts_avg": 39.27, "power_watts_peak": 46.83, "energy_joules_est": 36.58, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-12T09:59:05.292423"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1411.51, "latencies_ms": [1411.51], "images_per_second": 0.708, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " pizza: 1, box: 1, pizza box: 1, pizza crust: 1, cheese: 1, sauce: 1, pepperoni: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.6, "ram_available_mb": 109175.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13346.8, "ram_available_mb": 109159.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.83, 46.9, 46.9, 46.9, 46.9, 46.9, 46.72, 46.72, 46.72, 46.72, 46.72, 48.12, 48.12, 48.12, 48.12], "power_watts_avg": 47.16, "power_watts_peak": 48.12, "energy_joules_est": 66.58, "sample_count": 15, "duration_seconds": 1.412}, "timestamp": "2026-01-12T09:59:06.809052"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1350.812, "latencies_ms": [1350.812], "images_per_second": 0.74, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the cardboard box in the background. The pizza is on the left side of the box, and the box is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.9, "ram_available_mb": 109167.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.12, 32.47, 32.47, 32.47, 32.47, 32.47, 45.91, 45.91, 45.91, 45.91, 45.91, 48.61, 48.61, 48.61], "power_watts_avg": 41.84, "power_watts_peak": 48.61, "energy_joules_est": 56.54, "sample_count": 14, "duration_seconds": 1.351}, "timestamp": "2026-01-12T09:59:08.223455"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 876.577, "latencies_ms": [876.577], "images_per_second": 1.141, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A large pizza with cheese and tomato sauce is in a cardboard box on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.0, "ram_available_mb": 109171.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13330.7, "ram_available_mb": 109175.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 17.0}, "power_stats": {"power_watts_samples": [48.61, 48.61, 32.85, 32.85, 32.85, 32.85, 32.85, 47.02, 47.02], "power_watts_avg": 39.5, "power_watts_peak": 48.61, "energy_joules_est": 34.65, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-12T09:59:09.136742"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1256.662, "latencies_ms": [1256.662], "images_per_second": 0.796, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The pizza is in a cardboard box with a white and brown color scheme. The lighting is natural and the pizza is in a room with a black background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13322.8, "ram_available_mb": 109183.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13336.0, "ram_available_mb": 109170.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.02, 47.02, 47.02, 51.73, 51.73, 51.73, 51.73, 47.3, 47.3, 47.3, 47.3, 47.3, 45.12], "power_watts_avg": 48.43, "power_watts_peak": 51.73, "energy_joules_est": 60.89, "sample_count": 13, "duration_seconds": 1.257}, "timestamp": "2026-01-12T09:59:10.450451"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1116.561, "latencies_ms": [1116.561], "images_per_second": 0.896, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A woman sits on the edge of an open refrigerator, talking on her cell phone, while a man sits on the curb nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13337.1, "ram_available_mb": 109169.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.12, 45.12, 45.12, 45.12, 44.31, 44.31, 44.31, 44.31, 44.31, 47.16, 47.16, 47.16], "power_watts_avg": 45.29, "power_watts_peak": 47.16, "energy_joules_est": 50.6, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T09:59:11.665806"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1905.078, "latencies_ms": [1905.078], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. jacket: 1\n3. pants: 1\n4. shoes: 1\n5. refrigerator: 1\n6. cup: 2\n7. glass: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.2, "ram_available_mb": 109173.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13318.9, "ram_available_mb": 109187.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.16, 47.16, 38.06, 38.06, 38.06, 38.06, 38.06, 46.21, 46.21, 46.21, 46.21, 46.21, 46.57, 46.57, 46.57, 46.57, 46.57, 34.64, 34.64], "power_watts_avg": 43.04, "power_watts_peak": 47.16, "energy_joules_est": 82.02, "sample_count": 19, "duration_seconds": 1.906}, "timestamp": "2026-01-12T09:59:13.584124"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1695.815, "latencies_ms": [1695.815], "images_per_second": 0.59, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The woman is sitting on the open door of the refrigerator, which is located on the right side of the image. The refrigerator is situated on the left side of the image, and the woman is positioned closer to the camera than the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.1, "ram_available_mb": 109195.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13325.5, "ram_available_mb": 109180.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.64, 34.64, 34.64, 36.73, 36.73, 36.73, 36.73, 36.73, 46.86, 46.86, 46.86, 46.86, 44.96, 44.96, 44.96, 44.96, 44.96], "power_watts_avg": 41.17, "power_watts_peak": 46.86, "energy_joules_est": 69.84, "sample_count": 17, "duration_seconds": 1.696}, "timestamp": "2026-01-12T09:59:15.352575"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1006.764, "latencies_ms": [1006.764], "images_per_second": 0.993, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman sits on an open refrigerator door on a city street, while a man sits on a bench nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.7, "ram_available_mb": 109188.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13335.0, "ram_available_mb": 109171.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.78, 34.78, 34.78, 34.78, 34.78, 47.94, 47.94, 47.94, 47.94, 47.94], "power_watts_avg": 41.36, "power_watts_peak": 47.94, "energy_joules_est": 41.65, "sample_count": 10, "duration_seconds": 1.007}, "timestamp": "2026-01-12T09:59:16.364735"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1844.788, "latencies_ms": [1844.788], "images_per_second": 0.542, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image depicts a woman sitting on an open refrigerator door, with a man smoking a cigarette nearby. The scene is set on a street with a sidewalk and a building in the background. The lighting appears to be natural daylight, and the weather seems to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.0, "ram_available_mb": 109171.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13321.1, "ram_available_mb": 109185.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.89, 47.89, 47.89, 47.89, 47.89, 47.94, 47.94, 47.94, 47.94, 47.94, 47.95, 47.95, 47.95, 47.95, 47.95, 34.82, 34.82, 34.82, 34.82], "power_watts_avg": 45.17, "power_watts_peak": 47.95, "energy_joules_est": 83.33, "sample_count": 19, "duration_seconds": 1.845}, "timestamp": "2026-01-12T09:59:18.284122"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1089.21, "latencies_ms": [1089.21], "images_per_second": 0.918, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing a straw hat and a green shirt is sitting at a white table with a tray of hot dogs on it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13313.2, "ram_available_mb": 109193.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13333.1, "ram_available_mb": 109173.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.82, 32.71, 32.71, 32.71, 32.71, 45.49, 45.49, 45.49, 45.49, 45.49, 47.23], "power_watts_avg": 40.03, "power_watts_peak": 47.23, "energy_joules_est": 43.64, "sample_count": 11, "duration_seconds": 1.09}, "timestamp": "2026-01-12T09:59:19.452471"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1967.324, "latencies_ms": [1967.324], "images_per_second": 0.508, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. hat: 1\n3. shirt: 1\n4. chair: 1\n5. hotdogs: 12\n6. foil: 1\n7. grass: 1\n8. white: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.2, "ram_available_mb": 109181.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13328.4, "ram_available_mb": 109177.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 47.23, 44.97, 44.97, 44.97, 44.97, 44.97, 47.77, 47.77, 47.77, 47.77, 47.77, 37.3, 37.3, 37.3, 37.3, 37.3, 34.6], "power_watts_avg": 43.69, "power_watts_peak": 47.77, "energy_joules_est": 85.97, "sample_count": 20, "duration_seconds": 1.968}, "timestamp": "2026-01-12T09:59:21.472421"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1486.972, "latencies_ms": [1486.972], "images_per_second": 0.673, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, with the hot dogs in the center. The hot dogs are placed on a white table, which is positioned in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.4, "ram_available_mb": 109181.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13324.7, "ram_available_mb": 109181.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.6, 34.6, 34.6, 34.6, 40.4, 40.4, 40.4, 40.4, 40.4, 46.19, 46.19, 46.19, 46.19, 46.19, 39.54], "power_watts_avg": 40.72, "power_watts_peak": 46.19, "energy_joules_est": 60.6, "sample_count": 15, "duration_seconds": 1.488}, "timestamp": "2026-01-12T09:59:23.039125"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 954.584, "latencies_ms": [954.584], "images_per_second": 1.048, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing a straw hat is sitting at a table with a tray of hot dogs on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.8, "ram_available_mb": 109189.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13336.4, "ram_available_mb": 109169.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [39.54, 39.54, 39.54, 39.54, 42.55, 42.55, 42.55, 42.55, 47.72, 47.72], "power_watts_avg": 42.38, "power_watts_peak": 47.72, "energy_joules_est": 40.47, "sample_count": 10, "duration_seconds": 0.955}, "timestamp": "2026-01-12T09:59:24.049223"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2366.67, "latencies_ms": [2366.67], "images_per_second": 0.423, "prompt_tokens": 1110, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a man wearing a straw hat and a green shirt, sitting at a white table with a tray of hot dogs. The hot dogs are placed on a piece of aluminum foil, and the man is holding a red hot dog in his hand. The lighting in the image is bright and natural, suggesting that the photo was taken outdoors on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.5, "ram_available_mb": 109177.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.72, 47.72, 47.72, 46.34, 46.34, 46.34, 46.34, 46.34, 46.91, 46.91, 46.91, 46.91, 46.91, 40.78, 40.78, 40.78, 40.78, 40.78, 34.78, 34.78, 34.78, 34.78, 34.78, 34.63], "power_watts_avg": 42.58, "power_watts_peak": 47.72, "energy_joules_est": 100.8, "sample_count": 24, "duration_seconds": 2.367}, "timestamp": "2026-01-12T09:59:26.473032"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1333.875, "latencies_ms": [1333.875], "images_per_second": 0.75, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a room with a desk, a chair, a bookshelf, and a couch, with a laptop on the desk and a star hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13322.2, "ram_available_mb": 109184.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.63, 34.63, 34.63, 34.63, 41.05, 41.05, 41.05, 41.05, 41.05, 45.78, 45.78, 45.78, 45.78, 45.78], "power_watts_avg": 40.9, "power_watts_peak": 45.78, "energy_joules_est": 54.61, "sample_count": 14, "duration_seconds": 1.335}, "timestamp": "2026-01-12T09:59:27.940769"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1549.542, "latencies_ms": [1549.542], "images_per_second": 0.645, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " chair: 1, laptop: 1, bookshelf: 1, books: 1, blanket: 1, bookshelf: 1, books: 1, bookshelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13314.3, "ram_available_mb": 109192.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13330.4, "ram_available_mb": 109175.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.38, 39.38, 39.38, 39.38, 45.44, 45.44, 45.44, 45.44, 45.44, 46.33, 46.33, 46.33, 46.33, 46.33, 36.6, 36.6], "power_watts_avg": 43.1, "power_watts_peak": 46.33, "energy_joules_est": 66.8, "sample_count": 16, "duration_seconds": 1.55}, "timestamp": "2026-01-12T09:59:29.558221"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1593.907, "latencies_ms": [1593.907], "images_per_second": 0.627, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The laptop is on the left side of the room, the bookshelf is in the middle, and the couch is on the right side. The laptop is near the bookshelf, and the couch is near the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.5, "ram_available_mb": 109179.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.7, "ram_available_mb": 109179.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.6, 36.6, 36.6, 40.74, 40.74, 40.74, 40.74, 40.74, 46.64, 46.64, 46.64, 46.64, 46.64, 40.72, 40.72, 40.72], "power_watts_avg": 41.81, "power_watts_peak": 46.64, "energy_joules_est": 66.65, "sample_count": 16, "duration_seconds": 1.594}, "timestamp": "2026-01-12T09:59:31.174687"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 881.365, "latencies_ms": [881.365], "images_per_second": 1.135, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A room with a desk, bookshelf, and couch is shown in the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13318.8, "ram_available_mb": 109187.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13337.4, "ram_available_mb": 109168.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_watts_samples": [40.72, 40.72, 36.26, 36.26, 36.26, 36.26, 36.26, 47.75, 47.75], "power_watts_avg": 39.8, "power_watts_peak": 47.75, "energy_joules_est": 35.09, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T09:59:32.086212"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1353.888, "latencies_ms": [1353.888], "images_per_second": 0.739, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The room is lit by a single light bulb and has a warm, inviting atmosphere. The walls are painted a light beige color, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.5, "ram_available_mb": 109176.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.75, 47.75, 47.75, 51.71, 51.71, 51.71, 51.71, 51.71, 47.44, 47.44, 47.44, 47.44, 47.44, 42.14], "power_watts_avg": 48.65, "power_watts_peak": 51.71, "energy_joules_est": 65.9, "sample_count": 14, "duration_seconds": 1.354}, "timestamp": "2026-01-12T09:59:33.501828"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1223.105, "latencies_ms": [1223.105], "images_per_second": 0.818, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, two elephants are seen in a grassy field, with one of them wearing a hat, and a bird is flying in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.0, "ram_available_mb": 109177.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13329.8, "ram_available_mb": 109176.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.14, 42.14, 42.14, 42.14, 42.6, 42.6, 42.6, 42.6, 42.6, 46.62, 46.62, 46.62, 46.62], "power_watts_avg": 43.7, "power_watts_peak": 46.62, "energy_joules_est": 53.45, "sample_count": 13, "duration_seconds": 1.223}, "timestamp": "2026-01-12T09:59:34.819177"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 539.837, "latencies_ms": [539.837], "images_per_second": 1.852, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " elephant: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.0, "ram_available_mb": 109184.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13335.0, "ram_available_mb": 109171.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.62, 36.74, 36.74, 36.74, 36.74, 36.74], "power_watts_avg": 38.39, "power_watts_peak": 46.62, "energy_joules_est": 20.75, "sample_count": 6, "duration_seconds": 0.54}, "timestamp": "2026-01-12T09:59:35.428810"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2432.846, "latencies_ms": [2432.846], "images_per_second": 0.411, "prompt_tokens": 1117, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The two elephants are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the one on the right. The elephants are facing each other, with the one on the left appearing to be slightly larger in size. The background of the image features a hazy, green landscape with trees and bushes, suggesting a natural habitat for the elephants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.0, "ram_available_mb": 109171.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13304.1, "ram_available_mb": 109202.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 46.43, 46.43, 46.43, 59.11, 59.11, 59.11, 59.11, 59.11, 46.9, 46.9, 46.9, 46.9, 46.9, 35.55, 35.55, 35.55, 35.55, 35.55, 34.85, 34.85, 34.85, 34.85, 34.88], "power_watts_avg": 44.57, "power_watts_peak": 59.11, "energy_joules_est": 108.46, "sample_count": 25, "duration_seconds": 2.433}, "timestamp": "2026-01-12T09:59:37.952354"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1902.668, "latencies_ms": [1902.668], "images_per_second": 0.526, "prompt_tokens": 1111, "response_tokens_est": 56, "n_tiles": 1, "output_text": " In the heart of a verdant savannah, two majestic elephants engage in a tender moment, their trunks entwined in a display of affection. The lush greenery of the surrounding landscape provides a stark contrast to the elephants' imposing presence, creating a serene and captivating scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13304.1, "ram_available_mb": 109202.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13320.1, "ram_available_mb": 109186.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 41.67, 41.67, 41.67, 41.67, 41.67, 45.48, 45.48, 45.48, 45.48, 45.48, 38.48, 38.48, 38.48, 38.48, 38.48], "power_watts_avg": 40.4, "power_watts_peak": 45.48, "energy_joules_est": 76.9, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T09:59:39.921128"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 879.898, "latencies_ms": [879.898], "images_per_second": 1.136, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephants are brown, the sky is overcast, and the vegetation is green.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13312.2, "ram_available_mb": 109194.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13330.9, "ram_available_mb": 109175.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 34.77, 44.18, 44.18, 44.18, 44.18, 44.18], "power_watts_avg": 40.0, "power_watts_peak": 44.18, "energy_joules_est": 35.23, "sample_count": 9, "duration_seconds": 0.881}, "timestamp": "2026-01-12T09:59:40.882750"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1409.092, "latencies_ms": [1409.092], "images_per_second": 0.71, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A shirtless man wearing a white baseball cap and sunglasses is holding a white frisbee in his right hand and a green bottle in his left hand while standing in a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.1, "ram_available_mb": 109177.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13238.0, "ram_available_mb": 109268.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [46.73, 46.73, 46.73, 46.73, 46.73, 50.09, 50.09, 50.09, 50.09, 50.09, 47.23, 47.23, 47.23, 47.23], "power_watts_avg": 48.07, "power_watts_peak": 50.09, "energy_joules_est": 67.77, "sample_count": 14, "duration_seconds": 1.41}, "timestamp": "2026-01-12T09:59:42.299766"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1967.361, "latencies_ms": [1967.361], "images_per_second": 0.508, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. cap: 1\n3. shorts: 1\n4. frisbee: 1\n5. bottle: 1\n6. grass: 1\n7. trees: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13238.0, "ram_available_mb": 109268.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13308.7, "ram_available_mb": 109197.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.23, 33.89, 33.89, 33.89, 33.89, 33.89, 48.04, 48.04, 48.04, 48.04, 48.04, 48.34, 48.34, 48.34, 48.34, 48.34, 34.8, 34.8, 34.8, 34.8], "power_watts_avg": 41.89, "power_watts_peak": 48.34, "energy_joules_est": 82.42, "sample_count": 20, "duration_seconds": 1.968}, "timestamp": "2026-01-12T09:59:44.319326"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1626.537, "latencies_ms": [1626.537], "images_per_second": 0.615, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee and wearing a cap. The frisbee is in his hand, and he is standing on a grassy field. The background shows a person walking in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13308.7, "ram_available_mb": 109197.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13394.9, "ram_available_mb": 109111.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [33.26, 33.26, 33.26, 33.26, 33.26, 45.96, 45.96, 45.96, 45.96, 45.96, 47.55, 47.55, 47.55, 47.55, 47.55, 34.67, 34.67], "power_watts_avg": 41.36, "power_watts_peak": 47.55, "energy_joules_est": 67.31, "sample_count": 17, "duration_seconds": 1.627}, "timestamp": "2026-01-12T09:59:46.085943"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 856.135, "latencies_ms": [856.135], "images_per_second": 1.168, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is playing frisbee in a field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.9, "ram_available_mb": 109115.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13378.8, "ram_available_mb": 109127.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.67, 34.67, 34.67, 38.73, 38.73, 38.73, 38.73, 38.73, 46.18], "power_watts_avg": 38.21, "power_watts_peak": 46.18, "energy_joules_est": 32.73, "sample_count": 9, "duration_seconds": 0.857}, "timestamp": "2026-01-12T09:59:46.997873"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1435.216, "latencies_ms": [1435.216], "images_per_second": 0.697, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a man in a grassy field, wearing a white cap and shorts, holding a frisbee in his hand. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.8, "ram_available_mb": 109127.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.8, "ram_available_mb": 109141.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.18, 46.18, 46.18, 46.18, 51.18, 51.18, 51.18, 51.18, 51.18, 47.18, 47.18, 47.18, 47.18, 47.18, 38.29], "power_watts_avg": 47.65, "power_watts_peak": 51.18, "energy_joules_est": 68.42, "sample_count": 15, "duration_seconds": 1.436}, "timestamp": "2026-01-12T09:59:48.512745"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1123.875, "latencies_ms": [1123.875], "images_per_second": 0.89, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young boy wearing a blue sports jersey is cutting a chocolate cake with a knife on a table with a colorful tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.0, "ram_available_mb": 109149.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13370.7, "ram_available_mb": 109135.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.29, 38.29, 38.29, 38.29, 42.24, 42.24, 42.24, 42.24, 42.24, 46.45, 46.45, 46.45], "power_watts_avg": 41.98, "power_watts_peak": 46.45, "energy_joules_est": 47.2, "sample_count": 12, "duration_seconds": 1.124}, "timestamp": "2026-01-12T09:59:49.724901"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1948.534, "latencies_ms": [1948.534], "images_per_second": 0.513, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. boy: 1\n2. knife: 1\n3. plate: 1\n4. cake: 1\n5. tablecloth: 1\n6. wall: 1\n7. chair: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.7, "ram_available_mb": 109135.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.1, "ram_available_mb": 109098.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [46.45, 46.45, 37.02, 37.02, 37.02, 37.02, 37.02, 46.34, 46.34, 46.34, 46.34, 46.34, 48.95, 48.95, 48.95, 48.95, 48.95, 34.52, 34.52, 34.52], "power_watts_avg": 42.9, "power_watts_peak": 48.95, "energy_joules_est": 83.62, "sample_count": 20, "duration_seconds": 1.949}, "timestamp": "2026-01-12T09:59:51.739194"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1442.174, "latencies_ms": [1442.174], "images_per_second": 0.693, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The boy is in the foreground, leaning over a table with a cake in the middle. The cake is on a tablecloth with a pattern of animals, and the boy is holding a knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.2, "ram_available_mb": 109106.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13405.0, "ram_available_mb": 109101.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.52, 31.33, 31.33, 31.33, 31.33, 31.33, 45.84, 45.84, 45.84, 45.84, 45.84, 49.41, 49.41, 49.41, 49.41], "power_watts_avg": 41.2, "power_watts_peak": 49.41, "energy_joules_est": 59.46, "sample_count": 15, "duration_seconds": 1.443}, "timestamp": "2026-01-12T09:59:53.301447"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1188.018, "latencies_ms": [1188.018], "images_per_second": 0.842, "prompt_tokens": 1112, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A young boy wearing a blue shirt is cutting a cake with a knife. The cake is decorated with chocolate and has a toy car on top.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.2, "ram_available_mb": 109109.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13409.3, "ram_available_mb": 109097.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.41, 32.75, 32.75, 32.75, 32.75, 32.75, 47.05, 47.05, 47.05, 47.05, 47.05, 49.08], "power_watts_avg": 41.46, "power_watts_peak": 49.41, "energy_joules_est": 49.29, "sample_count": 12, "duration_seconds": 1.189}, "timestamp": "2026-01-12T09:59:54.512629"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1336.975, "latencies_ms": [1336.975], "images_per_second": 0.748, "prompt_tokens": 1110, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The boy is wearing a blue shirt and is cutting a chocolate cake with a knife. The cake is decorated with chocolate and is on a table covered with a tablecloth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13405.4, "ram_available_mb": 109100.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13310.5, "ram_available_mb": 109195.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.08, 49.08, 49.08, 49.08, 43.29, 43.29, 43.29, 43.29, 43.29, 47.48, 47.48, 47.48, 47.48, 47.48], "power_watts_avg": 46.44, "power_watts_peak": 49.08, "energy_joules_est": 62.11, "sample_count": 14, "duration_seconds": 1.337}, "timestamp": "2026-01-12T09:59:55.924203"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1435.975, "latencies_ms": [1435.975], "images_per_second": 0.696, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a close-up of a zebra's face, showcasing its distinctive black and white stripes, with another zebra in the background, partially visible, and a metal fence separating them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13310.5, "ram_available_mb": 109195.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.9, "ram_available_mb": 109162.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.84, 39.84, 39.84, 39.84, 39.84, 46.12, 46.12, 46.12, 46.12, 46.12, 46.42, 46.42, 46.42, 46.42, 46.42], "power_watts_avg": 44.13, "power_watts_peak": 46.42, "energy_joules_est": 63.39, "sample_count": 15, "duration_seconds": 1.437}, "timestamp": "2026-01-12T09:59:57.437434"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 539.422, "latencies_ms": [539.422], "images_per_second": 1.854, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.9, "ram_available_mb": 109162.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13430.4, "ram_available_mb": 109075.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.02, 35.02, 35.02, 35.02, 35.02, 45.56], "power_watts_avg": 36.78, "power_watts_peak": 45.56, "energy_joules_est": 19.85, "sample_count": 6, "duration_seconds": 0.54}, "timestamp": "2026-01-12T09:59:58.046726"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1565.742, "latencies_ms": [1565.742], "images_per_second": 0.639, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The zebra in the foreground is close to the camera, while the other zebra is farther away in the background. The zebra in the foreground is eating from a metal feeder, while the other zebra is standing behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.4, "ram_available_mb": 109075.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.56, 45.56, 45.56, 53.17, 53.17, 53.17, 53.17, 53.17, 48.72, 48.72, 48.72, 48.72, 48.72, 41.15, 41.15, 41.15], "power_watts_avg": 48.1, "power_watts_peak": 53.17, "energy_joules_est": 75.33, "sample_count": 16, "duration_seconds": 1.566}, "timestamp": "2026-01-12T09:59:59.657565"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 882.28, "latencies_ms": [882.28], "images_per_second": 1.133, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of zebras are standing in a pen, eating grass and looking around.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13400.1, "ram_available_mb": 109106.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [41.15, 41.15, 36.72, 36.72, 36.72, 36.72, 36.72, 47.12, 47.12], "power_watts_avg": 40.02, "power_watts_peak": 47.12, "energy_joules_est": 35.32, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:00:00.567279"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1929.372, "latencies_ms": [1929.372], "images_per_second": 0.518, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a close-up of a zebra's face, with its distinctive black and white stripes, and a background that includes a fence and some greenery. The lighting in the image is natural, likely from sunlight, and the zebra appears to be in a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13396.2, "ram_available_mb": 109110.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13382.7, "ram_available_mb": 109123.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.12, 47.12, 47.12, 52.24, 52.24, 52.24, 52.24, 52.24, 47.84, 47.84, 47.84, 47.84, 47.84, 42.21, 42.21, 42.21, 42.21, 42.21, 34.83, 34.83], "power_watts_avg": 46.12, "power_watts_peak": 52.24, "energy_joules_est": 89.0, "sample_count": 20, "duration_seconds": 1.93}, "timestamp": "2026-01-12T10:00:02.582979"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1009.704, "latencies_ms": [1009.704], "images_per_second": 0.99, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white photo of a train station with a sign that says La Spezia Centrale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.8, "ram_available_mb": 109131.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13380.3, "ram_available_mb": 109126.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 35.98, 35.98, 35.98, 35.98, 35.98, 45.3, 45.3, 45.3], "power_watts_avg": 38.21, "power_watts_peak": 45.3, "energy_joules_est": 38.6, "sample_count": 11, "duration_seconds": 1.01}, "timestamp": "2026-01-12T10:00:03.746731"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1962.715, "latencies_ms": [1962.715], "images_per_second": 0.509, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sign: 1\n2. train: 1\n3. bench: 1\n4. platform: 1\n5. train tracks: 2\n6. train station: 1\n7. mountain: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.4, "ram_available_mb": 109133.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13370.0, "ram_available_mb": 109136.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.3, 45.3, 41.31, 41.31, 41.31, 41.31, 46.18, 46.18, 46.18, 46.18, 46.18, 49.34, 49.34, 49.34, 49.34, 49.34, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 43.62, "power_watts_peak": 49.34, "energy_joules_est": 85.62, "sample_count": 20, "duration_seconds": 1.963}, "timestamp": "2026-01-12T10:00:05.762185"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1409.199, "latencies_ms": [1409.199], "images_per_second": 0.71, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The train station platform is located in the foreground, with the train tracks extending into the background. The sign is positioned above the platform, indicating the direction to the center of the station.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.7, "ram_available_mb": 109142.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.74, 32.23, 32.23, 32.23, 32.23, 32.23, 46.19, 46.19, 46.19, 46.19, 46.19, 48.74, 48.74, 48.74], "power_watts_avg": 40.93, "power_watts_peak": 48.74, "energy_joules_est": 57.73, "sample_count": 14, "duration_seconds": 1.41}, "timestamp": "2026-01-12T10:00:07.228659"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1010.84, "latencies_ms": [1010.84], "images_per_second": 0.989, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white photo of a train station with a sign that says La Spezia Centrale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.7, "ram_available_mb": 109142.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13280.4, "ram_available_mb": 109225.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 11.0}, "power_stats": {"power_watts_samples": [48.74, 48.74, 34.27, 34.27, 34.27, 34.27, 34.27, 48.09, 48.09, 48.09, 48.09], "power_watts_avg": 41.93, "power_watts_peak": 48.74, "energy_joules_est": 42.4, "sample_count": 11, "duration_seconds": 1.011}, "timestamp": "2026-01-12T10:00:08.338303"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1562.141, "latencies_ms": [1562.141], "images_per_second": 0.64, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is in black and white, with the train station and tracks being the main focus. The sky is overcast, and the station is well-lit, suggesting it is either early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13280.4, "ram_available_mb": 109225.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13326.7, "ram_available_mb": 109179.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.09, 47.2, 47.2, 47.2, 47.2, 47.2, 46.04, 46.04, 46.04, 46.04, 46.04, 48.22, 48.22, 48.22, 48.22, 48.22], "power_watts_avg": 47.21, "power_watts_peak": 48.22, "energy_joules_est": 73.78, "sample_count": 16, "duration_seconds": 1.563}, "timestamp": "2026-01-12T10:00:09.954158"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 986.031, "latencies_ms": [986.031], "images_per_second": 1.014, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is sitting on a red surfboard in the ocean, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.7, "ram_available_mb": 109183.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13326.0, "ram_available_mb": 109180.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.84, 34.84, 45.33, 45.33, 45.33, 45.33, 45.33, 47.02], "power_watts_avg": 41.3, "power_watts_peak": 47.02, "energy_joules_est": 40.75, "sample_count": 10, "duration_seconds": 0.987}, "timestamp": "2026-01-12T10:00:10.968489"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1998.283, "latencies_ms": [1998.283], "images_per_second": 0.5, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. ocean: 1\n4. sky: 1\n5. clouds: 1\n6. horizon: 1\n7. water: 1\n8. surfboard logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.2, "ram_available_mb": 109188.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13321.4, "ram_available_mb": 109184.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.02, 47.02, 47.02, 47.02, 47.49, 47.49, 47.49, 47.49, 47.49, 47.32, 47.32, 47.32, 47.32, 47.32, 37.28, 37.28, 37.28, 37.28, 37.28, 34.71], "power_watts_avg": 44.16, "power_watts_peak": 47.49, "energy_joules_est": 88.28, "sample_count": 20, "duration_seconds": 1.999}, "timestamp": "2026-01-12T10:00:12.989121"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1389.888, "latencies_ms": [1389.888], "images_per_second": 0.719, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The person is sitting on the surfboard, which is in the foreground of the image. The ocean is in the background, and the sky is above the person and the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.5, "ram_available_mb": 109192.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13335.3, "ram_available_mb": 109171.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 34.71, 34.71, 41.13, 41.13, 41.13, 41.13, 41.13, 46.67, 46.67, 46.67, 46.67, 46.67], "power_watts_avg": 41.27, "power_watts_peak": 46.67, "energy_joules_est": 57.38, "sample_count": 14, "duration_seconds": 1.39}, "timestamp": "2026-01-12T10:00:14.452174"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 812.819, "latencies_ms": [812.819], "images_per_second": 1.23, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is sitting on a surfboard in the ocean at sunset.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.3, "ram_available_mb": 109175.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13339.6, "ram_available_mb": 109166.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 36.0}, "power_stats": {"power_watts_samples": [40.99, 40.99, 40.99, 40.99, 40.99, 45.77, 45.77, 45.77, 45.77], "power_watts_avg": 43.12, "power_watts_peak": 45.77, "energy_joules_est": 35.07, "sample_count": 9, "duration_seconds": 0.813}, "timestamp": "2026-01-12T10:00:15.364005"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1705.824, "latencies_ms": [1705.824], "images_per_second": 0.586, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a solitary figure perched on a vibrant red surfboard, poised on the edge of a vast, dark ocean. The sky above is a tumultuous canvas of gray and orange, hinting at the dramatic beauty of the setting sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.6, "ram_available_mb": 109166.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13316.6, "ram_available_mb": 109189.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.81, 45.81, 45.81, 45.81, 45.81, 47.73, 47.73, 47.73, 47.73, 47.73, 47.67, 47.67, 47.67, 47.67, 47.67, 34.69, 34.69], "power_watts_avg": 45.61, "power_watts_peak": 47.73, "energy_joules_est": 77.82, "sample_count": 17, "duration_seconds": 1.706}, "timestamp": "2026-01-12T10:00:17.077387"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 961.229, "latencies_ms": [961.229], "images_per_second": 1.04, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man and a woman are sitting at a table on a train, eating sushi and other food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.6, "ram_available_mb": 109189.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13311.4, "ram_available_mb": 109194.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.69, 34.69, 34.69, 40.57, 40.57, 40.57, 40.57, 40.57, 47.88, 47.88], "power_watts_avg": 40.27, "power_watts_peak": 47.88, "energy_joules_est": 38.73, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-12T10:00:18.090834"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1915.601, "latencies_ms": [1915.601], "images_per_second": 0.522, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. chopsticks: 2\n4. tray: 1\n5. food: 1\n6. plate: 1\n7. bag: 1\n8. seat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.4, "ram_available_mb": 109194.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13311.0, "ram_available_mb": 109195.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.88, 47.88, 47.88, 47.69, 47.69, 47.69, 47.69, 47.69, 47.2, 47.2, 47.2, 47.2, 47.2, 42.56, 42.56, 42.56, 42.56, 42.56, 35.01, 35.01], "power_watts_avg": 45.05, "power_watts_peak": 47.88, "energy_joules_est": 86.3, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T10:00:20.105859"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1796.102, "latencies_ms": [1796.102], "images_per_second": 0.557, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, while the woman is on the right side. The man is closer to the camera than the woman. The food tray is in the middle of the image, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13311.0, "ram_available_mb": 109195.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 35.01, 37.72, 37.72, 37.72, 37.72, 37.72, 46.09, 46.09, 46.09, 46.09, 46.09, 43.86, 43.86, 43.86, 43.86, 43.86], "power_watts_avg": 41.3, "power_watts_peak": 46.09, "energy_joules_est": 74.2, "sample_count": 18, "duration_seconds": 1.797}, "timestamp": "2026-01-12T10:00:21.920892"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 962.473, "latencies_ms": [962.473], "images_per_second": 1.039, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A couple is enjoying a meal on a train, with a view of the tracks outside the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.5, "ram_available_mb": 109159.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13300.2, "ram_available_mb": 109206.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.58, 34.58, 34.58, 34.58, 34.58, 47.2, 47.2, 47.2, 47.2, 47.2], "power_watts_avg": 40.89, "power_watts_peak": 47.2, "energy_joules_est": 39.38, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-12T10:00:22.931460"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1357.281, "latencies_ms": [1357.281], "images_per_second": 0.737, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a well-lit train carriage with natural light coming through the windows. The colors in the image are vibrant and the materials are mostly plastic and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13292.4, "ram_available_mb": 109213.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13316.7, "ram_available_mb": 109189.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [47.46, 47.46, 47.46, 47.46, 47.46, 46.8, 46.8, 46.8, 46.8, 46.8, 46.99, 46.99, 46.99, 46.99], "power_watts_avg": 47.09, "power_watts_peak": 47.46, "energy_joules_est": 63.93, "sample_count": 14, "duration_seconds": 1.358}, "timestamp": "2026-01-12T10:00:24.344313"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1220.302, "latencies_ms": [1220.302], "images_per_second": 0.819, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " Two men are walking down the street at night, one in a white shirt and black tie, and the other in a pink shirt and black tie.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13308.9, "ram_available_mb": 109197.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13333.8, "ram_available_mb": 109172.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [46.99, 35.3, 35.3, 35.3, 35.3, 35.3, 47.25, 47.25, 47.25, 47.25, 47.25, 48.14, 48.14], "power_watts_avg": 42.77, "power_watts_peak": 48.14, "energy_joules_est": 52.2, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-12T10:00:25.657958"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1879.479, "latencies_ms": [1879.479], "images_per_second": 0.532, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. tie: 1\n3. shirt: 1\n4. tie: 1\n5. pants: 1\n6. shoes: 1\n7. building: 1\n8. sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.8, "ram_available_mb": 109172.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13397.0, "ram_available_mb": 109109.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.14, 48.14, 48.14, 36.17, 36.17, 36.17, 36.17, 36.17, 46.49, 46.49, 46.49, 46.49, 46.03, 46.03, 46.03, 46.03, 46.03, 35.11, 35.11], "power_watts_avg": 42.72, "power_watts_peak": 48.14, "energy_joules_est": 80.3, "sample_count": 19, "duration_seconds": 1.88}, "timestamp": "2026-01-12T10:00:27.570277"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2214.919, "latencies_ms": [2214.919], "images_per_second": 0.451, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The man on the left is closer to the camera than the man on the right. The man on the left is standing on the sidewalk, while the man on the right is walking on the sidewalk. The man on the left is wearing a white shirt and black tie, while the man on the right is wearing a pink shirt and black tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.0, "ram_available_mb": 109109.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.8, "ram_available_mb": 109140.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.11, 35.11, 35.11, 37.85, 37.85, 37.85, 37.85, 37.85, 46.74, 46.74, 46.74, 46.74, 46.74, 43.93, 43.93, 43.93, 43.93, 43.93, 35.07, 35.07, 35.07, 35.07, 35.07], "power_watts_avg": 40.14, "power_watts_peak": 46.74, "energy_joules_est": 88.95, "sample_count": 23, "duration_seconds": 2.216}, "timestamp": "2026-01-12T10:00:29.936201"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1023.955, "latencies_ms": [1023.955], "images_per_second": 0.977, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two men are walking down the street at night, one in a white shirt and the other in a pink shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13371.4, "ram_available_mb": 109134.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 42.14, 42.14, 42.14, 42.14, 42.14, 45.53, 45.53], "power_watts_avg": 40.12, "power_watts_peak": 45.53, "energy_joules_est": 41.09, "sample_count": 11, "duration_seconds": 1.024}, "timestamp": "2026-01-12T10:00:31.100001"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 921.073, "latencies_ms": [921.073], "images_per_second": 1.086, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The two men are walking on the sidewalk at night, with the streetlights illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.4, "ram_available_mb": 109138.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.8, "ram_available_mb": 109147.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.53, 45.53, 45.53, 42.01, 42.01, 42.01, 42.01, 42.01, 46.61, 46.61], "power_watts_avg": 43.98, "power_watts_peak": 46.61, "energy_joules_est": 40.54, "sample_count": 10, "duration_seconds": 0.922}, "timestamp": "2026-01-12T10:00:32.111292"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1072.011, "latencies_ms": [1072.011], "images_per_second": 0.933, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing glasses and a gray shirt is pouring wine into a glass at a bar while another person holds a wine glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.9, "ram_available_mb": 109155.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.2, "ram_available_mb": 109150.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.61, 46.61, 46.61, 45.92, 45.92, 45.92, 45.92, 45.92, 46.45, 46.45, 46.45], "power_watts_avg": 46.25, "power_watts_peak": 46.61, "energy_joules_est": 49.61, "sample_count": 11, "duration_seconds": 1.073}, "timestamp": "2026-01-12T10:00:33.227230"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2304.813, "latencies_ms": [2304.813], "images_per_second": 0.434, "prompt_tokens": 1114, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. man: 1\n2. wine bottle: 1\n3. wine glass: 1\n4. wine rack: 1\n5. wine bottle on rack: 1\n6. wine bottle on shelf: 1\n7. wine bottle on table: 1\n8. wine bottle on counter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.4, "ram_available_mb": 109157.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13303.5, "ram_available_mb": 109202.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.45, 46.45, 43.35, 43.35, 43.35, 43.35, 43.35, 47.35, 47.35, 47.35, 47.35, 47.35, 48.28, 48.28, 48.28, 48.28, 48.28, 34.68, 34.68, 34.68, 34.68, 34.68, 34.73], "power_watts_avg": 43.3, "power_watts_peak": 48.28, "energy_joules_est": 99.82, "sample_count": 23, "duration_seconds": 2.305}, "timestamp": "2026-01-12T10:00:35.547842"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1995.372, "latencies_ms": [1995.372], "images_per_second": 0.501, "prompt_tokens": 1118, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The man is standing to the left of the bar counter, with the wine bottle and glasses in front of him. The wine bottle is placed on the counter, while the glasses are held by the man. The background shows shelves with wine bottles, indicating that the bar is stocked with various wines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.5, "ram_available_mb": 109202.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13313.9, "ram_available_mb": 109192.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 38.9, 38.9, 38.9, 38.9, 38.9, 46.67, 46.67, 46.67, 46.67, 46.67, 42.46, 42.46, 42.46, 42.46, 42.46, 34.59, 34.59], "power_watts_avg": 40.67, "power_watts_peak": 46.67, "energy_joules_est": 81.21, "sample_count": 20, "duration_seconds": 1.997}, "timestamp": "2026-01-12T10:00:37.618226"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1060.814, "latencies_ms": [1060.814], "images_per_second": 0.943, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man is standing behind a bar, pouring wine into a glass. There are wine bottles on the shelves behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.9, "ram_available_mb": 109192.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13368.0, "ram_available_mb": 109138.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.59, 34.59, 35.62, 35.62, 35.62, 35.62, 35.62, 46.47, 46.47, 46.47, 46.47], "power_watts_avg": 39.38, "power_watts_peak": 46.47, "energy_joules_est": 41.8, "sample_count": 11, "duration_seconds": 1.061}, "timestamp": "2026-01-12T10:00:38.782832"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1115.913, "latencies_ms": [1115.913], "images_per_second": 0.896, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with warm lighting, and the wooden wine rack is filled with bottles of wine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.1, "ram_available_mb": 109142.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.47, 43.03, 43.03, 43.03, 43.03, 43.03, 46.94, 46.94, 46.94, 46.94, 46.94, 49.71], "power_watts_avg": 45.5, "power_watts_peak": 49.71, "energy_joules_est": 50.8, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-12T10:00:39.997127"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1304.798, "latencies_ms": [1304.798], "images_per_second": 0.766, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A tennis player is in the middle of a powerful swing with a blue and white tennis racket, attempting to hit a yellow tennis ball that is in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13355.2, "ram_available_mb": 109151.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [49.71, 49.71, 49.71, 49.71, 43.05, 43.05, 43.05, 43.05, 43.05, 46.14, 46.14, 46.14, 46.14], "power_watts_avg": 46.05, "power_watts_peak": 49.71, "energy_joules_est": 60.11, "sample_count": 13, "duration_seconds": 1.305}, "timestamp": "2026-01-12T10:00:41.312932"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2183.202, "latencies_ms": [2183.202], "images_per_second": 0.458, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. Tennis racket: 1\n2. Tennis ball: 1\n3. Grass: 1\n4. Player: 1\n5. Wristband: 1\n6. Shirt: 1\n7. Shorts: 1\n8. Footwear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.2, "ram_available_mb": 109155.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13287.4, "ram_available_mb": 109218.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.14, 37.1, 37.1, 37.1, 37.1, 37.1, 47.7, 47.7, 47.7, 47.7, 47.7, 48.37, 48.37, 48.37, 48.37, 48.37, 34.66, 34.66, 34.66, 34.66, 34.66, 34.68], "power_watts_avg": 41.82, "power_watts_peak": 48.37, "energy_joules_est": 91.31, "sample_count": 22, "duration_seconds": 2.184}, "timestamp": "2026-01-12T10:00:43.532588"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1848.068, "latencies_ms": [1848.068], "images_per_second": 0.541, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the tennis ball in the middle ground, and the green grass of the tennis court in the background. The player is positioned to the left of the tennis ball, and the tennis court extends to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13287.4, "ram_available_mb": 109218.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13329.5, "ram_available_mb": 109176.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 39.95, 39.95, 39.95, 39.95, 39.95, 46.48, 46.48, 46.48, 46.48, 46.48, 41.13, 41.13, 41.13, 41.13, 41.13, 34.82], "power_watts_avg": 40.88, "power_watts_peak": 46.48, "energy_joules_est": 75.58, "sample_count": 19, "duration_seconds": 1.849}, "timestamp": "2026-01-12T10:00:45.495752"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 937.758, "latencies_ms": [937.758], "images_per_second": 1.066, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A tennis player is playing on a grass court, swinging his racket to hit a ball.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13329.5, "ram_available_mb": 109176.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13332.5, "ram_available_mb": 109173.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 34.82, 34.82, 40.77, 40.77, 40.77, 40.77, 40.77, 45.89], "power_watts_avg": 38.9, "power_watts_peak": 45.89, "energy_joules_est": 36.5, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-12T10:00:46.555089"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2053.654, "latencies_ms": [2053.654], "images_per_second": 0.487, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a grass court, where a tennis player is in the midst of a powerful swing with a blue and white racket. The grass is a vibrant green, contrasting with the player's white attire. The lighting is natural and bright, casting a clear image of the action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.5, "ram_available_mb": 109173.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13336.5, "ram_available_mb": 109169.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.89, 45.89, 45.89, 45.89, 46.62, 46.62, 46.62, 46.62, 46.62, 46.46, 46.46, 46.46, 46.46, 46.46, 39.92, 39.92, 39.92, 39.92, 39.92, 34.56, 34.56], "power_watts_avg": 43.7, "power_watts_peak": 46.62, "energy_joules_est": 89.76, "sample_count": 21, "duration_seconds": 2.054}, "timestamp": "2026-01-12T10:00:48.671441"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1037.201, "latencies_ms": [1037.201], "images_per_second": 0.964, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A cat is standing on a wooden shelf in front of a television, which is displaying a man in a suit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.5, "ram_available_mb": 109169.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13345.8, "ram_available_mb": 109160.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.56, 34.56, 33.38, 33.38, 33.38, 33.38, 33.38, 45.71, 45.71, 45.71, 45.71], "power_watts_avg": 38.08, "power_watts_peak": 45.71, "energy_joules_est": 39.55, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-12T10:00:49.837072"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1954.277, "latencies_ms": [1954.277], "images_per_second": 0.512, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. cat: 1\n2. television: 1\n3. shelf: 1\n4. remote control: 1\n5. cup: 1\n6. bookshelf: 1\n7. wall: 1\n8. curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.0, "ram_available_mb": 109168.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.5, "ram_available_mb": 109163.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.71, 45.79, 45.79, 45.79, 45.79, 45.79, 46.72, 46.72, 46.72, 46.72, 46.72, 48.72, 48.72, 48.72, 48.72, 48.72, 34.86, 34.86, 34.86, 34.86], "power_watts_avg": 44.56, "power_watts_peak": 48.72, "energy_joules_est": 87.12, "sample_count": 20, "duration_seconds": 1.955}, "timestamp": "2026-01-12T10:00:51.856563"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1433.589, "latencies_ms": [1433.589], "images_per_second": 0.698, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The cat is positioned to the left of the television, which is located in the background. The television is situated on the right side of the wooden shelf, which is situated in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13338.5, "ram_available_mb": 109167.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13342.3, "ram_available_mb": 109164.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.39, 33.39, 33.39, 33.39, 33.39, 45.83, 45.83, 45.83, 45.83, 45.83, 47.27, 47.27, 47.27, 47.27, 47.27], "power_watts_avg": 42.17, "power_watts_peak": 47.27, "energy_joules_est": 60.49, "sample_count": 15, "duration_seconds": 1.435}, "timestamp": "2026-01-12T10:00:53.424457"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 820.027, "latencies_ms": [820.027], "images_per_second": 1.219, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is on top of a TV stand, looking at the TV.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13334.5, "ram_available_mb": 109171.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13347.2, "ram_available_mb": 109159.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.19, 34.19, 34.19, 34.19, 34.19, 46.59, 46.59, 46.59, 46.59], "power_watts_avg": 39.7, "power_watts_peak": 46.59, "energy_joules_est": 32.58, "sample_count": 9, "duration_seconds": 0.821}, "timestamp": "2026-01-12T10:00:54.336826"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 918.732, "latencies_ms": [918.732], "images_per_second": 1.088, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The cat is white and brown, the television is black, and the room is well lit.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13339.3, "ram_available_mb": 109167.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13355.7, "ram_available_mb": 109150.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 18.0}, "power_stats": {"power_watts_samples": [46.59, 44.22, 44.22, 44.22, 44.22, 44.22, 46.43, 46.43, 46.43, 46.43], "power_watts_avg": 45.34, "power_watts_peak": 46.59, "energy_joules_est": 41.68, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-12T10:00:55.348983"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1361.457, "latencies_ms": [1361.457], "images_per_second": 0.735, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a blue circular sign with a white silhouette of a person and a child riding a bicycle, and a white rectangular sign with black Chinese characters, indicating a pedestrian crossing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.7, "ram_available_mb": 109154.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13359.7, "ram_available_mb": 109146.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.43, 46.2, 46.2, 46.2, 46.2, 46.2, 46.5, 46.5, 46.5, 46.5, 46.5, 48.56, 48.56, 48.56], "power_watts_avg": 46.83, "power_watts_peak": 48.56, "energy_joules_est": 63.78, "sample_count": 14, "duration_seconds": 1.362}, "timestamp": "2026-01-12T10:00:56.764950"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1936.359, "latencies_ms": [1936.359], "images_per_second": 0.516, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 3\n2. tree: 1\n3. bicycle: 1\n4. road sign: 1\n5. pole: 1\n6. sky: 1\n7. sun: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.9, "ram_available_mb": 109154.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.0, "ram_available_mb": 109156.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.56, 48.56, 33.09, 33.09, 33.09, 33.09, 47.27, 47.27, 47.27, 47.27, 47.27, 49.39, 49.39, 49.39, 49.39, 49.39, 34.73, 34.73, 34.73, 34.73], "power_watts_avg": 42.58, "power_watts_peak": 49.39, "energy_joules_est": 82.48, "sample_count": 20, "duration_seconds": 1.937}, "timestamp": "2026-01-12T10:00:58.784330"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1559.558, "latencies_ms": [1559.558], "images_per_second": 0.641, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, with the blue circle sign positioned above the white sign. The blue circle sign is to the left of the white sign, and the trees are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.0, "ram_available_mb": 109156.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.73, 31.57, 31.57, 31.57, 31.57, 31.57, 45.38, 45.38, 45.38, 45.38, 45.38, 48.78, 48.78, 48.78, 48.78, 48.78], "power_watts_avg": 41.46, "power_watts_peak": 48.78, "energy_joules_est": 64.7, "sample_count": 16, "duration_seconds": 1.56}, "timestamp": "2026-01-12T10:01:00.450860"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1817.901, "latencies_ms": [1817.901], "images_per_second": 0.55, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a street scene with a blue and white sign featuring a bicycle and a family symbol, indicating a bike lane. The sign is mounted on a metal pole, and the background reveals a clear blue sky and lush green trees, suggesting a pleasant day outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.6, "ram_available_mb": 109154.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13341.0, "ram_available_mb": 109165.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.65, 34.65, 34.65, 34.65, 34.65, 46.72, 46.72, 46.72, 46.72, 46.72, 47.18, 47.18, 47.18, 47.18, 47.18, 35.06, 35.06, 35.06, 35.06], "power_watts_avg": 41.21, "power_watts_peak": 47.18, "energy_joules_est": 74.93, "sample_count": 19, "duration_seconds": 1.818}, "timestamp": "2026-01-12T10:01:02.369773"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1582.76, "latencies_ms": [1582.76], "images_per_second": 0.632, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a blue and white sign with a symbol of a person and a child on it, and a white sign with Chinese characters on it. The sky is clear and blue, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.1, "ram_available_mb": 109173.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.97, 32.97, 32.97, 32.97, 32.97, 46.3, 46.3, 46.3, 46.3, 46.3, 48.16, 48.16, 48.16, 48.16, 48.16, 34.71], "power_watts_avg": 41.99, "power_watts_peak": 48.16, "energy_joules_est": 66.48, "sample_count": 16, "duration_seconds": 1.583}, "timestamp": "2026-01-12T10:01:03.985445"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 977.166, "latencies_ms": [977.166], "images_per_second": 1.023, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl with black hair is sitting at a table in a restaurant, eating a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.8, "ram_available_mb": 109168.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 34.71, 34.71, 45.38, 45.38, 45.38, 45.38, 45.38, 47.59], "power_watts_avg": 41.33, "power_watts_peak": 47.59, "energy_joules_est": 40.41, "sample_count": 10, "duration_seconds": 0.978}, "timestamp": "2026-01-12T10:01:04.999437"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1185.578, "latencies_ms": [1185.578], "images_per_second": 0.843, "prompt_tokens": 1113, "response_tokens_est": 29, "n_tiles": 1, "output_text": " table: 1, chair: 1, pizza: 1, glass: 1, book: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.6, "ram_available_mb": 109154.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.59, 47.59, 47.59, 47.59, 47.89, 47.89, 47.89, 47.89, 47.89, 47.69, 47.69, 47.69], "power_watts_avg": 47.74, "power_watts_peak": 47.89, "energy_joules_est": 56.62, "sample_count": 12, "duration_seconds": 1.186}, "timestamp": "2026-01-12T10:01:06.213231"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2248.876, "latencies_ms": [2248.876], "images_per_second": 0.445, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The girl is sitting at a table in the foreground, with a glass of water and a pizza on the table in front of her. The pizza is on the left side of the table, while the glass of water is on the right side. The background shows other tables and chairs, indicating that the girl is in a restaurant or cafe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13337.4, "ram_available_mb": 109168.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.69, 47.69, 38.33, 38.33, 38.33, 38.33, 38.33, 47.44, 47.44, 47.44, 47.44, 47.44, 47.31, 47.31, 47.31, 47.31, 47.31, 34.82, 34.82, 34.82, 34.82, 34.82, 34.65], "power_watts_avg": 42.16, "power_watts_peak": 47.69, "energy_joules_est": 94.83, "sample_count": 23, "duration_seconds": 2.249}, "timestamp": "2026-01-12T10:01:08.535746"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 903.338, "latencies_ms": [903.338], "images_per_second": 1.107, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl is sitting at a table in a restaurant, eating a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.4, "ram_available_mb": 109168.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.3, "ram_available_mb": 109152.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.65, 34.65, 34.65, 39.31, 39.31, 39.31, 39.31, 39.31, 45.78], "power_watts_avg": 38.47, "power_watts_peak": 45.78, "energy_joules_est": 34.78, "sample_count": 9, "duration_seconds": 0.904}, "timestamp": "2026-01-12T10:01:09.498667"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1427.637, "latencies_ms": [1427.637], "images_per_second": 0.7, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken in a dimly lit restaurant with warm lighting. The colors in the image are mostly muted with the exception of the girl's hair, which is a vibrant yellow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.4, "ram_available_mb": 109159.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13338.9, "ram_available_mb": 109167.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.78, 45.78, 45.78, 45.78, 51.85, 51.85, 51.85, 51.85, 51.85, 47.88, 47.88, 47.88, 47.88, 47.88, 37.34], "power_watts_avg": 47.94, "power_watts_peak": 51.85, "energy_joules_est": 68.45, "sample_count": 15, "duration_seconds": 1.428}, "timestamp": "2026-01-12T10:01:11.014457"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1922.323, "latencies_ms": [1922.323], "images_per_second": 0.52, "prompt_tokens": 1099, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a vibrant and appetizing spread of food on a kitchen counter, with a variety of dishes including a bowl of green vegetables, a plate of rice and vegetables, and a plate of meat and vegetables, all set against the backdrop of a wooden wall and a yellow box.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.4, "ram_available_mb": 109165.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.34, 37.34, 37.34, 37.34, 43.13, 43.13, 43.13, 43.13, 43.13, 46.31, 46.31, 46.31, 46.31, 46.31, 37.99, 37.99, 37.99, 37.99, 37.99, 34.81], "power_watts_avg": 41.07, "power_watts_peak": 46.31, "energy_joules_est": 78.96, "sample_count": 20, "duration_seconds": 1.923}, "timestamp": "2026-01-12T10:01:13.035193"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1321.92, "latencies_ms": [1321.92], "images_per_second": 0.756, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bowl: 1, plate: 2, glass: 1, food: 1, broccoli: 1, cauliflower: 1, cauliflower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.4, "ram_available_mb": 109169.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.7, "ram_available_mb": 109161.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.81, 39.21, 39.21, 39.21, 39.21, 39.21, 45.31, 45.31, 45.31, 45.31, 45.31, 40.99], "power_watts_avg": 40.57, "power_watts_peak": 45.31, "energy_joules_est": 53.68, "sample_count": 14, "duration_seconds": 1.323}, "timestamp": "2026-01-12T10:01:14.502153"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2010.912, "latencies_ms": [2010.912], "images_per_second": 0.497, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the plates of food are placed in the foreground, with the bowls of vegetables and the box of bread in the background. The plates of food are positioned to the left of the bowls, and the box of bread is located to the right of the bowls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.8, "ram_available_mb": 109169.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [40.99, 40.99, 40.99, 40.99, 43.67, 43.67, 43.67, 43.67, 43.67, 46.41, 46.41, 46.41, 46.41, 46.41, 38.2, 38.2, 38.2, 38.2, 38.2, 34.7], "power_watts_avg": 42.0, "power_watts_peak": 46.41, "energy_joules_est": 84.49, "sample_count": 20, "duration_seconds": 2.011}, "timestamp": "2026-01-12T10:01:16.521559"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 896.7, "latencies_ms": [896.7], "images_per_second": 1.115, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are gathered around a table in a kitchen, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13332.1, "ram_available_mb": 109174.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 41.54, 41.54, 41.54, 41.54, 41.54, 46.9], "power_watts_avg": 39.86, "power_watts_peak": 46.9, "energy_joules_est": 35.77, "sample_count": 9, "duration_seconds": 0.897}, "timestamp": "2026-01-12T10:01:17.484533"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1506.767, "latencies_ms": [1506.767], "images_per_second": 0.664, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image is taken in a kitchen with a wooden wall in the background. The lighting is natural, coming from the window. The colors in the image are vibrant, with the food being the main focus.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13346.7, "ram_available_mb": 109159.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13332.3, "ram_available_mb": 109174.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.9, 46.9, 46.9, 46.9, 51.75, 51.75, 51.75, 51.75, 51.75, 47.98, 47.98, 47.98, 47.98, 47.98, 37.4], "power_watts_avg": 48.24, "power_watts_peak": 51.75, "energy_joules_est": 72.72, "sample_count": 15, "duration_seconds": 1.507}, "timestamp": "2026-01-12T10:01:19.001645"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1437.051, "latencies_ms": [1437.051], "images_per_second": 0.696, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image captures a bustling city street with a green bus, a white truck, and a red car driving down the road, while a black car is parked on the side of the street.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13332.3, "ram_available_mb": 109174.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13256.9, "ram_available_mb": 109249.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [37.4, 37.4, 37.4, 37.4, 44.98, 44.98, 44.98, 44.98, 44.98, 47.65, 47.65, 47.65, 47.65, 47.65, 38.14], "power_watts_avg": 43.39, "power_watts_peak": 47.65, "energy_joules_est": 62.38, "sample_count": 15, "duration_seconds": 1.438}, "timestamp": "2026-01-12T10:01:20.520725"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1991.439, "latencies_ms": [1991.439], "images_per_second": 0.502, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Bus: 1\n2. Car: 4\n3. Truck: 1\n4. Van: 1\n5. Bus stop: 1\n6. Street sign: 1\n7. Building: 3\n8. Tree: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13256.9, "ram_available_mb": 109249.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13306.7, "ram_available_mb": 109199.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.14, 38.14, 38.14, 38.14, 42.92, 42.92, 42.92, 42.92, 42.92, 46.69, 46.69, 46.69, 46.69, 46.69, 39.21, 39.21, 39.21, 39.21, 39.21, 34.62], "power_watts_avg": 41.56, "power_watts_peak": 46.69, "energy_joules_est": 82.79, "sample_count": 20, "duration_seconds": 1.992}, "timestamp": "2026-01-12T10:01:22.540003"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1856.424, "latencies_ms": [1856.424], "images_per_second": 0.539, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The bus is positioned in the middle of the street, with the cars on the left and the sidewalk on the right. The bus is relatively close to the camera, while the cars are farther away. The sidewalk is in the foreground, with the buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13304.6, "ram_available_mb": 109201.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13307.1, "ram_available_mb": 109199.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 39.65, 39.65, 39.65, 39.65, 39.65, 46.38, 46.38, 46.38, 46.38, 46.38, 41.48, 41.48, 41.48, 41.48, 41.48, 34.68], "power_watts_avg": 40.85, "power_watts_peak": 46.38, "energy_joules_est": 75.87, "sample_count": 19, "duration_seconds": 1.857}, "timestamp": "2026-01-12T10:01:24.509638"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2062.977, "latencies_ms": [2062.977], "images_per_second": 0.485, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a bustling city street with a variety of vehicles, including cars, buses, and trucks, all navigating through the traffic. The street is lined with tall buildings, creating a dense urban environment. The presence of a bus stop sign indicates that public transportation is a significant part of the city's infrastructure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.1, "ram_available_mb": 109203.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13307.1, "ram_available_mb": 109199.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 34.68, 40.65, 40.65, 40.65, 40.65, 40.65, 45.93, 45.93, 45.93, 45.93, 45.93, 39.88, 39.88, 39.88, 39.88, 34.7, 34.7, 34.7], "power_watts_avg": 39.77, "power_watts_peak": 45.93, "energy_joules_est": 82.08, "sample_count": 21, "duration_seconds": 2.064}, "timestamp": "2026-01-12T10:01:26.679018"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1820.519, "latencies_ms": [1820.519], "images_per_second": 0.549, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant city street bathed in natural light, with the sun casting a warm glow on the buildings and trees. The colors are predominantly muted, with the exception of the red car and the green bus, which stand out against the urban backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.1, "ram_available_mb": 109203.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13299.2, "ram_available_mb": 109207.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 33.3, 33.3, 33.3, 33.3, 33.3, 46.14, 46.14, 46.14, 46.14, 46.14, 47.62, 47.62, 47.62, 47.62, 47.62, 34.83, 34.83], "power_watts_avg": 40.76, "power_watts_peak": 47.62, "energy_joules_est": 74.24, "sample_count": 19, "duration_seconds": 1.821}, "timestamp": "2026-01-12T10:01:28.649043"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1002.796, "latencies_ms": [1002.796], "images_per_second": 0.997, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black laptop computer with a blue screen sits on a table with a cell phone and a remote control nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13299.2, "ram_available_mb": 109207.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13325.1, "ram_available_mb": 109181.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 37.37, 37.37, 37.37, 37.37, 37.37, 46.09, 46.09], "power_watts_avg": 38.35, "power_watts_peak": 46.09, "energy_joules_est": 38.47, "sample_count": 10, "duration_seconds": 1.003}, "timestamp": "2026-01-12T10:01:29.662346"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1458.645, "latencies_ms": [1458.645], "images_per_second": 0.686, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " laptop: 1, phone: 2, remote: 1, phone: 1, remote: 1, phone: 1, remote: 1, phone: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.3, "ram_available_mb": 109189.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.0, "ram_available_mb": 109180.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.09, 46.09, 46.09, 47.96, 47.96, 47.96, 47.96, 47.96, 48.05, 48.05, 48.05, 48.05, 48.05, 44.35, 44.35], "power_watts_avg": 47.13, "power_watts_peak": 48.05, "energy_joules_est": 68.78, "sample_count": 15, "duration_seconds": 1.459}, "timestamp": "2026-01-12T10:01:31.178861"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1213.551, "latencies_ms": [1213.551], "images_per_second": 0.824, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the cell phone is on the right side, and the remote is in front of the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.0, "ram_available_mb": 109184.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13331.8, "ram_available_mb": 109174.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.35, 44.35, 36.99, 36.99, 36.99, 36.99, 36.99, 47.02, 47.02, 47.02, 47.02, 47.02, 44.97], "power_watts_avg": 42.59, "power_watts_peak": 47.02, "energy_joules_est": 51.71, "sample_count": 13, "duration_seconds": 1.214}, "timestamp": "2026-01-12T10:01:32.491966"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 950.417, "latencies_ms": [950.417], "images_per_second": 1.052, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person is sitting at a table with a laptop, a cell phone, and a remote control.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13341.0, "ram_available_mb": 109165.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.97, 44.97, 44.97, 44.97, 44.39, 44.39, 44.39, 44.39, 44.39, 46.39], "power_watts_avg": 44.82, "power_watts_peak": 46.39, "energy_joules_est": 42.62, "sample_count": 10, "duration_seconds": 0.951}, "timestamp": "2026-01-12T10:01:33.500914"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 845.992, "latencies_ms": [845.992], "images_per_second": 1.182, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The laptop is black, the phone is black, and the table is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.1, "ram_available_mb": 109173.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13344.4, "ram_available_mb": 109161.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.39, 46.39, 46.39, 46.39, 47.23, 47.23, 47.23, 47.23, 47.23], "power_watts_avg": 46.86, "power_watts_peak": 47.23, "energy_joules_est": 39.66, "sample_count": 9, "duration_seconds": 0.846}, "timestamp": "2026-01-12T10:01:34.410105"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1378.249, "latencies_ms": [1378.249], "images_per_second": 0.726, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image shows a cluttered desk with a computer monitor, keyboard, and laptop, surrounded by books, a water bottle, and a pen, with a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.5, "ram_available_mb": 109165.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13333.0, "ram_available_mb": 109173.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.63, 46.63, 46.63, 46.63, 46.63, 49.7, 49.7, 49.7, 49.7, 49.7, 47.37, 47.37, 47.37, 47.37], "power_watts_avg": 47.94, "power_watts_peak": 49.7, "energy_joules_est": 66.1, "sample_count": 14, "duration_seconds": 1.379}, "timestamp": "2026-01-12T10:01:35.824222"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1966.452, "latencies_ms": [1966.452], "images_per_second": 0.509, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. monitor: 1\n2. keyboard: 1\n3. mouse: 1\n4. laptop: 1\n5. books: 10\n6. water bottle: 1\n7. pen: 1\n8. book: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.2, "ram_available_mb": 109181.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13327.1, "ram_available_mb": 109179.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.37, 33.3, 33.3, 33.3, 33.3, 33.3, 47.43, 47.43, 47.43, 47.43, 47.43, 48.92, 48.92, 48.92, 48.92, 48.92, 34.75, 34.75, 34.75, 34.75], "power_watts_avg": 41.73, "power_watts_peak": 48.92, "energy_joules_est": 82.07, "sample_count": 20, "duration_seconds": 1.967}, "timestamp": "2026-01-12T10:01:37.839275"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1945.847, "latencies_ms": [1945.847], "images_per_second": 0.514, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The computer monitor is positioned to the left of the keyboard, with the laptop to its right. The books are stacked on the left side of the desk, while the water bottle is placed on the right side. The window is located behind the desk, providing natural light to the workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.3, "ram_available_mb": 109187.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13335.1, "ram_available_mb": 109171.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.31, 33.31, 33.31, 33.31, 33.31, 46.11, 46.11, 46.11, 46.11, 46.11, 47.51, 47.51, 47.51, 47.51, 47.51, 34.67, 34.67, 34.67, 34.67, 34.67], "power_watts_avg": 40.4, "power_watts_peak": 47.51, "energy_joules_est": 78.63, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T10:01:39.908312"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 956.928, "latencies_ms": [956.928], "images_per_second": 1.045, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A cluttered desk with a computer, books, and a laptop is in front of a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.1, "ram_available_mb": 109171.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13343.0, "ram_available_mb": 109163.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 34.11, 34.11, 44.55, 44.55, 44.55, 44.55, 44.55], "power_watts_avg": 39.33, "power_watts_peak": 44.55, "energy_joules_est": 37.67, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-12T10:01:40.972386"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 984.079, "latencies_ms": [984.079], "images_per_second": 1.016, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through a window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.1, "ram_available_mb": 109171.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13345.5, "ram_available_mb": 109160.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [45.73, 45.73, 45.73, 45.73, 45.73, 47.54, 47.54, 47.54, 47.54, 47.54], "power_watts_avg": 46.63, "power_watts_peak": 47.54, "energy_joules_est": 45.92, "sample_count": 10, "duration_seconds": 0.985}, "timestamp": "2026-01-12T10:01:41.984264"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1150.133, "latencies_ms": [1150.133], "images_per_second": 0.869, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a helmet and black shirt is jumping in the air with his skateboard while a crowd of people watch from the stands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.6, "ram_available_mb": 109164.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.0, "ram_available_mb": 109163.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.16, 47.16, 47.16, 47.16, 47.39, 47.39, 47.39, 47.39, 47.39, 47.49, 47.49, 47.49], "power_watts_avg": 47.34, "power_watts_peak": 47.49, "energy_joules_est": 54.46, "sample_count": 12, "duration_seconds": 1.15}, "timestamp": "2026-01-12T10:01:43.200059"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1963.52, "latencies_ms": [1963.52], "images_per_second": 0.509, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. skateboard: 1\n4. crowd: 1\n5. camera: 1\n6. banner: 1\n7. railing: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.0, "ram_available_mb": 109163.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.9, "ram_available_mb": 109160.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.49, 47.49, 38.31, 38.31, 38.31, 38.31, 38.31, 46.99, 46.99, 46.99, 46.99, 46.99, 46.55, 46.55, 46.55, 46.55, 46.55, 34.82, 34.82, 34.82], "power_watts_avg": 42.94, "power_watts_peak": 47.49, "energy_joules_est": 84.32, "sample_count": 20, "duration_seconds": 1.964}, "timestamp": "2026-01-12T10:01:45.216022"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1408.276, "latencies_ms": [1408.276], "images_per_second": 0.71, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the air, while the crowd is in the background. The skateboarder is closer to the camera than the crowd.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.9, "ram_available_mb": 109160.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13400.8, "ram_available_mb": 109105.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 31.59, 31.59, 31.59, 31.59, 31.59, 45.82, 45.82, 45.82, 45.82, 45.82, 49.22, 49.22], "power_watts_avg": 39.65, "power_watts_peak": 49.22, "energy_joules_est": 55.88, "sample_count": 14, "duration_seconds": 1.409}, "timestamp": "2026-01-12T10:01:46.679740"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 850.54, "latencies_ms": [850.54], "images_per_second": 1.176, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A skateboarder is performing a trick in the air while a crowd watches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.9, "ram_available_mb": 109109.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13330.3, "ram_available_mb": 109176.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.22, 49.22, 49.22, 37.46, 37.46, 37.46, 37.46, 47.89, 47.89], "power_watts_avg": 43.7, "power_watts_peak": 49.22, "energy_joules_est": 37.18, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-12T10:01:47.591294"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1629.516, "latencies_ms": [1629.516], "images_per_second": 0.614, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image is taken in a dark indoor arena with bright lights illuminating the scene. The colors are vibrant, with the red and yellow of the skateboard and the black and white of the helmet standing out against the dark background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.4, "ram_available_mb": 109183.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.89, 47.89, 47.89, 51.36, 51.36, 51.36, 51.36, 51.36, 46.92, 46.92, 46.92, 46.92, 46.92, 41.54, 41.54, 41.54, 41.54], "power_watts_avg": 47.13, "power_watts_peak": 51.36, "energy_joules_est": 76.83, "sample_count": 17, "duration_seconds": 1.63}, "timestamp": "2026-01-12T10:01:49.309195"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1102.751, "latencies_ms": [1102.751], "images_per_second": 0.907, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A red fire hydrant with a smiley face and a smiley face on it is on the side of the road.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.5, "ram_available_mb": 109151.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.54, 32.02, 32.02, 32.02, 32.02, 32.02, 46.17, 46.17, 46.17, 46.17, 46.17], "power_watts_avg": 39.32, "power_watts_peak": 46.17, "energy_joules_est": 43.38, "sample_count": 11, "duration_seconds": 1.103}, "timestamp": "2026-01-12T10:01:50.422797"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1545.726, "latencies_ms": [1545.726], "images_per_second": 0.647, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " hydrant: 1\nsmile: 1\ntree: 1\ncar: 1\nstreet: 1\nbuilding: 1\ntree trunk: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.01, 49.01, 49.01, 49.01, 49.01, 47.9, 47.9, 47.9, 47.9, 47.9, 47.74, 47.74, 47.74, 47.74, 47.74, 34.86], "power_watts_avg": 47.38, "power_watts_peak": 49.01, "energy_joules_est": 73.26, "sample_count": 16, "duration_seconds": 1.546}, "timestamp": "2026-01-12T10:01:52.038930"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1710.581, "latencies_ms": [1710.581], "images_per_second": 0.585, "prompt_tokens": 1118, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The fire hydrant is located on the right side of the image, in the foreground, and is positioned near the edge of the frame. The street is in the background, with cars parked on the side and buildings visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.7, "ram_available_mb": 109163.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 41.99, 41.99, 41.99, 41.99, 41.99, 46.75, 46.75, 46.75, 46.75, 46.75, 39.26, 39.26, 39.26], "power_watts_avg": 41.23, "power_watts_peak": 46.75, "energy_joules_est": 70.55, "sample_count": 17, "duration_seconds": 1.711}, "timestamp": "2026-01-12T10:01:53.758096"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 990.565, "latencies_ms": [990.565], "images_per_second": 1.01, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A red fire hydrant stands on a city street corner, with a tree and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.7, "ram_available_mb": 109154.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.26, 39.26, 33.79, 33.79, 33.79, 33.79, 33.79, 47.97, 47.97, 47.97], "power_watts_avg": 39.14, "power_watts_peak": 47.97, "energy_joules_est": 38.79, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-12T10:01:54.770231"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1092.525, "latencies_ms": [1092.525], "images_per_second": 0.915, "prompt_tokens": 1110, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The fire hydrant is bright red and has a black face with a smiley face. The sky is clear and blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.97, 47.97, 47.63, 47.63, 47.63, 47.63, 47.63, 47.78, 47.78, 47.78, 47.78], "power_watts_avg": 47.75, "power_watts_peak": 47.97, "energy_joules_est": 52.19, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-12T10:01:55.882570"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 965.005, "latencies_ms": [965.005], "images_per_second": 1.036, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A green cart with a bunch of old suitcases stacked on it sits in front of a building.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [49.32, 49.32, 49.32, 49.32, 49.32, 47.73, 47.73, 47.73, 47.73, 47.73], "power_watts_avg": 48.53, "power_watts_peak": 49.32, "energy_joules_est": 46.85, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-12T10:01:56.897046"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2274.883, "latencies_ms": [2274.883], "images_per_second": 0.44, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. green trolley - 1\n2. brown suitcase - 1\n3. blue suitcase - 1\n4. green suitcase - 1\n5. brown leather suitcase - 1\n6. green metal cart - 1\n7. green door - 1\n8. poster - 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.1, "ram_available_mb": 109174.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13348.0, "ram_available_mb": 109158.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.45, 47.45, 47.45, 47.45, 47.45, 47.12, 47.12, 47.12, 47.12, 47.12, 47.74, 47.74, 47.74, 47.74, 47.74, 34.78, 34.78, 34.78, 34.78, 34.78, 34.79, 34.79, 34.79], "power_watts_avg": 43.03, "power_watts_peak": 47.74, "energy_joules_est": 97.92, "sample_count": 23, "duration_seconds": 2.275}, "timestamp": "2026-01-12T10:01:59.217460"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2315.866, "latencies_ms": [2315.866], "images_per_second": 0.432, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The green cart is positioned in the foreground, with the suitcases stacked on top of it. The suitcases are arranged in a haphazard manner, with some leaning against each other and others stacked on top of one another. The cart is located near a building with green doors and windows, and there is a poster on the wall behind the cart.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.1, "ram_available_mb": 109162.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13344.9, "ram_available_mb": 109161.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.11, 34.11, 34.11, 34.11, 34.11, 47.08, 47.08, 47.08, 47.08, 47.08, 47.76, 47.76, 47.76, 47.76, 47.76, 34.71, 34.71, 34.71, 34.71, 34.71, 34.52, 34.52], "power_watts_avg": 39.87, "power_watts_peak": 47.76, "energy_joules_est": 92.36, "sample_count": 24, "duration_seconds": 2.316}, "timestamp": "2026-01-12T10:02:01.652661"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 917.234, "latencies_ms": [917.234], "images_per_second": 1.09, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A green cart is filled with old suitcases and a cart is parked outside a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.9, "ram_available_mb": 109161.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13388.4, "ram_available_mb": 109117.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.52, 34.52, 33.01, 33.01, 33.01, 33.01, 33.01, 44.85, 44.85, 44.85], "power_watts_avg": 36.86, "power_watts_peak": 44.85, "energy_joules_est": 33.83, "sample_count": 10, "duration_seconds": 0.918}, "timestamp": "2026-01-12T10:02:02.712932"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1550.884, "latencies_ms": [1550.884], "images_per_second": 0.645, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a green trolley with a stack of old suitcases on it, with the suitcases being brown, blue, and green. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.4, "ram_available_mb": 109117.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13378.4, "ram_available_mb": 109127.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.85, 44.85, 46.47, 46.47, 46.47, 46.47, 46.47, 46.33, 46.33, 46.33, 46.33, 46.33, 46.81, 46.81, 46.81, 46.81], "power_watts_avg": 46.31, "power_watts_peak": 46.81, "energy_joules_est": 71.85, "sample_count": 16, "duration_seconds": 1.552}, "timestamp": "2026-01-12T10:02:04.329219"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 915.5, "latencies_ms": [915.5], "images_per_second": 1.092, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl in a pink dress is playing a video game on a Wii console.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.5, "ram_available_mb": 109135.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13370.2, "ram_available_mb": 109136.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [46.81, 32.73, 32.73, 32.73, 32.73, 32.73, 46.6, 46.6, 46.6, 46.6], "power_watts_avg": 39.69, "power_watts_peak": 46.81, "energy_joules_est": 36.36, "sample_count": 10, "duration_seconds": 0.916}, "timestamp": "2026-01-12T10:02:05.341910"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2228.832, "latencies_ms": [2228.832], "images_per_second": 0.449, "prompt_tokens": 1113, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. girl: 1\n2. sofa: 1\n3. window blinds: 1\n4. white object: 1\n5. girl's hand: 1\n6. girl's arm: 1\n7. girl's leg: 1\n8. girl's foot: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.2, "ram_available_mb": 109136.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.4, "ram_available_mb": 109141.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.6, 45.72, 45.72, 45.72, 45.72, 45.72, 45.98, 45.98, 45.98, 45.98, 45.98, 48.31, 48.31, 48.31, 48.31, 48.31, 34.83, 34.83, 34.83, 34.83, 34.83, 34.79, 34.79], "power_watts_avg": 43.06, "power_watts_peak": 48.31, "energy_joules_est": 95.99, "sample_count": 23, "duration_seconds": 2.229}, "timestamp": "2026-01-12T10:02:07.664369"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1490.061, "latencies_ms": [1490.061], "images_per_second": 0.671, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding a Wii remote in her right hand. The couch is located in the background, and the window blinds are positioned behind the couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.4, "ram_available_mb": 109145.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13344.4, "ram_available_mb": 109161.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 33.96, 33.96, 33.96, 33.96, 33.96, 45.13, 45.13, 45.13, 45.13, 45.13, 46.06, 46.06, 46.06], "power_watts_avg": 40.21, "power_watts_peak": 46.06, "energy_joules_est": 59.95, "sample_count": 15, "duration_seconds": 1.491}, "timestamp": "2026-01-12T10:02:09.229590"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 910.134, "latencies_ms": [910.134], "images_per_second": 1.099, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl is playing a video game on a Wii console in a living room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.5, "ram_available_mb": 109169.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13287.7, "ram_available_mb": 109218.6, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 10.0}, "power_stats": {"power_watts_samples": [46.06, 46.06, 35.57, 35.57, 35.57, 35.57, 35.57, 47.36, 47.36, 47.36], "power_watts_avg": 41.2, "power_watts_peak": 47.36, "energy_joules_est": 37.52, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-12T10:02:10.241451"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1646.892, "latencies_ms": [1646.892], "images_per_second": 0.607, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image is a photograph with a warm color tone, taken in a well-lit room with natural light coming from the window. The girl is wearing a pink dress with a floral pattern, and the couch is a neutral color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13287.7, "ram_available_mb": 109218.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.36, 47.36, 46.48, 46.48, 46.48, 46.48, 46.48, 45.99, 45.99, 45.99, 45.99, 45.99, 47.73, 47.73, 47.73, 47.73, 47.73], "power_watts_avg": 46.81, "power_watts_peak": 47.73, "energy_joules_est": 77.11, "sample_count": 17, "duration_seconds": 1.647}, "timestamp": "2026-01-12T10:02:11.958996"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1124.588, "latencies_ms": [1124.588], "images_per_second": 0.889, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A cluttered office desk with a laptop, keyboard, and headphones is surrounded by a trash can, computer tower, and chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.1, "ram_available_mb": 109179.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.75, 34.75, 34.75, 34.75, 34.75, 46.5, 46.5, 46.5, 46.5, 46.5, 46.7, 46.7], "power_watts_avg": 41.64, "power_watts_peak": 46.7, "energy_joules_est": 46.85, "sample_count": 12, "duration_seconds": 1.125}, "timestamp": "2026-01-12T10:02:13.174898"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1592.597, "latencies_ms": [1592.597], "images_per_second": 0.628, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " 1. black laptop\n2. black headphones\n3. black keyboard\n4. black mouse\n5. black computer monitor\n6. black computer mouse\n7. black computer keyboard\n8. black computer mouse", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.9, "ram_available_mb": 109169.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.7, 46.7, 46.7, 37.01, 37.01, 37.01, 37.01, 37.01, 46.19, 46.19, 46.19, 46.19, 46.19, 44.09, 44.09, 44.09], "power_watts_avg": 43.02, "power_watts_peak": 46.7, "energy_joules_est": 68.53, "sample_count": 16, "duration_seconds": 1.593}, "timestamp": "2026-01-12T10:02:14.789802"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1650.24, "latencies_ms": [1650.24], "images_per_second": 0.606, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The laptop is on the left side of the desk, the chair is on the right side, and the trash can is in the middle of the desk. The desk is in the foreground, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.09, 33.26, 33.26, 33.26, 33.26, 33.26, 47.81, 47.81, 47.81, 47.81, 47.81, 49.36, 49.36, 49.36, 49.36, 49.36, 34.7], "power_watts_avg": 43.0, "power_watts_peak": 49.36, "energy_joules_est": 70.98, "sample_count": 17, "duration_seconds": 1.651}, "timestamp": "2026-01-12T10:02:16.507075"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 931.855, "latencies_ms": [931.855], "images_per_second": 1.073, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A cluttered office with a computer on a desk, a chair, and a trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13415.6, "ram_available_mb": 109090.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 34.7, 44.72, 44.72, 44.72, 44.72, 44.72, 46.88], "power_watts_avg": 40.93, "power_watts_peak": 46.88, "energy_joules_est": 38.16, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-12T10:02:17.518894"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1540.394, "latencies_ms": [1540.394], "images_per_second": 0.649, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the windows, and the walls are painted white. The desk is made of glass and metal, and the chair is upholstered in gray fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.6, "ram_available_mb": 109090.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13395.3, "ram_available_mb": 109111.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.88, 46.88, 46.88, 46.88, 46.94, 46.94, 46.94, 46.94, 46.94, 46.76, 46.76, 46.76, 46.76, 46.76, 38.11, 38.11], "power_watts_avg": 45.77, "power_watts_peak": 46.94, "energy_joules_est": 70.52, "sample_count": 16, "duration_seconds": 1.541}, "timestamp": "2026-01-12T10:02:19.137386"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 852.289, "latencies_ms": [852.289], "images_per_second": 1.173, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is eating a pizza with mushrooms, peppers, and cheese on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.3, "ram_available_mb": 109115.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13387.6, "ram_available_mb": 109118.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [38.11, 38.11, 38.11, 38.4, 38.4, 38.4, 38.4, 38.4, 46.39], "power_watts_avg": 39.19, "power_watts_peak": 46.39, "energy_joules_est": 33.42, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-12T10:02:20.051174"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1944.967, "latencies_ms": [1944.967], "images_per_second": 0.514, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. plate: 1\n2. pizza: 1\n3. fork: 1\n4. hand: 1\n5. cheese: 1\n6. pepperoni: 1\n7. mushrooms: 1\n8. peppers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.6, "ram_available_mb": 109118.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13374.9, "ram_available_mb": 109131.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.39, 46.39, 46.39, 46.39, 51.4, 51.4, 51.4, 51.4, 51.4, 46.75, 46.75, 46.75, 46.75, 46.75, 38.95, 38.95, 38.95, 38.95, 38.95, 34.66], "power_watts_avg": 45.28, "power_watts_peak": 51.4, "energy_joules_est": 88.1, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T10:02:22.069505"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1171.84, "latencies_ms": [1171.84], "images_per_second": 0.853, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The pizza is in the foreground, on a white plate, and the fork is in the person's hand, which is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.9, "ram_available_mb": 109131.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13399.0, "ram_available_mb": 109107.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.66, 34.66, 34.66, 38.42, 38.42, 38.42, 38.42, 38.42, 45.56, 45.56, 45.56, 45.56], "power_watts_avg": 39.86, "power_watts_peak": 45.56, "energy_joules_est": 46.75, "sample_count": 12, "duration_seconds": 1.173}, "timestamp": "2026-01-12T10:02:23.331883"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 853.42, "latencies_ms": [853.42], "images_per_second": 1.172, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is eating a pizza with mushrooms, peppers, and cheese on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.3, "ram_available_mb": 109109.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13397.5, "ram_available_mb": 109108.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 55.0}, "power_stats": {"power_watts_samples": [45.56, 40.2, 40.2, 40.2, 40.2, 40.2, 47.23, 47.23, 47.23], "power_watts_avg": 43.13, "power_watts_peak": 47.23, "energy_joules_est": 36.83, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-12T10:02:24.241669"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 782.292, "latencies_ms": [782.292], "images_per_second": 1.278, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The pizza is red and white, and the plate is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.7, "ram_available_mb": 109116.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13405.8, "ram_available_mb": 109100.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 1.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 48.2, 48.2, 48.2, 48.2, 48.2, 47.03], "power_watts_avg": 47.81, "power_watts_peak": 48.2, "energy_joules_est": 37.43, "sample_count": 8, "duration_seconds": 0.783}, "timestamp": "2026-01-12T10:02:25.052698"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1182.464, "latencies_ms": [1182.464], "images_per_second": 0.846, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A white and red bus with the words \"Metropolitan Transit System\" on the side is parked on the street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.9, "ram_available_mb": 109108.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13437.2, "ram_available_mb": 109069.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.03, 47.03, 47.03, 47.03, 54.72, 54.72, 54.72, 54.72, 54.72, 51.65, 51.65, 51.65], "power_watts_avg": 51.39, "power_watts_peak": 54.72, "energy_joules_est": 60.79, "sample_count": 12, "duration_seconds": 1.183}, "timestamp": "2026-01-12T10:02:26.268387"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2099.113, "latencies_ms": [2099.113], "images_per_second": 0.476, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bus: 1\n2. windows: 10\n3. seats: 2\n4. people: 2\n5. trees: 1\n6. building: 1\n7. sign: 1\n8. wheels: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.2, "ram_available_mb": 109069.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13421.9, "ram_available_mb": 109084.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.65, 51.65, 42.6, 42.6, 42.6, 42.6, 42.6, 51.14, 51.14, 51.14, 51.14, 51.14, 54.14, 54.14, 54.14, 54.14, 54.14, 34.97, 34.97, 34.97, 34.97], "power_watts_avg": 46.79, "power_watts_peak": 54.14, "energy_joules_est": 98.23, "sample_count": 21, "duration_seconds": 2.099}, "timestamp": "2026-01-12T10:02:28.384919"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1526.554, "latencies_ms": [1526.554], "images_per_second": 0.655, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bus is parked on the left side of the street, with the sidewalk and trees on the right side. The bus is in the foreground, with the building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.1, "ram_available_mb": 109092.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13429.6, "ram_available_mb": 109076.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.54, 34.54, 34.54, 34.54, 34.54, 46.56, 46.56, 46.56, 46.56, 46.56, 51.31, 51.31, 51.31, 51.31, 51.31, 39.95], "power_watts_avg": 43.88, "power_watts_peak": 51.31, "energy_joules_est": 67.01, "sample_count": 16, "duration_seconds": 1.527}, "timestamp": "2026-01-12T10:02:30.049508"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1185.939, "latencies_ms": [1185.939], "images_per_second": 0.843, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A white and red bus is parked on the side of the road, with a building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13429.6, "ram_available_mb": 109076.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13418.6, "ram_available_mb": 109087.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [39.95, 39.95, 39.95, 39.95, 40.83, 40.83, 40.83, 40.83, 40.83, 50.23, 50.23, 50.23], "power_watts_avg": 42.89, "power_watts_peak": 50.23, "energy_joules_est": 50.88, "sample_count": 12, "duration_seconds": 1.186}, "timestamp": "2026-01-12T10:02:31.264131"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1017.306, "latencies_ms": [1017.306], "images_per_second": 0.983, "prompt_tokens": 1442, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The bus is white and red, and it is parked in a sunny parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.6, "ram_available_mb": 109087.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 8.0}, "power_stats": {"power_watts_samples": [50.23, 50.23, 43.52, 43.52, 43.52, 43.52, 43.52, 51.93, 51.93, 51.93, 51.93], "power_watts_avg": 47.8, "power_watts_peak": 51.93, "energy_joules_est": 48.64, "sample_count": 11, "duration_seconds": 1.018}, "timestamp": "2026-01-12T10:02:32.376670"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1181.025, "latencies_ms": [1181.025], "images_per_second": 0.847, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A baseball glove and a baseball cap are placed on the ground, with the cap resting on top of the glove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.4, "ram_available_mb": 109083.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13426.5, "ram_available_mb": 109079.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.93, 51.77, 51.77, 51.77, 51.77, 51.77, 47.8, 47.8, 47.8, 47.8, 47.8, 52.39], "power_watts_avg": 50.18, "power_watts_peak": 52.39, "energy_joules_est": 59.29, "sample_count": 12, "duration_seconds": 1.182}, "timestamp": "2026-01-12T10:02:33.589440"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1650.359, "latencies_ms": [1650.359], "images_per_second": 0.606, "prompt_tokens": 1446, "response_tokens_est": 40, "n_tiles": 1, "output_text": " baseball cap: 1, baseball glove: 1, baseball: 1, baseball bat: 0, baseball field: 0, baseball bat: 0, baseball field: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.3, "ram_available_mb": 109089.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13442.8, "ram_available_mb": 109063.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [52.39, 52.39, 52.39, 43.15, 43.15, 43.15, 43.15, 43.15, 51.7, 51.7, 51.7, 51.7, 51.7, 46.34, 46.34, 46.34, 46.34], "power_watts_avg": 48.05, "power_watts_peak": 52.39, "energy_joules_est": 79.31, "sample_count": 17, "duration_seconds": 1.651}, "timestamp": "2026-01-12T10:02:35.302512"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1720.644, "latencies_ms": [1720.644], "images_per_second": 0.581, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The baseball cap is positioned to the left of the baseball glove, which is placed in the center of the image. The glove is located in the foreground of the image, while the cap is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13442.8, "ram_available_mb": 109063.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.5, "ram_available_mb": 109095.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.34, 31.99, 31.99, 31.99, 31.99, 31.99, 50.59, 50.59, 50.59, 50.59, 50.59, 53.66, 53.66, 53.66, 53.66, 53.66, 34.77, 34.77], "power_watts_avg": 44.28, "power_watts_peak": 53.66, "energy_joules_est": 76.21, "sample_count": 18, "duration_seconds": 1.721}, "timestamp": "2026-01-12T10:02:37.129145"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 941.121, "latencies_ms": [941.121], "images_per_second": 1.063, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A baseball glove and a baseball cap are placed on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.5, "ram_available_mb": 109095.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13392.8, "ram_available_mb": 109113.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 56.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 34.93, 34.93, 34.93, 34.93, 34.93, 49.17, 49.17], "power_watts_avg": 37.73, "power_watts_peak": 49.17, "energy_joules_est": 35.52, "sample_count": 10, "duration_seconds": 0.941}, "timestamp": "2026-01-12T10:02:38.142104"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1426.16, "latencies_ms": [1426.16], "images_per_second": 0.701, "prompt_tokens": 1442, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image has a blue baseball cap with a white logo on it, and the baseball glove is brown. The cap is placed on top of the glove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.3, "ram_available_mb": 109123.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13459.6, "ram_available_mb": 109046.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.17, 49.17, 49.17, 51.92, 51.92, 51.92, 51.92, 51.92, 50.76, 50.76, 50.76, 50.76, 50.76, 48.8, 48.8], "power_watts_avg": 50.57, "power_watts_peak": 51.92, "energy_joules_est": 72.14, "sample_count": 15, "duration_seconds": 1.427}, "timestamp": "2026-01-12T10:02:39.662896"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 912.469, "latencies_ms": [912.469], "images_per_second": 1.096, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a red shirt is riding a surfboard on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13459.6, "ram_available_mb": 109046.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13441.3, "ram_available_mb": 109065.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.8, 48.8, 48.8, 36.8, 36.8, 36.8, 36.8, 36.8, 45.83, 45.83], "power_watts_avg": 42.2, "power_watts_peak": 48.8, "energy_joules_est": 38.53, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-12T10:02:40.675975"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2126.103, "latencies_ms": [2126.103], "images_per_second": 0.47, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Water: 1\n6. Sky: 1\n7. Clouds: 1\n8. Surfboard's leash: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13441.3, "ram_available_mb": 109065.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13472.8, "ram_available_mb": 109033.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.83, 45.83, 45.83, 46.59, 46.59, 46.59, 46.59, 46.59, 46.36, 46.36, 46.36, 46.36, 46.36, 44.42, 44.42, 44.42, 44.42, 44.42, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 43.79, "power_watts_peak": 46.59, "energy_joules_est": 93.12, "sample_count": 22, "duration_seconds": 2.127}, "timestamp": "2026-01-12T10:02:42.894147"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1413.04, "latencies_ms": [1413.04], "images_per_second": 0.708, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The surfer is positioned on the left side of the image, with the wave on the right side. The surfer is in the foreground, while the wave is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13453.1, "ram_available_mb": 109053.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13469.6, "ram_available_mb": 109036.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.22, 33.22, 33.22, 33.22, 33.22, 45.19, 45.19, 45.19, 45.19, 45.19, 46.98, 46.98, 46.98, 46.98, 46.98], "power_watts_avg": 41.8, "power_watts_peak": 46.98, "energy_joules_est": 59.1, "sample_count": 15, "duration_seconds": 1.414}, "timestamp": "2026-01-12T10:02:44.461879"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 724.134, "latencies_ms": [724.134], "images_per_second": 1.381, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13461.7, "ram_available_mb": 109044.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13469.7, "ram_available_mb": 109036.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 34.7, 34.7, 45.84, 45.84, 45.84], "power_watts_avg": 38.88, "power_watts_peak": 45.84, "energy_joules_est": 28.17, "sample_count": 8, "duration_seconds": 0.724}, "timestamp": "2026-01-12T10:02:45.272756"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1777.083, "latencies_ms": [1777.083], "images_per_second": 0.563, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a surfer riding a wave in a vibrant blue ocean, with the surfer wearing a red shirt and a yellow surfboard. The lighting is natural and bright, suggesting a sunny day, and the water appears to be clear and clean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13461.9, "ram_available_mb": 109044.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13464.6, "ram_available_mb": 109041.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.84, 45.84, 44.58, 44.58, 44.58, 44.58, 44.58, 46.77, 46.77, 46.77, 46.77, 46.77, 48.76, 48.76, 48.76, 48.76, 48.76, 34.85], "power_watts_avg": 45.95, "power_watts_peak": 48.76, "energy_joules_est": 81.67, "sample_count": 18, "duration_seconds": 1.777}, "timestamp": "2026-01-12T10:02:47.090133"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 990.928, "latencies_ms": [990.928], "images_per_second": 1.009, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A black and white photo of a bathroom with a toilet, sink, and a mirror above the sink.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13460.6, "ram_available_mb": 109045.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13457.4, "ram_available_mb": 109048.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 41.43, 41.43, 41.43, 41.43, 41.43, 47.13, 47.13], "power_watts_avg": 40.6, "power_watts_peak": 47.13, "energy_joules_est": 40.24, "sample_count": 10, "duration_seconds": 0.991}, "timestamp": "2026-01-12T10:02:48.102900"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1375.465, "latencies_ms": [1375.465], "images_per_second": 0.727, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " toilet: 1, sink: 1, mirror: 1, cup: 1, bottle: 1, cupboard: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13453.5, "ram_available_mb": 109052.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13372.2, "ram_available_mb": 109134.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.13, 47.13, 47.13, 47.64, 47.64, 47.64, 47.64, 47.64, 47.43, 47.43, 47.43, 47.43, 47.43, 41.22], "power_watts_avg": 47.0, "power_watts_peak": 47.64, "energy_joules_est": 64.66, "sample_count": 14, "duration_seconds": 1.376}, "timestamp": "2026-01-12T10:02:49.517205"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1315.546, "latencies_ms": [1315.546], "images_per_second": 0.76, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the sink is on the right side. The sink is positioned closer to the camera than the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.2, "ram_available_mb": 109134.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13432.1, "ram_available_mb": 109074.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [41.22, 41.22, 41.22, 41.22, 44.29, 44.29, 44.29, 44.29, 44.29, 47.31, 47.31, 47.31, 47.31, 47.31], "power_watts_avg": 44.49, "power_watts_peak": 47.31, "energy_joules_est": 58.55, "sample_count": 14, "duration_seconds": 1.316}, "timestamp": "2026-01-12T10:02:50.928965"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 722.183, "latencies_ms": [722.183], "images_per_second": 1.385, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A bathroom with a toilet, sink, and mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13432.1, "ram_available_mb": 109074.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13423.8, "ram_available_mb": 109082.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [36.64, 36.64, 36.64, 36.64, 36.64, 46.08, 46.08, 46.08], "power_watts_avg": 40.18, "power_watts_peak": 46.08, "energy_joules_est": 29.03, "sample_count": 8, "duration_seconds": 0.722}, "timestamp": "2026-01-12T10:02:51.737689"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 877.167, "latencies_ms": [877.167], "images_per_second": 1.14, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The bathroom is black and white, with a granite countertop and a white toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.8, "ram_available_mb": 109082.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13411.9, "ram_available_mb": 109094.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.08, 46.08, 46.8, 46.8, 46.8, 46.8, 46.8, 46.67, 46.67], "power_watts_avg": 46.61, "power_watts_peak": 46.8, "energy_joules_est": 40.9, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-12T10:02:52.648094"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1487.561, "latencies_ms": [1487.561], "images_per_second": 0.672, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a picturesque scene of a white clock tower with a blue dome, standing tall against the backdrop of a clear blue sky, with a white ornate structure adorned with intricate designs in the foreground.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13404.0, "ram_available_mb": 109102.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.8, "ram_available_mb": 109163.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.67, 46.67, 46.67, 51.46, 51.46, 51.46, 51.46, 51.46, 47.26, 47.26, 47.26, 47.26, 47.26, 43.3, 43.3], "power_watts_avg": 48.01, "power_watts_peak": 51.46, "energy_joules_est": 71.45, "sample_count": 15, "duration_seconds": 1.488}, "timestamp": "2026-01-12T10:02:54.163574"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2042.659, "latencies_ms": [2042.659], "images_per_second": 0.49, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. clock tower: 1\n2. roof tiles: 1\n3. gazebo: 1\n4. clock face: 1\n5. antenna: 1\n6. roof: 1\n7. tree: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.8, "ram_available_mb": 109163.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.2, "ram_available_mb": 109124.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.3, 43.3, 43.3, 38.66, 38.66, 38.66, 38.66, 38.66, 47.54, 47.54, 47.54, 47.54, 47.54, 43.92, 43.92, 43.92, 43.92, 43.92, 34.82, 34.82, 34.82], "power_watts_avg": 42.14, "power_watts_peak": 47.54, "energy_joules_est": 86.09, "sample_count": 21, "duration_seconds": 2.043}, "timestamp": "2026-01-12T10:02:56.279373"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1563.406, "latencies_ms": [1563.406], "images_per_second": 0.64, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The clock tower is positioned in the background, far away from the camera, and is surrounded by a clear blue sky. The ornate white and blue clock face is prominently displayed in the foreground, close to the camera.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13382.2, "ram_available_mb": 109124.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13469.0, "ram_available_mb": 109037.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.82, 31.46, 31.46, 31.46, 31.46, 31.46, 45.68, 45.68, 45.68, 45.68, 45.68, 49.38, 49.38, 49.38, 49.38, 49.38], "power_watts_avg": 41.71, "power_watts_peak": 49.38, "energy_joules_est": 65.26, "sample_count": 16, "duration_seconds": 1.564}, "timestamp": "2026-01-12T10:02:57.945624"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2268.842, "latencies_ms": [2268.842], "images_per_second": 0.441, "prompt_tokens": 1111, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a picturesque scene of a clock tower standing majestically against the backdrop of a clear blue sky. The tower, painted in pristine white, is adorned with a vibrant green roof and a clock face that stands out against its white facade. The tower is nestled amidst a lush green landscape, adding a touch of serenity to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13469.0, "ram_available_mb": 109037.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13437.5, "ram_available_mb": 109068.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 34.85, 34.85, 47.28, 47.28, 47.28, 47.28, 47.28, 47.26, 47.26, 47.26, 47.26, 47.26, 35.01, 35.01, 35.01, 35.01, 35.01, 34.97, 34.97, 34.97], "power_watts_avg": 40.3, "power_watts_peak": 47.28, "energy_joules_est": 91.46, "sample_count": 23, "duration_seconds": 2.269}, "timestamp": "2026-01-12T10:03:00.263785"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1878.361, "latencies_ms": [1878.361], "images_per_second": 0.532, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a white clock tower with a blue dome against a clear blue sky. The tower is adorned with a white railing and has a clock face on each side. The roof is covered in terracotta tiles, and the surrounding area is lush with green trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13433.5, "ram_available_mb": 109072.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13413.5, "ram_available_mb": 109092.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.97, 31.6, 31.6, 31.6, 31.6, 31.6, 46.07, 46.07, 46.07, 46.07, 46.07, 49.7, 49.7, 49.7, 49.7, 49.7, 34.79, 34.79, 34.79], "power_watts_avg": 40.85, "power_watts_peak": 49.7, "energy_joules_est": 76.76, "sample_count": 19, "duration_seconds": 1.879}, "timestamp": "2026-01-12T10:03:02.230486"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1244.541, "latencies_ms": [1244.541], "images_per_second": 0.804, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of elephants is seen walking on a dirt path in a forest, with one elephant in the foreground and others in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.5, "ram_available_mb": 109092.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13416.9, "ram_available_mb": 109089.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 32.19, 32.19, 32.19, 32.19, 32.19, 46.52, 46.52, 46.52, 46.52, 46.52, 49.06], "power_watts_avg": 39.4, "power_watts_peak": 49.06, "energy_joules_est": 49.09, "sample_count": 13, "duration_seconds": 1.246}, "timestamp": "2026-01-12T10:03:03.595287"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1459.872, "latencies_ms": [1459.872], "images_per_second": 0.685, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.0, "ram_available_mb": 109093.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13397.2, "ram_available_mb": 109109.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.06, 49.06, 49.06, 49.06, 40.9, 40.9, 40.9, 40.9, 46.64, 46.64, 46.64, 46.64, 46.64, 40.72, 40.72], "power_watts_avg": 44.96, "power_watts_peak": 49.06, "energy_joules_est": 65.65, "sample_count": 15, "duration_seconds": 1.46}, "timestamp": "2026-01-12T10:03:05.109989"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1299.954, "latencies_ms": [1299.954], "images_per_second": 0.769, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking on a dirt path, with trees and bushes on either side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.3, "ram_available_mb": 109117.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.3, "ram_available_mb": 109098.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.72, 40.72, 40.72, 40.74, 40.74, 40.74, 40.74, 40.74, 46.95, 46.95, 46.95, 46.95, 46.95], "power_watts_avg": 43.12, "power_watts_peak": 46.95, "energy_joules_est": 56.07, "sample_count": 13, "duration_seconds": 1.3}, "timestamp": "2026-01-12T10:03:06.422596"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.501, "latencies_ms": [1116.501], "images_per_second": 0.896, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A herd of elephants is walking through a forest, with one elephant in the foreground and the rest of the herd in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.4, "ram_available_mb": 109105.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13318.8, "ram_available_mb": 109187.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.23, 41.23, 41.23, 41.23, 41.23, 47.97, 47.97, 47.97, 47.97, 47.97, 47.7, 47.7], "power_watts_avg": 45.12, "power_watts_peak": 47.97, "energy_joules_est": 50.39, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T10:03:07.632750"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 845.893, "latencies_ms": [845.893], "images_per_second": 1.182, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The elephants are gray, the trees are green, and the ground is brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.8, "ram_available_mb": 109187.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13374.0, "ram_available_mb": 109132.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.7, 47.7, 47.7, 38.97, 38.97, 38.97, 38.97, 38.97, 46.62], "power_watts_avg": 42.73, "power_watts_peak": 47.7, "energy_joules_est": 36.17, "sample_count": 9, "duration_seconds": 0.847}, "timestamp": "2026-01-12T10:03:08.545473"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1180.895, "latencies_ms": [1180.895], "images_per_second": 0.847, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " An open refrigerator with no food inside, a bottle of yellow liquid on the top shelf, and a carton of eggs on the middle shelf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.1, "ram_available_mb": 109140.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.7, "ram_available_mb": 109123.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.62, 46.62, 46.62, 46.62, 51.04, 51.04, 51.04, 51.04, 51.04, 46.96, 46.96, 46.96], "power_watts_avg": 48.55, "power_watts_peak": 51.04, "energy_joules_est": 57.35, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-12T10:03:09.760422"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2057.399, "latencies_ms": [2057.399], "images_per_second": 0.486, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Refrigerator: 1\n2. Egg carton: 1\n3. Bottle: 1\n4. Shelves: 4\n5. Drawers: 4\n6. Floor: 1\n7. Light: 1\n8. Door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.8, "ram_available_mb": 109131.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13367.6, "ram_available_mb": 109138.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.96, 46.96, 38.66, 38.66, 38.66, 38.66, 38.66, 47.91, 47.91, 47.91, 47.91, 47.91, 48.4, 48.4, 48.4, 48.4, 48.4, 34.81, 34.81, 34.81, 34.81], "power_watts_avg": 43.24, "power_watts_peak": 48.4, "energy_joules_est": 88.98, "sample_count": 21, "duration_seconds": 2.058}, "timestamp": "2026-01-12T10:03:11.877753"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1720.067, "latencies_ms": [1720.067], "images_per_second": 0.581, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The refrigerator is located in the kitchen, with the left side of the door being closer to the camera than the right side. The bottle of mustard is placed on the top shelf of the refrigerator, which is positioned in the middle of the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.0, "ram_available_mb": 109145.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13377.0, "ram_available_mb": 109129.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.6, 33.6, 33.6, 33.6, 33.6, 46.25, 46.25, 46.25, 46.25, 46.25, 47.29, 47.29, 47.29, 47.29, 47.29, 34.73, 34.73, 34.73], "power_watts_avg": 41.1, "power_watts_peak": 47.29, "energy_joules_est": 70.73, "sample_count": 18, "duration_seconds": 1.721}, "timestamp": "2026-01-12T10:03:13.744711"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2301.814, "latencies_ms": [2301.814], "images_per_second": 0.434, "prompt_tokens": 1112, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The image captures a moment in a kitchen, where an open refrigerator stands as a testament to the day's culinary endeavors. The refrigerator, a symbol of domestic life, is filled with the remnants of meals, each item telling a story of the day's activities. The light from the kitchen illuminates the interior, casting a warm glow on the contents of the fridge.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 13377.0, "ram_available_mb": 109129.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13455.9, "ram_available_mb": 109050.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.31, 34.31, 34.31, 34.31, 34.31, 46.57, 46.57, 46.57, 46.57, 46.57, 47.38, 47.38, 47.38, 47.38, 47.38, 35.08, 35.08, 35.08, 35.08, 35.08, 35.03], "power_watts_avg": 40.05, "power_watts_peak": 47.38, "energy_joules_est": 92.2, "sample_count": 23, "duration_seconds": 2.302}, "timestamp": "2026-01-12T10:03:16.058989"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 713.176, "latencies_ms": [713.176], "images_per_second": 1.402, "prompt_tokens": 1110, "response_tokens_est": 11, "n_tiles": 1, "output_text": " The refrigerator is white and has a light on inside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13455.9, "ram_available_mb": 109050.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13455.9, "ram_available_mb": 109050.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 40.69, 40.69, 40.69, 40.69, 40.69], "power_watts_avg": 38.57, "power_watts_peak": 40.69, "energy_joules_est": 27.54, "sample_count": 8, "duration_seconds": 0.714}, "timestamp": "2026-01-12T10:03:16.919088"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 917.975, "latencies_ms": [917.975], "images_per_second": 1.089, "prompt_tokens": 1432, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A bunch of bananas are on a table with a purple background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13455.9, "ram_available_mb": 109050.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13354.9, "ram_available_mb": 109151.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.78, 45.78, 45.78, 45.78, 45.78, 51.91, 51.91, 51.91, 51.91, 51.91], "power_watts_avg": 48.85, "power_watts_peak": 51.91, "energy_joules_est": 44.89, "sample_count": 10, "duration_seconds": 0.919}, "timestamp": "2026-01-12T10:03:17.940695"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 671.068, "latencies_ms": [671.068], "images_per_second": 1.49, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 6", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13339.1, "ram_available_mb": 109167.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13398.0, "ram_available_mb": 109108.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [49.77, 49.77, 49.77, 49.77, 49.77, 49.98, 49.98], "power_watts_avg": 49.83, "power_watts_peak": 49.98, "energy_joules_est": 33.48, "sample_count": 7, "duration_seconds": 0.672}, "timestamp": "2026-01-12T10:03:18.656652"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1857.854, "latencies_ms": [1857.854], "images_per_second": 0.538, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The bananas are located in the foreground of the image, with a purple object in the background. The bananas are arranged in a row, with the leftmost banana being the closest to the viewer and the rightmost banana being the farthest away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.0, "ram_available_mb": 109108.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.2, "ram_available_mb": 109124.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [49.98, 49.98, 49.98, 53.17, 53.17, 53.17, 53.17, 53.17, 56.61, 56.61, 56.61, 56.61, 56.61, 50.06, 50.06, 50.06, 50.06, 50.06, 34.95], "power_watts_avg": 51.79, "power_watts_peak": 56.61, "energy_joules_est": 96.25, "sample_count": 19, "duration_seconds": 1.858}, "timestamp": "2026-01-12T10:03:20.579947"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 922.231, "latencies_ms": [922.231], "images_per_second": 1.084, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A bunch of bananas are on a table with a purple background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.4, "ram_available_mb": 109131.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13382.0, "ram_available_mb": 109124.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.95, 34.95, 34.95, 36.51, 36.51, 36.51, 36.51, 36.51, 49.9, 49.9], "power_watts_avg": 38.72, "power_watts_peak": 49.9, "energy_joules_est": 35.75, "sample_count": 10, "duration_seconds": 0.923}, "timestamp": "2026-01-12T10:03:21.647736"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 994.275, "latencies_ms": [994.275], "images_per_second": 1.006, "prompt_tokens": 1442, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and they are placed on a purple surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.0, "ram_available_mb": 109124.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13397.5, "ram_available_mb": 109108.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.9, 49.9, 49.9, 50.08, 50.08, 50.08, 50.08, 50.08, 50.26, 50.26], "power_watts_avg": 50.06, "power_watts_peak": 50.26, "energy_joules_est": 49.8, "sample_count": 10, "duration_seconds": 0.995}, "timestamp": "2026-01-12T10:03:22.663780"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1234.597, "latencies_ms": [1234.597], "images_per_second": 0.81, "prompt_tokens": 1432, "response_tokens_est": 25, "n_tiles": 1, "output_text": " Three orange cylindrical bollards are standing in a row on a sidewalk, with a city street and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.8, "ram_available_mb": 109107.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13389.2, "ram_available_mb": 109117.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [50.26, 50.26, 50.26, 51.8, 51.8, 51.8, 51.8, 51.8, 51.62, 51.62, 51.62, 51.62, 51.62], "power_watts_avg": 51.38, "power_watts_peak": 51.8, "energy_joules_est": 63.47, "sample_count": 13, "duration_seconds": 1.235}, "timestamp": "2026-01-12T10:03:23.981497"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2156.826, "latencies_ms": [2156.826], "images_per_second": 0.464, "prompt_tokens": 1446, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Bollards: 4\n2. Trees: 2\n3. Buildings: 4\n4. Street: 1\n5. Cars: 1\n6. Banners: 1\n7. Sign: 1\n8. Snow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.3, "ram_available_mb": 109125.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.2, "ram_available_mb": 109133.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.74, 49.74, 49.74, 49.74, 49.74, 44.32, 44.32, 44.32, 44.32, 44.32, 50.95, 50.95, 50.95, 50.95, 50.95, 42.13, 42.13, 42.13, 42.13, 42.13, 34.86, 34.86], "power_watts_avg": 45.7, "power_watts_peak": 50.95, "energy_joules_est": 98.59, "sample_count": 22, "duration_seconds": 2.157}, "timestamp": "2026-01-12T10:03:26.202738"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1728.359, "latencies_ms": [1728.359], "images_per_second": 0.579, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The three orange bollards are positioned in the foreground, with the city buildings in the background. The bollards are located on the left side of the image, while the buildings extend across the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.3, "ram_available_mb": 109141.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13380.6, "ram_available_mb": 109125.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 32.02, 32.02, 32.02, 32.02, 32.02, 50.07, 50.07, 50.07, 50.07, 50.07, 53.39, 53.39, 53.39, 53.39, 53.39, 34.79], "power_watts_avg": 43.44, "power_watts_peak": 53.39, "energy_joules_est": 75.13, "sample_count": 18, "duration_seconds": 1.73}, "timestamp": "2026-01-12T10:03:28.071798"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1615.886, "latencies_ms": [1615.886], "images_per_second": 0.619, "prompt_tokens": 1444, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a bustling city square with a row of orange bollards standing in the foreground, while a large building with a sign that reads \"WGN\" is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.7, "ram_available_mb": 109129.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13391.7, "ram_available_mb": 109114.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.79, 34.79, 39.95, 39.95, 39.95, 39.95, 39.95, 50.21, 50.21, 50.21, 50.21, 50.21, 45.28, 45.28, 45.28], "power_watts_avg": 42.7, "power_watts_peak": 50.21, "energy_joules_est": 69.02, "sample_count": 17, "duration_seconds": 1.616}, "timestamp": "2026-01-12T10:03:29.791507"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1326.023, "latencies_ms": [1326.023], "images_per_second": 0.754, "prompt_tokens": 1442, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a city square with a row of orange bollards, a clear blue sky, and a few trees with bare branches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.9, "ram_available_mb": 109122.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13361.1, "ram_available_mb": 109145.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [45.28, 45.28, 31.11, 31.11, 31.11, 31.11, 31.11, 50.4, 50.4, 50.4, 50.4, 50.4, 54.03, 54.03], "power_watts_avg": 43.3, "power_watts_peak": 54.03, "energy_joules_est": 57.44, "sample_count": 14, "duration_seconds": 1.327}, "timestamp": "2026-01-12T10:03:31.205006"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1132.581, "latencies_ms": [1132.581], "images_per_second": 0.883, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person wearing a helmet and a yellow shirt is riding a horse in a cart on a dirt track.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.1, "ram_available_mb": 109145.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13354.9, "ram_available_mb": 109151.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [54.03, 54.03, 33.45, 33.45, 33.45, 33.45, 33.45, 50.43, 50.43, 50.43, 50.43, 50.43], "power_watts_avg": 43.96, "power_watts_peak": 54.03, "energy_joules_est": 49.82, "sample_count": 12, "duration_seconds": 1.133}, "timestamp": "2026-01-12T10:03:32.425708"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2085.616, "latencies_ms": [2085.616], "images_per_second": 0.479, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. horse: 1\n3. cart: 1\n4. helmet: 1\n5. number: 1\n6. grass: 1\n7. dirt: 1\n8. sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.9, "ram_available_mb": 109151.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13378.3, "ram_available_mb": 109128.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [51.27, 51.27, 51.27, 51.27, 51.27, 45.52, 45.52, 45.52, 45.52, 45.52, 51.43, 51.43, 51.43, 51.43, 51.43, 39.66, 39.66, 39.66, 39.66, 39.66, 34.88], "power_watts_avg": 46.4, "power_watts_peak": 51.43, "energy_joules_est": 96.78, "sample_count": 21, "duration_seconds": 2.086}, "timestamp": "2026-01-12T10:03:34.548716"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1570.604, "latencies_ms": [1570.604], "images_per_second": 0.637, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The horse is in the foreground, pulling the cart, while the rider is in the background. The cart is in the middle of the track, and the rider is wearing a helmet.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13385.9, "ram_available_mb": 109120.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 38.44, 38.44, 38.44, 38.44, 50.09, 50.09, 50.09, 50.09, 50.09, 46.82, 46.82, 46.82], "power_watts_avg": 42.76, "power_watts_peak": 50.09, "energy_joules_est": 67.2, "sample_count": 16, "duration_seconds": 1.572}, "timestamp": "2026-01-12T10:03:36.219304"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1075.518, "latencies_ms": [1075.518], "images_per_second": 0.93, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A young man is riding a horse in a dirt track. The horse is pulling a cart.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.0, "ram_available_mb": 109124.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13375.8, "ram_available_mb": 109130.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 4.0}, "power_stats": {"power_watts_samples": [46.82, 46.82, 34.34, 34.34, 34.34, 34.34, 34.34, 51.03, 51.03, 51.03, 51.03], "power_watts_avg": 42.68, "power_watts_peak": 51.03, "energy_joules_est": 45.92, "sample_count": 11, "duration_seconds": 1.076}, "timestamp": "2026-01-12T10:03:37.332071"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2001.052, "latencies_ms": [2001.052], "images_per_second": 0.5, "prompt_tokens": 1442, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a brown horse pulling a cart with a person wearing a helmet and a yellow shirt. The horse is running on a dirt track, and the background includes a green field and a fence. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.9, "ram_available_mb": 109134.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13379.5, "ram_available_mb": 109126.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [51.03, 50.72, 50.72, 50.72, 50.72, 50.72, 51.42, 51.42, 51.42, 51.42, 51.42, 52.55, 52.55, 52.55, 52.55, 52.55, 34.82, 34.82, 34.82, 34.82], "power_watts_avg": 48.19, "power_watts_peak": 52.55, "energy_joules_est": 96.46, "sample_count": 20, "duration_seconds": 2.002}, "timestamp": "2026-01-12T10:03:39.350179"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 981.927, "latencies_ms": [981.927], "images_per_second": 1.018, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog is standing on a wooden platform in a backyard with a tree full of oranges behind it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13371.6, "ram_available_mb": 109134.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.82, 33.87, 33.87, 33.87, 33.87, 33.87, 47.71, 47.71, 47.71, 47.71], "power_watts_avg": 39.5, "power_watts_peak": 47.71, "energy_joules_est": 38.81, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T10:03:40.365197"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1905.001, "latencies_ms": [1905.001], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. dog: 1\n2. fence: 1\n3. tree: 1\n4. ground: 1\n5. bench: 1\n6. leaves: 1\n7. grass: 1\n8. house: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13346.9, "ram_available_mb": 109159.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.71, 48.02, 48.02, 48.02, 48.02, 48.02, 47.58, 47.58, 47.58, 47.58, 47.58, 49.28, 49.28, 49.28, 49.28, 49.28, 34.92, 34.92, 34.92], "power_watts_avg": 46.15, "power_watts_peak": 49.28, "energy_joules_est": 87.94, "sample_count": 19, "duration_seconds": 1.906}, "timestamp": "2026-01-12T10:03:42.283599"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1655.207, "latencies_ms": [1655.207], "images_per_second": 0.604, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The dog is standing on the left side of the image, with the tree on the right side. The dog is in the foreground, while the tree is in the background. The dog is closer to the camera than the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.9, "ram_available_mb": 109159.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13355.5, "ram_available_mb": 109150.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.92, 32.52, 32.52, 32.52, 32.52, 32.52, 47.12, 47.12, 47.12, 47.12, 47.12, 49.05, 49.05, 49.05, 49.05, 49.05, 34.62], "power_watts_avg": 41.94, "power_watts_peak": 49.05, "energy_joules_est": 69.44, "sample_count": 17, "duration_seconds": 1.656}, "timestamp": "2026-01-12T10:03:44.049500"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 929.98, "latencies_ms": [929.98], "images_per_second": 1.075, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A brown dog is standing on a wooden platform in a backyard with a tree full of oranges.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.5, "ram_available_mb": 109150.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13438.5, "ram_available_mb": 109067.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 34.62, 43.83, 43.83, 43.83, 43.83, 43.83, 47.23], "power_watts_avg": 40.48, "power_watts_peak": 47.23, "energy_joules_est": 37.66, "sample_count": 10, "duration_seconds": 0.93}, "timestamp": "2026-01-12T10:03:45.059596"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 976.906, "latencies_ms": [976.906], "images_per_second": 1.024, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The dog is brown, the fence is brown, the tree is green, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13438.5, "ram_available_mb": 109067.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13430.6, "ram_available_mb": 109075.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 47.23, 46.37, 46.37, 46.37, 46.37, 46.37, 46.65], "power_watts_avg": 46.74, "power_watts_peak": 47.23, "energy_joules_est": 45.68, "sample_count": 10, "duration_seconds": 0.977}, "timestamp": "2026-01-12T10:03:46.071858"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1831.575, "latencies_ms": [1831.575], "images_per_second": 0.546, "prompt_tokens": 1099, "response_tokens_est": 53, "n_tiles": 1, "output_text": " In the image, a person is standing on a wooden bench with their feet on a sign that reads \"WE'RE HERE TO BE STRONG\". The bench is placed on a brick floor, and the background features a gray wall with a blue and white sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.6, "ram_available_mb": 109075.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13326.5, "ram_available_mb": 109179.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.65, 46.65, 46.65, 46.65, 46.8, 46.8, 46.8, 46.8, 46.8, 47.37, 47.37, 47.37, 47.37, 47.37, 40.02, 40.02, 40.02, 40.02, 40.02], "power_watts_avg": 45.13, "power_watts_peak": 47.37, "energy_joules_est": 82.68, "sample_count": 19, "duration_seconds": 1.832}, "timestamp": "2026-01-12T10:03:47.990817"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1074.484, "latencies_ms": [1074.484], "images_per_second": 0.931, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " bench: 1, person: 1, paper: 1, shoe: 1, brick: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.6, "ram_available_mb": 109187.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.0, "ram_available_mb": 109155.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 34.92, 42.41, 42.41, 42.41, 42.41, 42.41, 45.23, 45.23], "power_watts_avg": 40.2, "power_watts_peak": 45.23, "energy_joules_est": 43.22, "sample_count": 11, "duration_seconds": 1.075}, "timestamp": "2026-01-12T10:03:49.154613"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2189.786, "latencies_ms": [2189.786], "images_per_second": 0.457, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The bench is positioned in the foreground, with the person's legs and feet prominently displayed. The sign is placed to the left of the bench, suggesting it is a temporary or makeshift setup. The person's legs are positioned on the bench, with their feet resting on the edge, indicating they are either sitting or standing on the bench.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.23, 45.23, 45.23, 42.72, 42.72, 42.72, 42.72, 42.72, 47.65, 47.65, 47.65, 47.65, 47.65, 42.85, 42.85, 42.85, 42.85, 42.85, 35.07, 35.07, 35.07, 35.07], "power_watts_avg": 42.82, "power_watts_peak": 47.65, "energy_joules_est": 93.78, "sample_count": 22, "duration_seconds": 2.19}, "timestamp": "2026-01-12T10:03:51.370381"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1943.209, "latencies_ms": [1943.209], "images_per_second": 0.515, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " A person wearing bright orange pants and blue and yellow shoes is standing on a wooden bench. The bench is made of two wooden posts and a wooden plank. There is a piece of paper on the bench with the words \"WE'RE\" and \"WITH\" written on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.1, "ram_available_mb": 109174.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.5, "ram_available_mb": 109166.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.87, 33.87, 33.87, 33.87, 33.87, 46.65, 46.65, 46.65, 46.65, 46.65, 47.94, 47.94, 47.94, 47.94, 47.94, 34.77, 34.77, 34.77, 34.77, 34.77], "power_watts_avg": 40.81, "power_watts_peak": 47.94, "energy_joules_est": 79.32, "sample_count": 20, "duration_seconds": 1.944}, "timestamp": "2026-01-12T10:03:53.437286"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2228.284, "latencies_ms": [2228.284], "images_per_second": 0.449, "prompt_tokens": 1109, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image features a wooden bench with a person's legs and feet on it, wearing bright orange pants and blue and yellow shoes. The bench is placed on a brick floor, and the background is a plain white wall. The lighting in the image is natural, coming from the left side, casting shadows on the right side of the bench.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.5, "ram_available_mb": 109166.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13340.3, "ram_available_mb": 109166.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.0, 34.0, 34.0, 34.0, 34.0, 45.17, 45.17, 45.17, 45.17, 45.17, 46.65, 46.65, 46.65, 46.65, 46.65, 35.28, 35.28, 35.28, 35.28, 35.28, 34.74, 34.74, 34.74], "power_watts_avg": 39.55, "power_watts_peak": 46.65, "energy_joules_est": 88.17, "sample_count": 23, "duration_seconds": 2.229}, "timestamp": "2026-01-12T10:03:55.810049"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1253.782, "latencies_ms": [1253.782], "images_per_second": 0.798, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a red sofa, a dining table set with a white tablecloth, and a television mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13330.0, "ram_available_mb": 109176.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.8, "ram_available_mb": 109160.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [34.74, 31.14, 31.14, 31.14, 31.14, 31.14, 45.23, 45.23, 45.23, 45.23, 45.23, 48.3, 48.3], "power_watts_avg": 39.47, "power_watts_peak": 48.3, "energy_joules_est": 49.53, "sample_count": 13, "duration_seconds": 1.255}, "timestamp": "2026-01-12T10:03:57.177365"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1964.844, "latencies_ms": [1964.844], "images_per_second": 0.509, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. red sofa: 1\n2. table: 1\n3. chairs: 2\n4. lamp: 2\n5. vase: 1\n6. curtains: 2\n7. television: 1\n8. picture: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13337.9, "ram_available_mb": 109168.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.0, "ram_available_mb": 109165.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.3, 48.3, 48.3, 38.29, 38.29, 38.29, 38.29, 38.29, 47.13, 47.13, 47.13, 47.13, 47.13, 44.35, 44.35, 44.35, 44.35, 44.35, 34.77, 34.77], "power_watts_avg": 43.16, "power_watts_peak": 48.3, "energy_joules_est": 84.84, "sample_count": 20, "duration_seconds": 1.965}, "timestamp": "2026-01-12T10:03:59.195677"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1622.836, "latencies_ms": [1622.836], "images_per_second": 0.616, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The red sofa is located on the left side of the room, with the dining table and chairs situated in the middle. The television is positioned on the right side of the room, with the window and curtains behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.0, "ram_available_mb": 109169.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13337.0, "ram_available_mb": 109169.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.32, 34.32, 34.32, 34.32, 34.32, 45.88, 45.88, 45.88, 45.88, 45.88, 47.18, 47.18, 47.18, 47.18, 47.18], "power_watts_avg": 41.56, "power_watts_peak": 47.18, "energy_joules_est": 67.49, "sample_count": 17, "duration_seconds": 1.624}, "timestamp": "2026-01-12T10:04:00.962262"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1399.755, "latencies_ms": [1399.755], "images_per_second": 0.714, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a red sofa, a dining table set with a white tablecloth and silverware, and a flat screen TV mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13340.2, "ram_available_mb": 109166.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 34.11, 34.11, 46.38, 46.38, 46.38, 46.38, 46.38, 46.87, 46.87, 46.87, 46.87], "power_watts_avg": 42.14, "power_watts_peak": 46.87, "energy_joules_est": 59.01, "sample_count": 14, "duration_seconds": 1.4}, "timestamp": "2026-01-12T10:04:02.377821"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1595.61, "latencies_ms": [1595.61], "images_per_second": 0.627, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The room is bathed in warm sunlight, casting a soft glow on the furnishings. The walls are painted a soothing light yellow, and the furniture is made of wood, giving the room a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.2, "ram_available_mb": 109166.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13344.6, "ram_available_mb": 109161.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.87, 33.68, 33.68, 33.68, 33.68, 33.68, 47.4, 47.4, 47.4, 47.4, 47.4, 48.44, 48.44, 48.44, 48.44, 48.44], "power_watts_avg": 43.41, "power_watts_peak": 48.44, "energy_joules_est": 69.28, "sample_count": 16, "duration_seconds": 1.596}, "timestamp": "2026-01-12T10:04:03.988492"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1047.979, "latencies_ms": [1047.979], "images_per_second": 0.954, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A black frying pan filled with a mixture of broccoli, carrots, and meat is being stirred with a metal spoon.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13344.6, "ram_available_mb": 109161.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13330.4, "ram_available_mb": 109175.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.6, 34.6, 34.6, 34.6, 34.6, 46.33, 46.33, 46.33, 46.33, 46.33, 47.5], "power_watts_avg": 41.1, "power_watts_peak": 47.5, "energy_joules_est": 43.11, "sample_count": 11, "duration_seconds": 1.049}, "timestamp": "2026-01-12T10:04:05.102371"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2127.803, "latencies_ms": [2127.803], "images_per_second": 0.47, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. broccoli: 12\n2. carrots: 10\n3. meat: 12\n4. potatoes: 10\n5. seasoning: 10\n6. broccoli: 12\n7. carrots: 10\n8. meat: 12", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13330.4, "ram_available_mb": 109175.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13338.3, "ram_available_mb": 109168.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.5, 47.5, 47.5, 47.5, 43.4, 43.4, 43.4, 43.4, 43.4, 46.76, 46.76, 46.76, 46.76, 40.23, 40.23, 40.23, 40.23, 40.23, 34.81, 34.81, 34.81, 34.81], "power_watts_avg": 42.47, "power_watts_peak": 47.5, "energy_joules_est": 90.4, "sample_count": 22, "duration_seconds": 2.128}, "timestamp": "2026-01-12T10:04:07.324038"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1539.128, "latencies_ms": [1539.128], "images_per_second": 0.65, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The broccoli is in the middle of the pan, the carrots are on the right side, and the meat is on the left side. The pan is in the foreground, and the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.3, "ram_available_mb": 109172.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.3, "ram_available_mb": 109172.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.81, 31.43, 31.43, 31.43, 31.43, 31.43, 45.28, 45.28, 45.28, 45.28, 45.28, 48.92, 48.92, 48.92, 48.92, 48.92], "power_watts_avg": 41.44, "power_watts_peak": 48.92, "energy_joules_est": 63.8, "sample_count": 16, "duration_seconds": 1.54}, "timestamp": "2026-01-12T10:04:08.991617"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 745.319, "latencies_ms": [745.319], "images_per_second": 1.342, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A black pan with food in it on a stove top.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.5, "ram_available_mb": 109179.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13350.1, "ram_available_mb": 109156.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.76, 34.76, 34.76, 34.76, 34.76, 46.34, 46.34, 46.34], "power_watts_avg": 39.1, "power_watts_peak": 46.34, "energy_joules_est": 29.16, "sample_count": 8, "duration_seconds": 0.746}, "timestamp": "2026-01-12T10:04:09.804112"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2080.378, "latencies_ms": [2080.378], "images_per_second": 0.481, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a black frying pan with a variety of vegetables and meat being cooked. The vegetables are in shades of green, orange, and red, while the meat appears to be pink and brown. The lighting in the image is bright and even, suggesting that the photo was taken in a well-lit kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.1, "ram_available_mb": 109156.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.34, 46.34, 44.9, 44.9, 44.9, 44.9, 44.9, 47.57, 47.57, 47.57, 47.57, 49.67, 49.67, 49.67, 49.67, 49.67, 34.97, 34.97, 34.97, 34.97, 34.97], "power_watts_avg": 44.32, "power_watts_peak": 49.67, "energy_joules_est": 92.22, "sample_count": 21, "duration_seconds": 2.081}, "timestamp": "2026-01-12T10:04:11.922584"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 853.46, "latencies_ms": [853.46], "images_per_second": 1.172, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " Three hot dogs with mustard on a brown plate are on a dark countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.1, "ram_available_mb": 109183.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13350.7, "ram_available_mb": 109155.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.48, 34.48, 34.48, 34.48, 34.48, 47.45, 47.45, 47.45, 47.45], "power_watts_avg": 40.24, "power_watts_peak": 47.45, "energy_joules_est": 34.37, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-12T10:04:12.837802"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1030.694, "latencies_ms": [1030.694], "images_per_second": 0.97, "prompt_tokens": 1114, "response_tokens_est": 23, "n_tiles": 1, "output_text": " 1. hot dog bun\n2. hot dog\n3. mustard\n4. plate\n5. book", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.8, "ram_available_mb": 109163.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13350.7, "ram_available_mb": 109155.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.45, 45.42, 45.42, 45.42, 45.42, 45.42, 46.99, 46.99, 46.99, 46.99, 46.99], "power_watts_avg": 46.32, "power_watts_peak": 47.45, "energy_joules_est": 47.77, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-12T10:04:13.951016"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1351.413, "latencies_ms": [1351.413], "images_per_second": 0.74, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The hot dogs are placed on the plate, which is in the foreground, and the book is in the background. The hot dogs are closer to the camera than the book.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.9, "ram_available_mb": 109171.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.8, "ram_available_mb": 109160.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [49.05, 49.05, 49.05, 49.05, 49.05, 46.81, 46.81, 46.81, 46.81, 46.81, 46.89, 46.89, 46.89, 46.89], "power_watts_avg": 47.63, "power_watts_peak": 49.05, "energy_joules_est": 64.39, "sample_count": 14, "duration_seconds": 1.352}, "timestamp": "2026-01-12T10:04:15.366643"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.184, "latencies_ms": [828.184], "images_per_second": 1.207, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three hot dogs with mustard on a plate are on a dark countertop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13341.9, "ram_available_mb": 109164.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.9, "ram_available_mb": 109164.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [46.89, 32.94, 32.94, 32.94, 32.94, 32.94, 47.02, 47.02, 47.02], "power_watts_avg": 39.19, "power_watts_peak": 47.02, "energy_joules_est": 32.49, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-12T10:04:16.278731"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2273.024, "latencies_ms": [2273.024], "images_per_second": 0.44, "prompt_tokens": 1110, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image features a plate with three hot dogs, each topped with mustard, placed on a dark brown plate. The hot dogs are placed in a row, with the mustard drizzled over them. The lighting in the image is bright, and the colors are vibrant, with the mustard being a bright yellow and the hot dogs a reddish-brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.0, "ram_available_mb": 109172.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13337.9, "ram_available_mb": 109168.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.02, 47.02, 47.68, 47.68, 47.68, 47.68, 47.68, 46.42, 46.42, 46.42, 46.42, 46.42, 48.07, 48.07, 48.07, 48.07, 48.07, 34.96, 34.96, 34.96, 34.96, 34.96, 34.9], "power_watts_avg": 44.11, "power_watts_peak": 48.07, "energy_joules_est": 100.29, "sample_count": 23, "duration_seconds": 2.274}, "timestamp": "2026-01-12T10:04:18.598626"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1529.797, "latencies_ms": [1529.797], "images_per_second": 0.654, "prompt_tokens": 1432, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, there are four people swimming in the ocean, with a green umbrella and two chairs placed on the beach, and a bird standing on the sand near the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.0, "ram_available_mb": 109176.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13373.1, "ram_available_mb": 109133.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 37.25, 37.25, 37.25, 37.25, 37.25, 50.37, 50.37, 50.37, 50.37, 50.37, 47.99, 47.99, 47.99], "power_watts_avg": 42.92, "power_watts_peak": 50.37, "energy_joules_est": 65.71, "sample_count": 16, "duration_seconds": 1.531}, "timestamp": "2026-01-12T10:04:20.267718"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 967.876, "latencies_ms": [967.876], "images_per_second": 1.033, "prompt_tokens": 1446, "response_tokens_est": 15, "n_tiles": 1, "output_text": " beach umbrella: 1\nchairs: 2\npeople: 4", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13369.2, "ram_available_mb": 109137.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [47.99, 47.99, 32.49, 32.49, 32.49, 32.49, 32.49, 50.18, 50.18, 50.18], "power_watts_avg": 40.9, "power_watts_peak": 50.18, "energy_joules_est": 39.6, "sample_count": 10, "duration_seconds": 0.968}, "timestamp": "2026-01-12T10:04:21.280082"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2141.631, "latencies_ms": [2141.631], "images_per_second": 0.467, "prompt_tokens": 1450, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The green umbrella is positioned to the right of the beach chairs, which are situated in the foreground of the image. The people are swimming in the water, which is located in the middle ground of the image, while the beach chairs are placed on the sandy beach, which is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13346.2, "ram_available_mb": 109160.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.18, 50.18, 50.52, 50.52, 50.52, 50.52, 50.52, 51.51, 51.51, 51.51, 51.51, 51.51, 53.88, 53.88, 53.88, 53.88, 53.88, 35.08, 35.08, 35.08, 35.08, 35.08], "power_watts_avg": 47.97, "power_watts_peak": 53.88, "energy_joules_est": 102.75, "sample_count": 22, "duration_seconds": 2.142}, "timestamp": "2026-01-12T10:04:23.499467"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1076.452, "latencies_ms": [1076.452], "images_per_second": 0.929, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are swimming in the ocean near a beach with a green umbrella and chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.2, "ram_available_mb": 109160.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.23, 35.23, 35.23, 35.23, 40.81, 40.81, 40.81, 40.81, 40.81, 49.7, 49.7], "power_watts_avg": 40.39, "power_watts_peak": 49.7, "energy_joules_est": 43.52, "sample_count": 11, "duration_seconds": 1.077}, "timestamp": "2026-01-12T10:04:24.668583"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1943.841, "latencies_ms": [1943.841], "images_per_second": 0.514, "prompt_tokens": 1442, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a beach scene with a group of people swimming in the ocean, a green umbrella providing shade, and a beach chair with a pink and blue cover. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13367.4, "ram_available_mb": 109138.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.7, 49.7, 49.7, 46.27, 46.27, 46.27, 46.27, 46.27, 51.41, 51.41, 51.41, 51.41, 51.41, 48.99, 48.99, 48.99, 48.99, 48.99, 34.81, 34.81], "power_watts_avg": 47.6, "power_watts_peak": 51.41, "energy_joules_est": 92.54, "sample_count": 20, "duration_seconds": 1.944}, "timestamp": "2026-01-12T10:04:26.686179"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1355.892, "latencies_ms": [1355.892], "images_per_second": 0.738, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a vintage kitchen with green wallpaper, a white sink, a white refrigerator, and a white table with a glass top, surrounded by various kitchen appliances and utensils.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.7, "ram_available_mb": 109158.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.2, 34.2, 34.2, 34.2, 34.2, 45.81, 45.81, 45.81, 45.81, 45.81, 46.5, 46.5], "power_watts_avg": 40.19, "power_watts_peak": 46.5, "energy_joules_est": 54.55, "sample_count": 14, "duration_seconds": 1.357}, "timestamp": "2026-01-12T10:04:28.155160"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1462.528, "latencies_ms": [1462.528], "images_per_second": 0.684, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " table: 1, chair: 1, sink: 1, refrigerator: 1, stove: 1, oven: 1, cabinet: 1, counter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.3, "ram_available_mb": 109154.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.5, 46.5, 46.5, 39.39, 39.39, 39.39, 39.39, 39.39, 47.15, 47.15, 47.15, 47.15, 47.15, 43.34, 43.34], "power_watts_avg": 43.92, "power_watts_peak": 47.15, "energy_joules_est": 64.26, "sample_count": 15, "duration_seconds": 1.463}, "timestamp": "2026-01-12T10:04:29.669218"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2179.222, "latencies_ms": [2179.222], "images_per_second": 0.459, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The sink is located to the right of the stove, and the refrigerator is positioned to the right of the sink. The table is situated in the center of the room, with the chair placed in front of it. The window is located to the left of the sink, and the door is located to the right of the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.5, "ram_available_mb": 109161.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13339.6, "ram_available_mb": 109166.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.34, 43.34, 43.34, 38.83, 38.83, 38.83, 38.83, 38.83, 47.31, 47.31, 47.31, 47.31, 47.31, 43.24, 43.24, 43.24, 43.24, 43.24, 34.82, 34.82, 34.82, 34.82], "power_watts_avg": 41.64, "power_watts_peak": 47.31, "energy_joules_est": 90.77, "sample_count": 22, "duration_seconds": 2.18}, "timestamp": "2026-01-12T10:04:31.888600"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1431.681, "latencies_ms": [1431.681], "images_per_second": 0.698, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a vintage kitchen with green wallpaper and a variety of appliances. The kitchen is equipped with a sink, a stove, and a refrigerator, all of which are in good condition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.7, "ram_available_mb": 109174.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.71, 33.71, 33.71, 33.71, 33.71, 46.61, 46.61, 46.61, 46.61, 46.61, 47.76, 47.76, 47.76, 47.76, 47.76], "power_watts_avg": 42.69, "power_watts_peak": 47.76, "energy_joules_est": 61.15, "sample_count": 15, "duration_seconds": 1.432}, "timestamp": "2026-01-12T10:04:33.451767"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1257.539, "latencies_ms": [1257.539], "images_per_second": 0.795, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are covered in green wallpaper. The floor is covered in a green and yellow floral carpet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.2, "ram_available_mb": 109153.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.13, 34.13, 34.13, 34.13, 34.13, 46.36, 46.36, 46.36, 46.36, 46.36, 47.19, 47.19, 47.19], "power_watts_avg": 41.85, "power_watts_peak": 47.19, "energy_joules_est": 52.63, "sample_count": 13, "duration_seconds": 1.258}, "timestamp": "2026-01-12T10:04:34.764703"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 975.756, "latencies_ms": [975.756], "images_per_second": 1.025, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A black and white dog is walking on a dirt path with a brown and white toy in its mouth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [47.19, 47.19, 34.52, 34.52, 34.52, 34.52, 34.52, 47.4, 47.4, 47.4], "power_watts_avg": 40.92, "power_watts_peak": 47.4, "energy_joules_est": 39.94, "sample_count": 10, "duration_seconds": 0.976}, "timestamp": "2026-01-12T10:04:35.776659"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1329.569, "latencies_ms": [1329.569], "images_per_second": 0.752, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " dog: 1, tree: 1, leaves: 1, shadow: 1, ground: 1, bark: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.5, "ram_available_mb": 109174.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.4, 47.4, 47.38, 47.38, 47.38, 47.38, 47.38, 47.37, 47.37, 47.37, 47.37, 47.37, 47.9, 47.9], "power_watts_avg": 47.45, "power_watts_peak": 47.9, "energy_joules_est": 63.12, "sample_count": 14, "duration_seconds": 1.33}, "timestamp": "2026-01-12T10:04:37.188436"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1503.638, "latencies_ms": [1503.638], "images_per_second": 0.665, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The dog is in the foreground, walking towards the right side of the image. The tree is in the background, to the left of the dog. The dog is closer to the camera than the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.5, "ram_available_mb": 109174.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.9, 47.9, 47.9, 37.84, 37.84, 37.84, 37.84, 37.84, 46.63, 46.63, 46.63, 46.63, 46.63, 43.88, 43.88], "power_watts_avg": 43.58, "power_watts_peak": 47.9, "energy_joules_est": 65.56, "sample_count": 15, "duration_seconds": 1.504}, "timestamp": "2026-01-12T10:04:38.702530"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1007.996, "latencies_ms": [1007.996], "images_per_second": 0.992, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white dog is walking on a dirt path in a wooded area, sniffing around a tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.0, "ram_available_mb": 109115.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13398.7, "ram_available_mb": 109107.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.88, 43.88, 43.88, 38.88, 38.88, 38.88, 38.88, 38.88, 48.03, 48.03, 48.03], "power_watts_avg": 42.74, "power_watts_peak": 48.03, "energy_joules_est": 43.09, "sample_count": 11, "duration_seconds": 1.008}, "timestamp": "2026-01-12T10:04:39.814131"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 904.913, "latencies_ms": [904.913], "images_per_second": 1.105, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The dog is black and white, the leaves are brown, and the tree is green.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13394.8, "ram_available_mb": 109111.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13379.9, "ram_available_mb": 109126.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.03, 48.03, 42.3, 42.3, 42.3, 42.3, 42.3, 46.42, 46.42, 46.42], "power_watts_avg": 44.68, "power_watts_peak": 48.03, "energy_joules_est": 40.45, "sample_count": 10, "duration_seconds": 0.905}, "timestamp": "2026-01-12T10:04:40.824167"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1033.138, "latencies_ms": [1033.138], "images_per_second": 0.968, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill, wearing a white helmet, a red backpack, and green skis.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13379.9, "ram_available_mb": 109126.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.42, 46.07, 46.07, 46.07, 46.07, 46.07, 46.05, 46.05, 46.05, 46.05, 46.05], "power_watts_avg": 46.09, "power_watts_peak": 46.42, "energy_joules_est": 47.65, "sample_count": 11, "duration_seconds": 1.034}, "timestamp": "2026-01-12T10:04:41.937345"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2001.443, "latencies_ms": [2001.443], "images_per_second": 0.5, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skis: 2\n2. ski poles: 2\n3. backpack: 1\n4. helmet: 1\n5. skier: 1\n6. snow: 1\n7. trees: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.2, "ram_available_mb": 109154.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.36, 48.36, 48.36, 48.36, 48.36, 46.75, 46.75, 46.75, 46.75, 46.75, 47.69, 47.69, 47.69, 47.69, 47.69, 34.74, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 44.38, "power_watts_peak": 48.36, "energy_joules_est": 88.85, "sample_count": 20, "duration_seconds": 2.002}, "timestamp": "2026-01-12T10:04:43.952164"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1589.835, "latencies_ms": [1589.835], "images_per_second": 0.629, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski trail and trees in the background. The skier is moving towards the right side of the image, with the ski trail extending into the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13358.9, "ram_available_mb": 109147.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 34.71, 34.71, 34.71, 47.78, 47.78, 47.78, 47.78, 47.78, 47.93, 47.93, 47.93, 47.93, 47.93, 34.88], "power_watts_avg": 42.93, "power_watts_peak": 47.93, "energy_joules_est": 68.27, "sample_count": 16, "duration_seconds": 1.59}, "timestamp": "2026-01-12T10:04:45.566600"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 799.782, "latencies_ms": [799.782], "images_per_second": 1.25, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.0, "ram_available_mb": 109155.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13362.7, "ram_available_mb": 109143.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 44.01, 44.01, 44.01, 44.01], "power_watts_avg": 39.44, "power_watts_peak": 44.01, "energy_joules_est": 31.57, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-12T10:04:46.377177"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1881.474, "latencies_ms": [1881.474], "images_per_second": 0.531, "prompt_tokens": 1110, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a person skiing down a snowy hill, wearing a white helmet and carrying a red backpack. The sky is clear and blue, indicating a sunny day. The snow is pristine white, and the trees in the background are covered in snow, suggesting a cold environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.8, "ram_available_mb": 109151.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.9, "ram_available_mb": 109155.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.01, 46.84, 46.84, 46.84, 46.84, 46.84, 51.85, 51.85, 51.85, 51.85, 51.85, 48.97, 48.97, 48.97, 48.97, 48.97, 34.91, 34.91, 34.91], "power_watts_avg": 46.69, "power_watts_peak": 51.85, "energy_joules_est": 87.86, "sample_count": 19, "duration_seconds": 1.882}, "timestamp": "2026-01-12T10:04:48.293504"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1169.886, "latencies_ms": [1169.886], "images_per_second": 0.855, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A large orange and black train with the number 6309 on the front is traveling down a track with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13347.0, "ram_available_mb": 109159.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.91, 32.02, 32.02, 32.02, 32.02, 32.02, 46.38, 46.38, 46.38, 46.38, 46.38, 49.53], "power_watts_avg": 39.7, "power_watts_peak": 49.53, "energy_joules_est": 46.49, "sample_count": 12, "duration_seconds": 1.171}, "timestamp": "2026-01-12T10:04:49.559750"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1992.073, "latencies_ms": [1992.073], "images_per_second": 0.502, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. trees: 1\n3. sky: 1\n4. gravel: 1\n5. fence: 1\n6. train number: 1\n7. train engine: 1\n8. train cars: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.53, 49.53, 49.53, 49.53, 43.95, 43.95, 43.95, 43.95, 43.95, 47.5, 47.5, 47.5, 47.5, 47.5, 38.45, 38.45, 38.45, 38.45, 38.45, 34.82], "power_watts_avg": 44.12, "power_watts_peak": 49.53, "energy_joules_est": 87.91, "sample_count": 20, "duration_seconds": 1.992}, "timestamp": "2026-01-12T10:04:51.577486"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1305.971, "latencies_ms": [1305.971], "images_per_second": 0.766, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The main object, the train, is positioned in the foreground, moving from left to right. The trees are located in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.2, "ram_available_mb": 109153.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 34.82, 40.13, 40.13, 40.13, 40.13, 40.13, 46.42, 46.42, 46.42, 46.42, 46.42], "power_watts_avg": 41.33, "power_watts_peak": 46.42, "energy_joules_est": 54.01, "sample_count": 13, "duration_seconds": 1.307}, "timestamp": "2026-01-12T10:04:52.942339"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 991.653, "latencies_ms": [991.653], "images_per_second": 1.008, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A large orange and black train is traveling down a track in a rural area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.2, "ram_available_mb": 109153.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13265.4, "ram_available_mb": 109240.9, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [41.99, 41.99, 41.99, 41.99, 41.99, 48.09, 48.09, 48.09, 48.09, 48.09], "power_watts_avg": 45.04, "power_watts_peak": 48.09, "energy_joules_est": 44.69, "sample_count": 10, "duration_seconds": 0.992}, "timestamp": "2026-01-12T10:04:53.955301"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1774.888, "latencies_ms": [1774.888], "images_per_second": 0.563, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The locomotive is painted in vibrant shades of orange and black, with the number 6309 prominently displayed on the front. The sky is a clear blue, and the trees in the background are bare, suggesting it might be late autumn or winter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13265.4, "ram_available_mb": 109240.9, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13312.0, "ram_available_mb": 109194.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.07, 48.07, 48.07, 48.07, 48.07, 47.71, 47.71, 47.71, 47.71, 47.71, 47.98, 47.98, 47.98, 47.98, 47.98, 34.92, 34.92, 34.92], "power_watts_avg": 45.75, "power_watts_peak": 48.07, "energy_joules_est": 81.23, "sample_count": 18, "duration_seconds": 1.775}, "timestamp": "2026-01-12T10:04:55.772338"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1295.085, "latencies_ms": [1295.085], "images_per_second": 0.772, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a wooden table with a plate containing a slice of bread topped with guacamole, a bowl of broccoli, and a serving of white dip.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13312.0, "ram_available_mb": 109194.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13325.6, "ram_available_mb": 109180.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.84, 34.84, 34.84, 34.84, 34.84, 47.35, 47.35, 47.35, 47.35, 47.35, 47.67], "power_watts_avg": 40.65, "power_watts_peak": 47.67, "energy_joules_est": 52.67, "sample_count": 13, "duration_seconds": 1.296}, "timestamp": "2026-01-12T10:04:57.089670"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1906.456, "latencies_ms": [1906.456], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bread: 2\n3. broccoli: 1\n4. cheese: 1\n5. avocado: 1\n6. bowl: 1\n7. table: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13321.7, "ram_available_mb": 109184.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13325.1, "ram_available_mb": 109181.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.67, 47.67, 47.67, 47.67, 43.38, 43.38, 43.38, 43.38, 43.38, 47.62, 47.62, 47.62, 47.62, 47.62, 39.34, 39.34, 39.34, 39.34, 39.34], "power_watts_avg": 44.34, "power_watts_peak": 47.67, "energy_joules_est": 84.54, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T10:04:59.008443"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1422.345, "latencies_ms": [1422.345], "images_per_second": 0.703, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The plate is in the foreground, with the bread, avocado, and broccoli in the background. The broccoli is near the plate, while the bread is on the left side of the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.1, "ram_available_mb": 109181.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13388.0, "ram_available_mb": 109118.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.05, 35.05, 35.05, 35.05, 43.65, 43.65, 43.65, 43.65, 43.65, 47.08, 47.08, 47.08, 47.08, 47.08, 38.51], "power_watts_avg": 42.16, "power_watts_peak": 47.08, "energy_joules_est": 60.0, "sample_count": 15, "duration_seconds": 1.423}, "timestamp": "2026-01-12T10:05:00.569415"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 686.463, "latencies_ms": [686.463], "images_per_second": 1.457, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A plate of food is on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.0, "ram_available_mb": 109118.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13444.6, "ram_available_mb": 109061.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.51, 38.51, 38.51, 38.51, 42.95, 42.95, 42.95], "power_watts_avg": 40.41, "power_watts_peak": 42.95, "energy_joules_est": 27.76, "sample_count": 7, "duration_seconds": 0.687}, "timestamp": "2026-01-12T10:05:01.278926"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1482.349, "latencies_ms": [1482.349], "images_per_second": 0.675, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a wooden table with a plate of food on it, including a bowl of broccoli and a slice of bread with avocado on it. The lighting is natural, and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13444.6, "ram_available_mb": 109061.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13429.7, "ram_available_mb": 109076.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.95, 42.95, 46.84, 46.84, 46.84, 46.84, 46.84, 51.18, 51.18, 51.18, 51.18, 51.18, 48.04, 48.04, 48.04], "power_watts_avg": 48.01, "power_watts_peak": 51.18, "energy_joules_est": 71.19, "sample_count": 15, "duration_seconds": 1.483}, "timestamp": "2026-01-12T10:05:02.795375"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 844.633, "latencies_ms": [844.633], "images_per_second": 1.184, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is sleeping on a bench with a blanket and a bag on it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13429.7, "ram_available_mb": 109076.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.04, 48.04, 33.77, 33.77, 33.77, 33.77, 33.77, 47.52, 47.52], "power_watts_avg": 40.0, "power_watts_peak": 48.04, "energy_joules_est": 33.81, "sample_count": 9, "duration_seconds": 0.845}, "timestamp": "2026-01-12T10:05:03.708665"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1329.532, "latencies_ms": [1329.532], "images_per_second": 0.752, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bench: 1\nbag: 1\npurse: 1\nparking meter: 2\nstreetlamp: 2\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.52, 47.52, 47.52, 51.67, 51.67, 51.67, 51.67, 51.67, 47.12, 47.12, 47.12, 47.12, 47.12, 44.84], "power_watts_avg": 48.67, "power_watts_peak": 51.67, "energy_joules_est": 64.73, "sample_count": 14, "duration_seconds": 1.33}, "timestamp": "2026-01-12T10:05:05.125270"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1373.816, "latencies_ms": [1373.816], "images_per_second": 0.728, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bench is located in the foreground of the image, with the parking meters and fence in the background. The person is lying on the bench, with the backpack and jacket nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13449.8, "ram_available_mb": 109056.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.84, 44.84, 44.84, 40.52, 40.52, 40.52, 40.52, 40.52, 46.72, 46.72, 46.72, 46.72, 46.72, 41.06], "power_watts_avg": 43.7, "power_watts_peak": 46.72, "energy_joules_est": 60.05, "sample_count": 14, "duration_seconds": 1.374}, "timestamp": "2026-01-12T10:05:06.539965"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 721.286, "latencies_ms": [721.286], "images_per_second": 1.386, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A person is sleeping on a bench in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13449.8, "ram_available_mb": 109056.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13434.8, "ram_available_mb": 109071.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.06, 41.06, 41.06, 41.06, 45.57, 45.57, 45.57, 45.57], "power_watts_avg": 43.32, "power_watts_peak": 45.57, "energy_joules_est": 31.26, "sample_count": 8, "duration_seconds": 0.722}, "timestamp": "2026-01-12T10:05:07.349622"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1244.358, "latencies_ms": [1244.358], "images_per_second": 0.804, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The bench is made of wood and is covered with an orange blanket. The scene is bathed in natural light, and the grass is a vibrant green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13434.3, "ram_available_mb": 109072.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13423.0, "ram_available_mb": 109083.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.57, 44.23, 44.23, 44.23, 44.23, 44.23, 48.58, 48.58, 48.58, 48.58, 48.58, 49.91, 49.91], "power_watts_avg": 46.88, "power_watts_peak": 49.91, "energy_joules_est": 58.35, "sample_count": 13, "duration_seconds": 1.245}, "timestamp": "2026-01-12T10:05:08.662834"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1116.481, "latencies_ms": [1116.481], "images_per_second": 0.896, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A tall, colorful vase with a mix of dried flowers and plants sits on a white shelf in a room with a brown wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.1, "ram_available_mb": 109091.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13412.7, "ram_available_mb": 109093.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.91, 49.91, 49.91, 39.64, 39.64, 39.64, 39.64, 39.64, 46.77, 46.77, 46.77, 46.77], "power_watts_avg": 44.59, "power_watts_peak": 49.91, "energy_joules_est": 49.8, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T10:05:09.876952"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1458.618, "latencies_ms": [1458.618], "images_per_second": 0.686, "prompt_tokens": 1114, "response_tokens_est": 39, "n_tiles": 1, "output_text": " vase: 1, pot: 1, wall: 1, wall art: 1, plant: 1, potted plant: 1, vase on table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.5, "ram_available_mb": 109104.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13399.7, "ram_available_mb": 109106.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.77, 40.2, 40.2, 40.2, 40.2, 40.2, 46.65, 46.65, 46.65, 46.65, 46.65, 49.47, 49.47, 49.47, 49.47], "power_watts_avg": 45.26, "power_watts_peak": 49.47, "energy_joules_est": 66.03, "sample_count": 15, "duration_seconds": 1.459}, "timestamp": "2026-01-12T10:05:11.389802"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1415.529, "latencies_ms": [1415.529], "images_per_second": 0.706, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The vase is positioned in the foreground, with the wall and other objects in the background. The vase is placed on a white shelf, which is situated to the left of the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.7, "ram_available_mb": 109110.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.8, "ram_available_mb": 109124.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.47, 33.13, 33.13, 33.13, 33.13, 33.13, 47.21, 47.21, 47.21, 47.21, 47.21, 48.99, 48.99, 48.99, 48.99], "power_watts_avg": 43.14, "power_watts_peak": 49.47, "energy_joules_est": 61.09, "sample_count": 15, "duration_seconds": 1.416}, "timestamp": "2026-01-12T10:05:12.905439"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 884.107, "latencies_ms": [884.107], "images_per_second": 1.131, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A vase with dried flowers sits on a white shelf in a room with brown walls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.0, "ram_available_mb": 109132.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13397.6, "ram_available_mb": 109108.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.99, 32.59, 32.59, 32.59, 32.59, 32.59, 46.39, 46.39, 46.39], "power_watts_avg": 39.01, "power_watts_peak": 48.99, "energy_joules_est": 34.51, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-12T10:05:13.816853"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1299.394, "latencies_ms": [1299.394], "images_per_second": 0.77, "prompt_tokens": 1110, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The vase is made of ceramic and has a variety of colors, including blue, green, and brown. The lighting is bright and natural, coming from the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.6, "ram_available_mb": 109108.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.39, 46.39, 47.12, 47.12, 47.12, 47.12, 47.12, 47.6, 47.6, 47.6, 47.6, 47.6, 48.91], "power_watts_avg": 47.33, "power_watts_peak": 48.91, "energy_joules_est": 61.52, "sample_count": 13, "duration_seconds": 1.3}, "timestamp": "2026-01-12T10:05:15.131052"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1008.603, "latencies_ms": [1008.603], "images_per_second": 0.991, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A skateboarder wearing a helmet and knee pads is performing a trick on a ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13288.0, "ram_available_mb": 109218.3, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [48.91, 48.91, 48.91, 42.29, 42.29, 42.29, 42.29, 42.29, 47.89, 47.89, 47.89], "power_watts_avg": 45.62, "power_watts_peak": 48.91, "energy_joules_est": 46.05, "sample_count": 11, "duration_seconds": 1.009}, "timestamp": "2026-01-12T10:05:16.244833"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2266.329, "latencies_ms": [2266.329], "images_per_second": 0.441, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. helmet: 1\n3. knee pads: 1\n4. skateboarder: 1\n5. skateboard wheels: 2\n6. skateboard deck: 1\n7. skateboard trucks: 1\n8. skateboard trucks bolts: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13288.0, "ram_available_mb": 109218.3, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13318.1, "ram_available_mb": 109188.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.89, 47.89, 41.43, 41.43, 41.43, 41.43, 41.43, 46.18, 46.18, 46.18, 46.18, 46.18, 45.5, 45.5, 45.5, 45.5, 45.5, 35.04, 35.04, 35.04, 35.04, 35.04, 34.88], "power_watts_avg": 42.24, "power_watts_peak": 47.89, "energy_joules_est": 95.73, "sample_count": 23, "duration_seconds": 2.267}, "timestamp": "2026-01-12T10:05:18.564202"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1573.645, "latencies_ms": [1573.645], "images_per_second": 0.635, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground of the image, performing a trick on the curved edge of the skatepark. The skatepark is located in the background, with a few spectators visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.1, "ram_available_mb": 109188.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.1, "ram_available_mb": 109145.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 41.09, 41.09, 41.09, 41.09, 41.09, 45.98, 45.98, 45.98, 45.98, 45.98, 39.94, 39.94], "power_watts_avg": 40.92, "power_watts_peak": 45.98, "energy_joules_est": 64.41, "sample_count": 16, "duration_seconds": 1.574}, "timestamp": "2026-01-12T10:05:20.228479"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 987.562, "latencies_ms": [987.562], "images_per_second": 1.013, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A skateboarder wearing a helmet and knee pads is performing a trick on a concrete skateboard ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.2, "ram_available_mb": 109149.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13376.9, "ram_available_mb": 109129.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [39.94, 39.94, 37.38, 37.38, 37.38, 37.38, 37.38, 47.3, 47.3, 47.3], "power_watts_avg": 40.87, "power_watts_peak": 47.3, "energy_joules_est": 40.37, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-12T10:05:21.240414"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 988.734, "latencies_ms": [988.734], "images_per_second": 1.011, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The skateboarder is wearing a helmet and knee pads, and the skate park is made of concrete.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.0, "ram_available_mb": 109137.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13304.3, "ram_available_mb": 109202.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 95.0}, "power_stats": {"power_watts_samples": [47.3, 47.3, 47.35, 47.35, 47.35, 47.35, 47.35, 47.72, 47.72, 47.72], "power_watts_avg": 47.45, "power_watts_peak": 47.72, "energy_joules_est": 46.93, "sample_count": 10, "duration_seconds": 0.989}, "timestamp": "2026-01-12T10:05:22.251143"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2932.18, "latencies_ms": [2932.18], "images_per_second": 0.341, "prompt_tokens": 1099, "response_tokens_est": 94, "n_tiles": 1, "output_text": " The image captures a vibrant night scene in a bustling city square, where a majestic clock tower stands tall, adorned with a festive blue and white Christmas tree, and is beautifully illuminated by strings of lights. The square is alive with people, adding a dynamic element to the scene, and is framed by a variety of buildings, including a prominent red and white building in the background. The ground is wet, reflecting the lights and adding a mirror-like quality to the scene.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13300.3, "ram_available_mb": 109206.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13325.4, "ram_available_mb": 109180.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.72, 47.72, 47.51, 47.51, 47.51, 47.51, 47.51, 47.61, 47.61, 47.61, 47.61, 47.61, 46.64, 46.64, 46.64, 46.64, 46.64, 34.7, 34.7, 34.7, 34.7, 34.7, 34.65, 34.65, 34.65, 34.65, 34.65, 34.81, 34.81, 34.81], "power_watts_avg": 41.85, "power_watts_peak": 47.72, "energy_joules_est": 122.73, "sample_count": 30, "duration_seconds": 2.933}, "timestamp": "2026-01-12T10:05:25.274109"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1336.43, "latencies_ms": [1336.43], "images_per_second": 0.748, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " clock: 1, tree: 1, building: 1, street: 1, people: 1, lights: 1, statue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.4, "ram_available_mb": 109180.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13396.1, "ram_available_mb": 109110.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 31.25, 31.25, 31.25, 31.25, 31.25, 45.25, 45.25, 45.25, 45.25, 45.25, 49.18, 49.18], "power_watts_avg": 39.32, "power_watts_peak": 49.18, "energy_joules_est": 52.58, "sample_count": 14, "duration_seconds": 1.337}, "timestamp": "2026-01-12T10:05:26.735244"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2017.968, "latencies_ms": [2017.968], "images_per_second": 0.496, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The clock tower is positioned in the center of the image, with the Christmas tree to its right. The street is in the foreground, with the buildings and shops in the background. The clock tower is the main focal point of the image, with the Christmas tree adding a festive touch to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.2, "ram_available_mb": 109118.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.7, "ram_available_mb": 109122.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.18, 49.18, 36.3, 36.3, 36.3, 36.3, 36.3, 46.55, 46.55, 46.55, 46.55, 46.55, 45.35, 45.35, 45.35, 45.35, 45.35, 34.89, 34.89, 34.89, 34.89], "power_watts_avg": 41.85, "power_watts_peak": 49.18, "energy_joules_est": 84.49, "sample_count": 21, "duration_seconds": 2.019}, "timestamp": "2026-01-12T10:05:28.850639"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2131.551, "latencies_ms": [2131.551], "images_per_second": 0.469, "prompt_tokens": 1111, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a vibrant night scene in a bustling city square, where a majestic clock tower stands tall, adorned with twinkling lights that add a magical touch to the urban landscape. The square is alive with people, some strolling leisurely, others gathered around a festive tree, all under the soft glow of the city lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.8, "ram_available_mb": 109126.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.9, "ram_available_mb": 109140.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.89, 31.64, 31.64, 31.64, 31.64, 31.64, 45.16, 45.16, 45.16, 45.16, 45.16, 48.87, 48.87, 48.87, 48.87, 48.87, 35.06, 35.06, 35.06, 35.06, 35.06, 35.0], "power_watts_avg": 39.71, "power_watts_peak": 48.87, "energy_joules_est": 84.66, "sample_count": 22, "duration_seconds": 2.132}, "timestamp": "2026-01-12T10:05:31.116012"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1929.708, "latencies_ms": [1929.708], "images_per_second": 0.518, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a nighttime scene with a prominent clock tower adorned with lights, a snow-covered Christmas tree, and a bustling street lined with shops and pedestrians. The sky is dark, and the street is wet, reflecting the lights and creating a glistening effect on the pavement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 38.49, 38.49, 38.49, 38.49, 38.49, 45.53, 45.53, 45.53, 45.53, 45.53, 42.13, 42.13, 42.13, 42.13, 42.13, 35.0, 35.0], "power_watts_avg": 40.29, "power_watts_peak": 45.53, "energy_joules_est": 77.76, "sample_count": 20, "duration_seconds": 1.93}, "timestamp": "2026-01-12T10:05:33.178800"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1096.712, "latencies_ms": [1096.712], "images_per_second": 0.912, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young man wearing a blue shirt and black shorts is playing tennis on a court with a yellow and black tennis racket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13319.6, "ram_available_mb": 109186.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 38.31, 38.31, 38.31, 38.31, 38.31, 46.26, 46.26, 46.26], "power_watts_avg": 39.58, "power_watts_peak": 46.26, "energy_joules_est": 43.44, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-12T10:05:34.292416"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2074.839, "latencies_ms": [2074.839], "images_per_second": 0.482, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. chain link fence: 1\n5. tennis court: 1\n6. trees: 1\n7. grass: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.6, "ram_available_mb": 109186.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13277.9, "ram_available_mb": 109228.4, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 43.56, 43.56, 43.56, 43.56, 43.56, 47.63, 47.63, 47.63, 47.63, 47.63, 48.11, 48.11, 48.11, 48.11, 48.11, 34.8, 34.8, 34.8, 34.8], "power_watts_avg": 44.2, "power_watts_peak": 48.11, "energy_joules_est": 91.75, "sample_count": 21, "duration_seconds": 2.076}, "timestamp": "2026-01-12T10:05:36.410445"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1994.673, "latencies_ms": [1994.673], "images_per_second": 0.501, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The tennis player is in the foreground of the image, holding a tennis racket and preparing to hit the ball. The tennis ball is in the middle ground, slightly to the right of the player. The tennis court is in the background, with a chain link fence separating it from the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13277.9, "ram_available_mb": 109228.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13323.2, "ram_available_mb": 109183.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [33.59, 33.59, 33.59, 33.59, 33.59, 46.4, 46.4, 46.4, 46.4, 46.4, 47.54, 47.54, 47.54, 47.54, 47.54, 34.78, 34.78, 34.78, 34.78, 34.78], "power_watts_avg": 40.58, "power_watts_peak": 47.54, "energy_joules_est": 80.97, "sample_count": 20, "duration_seconds": 1.996}, "timestamp": "2026-01-12T10:05:38.480097"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 884.942, "latencies_ms": [884.942], "images_per_second": 1.13, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young man is playing tennis on a court with a green fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.3, "ram_available_mb": 109187.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13328.6, "ram_available_mb": 109177.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 34.82, 34.82, 45.42, 45.42, 45.42, 45.42, 45.42], "power_watts_avg": 40.71, "power_watts_peak": 45.42, "energy_joules_est": 36.05, "sample_count": 9, "duration_seconds": 0.886}, "timestamp": "2026-01-12T10:05:39.441614"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1835.928, "latencies_ms": [1835.928], "images_per_second": 0.545, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image shows a young man playing tennis on a court with a green fence in the background. The court is made of concrete and has white lines marking the boundaries. The sky is overcast, and the lighting is natural, suggesting it might be a cloudy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.7, "ram_available_mb": 109185.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.7, "ram_available_mb": 109177.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 46.43, 46.43, 46.43, 49.0, 49.0, 49.0, 49.0, 49.0, 47.94, 47.94, 47.94, 47.94, 47.94, 34.83, 34.83, 34.83, 34.83], "power_watts_avg": 45.06, "power_watts_peak": 49.0, "energy_joules_est": 82.76, "sample_count": 19, "duration_seconds": 1.836}, "timestamp": "2026-01-12T10:05:41.361269"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1066.428, "latencies_ms": [1066.428], "images_per_second": 0.938, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a fireplace, a comfortable armchair, and a bookshelf filled with books.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.6, "ram_available_mb": 109158.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.83, 32.0, 32.0, 32.0, 32.0, 32.0, 45.56, 45.56, 45.56, 45.56, 45.56], "power_watts_avg": 38.42, "power_watts_peak": 45.56, "energy_joules_est": 41.0, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T10:05:42.523643"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1998.371, "latencies_ms": [1998.371], "images_per_second": 0.5, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. sofa: 1\n2. bookshelves: 2\n3. lamp: 2\n4. fireplace: 1\n5. plant: 2\n6. chair: 1\n7. table: 2\n8. picture: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.6, "ram_available_mb": 109162.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13332.1, "ram_available_mb": 109174.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.48, 48.48, 48.48, 48.48, 48.48, 45.89, 45.89, 45.89, 45.89, 45.89, 47.34, 47.34, 47.34, 47.34, 47.34, 36.92, 36.92, 36.92, 36.92, 34.76], "power_watts_avg": 44.55, "power_watts_peak": 48.48, "energy_joules_est": 89.04, "sample_count": 20, "duration_seconds": 1.999}, "timestamp": "2026-01-12T10:05:44.540600"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2427.258, "latencies_ms": [2427.258], "images_per_second": 0.412, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The beige armchair is positioned in the foreground, to the right of the fireplace, with the green plant to its left. The white bookshelves are located behind the armchair, with the green plant to the left of the fireplace. The beige sofa is positioned in the background, to the left of the fireplace, with the green plant to its right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.2, "ram_available_mb": 109182.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.76, 34.76, 34.76, 34.76, 42.89, 42.89, 42.89, 42.89, 42.89, 46.43, 46.43, 46.43, 46.43, 46.43, 38.38, 38.38, 38.38, 38.38, 38.38, 34.82, 34.82, 34.82, 34.82, 34.82, 34.7], "power_watts_avg": 39.45, "power_watts_peak": 46.43, "energy_joules_est": 95.79, "sample_count": 25, "duration_seconds": 2.428}, "timestamp": "2026-01-12T10:05:47.113600"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 831.447, "latencies_ms": [831.447], "images_per_second": 1.203, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cozy living room with a fireplace, two lamps, and a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 34.7, 41.14, 41.14, 41.14, 41.14, 41.14], "power_watts_avg": 38.28, "power_watts_peak": 41.14, "energy_joules_est": 31.84, "sample_count": 9, "duration_seconds": 0.832}, "timestamp": "2026-01-12T10:05:48.021489"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 879.391, "latencies_ms": [879.391], "images_per_second": 1.137, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.33, 46.33, 46.33, 46.33, 46.33, 50.78, 50.78, 50.78, 50.78], "power_watts_avg": 48.31, "power_watts_peak": 50.78, "energy_joules_est": 42.49, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-12T10:05:48.930885"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1268.997, "latencies_ms": [1268.997], "images_per_second": 0.788, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there are three zebras standing on a grassy hill, with one of them eating grass, and the other two standing close to each other.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13399.3, "ram_available_mb": 109107.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13445.9, "ram_available_mb": 109060.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [50.78, 46.08, 46.08, 46.08, 46.08, 48.69, 48.69, 48.69, 48.69, 48.69, 48.27, 48.27, 48.27], "power_watts_avg": 47.95, "power_watts_peak": 50.78, "energy_joules_est": 60.86, "sample_count": 13, "duration_seconds": 1.269}, "timestamp": "2026-01-12T10:05:50.245306"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 531.808, "latencies_ms": [531.808], "images_per_second": 1.88, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13442.0, "ram_available_mb": 109064.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13450.8, "ram_available_mb": 109055.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [48.27, 48.27, 36.99, 36.99, 36.99, 36.99], "power_watts_avg": 40.75, "power_watts_peak": 48.27, "energy_joules_est": 21.69, "sample_count": 6, "duration_seconds": 0.532}, "timestamp": "2026-01-12T10:05:50.855837"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2340.192, "latencies_ms": [2340.192], "images_per_second": 0.427, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the other two. The zebras are standing on a grassy hill, with the one on the left being closest to the camera. The zebras are facing towards the right side of the image, with the one on the left facing the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.9, "ram_available_mb": 109069.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13430.4, "ram_available_mb": 109075.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [36.99, 44.54, 44.54, 44.54, 44.54, 44.54, 57.72, 57.72, 57.72, 57.72, 57.72, 49.98, 49.98, 49.98, 49.98, 49.98, 34.97, 34.97, 34.97, 34.97, 34.97, 34.93, 34.93, 34.93], "power_watts_avg": 44.91, "power_watts_peak": 57.72, "energy_joules_est": 105.12, "sample_count": 24, "duration_seconds": 2.341}, "timestamp": "2026-01-12T10:05:53.273121"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 883.908, "latencies_ms": [883.908], "images_per_second": 1.131, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of zebras are grazing in a grassy field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13422.5, "ram_available_mb": 109083.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13433.8, "ram_available_mb": 109072.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 23.0}, "power_stats": {"power_watts_samples": [34.93, 34.93, 31.9, 31.9, 31.9, 31.9, 31.9, 45.7, 45.7], "power_watts_avg": 35.64, "power_watts_peak": 45.7, "energy_joules_est": 31.54, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-12T10:05:54.232850"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1595.182, "latencies_ms": [1595.182], "images_per_second": 0.627, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a group of zebras with black and white stripes, standing in a grassy field under a clear blue sky. The zebras are grazing on the grass, and the image has a natural and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13429.9, "ram_available_mb": 109076.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13415.1, "ram_available_mb": 109091.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.7, 45.7, 45.7, 51.76, 51.76, 51.76, 51.76, 51.76, 47.75, 47.75, 47.75, 47.75, 44.94, 44.94, 44.94, 44.94], "power_watts_avg": 47.92, "power_watts_peak": 51.76, "energy_joules_est": 76.46, "sample_count": 16, "duration_seconds": 1.596}, "timestamp": "2026-01-12T10:05:55.848862"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 981.804, "latencies_ms": [981.804], "images_per_second": 1.019, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, wearing hats and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13415.1, "ram_available_mb": 109091.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.94, 32.96, 32.96, 32.96, 32.96, 32.96, 47.63, 47.63, 47.63, 47.63], "power_watts_avg": 40.03, "power_watts_peak": 47.63, "energy_joules_est": 39.32, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T10:05:56.862634"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1986.667, "latencies_ms": [1986.667], "images_per_second": 0.503, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. chairs: 10\n2. people: 10\n3. table: 1\n4. bottles: 1\n5. napkins: 1\n6. plates: 1\n7. cups: 1\n8. glasses: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13379.8, "ram_available_mb": 109126.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.63, 48.06, 48.06, 48.06, 48.06, 48.06, 47.56, 47.56, 47.56, 47.56, 47.56, 49.65, 49.65, 49.65, 49.65, 49.65, 34.93, 34.93, 34.93, 34.93], "power_watts_avg": 45.68, "power_watts_peak": 49.65, "energy_joules_est": 90.78, "sample_count": 20, "duration_seconds": 1.987}, "timestamp": "2026-01-12T10:05:58.881351"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1646.259, "latencies_ms": [1646.259], "images_per_second": 0.607, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The group of people is seated around a table in the foreground of the image, with the restaurant's interior and other patrons in the background. The table is positioned in the center of the image, with the people seated around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.9, "ram_available_mb": 109130.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13377.5, "ram_available_mb": 109128.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.93, 33.37, 33.37, 33.37, 33.37, 33.37, 46.67, 46.67, 46.67, 46.67, 46.67, 48.19, 48.19, 48.19, 48.19, 34.87, 34.87], "power_watts_avg": 41.04, "power_watts_peak": 48.19, "energy_joules_est": 67.58, "sample_count": 17, "duration_seconds": 1.647}, "timestamp": "2026-01-12T10:06:00.651120"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 908.041, "latencies_ms": [908.041], "images_per_second": 1.101, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, wearing hats and smiling.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13369.6, "ram_available_mb": 109136.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13385.5, "ram_available_mb": 109120.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 40.42, 40.42, 40.42, 40.42, 40.42, 47.0, 47.0], "power_watts_avg": 40.07, "power_watts_peak": 47.0, "energy_joules_est": 36.41, "sample_count": 10, "duration_seconds": 0.909}, "timestamp": "2026-01-12T10:06:01.662769"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1706.306, "latencies_ms": [1706.306], "images_per_second": 0.586, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere, characterized by the rich brown color of the wooden floor and the warm lighting that illuminates the space. The walls are adorned with brick, adding a rustic charm to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.6, "ram_available_mb": 109128.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13375.0, "ram_available_mb": 109131.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.0, 47.0, 47.0, 46.24, 46.24, 46.24, 46.24, 46.24, 46.03, 46.03, 46.03, 46.03, 46.03, 42.03, 42.03, 42.03, 42.03], "power_watts_avg": 45.32, "power_watts_peak": 47.0, "energy_joules_est": 77.35, "sample_count": 17, "duration_seconds": 1.707}, "timestamp": "2026-01-12T10:06:03.381016"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1096.612, "latencies_ms": [1096.612], "images_per_second": 0.912, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In the image, a group of swans is seen swimming in a marina, with boats docked in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.9, "ram_available_mb": 109123.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.03, 33.65, 33.65, 33.65, 33.65, 33.65, 47.91, 47.91, 47.91, 47.91, 47.91], "power_watts_avg": 40.9, "power_watts_peak": 47.91, "energy_joules_est": 44.87, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-12T10:06:04.497087"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1148.774, "latencies_ms": [1148.774], "images_per_second": 0.87, "prompt_tokens": 1113, "response_tokens_est": 27, "n_tiles": 1, "output_text": " swan: 12, boat: 10, water: 1, dock: 1, purple: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.0, "ram_available_mb": 109131.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13379.1, "ram_available_mb": 109127.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.41, 48.41, 48.41, 48.41, 48.41, 47.72, 47.72, 47.72, 47.72, 47.72, 48.0, 48.0], "power_watts_avg": 48.05, "power_watts_peak": 48.41, "energy_joules_est": 55.23, "sample_count": 12, "duration_seconds": 1.149}, "timestamp": "2026-01-12T10:06:05.711355"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1565.658, "latencies_ms": [1565.658], "images_per_second": 0.639, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The swans are positioned in the foreground of the image, with the boats in the background. The boats are docked on the left side of the image, while the swans are swimming in the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.1, "ram_available_mb": 109127.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.0, 48.0, 48.0, 38.18, 38.18, 38.18, 38.18, 38.18, 46.83, 46.83, 46.83, 46.83, 46.83, 44.28, 44.28, 44.28], "power_watts_avg": 43.87, "power_watts_peak": 48.0, "energy_joules_est": 68.71, "sample_count": 16, "duration_seconds": 1.566}, "timestamp": "2026-01-12T10:06:07.327524"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 942.143, "latencies_ms": [942.143], "images_per_second": 1.061, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of swans are swimming in a marina with boats docked in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13358.6, "ram_available_mb": 109147.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13370.6, "ram_available_mb": 109135.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 15.0}, "power_stats": {"power_watts_samples": [44.28, 44.28, 32.95, 32.95, 32.95, 32.95, 32.95, 46.97, 46.97, 46.97], "power_watts_avg": 39.42, "power_watts_peak": 46.97, "energy_joules_est": 37.16, "sample_count": 10, "duration_seconds": 0.943}, "timestamp": "2026-01-12T10:06:08.340014"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1524.42, "latencies_ms": [1524.42], "images_per_second": 0.656, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a group of swans in a marina with purple-tinted water, reflecting the sunlight. The swans are white, and the water is calm, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.7, "ram_available_mb": 109143.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.0, "ram_available_mb": 109147.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.97, 46.97, 46.56, 46.56, 46.56, 46.56, 46.56, 46.62, 46.62, 46.62, 46.62, 49.75, 49.75, 49.75, 49.75, 49.75], "power_watts_avg": 47.62, "power_watts_peak": 49.75, "energy_joules_est": 72.62, "sample_count": 16, "duration_seconds": 1.525}, "timestamp": "2026-01-12T10:06:09.957317"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1030.437, "latencies_ms": [1030.437], "images_per_second": 0.97, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man and woman are cutting a wedding cake together in a tent with a table covered in a white tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.1, "ram_available_mb": 109151.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13359.2, "ram_available_mb": 109147.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [33.56, 33.56, 33.56, 33.56, 33.56, 46.47, 46.47, 46.47, 46.47, 46.47, 47.79], "power_watts_avg": 40.72, "power_watts_peak": 47.79, "energy_joules_est": 41.99, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-12T10:06:11.071388"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.6, "latencies_ms": [1902.6], "images_per_second": 0.526, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. table: 1\n4. chair: 1\n5. cake: 1\n6. speaker: 1\n7. person: 1\n8. tent: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.79, 47.79, 47.79, 47.79, 43.7, 43.7, 43.7, 43.7, 43.7, 46.54, 46.54, 46.54, 46.54, 46.54, 37.83, 37.83, 37.83, 37.83, 37.83], "power_watts_avg": 43.76, "power_watts_peak": 47.79, "energy_joules_est": 83.29, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T10:06:12.990753"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2310.219, "latencies_ms": [2310.219], "images_per_second": 0.433, "prompt_tokens": 1118, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The bride and groom are standing close to each other, with the bride on the left and the groom on the right. The cake is placed in the middle of the table, which is located in the foreground. The background of the image shows a stage with musical instruments and a speaker, indicating that the event is taking place in a large tent or venue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.3, "ram_available_mb": 109164.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13342.7, "ram_available_mb": 109163.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 34.89, 45.52, 45.52, 45.52, 45.52, 46.94, 46.94, 46.94, 46.94, 46.94, 36.27, 36.27, 36.27, 36.27, 36.27, 34.67, 34.67, 34.67, 34.67], "power_watts_avg": 39.62, "power_watts_peak": 46.94, "energy_joules_est": 91.55, "sample_count": 23, "duration_seconds": 2.311}, "timestamp": "2026-01-12T10:06:15.361355"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1004.504, "latencies_ms": [1004.504], "images_per_second": 0.996, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A newlywed couple is cutting their wedding cake in a tent with a white tablecloth and a wooden floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.7, "ram_available_mb": 109163.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13428.3, "ram_available_mb": 109078.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [34.67, 33.21, 33.21, 33.21, 33.21, 33.21, 47.17, 47.17, 47.17, 47.17, 47.17], "power_watts_avg": 39.69, "power_watts_peak": 47.17, "energy_joules_est": 39.88, "sample_count": 11, "duration_seconds": 1.005}, "timestamp": "2026-01-12T10:06:16.520305"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 948.312, "latencies_ms": [948.312], "images_per_second": 1.055, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The wedding reception is well-lit with natural light, and the tent is decorated with colorful flags.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.5, "ram_available_mb": 109085.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13411.3, "ram_available_mb": 109095.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.53, 48.53, 48.53, 48.53, 48.53, 45.63, 45.63, 45.63, 45.63, 45.63], "power_watts_avg": 47.08, "power_watts_peak": 48.53, "energy_joules_est": 44.66, "sample_count": 10, "duration_seconds": 0.949}, "timestamp": "2026-01-12T10:06:17.529030"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 826.683, "latencies_ms": [826.683], "images_per_second": 1.21, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A living room with a blue couch, a table, and a lamp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.4, "ram_available_mb": 109102.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13400.4, "ram_available_mb": 109105.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.7, 46.7, 46.7, 46.7, 46.7, 46.68, 46.68, 46.68, 46.68], "power_watts_avg": 46.69, "power_watts_peak": 46.7, "energy_joules_est": 38.65, "sample_count": 9, "duration_seconds": 0.828}, "timestamp": "2026-01-12T10:06:18.442604"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1412.404, "latencies_ms": [1412.404], "images_per_second": 0.708, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " sofa: 1, coffee table: 1, side table: 1, lamp: 1, plant: 2, rug: 1, painting: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.5, "ram_available_mb": 109109.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13388.9, "ram_available_mb": 109117.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.68, 45.62, 45.62, 45.62, 45.62, 45.62, 48.53, 48.53, 48.53, 48.53, 48.07, 48.07, 48.07, 48.07, 48.07], "power_watts_avg": 47.28, "power_watts_peak": 48.53, "energy_joules_est": 66.81, "sample_count": 15, "duration_seconds": 1.413}, "timestamp": "2026-01-12T10:06:19.955996"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2388.96, "latencies_ms": [2388.96], "images_per_second": 0.419, "prompt_tokens": 1117, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The sofa is positioned in the center of the room, with the coffee table in front of it. The lamp is placed on the side table to the left of the sofa, while the plant is situated on the side table to the right. The rug is located in the foreground, covering the floor, while the painting is hanging on the wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.1, "ram_available_mb": 109125.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13377.5, "ram_available_mb": 109128.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.4, 33.4, 33.4, 33.4, 33.4, 46.31, 46.31, 46.31, 46.31, 46.31, 47.47, 47.47, 47.47, 47.47, 47.47, 34.76, 34.76, 34.76, 34.76, 34.76, 34.84, 34.84, 34.84, 34.84], "power_watts_avg": 39.54, "power_watts_peak": 47.47, "energy_joules_est": 94.49, "sample_count": 24, "duration_seconds": 2.389}, "timestamp": "2026-01-12T10:06:22.372409"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 932.517, "latencies_ms": [932.517], "images_per_second": 1.072, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A living room with a blue couch, a coffee table, and a rug on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.5, "ram_available_mb": 109132.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.7, "ram_available_mb": 109124.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 15.0}, "power_stats": {"power_watts_samples": [34.84, 33.22, 33.22, 33.22, 33.22, 33.22, 46.76, 46.76, 46.76, 46.76], "power_watts_avg": 38.8, "power_watts_peak": 46.76, "energy_joules_est": 36.21, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T10:06:23.432355"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 961.109, "latencies_ms": [961.109], "images_per_second": 1.04, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is painted red and has a red carpet. The furniture is made of wood and glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.9, "ram_available_mb": 109132.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13385.5, "ram_available_mb": 109120.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 22.0}, "power_stats": {"power_watts_samples": [46.76, 47.01, 47.01, 47.01, 47.01, 47.01, 46.54, 46.54, 46.54, 46.54], "power_watts_avg": 46.8, "power_watts_peak": 47.01, "energy_joules_est": 45.01, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-12T10:06:24.440981"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1473.832, "latencies_ms": [1473.832], "images_per_second": 0.679, "prompt_tokens": 1432, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features a doll with a clock face on its face, which is positioned in front of a mirror, creating a reflection of the clock and the doll's face.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.6, "ram_available_mb": 109128.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13299.2, "ram_available_mb": 109207.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.54, 46.9, 46.9, 46.9, 46.9, 48.66, 48.66, 48.66, 48.66, 48.66, 51.58, 51.58, 51.58, 51.58, 51.58], "power_watts_avg": 49.02, "power_watts_peak": 51.58, "energy_joules_est": 72.3, "sample_count": 15, "duration_seconds": 1.475}, "timestamp": "2026-01-12T10:06:25.961995"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2383.485, "latencies_ms": [2383.485], "images_per_second": 0.42, "prompt_tokens": 1446, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. Clock: 1\n2. Doll: 1\n3. Doll's hair: 1\n4. Doll's eyes: 1\n5. Doll's mouth: 1\n6. Doll's nose: 1\n7. Doll's hands: 1\n8. Doll's feet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13299.2, "ram_available_mb": 109207.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13365.8, "ram_available_mb": 109140.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.55, 37.55, 37.55, 37.55, 37.55, 48.88, 48.88, 48.88, 48.88, 48.88, 52.23, 52.23, 52.23, 52.23, 52.23, 38.72, 38.72, 38.72, 38.72, 38.72, 34.96, 34.96, 34.96, 34.96], "power_watts_avg": 42.78, "power_watts_peak": 52.23, "energy_joules_est": 101.99, "sample_count": 24, "duration_seconds": 2.384}, "timestamp": "2026-01-12T10:06:28.383951"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1796.906, "latencies_ms": [1796.906], "images_per_second": 0.557, "prompt_tokens": 1450, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The clock is positioned on the left side of the image, while the doll is on the right side. The doll is in the foreground, with the clock in the background. The doll is closer to the viewer than the clock.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.0, "ram_available_mb": 109148.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.5, "ram_available_mb": 109124.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.96, 32.98, 32.98, 32.98, 32.98, 32.98, 48.8, 48.8, 48.8, 48.8, 48.8, 52.73, 52.73, 52.73, 52.73, 52.73, 36.61, 36.61], "power_watts_avg": 43.38, "power_watts_peak": 52.73, "energy_joules_est": 77.98, "sample_count": 18, "duration_seconds": 1.798}, "timestamp": "2026-01-12T10:06:30.253544"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 962.842, "latencies_ms": [962.842], "images_per_second": 1.039, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A doll with a clock face on its face is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.6, "ram_available_mb": 109132.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [36.61, 36.61, 36.4, 36.4, 36.4, 36.4, 36.4, 52.02, 52.02, 52.02], "power_watts_avg": 41.13, "power_watts_peak": 52.02, "energy_joules_est": 39.61, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-12T10:06:31.265385"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1922.208, "latencies_ms": [1922.208], "images_per_second": 0.52, "prompt_tokens": 1442, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a doll with a clock face on its face, which is a combination of yellow and black. The doll is made of plastic and has a red and black striped scarf. The lighting in the image is bright and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.2, "ram_available_mb": 109121.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.02, 52.02, 51.61, 51.61, 51.61, 51.61, 51.61, 51.22, 51.22, 51.22, 51.22, 51.22, 51.08, 51.08, 51.08, 51.08, 51.08, 35.07, 35.07, 35.07], "power_watts_avg": 48.94, "power_watts_peak": 52.02, "energy_joules_est": 94.08, "sample_count": 20, "duration_seconds": 1.922}, "timestamp": "2026-01-12T10:06:33.285352"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 893.82, "latencies_ms": [893.82], "images_per_second": 1.119, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man wearing a helmet and a beige jacket is sitting on a motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [35.07, 35.07, 30.04, 30.04, 30.04, 30.04, 30.04, 44.71, 44.71], "power_watts_avg": 34.42, "power_watts_peak": 44.71, "energy_joules_est": 30.82, "sample_count": 9, "duration_seconds": 0.895}, "timestamp": "2026-01-12T10:06:34.252783"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1941.162, "latencies_ms": [1941.162], "images_per_second": 0.515, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. motorcycle: 1\n4. jacket: 1\n5. pants: 1\n6. shoes: 1\n7. seat: 1\n8. seatbelt: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13327.2, "ram_available_mb": 109179.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.71, 44.71, 51.29, 51.29, 51.29, 51.29, 51.29, 47.61, 47.61, 47.61, 47.61, 47.61, 45.6, 45.6, 45.6, 45.6, 45.6, 34.88, 34.88, 34.88], "power_watts_avg": 45.83, "power_watts_peak": 51.29, "energy_joules_est": 88.99, "sample_count": 20, "duration_seconds": 1.942}, "timestamp": "2026-01-12T10:06:36.269901"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1508.272, "latencies_ms": [1508.272], "images_per_second": 0.663, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man is sitting on the left side of the motorcycle, which is positioned in the foreground of the image. The motorcycle is parked in a parking lot, which is located in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.2, "ram_available_mb": 109179.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 32.66, 32.66, 32.66, 32.66, 32.66, 45.67, 45.67, 45.67, 45.67, 45.67, 48.73, 48.73, 48.73], "power_watts_avg": 40.5, "power_watts_peak": 48.73, "energy_joules_est": 61.12, "sample_count": 15, "duration_seconds": 1.509}, "timestamp": "2026-01-12T10:06:37.835805"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 723.466, "latencies_ms": [723.466], "images_per_second": 1.382, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man wearing a helmet is sitting on a motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.1, "ram_available_mb": 109147.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.73, 48.73, 34.48, 34.48, 34.48, 34.48, 34.48, 48.29], "power_watts_avg": 39.77, "power_watts_peak": 48.73, "energy_joules_est": 28.78, "sample_count": 8, "duration_seconds": 0.724}, "timestamp": "2026-01-12T10:06:38.645425"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1717.793, "latencies_ms": [1717.793], "images_per_second": 0.582, "prompt_tokens": 1110, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image has a warm color tone, with the man's beige jacket and helmet standing out against the red background. The lighting is natural, coming from the left side of the image, casting a soft shadow on the man's face.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13337.1, "ram_available_mb": 109169.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 26.0}, "power_stats": {"power_watts_samples": [48.29, 48.29, 48.29, 48.29, 55.61, 55.61, 55.61, 55.61, 46.64, 46.64, 46.64, 46.64, 46.64, 40.02, 40.02, 40.02, 40.02, 40.02], "power_watts_avg": 47.16, "power_watts_peak": 55.61, "energy_joules_est": 81.01, "sample_count": 18, "duration_seconds": 1.718}, "timestamp": "2026-01-12T10:06:40.462313"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1048.709, "latencies_ms": [1048.709], "images_per_second": 0.954, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is preparing a pizza on a wooden table, with a metal bowl and other kitchen items in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.0, "ram_available_mb": 109169.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [32.94, 32.94, 32.94, 32.94, 32.94, 45.9, 45.9, 45.9, 45.9, 45.9, 47.72], "power_watts_avg": 40.18, "power_watts_peak": 47.72, "energy_joules_est": 42.16, "sample_count": 11, "duration_seconds": 1.049}, "timestamp": "2026-01-12T10:06:41.575641"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2081.089, "latencies_ms": [2081.089], "images_per_second": 0.481, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Pizza: 1\n2. Cheese: 1\n3. Spice: 1\n4. Meat: 1\n5. Sauce: 1\n6. Bread: 1\n7. Knife: 1\n8. Spatula: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13379.5, "ram_available_mb": 109126.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.72, 47.72, 47.72, 47.72, 43.91, 43.91, 43.91, 43.91, 43.91, 46.97, 46.97, 46.97, 46.97, 46.97, 37.52, 37.52, 37.52, 37.52, 37.52, 34.7, 34.7], "power_watts_avg": 42.97, "power_watts_peak": 47.72, "energy_joules_est": 89.44, "sample_count": 21, "duration_seconds": 2.082}, "timestamp": "2026-01-12T10:06:43.695302"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1442.177, "latencies_ms": [1442.177], "images_per_second": 0.693, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the person's hand in the background. The pizza is on the left side of the image, while the person's hand is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.6, "ram_available_mb": 109130.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 34.7, 36.35, 36.35, 36.35, 36.35, 36.35, 46.17, 46.17, 46.17, 46.17, 45.51, 45.51, 45.51], "power_watts_avg": 40.47, "power_watts_peak": 46.17, "energy_joules_est": 58.38, "sample_count": 15, "duration_seconds": 1.443}, "timestamp": "2026-01-12T10:06:45.257960"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 801.505, "latencies_ms": [801.505], "images_per_second": 1.248, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is preparing a pizza on a wooden table in a kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.3, "ram_available_mb": 109142.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.6, "ram_available_mb": 109095.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.51, 45.51, 36.26, 36.26, 36.26, 36.26, 36.26, 46.86], "power_watts_avg": 39.9, "power_watts_peak": 46.86, "energy_joules_est": 32.0, "sample_count": 8, "duration_seconds": 0.802}, "timestamp": "2026-01-12T10:06:46.069083"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 960.414, "latencies_ms": [960.414], "images_per_second": 1.041, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The pizza is golden brown and has a thick crust, and the cheese is melted and bubbly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.6, "ram_available_mb": 109095.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13334.2, "ram_available_mb": 109172.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.86, 46.86, 46.86, 46.86, 56.17, 56.17, 56.17, 56.17, 56.17, 47.88], "power_watts_avg": 51.62, "power_watts_peak": 56.17, "energy_joules_est": 49.59, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-12T10:06:47.078755"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 884.502, "latencies_ms": [884.502], "images_per_second": 1.131, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman in a white dress and white shoes is playing tennis on a grass court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.2, "ram_available_mb": 109172.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13383.5, "ram_available_mb": 109122.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [47.88, 47.88, 47.88, 47.88, 47.62, 47.62, 47.62, 47.62, 47.62], "power_watts_avg": 47.73, "power_watts_peak": 47.88, "energy_joules_est": 42.24, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-12T10:06:47.990388"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1999.704, "latencies_ms": [1999.704], "images_per_second": 0.5, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. woman: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. grass: 1\n5. net: 1\n6. white: 1\n7. white: 1\n8. white: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.5, "ram_available_mb": 109122.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.6, "ram_available_mb": 109145.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.27, 47.27, 47.27, 47.27, 47.27, 50.66, 50.66, 50.66, 50.66, 50.66, 47.51, 47.51, 47.51, 47.51, 47.51, 34.87, 34.87, 34.87, 34.87, 34.87], "power_watts_avg": 45.08, "power_watts_peak": 50.66, "energy_joules_est": 90.16, "sample_count": 20, "duration_seconds": 2.0}, "timestamp": "2026-01-12T10:06:50.006427"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1303.069, "latencies_ms": [1303.069], "images_per_second": 0.767, "prompt_tokens": 1118, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the tennis racket held high above her head, and the tennis court stretching out into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13380.3, "ram_available_mb": 109126.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.81, 34.81, 34.81, 48.07, 48.07, 48.07, 48.07, 48.07, 48.15, 48.15, 48.15], "power_watts_avg": 42.99, "power_watts_peak": 48.15, "energy_joules_est": 56.03, "sample_count": 13, "duration_seconds": 1.303}, "timestamp": "2026-01-12T10:06:51.319237"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 824.206, "latencies_ms": [824.206], "images_per_second": 1.213, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman in a white dress is playing tennis on a green grass court.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13376.3, "ram_available_mb": 109130.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13377.0, "ram_available_mb": 109129.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 27.0}, "power_stats": {"power_watts_samples": [48.15, 48.15, 35.25, 35.25, 35.25, 35.25, 35.25, 47.98, 47.98], "power_watts_avg": 40.95, "power_watts_peak": 48.15, "energy_joules_est": 33.76, "sample_count": 9, "duration_seconds": 0.824}, "timestamp": "2026-01-12T10:06:52.231469"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 905.444, "latencies_ms": [905.444], "images_per_second": 1.104, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The woman is wearing a white dress and white shoes, and the tennis court is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.2, "ram_available_mb": 109137.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13376.2, "ram_available_mb": 109130.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.98, 47.98, 47.98, 51.19, 51.19, 51.19, 51.19, 51.19, 46.75, 46.75], "power_watts_avg": 49.34, "power_watts_peak": 51.19, "energy_joules_est": 44.69, "sample_count": 10, "duration_seconds": 0.906}, "timestamp": "2026-01-12T10:06:53.241940"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1389.173, "latencies_ms": [1389.173], "images_per_second": 0.72, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white toilet, a shower curtain, and a towel hanging on the wall, as well as a wire shelf with folded clothes in the closet.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13368.3, "ram_available_mb": 109138.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.75, 46.75, 46.75, 45.47, 45.47, 45.47, 45.47, 45.47, 45.97, 45.97, 45.97, 45.97, 45.97, 45.47], "power_watts_avg": 45.92, "power_watts_peak": 46.75, "energy_joules_est": 63.82, "sample_count": 14, "duration_seconds": 1.39}, "timestamp": "2026-01-12T10:06:54.656493"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1460.088, "latencies_ms": [1460.088], "images_per_second": 0.685, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " toilet: 1, towel: 1, closet: 1, shelf: 1, door: 1, bathtub: 1, wall: 1, floor: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13362.5, "ram_available_mb": 109143.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.1, "ram_available_mb": 109147.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.47, 45.47, 45.47, 41.86, 41.86, 41.86, 41.86, 41.86, 47.9, 47.9, 47.9, 47.9, 47.9, 40.95, 40.95], "power_watts_avg": 44.48, "power_watts_peak": 47.9, "energy_joules_est": 64.96, "sample_count": 15, "duration_seconds": 1.461}, "timestamp": "2026-01-12T10:06:56.170098"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1544.541, "latencies_ms": [1544.541], "images_per_second": 0.647, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the shower curtain is on the right side. The closet is positioned in the background, and the towel is hanging on the wall above the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.2, "ram_available_mb": 109155.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [40.95, 40.95, 40.95, 40.65, 40.65, 40.65, 40.65, 40.65, 47.09, 47.09, 47.09, 47.09, 47.09, 42.27, 42.27, 42.27], "power_watts_avg": 43.02, "power_watts_peak": 47.09, "energy_joules_est": 66.46, "sample_count": 16, "duration_seconds": 1.545}, "timestamp": "2026-01-12T10:06:57.784456"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 884.129, "latencies_ms": [884.129], "images_per_second": 1.131, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small bathroom with a white toilet, a shower curtain, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.27, 42.27, 35.17, 35.17, 35.17, 35.17, 35.17, 46.92, 46.92], "power_watts_avg": 39.36, "power_watts_peak": 46.92, "energy_joules_est": 34.81, "sample_count": 9, "duration_seconds": 0.884}, "timestamp": "2026-01-12T10:06:58.694770"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 935.889, "latencies_ms": [935.889], "images_per_second": 1.069, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is painted in a light yellow color, and the floor is covered with brown tiles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.6, "ram_available_mb": 109161.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.92, 46.92, 46.92, 51.76, 51.76, 51.76, 51.76, 51.76, 47.49, 47.49], "power_watts_avg": 49.45, "power_watts_peak": 51.76, "energy_joules_est": 46.3, "sample_count": 10, "duration_seconds": 0.936}, "timestamp": "2026-01-12T10:06:59.706046"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 741.584, "latencies_ms": [741.584], "images_per_second": 1.348, "prompt_tokens": 1099, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Two people are holding wine glasses and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.7, "ram_available_mb": 109169.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.49, 47.49, 47.49, 47.42, 47.42, 47.42, 47.42, 47.42], "power_watts_avg": 47.44, "power_watts_peak": 47.49, "energy_joules_est": 35.21, "sample_count": 8, "duration_seconds": 0.742}, "timestamp": "2026-01-12T10:07:00.517494"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1910.666, "latencies_ms": [1910.666], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. glasses: 2\n2. people: 3\n3. table: 1\n4. chair: 1\n5. wall: 1\n6. door: 1\n7. window: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13341.2, "ram_available_mb": 109165.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.1, 47.1, 47.1, 47.1, 47.1, 55.3, 55.3, 55.3, 55.3, 55.3, 47.15, 47.15, 47.15, 47.15, 47.15, 34.87, 34.87, 34.87, 34.87], "power_watts_avg": 46.69, "power_watts_peak": 55.3, "energy_joules_est": 89.23, "sample_count": 19, "duration_seconds": 1.911}, "timestamp": "2026-01-12T10:07:02.434661"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2495.145, "latencies_ms": [2495.145], "images_per_second": 0.401, "prompt_tokens": 1117, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The two people are in the foreground, with the man on the right holding a wine glass and the woman on the left holding a wine glass. The wine glasses are in the middle of the image, with the man on the right holding a wine glass and the woman on the left holding a wine glass. The man on the right is closer to the camera than the woman on the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.3, "ram_available_mb": 109156.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13340.6, "ram_available_mb": 109165.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.54, 34.54, 34.54, 34.54, 34.54, 47.12, 47.12, 47.12, 47.12, 47.12, 47.69, 47.69, 47.69, 47.69, 47.69, 34.88, 34.88, 34.88, 34.88, 34.88, 34.88, 34.88, 34.88, 34.88, 34.88], "power_watts_avg": 39.82, "power_watts_peak": 47.69, "energy_joules_est": 99.39, "sample_count": 25, "duration_seconds": 2.496}, "timestamp": "2026-01-12T10:07:05.008337"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1043.565, "latencies_ms": [1043.565], "images_per_second": 0.958, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two people are holding wine glasses and smiling at the camera. They are in a room with a table and chairs.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13332.7, "ram_available_mb": 109173.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.6, "ram_available_mb": 109148.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 34.77, 44.96, 44.96, 44.96, 44.96, 44.96, 46.45, 46.45], "power_watts_avg": 41.53, "power_watts_peak": 46.45, "energy_joules_est": 43.38, "sample_count": 11, "duration_seconds": 1.045}, "timestamp": "2026-01-12T10:07:06.171952"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1331.866, "latencies_ms": [1331.866], "images_per_second": 0.751, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming through the windows. The colors in the image are vibrant and the materials are mostly wood and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.4, "ram_available_mb": 109153.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.45, 46.45, 46.45, 42.35, 42.35, 42.35, 42.35, 42.35, 46.8, 46.8, 46.8, 46.8, 46.8, 41.23], "power_watts_avg": 44.74, "power_watts_peak": 46.8, "energy_joules_est": 59.6, "sample_count": 14, "duration_seconds": 1.332}, "timestamp": "2026-01-12T10:07:07.587749"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1040.283, "latencies_ms": [1040.283], "images_per_second": 0.961, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, with a clear blue sky and a beach in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13352.4, "ram_available_mb": 109153.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13346.5, "ram_available_mb": 109159.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.23, 41.23, 41.23, 41.23, 43.29, 43.29, 43.29, 43.29, 43.29, 46.42, 46.42], "power_watts_avg": 43.11, "power_watts_peak": 46.42, "energy_joules_est": 44.87, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-12T10:07:08.702675"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1963.341, "latencies_ms": [1963.341], "images_per_second": 0.509, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. surfboard: 1\n3. wave: 1\n4. ocean: 1\n5. sky: 1\n6. beach: 1\n7. sand: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.6, "ram_available_mb": 109167.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13341.0, "ram_available_mb": 109165.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.42, 46.42, 46.42, 42.6, 42.6, 42.6, 42.6, 42.6, 46.76, 46.76, 46.76, 46.76, 46.76, 43.1, 43.1, 43.1, 43.1, 43.1, 34.89, 34.89], "power_watts_avg": 43.57, "power_watts_peak": 46.76, "energy_joules_est": 85.55, "sample_count": 20, "duration_seconds": 1.964}, "timestamp": "2026-01-12T10:07:10.723314"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2252.185, "latencies_ms": [2252.185], "images_per_second": 0.444, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the middle ground, with the surfer's body and surfboard occupying a significant portion of the frame. The background features a sandy beach and a clear sky, providing a serene contrast to the dynamic action of the surfer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.1, "ram_available_mb": 109169.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13335.8, "ram_available_mb": 109170.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 35.17, 35.17, 35.17, 35.17, 35.17, 46.21, 46.21, 46.21, 46.21, 46.21, 45.95, 45.95, 45.95, 45.95, 45.95, 34.9, 34.9, 34.9, 34.9, 34.9, 34.88], "power_watts_avg": 39.82, "power_watts_peak": 46.21, "energy_joules_est": 89.7, "sample_count": 23, "duration_seconds": 2.253}, "timestamp": "2026-01-12T10:07:13.096231"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1012.1, "latencies_ms": [1012.1], "images_per_second": 0.988, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, with a beach and clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.9, "ram_available_mb": 109178.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.7, "ram_available_mb": 109154.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 40.57, 40.57, 40.57, 40.57, 40.57, 45.8, 45.8], "power_watts_avg": 39.45, "power_watts_peak": 45.8, "energy_joules_est": 39.97, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-12T10:07:14.260882"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1640.61, "latencies_ms": [1640.61], "images_per_second": 0.61, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a surfer riding a wave in a clear blue ocean, with the sun shining brightly overhead. The surfer is wearing a black wetsuit and blue board shorts, and the wave is a light blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.8, "ram_available_mb": 109162.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13346.6, "ram_available_mb": 109159.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.8, 45.8, 41.88, 41.88, 41.88, 41.88, 41.88, 46.44, 46.44, 46.44, 46.44, 46.44, 45.52, 45.52, 45.52, 45.52, 45.52], "power_watts_avg": 44.75, "power_watts_peak": 46.44, "energy_joules_est": 73.45, "sample_count": 17, "duration_seconds": 1.641}, "timestamp": "2026-01-12T10:07:15.978282"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 924.245, "latencies_ms": [924.245], "images_per_second": 1.082, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A collection of laptops, tablets, and a red and black backpack are scattered on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.7, "ram_available_mb": 109163.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [34.04, 34.04, 34.04, 34.04, 34.04, 47.01, 47.01, 47.01, 47.01, 47.01], "power_watts_avg": 40.52, "power_watts_peak": 47.01, "energy_joules_est": 37.48, "sample_count": 10, "duration_seconds": 0.925}, "timestamp": "2026-01-12T10:07:16.991319"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3794.526, "latencies_ms": [3794.526], "images_per_second": 0.264, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " laptop: 3, laptop: 1, laptop: 1, laptop: 1, laptop: 1, laptop: 1, laptop: 1, laptop: 1, backpack: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: ", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13330.9, "ram_available_mb": 109175.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.4, 46.4, 46.4, 46.4, 46.4, 46.48, 46.48, 46.48, 46.48, 46.48, 47.59, 47.59, 47.59, 47.59, 47.59, 34.97, 34.97, 34.97, 34.97, 34.97, 34.66, 34.66, 34.66, 34.66, 34.66, 34.68, 34.68, 34.68, 34.68, 34.68, 34.91, 34.91, 34.91, 34.91, 34.91, 34.73, 34.73, 34.73], "power_watts_avg": 39.54, "power_watts_peak": 47.59, "energy_joules_est": 150.05, "sample_count": 38, "duration_seconds": 3.795}, "timestamp": "2026-01-12T10:07:20.823125"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1757.647, "latencies_ms": [1757.647], "images_per_second": 0.569, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The laptop computer is positioned to the left of the backpack, while the tablet computer is situated to the right of the backpack. The cables are spread out in front of the backpack, with some extending towards the laptop computer and others towards the tablet computer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.9, "ram_available_mb": 109175.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13319.6, "ram_available_mb": 109186.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.73, 31.6, 31.6, 31.6, 31.6, 31.6, 46.41, 46.41, 46.41, 46.41, 46.41, 49.58, 49.58, 49.58, 49.58, 49.58, 34.83, 34.83], "power_watts_avg": 41.24, "power_watts_peak": 49.58, "energy_joules_est": 72.52, "sample_count": 18, "duration_seconds": 1.759}, "timestamp": "2026-01-12T10:07:22.686032"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 770.015, "latencies_ms": [770.015], "images_per_second": 1.299, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A collection of laptops and a backpack are placed on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.6, "ram_available_mb": 109186.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13379.4, "ram_available_mb": 109126.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 39.71, 39.71, 39.71, 39.71, 39.71], "power_watts_avg": 37.88, "power_watts_peak": 39.71, "energy_joules_est": 29.18, "sample_count": 8, "duration_seconds": 0.77}, "timestamp": "2026-01-12T10:07:23.496416"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1222.104, "latencies_ms": [1222.104], "images_per_second": 0.818, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image is taken in a room with a brown carpet, and the lighting is dim. The objects in the image are made of metal and plastic.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13371.5, "ram_available_mb": 109134.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13368.4, "ram_available_mb": 109137.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.0, 47.0, 47.0, 47.0, 47.0, 54.96, 54.96, 54.96, 54.96, 54.96, 47.56, 47.56, 47.56], "power_watts_avg": 50.19, "power_watts_peak": 54.96, "energy_joules_est": 61.35, "sample_count": 13, "duration_seconds": 1.222}, "timestamp": "2026-01-12T10:07:24.808966"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1276.489, "latencies_ms": [1276.489], "images_per_second": 0.783, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A skier in a vibrant orange and green outfit is captured mid-air, performing a jump on a snowy mountain, with a blurred figure in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.4, "ram_available_mb": 109139.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.6, "ram_available_mb": 109143.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.56, 47.56, 33.48, 33.48, 33.48, 33.48, 33.48, 46.42, 46.42, 46.42, 46.42, 46.42, 48.37], "power_watts_avg": 41.77, "power_watts_peak": 48.37, "energy_joules_est": 53.34, "sample_count": 13, "duration_seconds": 1.277}, "timestamp": "2026-01-12T10:07:26.123466"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1972.645, "latencies_ms": [1972.645], "images_per_second": 0.507, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. skier: 1\n2. skis: 2\n3. poles: 2\n4. helmet: 1\n5. jacket: 1\n6. pants: 1\n7. snow: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.7, "ram_available_mb": 109151.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13346.4, "ram_available_mb": 109159.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.37, 48.37, 48.37, 48.37, 42.91, 42.91, 42.91, 42.91, 42.91, 47.56, 47.56, 47.56, 47.56, 47.56, 40.03, 40.03, 40.03, 40.03, 40.03, 34.72], "power_watts_avg": 44.03, "power_watts_peak": 48.37, "energy_joules_est": 86.89, "sample_count": 20, "duration_seconds": 1.973}, "timestamp": "2026-01-12T10:07:28.140600"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1599.579, "latencies_ms": [1599.579], "images_per_second": 0.625, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The skier is in the foreground, with the snowboarder in the background. The skier is to the left of the snowboarder. The skier is closer to the camera than the snowboarder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.2, "ram_available_mb": 109162.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13406.0, "ram_available_mb": 109100.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 34.72, 38.42, 38.42, 38.42, 38.42, 38.42, 45.98, 45.98, 45.98, 45.98, 45.98, 43.23, 43.23, 43.23], "power_watts_avg": 40.99, "power_watts_peak": 45.98, "energy_joules_est": 65.61, "sample_count": 16, "duration_seconds": 1.601}, "timestamp": "2026-01-12T10:07:29.806532"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1173.044, "latencies_ms": [1173.044], "images_per_second": 0.852, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A skier in a vibrant orange suit and green helmet is performing a jump in the snow, while another skier stands in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13402.0, "ram_available_mb": 109104.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.4, "ram_available_mb": 109171.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.23, 43.23, 35.2, 35.2, 35.2, 35.2, 35.2, 47.99, 47.99, 47.99, 47.99, 47.99], "power_watts_avg": 41.86, "power_watts_peak": 47.99, "energy_joules_est": 49.12, "sample_count": 12, "duration_seconds": 1.173}, "timestamp": "2026-01-12T10:07:31.020437"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1697.567, "latencies_ms": [1697.567], "images_per_second": 0.589, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The skier is wearing a vibrant orange and green outfit, and the snow is a pristine white. The skier is in mid-air, performing a jump, and the sun is shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.4, "ram_available_mb": 109171.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13383.9, "ram_available_mb": 109122.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.65, 47.65, 47.65, 47.65, 47.65, 47.34, 47.34, 47.34, 47.34, 47.34, 47.35, 47.35, 47.35, 47.35, 47.35, 34.9, 34.9], "power_watts_avg": 45.97, "power_watts_peak": 47.65, "energy_joules_est": 78.05, "sample_count": 17, "duration_seconds": 1.698}, "timestamp": "2026-01-12T10:07:32.736820"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 842.355, "latencies_ms": [842.355], "images_per_second": 1.187, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is perched on a window sill, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.0, "ram_available_mb": 109130.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13390.2, "ram_available_mb": 109116.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 38.71, 38.71, 38.71, 38.71, 38.71, 47.81], "power_watts_avg": 38.45, "power_watts_peak": 47.81, "energy_joules_est": 32.41, "sample_count": 9, "duration_seconds": 0.843}, "timestamp": "2026-01-12T10:07:33.649853"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2070.322, "latencies_ms": [2070.322], "images_per_second": 0.483, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. window: 1\n2. bird: 1\n3. door: 1\n4. wall: 1\n5. door handle: 1\n6. window frame: 1\n7. window latch: 1\n8. bird's beak: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.5, "ram_available_mb": 109117.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13377.4, "ram_available_mb": 109128.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.81, 47.81, 47.81, 47.81, 51.57, 51.57, 51.57, 51.57, 51.57, 47.02, 47.02, 47.02, 47.02, 47.02, 40.12, 40.12, 40.12, 40.12, 40.12, 34.77, 34.77], "power_watts_avg": 45.44, "power_watts_peak": 51.57, "energy_joules_est": 94.11, "sample_count": 21, "duration_seconds": 2.071}, "timestamp": "2026-01-12T10:07:35.772119"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1357.219, "latencies_ms": [1357.219], "images_per_second": 0.737, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The bird is positioned in the foreground, on the right side of the window, while the water is in the background. The bird is closer to the viewer than the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.9, "ram_available_mb": 109134.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13452.6, "ram_available_mb": 109053.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 32.92, 32.92, 32.92, 32.92, 32.92, 46.25, 46.25, 46.25, 46.25, 46.25, 48.66, 48.66], "power_watts_avg": 40.19, "power_watts_peak": 48.66, "energy_joules_est": 54.59, "sample_count": 14, "duration_seconds": 1.358}, "timestamp": "2026-01-12T10:07:37.237198"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 861.201, "latencies_ms": [861.201], "images_per_second": 1.161, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is perched on a window sill, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13452.6, "ram_available_mb": 109053.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13490.2, "ram_available_mb": 109016.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [48.66, 48.66, 48.66, 37.69, 37.69, 37.69, 37.69, 37.69, 47.23], "power_watts_avg": 42.41, "power_watts_peak": 48.66, "energy_joules_est": 36.54, "sample_count": 9, "duration_seconds": 0.862}, "timestamp": "2026-01-12T10:07:38.149419"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2042.968, "latencies_ms": [2042.968], "images_per_second": 0.489, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a bird perched on a window sill, with a view of a body of water in the background. The bird is black, and the window sill is made of wood. The lighting in the image is natural, coming from the outside, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13490.2, "ram_available_mb": 109016.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13466.1, "ram_available_mb": 109040.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 47.23, 51.67, 51.67, 51.67, 51.67, 51.67, 46.99, 46.99, 46.99, 46.99, 46.99, 40.26, 40.26, 40.26, 40.26, 40.26, 34.83, 34.83], "power_watts_avg": 45.39, "power_watts_peak": 51.67, "energy_joules_est": 92.76, "sample_count": 21, "duration_seconds": 2.044}, "timestamp": "2026-01-12T10:07:40.268748"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1031.984, "latencies_ms": [1031.984], "images_per_second": 0.969, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two men are cleaning a bathroom with a bucket and a mop, and there is a toilet in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13458.2, "ram_available_mb": 109048.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13463.5, "ram_available_mb": 109042.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 29.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 33.0, 33.0, 33.0, 33.0, 33.0, 45.81, 45.81, 45.81, 45.81], "power_watts_avg": 37.99, "power_watts_peak": 45.81, "energy_joules_est": 39.26, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-12T10:07:41.434146"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1352.36, "latencies_ms": [1352.36], "images_per_second": 0.739, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. toilet\n2. trash can\n3. person\n4. broom\n5. bucket\n6. shelf\n7. toilet paper\n8. cleaning supplies", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13459.1, "ram_available_mb": 109047.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13451.5, "ram_available_mb": 109054.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.81, 46.53, 46.53, 46.53, 46.53, 46.53, 46.62, 46.62, 46.62, 46.62, 46.62, 48.62, 48.62, 48.62], "power_watts_avg": 46.96, "power_watts_peak": 48.62, "energy_joules_est": 63.53, "sample_count": 14, "duration_seconds": 1.353}, "timestamp": "2026-01-12T10:07:42.849608"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1720.177, "latencies_ms": [1720.177], "images_per_second": 0.581, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The toilet is located in the foreground, with the trash can and the person in the orange hat positioned further back. The person in the orange hat is standing near the toilet, while the person in the white shirt is closer to the trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13451.5, "ram_available_mb": 109054.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13479.5, "ram_available_mb": 109026.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.62, 48.62, 33.01, 33.01, 33.01, 33.01, 33.01, 47.04, 47.04, 47.04, 47.04, 47.04, 49.0, 49.0, 49.0, 49.0, 49.0, 34.74], "power_watts_avg": 43.18, "power_watts_peak": 49.0, "energy_joules_est": 74.31, "sample_count": 18, "duration_seconds": 1.721}, "timestamp": "2026-01-12T10:07:44.668401"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 795.417, "latencies_ms": [795.417], "images_per_second": 1.257, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are cleaning a bathroom with a bucket and a mop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13471.6, "ram_available_mb": 109034.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13458.6, "ram_available_mb": 109047.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.74, 34.74, 34.74, 40.11, 40.11, 40.11, 40.11, 40.11], "power_watts_avg": 38.1, "power_watts_peak": 40.11, "energy_joules_est": 30.32, "sample_count": 8, "duration_seconds": 0.796}, "timestamp": "2026-01-12T10:07:45.478807"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1059.376, "latencies_ms": [1059.376], "images_per_second": 0.944, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a yellowish hue, and the floor is covered in blue paint.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13454.6, "ram_available_mb": 109051.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13446.4, "ram_available_mb": 109059.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.53, 46.53, 46.53, 46.53, 46.53, 54.43, 54.43, 54.43, 54.43, 54.43, 48.22], "power_watts_avg": 50.27, "power_watts_peak": 54.43, "energy_joules_est": 53.29, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T10:07:46.593012"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1639.244, "latencies_ms": [1639.244], "images_per_second": 0.61, "prompt_tokens": 1100, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In the image, a person is seen walking down a hallway, holding an umbrella with the word \"opera\" written on it, under a rain shower, with the hallway's walls painted in a striking red color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13438.6, "ram_available_mb": 109067.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13399.7, "ram_available_mb": 109106.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.22, 48.22, 48.22, 48.22, 43.75, 43.75, 43.75, 43.75, 43.75, 47.01, 47.01, 47.01, 47.01, 47.01, 38.82, 38.82, 38.82], "power_watts_avg": 44.89, "power_watts_peak": 48.22, "energy_joules_est": 73.62, "sample_count": 17, "duration_seconds": 1.64}, "timestamp": "2026-01-12T10:07:48.310967"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1906.759, "latencies_ms": [1906.759], "images_per_second": 0.524, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. umbrella: 1\n3. wall: 2\n4. door: 1\n5. floor: 1\n6. light: 1\n7. picture: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13399.7, "ram_available_mb": 109106.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13395.6, "ram_available_mb": 109110.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.82, 38.82, 33.94, 33.94, 33.94, 33.94, 33.94, 46.59, 46.59, 46.59, 46.59, 46.59, 47.53, 47.53, 47.53, 47.53, 47.53, 34.91, 34.91], "power_watts_avg": 41.46, "power_watts_peak": 47.53, "energy_joules_est": 79.08, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T10:07:50.229754"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1748.1, "latencies_ms": [1748.1], "images_per_second": 0.572, "prompt_tokens": 1118, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The person is standing in the middle of the hallway, with the door on the right side and the wall on the left side. The person is holding the umbrella in front of them, which is blocking the view of the door and the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.6, "ram_available_mb": 109110.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13414.2, "ram_available_mb": 109092.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 36.27, 36.27, 36.27, 36.27, 36.27, 46.85, 46.85, 46.85, 46.85, 46.85, 45.64, 45.64, 45.64, 45.64, 45.64, 34.86], "power_watts_avg": 41.58, "power_watts_peak": 46.85, "energy_joules_est": 72.74, "sample_count": 18, "duration_seconds": 1.749}, "timestamp": "2026-01-12T10:07:52.099283"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1040.896, "latencies_ms": [1040.896], "images_per_second": 0.961, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is walking down a hallway with a black umbrella that has the word \"opera\" on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.3, "ram_available_mb": 109100.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13418.2, "ram_available_mb": 109088.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 44.17, 44.17, 44.17, 44.17, 44.17, 46.9, 46.9], "power_watts_avg": 41.28, "power_watts_peak": 46.9, "energy_joules_est": 42.99, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-12T10:07:53.213011"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1738.721, "latencies_ms": [1738.721], "images_per_second": 0.575, "prompt_tokens": 1110, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a person holding an umbrella with the word \"opera\" written on it, standing in a hallway with red walls and a white door. The lighting is dim, and the rain is falling outside, creating a dramatic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.3, "ram_available_mb": 109096.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13406.5, "ram_available_mb": 109099.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.9, 46.9, 46.9, 41.74, 41.74, 41.74, 41.74, 41.74, 46.55, 46.55, 46.55, 46.55, 46.55, 43.24, 43.24, 43.24, 43.24, 43.24], "power_watts_avg": 44.35, "power_watts_peak": 46.9, "energy_joules_est": 77.14, "sample_count": 18, "duration_seconds": 1.739}, "timestamp": "2026-01-12T10:07:55.029732"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1267.551, "latencies_ms": [1267.551], "images_per_second": 0.789, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a red shirt and a backpack is standing on a path in the woods, while another man in a yellow raincoat is standing on a staircase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13402.5, "ram_available_mb": 109103.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13416.5, "ram_available_mb": 109089.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.45, 34.45, 34.45, 34.45, 34.45, 46.67, 46.67, 46.67, 46.67, 46.67, 47.08, 47.08, 47.08], "power_watts_avg": 42.06, "power_watts_peak": 47.08, "energy_joules_est": 53.34, "sample_count": 13, "duration_seconds": 1.268}, "timestamp": "2026-01-12T10:07:56.346582"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1956.34, "latencies_ms": [1956.34], "images_per_second": 0.511, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. backpack: 1\n3. signpost: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13408.7, "ram_available_mb": 109097.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13420.5, "ram_available_mb": 109085.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.08, 47.08, 34.25, 34.25, 34.25, 34.25, 34.25, 47.26, 47.26, 47.26, 47.26, 47.26, 48.67, 48.67, 48.67, 48.67, 48.67, 34.53, 34.53, 34.53], "power_watts_avg": 42.43, "power_watts_peak": 48.67, "energy_joules_est": 83.03, "sample_count": 20, "duration_seconds": 1.957}, "timestamp": "2026-01-12T10:07:58.364039"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1671.11, "latencies_ms": [1671.11], "images_per_second": 0.598, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man in the red shirt is standing in the foreground, while the man in the yellow jacket is standing on the steps in the background. The man in the red shirt is closer to the camera than the man in the yellow jacket.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13420.5, "ram_available_mb": 109085.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13464.7, "ram_available_mb": 109041.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.53, 31.35, 31.35, 31.35, 31.35, 31.35, 45.96, 45.96, 45.96, 45.96, 45.96, 49.25, 49.25, 49.25, 49.25, 49.25, 34.95], "power_watts_avg": 41.31, "power_watts_peak": 49.25, "energy_joules_est": 69.07, "sample_count": 17, "duration_seconds": 1.672}, "timestamp": "2026-01-12T10:08:00.126384"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1191.242, "latencies_ms": [1191.242], "images_per_second": 0.839, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man in a red shirt and backpack stands on a rocky path, while another man in a yellow raincoat walks up a set of stairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13464.7, "ram_available_mb": 109041.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13497.7, "ram_available_mb": 109008.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.95, 34.95, 34.95, 34.95, 44.11, 44.11, 44.11, 44.11, 44.11, 47.59, 47.59, 47.59], "power_watts_avg": 41.93, "power_watts_peak": 47.59, "energy_joules_est": 49.96, "sample_count": 12, "duration_seconds": 1.192}, "timestamp": "2026-01-12T10:08:01.337511"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1403.912, "latencies_ms": [1403.912], "images_per_second": 0.712, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a man wearing a red shirt and blue jeans, standing on a rocky path in a lush, green forest. The lighting is natural and bright, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13489.9, "ram_available_mb": 109016.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.59, 47.59, 39.23, 39.23, 39.23, 39.23, 39.23, 47.68, 47.68, 47.68, 47.68, 47.68, 48.57, 48.57], "power_watts_avg": 44.78, "power_watts_peak": 48.57, "energy_joules_est": 62.88, "sample_count": 14, "duration_seconds": 1.404}, "timestamp": "2026-01-12T10:08:02.750680"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1184.038, "latencies_ms": [1184.038], "images_per_second": 0.845, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Five men are standing together in a room, with one man wearing a red tie and another wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13395.9, "ram_available_mb": 109110.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.57, 48.57, 48.57, 36.44, 36.44, 36.44, 36.44, 36.44, 51.86, 51.86, 51.86, 51.86], "power_watts_avg": 44.61, "power_watts_peak": 51.86, "energy_joules_est": 52.85, "sample_count": 12, "duration_seconds": 1.185}, "timestamp": "2026-01-12T10:08:03.971930"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2080.494, "latencies_ms": [2080.494], "images_per_second": 0.481, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 4\n2. chair: 2\n3. bottle: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.9, "ram_available_mb": 109110.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13444.4, "ram_available_mb": 109061.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.74, 49.74, 49.74, 49.74, 49.74, 48.75, 48.75, 48.75, 48.75, 48.75, 52.14, 52.14, 52.14, 52.14, 52.14, 38.69, 38.69, 38.69, 38.69, 38.69, 34.92], "power_watts_avg": 46.74, "power_watts_peak": 52.14, "energy_joules_est": 97.26, "sample_count": 21, "duration_seconds": 2.081}, "timestamp": "2026-01-12T10:08:06.091024"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2145.835, "latencies_ms": [2145.835], "images_per_second": 0.466, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man on the left is standing closer to the camera than the man on the right. The man in the middle is standing between the two men on the left and the man on the right. The man on the right is standing further away from the camera than the man on the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.5, "ram_available_mb": 109069.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 34.92, 40.41, 40.41, 40.41, 40.41, 40.41, 50.29, 50.29, 50.29, 50.29, 50.29, 45.67, 45.67, 45.67, 45.67, 45.67, 34.63, 34.63, 34.63], "power_watts_avg": 42.06, "power_watts_peak": 50.29, "energy_joules_est": 90.29, "sample_count": 22, "duration_seconds": 2.147}, "timestamp": "2026-01-12T10:08:08.361467"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1030.379, "latencies_ms": [1030.379], "images_per_second": 0.971, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Five men are posing for a picture in a room with a bar in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13414.6, "ram_available_mb": 109091.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.63, 31.21, 31.21, 31.21, 31.21, 31.21, 49.2, 49.2, 49.2, 49.2, 49.2], "power_watts_avg": 39.7, "power_watts_peak": 49.2, "energy_joules_est": 40.93, "sample_count": 11, "duration_seconds": 1.031}, "timestamp": "2026-01-12T10:08:09.532290"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1746.866, "latencies_ms": [1746.866], "images_per_second": 0.572, "prompt_tokens": 1442, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the windows. The colors in the image are mostly neutral, with the exception of the red chairs and the red and white banner in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13414.6, "ram_available_mb": 109091.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.0, "ram_available_mb": 109094.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [52.69, 52.69, 52.69, 52.69, 52.69, 46.59, 46.59, 46.59, 46.59, 46.59, 51.14, 51.14, 51.14, 51.14, 51.14, 40.14, 40.14, 40.14], "power_watts_avg": 48.47, "power_watts_peak": 52.69, "energy_joules_est": 84.68, "sample_count": 18, "duration_seconds": 1.747}, "timestamp": "2026-01-12T10:08:11.346849"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1527.281, "latencies_ms": [1527.281], "images_per_second": 0.655, "prompt_tokens": 1100, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, where a yellow traffic sign stands out against the backdrop of a red traffic light, a black pole, and a white car parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13408.0, "ram_available_mb": 109098.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13391.0, "ram_available_mb": 109115.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.14, 40.14, 33.25, 33.25, 33.25, 33.25, 33.25, 46.94, 46.94, 46.94, 46.94, 46.94, 49.06, 49.06, 49.06, 49.06], "power_watts_avg": 42.34, "power_watts_peak": 49.06, "energy_joules_est": 64.69, "sample_count": 16, "duration_seconds": 1.528}, "timestamp": "2026-01-12T10:08:12.963111"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1955.733, "latencies_ms": [1955.733], "images_per_second": 0.511, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. traffic light: 1\n2. street lamp: 1\n3. pole: 1\n4. sign: 1\n5. car: 1\n6. building: 1\n7. sidewalk: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.0, "ram_available_mb": 109115.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13395.1, "ram_available_mb": 109111.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.06, 32.82, 32.82, 32.82, 32.82, 32.82, 46.23, 46.23, 46.23, 46.23, 46.23, 48.33, 48.33, 48.33, 48.33, 48.33, 35.06, 35.06, 35.06, 35.06], "power_watts_avg": 41.31, "power_watts_peak": 49.06, "energy_joules_est": 80.81, "sample_count": 20, "duration_seconds": 1.956}, "timestamp": "2026-01-12T10:08:14.975481"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1577.455, "latencies_ms": [1577.455], "images_per_second": 0.634, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The yellow sign is positioned to the right of the black pole, which is situated in the foreground of the image. In the background, there is a street with cars and buildings, and a traffic light is visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.1, "ram_available_mb": 109111.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13409.0, "ram_available_mb": 109097.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.1, 34.1, 34.1, 34.1, 34.1, 46.31, 46.31, 46.31, 46.31, 46.31, 47.03, 47.03, 47.03, 47.03, 47.03, 34.83], "power_watts_avg": 42.0, "power_watts_peak": 47.03, "energy_joules_est": 66.28, "sample_count": 16, "duration_seconds": 1.578}, "timestamp": "2026-01-12T10:08:16.637590"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1687.99, "latencies_ms": [1687.99], "images_per_second": 0.592, "prompt_tokens": 1112, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, where a yellow traffic sign stands out against the backdrop of a red traffic light and a blue bus. The street is lined with buildings, shops, and cars, creating a lively urban atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13405.0, "ram_available_mb": 109101.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13318.6, "ram_available_mb": 109187.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 34.83, 42.66, 42.66, 42.66, 42.66, 42.66, 47.51, 47.51, 47.51, 47.51, 47.51, 39.52, 39.52, 39.52], "power_watts_avg": 41.69, "power_watts_peak": 47.51, "energy_joules_est": 70.39, "sample_count": 17, "duration_seconds": 1.688}, "timestamp": "2026-01-12T10:08:18.351722"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1472.21, "latencies_ms": [1472.21], "images_per_second": 0.679, "prompt_tokens": 1110, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a street corner with a yellow and black traffic sign, a black pole, and a red traffic light. The sky is cloudy, and the street is wet, suggesting recent rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.6, "ram_available_mb": 109187.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13301.5, "ram_available_mb": 109204.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.52, 39.52, 33.42, 33.42, 33.42, 33.42, 33.42, 47.28, 47.28, 47.28, 47.28, 47.28, 49.47, 49.47, 49.47], "power_watts_avg": 42.06, "power_watts_peak": 49.47, "energy_joules_est": 61.95, "sample_count": 15, "duration_seconds": 1.473}, "timestamp": "2026-01-12T10:08:19.864308"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 931.344, "latencies_ms": [931.344], "images_per_second": 1.074, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man wearing a white shirt and a white hat is playing tennis on a court at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13301.5, "ram_available_mb": 109204.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13339.2, "ram_available_mb": 109167.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.47, 49.47, 33.25, 33.25, 33.25, 33.25, 33.25, 47.41, 47.41, 47.41], "power_watts_avg": 40.74, "power_watts_peak": 49.47, "energy_joules_est": 37.98, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-12T10:08:20.876268"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1991.614, "latencies_ms": [1991.614], "images_per_second": 0.502, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. fence: 1\n5. sign: 1\n6. net: 1\n7. court: 1\n8. player: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.8, "ram_available_mb": 109173.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13317.6, "ram_available_mb": 109188.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.41, 46.84, 46.84, 46.84, 46.84, 46.84, 46.51, 46.51, 46.51, 46.51, 46.51, 49.39, 49.39, 49.39, 49.39, 49.39, 34.86, 34.86, 34.86, 34.86], "power_watts_avg": 45.03, "power_watts_peak": 49.39, "energy_joules_est": 89.7, "sample_count": 20, "duration_seconds": 1.992}, "timestamp": "2026-01-12T10:08:22.891915"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1624.695, "latencies_ms": [1624.695], "images_per_second": 0.616, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the net and fence in the background. The player is closer to the camera than the fence, and the net is positioned in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.7, "ram_available_mb": 109196.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.86, 32.94, 32.94, 32.94, 32.94, 32.94, 47.07, 47.07, 47.07, 47.07, 47.07, 49.36, 49.36, 49.36, 49.36, 49.36, 35.0], "power_watts_avg": 42.16, "power_watts_peak": 49.36, "energy_joules_est": 68.5, "sample_count": 17, "duration_seconds": 1.625}, "timestamp": "2026-01-12T10:08:24.618124"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 718.537, "latencies_ms": [718.537], "images_per_second": 1.392, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is playing tennis on a court at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13362.2, "ram_available_mb": 109144.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 35.0, 42.97, 42.97, 42.97, 42.97], "power_watts_avg": 38.98, "power_watts_peak": 42.97, "energy_joules_est": 28.04, "sample_count": 8, "duration_seconds": 0.719}, "timestamp": "2026-01-12T10:08:25.427105"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1483.802, "latencies_ms": [1483.802], "images_per_second": 0.674, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a tennis court with a green surface, a red fence, and a player wearing a white shirt and black shorts. The lighting is dim, and the court is illuminated by artificial lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.2, "ram_available_mb": 109144.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13413.7, "ram_available_mb": 109092.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.97, 43.85, 43.85, 43.85, 43.85, 43.85, 50.0, 50.0, 50.0, 50.0, 50.0, 49.08, 49.08, 49.08, 49.08], "power_watts_avg": 47.24, "power_watts_peak": 50.0, "energy_joules_est": 70.1, "sample_count": 15, "duration_seconds": 1.484}, "timestamp": "2026-01-12T10:08:26.940660"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1417.472, "latencies_ms": [1417.472], "images_per_second": 0.705, "prompt_tokens": 1432, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A group of people, including a man in a black jacket and a woman in a white helmet, are standing on a snowy slope and talking to each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.7, "ram_available_mb": 109092.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.9, "ram_available_mb": 109154.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [49.08, 33.86, 33.86, 33.86, 33.86, 33.86, 50.09, 50.09, 50.09, 50.09, 50.09, 52.82, 52.82, 52.82, 52.82], "power_watts_avg": 45.34, "power_watts_peak": 52.82, "energy_joules_est": 64.28, "sample_count": 15, "duration_seconds": 1.418}, "timestamp": "2026-01-12T10:08:28.460837"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1947.747, "latencies_ms": [1947.747], "images_per_second": 0.513, "prompt_tokens": 1446, "response_tokens_est": 51, "n_tiles": 1, "output_text": " 1. person: 2\n2. helmet: 2\n3. goggles: 2\n4. skis: 2\n5. ski poles: 2\n6. net: 1\n7. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.9, "ram_available_mb": 109154.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13393.1, "ram_available_mb": 109113.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.82, 35.24, 35.24, 35.24, 35.24, 35.24, 47.85, 47.85, 47.85, 47.85, 47.85, 52.48, 52.48, 52.48, 52.48, 52.48, 37.07, 37.07, 37.07, 37.07], "power_watts_avg": 43.95, "power_watts_peak": 52.82, "energy_joules_est": 85.63, "sample_count": 20, "duration_seconds": 1.948}, "timestamp": "2026-01-12T10:08:30.477749"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1847.094, "latencies_ms": [1847.094], "images_per_second": 0.541, "prompt_tokens": 1450, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The skier in the foreground is wearing a helmet and goggles, while the skier in the background is wearing a helmet and goggles. The skier in the foreground is standing closer to the camera than the skier in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.1, "ram_available_mb": 109113.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.65, 33.65, 33.65, 33.65, 33.65, 44.28, 44.28, 44.28, 44.28, 44.28, 50.91, 50.91, 50.91, 50.91, 50.91, 41.08, 41.08, 41.08, 41.08], "power_watts_avg": 42.55, "power_watts_peak": 50.91, "energy_joules_est": 78.63, "sample_count": 19, "duration_seconds": 1.848}, "timestamp": "2026-01-12T10:08:32.451087"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1235.901, "latencies_ms": [1235.901], "images_per_second": 0.809, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of people are standing on a snowy hill, wearing helmets and goggles, and some of them are holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.8, "ram_available_mb": 109146.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13397.1, "ram_available_mb": 109109.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.02, 33.02, 33.02, 33.02, 33.02, 45.42, 45.42, 45.42, 45.42, 45.42, 51.63, 51.63, 51.63], "power_watts_avg": 42.08, "power_watts_peak": 51.63, "energy_joules_est": 52.04, "sample_count": 13, "duration_seconds": 1.237}, "timestamp": "2026-01-12T10:08:33.816666"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1595.836, "latencies_ms": [1595.836], "images_per_second": 0.627, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a group of people wearing helmets and goggles, standing on a snowy slope. The sky is clear, and the sun is shining brightly, casting a white glow on the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.6, "ram_available_mb": 109113.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13379.2, "ram_available_mb": 109127.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [51.63, 51.63, 37.23, 37.23, 37.23, 37.23, 37.23, 50.73, 50.73, 50.73, 50.73, 50.73, 53.03, 53.03, 53.03, 53.03], "power_watts_avg": 47.2, "power_watts_peak": 53.03, "energy_joules_est": 75.35, "sample_count": 16, "duration_seconds": 1.596}, "timestamp": "2026-01-12T10:08:35.435581"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 972.36, "latencies_ms": [972.36], "images_per_second": 1.028, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue truck with a trailer is driving down a wet street with houses and trees on either side.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13370.3, "ram_available_mb": 109136.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13369.7, "ram_available_mb": 109136.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [53.03, 33.74, 33.74, 33.74, 33.74, 33.74, 47.91, 47.91, 47.91, 47.91], "power_watts_avg": 41.34, "power_watts_peak": 53.03, "energy_joules_est": 40.2, "sample_count": 10, "duration_seconds": 0.973}, "timestamp": "2026-01-12T10:08:36.450276"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1931.625, "latencies_ms": [1931.625], "images_per_second": 0.518, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. truck: 1\n2. street: 1\n3. road: 1\n4. sidewalk: 1\n5. grass: 1\n6. trees: 1\n7. house: 1\n8. street light: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13369.7, "ram_available_mb": 109136.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13396.3, "ram_available_mb": 109110.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.91, 47.55, 47.55, 47.55, 47.55, 47.55, 47.04, 47.04, 47.04, 47.04, 47.04, 48.13, 48.13, 48.13, 48.13, 48.13, 34.95, 34.95, 34.95, 34.95], "power_watts_avg": 45.07, "power_watts_peak": 48.13, "energy_joules_est": 87.07, "sample_count": 20, "duration_seconds": 1.932}, "timestamp": "2026-01-12T10:08:38.466083"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1303.473, "latencies_ms": [1303.473], "images_per_second": 0.767, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The blue truck is on the left side of the road, while the white car is on the right side. The truck is closer to the camera than the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.3, "ram_available_mb": 109110.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13419.1, "ram_available_mb": 109087.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.95, 33.19, 33.19, 33.19, 33.19, 33.19, 46.76, 46.76, 46.76, 46.76, 46.76, 48.41, 48.41], "power_watts_avg": 40.89, "power_watts_peak": 48.41, "energy_joules_est": 53.31, "sample_count": 13, "duration_seconds": 1.304}, "timestamp": "2026-01-12T10:08:39.777903"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 822.542, "latencies_ms": [822.542], "images_per_second": 1.216, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A blue truck is driving down a wet street with houses on the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.1, "ram_available_mb": 109087.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13416.2, "ram_available_mb": 109090.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.41, 48.41, 48.41, 37.87, 37.87, 37.87, 37.87, 37.87, 47.93], "power_watts_avg": 42.5, "power_watts_peak": 48.41, "energy_joules_est": 34.97, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-12T10:08:40.688918"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 687.979, "latencies_ms": [687.979], "images_per_second": 1.454, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The truck is blue and the road is wet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.2, "ram_available_mb": 109090.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13407.1, "ram_available_mb": 109099.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.93, 47.93, 47.93, 50.85, 50.85, 50.85, 50.85], "power_watts_avg": 49.6, "power_watts_peak": 50.85, "energy_joules_est": 34.15, "sample_count": 7, "duration_seconds": 0.689}, "timestamp": "2026-01-12T10:08:41.398663"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1290.832, "latencies_ms": [1290.832], "images_per_second": 0.775, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a large airplane is seen on a runway, with a mountainous landscape in the background, and several red and white lights are visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.2, "ram_available_mb": 109103.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13412.3, "ram_available_mb": 109094.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [50.85, 45.0, 45.0, 45.0, 45.0, 45.0, 54.7, 54.7, 54.7, 54.7, 54.7, 49.79, 49.79], "power_watts_avg": 49.92, "power_watts_peak": 54.7, "energy_joules_est": 64.45, "sample_count": 13, "duration_seconds": 1.291}, "timestamp": "2026-01-12T10:08:42.712786"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 975.009, "latencies_ms": [975.009], "images_per_second": 1.026, "prompt_tokens": 1113, "response_tokens_est": 21, "n_tiles": 1, "output_text": " airplane: 1\nrunway: 1\nmountains: 1\nlight: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.4, "ram_available_mb": 109101.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.79, 49.79, 49.79, 40.73, 40.73, 40.73, 40.73, 40.73, 47.85, 47.85], "power_watts_avg": 44.87, "power_watts_peak": 49.79, "energy_joules_est": 43.77, "sample_count": 10, "duration_seconds": 0.976}, "timestamp": "2026-01-12T10:08:43.724056"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1718.828, "latencies_ms": [1718.828], "images_per_second": 0.582, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The airplane is in the foreground, with the runway and lights in the middle ground, and the mountains in the background. The airplane is positioned in the center of the image, with the runway extending towards the left and the lights on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.6, "ram_available_mb": 109110.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.85, 47.85, 47.85, 47.21, 47.21, 47.21, 47.21, 47.21, 47.81, 47.81, 47.81, 47.81, 47.81, 43.52, 43.52, 43.52, 43.52, 43.52], "power_watts_avg": 46.46, "power_watts_peak": 47.85, "energy_joules_est": 79.88, "sample_count": 18, "duration_seconds": 1.719}, "timestamp": "2026-01-12T10:08:45.541104"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 855.37, "latencies_ms": [855.37], "images_per_second": 1.169, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " An airplane is on the runway at an airport, with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13408.1, "ram_available_mb": 109098.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13402.7, "ram_available_mb": 109103.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.48, 34.48, 34.48, 34.48, 34.48, 46.39, 46.39, 46.39, 46.39], "power_watts_avg": 39.77, "power_watts_peak": 46.39, "energy_joules_est": 34.05, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-12T10:08:46.452413"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1376.24, "latencies_ms": [1376.24], "images_per_second": 0.727, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a large airplane on a runway with a hazy sky in the background. The airplane is white with blue accents, and the runway is wet, reflecting the light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.8, "ram_available_mb": 109111.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13394.2, "ram_available_mb": 109112.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.39, 44.88, 44.88, 44.88, 44.88, 44.88, 47.93, 47.93, 47.93, 47.93, 47.93, 48.64, 48.64, 48.64], "power_watts_avg": 46.88, "power_watts_peak": 48.64, "energy_joules_est": 64.55, "sample_count": 14, "duration_seconds": 1.377}, "timestamp": "2026-01-12T10:08:47.869390"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1248.589, "latencies_ms": [1248.589], "images_per_second": 0.801, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of people are enjoying a day at the beach, with one person holding a tennis racket and another holding a blue bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.2, "ram_available_mb": 109116.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13388.0, "ram_available_mb": 109118.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.64, 48.64, 33.01, 33.01, 33.01, 33.01, 33.01, 47.27, 47.27, 47.27, 47.27, 47.27, 49.43], "power_watts_avg": 42.16, "power_watts_peak": 49.43, "energy_joules_est": 52.67, "sample_count": 13, "duration_seconds": 1.249}, "timestamp": "2026-01-12T10:08:49.183257"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1382.662, "latencies_ms": [1382.662], "images_per_second": 0.723, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " 1. beach\n2. people\n3. flag\n4. mountain\n5. lifeguard station\n6. car\n7. beach umbrella\n8. beach chair", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.0, "ram_available_mb": 109118.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.0, "ram_available_mb": 109112.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.43, 49.43, 49.43, 49.43, 40.98, 40.98, 40.98, 40.98, 46.77, 46.77, 46.77, 46.77, 46.77, 41.78], "power_watts_avg": 45.52, "power_watts_peak": 49.43, "energy_joules_est": 62.94, "sample_count": 14, "duration_seconds": 1.383}, "timestamp": "2026-01-12T10:08:50.598846"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2225.729, "latencies_ms": [2225.729], "images_per_second": 0.449, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The woman in the orange shirt is standing closer to the camera than the woman in the yellow hoodie. The woman in the orange shirt is standing in the foreground, while the woman in the yellow hoodie is standing in the background. The woman in the orange shirt is also standing closer to the camera than the woman in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.1, "ram_available_mb": 109120.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13384.3, "ram_available_mb": 109122.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.78, 41.78, 41.78, 41.78, 44.88, 44.88, 44.88, 44.88, 44.88, 47.42, 47.42, 47.42, 47.42, 47.42, 38.32, 38.32, 38.32, 38.32, 38.32, 34.86, 34.86, 34.86, 34.86], "power_watts_avg": 41.73, "power_watts_peak": 47.42, "energy_joules_est": 92.89, "sample_count": 23, "duration_seconds": 2.226}, "timestamp": "2026-01-12T10:08:52.919568"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 799.391, "latencies_ms": [799.391], "images_per_second": 1.251, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of people are on a beach with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13380.4, "ram_available_mb": 109125.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13396.4, "ram_available_mb": 109109.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [34.86, 32.16, 32.16, 32.16, 32.16, 32.16, 45.29, 45.29], "power_watts_avg": 35.78, "power_watts_peak": 45.29, "energy_joules_est": 28.62, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-12T10:08:53.780894"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2040.67, "latencies_ms": [2040.67], "images_per_second": 0.49, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image is a vibrant depiction of a sunny day at the beach, with the golden sand underfoot and the clear blue sky above. The people in the photo are dressed in casual beach attire, with the woman in the foreground wearing a bright orange shirt and the man in the background sporting a black jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.4, "ram_available_mb": 109109.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13299.1, "ram_available_mb": 109207.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.29, 45.29, 45.29, 50.84, 50.84, 50.84, 50.84, 50.84, 48.09, 48.09, 48.09, 48.09, 45.57, 45.57, 45.57, 45.57, 45.57, 34.96, 34.96, 34.96, 34.96], "power_watts_avg": 45.24, "power_watts_peak": 50.84, "energy_joules_est": 92.35, "sample_count": 21, "duration_seconds": 2.041}, "timestamp": "2026-01-12T10:08:55.896550"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1040.039, "latencies_ms": [1040.039], "images_per_second": 0.962, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A tennis player is standing on a blue tennis court, holding a tennis racket and looking down at the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13299.1, "ram_available_mb": 109207.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13345.5, "ram_available_mb": 109160.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [34.96, 32.06, 32.06, 32.06, 32.06, 32.06, 45.66, 45.66, 45.66, 45.66, 45.66], "power_watts_avg": 38.51, "power_watts_peak": 45.66, "energy_joules_est": 40.08, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-12T10:08:57.061397"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2073.247, "latencies_ms": [2073.247], "images_per_second": 0.482, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. tennis shoes: 2\n5. shorts: 1\n6. shirt: 1\n7. headband: 1\n8. wristband: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13341.5, "ram_available_mb": 109164.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13336.6, "ram_available_mb": 109169.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.52, 48.52, 48.52, 48.52, 48.52, 45.79, 45.79, 45.79, 45.79, 45.79, 46.64, 46.64, 46.64, 46.64, 46.64, 36.59, 36.59, 36.59, 36.59, 36.59, 34.79], "power_watts_avg": 43.93, "power_watts_peak": 48.52, "energy_joules_est": 91.1, "sample_count": 21, "duration_seconds": 2.074}, "timestamp": "2026-01-12T10:08:59.180262"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1729.982, "latencies_ms": [1729.982], "images_per_second": 0.578, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the blue tennis court serving as the dominant background. The player's shadow is cast on the court, indicating the direction of the sunlight and the player's position relative to the sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.6, "ram_available_mb": 109169.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.2, "ram_available_mb": 109155.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.79, 37.69, 37.69, 37.69, 37.69, 37.69, 46.18, 46.18, 46.18, 46.18, 46.18, 43.28, 43.28, 43.28, 43.28, 43.28], "power_watts_avg": 41.12, "power_watts_peak": 46.18, "energy_joules_est": 71.17, "sample_count": 18, "duration_seconds": 1.731}, "timestamp": "2026-01-12T10:09:01.045137"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 941.119, "latencies_ms": [941.119], "images_per_second": 1.063, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A tennis player is standing on a blue court, holding a tennis racket and looking down.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13366.9, "ram_available_mb": 109139.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.67, 34.67, 34.67, 34.67, 34.67, 45.89, 45.89, 45.89, 45.89, 45.89], "power_watts_avg": 40.28, "power_watts_peak": 45.89, "energy_joules_est": 37.94, "sample_count": 10, "duration_seconds": 0.942}, "timestamp": "2026-01-12T10:09:02.054706"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1367.467, "latencies_ms": [1367.467], "images_per_second": 0.731, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a tennis player standing on a blue court with a white logo on the ground. The lighting is bright and the player is wearing a blue shirt and white shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.0, "ram_available_mb": 109143.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.9, "ram_available_mb": 109146.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.6, 46.6, 46.6, 46.6, 46.6, 46.6, 46.6, 46.6, 46.6, 46.6, 46.63, 46.63, 46.63, 46.63], "power_watts_avg": 46.61, "power_watts_peak": 46.63, "energy_joules_est": 63.75, "sample_count": 14, "duration_seconds": 1.368}, "timestamp": "2026-01-12T10:09:03.470594"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1189.602, "latencies_ms": [1189.602], "images_per_second": 0.841, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A woman in a floral shirt and beige shorts is standing in a kitchen with a large black stove and a white cabinet in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.0, "ram_available_mb": 109154.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13371.3, "ram_available_mb": 109135.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.63, 35.44, 35.44, 35.44, 35.44, 35.44, 47.13, 47.13, 47.13, 47.13, 47.13, 47.95], "power_watts_avg": 42.29, "power_watts_peak": 47.95, "energy_joules_est": 50.33, "sample_count": 12, "duration_seconds": 1.19}, "timestamp": "2026-01-12T10:09:04.683947"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1944.666, "latencies_ms": [1944.666], "images_per_second": 0.514, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. stove: 1\n3. cupboard: 1\n4. shelf: 1\n5. dish: 1\n6. pot: 1\n7. kettle: 1\n8. cup: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13371.3, "ram_available_mb": 109135.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13384.2, "ram_available_mb": 109122.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.95, 47.95, 47.95, 47.95, 41.12, 41.12, 41.12, 41.12, 41.12, 47.82, 47.82, 47.82, 47.82, 40.39, 40.39, 40.39, 40.39, 40.39, 34.81, 34.81], "power_watts_avg": 43.01, "power_watts_peak": 47.95, "energy_joules_est": 83.66, "sample_count": 20, "duration_seconds": 1.945}, "timestamp": "2026-01-12T10:09:06.700857"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1545.687, "latencies_ms": [1545.687], "images_per_second": 0.647, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The woman is standing to the left of the stove, which is located in the center of the image. The stove is positioned in the foreground, with the woman's body and the kitchen counter in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13384.2, "ram_available_mb": 109122.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13391.9, "ram_available_mb": 109114.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.81, 36.4, 36.4, 36.4, 36.4, 36.4, 45.8, 45.8, 45.8, 45.8, 45.8, 43.22, 43.22, 43.22], "power_watts_avg": 40.32, "power_watts_peak": 45.8, "energy_joules_est": 62.35, "sample_count": 16, "duration_seconds": 1.546}, "timestamp": "2026-01-12T10:09:08.364660"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 776.25, "latencies_ms": [776.25], "images_per_second": 1.288, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A woman is standing in a kitchen with a large black stove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13384.0, "ram_available_mb": 109122.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13407.8, "ram_available_mb": 109098.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [43.22, 43.22, 32.59, 32.59, 32.59, 32.59, 32.59, 46.63], "power_watts_avg": 37.0, "power_watts_peak": 46.63, "energy_joules_est": 28.74, "sample_count": 8, "duration_seconds": 0.777}, "timestamp": "2026-01-12T10:09:09.175648"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1676.029, "latencies_ms": [1676.029], "images_per_second": 0.597, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is a black and white photo with a vintage feel, capturing a woman in a kitchen with a large black stove and a white wall in the background. The lighting is soft and diffused, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.8, "ram_available_mb": 109102.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13389.6, "ram_available_mb": 109116.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.63, 46.63, 46.63, 46.63, 55.92, 55.92, 55.92, 55.92, 55.92, 47.65, 47.65, 47.65, 47.65, 47.65, 40.67, 40.67, 40.67], "power_watts_avg": 48.61, "power_watts_peak": 55.92, "energy_joules_est": 81.49, "sample_count": 17, "duration_seconds": 1.676}, "timestamp": "2026-01-12T10:09:10.890438"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1096.86, "latencies_ms": [1096.86], "images_per_second": 0.912, "prompt_tokens": 1432, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two giraffes are standing in front of a building, with one of them eating leaves from a tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.6, "ram_available_mb": 109116.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13321.5, "ram_available_mb": 109184.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [40.67, 32.2, 32.2, 32.2, 32.2, 32.2, 51.56, 51.56, 51.56, 51.56, 51.56], "power_watts_avg": 41.77, "power_watts_peak": 51.56, "energy_joules_est": 45.82, "sample_count": 11, "duration_seconds": 1.097}, "timestamp": "2026-01-12T10:09:12.003554"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2068.713, "latencies_ms": [2068.713], "images_per_second": 0.483, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. giraffe: 2\n2. giraffe: 2\n3. giraffe: 2\n4. giraffe: 2\n5. giraffe: 2\n6. giraffe: 2\n7. giraffe: 2\n8. giraffe: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.5, "ram_available_mb": 109184.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.1, "ram_available_mb": 109130.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [54.17, 54.17, 54.17, 54.17, 54.17, 48.7, 48.7, 48.7, 48.7, 48.7, 52.14, 52.14, 52.14, 52.14, 52.14, 38.03, 38.03, 38.03, 38.03, 38.03, 35.02], "power_watts_avg": 47.63, "power_watts_peak": 54.17, "energy_joules_est": 98.56, "sample_count": 21, "duration_seconds": 2.069}, "timestamp": "2026-01-12T10:09:14.118685"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1609.7, "latencies_ms": [1609.7], "images_per_second": 0.621, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The giraffes are positioned in the foreground of the image, with the building in the background. The giraffes are standing on the left side of the image, while the building is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.2, "ram_available_mb": 109134.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13383.8, "ram_available_mb": 109122.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.02, 35.02, 35.02, 35.02, 43.61, 43.61, 43.61, 43.61, 43.61, 51.52, 51.52, 51.52, 51.52, 51.52, 43.56, 43.56, 43.56], "power_watts_avg": 43.91, "power_watts_peak": 51.52, "energy_joules_est": 70.7, "sample_count": 17, "duration_seconds": 1.61}, "timestamp": "2026-01-12T10:09:15.833657"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1011.054, "latencies_ms": [1011.054], "images_per_second": 0.989, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two giraffes are standing in a zoo enclosure, one of them eating from a tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.6, "ram_available_mb": 109135.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13386.1, "ram_available_mb": 109120.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [43.56, 43.56, 33.22, 33.22, 33.22, 33.22, 33.22, 50.47, 50.47, 50.47, 50.47], "power_watts_avg": 41.37, "power_watts_peak": 50.47, "energy_joules_est": 41.84, "sample_count": 11, "duration_seconds": 1.011}, "timestamp": "2026-01-12T10:09:16.945464"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 900.433, "latencies_ms": [900.433], "images_per_second": 1.111, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The giraffes are brown and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.2, "ram_available_mb": 109128.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13393.8, "ram_available_mb": 109112.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [50.47, 49.93, 49.93, 49.93, 49.93, 49.93, 50.15, 50.15, 50.15], "power_watts_avg": 50.06, "power_watts_peak": 50.47, "energy_joules_est": 45.11, "sample_count": 9, "duration_seconds": 0.901}, "timestamp": "2026-01-12T10:09:17.856379"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1003.833, "latencies_ms": [1003.833], "images_per_second": 0.996, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young boy wearing a green and yellow baseball uniform is swinging a blue and white baseball bat at a baseball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.0, "ram_available_mb": 109120.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13370.7, "ram_available_mb": 109135.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [50.15, 50.15, 52.81, 52.81, 52.81, 52.81, 52.81, 48.34, 48.34, 48.34], "power_watts_avg": 50.94, "power_watts_peak": 52.81, "energy_joules_est": 51.15, "sample_count": 10, "duration_seconds": 1.004}, "timestamp": "2026-01-12T10:09:18.870544"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2036.234, "latencies_ms": [2036.234], "images_per_second": 0.491, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. boy: 1\n2. helmet: 1\n3. bat: 1\n4. ball: 1\n5. chain link fence: 1\n6. grass: 1\n7. chain link fence: 1\n8. baseball glove: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.7, "ram_available_mb": 109139.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.4, "ram_available_mb": 109154.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.34, 48.34, 47.69, 47.69, 47.69, 47.69, 47.69, 48.09, 48.09, 48.09, 48.09, 48.09, 49.28, 49.28, 49.28, 49.28, 49.28, 34.97, 34.97, 34.97, 34.97], "power_watts_avg": 45.8, "power_watts_peak": 49.28, "energy_joules_est": 93.29, "sample_count": 21, "duration_seconds": 2.037}, "timestamp": "2026-01-12T10:09:20.987623"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1326.905, "latencies_ms": [1326.905], "images_per_second": 0.754, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The baseball player is in the foreground, holding a bat and swinging it towards the ball. The ball is in the middle ground, and the fence is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.4, "ram_available_mb": 109154.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.2, "ram_available_mb": 109154.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.41, 33.41, 33.41, 33.41, 33.41, 45.88, 45.88, 45.88, 45.88, 45.88, 47.36, 47.36, 47.36, 47.36], "power_watts_avg": 41.85, "power_watts_peak": 47.36, "energy_joules_est": 55.57, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-12T10:09:22.452468"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 853.753, "latencies_ms": [853.753], "images_per_second": 1.171, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young boy is playing baseball in a field with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.2, "ram_available_mb": 109158.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13357.5, "ram_available_mb": 109148.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 30.0}, "power_stats": {"power_watts_samples": [47.36, 32.6, 32.6, 32.6, 32.6, 32.6, 46.7, 46.7, 46.7], "power_watts_avg": 38.94, "power_watts_peak": 47.36, "energy_joules_est": 33.26, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-12T10:09:23.364102"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1973.79, "latencies_ms": [1973.79], "images_per_second": 0.507, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures a young boy in a green and yellow baseball uniform, swinging a blue bat at a white baseball. The scene is bathed in bright sunlight, casting a warm glow on the boy and the baseball. The chain link fence in the background adds a rustic charm to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.6, "ram_available_mb": 109156.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13358.5, "ram_available_mb": 109147.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.7, 46.7, 48.32, 48.32, 48.32, 48.32, 48.32, 47.35, 47.35, 47.35, 47.35, 47.35, 48.58, 48.58, 48.58, 48.58, 48.58, 34.66, 34.66, 34.66], "power_watts_avg": 45.93, "power_watts_peak": 48.58, "energy_joules_est": 90.68, "sample_count": 20, "duration_seconds": 1.974}, "timestamp": "2026-01-12T10:09:25.381095"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1572.735, "latencies_ms": [1572.735], "images_per_second": 0.636, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a bustling scene at a vintage car show, with a variety of classic vehicles parked on cobblestone streets, including a red bus and a black car, while people walk around and observe the exhibits.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13358.5, "ram_available_mb": 109147.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.5, "ram_available_mb": 109153.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.66, 34.66, 32.89, 32.89, 32.89, 32.89, 32.89, 47.14, 47.14, 47.14, 47.14, 47.14, 49.63, 49.63, 49.63, 49.63], "power_watts_avg": 41.75, "power_watts_peak": 49.63, "energy_joules_est": 65.69, "sample_count": 16, "duration_seconds": 1.573}, "timestamp": "2026-01-12T10:09:26.997908"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2124.217, "latencies_ms": [2124.217], "images_per_second": 0.471, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. black car: 2\n2. red bus: 1\n3. black motorcycle: 1\n4. green tank: 1\n5. red flag: 1\n6. black car: 1\n7. black motorcycle: 1\n8. red flag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.6, "ram_available_mb": 109161.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 34.15, 34.15, 47.48, 47.48, 47.48, 47.48, 47.48, 48.19, 48.19, 48.19, 48.19, 48.19, 34.86, 34.86, 34.86, 34.86, 34.86, 34.74, 34.74], "power_watts_avg": 40.58, "power_watts_peak": 48.19, "energy_joules_est": 86.22, "sample_count": 22, "duration_seconds": 2.125}, "timestamp": "2026-01-12T10:09:29.219681"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1731.449, "latencies_ms": [1731.449], "images_per_second": 0.578, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The motorcycles are positioned in the foreground, with the cars parked behind them. The red bus is located in the background, while the construction site is situated further away. The trees are positioned in the background, providing a natural backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.1, "ram_available_mb": 109147.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.74, 34.74, 34.74, 36.05, 36.05, 36.05, 36.05, 36.05, 45.44, 45.44, 45.44, 45.44, 45.44, 44.0, 44.0, 44.0, 44.0, 44.0], "power_watts_avg": 40.65, "power_watts_peak": 45.44, "energy_joules_est": 70.4, "sample_count": 18, "duration_seconds": 1.732}, "timestamp": "2026-01-12T10:09:31.088189"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 957.715, "latencies_ms": [957.715], "images_per_second": 1.044, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered in a parking lot, with vintage cars and motorcycles parked around them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.1, "ram_available_mb": 109147.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 34.73, 34.73, 45.15, 45.15, 45.15, 45.15, 46.57], "power_watts_avg": 40.09, "power_watts_peak": 46.57, "energy_joules_est": 38.41, "sample_count": 10, "duration_seconds": 0.958}, "timestamp": "2026-01-12T10:09:32.100326"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1837.607, "latencies_ms": [1837.607], "images_per_second": 0.544, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a cobblestone street with a variety of vehicles, including vintage cars and motorcycles, parked on the side. The sky is clear and blue, indicating a sunny day. The vehicles are mostly black and white, with some having red and green accents.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.1, "ram_available_mb": 109147.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.57, 46.57, 46.57, 46.57, 46.81, 46.81, 46.81, 46.81, 46.81, 47.08, 47.08, 47.08, 47.08, 47.08, 37.34, 37.34, 37.34, 37.34, 37.34], "power_watts_avg": 44.34, "power_watts_peak": 47.08, "energy_joules_est": 81.5, "sample_count": 19, "duration_seconds": 1.838}, "timestamp": "2026-01-12T10:09:34.020153"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1568.615, "latencies_ms": [1568.615], "images_per_second": 0.638, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a close-up view of two parking meters, their backs facing the camera, with the sun setting in the background, casting a warm glow and creating a bokeh effect with the surrounding lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.0, "ram_available_mb": 109152.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.71, 33.71, 33.71, 33.71, 33.71, 45.11, 45.11, 45.11, 45.11, 45.11, 46.54, 46.54, 46.54, 46.54, 46.54, 35.0], "power_watts_avg": 41.36, "power_watts_peak": 46.54, "energy_joules_est": 64.91, "sample_count": 16, "duration_seconds": 1.569}, "timestamp": "2026-01-12T10:09:35.689365"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 636.861, "latencies_ms": [636.861], "images_per_second": 1.57, "prompt_tokens": 1113, "response_tokens_est": 8, "n_tiles": 1, "output_text": " 1. parking meter: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.0, "ram_available_mb": 109144.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13362.0, "ram_available_mb": 109144.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 35.0, 41.79, 41.79, 41.79], "power_watts_avg": 37.91, "power_watts_peak": 41.79, "energy_joules_est": 24.17, "sample_count": 7, "duration_seconds": 0.637}, "timestamp": "2026-01-12T10:09:36.399447"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1838.894, "latencies_ms": [1838.894], "images_per_second": 0.544, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The two parking meters are positioned in the foreground, with the sun setting in the background, creating a warm and inviting atmosphere. The parking meters are relatively close to the camera, while the sun is far away, creating a sense of depth and perspective in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.6, "ram_available_mb": 109148.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.79, 44.54, 44.54, 44.54, 44.54, 44.54, 52.29, 52.29, 52.29, 52.29, 52.29, 49.73, 49.73, 49.73, 49.73, 49.73, 34.81, 34.81, 34.81], "power_watts_avg": 46.27, "power_watts_peak": 52.29, "energy_joules_est": 85.1, "sample_count": 19, "duration_seconds": 1.839}, "timestamp": "2026-01-12T10:09:38.317856"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1662.459, "latencies_ms": [1662.459], "images_per_second": 0.602, "prompt_tokens": 1111, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a serene moment at a parking meter, bathed in the warm glow of the setting sun. The parking meter, with its metallic sheen and black color, stands out against the soft, golden light of the sunset.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 32.2, 32.2, 32.2, 32.2, 32.2, 45.46, 45.46, 45.46, 45.46, 45.46, 48.38, 48.38, 48.38, 48.38, 48.38], "power_watts_avg": 41.17, "power_watts_peak": 48.38, "energy_joules_est": 68.48, "sample_count": 17, "duration_seconds": 1.663}, "timestamp": "2026-01-12T10:09:40.083628"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1674.835, "latencies_ms": [1674.835], "images_per_second": 0.597, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features two parking meters with a warm, golden hue from the setting sun in the background. The parking meters are black and have a metallic finish, and the sun is setting behind them, casting a soft glow over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13399.8, "ram_available_mb": 109106.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 35.03, 35.03, 46.26, 46.26, 46.26, 46.26, 46.26, 47.02, 47.02, 47.02, 47.02, 47.02, 35.95, 35.95], "power_watts_avg": 41.97, "power_watts_peak": 47.02, "energy_joules_est": 70.3, "sample_count": 17, "duration_seconds": 1.675}, "timestamp": "2026-01-12T10:09:41.799345"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1794.59, "latencies_ms": [1794.59], "images_per_second": 0.557, "prompt_tokens": 1099, "response_tokens_est": 52, "n_tiles": 1, "output_text": " In the image, a large brown suitcase adorned with stickers from various countries like China, India, and Bangladesh is prominently displayed on a sidewalk, with a couple of people standing nearby, and a building with the word \"Fidelity\" visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.9, "ram_available_mb": 109114.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13384.3, "ram_available_mb": 109122.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.95, 35.95, 37.23, 37.23, 37.23, 37.23, 37.23, 47.36, 47.36, 47.36, 47.36, 47.36, 45.1, 45.1, 45.1, 45.1, 45.1, 34.83], "power_watts_avg": 41.95, "power_watts_peak": 47.36, "energy_joules_est": 75.31, "sample_count": 18, "duration_seconds": 1.795}, "timestamp": "2026-01-12T10:09:43.617128"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2294.538, "latencies_ms": [2294.538], "images_per_second": 0.436, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. man: 1\n3. woman: 1\n4. man in glasses: 1\n5. woman with blue jacket: 1\n6. man in yellow shirt: 1\n7. man in black jacket: 1\n8. man in blue shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13380.4, "ram_available_mb": 109125.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13368.3, "ram_available_mb": 109138.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 34.83, 45.71, 45.71, 45.71, 45.71, 45.71, 47.8, 47.8, 47.8, 47.8, 47.8, 37.2, 37.2, 37.2, 37.2, 37.2, 34.9, 34.9, 34.9, 34.9], "power_watts_avg": 40.54, "power_watts_peak": 47.8, "energy_joules_est": 93.05, "sample_count": 23, "duration_seconds": 2.295}, "timestamp": "2026-01-12T10:09:45.936132"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1770.778, "latencies_ms": [1770.778], "images_per_second": 0.565, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The suitcase is positioned to the left of the couple, who are standing in the foreground of the image. The suitcase is in front of the couple, and the couple is standing on a sidewalk, with the suitcase placed on a pedestal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.4, "ram_available_mb": 109145.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.9, 33.46, 33.46, 33.46, 33.46, 33.46, 46.71, 46.71, 46.71, 46.71, 46.71, 48.41, 48.41, 48.41, 48.41, 34.91, 34.91, 34.91], "power_watts_avg": 40.78, "power_watts_peak": 48.41, "energy_joules_est": 72.28, "sample_count": 18, "duration_seconds": 1.772}, "timestamp": "2026-01-12T10:09:47.803668"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1302.108, "latencies_ms": [1302.108], "images_per_second": 0.768, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A large brown suitcase with stickers on it is sitting on the sidewalk in front of a building. A man and a woman are standing next to the suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13448.3, "ram_available_mb": 109058.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 36.91, 36.91, 36.91, 36.91, 36.91, 47.48, 47.48, 47.48, 47.48, 47.48, 45.37], "power_watts_avg": 41.32, "power_watts_peak": 47.48, "energy_joules_est": 53.82, "sample_count": 13, "duration_seconds": 1.303}, "timestamp": "2026-01-12T10:09:49.118464"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 928.538, "latencies_ms": [928.538], "images_per_second": 1.077, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The suitcase is brown and white, and the suitcase is in front of a building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13444.4, "ram_available_mb": 109061.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13455.5, "ram_available_mb": 109050.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.37, 45.37, 45.37, 45.37, 45.31, 45.31, 45.31, 45.31, 45.31, 47.78], "power_watts_avg": 45.58, "power_watts_peak": 47.78, "energy_joules_est": 42.35, "sample_count": 10, "duration_seconds": 0.929}, "timestamp": "2026-01-12T10:09:50.130139"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1199.576, "latencies_ms": [1199.576], "images_per_second": 0.834, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image features a plate of food that includes a variety of mushrooms and broccoli, with the mushrooms being cooked and the broccoli being fresh and green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13447.6, "ram_available_mb": 109058.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13436.5, "ram_available_mb": 109069.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.78, 47.78, 47.78, 47.78, 46.46, 46.46, 46.46, 46.46, 46.46, 46.36, 46.36, 46.36], "power_watts_avg": 46.87, "power_watts_peak": 47.78, "energy_joules_est": 56.25, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-12T10:09:51.345845"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 859.059, "latencies_ms": [859.059], "images_per_second": 1.164, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " mushroom: 10, broccoli: 2, parsley: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.5, "ram_available_mb": 109069.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13363.9, "ram_available_mb": 109142.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 2.0}, "power_stats": {"power_watts_samples": [46.36, 46.36, 38.64, 38.64, 38.64, 38.64, 38.64, 48.04, 48.04], "power_watts_avg": 42.45, "power_watts_peak": 48.04, "energy_joules_est": 36.49, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-12T10:09:52.258983"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1327.175, "latencies_ms": [1327.175], "images_per_second": 0.753, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The mushrooms are located in the foreground, with the broccoli situated in the background. The parsley is sprinkled on top of the mushrooms and broccoli, creating a visually appealing contrast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.9, "ram_available_mb": 109142.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13404.1, "ram_available_mb": 109102.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.04, 48.04, 48.04, 51.61, 51.61, 51.61, 51.61, 51.61, 47.2, 47.2, 47.2, 47.2, 47.2, 43.81], "power_watts_avg": 48.71, "power_watts_peak": 51.61, "energy_joules_est": 64.68, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-12T10:09:53.674618"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1770.1, "latencies_ms": [1770.1], "images_per_second": 0.565, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " In a dimly lit room, a plate of food is presented, featuring a variety of ingredients including mushrooms, broccoli, and a piece of meat. The plate is garnished with fresh green herbs, adding a touch of color and freshness to the dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.3, "ram_available_mb": 109110.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.1, "ram_available_mb": 109094.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.81, 43.81, 43.81, 43.81, 41.77, 41.77, 41.77, 41.77, 41.77, 46.45, 46.45, 46.45, 46.45, 46.45, 39.73, 39.73, 39.73, 39.73], "power_watts_avg": 43.07, "power_watts_peak": 46.45, "energy_joules_est": 76.26, "sample_count": 18, "duration_seconds": 1.771}, "timestamp": "2026-01-12T10:09:55.492532"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1484.778, "latencies_ms": [1484.778], "images_per_second": 0.674, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a plate of food with a variety of colors, including green broccoli, brown mushrooms, and white chicken. The lighting is bright and natural, highlighting the textures and colors of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.1, "ram_available_mb": 109094.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13493.8, "ram_available_mb": 109012.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.73, 34.05, 34.05, 34.05, 34.05, 47.31, 47.31, 47.31, 47.31, 47.31, 48.19, 48.19, 48.19, 48.19, 48.19], "power_watts_avg": 43.56, "power_watts_peak": 48.19, "energy_joules_est": 64.69, "sample_count": 15, "duration_seconds": 1.485}, "timestamp": "2026-01-12T10:09:57.008298"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1397.627, "latencies_ms": [1397.627], "images_per_second": 0.715, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce, with a variety of vegetables and fruits neatly arranged on wooden crates and baskets, creating a visually appealing and healthy assortment of food items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13485.9, "ram_available_mb": 109020.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13471.1, "ram_available_mb": 109035.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.75, 34.75, 34.75, 34.75, 34.75, 47.88, 47.88, 47.88, 47.88, 47.88, 47.98, 47.98, 47.98, 47.98], "power_watts_avg": 43.22, "power_watts_peak": 47.98, "energy_joules_est": 60.43, "sample_count": 14, "duration_seconds": 1.398}, "timestamp": "2026-01-12T10:09:58.425042"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1373.913, "latencies_ms": [1373.913], "images_per_second": 0.728, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " carrot: 12, cabbage: 1, broccoli: 1, cauliflower: 1, kale: 1, lettuce: 1, fennel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13471.1, "ram_available_mb": 109035.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.98, 33.32, 33.32, 33.32, 33.32, 33.32, 47.89, 47.89, 47.89, 47.89, 47.89, 49.66, 49.66, 49.66], "power_watts_avg": 43.07, "power_watts_peak": 49.66, "energy_joules_est": 59.2, "sample_count": 14, "duration_seconds": 1.374}, "timestamp": "2026-01-12T10:09:59.839920"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1640.339, "latencies_ms": [1640.339], "images_per_second": 0.61, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The carrots are in the foreground, with the leafy greens behind them. The leafy greens are in the background, with the broccoli on top of the crates. The flowers are in the foreground, with the carrots in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13402.4, "ram_available_mb": 109103.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.66, 49.66, 35.41, 35.41, 35.41, 35.41, 35.41, 47.36, 47.36, 47.36, 47.36, 47.36, 47.17, 47.17, 47.17, 47.17, 47.17], "power_watts_avg": 44.06, "power_watts_peak": 49.66, "energy_joules_est": 72.29, "sample_count": 17, "duration_seconds": 1.641}, "timestamp": "2026-01-12T10:10:01.557267"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1824.384, "latencies_ms": [1824.384], "images_per_second": 0.548, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce at a market stall, with a variety of vegetables and fruits neatly arranged in baskets and crates. The colors and textures of the produce create a visually appealing scene, showcasing the freshness and abundance of the items on display.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13402.4, "ram_available_mb": 109103.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13469.0, "ram_available_mb": 109037.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.8, 34.8, 34.8, 46.65, 46.65, 46.65, 46.65, 46.65, 47.04, 47.04, 47.04, 47.04, 47.04, 34.94, 34.94, 34.94, 34.94], "power_watts_avg": 41.17, "power_watts_peak": 47.04, "energy_joules_est": 75.13, "sample_count": 19, "duration_seconds": 1.825}, "timestamp": "2026-01-12T10:10:03.475461"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2031.022, "latencies_ms": [2031.022], "images_per_second": 0.492, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a variety of fresh vegetables, including carrots, broccoli, and cauliflower, displayed in a rustic wooden crate. The lighting is natural and soft, highlighting the vibrant colors of the produce. The vegetables are arranged in a way that showcases their textures and colors, creating a visually appealing display.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13469.0, "ram_available_mb": 109037.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13452.5, "ram_available_mb": 109053.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [32.78, 32.78, 32.78, 32.78, 32.78, 45.38, 45.38, 45.38, 45.38, 45.38, 47.4, 47.4, 47.4, 47.4, 47.4, 34.63, 34.63, 34.63, 34.63, 34.63, 34.63], "power_watts_avg": 39.79, "power_watts_peak": 47.4, "energy_joules_est": 80.84, "sample_count": 21, "duration_seconds": 2.032}, "timestamp": "2026-01-12T10:10:05.645984"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1597.922, "latencies_ms": [1597.922], "images_per_second": 0.626, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image captures a bustling scene inside a donut shop, where a variety of donuts are being prepared on a conveyor belt, with workers diligently handling the doughnuts, and customers waiting in line to place their orders.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13452.5, "ram_available_mb": 109053.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13419.4, "ram_available_mb": 109086.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.63, 34.63, 34.63, 34.63, 39.63, 39.63, 39.63, 39.63, 39.63, 45.4, 45.4, 45.4, 45.4, 41.21, 41.21, 41.21], "power_watts_avg": 40.12, "power_watts_peak": 45.4, "energy_joules_est": 64.16, "sample_count": 16, "duration_seconds": 1.599}, "timestamp": "2026-01-12T10:10:07.313610"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 860.898, "latencies_ms": [860.898], "images_per_second": 1.162, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " donut: 10\nmachine: 2\nperson: 3", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13411.5, "ram_available_mb": 109094.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 35.0}, "power_stats": {"power_watts_samples": [41.21, 41.21, 36.79, 36.79, 36.79, 36.79, 36.79, 47.79, 47.79], "power_watts_avg": 40.22, "power_watts_peak": 47.79, "energy_joules_est": 34.64, "sample_count": 9, "duration_seconds": 0.861}, "timestamp": "2026-01-12T10:10:08.224042"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2189.589, "latencies_ms": [2189.589], "images_per_second": 0.457, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The donut machine is located in the foreground, with the donuts being processed on the left side. The donut machine is positioned in the middle of the image, with the donuts being processed on the right side. The donut machine is located in the foreground, with the donuts being processed on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13448.0, "ram_available_mb": 109058.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.79, 47.79, 47.79, 52.1, 52.1, 52.1, 52.1, 52.1, 47.06, 47.06, 47.06, 47.06, 47.06, 41.28, 41.28, 41.28, 41.28, 41.28, 34.49, 34.49, 34.49, 34.49], "power_watts_avg": 44.71, "power_watts_peak": 52.1, "energy_joules_est": 97.91, "sample_count": 22, "duration_seconds": 2.19}, "timestamp": "2026-01-12T10:10:10.442519"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1645.445, "latencies_ms": [1645.445], "images_per_second": 0.608, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a bustling scene inside a donut shop, where a variety of donuts are being prepared on a conveyor belt. The shop is well-lit, with customers waiting in line to purchase the freshly made donuts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13432.2, "ram_available_mb": 109074.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13426.9, "ram_available_mb": 109079.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.49, 33.2, 33.2, 33.2, 33.2, 33.2, 46.81, 46.81, 46.81, 46.81, 46.81, 48.27, 48.27, 48.27, 48.27, 48.27, 34.65], "power_watts_avg": 41.8, "power_watts_peak": 48.27, "energy_joules_est": 68.8, "sample_count": 17, "duration_seconds": 1.646}, "timestamp": "2026-01-12T10:10:12.209623"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1199.567, "latencies_ms": [1199.567], "images_per_second": 0.834, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a brightly lit bakery with a green wall and a red sign. The doughnuts are being cooked on a conveyor belt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.9, "ram_available_mb": 109079.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13417.8, "ram_available_mb": 109088.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.65, 34.65, 34.65, 40.61, 40.61, 40.61, 40.61, 40.61, 46.68, 46.68, 46.68, 46.68], "power_watts_avg": 41.14, "power_watts_peak": 46.68, "energy_joules_est": 49.37, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-12T10:10:13.420675"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1052.392, "latencies_ms": [1052.392], "images_per_second": 0.95, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man in a green jacket and white shoes is bending over in a forest, holding an orange frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.8, "ram_available_mb": 109092.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.68, 40.26, 40.26, 40.26, 40.26, 40.26, 47.81, 47.81, 47.81, 47.81, 47.81], "power_watts_avg": 44.28, "power_watts_peak": 47.81, "energy_joules_est": 46.61, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-12T10:10:14.534285"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2070.877, "latencies_ms": [2070.877], "images_per_second": 0.483, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. person: 1\n2. tree: 2\n3. frisbee: 1\n4. ground: 1\n5. leaves: 1\n6. tree trunk: 1\n7. green jacket: 1\n8. white socks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13430.2, "ram_available_mb": 109076.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [48.41, 48.41, 48.41, 48.41, 48.41, 46.89, 46.89, 46.89, 46.89, 46.89, 47.38, 47.38, 47.38, 47.38, 47.38, 34.53, 34.53, 34.53, 34.53, 34.53, 34.45], "power_watts_avg": 43.84, "power_watts_peak": 48.41, "energy_joules_est": 90.79, "sample_count": 21, "duration_seconds": 2.071}, "timestamp": "2026-01-12T10:10:16.646957"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1480.453, "latencies_ms": [1480.453], "images_per_second": 0.675, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing in the middle of the forest, with the trees surrounding him. The orange frisbee is in front of him, and the white frisbee is in his hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13426.2, "ram_available_mb": 109080.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13427.3, "ram_available_mb": 109079.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [34.45, 34.45, 34.45, 34.45, 40.27, 40.27, 40.27, 40.27, 40.27, 46.22, 46.22, 46.22, 46.22, 46.22, 40.29], "power_watts_avg": 40.7, "power_watts_peak": 46.22, "energy_joules_est": 60.3, "sample_count": 15, "duration_seconds": 1.482}, "timestamp": "2026-01-12T10:10:18.210489"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 913.99, "latencies_ms": [913.99], "images_per_second": 1.094, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man in a green jacket and white shoes is playing frisbee in a forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.5, "ram_available_mb": 109086.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [40.29, 40.29, 40.29, 40.91, 40.91, 40.91, 40.91, 40.91, 47.3, 47.3], "power_watts_avg": 42.0, "power_watts_peak": 47.3, "energy_joules_est": 38.42, "sample_count": 10, "duration_seconds": 0.915}, "timestamp": "2026-01-12T10:10:19.219912"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1542.516, "latencies_ms": [1542.516], "images_per_second": 0.648, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a person in a green jacket and white shoes, standing in a forest with a brown tree trunk and a white frisbee. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13420.9, "ram_available_mb": 109085.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.3, 47.3, 47.3, 46.86, 46.86, 46.86, 46.86, 46.86, 46.39, 46.39, 46.39, 46.39, 46.39, 41.4, 41.4, 41.4], "power_watts_avg": 45.77, "power_watts_peak": 47.3, "energy_joules_est": 70.62, "sample_count": 16, "duration_seconds": 1.543}, "timestamp": "2026-01-12T10:10:20.832798"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1070.906, "latencies_ms": [1070.906], "images_per_second": 0.934, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a white toilet, and a shower curtain with blue and green stripes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13409.1, "ram_available_mb": 109097.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13456.2, "ram_available_mb": 109050.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [41.4, 41.4, 34.49, 34.49, 34.49, 34.49, 34.49, 46.41, 46.41, 46.41, 46.41], "power_watts_avg": 40.08, "power_watts_peak": 46.41, "energy_joules_est": 42.93, "sample_count": 11, "duration_seconds": 1.071}, "timestamp": "2026-01-12T10:10:21.949615"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2130.655, "latencies_ms": [2130.655], "images_per_second": 0.469, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. sink: 1\n2. mirror: 1\n3. toilet: 1\n4. shower curtain: 1\n5. can of Ajax: 1\n6. bottle of blue liquid: 1\n7. toothbrush holder: 1\n8. toothbrush: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13456.2, "ram_available_mb": 109050.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13421.3, "ram_available_mb": 109085.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.41, 45.93, 45.93, 45.93, 45.93, 45.93, 47.42, 47.42, 47.42, 47.42, 47.42, 49.04, 49.04, 49.04, 49.04, 49.04, 34.75, 34.75, 34.75, 34.75, 34.75, 34.62], "power_watts_avg": 43.94, "power_watts_peak": 49.04, "energy_joules_est": 93.65, "sample_count": 22, "duration_seconds": 2.131}, "timestamp": "2026-01-12T10:10:24.167666"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1632.694, "latencies_ms": [1632.694], "images_per_second": 0.612, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The sink is located to the left of the mirror, which is above the toilet. The shower curtain is hanging to the right of the toilet. The can of Ajax is placed on the counter in front of the sink.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13413.5, "ram_available_mb": 109092.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13415.9, "ram_available_mb": 109090.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 38.56, 38.56, 38.56, 38.56, 38.56, 45.25, 45.25, 45.25, 45.25, 45.25, 41.47, 41.47, 41.47, 41.47], "power_watts_avg": 40.52, "power_watts_peak": 45.25, "energy_joules_est": 66.18, "sample_count": 17, "duration_seconds": 1.633}, "timestamp": "2026-01-12T10:10:25.935217"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 874.689, "latencies_ms": [874.689], "images_per_second": 1.143, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A bathroom with a sink, toilet, and shower curtain is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.9, "ram_available_mb": 109094.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13427.7, "ram_available_mb": 109078.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [41.47, 31.93, 31.93, 31.93, 31.93, 31.93, 46.54, 46.54, 46.54], "power_watts_avg": 37.86, "power_watts_peak": 46.54, "energy_joules_est": 33.14, "sample_count": 9, "duration_seconds": 0.875}, "timestamp": "2026-01-12T10:10:26.845688"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1128.989, "latencies_ms": [1128.989], "images_per_second": 0.886, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The bathroom is well-lit with natural light coming from a window, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.7, "ram_available_mb": 109078.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13407.0, "ram_available_mb": 109099.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.54, 46.54, 49.63, 49.63, 49.63, 49.63, 49.63, 47.53, 47.53, 47.53, 47.53, 47.53], "power_watts_avg": 48.24, "power_watts_peak": 49.63, "energy_joules_est": 54.47, "sample_count": 12, "duration_seconds": 1.129}, "timestamp": "2026-01-12T10:10:28.059308"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1223.785, "latencies_ms": [1223.785], "images_per_second": 0.817, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a modern kitchen with a large island, a sink, and a dining table with chairs, all set against a white wall and window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.1, "ram_available_mb": 109107.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13410.4, "ram_available_mb": 109095.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.42, 47.42, 47.42, 47.42, 47.42, 46.28, 46.28, 46.28, 46.28, 46.28, 46.77, 46.77, 46.77], "power_watts_avg": 46.83, "power_watts_peak": 47.42, "energy_joules_est": 57.34, "sample_count": 13, "duration_seconds": 1.224}, "timestamp": "2026-01-12T10:10:29.373479"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1361.242, "latencies_ms": [1361.242], "images_per_second": 0.735, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " sink: 1, countertop: 1, cabinet: 1, window: 1, table: 1, chair: 1, door: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13406.5, "ram_available_mb": 109099.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13404.5, "ram_available_mb": 109101.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.77, 46.77, 32.8, 32.8, 32.8, 32.8, 32.8, 46.57, 46.57, 46.57, 46.57, 46.57, 48.12, 48.12], "power_watts_avg": 41.9, "power_watts_peak": 48.12, "energy_joules_est": 57.05, "sample_count": 14, "duration_seconds": 1.362}, "timestamp": "2026-01-12T10:10:30.786786"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1418.011, "latencies_ms": [1418.011], "images_per_second": 0.705, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The sink is located to the left of the stove, and the dining table is situated in the background. The countertop is in the foreground, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.5, "ram_available_mb": 109101.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13420.2, "ram_available_mb": 109086.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.12, 48.12, 48.12, 37.61, 37.61, 37.61, 37.61, 37.61, 47.19, 47.19, 47.19, 47.19, 47.19, 44.15, 44.15], "power_watts_avg": 43.78, "power_watts_peak": 48.12, "energy_joules_est": 62.1, "sample_count": 15, "duration_seconds": 1.419}, "timestamp": "2026-01-12T10:10:32.300664"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 797.958, "latencies_ms": [797.958], "images_per_second": 1.253, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kitchen with a large island and a dining table in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.2, "ram_available_mb": 109086.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13398.5, "ram_available_mb": 109107.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [44.15, 44.15, 44.15, 36.21, 36.21, 36.21, 36.21, 36.21], "power_watts_avg": 39.19, "power_watts_peak": 44.15, "energy_joules_est": 31.29, "sample_count": 8, "duration_seconds": 0.799}, "timestamp": "2026-01-12T10:10:33.111743"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 825.014, "latencies_ms": [825.014], "images_per_second": 1.212, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The kitchen has a black countertop, white walls, and wooden chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.6, "ram_available_mb": 109111.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13403.7, "ram_available_mb": 109102.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.21, 46.21, 46.21, 46.21, 56.67, 56.67, 56.67, 56.67, 56.67], "power_watts_avg": 52.02, "power_watts_peak": 56.67, "energy_joules_est": 42.95, "sample_count": 9, "duration_seconds": 0.826}, "timestamp": "2026-01-12T10:10:34.023319"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1467.087, "latencies_ms": [1467.087], "images_per_second": 0.682, "prompt_tokens": 1100, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In the image, a child is peacefully sleeping in a bed, covered with a blanket adorned with a pattern of daisies, and the room is dimly lit, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.8, "ram_available_mb": 109110.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.0, "ram_available_mb": 109119.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.39, 46.39, 46.39, 46.39, 46.39, 47.61, 47.61, 47.61, 47.61, 47.61, 47.94, 47.94, 47.94, 47.94, 47.94], "power_watts_avg": 47.31, "power_watts_peak": 47.94, "energy_joules_est": 69.44, "sample_count": 15, "duration_seconds": 1.468}, "timestamp": "2026-01-12T10:10:35.540076"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2018.656, "latencies_ms": [2018.656], "images_per_second": 0.495, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 1\n2. bed: 1\n3. blanket: 1\n4. pillow: 1\n5. wall: 1\n6. bedside table: 1\n7. bed frame: 1\n8. bed sheet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.1, "ram_available_mb": 109127.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13380.0, "ram_available_mb": 109126.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.33, 34.33, 34.33, 34.33, 34.33, 47.19, 47.19, 47.19, 47.19, 47.19, 47.65, 47.65, 47.65, 47.65, 47.65, 34.71, 34.71, 34.71, 34.71, 34.71, 34.73], "power_watts_avg": 40.67, "power_watts_peak": 47.65, "energy_joules_est": 82.12, "sample_count": 21, "duration_seconds": 2.019}, "timestamp": "2026-01-12T10:10:37.660299"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1477.27, "latencies_ms": [1477.27], "images_per_second": 0.677, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The person is lying on the bed, which is positioned in the foreground of the image. The bed is located in the middle of the room, with the wall and a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13380.0, "ram_available_mb": 109126.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13414.2, "ram_available_mb": 109092.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 39.59, 39.59, 39.59, 39.59, 39.59, 44.96, 44.96, 44.96, 44.96, 44.96, 40.3, 40.3], "power_watts_avg": 40.51, "power_watts_peak": 44.96, "energy_joules_est": 59.87, "sample_count": 15, "duration_seconds": 1.478}, "timestamp": "2026-01-12T10:10:39.227251"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1407.775, "latencies_ms": [1407.775], "images_per_second": 0.71, "prompt_tokens": 1112, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In a dimly lit room, a child is peacefully sleeping in a bed with a floral comforter. The room is cozy and warm, creating a sense of comfort and tranquility.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.4, "ram_available_mb": 109099.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13422.2, "ram_available_mb": 109084.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.3, 40.3, 40.3, 40.92, 40.92, 40.92, 40.92, 40.92, 47.39, 47.39, 47.39, 47.39, 47.39, 41.13], "power_watts_avg": 43.11, "power_watts_peak": 47.39, "energy_joules_est": 60.72, "sample_count": 14, "duration_seconds": 1.408}, "timestamp": "2026-01-12T10:10:40.640987"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1838.668, "latencies_ms": [1838.668], "images_per_second": 0.544, "prompt_tokens": 1110, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image depicts a child sleeping in a bed with a dark blue comforter adorned with white daisy patterns. The room is dimly lit, with only a small amount of light coming from the window, casting a soft glow on the child and the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.3, "ram_available_mb": 109088.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13320.5, "ram_available_mb": 109185.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.13, 41.13, 41.13, 41.13, 45.38, 45.38, 45.38, 45.38, 45.38, 47.84, 47.84, 47.84, 47.84, 47.84, 38.11, 38.11, 38.11, 38.11, 38.11], "power_watts_avg": 43.22, "power_watts_peak": 47.84, "energy_joules_est": 79.48, "sample_count": 19, "duration_seconds": 1.839}, "timestamp": "2026-01-12T10:10:42.558926"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1280.859, "latencies_ms": [1280.859], "images_per_second": 0.781, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A person is riding a skateboard on a ramp, wearing white socks and sneakers, with a man sitting on the side of the ramp in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13320.5, "ram_available_mb": 109185.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13375.1, "ram_available_mb": 109131.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.15, 34.15, 34.15, 34.15, 44.44, 44.44, 44.44, 44.44, 44.44, 46.19, 46.19, 46.19, 46.19], "power_watts_avg": 41.81, "power_watts_peak": 46.19, "energy_joules_est": 53.6, "sample_count": 13, "duration_seconds": 1.282}, "timestamp": "2026-01-12T10:10:43.923968"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2066.344, "latencies_ms": [2066.344], "images_per_second": 0.484, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. shorts: 1\n4. socks: 1\n5. shoes: 1\n6. skateboard wheels: 2\n7. skateboard deck: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.1, "ram_available_mb": 109131.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.19, 34.61, 34.61, 34.61, 34.61, 34.61, 47.33, 47.33, 47.33, 47.33, 47.33, 49.56, 49.56, 49.56, 49.56, 49.56, 34.66, 34.66, 34.66, 34.66, 34.66], "power_watts_avg": 41.76, "power_watts_peak": 49.56, "energy_joules_est": 86.31, "sample_count": 21, "duration_seconds": 2.067}, "timestamp": "2026-01-12T10:10:46.042177"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1833.858, "latencies_ms": [1833.858], "images_per_second": 0.545, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The skateboarder's feet are positioned on the skateboard, with the left foot on the tail and the right foot on the nose, in the foreground. The skateboarder is in the middle of the image, with the ramp and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13372.6, "ram_available_mb": 109133.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.32, 34.32, 34.32, 34.32, 34.32, 45.93, 45.93, 45.93, 45.93, 45.93, 46.5, 46.5, 46.5, 46.5, 46.5, 35.83, 35.83, 35.83, 35.83], "power_watts_avg": 40.9, "power_watts_peak": 46.5, "energy_joules_est": 75.04, "sample_count": 19, "duration_seconds": 1.835}, "timestamp": "2026-01-12T10:10:48.008919"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1038.578, "latencies_ms": [1038.578], "images_per_second": 0.963, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is riding a skateboard on a ramp, while another person is sitting on the side of the ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.6, "ram_available_mb": 109133.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13380.5, "ram_available_mb": 109125.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [33.25, 33.25, 33.25, 33.25, 33.25, 45.8, 45.8, 45.8, 45.8, 45.8, 47.26], "power_watts_avg": 40.23, "power_watts_peak": 47.26, "energy_joules_est": 41.8, "sample_count": 11, "duration_seconds": 1.039}, "timestamp": "2026-01-12T10:10:49.171907"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2057.961, "latencies_ms": [2057.961], "images_per_second": 0.486, "prompt_tokens": 1110, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image is in black and white, with the skateboarder's legs and shoes being the main focus. The skateboarder is wearing white socks and sneakers with the DC logo on them. The skateboarder is wearing shorts, and the shadow of the skateboarder is visible on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.8, "ram_available_mb": 109131.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13366.9, "ram_available_mb": 109139.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.26, 47.26, 47.26, 47.26, 43.1, 43.1, 43.1, 43.1, 43.1, 46.71, 46.71, 46.71, 46.71, 46.71, 38.5, 38.5, 38.5, 38.5, 38.5, 34.91, 34.91], "power_watts_avg": 42.88, "power_watts_peak": 47.26, "energy_joules_est": 88.25, "sample_count": 21, "duration_seconds": 2.058}, "timestamp": "2026-01-12T10:10:51.287112"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1058.626, "latencies_ms": [1058.626], "images_per_second": 0.945, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is lying on the floor with a laptop, a tennis racket, and a book on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.9, "ram_available_mb": 109139.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13367.5, "ram_available_mb": 109138.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 5.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 34.76, 34.76, 34.76, 34.76, 34.76, 45.7, 45.7, 45.7, 45.7], "power_watts_avg": 38.77, "power_watts_peak": 45.7, "energy_joules_est": 41.1, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T10:10:52.452713"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1568.487, "latencies_ms": [1568.487], "images_per_second": 0.638, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " laptop: 1\ncamera: 1\nphone: 1\nracket: 1\nbottle: 1\nbook: 1\ncamera lens: 1\nbook: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.5, "ram_available_mb": 109138.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13346.7, "ram_available_mb": 109159.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.7, 44.42, 44.42, 44.42, 44.42, 44.42, 46.86, 46.86, 46.86, 46.86, 46.86, 49.03, 49.03, 49.03, 49.03, 49.03], "power_watts_avg": 46.7, "power_watts_peak": 49.03, "energy_joules_est": 73.27, "sample_count": 16, "duration_seconds": 1.569}, "timestamp": "2026-01-12T10:10:54.064504"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1835.459, "latencies_ms": [1835.459], "images_per_second": 0.545, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The laptop is in the middle of the image, with the tennis racket and camera to its right. The books are in the foreground, with the laptop and camera to its left. The man is in the foreground, with the laptop and camera to his right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.7, "ram_available_mb": 109159.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.46, 34.46, 34.46, 34.46, 34.46, 47.23, 47.23, 47.23, 47.23, 47.23, 47.34, 47.34, 47.34, 47.34, 47.34, 34.71, 34.71, 34.71, 34.71], "power_watts_avg": 41.26, "power_watts_peak": 47.34, "energy_joules_est": 75.75, "sample_count": 19, "duration_seconds": 1.836}, "timestamp": "2026-01-12T10:10:55.979080"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 964.88, "latencies_ms": [964.88], "images_per_second": 1.036, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man is lying on the floor with a laptop, a tennis racket, and a book.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.2, "ram_available_mb": 109172.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.9, "ram_available_mb": 109151.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [32.64, 32.64, 32.64, 32.64, 32.64, 45.57, 45.57, 45.57, 45.57, 45.57], "power_watts_avg": 39.1, "power_watts_peak": 45.57, "energy_joules_est": 37.77, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-12T10:10:57.041613"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1334.172, "latencies_ms": [1334.172], "images_per_second": 0.75, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the window. The colors in the image are vibrant and the materials are mostly plastic and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.0, "ram_available_mb": 109159.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.6, "ram_available_mb": 109144.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.8, 46.8, 46.8, 46.8, 46.8, 47.1, 47.1, 47.1, 47.1, 47.1, 47.51, 47.51, 47.51, 47.51], "power_watts_avg": 47.11, "power_watts_peak": 47.51, "energy_joules_est": 62.86, "sample_count": 14, "duration_seconds": 1.334}, "timestamp": "2026-01-12T10:10:58.455744"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1082.262, "latencies_ms": [1082.262], "images_per_second": 0.924, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image shows a kitchen with a black stove top, a black range hood above it, and a marble backsplash.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.7, "ram_available_mb": 109148.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.8, "ram_available_mb": 109138.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.51, 32.1, 32.1, 32.1, 32.1, 32.1, 46.71, 46.71, 46.71, 46.71, 46.71], "power_watts_avg": 40.14, "power_watts_peak": 47.51, "energy_joules_est": 43.46, "sample_count": 11, "duration_seconds": 1.083}, "timestamp": "2026-01-12T10:10:59.570232"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1675.214, "latencies_ms": [1675.214], "images_per_second": 0.597, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. black stove top\n2. black range hood\n3. black knife block\n4. black pot\n5. black pot lid\n6. black pot handle\n7. black pot base\n8. black pot ring", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.9, "ram_available_mb": 109146.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13361.1, "ram_available_mb": 109145.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.34, 49.34, 49.34, 49.34, 49.34, 47.81, 47.81, 47.81, 47.81, 47.81, 47.7, 47.7, 47.7, 47.7, 47.7, 34.72, 34.72], "power_watts_avg": 46.69, "power_watts_peak": 49.34, "energy_joules_est": 78.23, "sample_count": 17, "duration_seconds": 1.676}, "timestamp": "2026-01-12T10:11:01.287056"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1513.552, "latencies_ms": [1513.552], "images_per_second": 0.661, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The stove is located in the foreground, with the spice rack and hanging towels positioned further back. The spice rack is situated to the left of the stove, while the hanging towels are located to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.3, "ram_available_mb": 109153.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13354.1, "ram_available_mb": 109152.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 34.72, 38.92, 38.92, 38.92, 38.92, 38.92, 47.58, 47.58, 47.58, 47.58, 47.58, 44.11, 44.11, 44.11], "power_watts_avg": 41.81, "power_watts_peak": 47.58, "energy_joules_est": 63.31, "sample_count": 16, "duration_seconds": 1.514}, "timestamp": "2026-01-12T10:11:02.901476"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 777.894, "latencies_ms": [777.894], "images_per_second": 1.286, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A kitchen with a stove and a spice rack on the counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.1, "ram_available_mb": 109152.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13370.1, "ram_available_mb": 109136.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.11, 44.11, 32.59, 32.59, 32.59, 32.59, 32.59, 46.3], "power_watts_avg": 37.19, "power_watts_peak": 46.3, "energy_joules_est": 28.95, "sample_count": 8, "duration_seconds": 0.778}, "timestamp": "2026-01-12T10:11:03.713234"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 953.513, "latencies_ms": [953.513], "images_per_second": 1.049, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The kitchen has a marble backsplash, a black stove top, and a black range hood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.1, "ram_available_mb": 109136.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13362.3, "ram_available_mb": 109144.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.3, 46.3, 46.3, 56.16, 56.16, 56.16, 56.16, 56.16, 47.68, 47.68], "power_watts_avg": 51.51, "power_watts_peak": 56.16, "energy_joules_est": 49.14, "sample_count": 10, "duration_seconds": 0.954}, "timestamp": "2026-01-12T10:11:04.724344"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1139.907, "latencies_ms": [1139.907], "images_per_second": 0.877, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A person is sitting at a table with a plate of food and a cup of coffee, and there are other people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13348.8, "ram_available_mb": 109157.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.68, 47.68, 47.68, 47.11, 47.11, 47.11, 47.11, 47.11, 46.98, 46.98, 46.98, 46.98], "power_watts_avg": 47.21, "power_watts_peak": 47.68, "energy_joules_est": 53.84, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-12T10:11:05.940154"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2079.574, "latencies_ms": [2079.574], "images_per_second": 0.481, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. cup: 1\n2. plate: 1\n3. donut: 1\n4. donut: 1\n5. donut: 1\n6. donut: 1\n7. donut: 1\n8. donut: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.8, "ram_available_mb": 109159.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.98, 38.07, 38.07, 38.07, 38.07, 38.07, 46.66, 46.66, 46.66, 46.66, 46.66, 48.89, 48.89, 48.89, 48.89, 48.89, 34.68, 34.68, 34.68, 34.68, 34.68], "power_watts_avg": 42.31, "power_watts_peak": 48.89, "energy_joules_est": 88.01, "sample_count": 21, "duration_seconds": 2.08}, "timestamp": "2026-01-12T10:11:08.059401"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1882.777, "latencies_ms": [1882.777], "images_per_second": 0.531, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the person in the foreground holding a donut and the table in the background. The donut is placed in the center of the table, with the coffee cup to the left and the plate of donuts to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.3, "ram_available_mb": 109159.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 34.68, 34.68, 45.42, 45.42, 45.42, 45.42, 46.52, 46.52, 46.52, 46.52, 46.52, 36.62, 36.62, 36.62, 36.62, 36.62], "power_watts_avg": 40.57, "power_watts_peak": 46.52, "energy_joules_est": 76.41, "sample_count": 19, "duration_seconds": 1.884}, "timestamp": "2026-01-12T10:11:10.027444"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1102.479, "latencies_ms": [1102.479], "images_per_second": 0.907, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young man is sitting at a table in a coffee shop, eating a chocolate donut and drinking a cup of coffee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.5, "ram_available_mb": 109166.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.6, "ram_available_mb": 109147.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.49, 34.49, 34.49, 34.49, 34.49, 46.65, 46.65, 46.65, 46.65, 46.65, 46.78], "power_watts_avg": 41.13, "power_watts_peak": 46.78, "energy_joules_est": 45.4, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-12T10:11:11.192528"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1440.408, "latencies_ms": [1440.408], "images_per_second": 0.694, "prompt_tokens": 1110, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken in a dimly lit cafe with warm lighting, and the colors are rich and inviting. The materials are mostly wood and metal, and the weather is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.7, "ram_available_mb": 109151.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13345.8, "ram_available_mb": 109160.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.78, 46.78, 46.78, 46.78, 43.83, 43.83, 43.83, 43.83, 43.83, 47.95, 47.95, 47.95, 47.95, 47.95, 39.17], "power_watts_avg": 45.68, "power_watts_peak": 47.95, "energy_joules_est": 65.81, "sample_count": 15, "duration_seconds": 1.441}, "timestamp": "2026-01-12T10:11:12.708591"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1089.153, "latencies_ms": [1089.153], "images_per_second": 0.918, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a black and white toilet, and a blue and white tiled wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13345.8, "ram_available_mb": 109160.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.17, 39.17, 39.17, 39.17, 41.36, 41.36, 41.36, 41.36, 46.68, 46.68, 46.68], "power_watts_avg": 42.02, "power_watts_peak": 46.68, "energy_joules_est": 45.78, "sample_count": 11, "duration_seconds": 1.09}, "timestamp": "2026-01-12T10:11:13.824621"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2267.831, "latencies_ms": [2267.831], "images_per_second": 0.441, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Sink: 1\n3. Bathtub: 1\n4. Tile: 1\n5. Toilet paper holder: 1\n6. Toilet brush: 1\n7. Toilet seat: 1\n8. Bathroom counter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.5, "ram_available_mb": 109162.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.68, 46.68, 42.5, 42.5, 42.5, 42.5, 42.5, 47.68, 47.68, 47.68, 47.68, 47.68, 45.18, 45.18, 45.18, 45.18, 45.18, 34.49, 34.49, 34.49, 34.49, 34.49, 34.62], "power_watts_avg": 42.49, "power_watts_peak": 47.68, "energy_joules_est": 96.37, "sample_count": 23, "duration_seconds": 2.268}, "timestamp": "2026-01-12T10:11:16.145215"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1412.161, "latencies_ms": [1412.161], "images_per_second": 0.708, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The sink is located to the left of the toilet, which is situated in the foreground of the image. The toilet lid is closed, and the sink is white with a blue rim.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.6, "ram_available_mb": 109170.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 34.62, 41.64, 41.64, 41.64, 41.64, 41.64, 46.03, 46.03, 46.03, 46.03, 46.03, 39.31], "power_watts_avg": 41.08, "power_watts_peak": 46.03, "energy_joules_est": 58.04, "sample_count": 15, "duration_seconds": 1.413}, "timestamp": "2026-01-12T10:11:17.709937"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 968.703, "latencies_ms": [968.703], "images_per_second": 1.032, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A bathroom with a black and white toilet, a sink, and a blue and white tile wall.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13354.5, "ram_available_mb": 109151.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.31, 39.31, 39.31, 39.31, 40.99, 40.99, 40.99, 40.99, 40.99, 45.96], "power_watts_avg": 40.82, "power_watts_peak": 45.96, "energy_joules_est": 39.56, "sample_count": 10, "duration_seconds": 0.969}, "timestamp": "2026-01-12T10:11:18.720312"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1044.669, "latencies_ms": [1044.669], "images_per_second": 0.957, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bathroom has a black and white checkered floor, a white sink, and a black and white toilet.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13420.9, "ram_available_mb": 109085.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.96, 45.96, 45.96, 46.57, 46.57, 46.57, 46.57, 46.57, 47.37, 47.37, 47.37], "power_watts_avg": 46.62, "power_watts_peak": 47.37, "energy_joules_est": 48.72, "sample_count": 11, "duration_seconds": 1.045}, "timestamp": "2026-01-12T10:11:19.830198"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2789.141, "latencies_ms": [2789.141], "images_per_second": 0.359, "prompt_tokens": 1100, "response_tokens_est": 89, "n_tiles": 1, "output_text": " In the image, there is a memorial for Joseph Panis, who passed away on May 11, 1998, at the age of 41. The memorial is adorned with teddy bears and a sign that reads \"Joseph Panis\" and \"Mysti Mallean.\" The memorial is situated in a garden, surrounded by a fence and a variety of plants, including a large green plant in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13413.1, "ram_available_mb": 109093.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13376.6, "ram_available_mb": 109129.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.37, 47.37, 42.5, 42.5, 42.5, 42.5, 42.5, 46.62, 46.62, 46.62, 46.62, 46.62, 45.53, 45.53, 45.53, 45.53, 45.53, 34.56, 34.56, 34.56, 34.56, 34.56, 34.53, 34.53, 34.53, 34.53, 34.53, 34.41], "power_watts_avg": 40.99, "power_watts_peak": 47.37, "energy_joules_est": 114.38, "sample_count": 28, "duration_seconds": 2.79}, "timestamp": "2026-01-12T10:11:22.659492"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1956.225, "latencies_ms": [1956.225], "images_per_second": 0.511, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. teddy bear: 3\n2. sign: 1\n3. grass: 1\n4. tree: 1\n5. fence: 1\n6. wall: 1\n7. house: 1\n8. path: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.6, "ram_available_mb": 109129.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13392.1, "ram_available_mb": 109114.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.41, 34.41, 34.41, 34.41, 40.62, 40.62, 40.62, 40.62, 40.62, 46.38, 46.38, 46.38, 46.38, 46.38, 40.16, 40.16, 40.16, 40.16, 34.48, 34.48], "power_watts_avg": 40.11, "power_watts_peak": 46.38, "energy_joules_est": 78.5, "sample_count": 20, "duration_seconds": 1.957}, "timestamp": "2026-01-12T10:11:24.724761"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1623.364, "latencies_ms": [1623.364], "images_per_second": 0.616, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The teddy bears are positioned on the right side of the cross, which is located in the middle of the image. The cross is situated in the foreground of the image, with the background featuring a grassy area and a building.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13392.1, "ram_available_mb": 109114.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13403.4, "ram_available_mb": 109102.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.48, 34.48, 34.48, 37.82, 37.82, 37.82, 37.82, 37.82, 45.8, 45.8, 45.8, 45.8, 45.8, 43.42, 43.42, 43.42, 43.42], "power_watts_avg": 40.9, "power_watts_peak": 45.8, "energy_joules_est": 66.42, "sample_count": 17, "duration_seconds": 1.624}, "timestamp": "2026-01-12T10:11:26.493039"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1140.842, "latencies_ms": [1140.842], "images_per_second": 0.877, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A teddy bear cross is placed in a grassy area with a sign that reads \"Joseph Pans Mystie Maldean\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.5, "ram_available_mb": 109110.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13395.9, "ram_available_mb": 109110.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [43.42, 32.59, 32.59, 32.59, 32.59, 32.59, 46.12, 46.12, 46.12, 46.12, 46.12, 48.22], "power_watts_avg": 40.43, "power_watts_peak": 48.22, "energy_joules_est": 46.14, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-12T10:11:27.705115"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 995.386, "latencies_ms": [995.386], "images_per_second": 1.005, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The teddy bears are white and the cross is white. The grass is green and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.4, "ram_available_mb": 109110.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.22, 48.22, 48.22, 48.22, 41.38, 41.38, 41.38, 41.38, 41.38, 46.43], "power_watts_avg": 44.62, "power_watts_peak": 48.22, "energy_joules_est": 44.43, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-12T10:11:28.714792"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1347.753, "latencies_ms": [1347.753], "images_per_second": 0.742, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image captures a bustling restaurant with a large clock on the wall, where people are seated at tables, enjoying their meals and drinks, with a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.5, "ram_available_mb": 109106.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 46.43, 46.43, 47.34, 47.34, 47.34, 47.34, 47.36, 47.36, 47.36, 47.36, 47.36, 40.63], "power_watts_avg": 46.61, "power_watts_peak": 47.36, "energy_joules_est": 62.87, "sample_count": 14, "duration_seconds": 1.349}, "timestamp": "2026-01-12T10:11:30.131940"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1414.869, "latencies_ms": [1414.869], "images_per_second": 0.707, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " table: 10, chair: 20, person: 20, clock: 1, wall: 1, ceiling: 1, floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.1, "ram_available_mb": 109187.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13343.8, "ram_available_mb": 109162.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.63, 40.63, 40.63, 40.63, 44.4, 44.4, 44.4, 44.4, 44.4, 46.82, 46.82, 46.82, 46.82, 46.82, 37.05], "power_watts_avg": 43.71, "power_watts_peak": 46.82, "energy_joules_est": 61.86, "sample_count": 15, "duration_seconds": 1.415}, "timestamp": "2026-01-12T10:11:31.647044"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1709.54, "latencies_ms": [1709.54], "images_per_second": 0.585, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The clock is positioned in the background, far from the camera, and is surrounded by a dining area with tables and chairs. The dining area is located in the foreground, close to the camera, and is filled with people sitting at tables.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.2, "ram_available_mb": 109167.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [37.05, 37.05, 37.05, 37.05, 43.01, 43.01, 43.01, 43.01, 43.01, 45.88, 45.88, 45.88, 45.88, 45.88, 37.64, 37.64, 37.64], "power_watts_avg": 41.5, "power_watts_peak": 45.88, "energy_joules_est": 70.97, "sample_count": 17, "duration_seconds": 1.71}, "timestamp": "2026-01-12T10:11:33.362781"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1046.207, "latencies_ms": [1046.207], "images_per_second": 0.956, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image captures a bustling restaurant with a large clock in the background, where people are enjoying their meals and drinks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.2, "ram_available_mb": 109167.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 21.0}, "power_stats": {"power_watts_samples": [37.64, 37.64, 35.52, 35.52, 35.52, 35.52, 35.52, 47.75, 47.75, 47.75, 47.75], "power_watts_avg": 40.35, "power_watts_peak": 47.75, "energy_joules_est": 42.23, "sample_count": 11, "duration_seconds": 1.047}, "timestamp": "2026-01-12T10:11:34.473678"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1790.399, "latencies_ms": [1790.399], "images_per_second": 0.559, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere, characterized by the soft lighting and the warm tones of the wood and metal. The colors are rich and vibrant, with the green chairs and the brown wooden tables adding to the cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13348.7, "ram_available_mb": 109157.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.75, 45.15, 45.15, 45.15, 45.15, 45.15, 46.96, 46.96, 46.96, 46.96, 46.96, 49.01, 49.01, 49.01, 49.01, 49.01, 34.9, 34.9], "power_watts_avg": 45.73, "power_watts_peak": 49.01, "energy_joules_est": 81.89, "sample_count": 18, "duration_seconds": 1.791}, "timestamp": "2026-01-12T10:11:36.287967"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1263.933, "latencies_ms": [1263.933], "images_per_second": 0.791, "prompt_tokens": 1100, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A man and a child are standing on a snow-covered slope, with the man wearing a black jacket and the child wearing a pink snowsuit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13351.5, "ram_available_mb": 109154.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 38.82, 38.82, 38.82, 38.82, 38.82, 47.66, 47.66, 47.66, 47.66, 47.66], "power_watts_avg": 41.32, "power_watts_peak": 47.66, "energy_joules_est": 52.23, "sample_count": 13, "duration_seconds": 1.264}, "timestamp": "2026-01-12T10:11:37.601505"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1978.087, "latencies_ms": [1978.087], "images_per_second": 0.506, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. snow: 1\n3. trees: 1\n4. rocks: 1\n5. skis: 1\n6. goggles: 1\n7. snowboard: 1\n8. backpack: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13351.5, "ram_available_mb": 109154.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13335.3, "ram_available_mb": 109171.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.44, 44.44, 44.44, 44.44, 44.44, 46.05, 46.05, 46.05, 46.05, 46.05, 47.02, 47.02, 47.02, 47.02, 47.02, 35.5, 35.5, 35.5, 35.5, 35.5], "power_watts_avg": 43.25, "power_watts_peak": 47.02, "energy_joules_est": 85.57, "sample_count": 20, "duration_seconds": 1.978}, "timestamp": "2026-01-12T10:11:39.614548"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1791.647, "latencies_ms": [1791.647], "images_per_second": 0.558, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The child in the foreground is standing closer to the camera than the person in the black jacket, who is positioned in the background. The child is standing on the left side of the image, while the person in the black jacket is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.3, "ram_available_mb": 109171.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13326.3, "ram_available_mb": 109180.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.6, 34.6, 34.6, 34.6, 42.32, 42.32, 42.32, 42.32, 42.32, 46.22, 46.22, 46.22, 46.22, 46.22, 38.66, 38.66, 38.66, 38.66], "power_watts_avg": 40.87, "power_watts_peak": 46.22, "energy_joules_est": 73.25, "sample_count": 18, "duration_seconds": 1.792}, "timestamp": "2026-01-12T10:11:41.479334"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 911.482, "latencies_ms": [911.482], "images_per_second": 1.097, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man and a child are standing on a snowy mountain, with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.3, "ram_available_mb": 109180.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.66, 33.66, 33.66, 33.66, 33.66, 33.66, 47.32, 47.32, 47.32, 47.32], "power_watts_avg": 39.63, "power_watts_peak": 47.32, "energy_joules_est": 36.14, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-12T10:11:42.490982"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1533.385, "latencies_ms": [1533.385], "images_per_second": 0.652, "prompt_tokens": 1110, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a snowy mountain with a child wearing a black jacket and a man wearing a black jacket standing on the snow. The sky is clear with a few clouds, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.8, "ram_available_mb": 109185.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13340.1, "ram_available_mb": 109166.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.32, 46.4, 46.4, 46.4, 46.4, 46.4, 45.97, 45.97, 45.97, 45.97, 45.97, 48.45, 48.45, 48.45, 48.45, 48.45], "power_watts_avg": 46.96, "power_watts_peak": 48.45, "energy_joules_est": 72.03, "sample_count": 16, "duration_seconds": 1.534}, "timestamp": "2026-01-12T10:11:44.104763"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1140.816, "latencies_ms": [1140.816], "images_per_second": 0.877, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A pair of feet wearing flip-flops is standing on a wooden floor with a broken mobile phone and its parts scattered around them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.1, "ram_available_mb": 109166.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.57, 34.57, 34.57, 34.57, 34.57, 45.17, 45.17, 45.17, 45.17, 45.17, 46.49, 46.49], "power_watts_avg": 40.98, "power_watts_peak": 46.49, "energy_joules_est": 46.77, "sample_count": 12, "duration_seconds": 1.141}, "timestamp": "2026-01-12T10:11:45.321047"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 878.21, "latencies_ms": [878.21], "images_per_second": 1.139, "prompt_tokens": 1113, "response_tokens_est": 17, "n_tiles": 1, "output_text": " 1. flip phone: 2\n2. person's feet: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13389.8, "ram_available_mb": 109116.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 25.0}, "power_stats": {"power_watts_samples": [46.49, 46.49, 46.49, 37.57, 37.57, 37.57, 37.57, 37.57, 46.85], "power_watts_avg": 41.58, "power_watts_peak": 46.85, "energy_joules_est": 36.52, "sample_count": 9, "duration_seconds": 0.879}, "timestamp": "2026-01-12T10:11:46.230493"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1830.958, "latencies_ms": [1830.958], "images_per_second": 0.546, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The two flip phones are positioned in the foreground, with the battery and circuit board in the middle, and the two flip phones are in the background. The person's feet are in the foreground, with the flip phones and the battery and circuit board in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.9, "ram_available_mb": 109124.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.85, 46.85, 46.85, 52.34, 52.34, 52.34, 52.34, 52.34, 47.72, 47.72, 47.72, 47.72, 47.72, 41.31, 41.31, 41.31, 41.31, 41.31, 34.81], "power_watts_avg": 46.43, "power_watts_peak": 52.34, "energy_joules_est": 85.02, "sample_count": 19, "duration_seconds": 1.831}, "timestamp": "2026-01-12T10:11:48.145778"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.61, "latencies_ms": [1116.61], "images_per_second": 0.896, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A pair of feet wearing flip flops are standing on a wooden floor with a broken cell phone and its parts scattered around them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.7, "ram_available_mb": 109126.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13383.3, "ram_available_mb": 109123.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.81, 34.81, 40.44, 40.44, 40.44, 40.44, 40.44, 45.61, 45.61, 45.61], "power_watts_avg": 39.86, "power_watts_peak": 45.61, "energy_joules_est": 44.54, "sample_count": 12, "duration_seconds": 1.118}, "timestamp": "2026-01-12T10:11:49.411417"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 769.822, "latencies_ms": [769.822], "images_per_second": 1.299, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The wooden floor is brown and the person's feet are black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.4, "ram_available_mb": 109130.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13391.3, "ram_available_mb": 109115.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [45.61, 45.61, 36.96, 36.96, 36.96, 36.96, 36.96, 46.2], "power_watts_avg": 40.27, "power_watts_peak": 46.2, "energy_joules_est": 31.03, "sample_count": 8, "duration_seconds": 0.77}, "timestamp": "2026-01-12T10:11:50.222768"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1928.575, "latencies_ms": [1928.575], "images_per_second": 0.519, "prompt_tokens": 1099, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures the majestic Palace of Westminster, also known as the Houses of Parliament, bathed in the warm glow of the setting sun, with the iconic Big Ben tower standing tall in the background, while a boat with a red and white flag floats on the river in the foreground.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13383.4, "ram_available_mb": 109122.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.2, 46.2, 46.2, 55.89, 55.89, 55.89, 55.89, 55.89, 47.52, 47.52, 47.52, 47.52, 47.52, 40.94, 40.94, 40.94, 40.94, 40.94, 34.86, 34.86], "power_watts_avg": 46.5, "power_watts_peak": 55.89, "energy_joules_est": 89.71, "sample_count": 20, "duration_seconds": 1.929}, "timestamp": "2026-01-12T10:11:52.241235"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1906.148, "latencies_ms": [1906.148], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Tower: 1\n2. Boat: 2\n3. Building: 1\n4. Bridge: 1\n5. Flag: 1\n6. Boat: 2\n7. Boat: 2\n8. Boat: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.5, "ram_available_mb": 109115.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13370.9, "ram_available_mb": 109135.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 36.3, 36.3, 36.3, 36.3, 36.3, 45.29, 45.29, 45.29, 45.29, 45.29, 44.79, 44.79, 44.79, 44.79, 44.79, 34.89], "power_watts_avg": 40.6, "power_watts_peak": 45.29, "energy_joules_est": 77.42, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T10:11:54.209116"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1799.878, "latencies_ms": [1799.878], "images_per_second": 0.556, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The clock tower is located on the left side of the image, while the Palace of Westminster is situated in the background. The foreground features a barge with a red and white striped awning, and the background includes a bridge with a white railing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.9, "ram_available_mb": 109135.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.2, "ram_available_mb": 109123.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 39.22, 39.22, 39.22, 39.22, 39.22, 46.82, 46.82, 46.82, 46.82, 46.82, 42.62, 42.62, 42.62, 42.62, 42.62], "power_watts_avg": 41.55, "power_watts_peak": 46.82, "energy_joules_est": 74.83, "sample_count": 18, "duration_seconds": 1.801}, "timestamp": "2026-01-12T10:11:56.077376"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2318.064, "latencies_ms": [2318.064], "images_per_second": 0.431, "prompt_tokens": 1111, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The image captures the majestic Palace of Westminster, also known as the Houses of Parliament, in London, England. The scene is set on a river, with boats visible in the foreground, adding a sense of tranquility to the historic landmark. The sky overhead is overcast, casting a soft light over the scene and highlighting the intricate details of the building's architecture.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.2, "ram_available_mb": 109123.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 34.89, 47.7, 47.7, 47.7, 47.7, 47.7, 47.94, 47.94, 47.94, 47.94, 47.94, 34.98, 34.98, 34.98, 34.98, 34.98, 34.99, 34.99, 34.99, 34.99], "power_watts_avg": 40.32, "power_watts_peak": 47.94, "energy_joules_est": 93.47, "sample_count": 24, "duration_seconds": 2.318}, "timestamp": "2026-01-12T10:11:58.497049"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1354.852, "latencies_ms": [1354.852], "images_per_second": 0.738, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the buildings are bathed in a warm yellow light. The water is a deep blue, reflecting the city lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.5, "ram_available_mb": 109097.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [32.62, 32.62, 32.62, 32.62, 32.62, 44.94, 44.94, 44.94, 44.94, 44.94, 47.39, 47.39, 47.39, 47.39], "power_watts_avg": 41.24, "power_watts_peak": 47.39, "energy_joules_est": 55.9, "sample_count": 14, "duration_seconds": 1.356}, "timestamp": "2026-01-12T10:11:59.962372"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1445.933, "latencies_ms": [1445.933], "images_per_second": 0.692, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a spacious living room with a red carpet, a green sofa, a black chair, and a dining table with chairs, all arranged in a well-lit and organized space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.6, "ram_available_mb": 109105.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13393.8, "ram_available_mb": 109112.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [47.39, 32.8, 32.8, 32.8, 32.8, 32.8, 47.15, 47.15, 47.15, 47.15, 47.15, 49.24, 49.24, 49.24, 49.24], "power_watts_avg": 42.94, "power_watts_peak": 49.24, "energy_joules_est": 62.1, "sample_count": 15, "duration_seconds": 1.446}, "timestamp": "2026-01-12T10:12:01.478736"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1585.621, "latencies_ms": [1585.621], "images_per_second": 0.631, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " chair: 1, sofa: 1, television: 1, potted plant: 1, mirror: 1, television stand: 1, sofa: 1, chair: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13393.8, "ram_available_mb": 109112.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.24, 33.09, 33.09, 33.09, 33.09, 33.09, 46.9, 46.9, 46.9, 46.9, 46.9, 48.35, 48.35, 48.35, 48.35, 48.35], "power_watts_avg": 43.18, "power_watts_peak": 49.24, "energy_joules_est": 68.49, "sample_count": 16, "duration_seconds": 1.586}, "timestamp": "2026-01-12T10:12:03.093631"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2140.8, "latencies_ms": [2140.8], "images_per_second": 0.467, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The living room is situated in the center of the image, with the furniture arranged around it. The foreground features a red rug and a coffee table, while the background includes a television and a bookshelf. The left side of the room is dominated by a window, while the right side has a door leading to another room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13378.5, "ram_available_mb": 109127.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 34.85, 34.85, 47.52, 47.52, 47.52, 47.52, 47.52, 47.77, 47.77, 47.77, 47.77, 47.77, 36.02, 36.02, 36.02, 36.02, 36.02, 34.89, 34.89], "power_watts_avg": 40.93, "power_watts_peak": 47.77, "energy_joules_est": 87.66, "sample_count": 22, "duration_seconds": 2.141}, "timestamp": "2026-01-12T10:12:05.311820"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 831.043, "latencies_ms": [831.043], "images_per_second": 1.203, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A living room with a red carpet, a couch, and a chair.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13378.5, "ram_available_mb": 109127.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.1, "ram_available_mb": 109119.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 1.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 33.74, 33.74, 33.74, 33.74, 33.74, 45.86, 45.86], "power_watts_avg": 36.69, "power_watts_peak": 45.86, "energy_joules_est": 30.51, "sample_count": 9, "duration_seconds": 0.832}, "timestamp": "2026-01-12T10:12:06.273373"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1058.977, "latencies_ms": [1058.977], "images_per_second": 0.944, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming in from the windows, and the hardwood floors are polished and clean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.1, "ram_available_mb": 109119.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13456.1, "ram_available_mb": 109050.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [45.86, 45.86, 45.86, 51.12, 51.12, 51.12, 51.12, 51.12, 46.37, 46.37, 46.37], "power_watts_avg": 48.39, "power_watts_peak": 51.12, "energy_joules_est": 51.27, "sample_count": 11, "duration_seconds": 1.059}, "timestamp": "2026-01-12T10:12:07.383863"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1269.408, "latencies_ms": [1269.408], "images_per_second": 0.788, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " Two parking meters are attached to a red pole on a sidewalk, with a building in the background displaying a sign that reads \"40 Years of Saving Lives.\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13456.1, "ram_available_mb": 109050.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13428.5, "ram_available_mb": 109077.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.37, 46.37, 42.4, 42.4, 42.4, 42.4, 42.4, 47.41, 47.41, 47.41, 47.41, 47.41, 48.03], "power_watts_avg": 45.37, "power_watts_peak": 48.03, "energy_joules_est": 57.6, "sample_count": 13, "duration_seconds": 1.27}, "timestamp": "2026-01-12T10:12:08.697950"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1530.963, "latencies_ms": [1530.963], "images_per_second": 0.653, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. red post\n2. parking meter\n3. red circular holder\n4. parking meter holder\n5. parking meter\n6. parking meter\n7. parking meter\n8. parking meter", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.7, "ram_available_mb": 109085.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13416.5, "ram_available_mb": 109089.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.03, 48.03, 48.03, 48.03, 42.47, 42.47, 42.47, 42.47, 42.47, 47.54, 47.54, 47.54, 47.54, 47.54, 40.56, 40.56], "power_watts_avg": 45.2, "power_watts_peak": 48.03, "energy_joules_est": 69.22, "sample_count": 16, "duration_seconds": 1.531}, "timestamp": "2026-01-12T10:12:10.309354"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1609.34, "latencies_ms": [1609.34], "images_per_second": 0.621, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The two parking meters are positioned on the left side of the image, with the red pole in the foreground and the building in the background. The parking meters are closer to the camera than the building, which is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.5, "ram_available_mb": 109093.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.8, "ram_available_mb": 109097.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.56, 40.56, 40.56, 36.98, 36.98, 36.98, 36.98, 36.98, 46.49, 46.49, 46.49, 46.49, 46.49, 45.44, 45.44, 45.44], "power_watts_avg": 42.21, "power_watts_peak": 46.49, "energy_joules_est": 67.94, "sample_count": 16, "duration_seconds": 1.61}, "timestamp": "2026-01-12T10:12:11.927846"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1036.018, "latencies_ms": [1036.018], "images_per_second": 0.965, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A red pole with two parking meters on top stands on a sidewalk in front of a building with a large window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.9, "ram_available_mb": 109105.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13320.5, "ram_available_mb": 109185.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.44, 45.44, 33.25, 33.25, 33.25, 33.25, 48.23, 48.23, 48.23, 48.23, 48.23], "power_watts_avg": 42.27, "power_watts_peak": 48.23, "energy_joules_est": 43.82, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-12T10:12:13.040654"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2090.082, "latencies_ms": [2090.082], "images_per_second": 0.478, "prompt_tokens": 1110, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a red parking meter with two meters on top, standing on a sidewalk. The parking meter is located in front of a building with a large window that has a banner with the text \"40 Years of Saving Lives\". The weather appears to be clear, as the sky is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.5, "ram_available_mb": 109185.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13338.4, "ram_available_mb": 109167.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.07, 49.07, 49.07, 49.07, 49.07, 46.97, 46.97, 46.97, 46.97, 46.97, 47.31, 47.31, 47.31, 47.31, 47.31, 34.64, 34.64, 34.64, 34.64, 34.64, 35.02], "power_watts_avg": 44.05, "power_watts_peak": 49.07, "energy_joules_est": 92.07, "sample_count": 21, "duration_seconds": 2.09}, "timestamp": "2026-01-12T10:12:15.155298"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1432.608, "latencies_ms": [1432.608], "images_per_second": 0.698, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man and a woman are sitting on a couch in a living room, watching television, with a coffee table in front of them that has a bunch of snacks and a candle on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.4, "ram_available_mb": 109167.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13334.0, "ram_available_mb": 109172.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.02, 35.02, 35.02, 35.02, 42.18, 42.18, 42.18, 42.18, 42.18, 46.48, 46.48, 46.48, 46.48, 46.48, 40.34], "power_watts_avg": 41.58, "power_watts_peak": 46.48, "energy_joules_est": 59.63, "sample_count": 15, "duration_seconds": 1.434}, "timestamp": "2026-01-12T10:12:16.721513"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2090.418, "latencies_ms": [2090.418], "images_per_second": 0.478, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. sofa: 2\n2. television: 1\n3. coffee table: 1\n4. dining table: 1\n5. dining chairs: 2\n6. dining table: 1\n7. dining table: 1\n8. dining table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.0, "ram_available_mb": 109172.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13370.0, "ram_available_mb": 109136.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.34, 40.34, 40.34, 40.34, 41.49, 41.49, 41.49, 41.49, 41.49, 46.67, 46.67, 46.67, 46.67, 46.67, 39.93, 39.93, 39.93, 39.93, 34.84, 34.84, 34.84], "power_watts_avg": 41.26, "power_watts_peak": 46.67, "energy_joules_est": 86.27, "sample_count": 21, "duration_seconds": 2.091}, "timestamp": "2026-01-12T10:12:18.840093"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1578.15, "latencies_ms": [1578.15], "images_per_second": 0.634, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The television is on the left side of the room, the couch is in the middle, and the coffee table is in the foreground. The person on the couch is closer to the camera than the person on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.7, "ram_available_mb": 109143.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13372.9, "ram_available_mb": 109133.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.14, 34.14, 34.14, 34.14, 34.14, 46.61, 46.61, 46.61, 46.61, 46.61, 47.62, 47.62, 47.62, 47.62], "power_watts_avg": 41.49, "power_watts_peak": 47.62, "energy_joules_est": 65.52, "sample_count": 16, "duration_seconds": 1.579}, "timestamp": "2026-01-12T10:12:20.505787"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 902.152, "latencies_ms": [902.152], "images_per_second": 1.108, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young man and woman are sitting on a couch in a living room, watching TV.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.7, "ram_available_mb": 109124.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [47.62, 33.9, 33.9, 33.9, 33.9, 33.9, 47.74, 47.74, 47.74], "power_watts_avg": 40.04, "power_watts_peak": 47.74, "energy_joules_est": 36.14, "sample_count": 9, "duration_seconds": 0.903}, "timestamp": "2026-01-12T10:12:21.414325"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1011.851, "latencies_ms": [1011.851], "images_per_second": 0.988, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is lit by a warm yellow light, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.8, "ram_available_mb": 109132.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13303.4, "ram_available_mb": 109202.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 31.0}, "power_stats": {"power_watts_samples": [47.74, 47.74, 48.47, 48.47, 48.47, 48.47, 48.47, 47.96, 47.96, 47.96, 47.96], "power_watts_avg": 48.15, "power_watts_peak": 48.47, "energy_joules_est": 48.74, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-12T10:12:22.527181"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 865.996, "latencies_ms": [865.996], "images_per_second": 1.155, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a white power strip with multiple outlets in front of a toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13303.4, "ram_available_mb": 109202.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13335.2, "ram_available_mb": 109171.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [47.96, 47.25, 47.25, 47.25, 47.25, 46.46, 46.46, 46.46, 46.46], "power_watts_avg": 46.98, "power_watts_peak": 47.96, "energy_joules_est": 40.71, "sample_count": 9, "duration_seconds": 0.867}, "timestamp": "2026-01-12T10:12:23.437896"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1386.027, "latencies_ms": [1386.027], "images_per_second": 0.721, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " toilet: 1, person: 1, floor: 1, wall: 1, box: 1, floor lamp: 1, remote control: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.3, "ram_available_mb": 109179.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13333.3, "ram_available_mb": 109173.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.46, 46.5, 46.5, 46.5, 46.5, 46.5, 47.36, 47.36, 47.36, 47.36, 47.36, 49.55, 49.55, 49.55], "power_watts_avg": 47.46, "power_watts_peak": 49.55, "energy_joules_est": 65.79, "sample_count": 14, "duration_seconds": 1.386}, "timestamp": "2026-01-12T10:12:24.849609"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1645.62, "latencies_ms": [1645.62], "images_per_second": 0.608, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The person's hand is positioned to the right of the toilet, with the toilet paper holder being in the foreground. The person is holding the power strip in front of the toilet, which is located in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.3, "ram_available_mb": 109173.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.4, "ram_available_mb": 109164.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [49.55, 49.55, 37.0, 37.0, 37.0, 37.0, 37.0, 47.53, 47.53, 47.53, 47.53, 47.53, 45.62, 45.62, 45.62, 45.62, 45.62], "power_watts_avg": 44.11, "power_watts_peak": 49.55, "energy_joules_est": 72.61, "sample_count": 17, "duration_seconds": 1.646}, "timestamp": "2026-01-12T10:12:26.564816"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 781.866, "latencies_ms": [781.866], "images_per_second": 1.279, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A person is holding a power strip in front of a toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.5, "ram_available_mb": 109168.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13346.1, "ram_available_mb": 109160.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [34.3, 34.3, 34.3, 34.3, 34.3, 47.13, 47.13, 47.13], "power_watts_avg": 39.11, "power_watts_peak": 47.13, "energy_joules_est": 30.59, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-12T10:12:27.375336"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1330.095, "latencies_ms": [1330.095], "images_per_second": 0.752, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is a photograph of a white toilet with a silver metal stand next to it. The toilet is located in a room with a white wall and a wooden floor.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13346.1, "ram_available_mb": 109160.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.0, "ram_available_mb": 109165.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.13, 47.13, 48.5, 48.5, 48.5, 48.5, 48.5, 47.37, 47.37, 47.37, 47.37, 47.37, 47.44, 47.44], "power_watts_avg": 47.75, "power_watts_peak": 48.5, "energy_joules_est": 63.53, "sample_count": 14, "duration_seconds": 1.33}, "timestamp": "2026-01-12T10:12:28.787959"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1162.868, "latencies_ms": [1162.868], "images_per_second": 0.86, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air, with a crowd of spectators watching from the side of a snow-covered hill.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.1, "ram_available_mb": 109173.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13341.0, "ram_available_mb": 109165.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.44, 47.44, 47.44, 38.48, 38.48, 38.48, 38.48, 38.48, 46.45, 46.45, 46.45, 46.45], "power_watts_avg": 43.38, "power_watts_peak": 47.44, "energy_joules_est": 50.47, "sample_count": 12, "duration_seconds": 1.163}, "timestamp": "2026-01-12T10:12:30.000429"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2254.846, "latencies_ms": [2254.846], "images_per_second": 0.443, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. snowboarder: 1\n3. crowd: 1\n4. snowboarder: 1\n5. snowboarder: 1\n6. snowboarder: 1\n7. snowboarder: 1\n8. snowboarder: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13337.0, "ram_available_mb": 109169.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.9, "ram_available_mb": 109174.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.45, 42.31, 42.31, 42.31, 42.31, 42.31, 47.53, 47.53, 47.53, 47.53, 47.53, 48.96, 48.96, 48.96, 48.96, 48.96, 34.96, 34.96, 34.96, 34.96, 34.96, 34.79, 34.79], "power_watts_avg": 42.82, "power_watts_peak": 48.96, "energy_joules_est": 96.56, "sample_count": 23, "duration_seconds": 2.255}, "timestamp": "2026-01-12T10:12:32.318627"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1829.261, "latencies_ms": [1829.261], "images_per_second": 0.547, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The snowboarder is in the foreground, performing a trick in the air. The crowd is in the background, watching the event. The snow ramp is in the middle ground, with the snowboarder's trick taking place on the right side of the ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 36.35, 36.35, 36.35, 36.35, 36.35, 46.44, 46.44, 46.44, 46.44, 46.44, 45.74, 45.74, 45.74, 45.74, 45.74, 34.85, 34.85], "power_watts_avg": 41.15, "power_watts_peak": 46.44, "energy_joules_est": 75.33, "sample_count": 19, "duration_seconds": 1.83}, "timestamp": "2026-01-12T10:12:34.252410"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1195.276, "latencies_ms": [1195.276], "images_per_second": 0.837, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air above a snow ramp. The ramp is surrounded by a crowd of spectators watching the event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 40.01, 40.01, 40.01, 40.01, 40.01, 46.32, 46.32, 46.32, 46.32], "power_watts_avg": 40.82, "power_watts_peak": 46.32, "energy_joules_est": 48.82, "sample_count": 12, "duration_seconds": 1.196}, "timestamp": "2026-01-12T10:12:35.465795"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1570.871, "latencies_ms": [1570.871], "images_per_second": 0.637, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a snowboarder performing a trick in the air, with a clear blue sky in the background. The snowboarder is wearing a red and white outfit, and the snow is white and pristine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.32, 40.59, 40.59, 40.59, 40.59, 40.59, 47.7, 47.7, 47.7, 47.7, 47.7, 48.83, 48.83, 48.83, 48.83, 48.83], "power_watts_avg": 45.74, "power_watts_peak": 48.83, "energy_joules_est": 71.88, "sample_count": 16, "duration_seconds": 1.571}, "timestamp": "2026-01-12T10:12:37.077506"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 804.818, "latencies_ms": [804.818], "images_per_second": 1.243, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A room with a desk, chair, and a plant in it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13369.4, "ram_available_mb": 109136.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [34.78, 34.78, 34.78, 34.78, 34.78, 47.33, 47.33, 47.33], "power_watts_avg": 39.48, "power_watts_peak": 47.33, "energy_joules_est": 31.82, "sample_count": 8, "duration_seconds": 0.806}, "timestamp": "2026-01-12T10:12:37.889501"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2045.476, "latencies_ms": [2045.476], "images_per_second": 0.489, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. white chair: 1\n2. desk: 1\n3. computer monitor: 1\n4. keyboard: 1\n5. mouse: 1\n6. lamp: 1\n7. potted plant: 1\n8. bookshelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.4, "ram_available_mb": 109136.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13325.7, "ram_available_mb": 109180.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.33, 47.33, 47.78, 47.78, 47.78, 47.78, 47.78, 48.16, 48.16, 48.16, 48.16, 48.16, 47.53, 47.53, 47.53, 47.53, 47.53, 34.92, 34.92, 34.92, 34.92], "power_watts_avg": 45.32, "power_watts_peak": 48.16, "energy_joules_est": 92.7, "sample_count": 21, "duration_seconds": 2.046}, "timestamp": "2026-01-12T10:12:40.006870"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2124.732, "latencies_ms": [2124.732], "images_per_second": 0.471, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The desk is positioned to the left of the white sofa, with the chair in front of it. The computer monitor is placed on the desk, while the laptop is situated to the right of the monitor. The potted plant is located near the desk, while the bookshelf is situated further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13325.7, "ram_available_mb": 109180.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.06, 33.06, 33.06, 33.06, 33.06, 45.88, 45.88, 45.88, 45.88, 45.88, 47.77, 47.77, 47.77, 47.77, 47.77, 34.75, 34.75, 34.75, 34.75, 34.75, 34.67, 34.67], "power_watts_avg": 39.85, "power_watts_peak": 47.77, "energy_joules_est": 84.7, "sample_count": 22, "duration_seconds": 2.126}, "timestamp": "2026-01-12T10:12:42.277440"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 933.672, "latencies_ms": [933.672], "images_per_second": 1.071, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A room with a desk, chair, and computer setup, with a plant in the corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13399.6, "ram_available_mb": 109106.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.67, 34.67, 34.67, 35.59, 35.59, 35.59, 35.59, 35.59, 45.36, 45.36], "power_watts_avg": 37.27, "power_watts_peak": 45.36, "energy_joules_est": 34.83, "sample_count": 10, "duration_seconds": 0.935}, "timestamp": "2026-01-12T10:12:43.338445"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 882.901, "latencies_ms": [882.901], "images_per_second": 1.133, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.7, "ram_available_mb": 109110.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13387.9, "ram_available_mb": 109118.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.36, 45.36, 46.17, 46.17, 46.17, 46.17, 46.17, 46.49, 46.49], "power_watts_avg": 46.06, "power_watts_peak": 46.49, "energy_joules_est": 40.69, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:12:44.249743"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1139.367, "latencies_ms": [1139.367], "images_per_second": 0.878, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A person is standing on a dirt road with a motorcycle parked beside them, with a scenic view of mountains and trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13380.1, "ram_available_mb": 109126.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13392.1, "ram_available_mb": 109114.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.49, 46.49, 46.49, 52.19, 52.19, 52.19, 52.19, 52.19, 47.47, 47.47, 47.47, 47.47], "power_watts_avg": 49.19, "power_watts_peak": 52.19, "energy_joules_est": 56.08, "sample_count": 12, "duration_seconds": 1.14}, "timestamp": "2026-01-12T10:12:45.465658"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2120.306, "latencies_ms": [2120.306], "images_per_second": 0.472, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Motorcycle: 1\n2. Motorcycle: 1\n3. Motorcycle: 1\n4. Motorcycle: 1\n5. Motorcycle: 1\n6. Motorcycle: 1\n7. Motorcycle: 1\n8. Motorcycle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.1, "ram_available_mb": 109114.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13373.9, "ram_available_mb": 109132.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.47, 39.27, 39.27, 39.27, 39.27, 39.27, 46.7, 46.7, 46.7, 46.7, 46.7, 48.88, 48.88, 48.88, 48.88, 48.88, 34.74, 34.74, 34.74, 34.74, 34.74, 34.85], "power_watts_avg": 42.29, "power_watts_peak": 48.88, "energy_joules_est": 89.68, "sample_count": 22, "duration_seconds": 2.121}, "timestamp": "2026-01-12T10:12:47.686617"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1702.893, "latencies_ms": [1702.893], "images_per_second": 0.587, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The motorcycle is positioned to the left of the person, who is standing on the right side of the image. The motorcycle is in the foreground, while the person is in the background. The person is closer to the camera than the motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.0, "ram_available_mb": 109136.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13373.7, "ram_available_mb": 109132.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 34.85, 39.46, 39.46, 39.46, 39.46, 39.46, 45.2, 45.2, 45.2, 45.2, 45.2, 40.58, 40.58, 40.58, 40.58], "power_watts_avg": 40.6, "power_watts_peak": 45.2, "energy_joules_est": 69.17, "sample_count": 17, "duration_seconds": 1.704}, "timestamp": "2026-01-12T10:12:49.454800"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 959.888, "latencies_ms": [959.888], "images_per_second": 1.042, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A motorcyclist is standing on a dirt road in the mountains, looking out at the scenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.8, "ram_available_mb": 109140.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13384.7, "ram_available_mb": 109121.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 10.0}, "power_stats": {"power_watts_samples": [40.58, 33.08, 33.08, 33.08, 33.08, 33.08, 47.89, 47.89, 47.89, 47.89], "power_watts_avg": 39.75, "power_watts_peak": 47.89, "energy_joules_est": 38.17, "sample_count": 10, "duration_seconds": 0.96}, "timestamp": "2026-01-12T10:12:50.467353"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1716.104, "latencies_ms": [1716.104], "images_per_second": 0.583, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a dirt road with a motorcyclist and a backpack, set against a backdrop of a clear blue sky with scattered clouds. The motorcyclist is wearing a helmet and a black jacket, while the backpack is black and red.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13380.8, "ram_available_mb": 109125.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.89, 46.84, 46.84, 46.84, 46.84, 46.84, 47.08, 47.08, 47.08, 47.08, 47.08, 49.6, 49.6, 49.6, 49.6, 49.6, 34.88, 34.88], "power_watts_avg": 46.4, "power_watts_peak": 49.6, "energy_joules_est": 79.66, "sample_count": 18, "duration_seconds": 1.717}, "timestamp": "2026-01-12T10:12:52.283461"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1307.378, "latencies_ms": [1307.378], "images_per_second": 0.765, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a kitchen with wooden cabinets, a white stove, and a white refrigerator, with a dining table in the center and a bowl of oranges on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.4, "ram_available_mb": 109144.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13373.9, "ram_available_mb": 109132.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 38.37, 38.37, 38.37, 38.37, 38.37, 46.11, 46.11, 46.11, 46.11, 46.11, 43.36], "power_watts_avg": 40.74, "power_watts_peak": 46.11, "energy_joules_est": 53.28, "sample_count": 14, "duration_seconds": 1.308}, "timestamp": "2026-01-12T10:12:53.696701"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1721.203, "latencies_ms": [1721.203], "images_per_second": 0.581, "prompt_tokens": 1113, "response_tokens_est": 49, "n_tiles": 1, "output_text": " table: 1, chair: 1, bananas: 1, oranges: 1, bowl: 1, stove: 1, refrigerator: 1, cabinet: 1, door: 1, light: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13365.5, "ram_available_mb": 109140.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [43.36, 43.36, 43.36, 43.36, 42.24, 42.24, 42.24, 42.24, 42.24, 46.2, 46.2, 46.2, 46.2, 46.2, 39.41, 39.41, 39.41, 39.41], "power_watts_avg": 42.96, "power_watts_peak": 46.2, "energy_joules_est": 73.96, "sample_count": 18, "duration_seconds": 1.722}, "timestamp": "2026-01-12T10:12:55.511140"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1456.562, "latencies_ms": [1456.562], "images_per_second": 0.687, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The kitchen is located in the center of the house, with the dining table and chairs placed in the foreground. The refrigerator is positioned in the background, while the sink is situated near the stove.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13365.5, "ram_available_mb": 109140.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.41, 32.69, 32.69, 32.69, 32.69, 32.69, 46.6, 46.6, 46.6, 46.6, 46.6, 48.61, 48.61, 48.61, 48.61], "power_watts_avg": 42.02, "power_watts_peak": 48.61, "energy_joules_est": 61.24, "sample_count": 15, "duration_seconds": 1.457}, "timestamp": "2026-01-12T10:12:57.028099"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1083.464, "latencies_ms": [1083.464], "images_per_second": 0.923, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A kitchen with white appliances and wooden cabinets, a dining table with a bowl of oranges on it, and a white refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13419.2, "ram_available_mb": 109087.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.61, 33.68, 33.68, 33.68, 33.68, 33.68, 47.23, 47.23, 47.23, 47.23, 47.23], "power_watts_avg": 41.19, "power_watts_peak": 48.61, "energy_joules_est": 44.65, "sample_count": 11, "duration_seconds": 1.084}, "timestamp": "2026-01-12T10:12:58.141317"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1005.288, "latencies_ms": [1005.288], "images_per_second": 0.995, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The kitchen is well lit with natural light coming in from the windows, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13420.1, "ram_available_mb": 109086.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [48.44, 48.44, 48.44, 48.44, 46.15, 46.15, 46.15, 46.15, 46.15, 47.6], "power_watts_avg": 47.21, "power_watts_peak": 48.44, "energy_joules_est": 47.49, "sample_count": 10, "duration_seconds": 1.006}, "timestamp": "2026-01-12T10:12:59.153527"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 847.675, "latencies_ms": [847.675], "images_per_second": 1.18, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A female tennis player is preparing to serve the ball on a green tennis court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.2, "ram_available_mb": 109090.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.6, 47.6, 47.6, 47.6, 47.42, 47.42, 47.42, 47.42, 47.42], "power_watts_avg": 47.5, "power_watts_peak": 47.6, "energy_joules_est": 40.27, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-12T10:13:00.066587"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2058.865, "latencies_ms": [2058.865], "images_per_second": 0.486, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. woman: 1\n2. racket: 1\n3. tennis ball: 1\n4. person: 1\n5. blue wall: 1\n6. white line: 1\n7. green surface: 1\n8. white cap: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.47, 47.47, 47.47, 47.47, 47.47, 49.57, 49.57, 49.57, 49.57, 49.57, 47.82, 47.82, 47.82, 47.82, 47.82, 34.95, 34.95, 34.95, 34.95, 34.95, 34.83], "power_watts_avg": 44.47, "power_watts_peak": 49.57, "energy_joules_est": 91.58, "sample_count": 21, "duration_seconds": 2.059}, "timestamp": "2026-01-12T10:13:02.186255"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1857.921, "latencies_ms": [1857.921], "images_per_second": 0.538, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the ball in the middle ground and the blue wall in the background. The player is facing the ball, which is near the center of the image, and the wall is to the right of the player.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.9, "ram_available_mb": 109161.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 34.83, 40.37, 40.37, 40.37, 40.37, 40.37, 45.98, 45.98, 45.98, 45.98, 41.45, 41.45, 41.45, 41.45, 41.45, 34.74], "power_watts_avg": 40.37, "power_watts_peak": 45.98, "energy_joules_est": 75.05, "sample_count": 19, "duration_seconds": 1.859}, "timestamp": "2026-01-12T10:13:04.156989"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 849.075, "latencies_ms": [849.075], "images_per_second": 1.178, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A female tennis player is preparing to serve the ball on a green tennis court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13422.0, "ram_available_mb": 109084.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.74, 34.74, 34.74, 34.74, 41.6, 41.6, 41.6, 41.6, 41.6], "power_watts_avg": 38.55, "power_watts_peak": 41.6, "energy_joules_est": 32.75, "sample_count": 9, "duration_seconds": 0.85}, "timestamp": "2026-01-12T10:13:05.116127"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1385.842, "latencies_ms": [1385.842], "images_per_second": 0.722, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a female tennis player in a white outfit, with a vibrant green court and a blue wall in the background. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.0, "ram_available_mb": 109084.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13422.1, "ram_available_mb": 109084.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [46.01, 46.01, 46.01, 46.01, 46.01, 51.45, 51.45, 51.45, 51.45, 51.45, 47.38, 47.38, 47.38, 47.38], "power_watts_avg": 48.34, "power_watts_peak": 51.45, "energy_joules_est": 67.03, "sample_count": 14, "duration_seconds": 1.387}, "timestamp": "2026-01-12T10:13:06.528309"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 897.801, "latencies_ms": [897.801], "images_per_second": 1.114, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red fire hydrant is on the sidewalk, and a man is standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.1, "ram_available_mb": 109084.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13412.2, "ram_available_mb": 109094.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 60.0}, "power_stats": {"power_watts_samples": [47.38, 35.62, 35.62, 35.62, 35.62, 35.62, 47.57, 47.57, 47.57], "power_watts_avg": 40.91, "power_watts_peak": 47.57, "energy_joules_est": 36.74, "sample_count": 9, "duration_seconds": 0.898}, "timestamp": "2026-01-12T10:13:07.440383"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1544.371, "latencies_ms": [1544.371], "images_per_second": 0.648, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. red fire hydrant\n2. white manhole cover\n3. yellow pedestrian sign\n4. person standing\n5. person walking\n6. tree\n7. building\n8. sidewalk", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.3, "ram_available_mb": 109102.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.57, 47.57, 46.07, 46.07, 46.07, 46.07, 46.07, 47.77, 47.77, 47.77, 47.77, 50.06, 50.06, 50.06, 50.06, 50.06], "power_watts_avg": 47.93, "power_watts_peak": 50.06, "energy_joules_est": 74.04, "sample_count": 16, "duration_seconds": 1.545}, "timestamp": "2026-01-12T10:13:09.053493"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1391.272, "latencies_ms": [1391.272], "images_per_second": 0.719, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The fire hydrant is located on the left side of the sidewalk, with the pedestrian on the right side. The pedestrian is standing closer to the fire hydrant than the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13351.4, "ram_available_mb": 109154.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [34.09, 34.09, 34.09, 34.09, 34.09, 46.86, 46.86, 46.86, 46.86, 46.86, 46.96, 46.96, 46.96, 46.96], "power_watts_avg": 42.33, "power_watts_peak": 46.96, "energy_joules_est": 58.93, "sample_count": 14, "duration_seconds": 1.392}, "timestamp": "2026-01-12T10:13:10.466431"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 888.945, "latencies_ms": [888.945], "images_per_second": 1.125, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red fire hydrant is on the sidewalk, and a man is standing nearby.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13351.4, "ram_available_mb": 109154.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 13.0}, "power_stats": {"power_watts_samples": [46.96, 33.2, 33.2, 33.2, 33.2, 33.2, 47.93, 47.93, 47.93], "power_watts_avg": 39.64, "power_watts_peak": 47.93, "energy_joules_est": 35.25, "sample_count": 9, "duration_seconds": 0.889}, "timestamp": "2026-01-12T10:13:11.375408"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 828.489, "latencies_ms": [828.489], "images_per_second": 1.207, "prompt_tokens": 1110, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The fire hydrant is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_watts_samples": [47.93, 47.93, 50.44, 50.44, 50.44, 50.44, 50.44, 47.68, 47.68], "power_watts_avg": 49.27, "power_watts_peak": 50.44, "energy_joules_est": 40.83, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-12T10:13:12.286348"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1053.416, "latencies_ms": [1053.416], "images_per_second": 0.949, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image shows a small bathroom with a white toilet, a green trash can, and a white paper towel dispenser.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13372.6, "ram_available_mb": 109133.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.68, 47.68, 47.68, 51.04, 51.04, 51.04, 51.04, 51.04, 46.84, 46.84, 46.84], "power_watts_avg": 48.98, "power_watts_peak": 51.04, "energy_joules_est": 51.61, "sample_count": 11, "duration_seconds": 1.054}, "timestamp": "2026-01-12T10:13:13.398045"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2488.387, "latencies_ms": [2488.387], "images_per_second": 0.402, "prompt_tokens": 1113, "response_tokens_est": 78, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Toilet tank: 1\n3. Toilet seat: 1\n4. Toilet lid: 1\n5. Toilet tank lid: 1\n6. Toilet tank handle: 1\n7. Toilet tank flush button: 1\n8. Toilet tank flush button handle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13357.8, "ram_available_mb": 109148.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.84, 46.84, 43.17, 43.17, 43.17, 43.17, 43.17, 46.88, 46.88, 46.88, 46.88, 46.88, 48.07, 48.07, 48.07, 48.07, 48.07, 34.98, 34.98, 34.98, 34.98, 34.98, 35.0, 35.0, 35.0], "power_watts_avg": 42.57, "power_watts_peak": 48.07, "energy_joules_est": 105.93, "sample_count": 25, "duration_seconds": 2.489}, "timestamp": "2026-01-12T10:13:15.915252"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1598.705, "latencies_ms": [1598.705], "images_per_second": 0.626, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The toilet is positioned in the center of the image, with the person's feet visible in the foreground. The trash can is located to the left of the toilet, while the paper towel dispenser is situated to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.8, "ram_available_mb": 109148.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13435.9, "ram_available_mb": 109070.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.0, 32.26, 32.26, 32.26, 32.26, 32.26, 47.15, 47.15, 47.15, 47.15, 47.15, 49.93, 49.93, 49.93, 49.93, 49.93], "power_watts_avg": 42.6, "power_watts_peak": 49.93, "energy_joules_est": 68.13, "sample_count": 16, "duration_seconds": 1.599}, "timestamp": "2026-01-12T10:13:17.580613"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 904.932, "latencies_ms": [904.932], "images_per_second": 1.105, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A person is standing in a small bathroom with a white toilet and a green trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.9, "ram_available_mb": 109070.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 35.03, 35.03, 47.86, 47.86, 47.86, 47.86], "power_watts_avg": 40.74, "power_watts_peak": 47.86, "energy_joules_est": 36.88, "sample_count": 9, "duration_seconds": 0.905}, "timestamp": "2026-01-12T10:13:18.491811"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 958.594, "latencies_ms": [958.594], "images_per_second": 1.043, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The bathroom is well-lit with natural light, and the walls are painted in a light color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13397.0, "ram_available_mb": 109109.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [47.86, 46.95, 46.95, 46.95, 46.95, 46.95, 48.23, 48.23, 48.23, 48.23], "power_watts_avg": 47.55, "power_watts_peak": 48.23, "energy_joules_est": 45.6, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-12T10:13:19.504569"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1113.74, "latencies_ms": [1113.74], "images_per_second": 0.898, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A person wearing a red jacket and black pants is skiing down a snow-covered mountain with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13398.3, "ram_available_mb": 109108.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.23, 46.96, 46.96, 46.96, 46.96, 46.96, 47.27, 47.27, 47.27, 47.27, 47.27, 48.82], "power_watts_avg": 47.35, "power_watts_peak": 48.82, "energy_joules_est": 52.74, "sample_count": 12, "duration_seconds": 1.114}, "timestamp": "2026-01-12T10:13:20.719381"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1939.447, "latencies_ms": [1939.447], "images_per_second": 0.516, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skis: 2\n3. poles: 2\n4. backpack: 1\n5. helmet: 1\n6. jacket: 1\n7. pants: 1\n8. snow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.3, "ram_available_mb": 109108.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13453.7, "ram_available_mb": 109052.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.82, 48.82, 48.82, 48.82, 41.46, 41.46, 41.46, 41.46, 41.46, 46.21, 46.21, 46.21, 46.21, 46.21, 39.64, 39.64, 39.64, 39.64, 39.64, 34.8], "power_watts_avg": 43.33, "power_watts_peak": 48.82, "energy_joules_est": 84.05, "sample_count": 20, "duration_seconds": 1.94}, "timestamp": "2026-01-12T10:13:22.736127"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2060.665, "latencies_ms": [2060.665], "images_per_second": 0.485, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the mountain peak in the background. The skier is facing towards the mountain peak, indicating a sense of direction or focus on the destination. The skier is also positioned to the left of the image, with the mountain peak to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13449.7, "ram_available_mb": 109056.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13409.2, "ram_available_mb": 109097.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.8, 37.77, 37.77, 37.77, 37.77, 37.77, 45.66, 45.66, 45.66, 45.66, 45.66, 43.0, 43.0, 43.0, 43.0, 43.0, 34.93, 34.93, 34.93], "power_watts_avg": 40.06, "power_watts_peak": 45.66, "energy_joules_est": 82.6, "sample_count": 21, "duration_seconds": 2.062}, "timestamp": "2026-01-12T10:13:24.907470"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 883.756, "latencies_ms": [883.756], "images_per_second": 1.132, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is skiing on a snowy mountain with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.3, "ram_available_mb": 109105.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13421.4, "ram_available_mb": 109084.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.93, 31.41, 31.41, 31.41, 31.41, 31.41, 46.0, 46.0, 46.0], "power_watts_avg": 36.66, "power_watts_peak": 46.0, "energy_joules_est": 32.44, "sample_count": 9, "duration_seconds": 0.885}, "timestamp": "2026-01-12T10:13:25.867833"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1731.622, "latencies_ms": [1731.622], "images_per_second": 0.577, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a person wearing a red jacket and black pants, skiing down a snow-covered mountain under a clear blue sky. The snow is pristine white, and the person's skis are visible as they carve their path down the slope.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.4, "ram_available_mb": 109084.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13336.2, "ram_available_mb": 109170.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.0, 46.0, 50.7, 50.7, 50.7, 50.7, 50.7, 47.84, 47.84, 47.84, 47.84, 47.84, 46.64, 46.64, 46.64, 46.64, 46.64, 34.75], "power_watts_avg": 47.37, "power_watts_peak": 50.7, "energy_joules_est": 82.05, "sample_count": 18, "duration_seconds": 1.732}, "timestamp": "2026-01-12T10:13:27.684831"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1069.82, "latencies_ms": [1069.82], "images_per_second": 0.935, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a bib with the number 30 is skiing down a snowy mountain with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13336.2, "ram_available_mb": 109170.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13369.8, "ram_available_mb": 109136.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.75, 34.75, 34.75, 34.75, 42.51, 42.51, 42.51, 42.51, 42.51, 46.29, 46.29], "power_watts_avg": 40.37, "power_watts_peak": 46.29, "energy_joules_est": 43.21, "sample_count": 11, "duration_seconds": 1.07}, "timestamp": "2026-01-12T10:13:28.798867"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1996.287, "latencies_ms": [1996.287], "images_per_second": 0.501, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. skis: 2\n3. ski poles: 2\n4. bib: 1\n5. backpack: 1\n6. snow: 1\n7. trees: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.9, "ram_available_mb": 109144.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.7, "ram_available_mb": 109141.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.29, 46.29, 46.29, 42.57, 42.57, 42.57, 42.57, 42.57, 47.48, 47.48, 47.48, 47.48, 47.48, 43.53, 43.53, 43.53, 43.53, 43.53, 34.82, 34.82], "power_watts_avg": 43.82, "power_watts_peak": 47.48, "energy_joules_est": 87.5, "sample_count": 20, "duration_seconds": 1.997}, "timestamp": "2026-01-12T10:13:30.816573"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1282.262, "latencies_ms": [1282.262], "images_per_second": 0.78, "prompt_tokens": 1118, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The skier is in the foreground, with the trees and mountains in the background. The skier is to the left of the skier in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13360.8, "ram_available_mb": 109145.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.1, "ram_available_mb": 109144.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 34.89, 34.89, 34.89, 34.89, 34.89, 46.84, 46.84, 46.84, 46.84, 46.84, 46.81], "power_watts_avg": 40.39, "power_watts_peak": 46.84, "energy_joules_est": 51.83, "sample_count": 13, "duration_seconds": 1.283}, "timestamp": "2026-01-12T10:13:32.180981"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1074.59, "latencies_ms": [1074.59], "images_per_second": 0.931, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a bib with the number 30 is skiing down a snowy mountain with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13370.1, "ram_available_mb": 109136.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.81, 46.81, 46.81, 46.81, 43.86, 43.86, 43.86, 43.86, 43.86, 47.56, 47.56], "power_watts_avg": 45.6, "power_watts_peak": 47.56, "energy_joules_est": 49.03, "sample_count": 11, "duration_seconds": 1.075}, "timestamp": "2026-01-12T10:13:33.294629"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1630.551, "latencies_ms": [1630.551], "images_per_second": 0.613, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a man wearing a red and white jacket, black pants, and a black hat, skiing down a snowy mountain with trees in the background. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.2, "ram_available_mb": 109144.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.56, 47.56, 47.56, 42.64, 42.64, 42.64, 42.64, 42.64, 47.3, 47.3, 47.3, 47.3, 47.3, 43.38, 43.38, 43.38, 43.38], "power_watts_avg": 45.05, "power_watts_peak": 47.56, "energy_joules_est": 73.48, "sample_count": 17, "duration_seconds": 1.631}, "timestamp": "2026-01-12T10:13:35.013606"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1295.175, "latencies_ms": [1295.175], "images_per_second": 0.772, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A black and white photo of a computer desk with a keyboard, mouse, and monitor, with the word \"WORKPLACE\" in the top right corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.7, "ram_available_mb": 109150.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13365.7, "ram_available_mb": 109140.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.38, 32.48, 32.48, 32.48, 32.48, 32.48, 46.48, 46.48, 46.48, 46.48, 46.48, 47.96, 47.96], "power_watts_avg": 41.08, "power_watts_peak": 47.96, "energy_joules_est": 53.23, "sample_count": 13, "duration_seconds": 1.296}, "timestamp": "2026-01-12T10:13:36.329819"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1980.331, "latencies_ms": [1980.331], "images_per_second": 0.505, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. monitor: 1\n2. keyboard: 1\n3. mouse: 1\n4. desk: 1\n5. wall: 1\n6. computer: 1\n7. desk chair: 1\n8. desk surface: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.7, "ram_available_mb": 109140.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.96, 47.96, 47.96, 38.3, 38.3, 38.3, 38.3, 38.3, 47.94, 47.94, 47.94, 47.94, 47.94, 44.07, 44.07, 44.07, 44.07, 44.07, 34.71, 34.71], "power_watts_avg": 43.24, "power_watts_peak": 47.96, "energy_joules_est": 85.65, "sample_count": 20, "duration_seconds": 1.981}, "timestamp": "2026-01-12T10:13:38.343844"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2054.293, "latencies_ms": [2054.293], "images_per_second": 0.487, "prompt_tokens": 1118, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The keyboard is positioned in the foreground, close to the camera, while the computer monitor is in the background, farther away. The mouse is placed near the keyboard, and the computer monitor is positioned above the keyboard, with the text \"WORKPLACE\" appearing in the top right corner of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.3, "ram_available_mb": 109145.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 34.71, 37.59, 37.59, 37.59, 37.59, 37.59, 47.51, 47.51, 47.51, 47.51, 47.51, 45.46, 45.46, 45.46, 45.46, 34.91, 34.91, 34.91, 34.91], "power_watts_avg": 40.53, "power_watts_peak": 47.51, "energy_joules_est": 83.28, "sample_count": 21, "duration_seconds": 2.055}, "timestamp": "2026-01-12T10:13:40.459812"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 885.233, "latencies_ms": [885.233], "images_per_second": 1.13, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a computer desk with a keyboard and mouse on it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13357.4, "ram_available_mb": 109148.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13373.9, "ram_available_mb": 109132.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [34.91, 31.88, 31.88, 31.88, 31.88, 31.88, 45.82, 45.82, 45.82], "power_watts_avg": 36.86, "power_watts_peak": 45.82, "energy_joules_est": 32.67, "sample_count": 9, "duration_seconds": 0.886}, "timestamp": "2026-01-12T10:13:41.422022"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1411.579, "latencies_ms": [1411.579], "images_per_second": 0.708, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is in black and white, with a white desk and a white wall in the background. The lighting is bright and even, and the materials are smooth and matte.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13375.8, "ram_available_mb": 109130.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.82, 45.82, 48.41, 48.41, 48.41, 48.41, 48.41, 47.39, 47.39, 47.39, 47.39, 47.39, 48.49, 48.49, 48.49], "power_watts_avg": 47.74, "power_watts_peak": 48.49, "energy_joules_est": 67.41, "sample_count": 15, "duration_seconds": 1.412}, "timestamp": "2026-01-12T10:13:42.936146"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 960.361, "latencies_ms": [960.361], "images_per_second": 1.041, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A woman wearing a striped shirt is sitting at a table in a restaurant and eating a bagel.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13375.8, "ram_available_mb": 109130.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13454.6, "ram_available_mb": 109051.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [48.49, 48.49, 32.46, 32.46, 32.46, 32.46, 32.46, 46.09, 46.09, 46.09], "power_watts_avg": 39.76, "power_watts_peak": 48.49, "energy_joules_est": 38.21, "sample_count": 10, "duration_seconds": 0.961}, "timestamp": "2026-01-12T10:13:43.949091"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1974.649, "latencies_ms": [1974.649], "images_per_second": 0.506, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. bagel: 1\n3. coffee cup: 1\n4. box: 1\n5. sandwich: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13454.6, "ram_available_mb": 109051.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13416.2, "ram_available_mb": 109090.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.09, 46.09, 47.3, 47.3, 47.3, 47.3, 47.37, 47.37, 47.37, 47.37, 47.37, 49.24, 49.24, 49.24, 49.24, 49.24, 34.77, 34.77, 34.77, 34.77], "power_watts_avg": 45.17, "power_watts_peak": 49.24, "energy_joules_est": 89.23, "sample_count": 20, "duration_seconds": 1.975}, "timestamp": "2026-01-12T10:13:45.968552"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1331.17, "latencies_ms": [1331.17], "images_per_second": 0.751, "prompt_tokens": 1118, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The woman is in the foreground, holding a bagel, while the coffee cup is in the background. The bagel is closer to the camera than the coffee cup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.2, "ram_available_mb": 109090.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.4, "ram_available_mb": 109095.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.77, 32.32, 32.32, 32.32, 32.32, 32.32, 46.41, 46.41, 46.41, 46.41, 46.41, 48.86, 48.86, 48.86], "power_watts_avg": 41.07, "power_watts_peak": 48.86, "energy_joules_est": 54.7, "sample_count": 14, "duration_seconds": 1.332}, "timestamp": "2026-01-12T10:13:47.429177"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 904.471, "latencies_ms": [904.471], "images_per_second": 1.106, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman is sitting at a table in a restaurant, holding a bagel and smiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.5, "ram_available_mb": 109099.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13406.7, "ram_available_mb": 109099.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 20.0}, "power_stats": {"power_watts_samples": [48.86, 48.86, 33.5, 33.5, 33.5, 33.5, 33.5, 46.84, 46.84], "power_watts_avg": 39.88, "power_watts_peak": 48.86, "energy_joules_est": 36.1, "sample_count": 9, "duration_seconds": 0.905}, "timestamp": "2026-01-12T10:13:48.343268"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1701.935, "latencies_ms": [1701.935], "images_per_second": 0.588, "prompt_tokens": 1110, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image has a warm color tone, with the person's shirt being a deep purple and the coffee cup being white. The lighting is natural, coming from the window, and the background is blurred, indicating that the person is in motion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13402.8, "ram_available_mb": 109103.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13313.1, "ram_available_mb": 109193.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.84, 46.84, 46.84, 52.23, 52.23, 52.23, 52.23, 52.23, 48.21, 48.21, 48.21, 48.21, 48.21, 44.68, 44.68, 44.68, 44.68], "power_watts_avg": 48.32, "power_watts_peak": 52.23, "energy_joules_est": 82.25, "sample_count": 17, "duration_seconds": 1.702}, "timestamp": "2026-01-12T10:13:50.059701"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 905.902, "latencies_ms": [905.902], "images_per_second": 1.104, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two zebras with black and white stripes are grazing on green grass in a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.1, "ram_available_mb": 109193.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13336.7, "ram_available_mb": 109169.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [34.76, 34.76, 34.76, 34.76, 34.76, 47.95, 47.95, 47.95, 47.95, 47.95], "power_watts_avg": 41.36, "power_watts_peak": 47.95, "energy_joules_est": 37.49, "sample_count": 10, "duration_seconds": 0.907}, "timestamp": "2026-01-12T10:13:51.072803"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 537.876, "latencies_ms": [537.876], "images_per_second": 1.859, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.0, "ram_available_mb": 109171.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13342.9, "ram_available_mb": 109163.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.54, 46.54, 46.54, 46.54, 46.54, 46.08], "power_watts_avg": 46.46, "power_watts_peak": 46.54, "energy_joules_est": 25.01, "sample_count": 6, "duration_seconds": 0.538}, "timestamp": "2026-01-12T10:13:51.681643"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1572.32, "latencies_ms": [1572.32], "images_per_second": 0.636, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with one zebra on the left and the other on the right. The zebras are eating grass in the foreground, with the grass extending into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.9, "ram_available_mb": 109163.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13327.6, "ram_available_mb": 109178.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.08, 46.08, 46.08, 46.08, 56.45, 56.45, 56.45, 56.45, 56.45, 47.03, 47.03, 47.03, 47.03, 47.03, 37.63, 37.63], "power_watts_avg": 48.56, "power_watts_peak": 56.45, "energy_joules_est": 76.37, "sample_count": 16, "duration_seconds": 1.573}, "timestamp": "2026-01-12T10:13:53.295805"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 808.453, "latencies_ms": [808.453], "images_per_second": 1.237, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two zebras are grazing on green grass in a fenced enclosure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13319.7, "ram_available_mb": 109186.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [37.63, 37.63, 37.63, 39.74, 39.74, 39.74, 39.74, 39.74, 47.49], "power_watts_avg": 39.9, "power_watts_peak": 47.49, "energy_joules_est": 32.26, "sample_count": 9, "duration_seconds": 0.809}, "timestamp": "2026-01-12T10:13:54.205490"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1687.606, "latencies_ms": [1687.606], "images_per_second": 0.593, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features two zebras with black and white stripes grazing on green grass. The lighting is natural and bright, suggesting it is daytime. The zebras are standing close to each other, indicating a sense of companionship or social interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.7, "ram_available_mb": 109163.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.49, 47.49, 47.49, 47.49, 50.32, 50.32, 50.32, 50.32, 50.32, 46.3, 46.3, 46.3, 46.3, 46.3, 38.5, 38.5, 38.5], "power_watts_avg": 46.39, "power_watts_peak": 50.32, "energy_joules_est": 78.3, "sample_count": 17, "duration_seconds": 1.688}, "timestamp": "2026-01-12T10:13:55.923244"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1021.749, "latencies_ms": [1021.749], "images_per_second": 0.979, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two young men are riding a green bicycle on a busy street with a Coca Cola store in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13333.6, "ram_available_mb": 109172.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.5, 38.5, 34.01, 34.01, 34.01, 34.01, 34.01, 47.2, 47.2, 47.2, 47.2], "power_watts_avg": 39.63, "power_watts_peak": 47.2, "energy_joules_est": 40.51, "sample_count": 11, "duration_seconds": 1.022}, "timestamp": "2026-01-12T10:13:57.035067"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1936.623, "latencies_ms": [1936.623], "images_per_second": 0.516, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bicycle: 2\n2. person: 2\n3. motorcycle: 2\n4. scooter: 1\n5. store: 1\n6. plant: 1\n7. sign: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.6, "ram_available_mb": 109172.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13333.6, "ram_available_mb": 109172.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.2, 46.96, 46.96, 46.96, 46.96, 46.96, 46.34, 46.34, 46.34, 46.34, 46.34, 48.65, 48.65, 48.65, 48.65, 48.65, 34.98, 34.98, 34.98, 34.98], "power_watts_avg": 44.84, "power_watts_peak": 48.65, "energy_joules_est": 86.86, "sample_count": 20, "duration_seconds": 1.937}, "timestamp": "2026-01-12T10:13:59.054119"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1566.384, "latencies_ms": [1566.384], "images_per_second": 0.638, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The two men are positioned on the left side of the image, with the bicycle in the foreground. The background features a building with a Coca Cola advertisement, and a few other people are visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.6, "ram_available_mb": 109176.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.2, "ram_available_mb": 109161.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.51, 33.51, 33.51, 33.51, 33.51, 45.66, 45.66, 45.66, 45.66, 45.66, 47.26, 47.26, 47.26, 47.26, 47.26, 34.84], "power_watts_avg": 41.69, "power_watts_peak": 47.26, "energy_joules_est": 65.33, "sample_count": 16, "duration_seconds": 1.567}, "timestamp": "2026-01-12T10:14:00.720674"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 799.019, "latencies_ms": [799.019], "images_per_second": 1.252, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two young men are riding a bicycle down a busy street in Vietnam.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.4, "ram_available_mb": 109168.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.6, "ram_available_mb": 109160.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.84, 34.84, 43.45, 43.45, 43.45, 43.45], "power_watts_avg": 39.14, "power_watts_peak": 43.45, "energy_joules_est": 31.3, "sample_count": 8, "duration_seconds": 0.8}, "timestamp": "2026-01-12T10:14:01.532351"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 947.164, "latencies_ms": [947.164], "images_per_second": 1.056, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is taken during the day with natural light, and the colors are vibrant and bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.6, "ram_available_mb": 109160.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.2, "ram_available_mb": 109162.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [43.45, 46.63, 46.63, 46.63, 46.63, 46.63, 52.02, 52.02, 52.02, 52.02], "power_watts_avg": 48.47, "power_watts_peak": 52.02, "energy_joules_est": 45.94, "sample_count": 10, "duration_seconds": 0.948}, "timestamp": "2026-01-12T10:14:02.544182"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2093.288, "latencies_ms": [2093.288], "images_per_second": 0.478, "prompt_tokens": 1099, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a tennis match, with two players in white attire actively engaged on a grass court, while a referee and a ball boy are positioned nearby, ready to assist. The spectators, seated in the stands, are attentively watching the unfolding action, adding to the atmosphere of anticipation and excitement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.2, "ram_available_mb": 109166.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13339.2, "ram_available_mb": 109167.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [52.02, 46.54, 46.54, 46.54, 46.54, 46.54, 46.91, 46.91, 46.91, 46.91, 46.91, 48.53, 48.53, 48.53, 48.53, 34.89, 34.89, 34.89, 34.89, 34.89, 34.88], "power_watts_avg": 43.94, "power_watts_peak": 52.02, "energy_joules_est": 92.0, "sample_count": 21, "duration_seconds": 2.094}, "timestamp": "2026-01-12T10:14:04.662902"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2176.399, "latencies_ms": [2176.399], "images_per_second": 0.459, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. Tennis racket: 1\n2. Tennis ball: 1\n3. Player: 2\n4. Chair: 1\n5. Ball boy: 1\n6. Umpire: 1\n7. Spectator: 1\n8. Seat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.3, "ram_available_mb": 109175.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 42.95, 42.95, 42.95, 42.95, 42.95, 46.94, 46.94, 46.94, 46.94, 46.94, 38.66, 38.66, 38.66, 38.66, 38.66, 34.78, 34.78, 34.78], "power_watts_avg": 40.3, "power_watts_peak": 46.94, "energy_joules_est": 87.75, "sample_count": 22, "duration_seconds": 2.177}, "timestamp": "2026-01-12T10:14:06.934304"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1437.382, "latencies_ms": [1437.382], "images_per_second": 0.696, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, while the ball is located in the center. The audience is situated in the background, with some spectators closer to the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13355.0, "ram_available_mb": 109151.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.78, 31.8, 31.8, 31.8, 31.8, 31.8, 46.54, 46.54, 46.54, 46.54, 46.54, 49.69, 49.69, 49.69, 49.69], "power_watts_avg": 41.68, "power_watts_peak": 49.69, "energy_joules_est": 59.95, "sample_count": 15, "duration_seconds": 1.438}, "timestamp": "2026-01-12T10:14:08.500095"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 875.853, "latencies_ms": [875.853], "images_per_second": 1.142, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A tennis match is taking place in a large stadium with a crowd of spectators watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.1, "ram_available_mb": 109159.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.7, "ram_available_mb": 109148.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [49.69, 32.37, 32.37, 32.37, 32.37, 32.37, 46.57, 46.57, 46.57], "power_watts_avg": 39.03, "power_watts_peak": 49.69, "energy_joules_est": 34.21, "sample_count": 9, "duration_seconds": 0.876}, "timestamp": "2026-01-12T10:14:09.412889"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1660.577, "latencies_ms": [1660.577], "images_per_second": 0.602, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken during a daytime tennis match, with the players dressed in white and the court's green grass contrasting with the spectators' attire. The lighting is natural, coming from the sun, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.8, "ram_available_mb": 109156.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.2, "ram_available_mb": 109161.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.57, 46.57, 49.63, 49.63, 49.63, 49.63, 49.63, 47.54, 47.54, 47.54, 47.54, 47.54, 48.21, 48.21, 48.21, 48.21, 48.21], "power_watts_avg": 48.24, "power_watts_peak": 49.63, "energy_joules_est": 80.13, "sample_count": 17, "duration_seconds": 1.661}, "timestamp": "2026-01-12T10:14:11.130863"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1405.305, "latencies_ms": [1405.305], "images_per_second": 0.712, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a brown couch, a television on a wooden stand, and a variety of plants on shelves and the floor, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 35.01, 35.01, 35.01, 47.28, 47.28, 47.28, 47.28, 47.28, 47.26, 47.26, 47.26, 47.26], "power_watts_avg": 42.89, "power_watts_peak": 47.28, "energy_joules_est": 60.3, "sample_count": 14, "duration_seconds": 1.406}, "timestamp": "2026-01-12T10:14:12.549034"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1699.122, "latencies_ms": [1699.122], "images_per_second": 0.589, "prompt_tokens": 1113, "response_tokens_est": 48, "n_tiles": 1, "output_text": " television: 1\ncouch: 1\ntelevision stand: 1\ntelevision: 1\ncouch: 1\ntelevision stand: 1\ntelevision: 1\ncouch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.26, 34.74, 34.74, 34.74, 34.74, 34.74, 48.0, 48.0, 48.0, 48.0, 48.37, 48.37, 48.37, 48.37, 48.37, 35.1, 35.1], "power_watts_avg": 42.65, "power_watts_peak": 48.37, "energy_joules_est": 72.48, "sample_count": 17, "duration_seconds": 1.699}, "timestamp": "2026-01-12T10:14:14.264796"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1222.944, "latencies_ms": [1222.944], "images_per_second": 0.818, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The television is on the left side of the room, the couch is on the right side, and the plants are in the middle of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.3, "ram_available_mb": 109164.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [35.1, 35.1, 35.1, 41.66, 41.66, 41.66, 41.66, 41.66, 47.79, 47.79, 47.79, 47.79, 47.79], "power_watts_avg": 42.5, "power_watts_peak": 47.79, "energy_joules_est": 51.99, "sample_count": 13, "duration_seconds": 1.223}, "timestamp": "2026-01-12T10:14:15.574397"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 863.016, "latencies_ms": [863.016], "images_per_second": 1.159, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A living room with a brown couch, a TV, and a TV stand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.3, "ram_available_mb": 109164.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [40.83, 40.83, 40.83, 40.83, 40.83, 46.82, 46.82, 46.82, 46.82], "power_watts_avg": 43.49, "power_watts_peak": 46.82, "energy_joules_est": 37.55, "sample_count": 9, "duration_seconds": 0.863}, "timestamp": "2026-01-12T10:14:16.483741"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 985.93, "latencies_ms": [985.93], "images_per_second": 1.014, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.1, "ram_available_mb": 109162.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 3.0}, "power_stats": {"power_watts_samples": [46.82, 45.57, 45.57, 45.57, 45.57, 45.57, 47.02, 47.02, 47.02, 47.02], "power_watts_avg": 46.27, "power_watts_peak": 47.02, "energy_joules_est": 45.63, "sample_count": 10, "duration_seconds": 0.986}, "timestamp": "2026-01-12T10:14:17.492561"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1096.971, "latencies_ms": [1096.971], "images_per_second": 0.912, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A woman in a red dress and white visor is holding a tennis racket and smiling on a red clay tennis court.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13344.1, "ram_available_mb": 109162.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13336.5, "ram_available_mb": 109169.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.02, 48.14, 48.14, 48.14, 48.14, 48.14, 47.66, 47.66, 47.66, 47.66, 47.66], "power_watts_avg": 47.82, "power_watts_peak": 48.14, "energy_joules_est": 52.49, "sample_count": 11, "duration_seconds": 1.098}, "timestamp": "2026-01-12T10:14:18.600314"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2102.017, "latencies_ms": [2102.017], "images_per_second": 0.476, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. woman: 1\n2. tennis racket: 1\n3. visor: 1\n4. shorts: 1\n5. tennis shoes: 1\n6. tennis ball: 1\n7. tennis court: 1\n8. green fence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.5, "ram_available_mb": 109169.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13361.1, "ram_available_mb": 109145.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.38, 49.38, 49.38, 49.38, 49.38, 48.34, 48.34, 48.34, 48.34, 48.34, 47.99, 47.99, 47.99, 47.99, 47.99, 34.67, 34.67, 34.67, 34.67, 34.67, 34.77], "power_watts_avg": 44.6, "power_watts_peak": 49.38, "energy_joules_est": 93.79, "sample_count": 21, "duration_seconds": 2.103}, "timestamp": "2026-01-12T10:14:20.720096"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1682.907, "latencies_ms": [1682.907], "images_per_second": 0.594, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the green fence and the green wall in the background. The player is holding a tennis racket in her right hand, and her left hand is holding a tennis ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.1, "ram_available_mb": 109145.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 40.45, 40.45, 40.45, 40.45, 40.45, 46.79, 46.79, 46.79, 46.79, 46.79, 41.38, 41.38, 41.38, 41.38], "power_watts_avg": 41.53, "power_watts_peak": 46.79, "energy_joules_est": 69.91, "sample_count": 17, "duration_seconds": 1.683}, "timestamp": "2026-01-12T10:14:22.483651"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1022.468, "latencies_ms": [1022.468], "images_per_second": 0.978, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A female tennis player is on a clay court, holding a tennis racket and wearing a white visor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13400.8, "ram_available_mb": 109105.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [41.38, 33.03, 33.03, 33.03, 33.03, 33.03, 47.68, 47.68, 47.68, 47.68, 47.68], "power_watts_avg": 40.45, "power_watts_peak": 47.68, "energy_joules_est": 41.37, "sample_count": 11, "duration_seconds": 1.023}, "timestamp": "2026-01-12T10:14:23.595538"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1572.36, "latencies_ms": [1572.36], "images_per_second": 0.636, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a woman in a vibrant red dress and white visor, holding a black and red tennis racket, on a clay tennis court. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.9, "ram_available_mb": 109113.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13393.0, "ram_available_mb": 109113.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [48.67, 48.67, 48.67, 48.67, 48.67, 46.31, 46.31, 46.31, 46.31, 46.31, 46.83, 46.83, 46.83, 46.83, 46.83, 34.88], "power_watts_avg": 46.49, "power_watts_peak": 48.67, "energy_joules_est": 73.13, "sample_count": 16, "duration_seconds": 1.573}, "timestamp": "2026-01-12T10:14:25.208818"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2947.462, "latencies_ms": [2947.462], "images_per_second": 0.339, "prompt_tokens": 1099, "response_tokens_est": 95, "n_tiles": 1, "output_text": " The image captures a bustling city street lined with a variety of buildings, including a prominent red brick building with a sign that reads \"OmniFest\" and a green awning with the word \"FARMER\" on it. The street is filled with cars and people, and there are several signs and advertisements visible, including a large billboard for \"OmniFest\" and a red awning with the word \"FARMER\" on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13372.1, "ram_available_mb": 109134.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 43.4, 43.4, 43.4, 43.4, 43.4, 47.04, 47.04, 47.04, 47.04, 47.04, 39.5, 39.5, 39.5, 39.5, 39.5, 34.93, 34.93, 34.93, 34.93, 34.93, 34.87, 34.87, 34.87, 34.87, 34.87, 34.87], "power_watts_avg": 39.1, "power_watts_peak": 47.04, "energy_joules_est": 115.27, "sample_count": 30, "duration_seconds": 2.948}, "timestamp": "2026-01-12T10:14:28.233126"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1942.694, "latencies_ms": [1942.694], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. car: 3\n2. building: 10\n3. street: 1\n4. sign: 1\n5. person: 1\n6. airplane: 1\n7. store: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.1, "ram_available_mb": 109134.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 38.46, 38.46, 38.46, 38.46, 38.46, 45.7, 45.7, 45.7, 45.7, 45.7, 42.05, 42.05, 42.05, 42.05, 42.05, 34.9, 34.9], "power_watts_avg": 40.28, "power_watts_peak": 45.7, "energy_joules_est": 78.25, "sample_count": 20, "duration_seconds": 1.943}, "timestamp": "2026-01-12T10:14:30.298143"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2853.368, "latencies_ms": [2853.368], "images_per_second": 0.35, "prompt_tokens": 1117, "response_tokens_est": 91, "n_tiles": 1, "output_text": " The main objects in the image are positioned in the foreground, with the street and cars in the foreground, and the buildings in the background. The buildings are arranged in a row, with the nearest building being the one with the \"OmniFest\" sign, and the farthest building being the one with the \"For Lease\" sign. The cars are parked along the side of the street, with some in the foreground and others in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.2, "ram_available_mb": 109149.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13356.9, "ram_available_mb": 109149.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 35.72, 35.72, 35.72, 35.72, 35.72, 45.6, 45.6, 45.6, 45.6, 45.6, 45.69, 45.69, 45.69, 45.69, 45.69, 34.83, 34.83, 34.83, 34.83, 34.83, 34.74, 34.74, 34.74, 34.74, 34.62, 34.62], "power_watts_avg": 38.69, "power_watts_peak": 45.69, "energy_joules_est": 110.43, "sample_count": 29, "duration_seconds": 2.854}, "timestamp": "2026-01-12T10:14:33.276616"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1493.598, "latencies_ms": [1493.598], "images_per_second": 0.67, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a bustling city street lined with various shops and restaurants. Cars are parked along the side of the road, and people can be seen walking on the sidewalk, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13356.9, "ram_available_mb": 109149.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13414.8, "ram_available_mb": 109091.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.62, 34.62, 34.62, 36.25, 36.25, 36.25, 36.25, 36.25, 45.69, 45.69, 45.69, 45.69, 45.69, 44.06, 44.06], "power_watts_avg": 40.11, "power_watts_peak": 45.69, "energy_joules_est": 59.95, "sample_count": 15, "duration_seconds": 1.495}, "timestamp": "2026-01-12T10:14:34.844470"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1937.285, "latencies_ms": [1937.285], "images_per_second": 0.516, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a vibrant city street bathed in the soft glow of daylight, with the sky painted in a light blue canvas. The buildings, constructed from brick and wood, stand tall and proud, their red and green aisles adding a splash of color to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13414.8, "ram_available_mb": 109091.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.5, "ram_available_mb": 109171.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.06, 44.06, 44.06, 37.81, 37.81, 37.81, 37.81, 37.81, 47.54, 47.54, 47.54, 47.54, 47.54, 44.76, 44.76, 44.76, 44.76, 44.76, 34.86, 34.86], "power_watts_avg": 42.62, "power_watts_peak": 47.54, "energy_joules_est": 82.6, "sample_count": 20, "duration_seconds": 1.938}, "timestamp": "2026-01-12T10:14:36.863719"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1040.676, "latencies_ms": [1040.676], "images_per_second": 0.961, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A female tennis player in a pink outfit is playing on a blue court with a yellow tennis ball in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.5, "ram_available_mb": 109171.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13421.6, "ram_available_mb": 109084.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 32.61, 32.61, 32.61, 32.61, 32.61, 45.61, 45.61, 45.61, 45.61], "power_watts_avg": 37.74, "power_watts_peak": 45.61, "energy_joules_est": 39.33, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-12T10:14:38.028818"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2130.6, "latencies_ms": [2130.6], "images_per_second": 0.469, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. tennis racket: 1\n2. tennis ball: 1\n3. woman: 1\n4. tennis court: 1\n5. white line: 1\n6. blue surface: 1\n7. green surface: 1\n8. white shoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.6, "ram_available_mb": 109084.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.5, "ram_available_mb": 109093.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.61, 46.69, 46.69, 46.69, 46.69, 46.69, 46.65, 46.65, 46.65, 46.65, 46.65, 48.66, 48.66, 48.66, 48.66, 48.66, 34.76, 34.76, 34.76, 34.76, 34.76, 34.71], "power_watts_avg": 43.82, "power_watts_peak": 48.66, "energy_joules_est": 93.39, "sample_count": 22, "duration_seconds": 2.131}, "timestamp": "2026-01-12T10:14:40.249605"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1441.238, "latencies_ms": [1441.238], "images_per_second": 0.694, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball located in the center. The player is in the foreground, while the tennis court extends into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.6, "ram_available_mb": 109101.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13398.6, "ram_available_mb": 109107.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.71, 34.71, 34.71, 34.71, 40.65, 40.65, 40.65, 40.65, 40.65, 46.4, 46.4, 46.4, 46.4, 46.4, 41.29], "power_watts_avg": 41.03, "power_watts_peak": 46.4, "energy_joules_est": 59.15, "sample_count": 15, "duration_seconds": 1.442}, "timestamp": "2026-01-12T10:14:41.765312"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 835.772, "latencies_ms": [835.772], "images_per_second": 1.196, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A female tennis player is playing on a blue court with a green background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.8, "ram_available_mb": 109115.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13390.6, "ram_available_mb": 109115.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [41.29, 41.29, 41.29, 40.41, 40.41, 40.41, 40.41, 40.41, 46.45], "power_watts_avg": 41.37, "power_watts_peak": 46.45, "energy_joules_est": 34.6, "sample_count": 9, "duration_seconds": 0.836}, "timestamp": "2026-01-12T10:14:42.677418"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 996.002, "latencies_ms": [996.002], "images_per_second": 1.004, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The tennis player is wearing a red outfit and white shoes, and the court is blue with white lines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.6, "ram_available_mb": 109115.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13378.2, "ram_available_mb": 109128.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.45, 46.45, 46.45, 46.45, 50.75, 50.75, 50.75, 50.75, 50.75, 46.68], "power_watts_avg": 48.62, "power_watts_peak": 50.75, "energy_joules_est": 48.46, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-12T10:14:43.687559"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1104.572, "latencies_ms": [1104.572], "images_per_second": 0.905, "prompt_tokens": 1432, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue and orange train with a white front is traveling on a track through a lush green forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.5, "ram_available_mb": 109126.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13372.5, "ram_available_mb": 109133.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.68, 46.68, 46.68, 46.68, 46.15, 46.15, 46.15, 46.15, 46.15, 51.61, 51.61], "power_watts_avg": 47.34, "power_watts_peak": 51.61, "energy_joules_est": 52.32, "sample_count": 11, "duration_seconds": 1.105}, "timestamp": "2026-01-12T10:14:44.802171"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1477.741, "latencies_ms": [1477.741], "images_per_second": 0.677, "prompt_tokens": 1446, "response_tokens_est": 34, "n_tiles": 1, "output_text": " train: 1, tracks: 1, bushes: 1, trees: 1, windows: 1, doors: 1, front: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.5, "ram_available_mb": 109133.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13437.6, "ram_available_mb": 109068.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [51.61, 51.61, 51.61, 48.37, 48.37, 48.37, 48.37, 48.37, 52.33, 52.33, 52.33, 52.33, 52.33, 48.18, 48.18], "power_watts_avg": 50.31, "power_watts_peak": 52.33, "energy_joules_est": 74.39, "sample_count": 15, "duration_seconds": 1.478}, "timestamp": "2026-01-12T10:14:46.317761"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1476.239, "latencies_ms": [1476.239], "images_per_second": 0.677, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, moving towards the right. The train is in the foreground, with the tracks and surrounding vegetation in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13433.7, "ram_available_mb": 109072.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13429.5, "ram_available_mb": 109076.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.18, 48.18, 48.18, 37.71, 37.71, 37.71, 37.71, 37.71, 51.3, 51.3, 51.3, 51.3, 51.3, 49.59, 49.59], "power_watts_avg": 45.92, "power_watts_peak": 51.3, "energy_joules_est": 67.81, "sample_count": 15, "duration_seconds": 1.477}, "timestamp": "2026-01-12T10:14:47.833259"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 962.603, "latencies_ms": [962.603], "images_per_second": 1.039, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A blue and orange train is traveling on a track through a wooded area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13429.5, "ram_available_mb": 109076.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13422.7, "ram_available_mb": 109083.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [49.59, 49.59, 49.59, 37.36, 37.36, 37.36, 37.36, 37.36, 51.45, 51.45], "power_watts_avg": 43.85, "power_watts_peak": 51.45, "energy_joules_est": 42.23, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-12T10:14:48.845164"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 899.705, "latencies_ms": [899.705], "images_per_second": 1.111, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The train is blue and orange, and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13414.8, "ram_available_mb": 109091.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13435.5, "ram_available_mb": 109070.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.45, 51.45, 51.45, 51.75, 51.75, 51.75, 51.75, 51.75, 51.71], "power_watts_avg": 51.65, "power_watts_peak": 51.75, "energy_joules_est": 46.5, "sample_count": 9, "duration_seconds": 0.9}, "timestamp": "2026-01-12T10:14:49.756851"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 821.367, "latencies_ms": [821.367], "images_per_second": 1.217, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two cats are sleeping on a pink blanket with remote controls on either side.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13435.5, "ram_available_mb": 109070.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13417.4, "ram_available_mb": 109088.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.71, 51.71, 51.71, 51.71, 57.55, 57.55, 57.55, 57.55, 57.55], "power_watts_avg": 54.95, "power_watts_peak": 57.55, "energy_joules_est": 45.18, "sample_count": 9, "duration_seconds": 0.822}, "timestamp": "2026-01-12T10:14:50.671135"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1961.069, "latencies_ms": [1961.069], "images_per_second": 0.51, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. cat: 2\n2. remote control: 2\n3. pink blanket: 1\n4. tail: 1\n5. paw: 1\n6. head: 1\n7. body: 1\n8. fur: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.4, "ram_available_mb": 109088.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.2, "ram_available_mb": 109119.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.06, 48.06, 48.06, 48.06, 50.35, 50.35, 50.35, 50.35, 50.35, 46.5, 46.5, 46.5, 46.5, 46.5, 37.89, 37.89, 37.89, 37.89, 37.89, 35.01], "power_watts_avg": 45.05, "power_watts_peak": 50.35, "energy_joules_est": 88.36, "sample_count": 20, "duration_seconds": 1.962}, "timestamp": "2026-01-12T10:14:52.691545"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1967.626, "latencies_ms": [1967.626], "images_per_second": 0.508, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The two cats are lying on a pink blanket, with the cat on the left being closer to the camera and the cat on the right being farther away. The remote control is placed near the cat on the left, while the other remote control is located closer to the cat on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.3, "ram_available_mb": 109127.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 35.01, 35.01, 41.11, 41.11, 41.11, 41.11, 41.11, 46.09, 46.09, 46.09, 46.09, 46.09, 39.96, 39.96, 39.96, 39.96, 39.96, 34.81], "power_watts_avg": 40.53, "power_watts_peak": 46.09, "energy_joules_est": 79.79, "sample_count": 20, "duration_seconds": 1.969}, "timestamp": "2026-01-12T10:14:54.759759"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 818.387, "latencies_ms": [818.387], "images_per_second": 1.222, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two cats are sleeping on a pink blanket, with a remote control nearby.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13461.7, "ram_available_mb": 109044.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.81, 38.47, 38.47, 38.47, 38.47, 38.47, 46.59], "power_watts_avg": 38.15, "power_watts_peak": 46.59, "energy_joules_est": 31.24, "sample_count": 9, "duration_seconds": 0.819}, "timestamp": "2026-01-12T10:14:55.718670"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1208.352, "latencies_ms": [1208.352], "images_per_second": 0.828, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image features two cats sleeping on a pink blanket, with a remote control nearby. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13461.7, "ram_available_mb": 109044.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13444.2, "ram_available_mb": 109062.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.59, 46.59, 46.59, 46.59, 50.77, 50.77, 50.77, 50.77, 50.77, 46.56, 46.56, 46.56, 46.56], "power_watts_avg": 48.19, "power_watts_peak": 50.77, "energy_joules_est": 58.27, "sample_count": 13, "duration_seconds": 1.209}, "timestamp": "2026-01-12T10:14:57.030834"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1320.814, "latencies_ms": [1320.814], "images_per_second": 0.757, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A man in a black wetsuit is surfing on a river with a blue surfboard, while another person is standing on the riverbank holding a blue surfboard.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13444.2, "ram_available_mb": 109062.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13420.3, "ram_available_mb": 109086.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [46.56, 37.57, 37.57, 37.57, 37.57, 37.57, 46.3, 46.3, 46.3, 46.3, 46.3, 48.59, 48.59, 48.59], "power_watts_avg": 43.69, "power_watts_peak": 48.59, "energy_joules_est": 57.72, "sample_count": 14, "duration_seconds": 1.321}, "timestamp": "2026-01-12T10:14:58.447489"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1973.413, "latencies_ms": [1973.413], "images_per_second": 0.507, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. River: 1\n4. Bridge: 1\n5. Tree: 1\n6. Bench: 1\n7. Wall: 1\n8. Bench: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13420.3, "ram_available_mb": 109086.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13469.5, "ram_available_mb": 109036.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.59, 48.59, 33.33, 33.33, 33.33, 33.33, 33.33, 46.35, 46.35, 46.35, 46.35, 46.35, 48.29, 48.29, 48.29, 48.29, 48.29, 34.95, 34.95, 34.95], "power_watts_avg": 42.1, "power_watts_peak": 48.59, "energy_joules_est": 83.09, "sample_count": 20, "duration_seconds": 1.974}, "timestamp": "2026-01-12T10:15:00.461821"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1391.869, "latencies_ms": [1391.869], "images_per_second": 0.718, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave in the river, while the bridge is located in the background. The surfer is closer to the camera than the bridge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13469.5, "ram_available_mb": 109036.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13503.2, "ram_available_mb": 109003.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.95, 32.17, 32.17, 32.17, 32.17, 32.17, 46.58, 46.58, 46.58, 46.58, 46.58, 49.73, 49.73, 49.73], "power_watts_avg": 41.28, "power_watts_peak": 49.73, "energy_joules_est": 57.48, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-12T10:15:01.925067"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1166.257, "latencies_ms": [1166.257], "images_per_second": 0.857, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a wetsuit is surfing on a river with a blue surfboard. The river is surrounded by trees and a bridge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13503.2, "ram_available_mb": 109003.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13435.8, "ram_available_mb": 109070.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.73, 49.73, 35.93, 35.93, 35.93, 35.93, 35.93, 47.83, 47.83, 47.83, 47.83, 47.83], "power_watts_avg": 43.19, "power_watts_peak": 49.73, "energy_joules_est": 50.39, "sample_count": 12, "duration_seconds": 1.167}, "timestamp": "2026-01-12T10:15:03.137846"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1877.163, "latencies_ms": [1877.163], "images_per_second": 0.533, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a surfer in a black wetsuit riding a wave in a river, with a blue surfboard visible in the background. The lighting is natural, and the water appears to be a muddy brown color, suggesting it might be a river or a lake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.8, "ram_available_mb": 109070.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13453.0, "ram_available_mb": 109053.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 47.23, 47.23, 47.33, 47.33, 47.33, 47.33, 47.33, 47.58, 47.58, 47.58, 47.58, 47.58, 34.91, 34.91, 34.91, 34.91], "power_watts_avg": 44.76, "power_watts_peak": 47.58, "energy_joules_est": 84.04, "sample_count": 19, "duration_seconds": 1.878}, "timestamp": "2026-01-12T10:15:05.053044"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1067.944, "latencies_ms": [1067.944], "images_per_second": 0.936, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman and a child are flying a colorful kite in a park with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13454.3, "ram_available_mb": 109052.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13442.5, "ram_available_mb": 109063.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [33.87, 33.87, 33.87, 33.87, 33.87, 46.0, 46.0, 46.0, 46.0, 46.0, 51.64], "power_watts_avg": 41.0, "power_watts_peak": 51.64, "energy_joules_est": 43.81, "sample_count": 11, "duration_seconds": 1.069}, "timestamp": "2026-01-12T10:15:06.217600"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2178.555, "latencies_ms": [2178.555], "images_per_second": 0.459, "prompt_tokens": 1446, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 2\n2. child: 1\n3. kite: 1\n4. grass: 1\n5. trees: 1\n6. sky: 1\n7. person's hand: 1\n8. person's leg: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13442.5, "ram_available_mb": 109063.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13462.2, "ram_available_mb": 109044.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [51.64, 51.64, 51.64, 51.64, 47.05, 47.05, 47.05, 47.05, 47.05, 51.59, 51.59, 51.59, 51.59, 51.59, 43.97, 43.97, 43.97, 43.97, 43.97, 35.06, 35.06, 35.06], "power_watts_avg": 46.58, "power_watts_peak": 51.64, "energy_joules_est": 101.49, "sample_count": 22, "duration_seconds": 2.179}, "timestamp": "2026-01-12T10:15:08.434943"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1855.825, "latencies_ms": [1855.825], "images_per_second": 0.539, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the person is in the background, standing on the grass. The person is holding the kite string, which is in the foreground, and the kite is in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13462.2, "ram_available_mb": 109044.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13399.0, "ram_available_mb": 109107.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.06, 31.64, 31.64, 31.64, 31.64, 31.64, 50.41, 50.41, 50.41, 50.41, 50.41, 54.03, 54.03, 54.03, 54.03, 54.03, 35.04, 35.04, 35.04], "power_watts_avg": 43.19, "power_watts_peak": 54.03, "energy_joules_est": 80.17, "sample_count": 19, "duration_seconds": 1.856}, "timestamp": "2026-01-12T10:15:10.409205"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 918.002, "latencies_ms": [918.002], "images_per_second": 1.089, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A woman and a child are flying a kite in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.0, "ram_available_mb": 109107.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13403.0, "ram_available_mb": 109103.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [35.04, 35.04, 30.65, 30.65, 30.65, 30.65, 30.65, 49.95, 49.95, 49.95], "power_watts_avg": 37.32, "power_watts_peak": 49.95, "energy_joules_est": 34.27, "sample_count": 10, "duration_seconds": 0.918}, "timestamp": "2026-01-12T10:15:11.477325"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2183.189, "latencies_ms": [2183.189], "images_per_second": 0.458, "prompt_tokens": 1442, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a vibrant kite with a mix of colors and patterns, soaring in the sky, while a person wearing a black jacket and blue jeans is flying it. The sky is clear and blue, indicating a sunny day, and the grass is green, suggesting it is a park or open field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13403.0, "ram_available_mb": 109103.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13419.5, "ram_available_mb": 109086.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.95, 49.95, 49.95, 49.95, 49.95, 49.95, 50.14, 50.14, 50.14, 50.14, 50.14, 54.16, 54.16, 54.16, 54.16, 54.16, 34.91, 34.91, 34.91, 34.91, 34.91, 34.99], "power_watts_avg": 46.85, "power_watts_peak": 54.16, "energy_joules_est": 102.3, "sample_count": 22, "duration_seconds": 2.183}, "timestamp": "2026-01-12T10:15:13.696396"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 881.14, "latencies_ms": [881.14], "images_per_second": 1.135, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young boy is playing tennis on a court with a green fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.6, "ram_available_mb": 109094.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13407.0, "ram_available_mb": 109099.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.99, 34.99, 34.99, 34.99, 42.26, 42.26, 42.26, 42.26, 42.26], "power_watts_avg": 39.03, "power_watts_peak": 42.26, "energy_joules_est": 34.42, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T10:15:14.659629"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1982.28, "latencies_ms": [1982.28], "images_per_second": 0.504, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. ball: 1\n4. tennis court: 1\n5. banner: 1\n6. fence: 1\n7. net: 1\n8. text: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.0, "ram_available_mb": 109099.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13382.0, "ram_available_mb": 109124.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.44, 46.44, 46.44, 46.44, 46.44, 52.03, 52.03, 52.03, 52.03, 52.03, 47.41, 47.41, 47.41, 47.41, 47.41, 36.6, 36.6, 36.6, 36.6, 36.6], "power_watts_avg": 45.62, "power_watts_peak": 52.03, "energy_joules_est": 90.46, "sample_count": 20, "duration_seconds": 1.983}, "timestamp": "2026-01-12T10:15:16.676831"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1525.047, "latencies_ms": [1525.047], "images_per_second": 0.656, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The tennis player is in the foreground, holding a yellow tennis racket and preparing to hit a yellow tennis ball. The green fence is in the background, and the blue court is in the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.0, "ram_available_mb": 109124.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.2, "ram_available_mb": 109156.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.18, 35.18, 35.18, 35.18, 42.98, 42.98, 42.98, 42.98, 42.98, 46.45, 46.45, 46.45, 46.45, 46.45, 38.67, 38.67], "power_watts_avg": 41.57, "power_watts_peak": 46.45, "energy_joules_est": 63.44, "sample_count": 16, "duration_seconds": 1.526}, "timestamp": "2026-01-12T10:15:18.341337"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 886.406, "latencies_ms": [886.406], "images_per_second": 1.128, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young boy is playing tennis on a court with a green fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.2, "ram_available_mb": 109156.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13422.9, "ram_available_mb": 109083.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.67, 38.67, 38.67, 37.57, 37.57, 37.57, 37.57, 37.57, 46.49], "power_watts_avg": 38.93, "power_watts_peak": 46.49, "energy_joules_est": 34.53, "sample_count": 9, "duration_seconds": 0.887}, "timestamp": "2026-01-12T10:15:19.252878"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2206.73, "latencies_ms": [2206.73], "images_per_second": 0.453, "prompt_tokens": 1109, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image features a young boy playing tennis on a green court with a blue surface. The boy is wearing a white shirt and black shorts, and he is holding a yellow tennis racket. The background of the image is a green curtain, and there is a sign on the left side of the image that reads \"Are you next?\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.9, "ram_available_mb": 109087.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.49, 46.49, 46.49, 46.49, 52.45, 52.45, 52.45, 52.45, 52.45, 47.54, 47.54, 47.54, 47.54, 47.54, 39.67, 39.67, 39.67, 39.67, 39.67, 34.75, 34.75, 34.75], "power_watts_avg": 44.93, "power_watts_peak": 52.45, "energy_joules_est": 99.17, "sample_count": 22, "duration_seconds": 2.207}, "timestamp": "2026-01-12T10:15:21.473462"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1146.319, "latencies_ms": [1146.319], "images_per_second": 0.872, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image depicts a messy bedroom with a bed covered in a brown blanket, a chair, and a desk with a computer on it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13322.9, "ram_available_mb": 109183.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.75, 32.73, 32.73, 32.73, 32.73, 32.73, 47.06, 47.06, 47.06, 47.06, 47.06, 49.11], "power_watts_avg": 40.23, "power_watts_peak": 49.11, "energy_joules_est": 46.13, "sample_count": 12, "duration_seconds": 1.147}, "timestamp": "2026-01-12T10:15:22.736311"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1334.745, "latencies_ms": [1334.745], "images_per_second": 0.749, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bed: 1, chair: 1, desk: 1, door: 1, box: 1, blanket: 1, pillow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.2, "ram_available_mb": 109177.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13344.3, "ram_available_mb": 109162.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.11, 49.11, 49.11, 49.11, 42.96, 42.96, 42.96, 42.96, 42.96, 47.01, 47.01, 47.01, 47.01, 47.01], "power_watts_avg": 46.16, "power_watts_peak": 49.11, "energy_joules_est": 61.63, "sample_count": 14, "duration_seconds": 1.335}, "timestamp": "2026-01-12T10:15:24.149677"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1535.087, "latencies_ms": [1535.087], "images_per_second": 0.651, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the desk and chair situated on the right side. The desk is positioned in the foreground, while the chair is located further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.4, "ram_available_mb": 109165.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13360.6, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.8, 39.8, 39.8, 39.8, 39.8, 46.43, 46.43, 46.43, 46.43, 46.43, 46.82, 46.82, 46.82, 46.82, 46.82, 35.21], "power_watts_avg": 43.78, "power_watts_peak": 46.82, "energy_joules_est": 67.22, "sample_count": 16, "duration_seconds": 1.535}, "timestamp": "2026-01-12T10:15:25.764972"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 796.905, "latencies_ms": [796.905], "images_per_second": 1.255, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A messy bedroom with a bed, a chair, and a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.7, "ram_available_mb": 109153.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.21, 35.21, 35.21, 35.21, 41.56, 41.56, 41.56, 41.56], "power_watts_avg": 38.39, "power_watts_peak": 41.56, "energy_joules_est": 30.6, "sample_count": 8, "duration_seconds": 0.797}, "timestamp": "2026-01-12T10:15:26.575530"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 930.86, "latencies_ms": [930.86], "images_per_second": 1.074, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is lit by a single lightbulb, and the walls are made of brick.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13368.4, "ram_available_mb": 109137.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_watts_samples": [46.47, 46.47, 46.47, 46.47, 46.47, 53.39, 53.39, 53.39, 53.39, 53.39], "power_watts_avg": 49.93, "power_watts_peak": 53.39, "energy_joules_est": 46.49, "sample_count": 10, "duration_seconds": 0.931}, "timestamp": "2026-01-12T10:15:27.586823"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.165, "latencies_ms": [983.165], "images_per_second": 1.017, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman in a red and green outfit is riding a brown horse over a jump obstacle in a field.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13364.5, "ram_available_mb": 109141.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13364.4, "ram_available_mb": 109141.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.77, 46.77, 46.77, 46.77, 46.77, 46.63, 46.63, 46.63, 46.63, 46.63], "power_watts_avg": 46.7, "power_watts_peak": 46.77, "energy_joules_est": 45.94, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-12T10:15:28.599705"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1537.546, "latencies_ms": [1537.546], "images_per_second": 0.65, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " horse: 1, rider: 1, saddle: 1, bridle: 1, leg protection: 2, leg band: 1, helmet: 1, number: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.4, "ram_available_mb": 109141.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.03, 48.03, 48.03, 48.03, 48.03, 47.99, 47.99, 47.99, 47.99, 47.99, 47.78, 47.78, 47.78, 47.78, 47.78, 34.89], "power_watts_avg": 47.12, "power_watts_peak": 48.03, "energy_joules_est": 72.47, "sample_count": 16, "duration_seconds": 1.538}, "timestamp": "2026-01-12T10:15:30.215251"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1728.625, "latencies_ms": [1728.625], "images_per_second": 0.578, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The horse is in the foreground, jumping over the obstacle, while the rider is in the background, wearing a helmet and a colorful jacket. The obstacle is located in the middle ground, and the rider is positioned to the left of the horse.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13356.2, "ram_available_mb": 109150.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 43.36, 43.36, 43.36, 43.36, 43.36, 46.8, 46.8, 46.8, 46.8, 46.8, 38.2, 38.2, 38.2, 38.2], "power_watts_avg": 41.29, "power_watts_peak": 46.8, "energy_joules_est": 71.38, "sample_count": 18, "duration_seconds": 1.729}, "timestamp": "2026-01-12T10:15:32.029779"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 996.392, "latencies_ms": [996.392], "images_per_second": 1.004, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman in a red and green outfit is riding a brown horse over a jump obstacle in a field.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [38.2, 32.56, 32.56, 32.56, 32.56, 32.56, 46.36, 46.36, 46.36, 46.36], "power_watts_avg": 38.65, "power_watts_peak": 46.36, "energy_joules_est": 38.52, "sample_count": 10, "duration_seconds": 0.997}, "timestamp": "2026-01-12T10:15:33.041630"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2099.092, "latencies_ms": [2099.092], "images_per_second": 0.476, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a horse and rider in a dynamic pose, with the horse's coat a rich brown and the rider's attire a vibrant mix of red, green, and white. The scene is bathed in natural light, casting soft shadows and highlighting the textures of the horse's coat and the rider's gear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13337.7, "ram_available_mb": 109168.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.36, 47.51, 47.51, 47.51, 47.51, 47.51, 47.98, 47.98, 47.98, 47.98, 47.98, 48.89, 48.89, 48.89, 48.89, 48.89, 34.97, 34.97, 34.97, 34.97, 34.97], "power_watts_avg": 44.91, "power_watts_peak": 48.89, "energy_joules_est": 94.28, "sample_count": 21, "duration_seconds": 2.099}, "timestamp": "2026-01-12T10:15:35.157890"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1013.312, "latencies_ms": [1013.312], "images_per_second": 0.987, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Three men are sitting under a large umbrella on a sidewalk, with a car and a bicycle parked behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.7, "ram_available_mb": 109172.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.8, "ram_available_mb": 109148.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 43.8, 43.8, 43.8, 43.8, 43.8, 46.99, 46.99], "power_watts_avg": 41.14, "power_watts_peak": 46.99, "energy_joules_est": 41.73, "sample_count": 11, "duration_seconds": 1.014}, "timestamp": "2026-01-12T10:15:36.323174"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1915.624, "latencies_ms": [1915.624], "images_per_second": 0.522, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 3\n2. umbrella: 2\n3. chair: 1\n4. car: 2\n5. bicycle: 1\n6. table: 1\n7. sign: 1\n8. person: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.9, "ram_available_mb": 109156.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.1, "ram_available_mb": 109153.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.99, 46.99, 46.99, 41.7, 41.7, 41.7, 41.7, 41.7, 46.26, 46.26, 46.26, 46.26, 46.26, 42.87, 42.87, 42.87, 42.87, 42.87, 34.88, 34.88], "power_watts_avg": 43.24, "power_watts_peak": 46.99, "energy_joules_est": 82.85, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T10:15:38.343785"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1864.494, "latencies_ms": [1864.494], "images_per_second": 0.536, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man sitting under the umbrella is positioned to the left of the man sitting on the chair, with the man on the chair being closer to the camera. The man sitting on the chair is in the foreground, while the man sitting under the umbrella is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.2, "ram_available_mb": 109161.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13348.9, "ram_available_mb": 109157.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.21, 34.21, 34.21, 34.21, 34.21, 45.21, 45.21, 45.21, 45.21, 45.21, 46.52, 46.52, 46.52, 46.52, 46.52, 34.83, 34.83], "power_watts_avg": 40.48, "power_watts_peak": 46.52, "energy_joules_est": 75.52, "sample_count": 19, "duration_seconds": 1.866}, "timestamp": "2026-01-12T10:15:40.312001"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1066.452, "latencies_ms": [1066.452], "images_per_second": 0.938, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man sits under a large umbrella on a sidewalk, while two other men sit on the ground in front of him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.9, "ram_available_mb": 109157.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 36.31, 36.31, 36.31, 36.31, 36.31, 46.29, 46.29, 46.29], "power_watts_avg": 38.63, "power_watts_peak": 46.29, "energy_joules_est": 41.22, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T10:15:41.475497"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1919.293, "latencies_ms": [1919.293], "images_per_second": 0.521, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the light and dark areas. The scene is well-lit, suggesting it was taken during the day. The materials used in the image are typical for street scenes, with metal chairs and umbrellas providing shade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.5, "ram_available_mb": 109153.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.29, 43.35, 43.35, 43.35, 43.35, 43.35, 47.2, 47.2, 47.2, 47.2, 47.2, 49.63, 49.63, 49.63, 49.63, 49.63, 34.82, 34.82, 34.82, 34.82], "power_watts_avg": 44.32, "power_watts_peak": 49.63, "energy_joules_est": 85.09, "sample_count": 20, "duration_seconds": 1.92}, "timestamp": "2026-01-12T10:15:43.496474"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1120.721, "latencies_ms": [1120.721], "images_per_second": 0.892, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a kitchen with white cabinets, a stove, and a refrigerator, and a ceiling fan with lights hanging from it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.6, "ram_available_mb": 109161.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.5, "ram_available_mb": 109149.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.82, 31.44, 31.44, 31.44, 31.44, 31.44, 46.16, 46.16, 46.16, 46.16, 46.16, 49.63], "power_watts_avg": 39.37, "power_watts_peak": 49.63, "energy_joules_est": 44.14, "sample_count": 12, "duration_seconds": 1.121}, "timestamp": "2026-01-12T10:15:44.711737"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1488.126, "latencies_ms": [1488.126], "images_per_second": 0.672, "prompt_tokens": 1114, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. white cabinets\n2. white stove\n3. white refrigerator\n4. white oven\n5. white sink\n6. white dishwasher\n7. white microwave\n8. white refrigerator", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.5, "ram_available_mb": 109153.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13349.8, "ram_available_mb": 109156.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.63, 49.63, 49.63, 49.63, 42.94, 42.94, 42.94, 42.94, 42.94, 46.44, 46.44, 46.44, 46.44, 46.44, 38.18], "power_watts_avg": 45.57, "power_watts_peak": 49.63, "energy_joules_est": 67.84, "sample_count": 15, "duration_seconds": 1.489}, "timestamp": "2026-01-12T10:15:46.227196"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1515.126, "latencies_ms": [1515.126], "images_per_second": 0.66, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The stove is located to the left of the sink, and the refrigerator is positioned to the right of the sink. The ceiling fan is located above the sink, and the window is located above the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.8, "ram_available_mb": 109156.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13359.7, "ram_available_mb": 109146.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [38.18, 38.18, 38.18, 38.18, 43.85, 43.85, 43.85, 43.85, 43.85, 47.85, 47.85, 47.85, 47.85, 47.85, 38.77, 38.77], "power_watts_avg": 43.05, "power_watts_peak": 47.85, "energy_joules_est": 65.24, "sample_count": 16, "duration_seconds": 1.516}, "timestamp": "2026-01-12T10:15:47.843647"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1648.037, "latencies_ms": [1648.037], "images_per_second": 0.607, "prompt_tokens": 1112, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a quaint kitchen bathed in soft light, with white cabinets and appliances that exude a sense of homeliness. A ceiling fan hangs from the center of the room, its blades gently swaying in the breeze.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13349.8, "ram_available_mb": 109156.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13363.8, "ram_available_mb": 109142.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.77, 38.77, 38.77, 37.3, 37.3, 37.3, 37.3, 37.3, 46.05, 46.05, 46.05, 46.05, 46.05, 43.87, 43.87, 43.87, 43.87], "power_watts_avg": 41.67, "power_watts_peak": 46.05, "energy_joules_est": 68.71, "sample_count": 17, "duration_seconds": 1.649}, "timestamp": "2026-01-12T10:15:49.560862"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 994.51, "latencies_ms": [994.51], "images_per_second": 1.006, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light coming through the windows, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.8, "ram_available_mb": 109142.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13356.4, "ram_available_mb": 109149.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 48.0}, "power_stats": {"power_watts_samples": [43.87, 33.42, 33.42, 33.42, 33.42, 33.42, 46.79, 46.79, 46.79, 46.79], "power_watts_avg": 39.82, "power_watts_peak": 46.79, "energy_joules_est": 39.62, "sample_count": 10, "duration_seconds": 0.995}, "timestamp": "2026-01-12T10:15:50.573254"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1356.363, "latencies_ms": [1356.363], "images_per_second": 0.737, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A child is lying in bed with a pillow under their head, wearing a white tank top and blue pajama pants with a pattern of daisies and other shapes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.4, "ram_available_mb": 109149.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.7, "ram_available_mb": 109165.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.79, 47.42, 47.42, 47.42, 47.42, 47.42, 47.68, 47.68, 47.68, 47.68, 48.23, 48.23, 48.23, 48.23], "power_watts_avg": 47.68, "power_watts_peak": 48.23, "energy_joules_est": 64.71, "sample_count": 14, "duration_seconds": 1.357}, "timestamp": "2026-01-12T10:15:51.989322"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1932.646, "latencies_ms": [1932.646], "images_per_second": 0.517, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. child: 1\n2. pillow: 1\n3. blanket: 1\n4. bed: 1\n5. wall: 1\n6. nightstand: 1\n7. lamp: 1\n8. curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.8, "ram_available_mb": 109169.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.5, "ram_available_mb": 109149.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.23, 32.22, 32.22, 32.22, 32.22, 32.22, 46.96, 46.96, 46.96, 46.96, 46.96, 49.93, 49.93, 49.93, 49.93, 49.93, 35.03, 35.03, 35.03, 35.03], "power_watts_avg": 41.7, "power_watts_peak": 49.93, "energy_joules_est": 80.6, "sample_count": 20, "duration_seconds": 1.933}, "timestamp": "2026-01-12T10:15:54.005506"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1455.999, "latencies_ms": [1455.999], "images_per_second": 0.687, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The child is lying on the bed, which is positioned in the foreground of the image. The bed is situated in the middle of the room, with the wall and a lamp in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.6, "ram_available_mb": 109157.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [35.03, 32.1, 32.1, 32.1, 32.1, 32.1, 45.41, 45.41, 45.41, 45.41, 45.41, 48.6, 48.6, 48.6, 48.6], "power_watts_avg": 41.13, "power_watts_peak": 48.6, "energy_joules_est": 59.93, "sample_count": 15, "duration_seconds": 1.457}, "timestamp": "2026-01-12T10:15:55.572179"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 798.628, "latencies_ms": [798.628], "images_per_second": 1.252, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A child is sleeping in a dark room with a blanket and pillow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.2, "ram_available_mb": 109143.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13373.8, "ram_available_mb": 109132.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [48.6, 33.87, 33.87, 33.87, 33.87, 33.87, 47.23, 47.23], "power_watts_avg": 39.05, "power_watts_peak": 48.6, "energy_joules_est": 31.19, "sample_count": 8, "duration_seconds": 0.799}, "timestamp": "2026-01-12T10:15:56.382344"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1940.207, "latencies_ms": [1940.207], "images_per_second": 0.515, "prompt_tokens": 1110, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image is a nighttime photograph of a child sleeping in a room with a dark background. The child is wearing a white tank top and blue patterned pajama pants. The room is dimly lit, with only a small portion of the room illuminated by a lamp on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.7, "ram_available_mb": 109124.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 50.88, 50.88, 50.88, 50.88, 50.88, 47.86, 47.86, 47.86, 47.86, 45.5, 45.5, 45.5, 45.5, 45.5, 34.84, 34.84, 34.84], "power_watts_avg": 45.98, "power_watts_peak": 50.88, "energy_joules_est": 89.23, "sample_count": 20, "duration_seconds": 1.941}, "timestamp": "2026-01-12T10:15:58.397568"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2096.597, "latencies_ms": [2096.597], "images_per_second": 0.477, "prompt_tokens": 1099, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image features a green highway sign with the text \"NO TRUCKS\" at the top, \"EAST\" and \"INTERSTATE 78\" on the left side, and \"Queens Bronx\" in the center, with a small red and white \"Route 27\" sign above it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13363.9, "ram_available_mb": 109142.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 32.59, 32.59, 32.59, 32.59, 32.59, 45.75, 45.75, 45.75, 45.75, 45.75, 48.22, 48.22, 48.22, 48.22, 48.22, 35.12, 35.12, 35.12, 35.12], "power_watts_avg": 40.14, "power_watts_peak": 48.22, "energy_joules_est": 84.19, "sample_count": 21, "duration_seconds": 2.097}, "timestamp": "2026-01-12T10:16:00.565044"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1931.638, "latencies_ms": [1931.638], "images_per_second": 0.518, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 1\n2. graffiti: 1\n3. road sign: 1\n4. bridge: 1\n5. highway: 1\n6. text: 1\n7. letters: 1\n8. numbers: 1", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13387.4, "ram_available_mb": 109118.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 34.87, 34.87, 47.14, 47.14, 47.14, 47.14, 47.14, 47.48, 47.48, 47.48, 47.48, 47.48, 35.01, 35.01, 35.01, 35.01, 35.01], "power_watts_avg": 41.12, "power_watts_peak": 47.48, "energy_joules_est": 79.46, "sample_count": 20, "duration_seconds": 1.932}, "timestamp": "2026-01-12T10:16:02.631628"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1457.205, "latencies_ms": [1457.205], "images_per_second": 0.686, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The green highway sign is positioned in the foreground, with the metal truss structure in the background. The sign is to the left of the truss structure, and the sky is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.4, "ram_available_mb": 109122.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13410.8, "ram_available_mb": 109095.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.53, 34.53, 34.53, 34.53, 34.53, 43.94, 43.94, 43.94, 43.94, 46.18, 46.18, 46.18, 46.18, 46.18, 37.48], "power_watts_avg": 41.12, "power_watts_peak": 46.18, "energy_joules_est": 59.95, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-12T10:16:04.199247"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1752.84, "latencies_ms": [1752.84], "images_per_second": 0.571, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a green highway sign with the words \"Queens Bronx\" written on it, indicating a route for travelers. The sign is situated on a metal structure, possibly part of a highway or bridge, and is surrounded by a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.8, "ram_available_mb": 109095.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13450.9, "ram_available_mb": 109055.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.48, 37.48, 37.48, 37.48, 44.55, 44.55, 44.55, 44.55, 44.55, 46.91, 46.91, 46.91, 46.91, 46.91, 37.52, 37.52, 37.52, 37.52], "power_watts_avg": 42.07, "power_watts_peak": 46.91, "energy_joules_est": 73.77, "sample_count": 18, "duration_seconds": 1.753}, "timestamp": "2026-01-12T10:16:06.015967"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1299.664, "latencies_ms": [1299.664], "images_per_second": 0.769, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The sign is green with white lettering, and it is attached to a metal frame. The sky is overcast, and the sign is lit by natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13446.9, "ram_available_mb": 109059.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13443.5, "ram_available_mb": 109062.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.52, 32.62, 32.62, 32.62, 32.62, 32.62, 46.84, 46.84, 46.84, 46.84, 46.84, 49.35, 49.35], "power_watts_avg": 41.04, "power_watts_peak": 49.35, "energy_joules_est": 53.35, "sample_count": 13, "duration_seconds": 1.3}, "timestamp": "2026-01-12T10:16:07.330420"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 875.382, "latencies_ms": [875.382], "images_per_second": 1.142, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red vintage truck is parked in a lot with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.6, "ram_available_mb": 109070.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [49.35, 49.35, 49.35, 39.88, 39.88, 39.88, 39.88, 39.88, 47.85], "power_watts_avg": 43.92, "power_watts_peak": 49.35, "energy_joules_est": 38.47, "sample_count": 9, "duration_seconds": 0.876}, "timestamp": "2026-01-12T10:16:08.243836"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1988.384, "latencies_ms": [1988.384], "images_per_second": 0.503, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. truck: 1\n2. wheels: 2\n3. tires: 2\n4. tail lights: 2\n5. headlights: 2\n6. license plate: 1\n7. body: 1\n8. roof: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.85, 47.85, 47.85, 47.85, 52.22, 52.22, 52.22, 52.22, 52.22, 47.44, 47.44, 47.44, 47.44, 47.44, 39.94, 39.94, 39.94, 39.94, 39.94, 34.9], "power_watts_avg": 46.22, "power_watts_peak": 52.22, "energy_joules_est": 91.92, "sample_count": 20, "duration_seconds": 1.989}, "timestamp": "2026-01-12T10:16:10.264233"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1624.577, "latencies_ms": [1624.577], "images_per_second": 0.616, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The red pickup truck is positioned in the foreground, with the blue tent and street lamp in the background. The truck is facing towards the left side of the image, while the tent and lamp are located towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.2, "ram_available_mb": 109124.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 39.03, 39.03, 39.03, 39.03, 39.03, 46.48, 46.48, 46.48, 46.48, 46.48, 42.44, 42.44, 42.44, 42.44], "power_watts_avg": 41.29, "power_watts_peak": 46.48, "energy_joules_est": 67.11, "sample_count": 17, "duration_seconds": 1.625}, "timestamp": "2026-01-12T10:16:12.030943"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 896.021, "latencies_ms": [896.021], "images_per_second": 1.116, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red vintage truck is parked in a lot with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.3, "ram_available_mb": 109132.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.44, 32.37, 32.37, 32.37, 32.37, 32.37, 46.57, 46.57, 46.57], "power_watts_avg": 38.22, "power_watts_peak": 46.57, "energy_joules_est": 34.25, "sample_count": 9, "duration_seconds": 0.896}, "timestamp": "2026-01-12T10:16:12.941606"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 987.725, "latencies_ms": [987.725], "images_per_second": 1.012, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The truck is red with chrome wheels and a shiny finish. The sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13379.8, "ram_available_mb": 109126.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.57, 46.57, 48.67, 48.67, 48.67, 48.67, 48.67, 47.7, 47.7, 47.7], "power_watts_avg": 47.96, "power_watts_peak": 48.67, "energy_joules_est": 47.39, "sample_count": 10, "duration_seconds": 0.988}, "timestamp": "2026-01-12T10:16:13.951333"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 874.416, "latencies_ms": [874.416], "images_per_second": 1.144, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of cows are standing behind a barbed wire fence, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.9, "ram_available_mb": 109130.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13384.7, "ram_available_mb": 109121.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.7, 47.7, 47.95, 47.95, 47.95, 47.95, 47.95, 47.78, 47.78], "power_watts_avg": 47.86, "power_watts_peak": 47.95, "energy_joules_est": 41.87, "sample_count": 9, "duration_seconds": 0.875}, "timestamp": "2026-01-12T10:16:14.862202"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1948.437, "latencies_ms": [1948.437], "images_per_second": 0.513, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. barbed wire: 1\n2. cows: 4\n3. grass: 1\n4. trees: 1\n5. fence: 1\n6. sky: 1\n7. clouds: 1\n8. fence post: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.8, "ram_available_mb": 109129.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13379.2, "ram_available_mb": 109127.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.78, 47.78, 47.78, 52.33, 52.33, 52.33, 52.33, 52.33, 47.9, 47.9, 47.9, 47.9, 47.9, 44.3, 44.3, 44.3, 44.3, 44.3, 35.0, 35.0], "power_watts_avg": 46.8, "power_watts_peak": 52.33, "energy_joules_est": 91.2, "sample_count": 20, "duration_seconds": 1.949}, "timestamp": "2026-01-12T10:16:16.877178"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1138.157, "latencies_ms": [1138.157], "images_per_second": 0.879, "prompt_tokens": 1117, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The cows are positioned in the foreground, with the barbed wire fence in the middle ground, and the field and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13371.3, "ram_available_mb": 109135.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13382.3, "ram_available_mb": 109124.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 34.11, 34.11, 34.11, 34.11, 34.11, 46.18, 46.18, 46.18, 46.18, 46.18], "power_watts_avg": 39.29, "power_watts_peak": 46.18, "energy_joules_est": 44.74, "sample_count": 12, "duration_seconds": 1.139}, "timestamp": "2026-01-12T10:16:18.141451"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1634.486, "latencies_ms": [1634.486], "images_per_second": 0.612, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In this black and white photo, we see a group of cows standing behind a barbed wire fence, looking directly at the camera. The cows are of different colors, with one having a white face and the others having black faces.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13378.3, "ram_available_mb": 109128.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.4, "ram_available_mb": 109129.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.62, 47.62, 47.62, 47.62, 47.62, 47.11, 47.11, 47.11, 47.11, 47.11, 47.1, 47.1, 47.1, 47.1, 47.1, 35.08, 35.08], "power_watts_avg": 45.84, "power_watts_peak": 47.62, "energy_joules_est": 74.95, "sample_count": 17, "duration_seconds": 1.635}, "timestamp": "2026-01-12T10:16:19.860374"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1189.466, "latencies_ms": [1189.466], "images_per_second": 0.841, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is in black and white, with a barbed wire fence in the foreground, and the cows are standing in a field with tall grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.5, "ram_available_mb": 109137.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.2, "ram_available_mb": 109123.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [35.08, 35.08, 35.08, 37.54, 37.54, 37.54, 37.54, 37.54, 46.62, 46.62, 46.62, 46.62], "power_watts_avg": 39.95, "power_watts_peak": 46.62, "energy_joules_est": 47.54, "sample_count": 12, "duration_seconds": 1.19}, "timestamp": "2026-01-12T10:16:21.073622"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1658.289, "latencies_ms": [1658.289], "images_per_second": 0.603, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed, a comfortable chair, a fireplace, and a television mounted on the wall, all set against a warm and inviting backdrop of wooden furniture and a ceiling with a glowing light strip.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.5, "ram_available_mb": 109134.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [46.62, 44.5, 44.5, 44.5, 44.5, 44.5, 47.76, 47.76, 47.76, 47.76, 47.76, 48.11, 48.11, 48.11, 48.11, 48.11, 34.78], "power_watts_avg": 46.07, "power_watts_peak": 48.11, "energy_joules_est": 76.42, "sample_count": 17, "duration_seconds": 1.659}, "timestamp": "2026-01-12T10:16:22.792955"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1968.666, "latencies_ms": [1968.666], "images_per_second": 0.508, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bed: 1\n2. clock: 1\n3. television: 1\n4. chair: 2\n5. lamp: 1\n6. window blinds: 1\n7. fireplace: 1\n8. rug: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.6, "ram_available_mb": 109142.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13365.9, "ram_available_mb": 109140.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.78, 34.78, 34.78, 40.49, 40.49, 40.49, 40.49, 40.49, 46.94, 46.94, 46.94, 46.94, 46.94, 41.19, 41.19, 41.19, 41.19, 41.19, 34.83, 34.83], "power_watts_avg": 40.86, "power_watts_peak": 46.94, "energy_joules_est": 80.46, "sample_count": 20, "duration_seconds": 1.969}, "timestamp": "2026-01-12T10:16:24.812002"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1901.581, "latencies_ms": [1901.581], "images_per_second": 0.526, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the clock on the wall above it. The fireplace is situated on the right side of the room, with the television above it. The chair is placed in the middle of the room, with the window behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13361.7, "ram_available_mb": 109144.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 37.76, 37.76, 37.76, 37.76, 37.76, 46.38, 46.38, 46.38, 46.38, 46.38, 43.39, 43.39, 43.39, 43.39, 43.39, 34.9], "power_watts_avg": 40.9, "power_watts_peak": 46.38, "energy_joules_est": 77.82, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T10:16:26.780823"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 856.49, "latencies_ms": [856.49], "images_per_second": 1.168, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The room is a cozy bedroom with a bed, chairs, and a fireplace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.7, "ram_available_mb": 109148.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13357.6, "ram_available_mb": 109148.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 39.58, 39.58, 39.58, 39.58, 39.58, 46.69], "power_watts_avg": 38.81, "power_watts_peak": 46.69, "energy_joules_est": 33.28, "sample_count": 9, "duration_seconds": 0.857}, "timestamp": "2026-01-12T10:16:27.742284"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1228.171, "latencies_ms": [1228.171], "images_per_second": 0.814, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The room is illuminated by warm lighting, with a wooden ceiling and walls. The furniture is made of wood, and the room has a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13357.6, "ram_available_mb": 109148.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13343.2, "ram_available_mb": 109163.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.69, 46.69, 46.69, 46.69, 51.68, 51.68, 51.68, 51.68, 51.68, 47.28, 47.28, 47.28, 47.28], "power_watts_avg": 48.79, "power_watts_peak": 51.68, "energy_joules_est": 59.95, "sample_count": 13, "duration_seconds": 1.229}, "timestamp": "2026-01-12T10:16:29.055052"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1329.039, "latencies_ms": [1329.039], "images_per_second": 0.752, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a group of four birds with black feathers and blue accents are seen walking on a dry, grassy field, with a bush and trees in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13335.3, "ram_available_mb": 109171.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [47.28, 35.97, 35.97, 35.97, 35.97, 35.97, 46.37, 46.37, 46.37, 46.37, 46.37, 48.87, 48.87, 48.87], "power_watts_avg": 43.26, "power_watts_peak": 48.87, "energy_joules_est": 57.51, "sample_count": 14, "duration_seconds": 1.33}, "timestamp": "2026-01-12T10:16:30.472814"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.346, "latencies_ms": [1902.346], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 4\n2. grass: 1\n3. bush: 1\n4. tree: 1\n5. sky: 1\n6. ground: 1\n7. dirt: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.87, 48.87, 33.19, 33.19, 33.19, 33.19, 33.19, 46.54, 46.54, 46.54, 46.54, 46.54, 49.06, 49.06, 49.06, 49.06, 49.06, 34.91, 34.91], "power_watts_avg": 42.71, "power_watts_peak": 49.06, "energy_joules_est": 81.27, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T10:16:32.390279"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1737.133, "latencies_ms": [1737.133], "images_per_second": 0.576, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the two larger birds in the center and the smaller bird to the right. The larger birds are positioned closer to the camera than the smaller bird, which is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 35.07, 35.07, 35.07, 35.07, 35.07, 47.04, 47.04, 47.04, 47.04, 47.04, 47.41, 47.41, 47.41, 47.41, 47.41, 34.63], "power_watts_avg": 41.78, "power_watts_peak": 47.41, "energy_joules_est": 72.61, "sample_count": 18, "duration_seconds": 1.738}, "timestamp": "2026-01-12T10:16:34.258202"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 925.253, "latencies_ms": [925.253], "images_per_second": 1.081, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of four birds with black feathers and blue accents are walking on a dry grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13446.5, "ram_available_mb": 109059.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.63, 34.63, 34.63, 34.63, 42.69, 42.69, 42.69, 42.69, 42.69, 46.96], "power_watts_avg": 39.89, "power_watts_peak": 46.96, "energy_joules_est": 36.93, "sample_count": 10, "duration_seconds": 0.926}, "timestamp": "2026-01-12T10:16:35.264162"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1655.816, "latencies_ms": [1655.816], "images_per_second": 0.604, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a group of four birds with black feathers and blue accents, standing on a dry, grassy field. The sky is overcast, and the birds appear to be in a natural habitat, possibly a savannah or grassland.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13446.5, "ram_available_mb": 109059.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13422.9, "ram_available_mb": 109083.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.96, 46.96, 46.96, 46.96, 46.43, 46.43, 46.43, 46.43, 46.43, 46.58, 46.58, 46.58, 46.58, 46.58, 39.33, 39.33, 39.33], "power_watts_avg": 45.35, "power_watts_peak": 46.96, "energy_joules_est": 75.12, "sample_count": 17, "duration_seconds": 1.657}, "timestamp": "2026-01-12T10:16:36.979445"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1055.128, "latencies_ms": [1055.128], "images_per_second": 0.948, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Three people are standing in the snow, wearing winter clothing and holding ski poles, with a forested area in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13422.9, "ram_available_mb": 109083.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13478.6, "ram_available_mb": 109027.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.33, 39.33, 33.52, 33.52, 33.52, 33.52, 33.52, 47.31, 47.31, 47.31, 47.31], "power_watts_avg": 39.59, "power_watts_peak": 47.31, "energy_joules_est": 41.79, "sample_count": 11, "duration_seconds": 1.056}, "timestamp": "2026-01-12T10:16:38.092405"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1949.622, "latencies_ms": [1949.622], "images_per_second": 0.513, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. skis: 3\n2. ski poles: 6\n3. snow: 1\n4. trees: 1\n5. people: 3\n6. clothing: 3\n7. backpack: 1\n8. hat: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13478.3, "ram_available_mb": 109028.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13429.7, "ram_available_mb": 109076.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.42, 48.42, 48.42, 48.42, 48.42, 47.43, 47.43, 47.43, 47.43, 47.43, 48.48, 48.48, 48.48, 48.48, 48.48, 35.03, 35.03, 35.03, 35.03, 35.03], "power_watts_avg": 44.84, "power_watts_peak": 48.48, "energy_joules_est": 87.44, "sample_count": 20, "duration_seconds": 1.95}, "timestamp": "2026-01-12T10:16:40.112329"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2396.997, "latencies_ms": [2396.997], "images_per_second": 0.417, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The person on the left is standing closer to the camera than the person in the middle, who is standing slightly farther away. The person on the right is standing in the background, with the person in the middle being the closest to the camera. The person on the left is also standing closer to the camera than the person in the middle, who is standing slightly farther away.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13429.7, "ram_available_mb": 109076.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13464.1, "ram_available_mb": 109042.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.97, 33.97, 33.97, 33.97, 33.97, 46.02, 46.02, 46.02, 46.02, 46.02, 47.1, 47.1, 47.1, 47.1, 47.1, 34.9, 34.9, 34.9, 34.9, 34.9, 34.84, 34.84, 34.84, 34.84], "power_watts_avg": 39.56, "power_watts_peak": 47.1, "energy_joules_est": 94.84, "sample_count": 24, "duration_seconds": 2.398}, "timestamp": "2026-01-12T10:16:42.584570"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 822.438, "latencies_ms": [822.438], "images_per_second": 1.216, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three people are standing in the snow wearing winter clothing and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13456.2, "ram_available_mb": 109050.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13462.0, "ram_available_mb": 109044.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.24, 34.24, 34.24, 34.24, 34.24, 46.92, 46.92, 46.92, 46.92], "power_watts_avg": 39.88, "power_watts_peak": 46.92, "energy_joules_est": 32.82, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-12T10:16:43.546938"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1514.245, "latencies_ms": [1514.245], "images_per_second": 0.66, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features three people standing in a snowy landscape, wearing winter clothing and holding ski poles. The sky is overcast, and the snow is pristine white, covering the ground and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13462.0, "ram_available_mb": 109044.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13492.8, "ram_available_mb": 109013.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.92, 44.92, 44.92, 44.92, 44.92, 44.92, 46.62, 46.62, 46.62, 46.62, 46.62, 49.21, 49.21, 49.21, 49.21, 49.21], "power_watts_avg": 46.92, "power_watts_peak": 49.21, "energy_joules_est": 71.06, "sample_count": 16, "duration_seconds": 1.515}, "timestamp": "2026-01-12T10:16:45.162950"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1391.935, "latencies_ms": [1391.935], "images_per_second": 0.718, "prompt_tokens": 1432, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A white and blue bus with the number 61 and the word \"Crosstown\" on the front is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13475.4, "ram_available_mb": 109030.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13410.8, "ram_available_mb": 109095.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.21, 34.21, 34.21, 34.21, 34.21, 44.2, 44.2, 44.2, 44.2, 44.2, 50.76, 50.76, 50.76, 50.76], "power_watts_avg": 42.51, "power_watts_peak": 50.76, "energy_joules_est": 59.17, "sample_count": 14, "duration_seconds": 1.392}, "timestamp": "2026-01-12T10:16:46.582220"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2289.539, "latencies_ms": [2289.539], "images_per_second": 0.437, "prompt_tokens": 1446, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Bus: 1\n2. License plate: 1\n3. Bike rack: 1\n4. Side mirror: 1\n5. Headlights: 2\n6. Windshield: 1\n7. Side mirror: 1\n8. License plate: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13410.8, "ram_available_mb": 109095.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13463.6, "ram_available_mb": 109042.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [50.76, 40.77, 40.77, 40.77, 40.77, 40.77, 49.47, 49.47, 49.47, 49.47, 49.47, 51.78, 51.78, 51.78, 51.78, 51.78, 36.99, 36.99, 36.99, 36.99, 34.84, 34.84, 34.84], "power_watts_avg": 44.06, "power_watts_peak": 51.78, "energy_joules_est": 100.9, "sample_count": 23, "duration_seconds": 2.29}, "timestamp": "2026-01-12T10:16:48.903905"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1727.207, "latencies_ms": [1727.207], "images_per_second": 0.579, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The background features a brick building and a clear blue sky, while the foreground shows a sidewalk and a street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13459.0, "ram_available_mb": 109047.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13465.2, "ram_available_mb": 109041.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 32.49, 32.49, 32.49, 32.49, 32.49, 50.51, 50.51, 50.51, 50.51, 50.51, 53.58, 53.58, 53.58, 53.58, 53.58, 34.8], "power_watts_avg": 43.74, "power_watts_peak": 53.58, "energy_joules_est": 75.61, "sample_count": 18, "duration_seconds": 1.728}, "timestamp": "2026-01-12T10:16:50.770399"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1392.969, "latencies_ms": [1392.969], "images_per_second": 0.718, "prompt_tokens": 1444, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white and blue bus is parked on the side of the road, with a sign on the front that says \"51 CROSSTOWN\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13465.2, "ram_available_mb": 109041.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13450.6, "ram_available_mb": 109055.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.8, 34.8, 39.74, 39.74, 39.74, 39.74, 39.74, 50.19, 50.19, 50.19, 50.19, 50.19], "power_watts_avg": 42.06, "power_watts_peak": 50.19, "energy_joules_est": 58.61, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-12T10:16:52.191028"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1079.381, "latencies_ms": [1079.381], "images_per_second": 0.926, "prompt_tokens": 1442, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bus is white with blue and green graphics, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13450.6, "ram_available_mb": 109055.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13404.4, "ram_available_mb": 109101.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.1, 46.1, 46.1, 46.1, 44.69, 44.69, 44.69, 44.69, 44.69, 51.3, 51.3], "power_watts_avg": 46.4, "power_watts_peak": 51.3, "energy_joules_est": 50.1, "sample_count": 11, "duration_seconds": 1.08}, "timestamp": "2026-01-12T10:16:53.306546"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1646.561, "latencies_ms": [1646.561], "images_per_second": 0.607, "prompt_tokens": 768, "response_tokens_est": 52, "n_tiles": 1, "output_text": " A man dressed in a school uniform, consisting of a blue blazer, a white shirt, a red and blue striped tie, a gray pleated skirt, black tights, and black shoes, is standing in front of a red and white striped wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.4, "ram_available_mb": 109101.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13386.0, "ram_available_mb": 109120.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_watts_samples": [51.3, 51.3, 51.3, 50.25, 50.25, 50.25, 50.25, 50.25, 43.06, 43.06, 43.06, 43.06, 43.06, 35.96, 35.96, 35.96, 35.96], "power_watts_avg": 44.96, "power_watts_peak": 51.3, "energy_joules_est": 74.05, "sample_count": 17, "duration_seconds": 1.647}, "timestamp": "2026-01-12T10:16:55.021017"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1817.857, "latencies_ms": [1817.857], "images_per_second": 0.55, "prompt_tokens": 782, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. wall: 1\n3. handbag: 1\n4. tie: 1\n5. shirt: 1\n6. tie clip: 1\n7. tie: 1\n8. tie clip: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.0, "ram_available_mb": 109120.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13433.8, "ram_available_mb": 109072.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4575.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.96, 32.19, 32.19, 32.19, 32.19, 32.19, 42.4, 42.4, 42.4, 42.4, 42.4, 44.96, 44.96, 44.96, 44.96, 44.96, 34.9, 34.9, 34.9], "power_watts_avg": 38.86, "power_watts_peak": 44.96, "energy_joules_est": 70.66, "sample_count": 19, "duration_seconds": 1.818}, "timestamp": "2026-01-12T10:16:56.934804"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1373.388, "latencies_ms": [1373.388], "images_per_second": 0.728, "prompt_tokens": 786, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is standing in the foreground of the image, with the red carpet and white wall in the background. The black bag is held in his left hand, while his right hand is resting on his hip.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13433.8, "ram_available_mb": 109072.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13423.8, "ram_available_mb": 109082.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4575.3, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 32.51, 32.51, 32.51, 32.51, 32.51, 40.84, 40.84, 40.84, 40.84, 40.84, 43.41, 43.41], "power_watts_avg": 37.38, "power_watts_peak": 43.41, "energy_joules_est": 51.37, "sample_count": 14, "duration_seconds": 1.374}, "timestamp": "2026-01-12T10:16:58.397721"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 737.643, "latencies_ms": [737.643], "images_per_second": 1.356, "prompt_tokens": 780, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man dressed in a school uniform stands in front of a red and white wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.8, "ram_available_mb": 109082.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13414.7, "ram_available_mb": 109091.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.8, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [43.41, 43.41, 38.46, 38.46, 38.46, 38.46, 38.46, 42.92], "power_watts_avg": 40.25, "power_watts_peak": 43.41, "energy_joules_est": 29.72, "sample_count": 8, "duration_seconds": 0.738}, "timestamp": "2026-01-12T10:16:59.206840"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 932.217, "latencies_ms": [932.217], "images_per_second": 1.073, "prompt_tokens": 778, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a photograph with a white background and a red carpet. The lighting is natural, and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.7, "ram_available_mb": 109091.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 2.1, "ram_used_mb": 13399.9, "ram_available_mb": 109106.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [42.92, 42.92, 42.92, 42.92, 47.1, 47.1, 47.1, 47.1, 47.1, 42.44], "power_watts_avg": 44.96, "power_watts_peak": 47.1, "energy_joules_est": 41.94, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T10:17:00.216756"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1307.87, "latencies_ms": [1307.87], "images_per_second": 0.765, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a series of train tracks with numerous overhead power lines and poles, all covered in a layer of fog or mist, creating a mysterious and somewhat eerie atmosphere.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 13399.6, "ram_available_mb": 109106.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13403.7, "ram_available_mb": 109102.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [42.44, 42.44, 42.44, 42.44, 44.32, 44.32, 44.32, 44.32, 44.32, 46.94, 46.94, 46.94, 46.94], "power_watts_avg": 44.54, "power_watts_peak": 46.94, "energy_joules_est": 58.3, "sample_count": 13, "duration_seconds": 1.309}, "timestamp": "2026-01-12T10:17:01.534560"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1914.045, "latencies_ms": [1914.045], "images_per_second": 0.522, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. train: 1\n2. train: 1\n3. train: 1\n4. train: 1\n5. train: 1\n6. train: 1\n7. train: 1\n8. train: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.7, "ram_available_mb": 109102.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13321.1, "ram_available_mb": 109185.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.94, 37.26, 37.26, 37.26, 37.26, 37.26, 48.13, 48.13, 48.13, 48.13, 48.13, 49.38, 49.38, 49.38, 49.38, 49.38, 34.81, 34.81, 34.81, 34.81], "power_watts_avg": 43.0, "power_watts_peak": 49.38, "energy_joules_est": 82.33, "sample_count": 20, "duration_seconds": 1.915}, "timestamp": "2026-01-12T10:17:03.552949"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1786.826, "latencies_ms": [1786.826], "images_per_second": 0.56, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main objects in the image are arranged in a linear fashion, with the foreground consisting of the train tracks and the background featuring the electrical poles and wires. The train tracks are positioned in the foreground, while the electrical poles and wires are located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.1, "ram_available_mb": 109185.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.04, 32.04, 32.04, 32.04, 32.04, 45.09, 45.09, 45.09, 45.09, 45.09, 48.27, 48.27, 48.27, 48.27, 48.27, 35.06, 35.06, 35.06], "power_watts_avg": 40.68, "power_watts_peak": 48.27, "energy_joules_est": 72.72, "sample_count": 18, "duration_seconds": 1.788}, "timestamp": "2026-01-12T10:17:05.417102"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1165.789, "latencies_ms": [1165.789], "images_per_second": 0.858, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a series of train tracks and overhead power lines in a foggy environment, with the tracks appearing to be submerged in water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.4, "ram_available_mb": 109168.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.06, 35.06, 37.13, 37.13, 37.13, 37.13, 37.13, 47.57, 47.57, 47.57, 47.57, 47.57], "power_watts_avg": 41.14, "power_watts_peak": 47.57, "energy_joules_est": 47.98, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-12T10:17:06.629551"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2012.659, "latencies_ms": [2012.659], "images_per_second": 0.497, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a series of metal structures with wires and poles, set against a hazy sky. The colors are muted, with the metal structures appearing in shades of silver and gray, while the sky is a pale blue. The lighting is soft and diffused, creating a sense of tranquility.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.5, "ram_available_mb": 109150.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.7, "ram_available_mb": 109142.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.13, 46.13, 46.13, 46.13, 46.13, 47.49, 47.49, 47.49, 47.49, 47.49, 47.12, 47.12, 47.12, 47.12, 47.12, 34.57, 34.57, 34.57, 34.57, 34.57, 34.89], "power_watts_avg": 43.4, "power_watts_peak": 47.49, "energy_joules_est": 87.38, "sample_count": 21, "duration_seconds": 2.013}, "timestamp": "2026-01-12T10:17:08.747085"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1257.139, "latencies_ms": [1257.139], "images_per_second": 0.795, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white toilet, a green stool with a potted plant on it, and a pile of clothes and shoes on the floor.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13363.7, "ram_available_mb": 109142.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13439.8, "ram_available_mb": 109066.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 39.54, 39.54, 39.54, 39.54, 39.54, 45.23, 45.23, 45.23, 45.23, 45.23], "power_watts_avg": 40.65, "power_watts_peak": 45.23, "energy_joules_est": 51.16, "sample_count": 13, "duration_seconds": 1.258}, "timestamp": "2026-01-12T10:17:10.116052"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1337.949, "latencies_ms": [1337.949], "images_per_second": 0.747, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " toilet: 1, shoes: 10, socks: 1, bag: 1, boots: 1, jacket: 1, towel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13431.9, "ram_available_mb": 109074.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.3, "ram_available_mb": 109094.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [40.26, 40.26, 40.26, 40.26, 40.26, 47.42, 47.42, 47.42, 47.42, 47.42, 47.4, 47.4, 47.4, 47.4], "power_watts_avg": 44.86, "power_watts_peak": 47.42, "energy_joules_est": 60.04, "sample_count": 14, "duration_seconds": 1.338}, "timestamp": "2026-01-12T10:17:11.530962"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1958.128, "latencies_ms": [1958.128], "images_per_second": 0.511, "prompt_tokens": 1118, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, with the sink and mirror situated to its right. The shoes are scattered throughout the room, with some near the toilet and others closer to the sink. The clothes are primarily located near the sink, with a few scattered around the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.3, "ram_available_mb": 109094.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13475.0, "ram_available_mb": 109031.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.4, 32.5, 32.5, 32.5, 32.5, 32.5, 47.03, 47.03, 47.03, 47.03, 47.03, 49.7, 49.7, 49.7, 49.7, 49.7, 35.11, 35.11, 35.11, 35.11], "power_watts_avg": 41.7, "power_watts_peak": 49.7, "energy_joules_est": 81.68, "sample_count": 20, "duration_seconds": 1.959}, "timestamp": "2026-01-12T10:17:13.549033"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 923.299, "latencies_ms": [923.299], "images_per_second": 1.083, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A messy bathroom with a toilet, a plant, and a bunch of clothes on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13471.1, "ram_available_mb": 109035.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13467.5, "ram_available_mb": 109038.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [33.14, 33.14, 33.14, 33.14, 33.14, 46.33, 46.33, 46.33, 46.33, 46.33], "power_watts_avg": 39.73, "power_watts_peak": 46.33, "energy_joules_est": 36.71, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-12T10:17:14.609834"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 922.973, "latencies_ms": [922.973], "images_per_second": 1.083, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is lit by natural light coming from a window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13467.5, "ram_available_mb": 109038.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13468.2, "ram_available_mb": 109038.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.3, 46.3, 46.3, 46.3, 46.3, 46.72, 46.72, 46.72, 46.72, 46.72], "power_watts_avg": 46.51, "power_watts_peak": 46.72, "energy_joules_est": 42.96, "sample_count": 10, "duration_seconds": 0.924}, "timestamp": "2026-01-12T10:17:15.621727"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 879.276, "latencies_ms": [879.276], "images_per_second": 1.137, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A polar bear is playing with two green and yellow balls in a pool of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13460.4, "ram_available_mb": 109045.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.96, 46.96, 46.96, 46.96, 46.96, 46.36, 46.36, 46.36, 46.36], "power_watts_avg": 46.69, "power_watts_peak": 46.96, "energy_joules_est": 41.07, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-12T10:17:16.533370"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1089.196, "latencies_ms": [1089.196], "images_per_second": 0.918, "prompt_tokens": 1113, "response_tokens_est": 25, "n_tiles": 1, "output_text": " polar bear: 1, ball: 3, water: 1, rock: 1, sand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.36, 45.92, 45.92, 45.92, 45.92, 45.92, 47.77, 47.77, 47.77, 47.77, 47.77], "power_watts_avg": 46.8, "power_watts_peak": 47.77, "energy_joules_est": 51.01, "sample_count": 11, "duration_seconds": 1.09}, "timestamp": "2026-01-12T10:17:17.644173"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1515.483, "latencies_ms": [1515.483], "images_per_second": 0.66, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The polar bear is in the foreground of the image, with the green and yellow balls in the water in the middle ground. The bear is reaching towards the balls with its mouth, indicating a playful interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13389.0, "ram_available_mb": 109117.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.48, 49.48, 49.48, 49.48, 49.48, 47.64, 47.64, 47.64, 47.64, 47.64, 47.57, 47.57, 47.57, 47.57, 47.57, 34.94], "power_watts_avg": 47.4, "power_watts_peak": 49.48, "energy_joules_est": 71.85, "sample_count": 16, "duration_seconds": 1.516}, "timestamp": "2026-01-12T10:17:19.256179"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1003.933, "latencies_ms": [1003.933], "images_per_second": 0.996, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " In a zoo enclosure, a polar bear is playing with two green and yellow balls in a pool of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.0, "ram_available_mb": 109117.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13479.8, "ram_available_mb": 109026.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.94, 34.94, 34.94, 34.94, 42.39, 42.39, 42.39, 42.39, 42.39, 46.26], "power_watts_avg": 39.8, "power_watts_peak": 46.26, "energy_joules_est": 39.97, "sample_count": 10, "duration_seconds": 1.004}, "timestamp": "2026-01-12T10:17:20.264544"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1392.301, "latencies_ms": [1392.301], "images_per_second": 0.718, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The polar bear is in a pool of water, with a green and yellow ball in its mouth. The lighting is natural, and the bear's fur is wet and matted.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13479.8, "ram_available_mb": 109026.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 46.26, 46.26, 47.94, 47.94, 47.94, 47.94, 47.94, 48.17, 48.17, 48.17, 48.17, 48.17], "power_watts_avg": 47.54, "power_watts_peak": 48.17, "energy_joules_est": 66.21, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-12T10:17:21.676583"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1731.878, "latencies_ms": [1731.878], "images_per_second": 0.577, "prompt_tokens": 1432, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is a split-screen photo showing a person sitting on a chair with their legs crossed, wearing blue socks and jeans, and holding a flip phone, with the phone's screen displaying the time and date.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13400.6, "ram_available_mb": 109105.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.06, 40.06, 40.06, 40.06, 40.06, 45.04, 45.04, 45.04, 45.04, 45.04, 51.74, 51.74, 51.74, 51.74, 51.74, 41.16, 41.16, 41.16], "power_watts_avg": 44.87, "power_watts_peak": 51.74, "energy_joules_est": 77.75, "sample_count": 18, "duration_seconds": 1.733}, "timestamp": "2026-01-12T10:17:23.493206"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1521.2, "latencies_ms": [1521.2], "images_per_second": 0.657, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " chair: 1, person: 1, cell phone: 1, window: 1, floor: 1, legs: 1, socks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.6, "ram_available_mb": 109105.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13372.9, "ram_available_mb": 109133.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [41.16, 41.16, 31.4, 31.4, 31.4, 31.4, 31.4, 50.56, 50.56, 50.56, 50.56, 53.93, 53.93, 53.93, 53.93, 53.93], "power_watts_avg": 44.45, "power_watts_peak": 53.93, "energy_joules_est": 67.64, "sample_count": 16, "duration_seconds": 1.522}, "timestamp": "2026-01-12T10:17:25.113805"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1933.528, "latencies_ms": [1933.528], "images_per_second": 0.517, "prompt_tokens": 1450, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The left side of the image shows a person's legs and feet, with the phone held in the right side of the image. The phone is positioned closer to the camera than the person's legs, which are positioned closer to the camera than the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13382.8, "ram_available_mb": 109123.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [33.41, 33.41, 33.41, 33.41, 33.41, 46.44, 46.44, 46.44, 46.44, 46.44, 51.83, 51.83, 51.83, 51.83, 51.83, 38.62, 38.62, 38.62, 38.62, 38.62], "power_watts_avg": 42.58, "power_watts_peak": 51.83, "energy_joules_est": 82.34, "sample_count": 20, "duration_seconds": 1.934}, "timestamp": "2026-01-12T10:17:27.129291"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1189.439, "latencies_ms": [1189.439], "images_per_second": 0.841, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is sitting on a chair with their feet up on the floor, and they are holding a cell phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.8, "ram_available_mb": 109123.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.1, "ram_available_mb": 109139.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.26, 34.26, 34.26, 34.26, 34.26, 45.99, 45.99, 45.99, 45.99, 45.99, 51.45, 51.45], "power_watts_avg": 42.02, "power_watts_peak": 51.45, "energy_joules_est": 49.99, "sample_count": 12, "duration_seconds": 1.19}, "timestamp": "2026-01-12T10:17:28.346903"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1545.86, "latencies_ms": [1545.86], "images_per_second": 0.647, "prompt_tokens": 1442, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a wooden floor with a blue towel on it, and a person is holding a cell phone. The lighting is natural, coming from a window with a white frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13378.3, "ram_available_mb": 109128.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.45, 51.45, 51.45, 42.48, 42.48, 42.48, 42.48, 42.48, 51.66, 51.66, 51.66, 51.66, 51.66, 48.64, 48.64, 48.64], "power_watts_avg": 48.19, "power_watts_peak": 51.66, "energy_joules_est": 74.5, "sample_count": 16, "duration_seconds": 1.546}, "timestamp": "2026-01-12T10:17:29.962131"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 963.632, "latencies_ms": [963.632], "images_per_second": 1.038, "prompt_tokens": 1432, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A yellow train is traveling down a snowy track with trees on either side.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13404.1, "ram_available_mb": 109102.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [48.64, 48.64, 31.71, 31.71, 31.71, 31.71, 31.71, 50.77, 50.77, 50.77], "power_watts_avg": 40.82, "power_watts_peak": 50.77, "energy_joules_est": 39.37, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-12T10:17:30.980383"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1519.157, "latencies_ms": [1519.157], "images_per_second": 0.658, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " train: 1, trees: 10, snow: 1, sky: 1, birds: 1, signal: 1, wires: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13396.2, "ram_available_mb": 109110.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13397.9, "ram_available_mb": 109108.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [50.77, 50.77, 50.94, 50.94, 50.94, 50.94, 50.94, 50.87, 50.87, 50.87, 50.87, 50.87, 54.24, 54.24, 54.24, 54.24], "power_watts_avg": 51.72, "power_watts_peak": 54.24, "energy_joules_est": 78.59, "sample_count": 16, "duration_seconds": 1.519}, "timestamp": "2026-01-12T10:17:32.599829"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1872.536, "latencies_ms": [1872.536], "images_per_second": 0.534, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The train is moving from the left to the right side of the image, with the tracks running parallel to the viewer's perspective. The trees and power lines are located in the background, while the snow-covered ground is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.9, "ram_available_mb": 109108.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [54.24, 33.18, 33.18, 33.18, 33.18, 46.64, 46.64, 46.64, 46.64, 46.64, 51.95, 51.95, 51.95, 51.95, 51.95, 39.26, 39.26, 39.26, 39.26], "power_watts_avg": 44.05, "power_watts_peak": 54.24, "energy_joules_est": 82.49, "sample_count": 19, "duration_seconds": 1.873}, "timestamp": "2026-01-12T10:17:34.521779"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1052.167, "latencies_ms": [1052.167], "images_per_second": 0.95, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A yellow train is traveling down a snowy track, surrounded by trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.6, "ram_available_mb": 109110.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13411.3, "ram_available_mb": 109095.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.26, 32.67, 32.67, 32.67, 32.67, 32.67, 48.08, 48.08, 48.08, 48.08, 48.08], "power_watts_avg": 40.27, "power_watts_peak": 48.08, "energy_joules_est": 42.41, "sample_count": 11, "duration_seconds": 1.053}, "timestamp": "2026-01-12T10:17:35.689169"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1272.182, "latencies_ms": [1272.182], "images_per_second": 0.786, "prompt_tokens": 1442, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a yellow train traveling down a snowy track, with a gray sky overhead and trees lining the sides of the track.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.4, "ram_available_mb": 109102.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13411.2, "ram_available_mb": 109095.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [52.57, 52.57, 52.57, 52.57, 52.57, 45.91, 45.91, 45.91, 45.91, 45.91, 50.59, 50.59, 50.59], "power_watts_avg": 49.55, "power_watts_peak": 52.57, "energy_joules_est": 63.07, "sample_count": 13, "duration_seconds": 1.273}, "timestamp": "2026-01-12T10:17:37.007992"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1416.528, "latencies_ms": [1416.528], "images_per_second": 0.706, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, a pile of snow has accumulated on the side of a road, with a few people walking in the background, and a black pipe is partially buried in the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.1, "ram_available_mb": 109095.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13390.0, "ram_available_mb": 109116.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [50.59, 40.18, 40.18, 40.18, 40.18, 40.18, 47.11, 47.11, 47.11, 47.11, 47.11, 49.06, 49.06, 49.06, 49.06], "power_watts_avg": 45.55, "power_watts_peak": 50.59, "energy_joules_est": 64.56, "sample_count": 15, "duration_seconds": 1.417}, "timestamp": "2026-01-12T10:17:38.524703"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2040.75, "latencies_ms": [2040.75], "images_per_second": 0.49, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. snow: 3\n2. people: 4\n3. snowbank: 1\n4. pole: 1\n5. building: 1\n6. road: 1\n7. snowplow: 1\n8. snowdrift: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.1, "ram_available_mb": 109124.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13371.0, "ram_available_mb": 109135.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.06, 31.61, 31.61, 31.61, 31.61, 31.61, 46.18, 46.18, 46.18, 46.18, 46.18, 49.67, 49.67, 49.67, 49.67, 49.67, 34.96, 34.96, 34.96, 34.96, 34.96], "power_watts_avg": 41.01, "power_watts_peak": 49.67, "energy_joules_est": 83.72, "sample_count": 21, "duration_seconds": 2.042}, "timestamp": "2026-01-12T10:17:40.641988"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1842.908, "latencies_ms": [1842.908], "images_per_second": 0.543, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the snow-covered ground and the two metal poles being the closest to the viewer. The people are in the background, walking away from the camera, and the wooden building is further in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.1, "ram_available_mb": 109143.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.5, 34.5, 34.5, 34.5, 34.5, 44.34, 44.34, 44.34, 44.34, 44.34, 45.67, 45.67, 45.67, 45.67, 45.67, 36.08, 36.08, 36.08, 36.08], "power_watts_avg": 40.36, "power_watts_peak": 45.67, "energy_joules_est": 74.41, "sample_count": 19, "duration_seconds": 1.843}, "timestamp": "2026-01-12T10:17:42.611590"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1126.207, "latencies_ms": [1126.207], "images_per_second": 0.888, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In a snowy urban setting, a pile of snow has accumulated on the side of a road, with several people walking past it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13374.4, "ram_available_mb": 109131.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.67, 33.67, 33.67, 33.67, 33.67, 45.78, 45.78, 45.78, 45.78, 45.78, 46.8, 46.8], "power_watts_avg": 40.91, "power_watts_peak": 46.8, "energy_joules_est": 46.11, "sample_count": 12, "duration_seconds": 1.127}, "timestamp": "2026-01-12T10:17:43.875670"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1492.864, "latencies_ms": [1492.864], "images_per_second": 0.67, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a snowy scene with a pile of snow in the foreground, and people walking in the background. The snow is white and fluffy, and the lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13381.2, "ram_available_mb": 109125.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.8, 46.8, 46.8, 37.98, 37.98, 37.98, 37.98, 37.98, 46.58, 46.58, 46.58, 46.58, 46.58, 44.27, 44.27], "power_watts_avg": 43.45, "power_watts_peak": 46.8, "energy_joules_est": 64.88, "sample_count": 15, "duration_seconds": 1.493}, "timestamp": "2026-01-12T10:17:45.389745"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 784.87, "latencies_ms": [784.87], "images_per_second": 1.274, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A no parking sign is on a pole in a wooded area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13377.3, "ram_available_mb": 109129.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13382.4, "ram_available_mb": 109123.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 50.0}, "power_stats": {"power_watts_samples": [44.27, 44.27, 44.27, 37.46, 37.46, 37.46, 37.46, 37.46], "power_watts_avg": 40.01, "power_watts_peak": 44.27, "energy_joules_est": 31.43, "sample_count": 8, "duration_seconds": 0.785}, "timestamp": "2026-01-12T10:17:46.201801"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1943.049, "latencies_ms": [1943.049], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 1\n2. pole: 1\n3. tree: 2\n4. building: 1\n5. street light: 1\n6. fence: 1\n7. umbrella: 1\n8. leaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.5, "ram_available_mb": 109131.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13371.2, "ram_available_mb": 109135.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.38, 47.38, 47.38, 47.38, 47.38, 56.09, 56.09, 56.09, 56.09, 56.09, 47.79, 47.79, 47.79, 47.79, 37.59, 37.59, 37.59, 37.59, 37.59, 34.88], "power_watts_avg": 46.57, "power_watts_peak": 56.09, "energy_joules_est": 90.49, "sample_count": 20, "duration_seconds": 1.943}, "timestamp": "2026-01-12T10:17:48.221047"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1373.803, "latencies_ms": [1373.803], "images_per_second": 0.728, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sign is located on the right side of the image, while the tree is on the left side. The sign is in the foreground, and the tree is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13380.1, "ram_available_mb": 109126.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 41.46, 41.46, 41.46, 41.46, 41.46, 45.95, 45.95, 45.95, 45.95, 45.95], "power_watts_avg": 41.18, "power_watts_peak": 45.95, "energy_joules_est": 56.61, "sample_count": 14, "duration_seconds": 1.375}, "timestamp": "2026-01-12T10:17:49.686884"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 801.673, "latencies_ms": [801.673], "images_per_second": 1.247, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A no parking sign is posted on a pole in a residential area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.1, "ram_available_mb": 109130.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13376.8, "ram_available_mb": 109129.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.25, 40.25, 40.25, 40.25, 40.25, 46.42, 46.42, 46.42], "power_watts_avg": 42.56, "power_watts_peak": 46.42, "energy_joules_est": 34.15, "sample_count": 8, "duration_seconds": 0.802}, "timestamp": "2026-01-12T10:17:50.496519"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1092.026, "latencies_ms": [1092.026], "images_per_second": 0.916, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a street scene with a no parking sign, a yellow and black umbrella, and a tree with green leaves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.0, "ram_available_mb": 109137.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13377.6, "ram_available_mb": 109128.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 46.0}, "power_stats": {"power_watts_samples": [46.42, 46.42, 45.98, 45.98, 45.98, 45.98, 45.98, 49.12, 49.12, 49.12, 49.12], "power_watts_avg": 47.2, "power_watts_peak": 49.12, "energy_joules_est": 51.57, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-12T10:17:51.609441"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1221.933, "latencies_ms": [1221.933], "images_per_second": 0.818, "prompt_tokens": 1100, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A stuffed teddy bear wearing glasses and headphones is sitting on a red desk with a keyboard, a microphone, and a tape recorder in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.7, "ram_available_mb": 109136.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.44, 49.44, 49.44, 49.44, 49.44, 47.79, 47.79, 47.79, 47.79, 47.79, 47.84, 47.84, 47.84], "power_watts_avg": 48.43, "power_watts_peak": 49.44, "energy_joules_est": 59.21, "sample_count": 13, "duration_seconds": 1.222}, "timestamp": "2026-01-12T10:17:52.924783"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1463.004, "latencies_ms": [1463.004], "images_per_second": 0.684, "prompt_tokens": 1114, "response_tokens_est": 38, "n_tiles": 1, "output_text": " teddy bear: 1\nglasses: 1\nkeyboard: 1\ncamera: 1\nmic: 1\nremote: 1\ncomputer mouse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.2, "ram_available_mb": 109144.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.84, 47.84, 33.31, 33.31, 33.31, 33.31, 33.31, 46.02, 46.02, 46.02, 46.02, 46.02, 47.6, 47.6, 47.6], "power_watts_avg": 42.34, "power_watts_peak": 47.84, "energy_joules_est": 61.96, "sample_count": 15, "duration_seconds": 1.463}, "timestamp": "2026-01-12T10:17:54.443805"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1590.755, "latencies_ms": [1590.755], "images_per_second": 0.629, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The teddy bear is positioned in the foreground, with the keyboard and microphone placed in front of it. The teddy bear is located to the left of the keyboard, and the microphone is positioned to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.6, 47.6, 34.94, 34.94, 34.94, 34.94, 34.94, 47.02, 47.02, 47.02, 47.02, 47.02, 47.19, 47.19, 47.19, 47.19], "power_watts_avg": 43.36, "power_watts_peak": 47.6, "energy_joules_est": 69.0, "sample_count": 16, "duration_seconds": 1.591}, "timestamp": "2026-01-12T10:17:56.060869"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 962.737, "latencies_ms": [962.737], "images_per_second": 1.039, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A teddy bear wearing glasses and headphones is sitting on a desk with a keyboard in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.3, "ram_available_mb": 109143.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13379.8, "ram_available_mb": 109126.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [47.19, 33.79, 33.79, 33.79, 33.79, 33.79, 47.79, 47.79, 47.79, 47.79], "power_watts_avg": 40.73, "power_watts_peak": 47.79, "energy_joules_est": 39.23, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-12T10:17:57.071914"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 911.669, "latencies_ms": [911.669], "images_per_second": 1.097, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The teddy bear is beige, the keyboard is black, and the background is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.8, "ram_available_mb": 109130.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13384.4, "ram_available_mb": 109121.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [47.79, 46.93, 46.93, 46.93, 46.93, 46.93, 47.3, 47.3, 47.3, 47.3], "power_watts_avg": 47.16, "power_watts_peak": 47.79, "energy_joules_est": 43.01, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-12T10:17:58.081959"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2077.588, "latencies_ms": [2077.588], "images_per_second": 0.481, "prompt_tokens": 1432, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image captures a daring skier in mid-air, performing an impressive flip over a snowy mountain peak, with the date \"27 Feb 2010\" and the phrase \"Tour de Sas\" displayed at the bottom, indicating the event and location.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13376.5, "ram_available_mb": 109129.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13392.3, "ram_available_mb": 109114.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.3, 46.59, 46.59, 46.59, 46.59, 46.59, 48.65, 48.65, 48.65, 48.65, 48.65, 51.96, 51.96, 51.96, 51.96, 51.96, 36.23, 36.23, 36.23, 36.23, 36.23], "power_watts_avg": 45.93, "power_watts_peak": 51.96, "energy_joules_est": 95.44, "sample_count": 21, "duration_seconds": 2.078}, "timestamp": "2026-01-12T10:18:00.205447"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2075.015, "latencies_ms": [2075.015], "images_per_second": 0.482, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skis: 2\n2. person: 1\n3. mountain: 1\n4. snow: 1\n5. trees: 1\n6. sky: 1\n7. text: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.3, "ram_available_mb": 109114.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13370.7, "ram_available_mb": 109135.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 41.33, 41.33, 41.33, 41.33, 41.33, 50.62, 50.62, 50.62, 50.62, 50.62, 44.15, 44.15, 44.15, 44.15, 44.15, 35.32, 35.32], "power_watts_avg": 42.41, "power_watts_peak": 50.62, "energy_joules_est": 88.04, "sample_count": 21, "duration_seconds": 2.076}, "timestamp": "2026-01-12T10:18:02.377673"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1571.835, "latencies_ms": [1571.835], "images_per_second": 0.636, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skier is in the foreground, with the mountain and trees in the background. The skier is to the left of the mountain, and the skis are to the right.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13370.7, "ram_available_mb": 109135.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13346.2, "ram_available_mb": 109160.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.32, 35.32, 33.99, 33.99, 33.99, 33.99, 33.99, 50.3, 50.3, 50.3, 50.3, 50.3, 52.02, 52.02, 52.02, 52.02], "power_watts_avg": 43.76, "power_watts_peak": 52.02, "energy_joules_est": 68.82, "sample_count": 16, "duration_seconds": 1.573}, "timestamp": "2026-01-12T10:18:04.048698"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1050.946, "latencies_ms": [1050.946], "images_per_second": 0.952, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A skier is performing a trick in the snow, wearing a white and orange outfit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.2, "ram_available_mb": 109160.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13370.9, "ram_available_mb": 109135.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [52.02, 32.83, 32.83, 32.83, 32.83, 32.83, 51.31, 51.31, 51.31, 51.31, 51.31], "power_watts_avg": 42.97, "power_watts_peak": 52.02, "energy_joules_est": 45.17, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-12T10:18:05.159081"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2127.306, "latencies_ms": [2127.306], "images_per_second": 0.47, "prompt_tokens": 1442, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a skier in an orange and white outfit, with skis in the air, against a backdrop of a snowy mountain and clear blue sky. The lighting is bright and natural, suggesting daytime, and the snow appears to be freshly fallen, giving it a pristine white appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.4, "ram_available_mb": 109139.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.6, "ram_available_mb": 109141.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [53.31, 53.31, 53.31, 53.31, 53.31, 46.96, 46.96, 46.96, 46.96, 46.96, 51.41, 51.41, 51.41, 51.41, 51.41, 39.66, 39.66, 39.66, 39.66, 39.66, 34.95, 34.95], "power_watts_avg": 46.66, "power_watts_peak": 53.31, "energy_joules_est": 99.28, "sample_count": 22, "duration_seconds": 2.128}, "timestamp": "2026-01-12T10:18:07.378399"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1535.505, "latencies_ms": [1535.505], "images_per_second": 0.651, "prompt_tokens": 1432, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, there are two surfers riding the waves in the ocean, with one surfer positioned closer to the camera and the other further away, both skillfully navigating the waves.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13381.5, "ram_available_mb": 109124.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.95, 34.95, 32.89, 32.89, 32.89, 32.89, 32.89, 49.22, 49.22, 49.22, 49.22, 49.22, 52.31, 52.31, 52.31, 52.31], "power_watts_avg": 43.11, "power_watts_peak": 52.31, "energy_joules_est": 66.22, "sample_count": 16, "duration_seconds": 1.536}, "timestamp": "2026-01-12T10:18:09.053231"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1937.679, "latencies_ms": [1937.679], "images_per_second": 0.516, "prompt_tokens": 1446, "response_tokens_est": 51, "n_tiles": 1, "output_text": " 1. surfboard: 2\n2. wave: 2\n3. surfer: 2\n4. ocean: 2\n5. sky: 1\n6. sun: 1\n7. water: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.5, "ram_available_mb": 109124.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [52.31, 32.59, 32.59, 32.59, 32.59, 32.59, 50.57, 50.57, 50.57, 50.57, 50.57, 53.44, 53.44, 53.44, 53.44, 53.44, 35.21, 35.21, 35.21, 35.21], "power_watts_avg": 43.81, "power_watts_peak": 53.44, "energy_joules_est": 84.9, "sample_count": 20, "duration_seconds": 1.938}, "timestamp": "2026-01-12T10:18:11.067001"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2217.409, "latencies_ms": [2217.409], "images_per_second": 0.451, "prompt_tokens": 1450, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The surfer on the left is closer to the camera than the surfer on the right. The surfer on the left is in the foreground, while the surfer on the right is in the background. The surfer on the left is closer to the camera than the surfer on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.1, "ram_available_mb": 109144.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [32.74, 32.74, 32.74, 32.74, 32.74, 46.9, 46.9, 46.9, 46.9, 46.9, 52.18, 52.18, 52.18, 52.18, 52.18, 38.83, 38.83, 38.83, 38.83, 38.83, 34.91, 34.91], "power_watts_avg": 41.96, "power_watts_peak": 52.18, "energy_joules_est": 93.07, "sample_count": 22, "duration_seconds": 2.218}, "timestamp": "2026-01-12T10:18:13.343298"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1085.019, "latencies_ms": [1085.019], "images_per_second": 0.922, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two surfers are riding the waves on the ocean, with the sun setting in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13374.9, "ram_available_mb": 109131.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 24.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 34.91, 35.92, 35.92, 35.92, 35.92, 35.92, 50.97, 50.97, 50.97], "power_watts_avg": 39.75, "power_watts_peak": 50.97, "energy_joules_est": 43.18, "sample_count": 11, "duration_seconds": 1.086}, "timestamp": "2026-01-12T10:18:14.512455"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2381.064, "latencies_ms": [2381.064], "images_per_second": 0.42, "prompt_tokens": 1442, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures the dynamic interaction between the surfer and the ocean, with the surfer riding a wave and the ocean's vastness and power. The lighting is natural, with the sun casting a warm glow on the scene, and the colors are vibrant, with the blue of the ocean and the white of the waves standing out.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13365.5, "ram_available_mb": 109140.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13368.4, "ram_available_mb": 109137.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [50.97, 48.01, 48.01, 48.01, 48.01, 48.01, 51.66, 51.66, 51.66, 51.66, 51.66, 54.32, 54.32, 54.32, 54.32, 54.32, 35.07, 35.07, 35.07, 35.07, 35.07, 35.01, 35.01, 35.01], "power_watts_avg": 45.89, "power_watts_peak": 54.32, "energy_joules_est": 109.29, "sample_count": 24, "duration_seconds": 2.382}, "timestamp": "2026-01-12T10:18:16.937162"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1467.194, "latencies_ms": [1467.194], "images_per_second": 0.682, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A pizza with a variety of toppings is placed on a metal tray, accompanied by a jar of pepperoni and a bottle of sauce, all set on a table with a blue tablecloth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13368.4, "ram_available_mb": 109137.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.5, "ram_available_mb": 109143.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 35.67, 35.67, 35.67, 35.67, 35.67, 47.22, 47.22, 47.22, 47.22, 47.22, 46.36, 46.36, 46.36], "power_watts_avg": 41.57, "power_watts_peak": 47.22, "energy_joules_est": 61.0, "sample_count": 15, "duration_seconds": 1.467}, "timestamp": "2026-01-12T10:18:18.451609"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1363.756, "latencies_ms": [1363.756], "images_per_second": 0.733, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " pizza: 1, plate: 1, pepperoni: 1, cheese: 1, sauce: 1, crust: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.6, "ram_available_mb": 109151.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13364.4, "ram_available_mb": 109141.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.36, 46.36, 35.34, 35.34, 35.34, 35.34, 35.34, 47.37, 47.37, 47.37, 47.37, 47.37, 46.78, 46.78], "power_watts_avg": 42.85, "power_watts_peak": 47.37, "energy_joules_est": 58.44, "sample_count": 14, "duration_seconds": 1.364}, "timestamp": "2026-01-12T10:18:19.864429"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1735.39, "latencies_ms": [1735.39], "images_per_second": 0.576, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the pepperoni and cheese visible. The pepperoni and cheese are on the pizza, which is on the table. The table is in the background, with the pizza and pepperoni and cheese on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13368.3, "ram_available_mb": 109138.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.78, 46.78, 46.78, 39.12, 39.12, 39.12, 39.12, 39.12, 47.38, 47.38, 47.38, 47.38, 47.38, 42.85, 42.85, 42.85, 42.85, 42.85], "power_watts_avg": 43.73, "power_watts_peak": 47.38, "energy_joules_est": 75.9, "sample_count": 18, "duration_seconds": 1.736}, "timestamp": "2026-01-12T10:18:21.677701"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1831.529, "latencies_ms": [1831.529], "images_per_second": 0.546, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " In a dimly lit restaurant, a delicious pizza sits on a metal tray, accompanied by a jar of pepperoni sauce and a napkin. The pizza boasts a golden crust, topped with melted cheese, and a variety of toppings that add to its appeal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.4, "ram_available_mb": 109145.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.55, 34.55, 34.55, 34.55, 34.55, 46.45, 46.45, 46.45, 46.45, 46.45, 46.91, 46.91, 46.91, 46.91, 46.91, 34.97, 34.97, 34.97, 34.97], "power_watts_avg": 41.02, "power_watts_peak": 46.91, "energy_joules_est": 75.15, "sample_count": 19, "duration_seconds": 1.832}, "timestamp": "2026-01-12T10:18:23.591459"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1044.242, "latencies_ms": [1044.242], "images_per_second": 0.958, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The pizza is on a metal tray with a blue tablecloth, and the table is lit by a red light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.5, "ram_available_mb": 109146.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [33.03, 33.03, 33.03, 33.03, 33.03, 45.6, 45.6, 45.6, 45.6, 45.6, 47.54], "power_watts_avg": 40.06, "power_watts_peak": 47.54, "energy_joules_est": 41.88, "sample_count": 11, "duration_seconds": 1.045}, "timestamp": "2026-01-12T10:18:24.755580"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 909.446, "latencies_ms": [909.446], "images_per_second": 1.1, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A clock with Roman numerals is on a pole, and the street is covered in snow.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13369.4, "ram_available_mb": 109136.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13377.4, "ram_available_mb": 109128.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.54, 47.54, 47.54, 47.54, 43.33, 43.33, 43.33, 43.33, 43.33, 46.66], "power_watts_avg": 45.35, "power_watts_peak": 47.54, "energy_joules_est": 41.27, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-12T10:18:25.770900"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1911.334, "latencies_ms": [1911.334], "images_per_second": 0.523, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. clock: 1\n2. street: 1\n3. snow: 1\n4. building: 1\n5. pole: 1\n6. sidewalk: 1\n7. street light: 1\n8. tree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.4, "ram_available_mb": 109128.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.66, 46.66, 46.66, 46.66, 46.19, 46.19, 46.19, 46.19, 46.19, 46.45, 46.45, 46.45, 46.45, 46.45, 38.7, 38.7, 38.7, 38.7, 38.7, 35.25], "power_watts_avg": 43.93, "power_watts_peak": 46.66, "energy_joules_est": 83.99, "sample_count": 20, "duration_seconds": 1.912}, "timestamp": "2026-01-12T10:18:27.786516"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1486.589, "latencies_ms": [1486.589], "images_per_second": 0.673, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The clock is positioned on the left side of the image, with the street and buildings extending into the background. The clock is in the foreground, with the street and buildings receding into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.5, "ram_available_mb": 109159.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13343.0, "ram_available_mb": 109163.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.25, 35.25, 35.25, 35.25, 42.23, 42.23, 42.23, 42.23, 42.23, 46.4, 46.4, 46.4, 46.4, 46.4, 39.15], "power_watts_avg": 41.55, "power_watts_peak": 46.4, "energy_joules_est": 61.79, "sample_count": 15, "duration_seconds": 1.487}, "timestamp": "2026-01-12T10:18:29.300354"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1942.193, "latencies_ms": [1942.193], "images_per_second": 0.515, "prompt_tokens": 1112, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a serene winter scene on a street corner, where a black clock tower stands tall against the backdrop of a clear blue sky. The clock, adorned with a gold face and black numbers, silently marks the passage of time amidst the quietude of the snow-covered sidewalk.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13339.1, "ram_available_mb": 109167.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13349.7, "ram_available_mb": 109156.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [39.15, 39.15, 39.15, 39.15, 42.74, 42.74, 42.74, 42.74, 42.74, 47.56, 47.56, 47.56, 47.56, 47.56, 40.44, 40.44, 40.44, 40.44, 40.44, 34.84], "power_watts_avg": 42.26, "power_watts_peak": 47.56, "energy_joules_est": 82.09, "sample_count": 20, "duration_seconds": 1.943}, "timestamp": "2026-01-12T10:18:31.319679"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 843.273, "latencies_ms": [843.273], "images_per_second": 1.186, "prompt_tokens": 1110, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The clock is black with white numbers and hands, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13349.7, "ram_available_mb": 109156.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13417.9, "ram_available_mb": 109088.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.84, 37.91, 37.91, 37.91, 37.91, 37.91, 45.99], "power_watts_avg": 37.78, "power_watts_peak": 45.99, "energy_joules_est": 31.89, "sample_count": 9, "duration_seconds": 0.844}, "timestamp": "2026-01-12T10:18:32.278692"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1056.302, "latencies_ms": [1056.302], "images_per_second": 0.947, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A baseball player wearing a blue helmet and white uniform is swinging a bat at a baseball that is in mid-air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.0, "ram_available_mb": 109096.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13313.6, "ram_available_mb": 109192.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.99, 45.99, 45.99, 45.99, 50.94, 50.94, 50.94, 50.94, 50.94, 46.84, 46.84], "power_watts_avg": 48.4, "power_watts_peak": 50.94, "energy_joules_est": 51.17, "sample_count": 11, "duration_seconds": 1.057}, "timestamp": "2026-01-12T10:18:33.393769"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2380.747, "latencies_ms": [2380.747], "images_per_second": 0.42, "prompt_tokens": 1113, "response_tokens_est": 74, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball: 1\n3. catcher's mitt: 1\n4. baseball player: 1\n5. baseball player's uniform: 1\n6. baseball player's helmet: 1\n7. baseball player's glove: 1\n8. baseball player's pants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.6, "ram_available_mb": 109192.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13358.7, "ram_available_mb": 109147.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.84, 46.84, 46.84, 43.16, 43.16, 43.16, 43.16, 43.16, 47.16, 47.16, 47.16, 47.16, 47.16, 44.12, 44.12, 44.12, 44.12, 44.12, 34.89, 34.89, 34.89, 34.89, 34.89, 34.9], "power_watts_avg": 42.59, "power_watts_peak": 47.16, "energy_joules_est": 101.4, "sample_count": 24, "duration_seconds": 2.381}, "timestamp": "2026-01-12T10:18:35.816419"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1721.344, "latencies_ms": [1721.344], "images_per_second": 0.581, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The batter is in the foreground, the catcher is in the background, and the ball is in the middle ground. The batter is closer to the camera than the catcher, and the ball is closer to the batter than the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.9, "ram_available_mb": 109155.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 38.68, 38.68, 38.68, 38.68, 38.68, 46.42, 46.42, 46.42, 46.42, 46.42, 42.77, 42.77, 42.77, 42.77, 42.77], "power_watts_avg": 41.34, "power_watts_peak": 46.42, "energy_joules_est": 71.18, "sample_count": 18, "duration_seconds": 1.722}, "timestamp": "2026-01-12T10:18:37.683926"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1443.614, "latencies_ms": [1443.614], "images_per_second": 0.693, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A baseball player wearing a blue helmet and white uniform is swinging a bat at a baseball. A catcher in a red uniform is crouched behind him, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13401.6, "ram_available_mb": 109104.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.42, 34.42, 34.42, 34.42, 34.42, 46.15, 46.15, 46.15, 46.15, 46.15, 46.86, 46.86, 46.86, 46.86, 46.86], "power_watts_avg": 42.47, "power_watts_peak": 46.86, "energy_joules_est": 61.33, "sample_count": 15, "duration_seconds": 1.444}, "timestamp": "2026-01-12T10:18:39.199831"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2284.843, "latencies_ms": [2284.843], "images_per_second": 0.438, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter in full swing, the catcher poised to catch the ball, and the field bathed in the warm glow of sunlight. The colors are vibrant, with the blue of the batter's uniform standing out against the green of the field and the red of the catcher's uniform.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.7, "ram_available_mb": 109112.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13386.6, "ram_available_mb": 109119.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 34.82, 34.82, 34.82, 46.02, 46.02, 46.02, 46.02, 46.02, 46.55, 46.55, 46.55, 46.55, 46.55, 36.49, 36.49, 36.49, 36.49, 36.49, 34.81, 34.81, 34.81], "power_watts_avg": 40.17, "power_watts_peak": 46.55, "energy_joules_est": 91.8, "sample_count": 23, "duration_seconds": 2.285}, "timestamp": "2026-01-12T10:18:41.519820"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 931.658, "latencies_ms": [931.658], "images_per_second": 1.073, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A brown teddy bear with a red bow tie is sitting on a chair with a red cushion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.9, "ram_available_mb": 109118.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13442.6, "ram_available_mb": 109063.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 43.0}, "power_stats": {"power_watts_samples": [34.81, 32.47, 32.47, 32.47, 32.47, 32.47, 46.4, 46.4, 46.4, 46.4], "power_watts_avg": 38.27, "power_watts_peak": 46.4, "energy_joules_est": 35.7, "sample_count": 10, "duration_seconds": 0.933}, "timestamp": "2026-01-12T10:18:42.584564"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1094.115, "latencies_ms": [1094.115], "images_per_second": 0.914, "prompt_tokens": 1114, "response_tokens_est": 25, "n_tiles": 1, "output_text": " chair: 1, teddy bear: 1, cushion: 1, curtain: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13438.7, "ram_available_mb": 109067.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13424.1, "ram_available_mb": 109082.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.4, 46.99, 46.99, 46.99, 46.99, 46.99, 46.81, 46.81, 46.81, 46.81, 46.81], "power_watts_avg": 46.86, "power_watts_peak": 46.99, "energy_joules_est": 51.28, "sample_count": 11, "duration_seconds": 1.094}, "timestamp": "2026-01-12T10:18:43.697381"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1471.107, "latencies_ms": [1471.107], "images_per_second": 0.68, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The teddy bear is positioned on the left side of the chair, which is located in the middle of the image. The chair is situated in the foreground, with the background featuring a striped curtain.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13424.1, "ram_available_mb": 109082.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.5, "ram_available_mb": 109118.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.81, 48.81, 48.81, 48.81, 48.81, 47.19, 47.19, 47.19, 47.19, 47.19, 47.65, 47.65, 47.65, 47.65, 47.65], "power_watts_avg": 47.88, "power_watts_peak": 48.81, "energy_joules_est": 70.47, "sample_count": 15, "duration_seconds": 1.472}, "timestamp": "2026-01-12T10:18:45.213165"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 782.186, "latencies_ms": [782.186], "images_per_second": 1.278, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A teddy bear is sitting on a chair with a red cushion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.5, "ram_available_mb": 109118.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13400.4, "ram_available_mb": 109105.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.23, 35.23, 35.23, 35.23, 35.23, 46.14, 46.14, 46.14], "power_watts_avg": 39.32, "power_watts_peak": 46.14, "energy_joules_est": 30.78, "sample_count": 8, "duration_seconds": 0.783}, "timestamp": "2026-01-12T10:18:46.023556"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1063.368, "latencies_ms": [1063.368], "images_per_second": 0.94, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The teddy bear is brown and has a red bow tie. The chair is made of wood and has a red cushion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.4, "ram_available_mb": 109105.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13386.9, "ram_available_mb": 109119.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.14, 45.21, 45.21, 45.21, 45.21, 45.21, 48.77, 48.77, 48.77, 48.77, 48.77], "power_watts_avg": 46.92, "power_watts_peak": 48.77, "energy_joules_est": 49.91, "sample_count": 11, "duration_seconds": 1.064}, "timestamp": "2026-01-12T10:18:47.133645"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 887.581, "latencies_ms": [887.581], "images_per_second": 1.127, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain with a bright sun shining in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.9, "ram_available_mb": 109119.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13423.1, "ram_available_mb": 109083.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [48.94, 48.94, 48.94, 48.94, 48.94, 47.38, 47.38, 47.38, 47.38], "power_watts_avg": 48.25, "power_watts_peak": 48.94, "energy_joules_est": 42.83, "sample_count": 9, "duration_seconds": 0.888}, "timestamp": "2026-01-12T10:18:48.044606"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1945.768, "latencies_ms": [1945.768], "images_per_second": 0.514, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. person: 2\n3. helmet: 1\n4. goggles: 1\n5. sun: 1\n6. rock: 1\n7. snow: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.2, "ram_available_mb": 109091.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13416.8, "ram_available_mb": 109089.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.38, 45.45, 45.45, 45.45, 45.45, 45.45, 47.57, 47.57, 47.57, 47.57, 47.57, 49.67, 49.67, 49.67, 49.67, 49.67, 34.73, 34.73, 34.73, 34.73], "power_watts_avg": 44.99, "power_watts_peak": 49.67, "energy_joules_est": 87.55, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T10:18:50.059929"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2131.877, "latencies_ms": [2131.877], "images_per_second": 0.469, "prompt_tokens": 1118, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The person on the left is standing closer to the camera than the person on the right. The person on the right is standing in the background, while the person on the left is standing in the foreground. The person on the right is holding a snowboard, while the person on the left is holding a snowboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.8, "ram_available_mb": 109089.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13389.9, "ram_available_mb": 109116.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.73, 32.43, 32.43, 32.43, 32.43, 32.43, 45.85, 45.85, 45.85, 45.85, 45.85, 48.13, 48.13, 48.13, 48.13, 48.13, 34.83, 34.83, 34.83, 34.83, 34.83, 34.84], "power_watts_avg": 39.81, "power_watts_peak": 48.13, "energy_joules_est": 84.88, "sample_count": 22, "duration_seconds": 2.132}, "timestamp": "2026-01-12T10:18:52.328082"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1010.054, "latencies_ms": [1010.054], "images_per_second": 0.99, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two snowboarders stand on a snowy mountain, one holding a snowboard and the other wearing a helmet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.9, "ram_available_mb": 109116.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13404.1, "ram_available_mb": 109102.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 66.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.84, 36.94, 36.94, 36.94, 36.94, 36.94, 45.63, 45.63, 45.63], "power_watts_avg": 38.74, "power_watts_peak": 45.63, "energy_joules_est": 39.17, "sample_count": 11, "duration_seconds": 1.011}, "timestamp": "2026-01-12T10:18:53.491613"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1377.09, "latencies_ms": [1377.09], "images_per_second": 0.726, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features two individuals standing on a snow-covered mountain, with the sun shining brightly in the background. The sky is clear and blue, and the snow is pristine white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.1, "ram_available_mb": 109102.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13405.0, "ram_available_mb": 109101.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [45.63, 45.63, 42.14, 42.14, 42.14, 42.14, 42.14, 46.33, 46.33, 46.33, 46.33, 46.33, 48.49, 48.49], "power_watts_avg": 45.04, "power_watts_peak": 48.49, "energy_joules_est": 62.05, "sample_count": 14, "duration_seconds": 1.378}, "timestamp": "2026-01-12T10:18:54.907552"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1665.831, "latencies_ms": [1665.831], "images_per_second": 0.6, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a serene autumn scene, where a tree laden with ripe red apples stands tall, its branches adorned with a few remaining leaves, while the background is a blur of trees and foliage, creating a sense of depth and tranquility.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13397.1, "ram_available_mb": 109109.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13320.6, "ram_available_mb": 109185.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.49, 48.49, 48.49, 37.47, 37.47, 37.47, 37.47, 37.47, 47.28, 47.28, 47.28, 47.28, 47.28, 44.98, 44.98, 44.98, 44.98], "power_watts_avg": 44.07, "power_watts_peak": 48.49, "energy_joules_est": 73.42, "sample_count": 17, "duration_seconds": 1.666}, "timestamp": "2026-01-12T10:18:56.627971"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1061.899, "latencies_ms": [1061.899], "images_per_second": 0.942, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " apple: 5, tree: 1, branch: 1, leaf: 1, hole: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.6, "ram_available_mb": 109185.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13340.8, "ram_available_mb": 109165.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.3, 34.3, 34.3, 34.3, 34.3, 47.44, 47.44, 47.44, 47.44, 47.44, 48.07], "power_watts_avg": 41.52, "power_watts_peak": 48.07, "energy_joules_est": 44.11, "sample_count": 11, "duration_seconds": 1.062}, "timestamp": "2026-01-12T10:18:57.740522"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1548.977, "latencies_ms": [1548.977], "images_per_second": 0.646, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The apples are located in the foreground of the image, with the tree trunk positioned in the middle ground. The background is filled with a blurred forest scene, providing a sense of depth and scale to the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.8, "ram_available_mb": 109169.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13324.4, "ram_available_mb": 109181.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.07, 48.07, 48.07, 48.07, 44.54, 44.54, 44.54, 44.54, 44.54, 47.16, 47.16, 47.16, 47.16, 47.16, 37.37, 37.37], "power_watts_avg": 45.34, "power_watts_peak": 48.07, "energy_joules_est": 70.24, "sample_count": 16, "duration_seconds": 1.549}, "timestamp": "2026-01-12T10:18:59.354845"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1488.496, "latencies_ms": [1488.496], "images_per_second": 0.672, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a serene autumn scene in a forest where a tree stands tall with its branches laden with ripe red apples. The warm sunlight filters through the leaves, casting a soft glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.5, "ram_available_mb": 109189.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13340.8, "ram_available_mb": 109165.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [37.37, 37.37, 37.37, 39.46, 39.46, 39.46, 39.46, 39.46, 46.95, 46.95, 46.95, 46.95, 46.95, 43.03, 43.03], "power_watts_avg": 42.01, "power_watts_peak": 46.95, "energy_joules_est": 62.55, "sample_count": 15, "duration_seconds": 1.489}, "timestamp": "2026-01-12T10:19:00.868738"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1599.299, "latencies_ms": [1599.299], "images_per_second": 0.625, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a tree with a hole in its trunk, surrounded by a warm, golden light. The apples hanging from the tree are a vibrant red color, and the leaves are a mix of green and brown hues.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.3, "ram_available_mb": 109175.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13334.7, "ram_available_mb": 109171.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [43.03, 43.03, 43.03, 39.5, 39.5, 39.5, 39.5, 39.5, 47.53, 47.53, 47.53, 47.53, 47.53, 43.75, 43.75, 43.75], "power_watts_avg": 43.47, "power_watts_peak": 47.53, "energy_joules_est": 69.55, "sample_count": 16, "duration_seconds": 1.6}, "timestamp": "2026-01-12T10:19:02.484372"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1026.023, "latencies_ms": [1026.023], "images_per_second": 0.975, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two men in white shirts are working in a kitchen, one of them is preparing food in a frying pan.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13333.0, "ram_available_mb": 109173.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 31.0}, "power_stats": {"power_watts_samples": [43.75, 43.75, 34.61, 34.61, 34.61, 34.61, 34.61, 47.56, 47.56, 47.56, 47.56], "power_watts_avg": 40.98, "power_watts_peak": 47.56, "energy_joules_est": 42.07, "sample_count": 11, "duration_seconds": 1.027}, "timestamp": "2026-01-12T10:19:03.598568"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1516.614, "latencies_ms": [1516.614], "images_per_second": 0.659, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. Kitchen counter\n2. Food containers\n3. Pots\n4. Pans\n5. Utensils\n6. Food trays\n7. Kitchen equipment\n8. Shelves", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.56, 46.61, 46.61, 46.61, 46.61, 46.61, 46.48, 46.48, 46.48, 46.48, 46.48, 48.47, 48.47, 48.47, 48.47, 48.47], "power_watts_avg": 47.21, "power_watts_peak": 48.47, "energy_joules_est": 71.61, "sample_count": 16, "duration_seconds": 1.517}, "timestamp": "2026-01-12T10:19:05.210422"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1856.956, "latencies_ms": [1856.956], "images_per_second": 0.539, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man in the foreground is closer to the camera than the man in the background. The man in the foreground is to the left of the man in the background. The man in the foreground is near the counter, while the man in the background is near the stove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.5, "ram_available_mb": 109134.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 34.9, 34.9, 45.35, 45.35, 45.35, 45.35, 45.35, 46.55, 46.55, 46.55, 46.55, 46.55, 35.9, 35.9, 35.9, 35.9], "power_watts_avg": 40.93, "power_watts_peak": 46.55, "energy_joules_est": 76.01, "sample_count": 19, "duration_seconds": 1.857}, "timestamp": "2026-01-12T10:19:07.125076"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.461, "latencies_ms": [1116.461], "images_per_second": 0.896, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two men are working in a kitchen, one is cooking food in a fryer and the other is preparing food in a pan.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.5, "ram_available_mb": 109138.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.2, "ram_available_mb": 109139.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [34.01, 34.01, 34.01, 34.01, 34.01, 46.12, 46.12, 46.12, 46.12, 46.12, 46.97, 46.97], "power_watts_avg": 41.22, "power_watts_peak": 46.97, "energy_joules_est": 46.03, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T10:19:08.386413"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1014.787, "latencies_ms": [1014.787], "images_per_second": 0.985, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The kitchen is well-lit with fluorescent lights, and the stainless steel appliances gleam under the bright lights.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13359.3, "ram_available_mb": 109147.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13370.1, "ram_available_mb": 109136.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 58.0}, "power_stats": {"power_watts_samples": [46.97, 46.97, 46.97, 37.82, 37.82, 37.82, 37.82, 37.82, 46.26, 46.26, 46.26], "power_watts_avg": 42.62, "power_watts_peak": 46.97, "energy_joules_est": 43.27, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-12T10:19:09.496952"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 961.006, "latencies_ms": [961.006], "images_per_second": 1.041, "prompt_tokens": 766, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of motorcyclists are gathered on a roadside, with their bikes parked alongside the road, and a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.2, "ram_available_mb": 109140.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.7, "ram_available_mb": 109149.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4528.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 43.16, 43.16, 43.16, 43.16, 43.16, 41.93, 41.93, 41.93], "power_watts_avg": 43.41, "power_watts_peak": 46.26, "energy_joules_est": 41.74, "sample_count": 10, "duration_seconds": 0.962}, "timestamp": "2026-01-12T10:19:10.510080"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 432.785, "latencies_ms": [432.785], "images_per_second": 2.311, "prompt_tokens": 780, "response_tokens_est": 5, "n_tiles": 1, "output_text": " motorcycle: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.8, "ram_available_mb": 109157.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.8, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 24.0}, "power_stats": {"power_watts_samples": [41.93, 41.93, 42.88, 42.88, 42.88], "power_watts_avg": 42.5, "power_watts_peak": 42.88, "energy_joules_est": 18.41, "sample_count": 5, "duration_seconds": 0.433}, "timestamp": "2026-01-12T10:19:11.017134"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1515.116, "latencies_ms": [1515.116], "images_per_second": 0.66, "prompt_tokens": 784, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The motorcycles are positioned on the left side of the road, with the nearest motorcycle being closest to the camera. The group of people is standing on the right side of the road, with the furthest person being farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.8, "ram_available_mb": 109148.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4575.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.88, 42.88, 41.42, 41.42, 41.42, 41.42, 41.42, 51.4, 51.4, 51.4, 51.4, 51.4, 43.71, 43.71, 43.71, 43.71], "power_watts_avg": 45.29, "power_watts_peak": 51.4, "energy_joules_est": 68.64, "sample_count": 16, "duration_seconds": 1.515}, "timestamp": "2026-01-12T10:19:12.630696"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 852.182, "latencies_ms": [852.182], "images_per_second": 1.173, "prompt_tokens": 778, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of motorcyclists are gathered on a roadside overlooking the ocean, with a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.32, 33.32, 33.32, 33.32, 33.32, 41.62, 41.62, 41.62, 41.62], "power_watts_avg": 37.01, "power_watts_peak": 41.62, "energy_joules_est": 31.55, "sample_count": 9, "duration_seconds": 0.852}, "timestamp": "2026-01-12T10:19:13.541491"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2053.268, "latencies_ms": [2053.268], "images_per_second": 0.487, "prompt_tokens": 776, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image features a group of motorcyclists gathered on a roadside, with their motorcycles parked in a line. The sky is filled with clouds, and the lighting suggests it is either early morning or late afternoon. The colors in the image are predominantly blue, gray, and black, with the motorcycles adding a splash of color to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13335.5, "ram_available_mb": 109170.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [41.62, 41.31, 41.31, 41.31, 41.31, 41.31, 42.59, 42.59, 42.59, 42.59, 42.59, 44.56, 44.56, 44.56, 44.56, 44.56, 34.67, 34.67, 34.67, 34.67, 34.67], "power_watts_avg": 40.82, "power_watts_peak": 44.56, "energy_joules_est": 83.83, "sample_count": 21, "duration_seconds": 2.054}, "timestamp": "2026-01-12T10:19:15.658481"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1098.019, "latencies_ms": [1098.019], "images_per_second": 0.911, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A small airplane with the letters GVRZ on the tail flies through the sky, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.6, "ram_available_mb": 109178.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13362.0, "ram_available_mb": 109144.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.38, 34.38, 34.38, 34.38, 34.38, 44.39, 44.39, 44.39, 44.39, 44.39, 46.14], "power_watts_avg": 40.0, "power_watts_peak": 46.14, "energy_joules_est": 43.97, "sample_count": 11, "duration_seconds": 1.099}, "timestamp": "2026-01-12T10:19:16.823428"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1915.933, "latencies_ms": [1915.933], "images_per_second": 0.522, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. smoke: 2\n3. clouds: 2\n4. sky: 1\n5. tail: 1\n6. propeller: 1\n7. wing: 1\n8. fuselage: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13358.0, "ram_available_mb": 109148.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13271.2, "ram_available_mb": 109235.1, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.14, 46.14, 46.14, 46.14, 42.66, 42.66, 42.66, 42.66, 42.66, 47.6, 47.6, 47.6, 47.6, 41.19, 41.19, 41.19, 41.19, 41.19, 34.8, 34.8], "power_watts_avg": 43.19, "power_watts_peak": 47.6, "energy_joules_est": 82.76, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T10:19:18.843188"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1218.419, "latencies_ms": [1218.419], "images_per_second": 0.821, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The airplane is in the foreground, flying from left to right, while the clouds are in the background. The airplane is flying higher than the clouds.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13270.9, "ram_available_mb": 109235.4, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13333.9, "ram_available_mb": 109172.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.8, 35.91, 35.91, 35.91, 35.91, 35.91, 45.07, 45.07, 45.07, 45.07, 45.07], "power_watts_avg": 39.18, "power_watts_peak": 45.07, "energy_joules_est": 47.77, "sample_count": 13, "duration_seconds": 1.219}, "timestamp": "2026-01-12T10:19:20.208604"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 880.146, "latencies_ms": [880.146], "images_per_second": 1.136, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small airplane is flying in the sky, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13326.0, "ram_available_mb": 109180.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.1, "ram_available_mb": 109164.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.23, 44.23, 44.23, 44.23, 44.23, 45.08, 45.08, 45.08, 45.08], "power_watts_avg": 44.61, "power_watts_peak": 45.08, "energy_joules_est": 39.28, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-12T10:19:21.119581"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1519.869, "latencies_ms": [1519.869], "images_per_second": 0.658, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the dark and light areas. The sky is filled with clouds, and the airplane is flying through them, leaving a trail of smoke behind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.2, "ram_available_mb": 109168.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13339.4, "ram_available_mb": 109166.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.08, 45.78, 45.78, 45.78, 45.78, 45.78, 48.86, 48.86, 48.86, 48.86, 48.86, 48.15, 48.15, 48.15, 48.15, 34.72], "power_watts_avg": 46.6, "power_watts_peak": 48.86, "energy_joules_est": 70.85, "sample_count": 16, "duration_seconds": 1.52}, "timestamp": "2026-01-12T10:19:22.736620"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1066.08, "latencies_ms": [1066.08], "images_per_second": 0.938, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " In the image, a group of sheep are standing on a grassy hill, with a lake and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.4, "ram_available_mb": 109166.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 34.72, 34.72, 43.7, 43.7, 43.7, 43.7, 43.7, 46.06, 46.06], "power_watts_avg": 40.86, "power_watts_peak": 46.06, "energy_joules_est": 43.59, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T10:19:23.849408"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1908.765, "latencies_ms": [1908.765], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 5\n2. grass: 1\n3. rocks: 1\n4. water: 1\n5. mountains: 2\n6. sky: 1\n7. clouds: 1\n8. lake: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13381.4, "ram_available_mb": 109124.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.06, 46.06, 46.06, 43.35, 43.35, 43.35, 43.35, 43.35, 47.38, 47.38, 47.38, 47.38, 47.38, 41.19, 41.19, 41.19, 41.19, 41.19, 34.86], "power_watts_avg": 43.82, "power_watts_peak": 47.38, "energy_joules_est": 83.68, "sample_count": 19, "duration_seconds": 1.91}, "timestamp": "2026-01-12T10:19:25.767400"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1447.54, "latencies_ms": [1447.54], "images_per_second": 0.691, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the mountains in the background. The sheep are standing on a grassy hill, with the lake visible to the right of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.4, "ram_available_mb": 109128.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13313.4, "ram_available_mb": 109192.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 44.84, 44.84, 44.84, 44.84, 44.84, 47.75, 47.75, 47.75, 47.75, 47.75, 38.59], "power_watts_avg": 42.73, "power_watts_peak": 47.75, "energy_joules_est": 61.87, "sample_count": 15, "duration_seconds": 1.448}, "timestamp": "2026-01-12T10:19:27.284336"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1145.078, "latencies_ms": [1145.078], "images_per_second": 0.873, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In this picturesque landscape, a group of sheep are grazing on a grassy hillside, with a serene lake and majestic mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.4, "ram_available_mb": 109192.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13337.0, "ram_available_mb": 109169.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.59, 38.59, 38.59, 38.59, 43.24, 43.24, 43.24, 43.24, 43.24, 46.93, 46.93, 46.93], "power_watts_avg": 42.61, "power_watts_peak": 46.93, "energy_joules_est": 48.82, "sample_count": 12, "duration_seconds": 1.146}, "timestamp": "2026-01-12T10:19:28.497067"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1758.959, "latencies_ms": [1758.959], "images_per_second": 0.569, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a group of sheep standing on a grassy hill, with a clear blue sky above and a body of water in the background. The sheep are white, and the grass is green, with the mountains in the background providing a natural backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.0, "ram_available_mb": 109173.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13327.9, "ram_available_mb": 109178.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.93, 46.93, 38.35, 38.35, 38.35, 38.35, 38.35, 46.66, 46.66, 46.66, 46.66, 46.66, 48.33, 48.33, 48.33, 48.33, 48.33, 34.78], "power_watts_avg": 44.18, "power_watts_peak": 48.33, "energy_joules_est": 77.74, "sample_count": 18, "duration_seconds": 1.76}, "timestamp": "2026-01-12T10:19:30.316057"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 882.341, "latencies_ms": [882.341], "images_per_second": 1.133, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman in a wheelchair is holding a tennis racket and looking at the camera.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13320.0, "ram_available_mb": 109186.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.78, 34.78, 34.78, 34.78, 41.77, 41.77, 41.77, 41.77, 41.77], "power_watts_avg": 38.66, "power_watts_peak": 41.77, "energy_joules_est": 34.14, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:19:31.229287"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2205.609, "latencies_ms": [2205.609], "images_per_second": 0.453, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. woman: 1\n2. wheelchair: 1\n3. racket: 1\n4. woman's hand: 1\n5. woman's arm: 1\n6. woman's leg: 1\n7. woman's foot: 1\n8. woman's knee: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.5, "ram_available_mb": 109163.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.9, "ram_available_mb": 109160.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.01, 47.01, 47.01, 47.01, 51.69, 51.69, 51.69, 51.69, 51.69, 47.59, 47.59, 47.59, 47.59, 47.59, 36.06, 36.06, 36.06, 36.06, 36.06, 34.72, 34.72, 34.72], "power_watts_avg": 44.04, "power_watts_peak": 51.69, "energy_joules_est": 97.16, "sample_count": 22, "duration_seconds": 2.206}, "timestamp": "2026-01-12T10:19:33.450493"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1210.223, "latencies_ms": [1210.223], "images_per_second": 0.826, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The woman in the wheelchair is in the foreground, holding a tennis racket. The other woman is in the background, sitting in a wheelchair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 33.68, 33.68, 33.68, 33.68, 33.68, 46.6, 46.6, 46.6, 46.6, 46.6, 47.9], "power_watts_avg": 39.9, "power_watts_peak": 47.9, "energy_joules_est": 48.34, "sample_count": 13, "duration_seconds": 1.211}, "timestamp": "2026-01-12T10:19:34.815147"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 782.167, "latencies_ms": [782.167], "images_per_second": 1.278, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A woman in a wheelchair is playing tennis with a racket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.0, "ram_available_mb": 109164.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.9, 47.9, 47.9, 47.9, 40.9, 40.9, 40.9, 40.9], "power_watts_avg": 44.4, "power_watts_peak": 47.9, "energy_joules_est": 34.74, "sample_count": 8, "duration_seconds": 0.782}, "timestamp": "2026-01-12T10:19:35.625416"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1693.24, "latencies_ms": [1693.24], "images_per_second": 0.591, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a gymnasium with a white wall in the background. The lighting is natural, coming from the windows on the left side of the image. The woman is wearing a gray t-shirt and has brown hair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.6, "ram_available_mb": 109162.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.9, 45.37, 45.37, 45.37, 45.37, 45.37, 52.95, 52.95, 52.95, 52.95, 52.95, 48.57, 48.57, 48.57, 48.57, 34.93, 34.93], "power_watts_avg": 46.86, "power_watts_peak": 52.95, "energy_joules_est": 79.36, "sample_count": 17, "duration_seconds": 1.694}, "timestamp": "2026-01-12T10:19:37.342103"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1265.153, "latencies_ms": [1265.153], "images_per_second": 0.79, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young girl wearing a black helmet and a pink plaid shirt is sitting on a brown leather saddle with a purple blanket underneath.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13339.7, "ram_available_mb": 109166.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13378.8, "ram_available_mb": 109127.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 65.0}, "power_stats": {"power_watts_samples": [34.93, 34.93, 34.93, 39.49, 39.49, 39.49, 39.49, 39.49, 51.41, 51.41, 51.41, 51.41, 51.41], "power_watts_avg": 43.02, "power_watts_peak": 51.41, "energy_joules_est": 54.45, "sample_count": 13, "duration_seconds": 1.266}, "timestamp": "2026-01-12T10:19:38.663172"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2540.195, "latencies_ms": [2540.195], "images_per_second": 0.394, "prompt_tokens": 1446, "response_tokens_est": 73, "n_tiles": 1, "output_text": " 1. black helmet: 1\n2. pink plaid shirt: 1\n3. blue jeans: 1\n4. brown leather saddle: 1\n5. purple cloth: 1\n6. brown leather saddle horn: 1\n7. brown leather saddle blanket: 1\n8. brown leather saddle tree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.9, "ram_available_mb": 109135.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13370.8, "ram_available_mb": 109135.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.64, 46.64, 46.64, 46.64, 46.64, 46.78, 46.78, 46.78, 46.78, 46.78, 51.01, 51.01, 51.01, 51.01, 51.01, 39.2, 39.2, 39.2, 39.2, 39.2, 34.88, 34.88, 34.88, 34.88, 34.88, 34.81], "power_watts_avg": 43.36, "power_watts_peak": 51.01, "energy_joules_est": 110.16, "sample_count": 26, "duration_seconds": 2.541}, "timestamp": "2026-01-12T10:19:41.287577"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2042.115, "latencies_ms": [2042.115], "images_per_second": 0.49, "prompt_tokens": 1450, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The child is sitting on the saddle, which is placed on the purple blanket. The saddle is positioned in the foreground, while the child is in the background. The child is sitting to the left of the saddle, and the saddle is to the right of the child.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.8, "ram_available_mb": 109135.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.2, "ram_available_mb": 109141.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 34.81, 37.63, 37.63, 37.63, 37.63, 37.63, 49.41, 49.41, 49.41, 49.41, 49.41, 46.56, 46.56, 46.56, 46.56, 46.56, 34.92, 34.92, 34.92], "power_watts_avg": 41.77, "power_watts_peak": 49.41, "energy_joules_est": 85.34, "sample_count": 21, "duration_seconds": 2.043}, "timestamp": "2026-01-12T10:19:43.463115"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1332.864, "latencies_ms": [1332.864], "images_per_second": 0.75, "prompt_tokens": 1444, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young girl wearing a black helmet and a pink plaid shirt is sitting on a brown saddle in a field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.2, "ram_available_mb": 109141.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.9, "ram_available_mb": 109164.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 33.06, 33.06, 33.06, 33.06, 33.06, 50.52, 50.52, 50.52, 50.52, 50.52, 52.84, 52.84], "power_watts_avg": 42.39, "power_watts_peak": 52.84, "energy_joules_est": 56.51, "sample_count": 14, "duration_seconds": 1.333}, "timestamp": "2026-01-12T10:19:44.874539"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1568.998, "latencies_ms": [1568.998], "images_per_second": 0.637, "prompt_tokens": 1442, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a young girl wearing a black helmet and a pink plaid shirt, sitting on a brown leather saddle. The background is filled with green trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.9, "ram_available_mb": 109164.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13362.1, "ram_available_mb": 109144.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [52.84, 52.84, 52.84, 37.21, 37.21, 37.21, 37.21, 37.21, 50.69, 50.69, 50.69, 50.69, 50.69, 48.99, 48.99, 48.99], "power_watts_avg": 46.56, "power_watts_peak": 52.84, "energy_joules_est": 73.07, "sample_count": 16, "duration_seconds": 1.569}, "timestamp": "2026-01-12T10:19:46.493337"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1459.93, "latencies_ms": [1459.93], "images_per_second": 0.685, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In the image, two surfers are riding the waves on their surfboards, with one surfer positioned closer to the camera and the other further away, both enjoying the thrill of the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.1, "ram_available_mb": 109148.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13341.9, "ram_available_mb": 109164.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.99, 48.99, 34.78, 34.78, 34.78, 34.78, 34.78, 47.15, 47.15, 47.15, 47.15, 47.15, 47.63, 47.63, 47.63], "power_watts_avg": 43.37, "power_watts_peak": 48.99, "energy_joules_est": 63.32, "sample_count": 15, "duration_seconds": 1.46}, "timestamp": "2026-01-12T10:19:48.007202"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2031.171, "latencies_ms": [2031.171], "images_per_second": 0.492, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Surfer: 2\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Bird: 1\n6. Photographer: 1\n7. Photograph: 1\n8. Frame: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.0, "ram_available_mb": 109172.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13333.9, "ram_available_mb": 109172.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.63, 47.63, 34.0, 34.0, 34.0, 34.0, 34.0, 47.39, 47.39, 47.39, 47.39, 47.39, 48.93, 48.93, 48.93, 48.93, 48.93, 35.03, 35.03, 35.03, 35.03], "power_watts_avg": 42.24, "power_watts_peak": 48.93, "energy_joules_est": 85.8, "sample_count": 21, "duration_seconds": 2.031}, "timestamp": "2026-01-12T10:19:50.123785"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2311.941, "latencies_ms": [2311.941], "images_per_second": 0.433, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The surfer on the left is closer to the camera than the surfer on the right. The surfer on the left is in the foreground, while the surfer on the right is in the background. The surfer on the left is riding a wave that is closer to the camera than the wave that the surfer on the right is riding.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13326.0, "ram_available_mb": 109180.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.5, "ram_available_mb": 109156.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.03, 33.25, 33.25, 33.25, 33.25, 33.25, 46.73, 46.73, 46.73, 46.73, 46.73, 48.41, 48.41, 48.41, 48.41, 48.41, 34.77, 34.77, 34.77, 34.77, 34.8, 34.8, 34.8], "power_watts_avg": 40.02, "power_watts_peak": 48.41, "energy_joules_est": 92.53, "sample_count": 23, "duration_seconds": 2.312}, "timestamp": "2026-01-12T10:19:52.442012"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1062.057, "latencies_ms": [1062.057], "images_per_second": 0.942, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two surfers are riding the waves in the ocean, one is closer to the camera and the other is farther away.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13345.6, "ram_available_mb": 109160.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.5, "ram_available_mb": 109152.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.84, 34.84, 34.84, 34.84, 34.84, 47.06, 47.06, 47.06, 47.06], "power_watts_avg": 39.28, "power_watts_peak": 47.06, "energy_joules_est": 41.73, "sample_count": 11, "duration_seconds": 1.062}, "timestamp": "2026-01-12T10:19:53.602154"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1886.435, "latencies_ms": [1886.435], "images_per_second": 0.53, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a dynamic scene of two surfers riding a wave in the ocean. The water is a deep blue, and the sky is clear, suggesting a sunny day. The surfers are clad in black wetsuits, contrasting with the vibrant blue of the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.9, "ram_available_mb": 109163.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.06, 46.45, 46.45, 46.45, 46.45, 46.45, 47.24, 47.24, 47.24, 47.24, 47.24, 48.93, 48.93, 48.93, 48.93, 48.93, 34.86, 34.86, 34.86], "power_watts_avg": 45.51, "power_watts_peak": 48.93, "energy_joules_est": 85.87, "sample_count": 19, "duration_seconds": 1.887}, "timestamp": "2026-01-12T10:19:55.517327"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1249.155, "latencies_ms": [1249.155], "images_per_second": 0.801, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a cozy kitchen with a window that has frosted glass, a wooden cabinet, and a small table with a potted plant on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.9, "ram_available_mb": 109163.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.0, "ram_available_mb": 109155.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.86, 32.02, 32.02, 32.02, 32.02, 32.02, 46.42, 46.42, 46.42, 46.42, 46.42, 49.5, 49.5], "power_watts_avg": 40.47, "power_watts_peak": 49.5, "energy_joules_est": 50.58, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-12T10:19:56.884679"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1930.299, "latencies_ms": [1930.299], "images_per_second": 0.518, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. window: 1\n2. shelf: 2\n3. cabinet: 1\n4. stove: 1\n5. pot: 1\n6. plant: 1\n7. shelf: 1\n8. cupboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.1, "ram_available_mb": 109163.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.5, 49.5, 49.5, 39.3, 39.3, 39.3, 39.3, 39.3, 46.86, 46.86, 46.86, 46.86, 46.86, 42.59, 42.59, 42.59, 42.59, 42.59, 34.89, 34.89], "power_watts_avg": 43.1, "power_watts_peak": 49.5, "energy_joules_est": 83.22, "sample_count": 20, "duration_seconds": 1.931}, "timestamp": "2026-01-12T10:19:58.904120"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1639.481, "latencies_ms": [1639.481], "images_per_second": 0.61, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The window is located in the center of the image, with the wooden cabinet to the right and the stove to the left. The plants are placed in front of the window, while the books are on the shelf of the cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.5, "ram_available_mb": 109159.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13355.7, "ram_available_mb": 109150.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 53.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 35.05, 35.05, 35.05, 35.05, 35.05, 45.77, 45.77, 45.77, 45.77, 45.77, 46.23, 46.23, 46.23, 46.23, 46.23], "power_watts_avg": 41.47, "power_watts_peak": 46.23, "energy_joules_est": 68.02, "sample_count": 17, "duration_seconds": 1.64}, "timestamp": "2026-01-12T10:20:00.669374"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2990.744, "latencies_ms": [2990.744], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 97, "n_tiles": 1, "output_text": " The image captures a cozy kitchen scene, bathed in soft light filtering through a window adorned with a colorful paper decoration. The room is filled with an array of objects, each telling a story of its own. Shelves brimming with jars and containers, a stove waiting for its next culinary adventure, and a wooden cabinet that seems to hold secrets of its own. The overall setting is one of warmth and homeliness, inviting one to step in and explore the many stories hidden within.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.7, "ram_available_mb": 109150.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.13, 34.13, 34.13, 34.13, 34.13, 46.95, 46.95, 46.95, 46.95, 46.95, 47.62, 47.62, 47.62, 47.62, 47.62, 34.85, 34.85, 34.85, 34.85, 34.85, 34.92, 34.92, 34.92, 34.92, 34.92, 34.71, 34.71, 34.71, 34.71, 34.71], "power_watts_avg": 38.86, "power_watts_peak": 47.62, "energy_joules_est": 116.25, "sample_count": 30, "duration_seconds": 2.991}, "timestamp": "2026-01-12T10:20:03.686872"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 963.935, "latencies_ms": [963.935], "images_per_second": 1.037, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is dimly lit with a warm yellow light, and the window is covered with frost.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13472.7, "ram_available_mb": 109033.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.66, 34.66, 34.66, 34.66, 45.3, 45.3, 45.3, 45.3, 45.3, 46.69], "power_watts_avg": 41.18, "power_watts_peak": 46.69, "energy_joules_est": 39.72, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-12T10:20:04.749026"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3784.488, "latencies_ms": [3784.488], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 128, "n_tiles": 1, "output_text": " In the image, a vibrant red background serves as a backdrop for a collection of objects, including a pineapple, a potted plant, a plate of oranges, and a container of incense sticks. The pineapple, with its spiky green leaves, is positioned on the left side of the image, while the potted plant, with its lush green foliage, is situated in the center. The plate of oranges, with their bright orange color, is placed on the right side of the image, and the container of incense sticks, with its red and white colors, is located in the middle. The arrangement of these objects creates a harmonious balance", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13464.8, "ram_available_mb": 109041.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13369.9, "ram_available_mb": 109136.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.69, 46.69, 46.69, 46.69, 47.26, 47.26, 47.26, 47.26, 47.26, 47.05, 47.05, 47.05, 47.05, 47.05, 37.94, 37.94, 37.94, 37.94, 37.94, 34.84, 34.84, 34.84, 34.84, 34.84, 34.71, 34.71, 34.71, 34.71, 34.71, 34.75, 34.75, 34.75, 34.75, 34.75, 34.82, 34.82, 34.82, 34.82], "power_watts_avg": 39.71, "power_watts_peak": 47.26, "energy_joules_est": 150.28, "sample_count": 38, "duration_seconds": 3.785}, "timestamp": "2026-01-12T10:20:08.575189"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1275.18, "latencies_ms": [1275.18], "images_per_second": 0.784, "prompt_tokens": 1113, "response_tokens_est": 32, "n_tiles": 1, "output_text": " pineapple: 1, red cups: 5, oranges: 4, red pot: 1, incense: 1, red plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.9, "ram_available_mb": 109136.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.5, "ram_available_mb": 109112.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.82, 33.0, 33.0, 33.0, 33.0, 33.0, 46.29, 46.29, 46.29, 46.29, 46.29, 48.39, 48.39], "power_watts_avg": 40.62, "power_watts_peak": 48.39, "energy_joules_est": 51.84, "sample_count": 13, "duration_seconds": 1.276}, "timestamp": "2026-01-12T10:20:09.940195"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1730.833, "latencies_ms": [1730.833], "images_per_second": 0.578, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The pineapple is positioned to the left of the incense holder, with the oranges placed on a white plate to the right. The red cups are arranged in a row in the foreground, with the incense holder and plate of oranges situated in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13385.7, "ram_available_mb": 109120.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13401.5, "ram_available_mb": 109104.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [48.39, 48.39, 37.26, 37.26, 37.26, 37.26, 37.26, 47.65, 47.65, 47.65, 47.65, 47.65, 45.9, 45.9, 45.9, 45.9, 45.9, 34.66], "power_watts_avg": 43.64, "power_watts_peak": 48.39, "energy_joules_est": 75.56, "sample_count": 18, "duration_seconds": 1.731}, "timestamp": "2026-01-12T10:20:11.755822"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1375.72, "latencies_ms": [1375.72], "images_per_second": 0.727, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In this image, we can see a table with some objects like a pineapple, a plate with oranges, some cups and a pot. We can see the wall with some text.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.5, "ram_available_mb": 109104.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13338.2, "ram_available_mb": 109168.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.66, 34.66, 34.66, 34.66, 43.81, 43.81, 43.81, 43.81, 43.81, 46.46, 46.46, 46.46, 46.46, 46.46], "power_watts_avg": 42.14, "power_watts_peak": 46.46, "energy_joules_est": 57.99, "sample_count": 14, "duration_seconds": 1.376}, "timestamp": "2026-01-12T10:20:13.166347"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2384.778, "latencies_ms": [2384.778], "images_per_second": 0.419, "prompt_tokens": 1109, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image features a vibrant display of red and orange fruits, with a pineapple and a plate of oranges prominently displayed. The lighting is bright and even, highlighting the textures and colors of the fruits and the background. The materials used in the image are a combination of natural and man-made objects, with the fruits being organic and the background being a man-made structure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.2, "ram_available_mb": 109168.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13376.8, "ram_available_mb": 109129.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.25, 38.25, 38.25, 38.25, 38.25, 47.64, 47.64, 47.64, 47.64, 47.64, 47.63, 47.63, 47.63, 47.63, 47.63, 34.79, 34.79, 34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34.77], "power_watts_avg": 40.86, "power_watts_peak": 47.64, "energy_joules_est": 97.45, "sample_count": 24, "duration_seconds": 2.385}, "timestamp": "2026-01-12T10:20:15.583798"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 980.384, "latencies_ms": [980.384], "images_per_second": 1.02, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man with a beard and glasses is eating a large piece of fried food with fries and dipping sauce.", "error": null, "sys_before": {"cpu_percent": 1.8, "ram_used_mb": 13376.8, "ram_available_mb": 109129.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13396.5, "ram_available_mb": 109109.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [34.77, 33.22, 33.22, 33.22, 33.22, 46.66, 46.66, 46.66, 46.66, 46.66], "power_watts_avg": 40.09, "power_watts_peak": 46.66, "energy_joules_est": 39.36, "sample_count": 10, "duration_seconds": 0.982}, "timestamp": "2026-01-12T10:20:16.649330"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1912.78, "latencies_ms": [1912.78], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. fries: 1\n3. sandwich: 1\n4. cup: 1\n5. man: 1\n6. clock: 1\n7. wall: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.5, "ram_available_mb": 109113.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13375.0, "ram_available_mb": 109131.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.33, 47.33, 47.33, 47.33, 47.33, 47.46, 47.46, 47.46, 47.46, 47.46, 48.01, 48.01, 48.01, 48.01, 48.01, 34.83, 34.83, 34.83, 34.83], "power_watts_avg": 44.91, "power_watts_peak": 48.01, "energy_joules_est": 85.93, "sample_count": 19, "duration_seconds": 1.913}, "timestamp": "2026-01-12T10:20:18.569166"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1249.596, "latencies_ms": [1249.596], "images_per_second": 0.8, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The man is in the foreground, holding a plate of food. The fries are in the middle ground, and the background shows a restaurant with other people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.1, "ram_available_mb": 109139.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13369.4, "ram_available_mb": 109136.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.83, 33.47, 33.47, 33.47, 33.47, 33.47, 47.12, 47.12, 47.12, 47.12, 47.12, 47.9, 47.9], "power_watts_avg": 41.04, "power_watts_peak": 47.9, "energy_joules_est": 51.32, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-12T10:20:19.931773"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1171.38, "latencies_ms": [1171.38], "images_per_second": 0.854, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man is eating a large piece of fried food with fries and dipping sauce. He is in a restaurant with other people in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13365.4, "ram_available_mb": 109140.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13375.9, "ram_available_mb": 109130.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.9, 47.9, 47.9, 37.25, 37.25, 37.25, 37.25, 37.25, 47.1, 47.1, 47.1, 47.1], "power_watts_avg": 43.2, "power_watts_peak": 47.9, "energy_joules_est": 50.63, "sample_count": 12, "duration_seconds": 1.172}, "timestamp": "2026-01-12T10:20:21.145953"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1407.163, "latencies_ms": [1407.163], "images_per_second": 0.711, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere. The lighting is bright and natural, illuminating the scene and highlighting the colors of the food and the man's attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.0, "ram_available_mb": 109138.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.1, "ram_available_mb": 109135.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [44.84, 44.84, 44.84, 44.84, 44.84, 47.52, 47.52, 47.52, 47.52, 47.52, 47.4, 47.4, 47.4, 47.4], "power_watts_avg": 46.53, "power_watts_peak": 47.52, "energy_joules_est": 65.5, "sample_count": 14, "duration_seconds": 1.408}, "timestamp": "2026-01-12T10:20:22.560847"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1282.647, "latencies_ms": [1282.647], "images_per_second": 0.78, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image captures a rainy day scene from inside a building, where a person is seen walking with an umbrella, and a bike rack is filled with bicycles outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.2, "ram_available_mb": 109143.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13282.7, "ram_available_mb": 109223.6, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.4, 33.32, 33.32, 33.32, 33.32, 33.32, 47.8, 47.8, 47.8, 47.8, 47.8, 49.55, 49.55], "power_watts_avg": 42.47, "power_watts_peak": 49.55, "energy_joules_est": 54.48, "sample_count": 13, "duration_seconds": 1.283}, "timestamp": "2026-01-12T10:20:23.875889"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2119.848, "latencies_ms": [2119.848], "images_per_second": 0.472, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Bike: 4\n2. Bike: 2\n3. Bike: 1\n4. Bike: 1\n5. Bike: 1\n6. Bike: 1\n7. Bike: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13282.7, "ram_available_mb": 109223.6, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13321.8, "ram_available_mb": 109184.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.55, 49.55, 49.55, 40.12, 40.12, 40.12, 40.12, 40.12, 47.43, 47.43, 47.43, 47.43, 47.43, 43.15, 43.15, 43.15, 43.15, 43.15, 34.8, 34.8, 34.8, 34.8], "power_watts_avg": 42.79, "power_watts_peak": 49.55, "energy_joules_est": 90.73, "sample_count": 22, "duration_seconds": 2.12}, "timestamp": "2026-01-12T10:20:26.096090"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1355.195, "latencies_ms": [1355.195], "images_per_second": 0.738, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The bicycle is positioned in the foreground, with the person walking with the umbrella in the background. The building is located in the middle ground, with the courtyard in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.8, "ram_available_mb": 109184.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13338.3, "ram_available_mb": 109168.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.8, 32.31, 32.31, 32.31, 32.31, 45.28, 45.28, 45.28, 45.28, 45.28, 47.99, 47.99, 47.99, 47.99], "power_watts_avg": 41.6, "power_watts_peak": 47.99, "energy_joules_est": 56.4, "sample_count": 14, "duration_seconds": 1.356}, "timestamp": "2026-01-12T10:20:27.561223"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1141.558, "latencies_ms": [1141.558], "images_per_second": 0.876, "prompt_tokens": 1112, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image captures a rainy day at a modern building complex, where people are seen walking with umbrellas and bicycles are parked outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.4, "ram_available_mb": 109175.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.0, "ram_available_mb": 109159.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.99, 32.41, 32.41, 32.41, 32.41, 32.41, 46.9, 46.9, 46.9, 46.9, 46.9, 49.67], "power_watts_avg": 41.18, "power_watts_peak": 49.67, "energy_joules_est": 47.04, "sample_count": 12, "duration_seconds": 1.142}, "timestamp": "2026-01-12T10:20:28.775419"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1772.196, "latencies_ms": [1772.196], "images_per_second": 0.564, "prompt_tokens": 1110, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image is taken from inside a building, looking out at a rainy day. The sky is overcast, and the ground is wet, reflecting the light from the sky. The buildings are made of glass and metal, and the bicycles are parked outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.1, "ram_available_mb": 109163.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13331.9, "ram_available_mb": 109174.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.67, 49.67, 49.67, 49.67, 43.76, 43.76, 43.76, 43.76, 43.76, 46.74, 46.74, 46.74, 46.74, 46.74, 37.94, 37.94, 37.94, 37.94], "power_watts_avg": 44.61, "power_watts_peak": 49.67, "energy_joules_est": 79.07, "sample_count": 18, "duration_seconds": 1.773}, "timestamp": "2026-01-12T10:20:30.594642"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1425.437, "latencies_ms": [1425.437], "images_per_second": 0.702, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image shows a close-up of a plate with a creamy, yellow-colored substance, possibly cheese, on top of a piece of bread, with a fork and knife placed nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13337.9, "ram_available_mb": 109168.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [37.94, 33.27, 33.27, 33.27, 33.27, 33.27, 47.21, 47.21, 47.21, 47.21, 47.21, 49.11, 49.11, 49.11, 49.11], "power_watts_avg": 42.45, "power_watts_peak": 49.11, "energy_joules_est": 60.54, "sample_count": 15, "duration_seconds": 1.426}, "timestamp": "2026-01-12T10:20:32.113151"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 529.256, "latencies_ms": [529.256], "images_per_second": 1.889, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " fork: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.9, "ram_available_mb": 109168.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13404.6, "ram_available_mb": 109101.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.11, 32.85, 32.85, 32.85, 32.85, 32.85], "power_watts_avg": 35.56, "power_watts_peak": 49.11, "energy_joules_est": 18.83, "sample_count": 6, "duration_seconds": 0.53}, "timestamp": "2026-01-12T10:20:32.721902"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1211.851, "latencies_ms": [1211.851], "images_per_second": 0.825, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The fork is located in the background, behind the plate of food. The plate is in the foreground, and the food is on top of it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13404.6, "ram_available_mb": 109101.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13394.5, "ram_available_mb": 109111.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.76, 46.76, 46.76, 46.76, 46.76, 60.7, 60.7, 60.7, 60.7, 60.7, 47.07, 47.07, 47.07], "power_watts_avg": 52.2, "power_watts_peak": 60.7, "energy_joules_est": 63.28, "sample_count": 13, "duration_seconds": 1.212}, "timestamp": "2026-01-12T10:20:34.035067"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 876.385, "latencies_ms": [876.385], "images_per_second": 1.141, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A close up of a plate of food with a fork and knife on the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.6, "ram_available_mb": 109119.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13403.2, "ram_available_mb": 109103.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.07, 47.07, 33.4, 33.4, 33.4, 33.4, 33.4, 46.5, 46.5], "power_watts_avg": 39.35, "power_watts_peak": 47.07, "energy_joules_est": 34.5, "sample_count": 9, "duration_seconds": 0.877}, "timestamp": "2026-01-12T10:20:34.947972"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1243.544, "latencies_ms": [1243.544], "images_per_second": 0.804, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image features a close-up of a plate of food with a creamy yellow sauce, a fork and knife on the side, and a dark background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13395.3, "ram_available_mb": 109111.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13396.4, "ram_available_mb": 109109.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.5, 46.5, 51.88, 51.88, 51.88, 51.88, 51.88, 47.57, 47.57, 47.57, 47.57, 47.57, 45.56], "power_watts_avg": 48.91, "power_watts_peak": 51.88, "energy_joules_est": 60.84, "sample_count": 13, "duration_seconds": 1.244}, "timestamp": "2026-01-12T10:20:36.262799"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1062.772, "latencies_ms": [1062.772], "images_per_second": 0.941, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A silver laptop sits open on a desk with a green leaf wallpaper, a black computer mouse, and a black keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.4, "ram_available_mb": 109109.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13456.4, "ram_available_mb": 109049.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [45.56, 45.56, 45.56, 45.56, 44.2, 44.2, 44.2, 44.2, 44.2, 46.91, 46.91], "power_watts_avg": 45.19, "power_watts_peak": 46.91, "energy_joules_est": 48.05, "sample_count": 11, "duration_seconds": 1.063}, "timestamp": "2026-01-12T10:20:37.378476"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 563.434, "latencies_ms": [563.434], "images_per_second": 1.775, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " computer monitor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13448.5, "ram_available_mb": 109057.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13449.7, "ram_available_mb": 109056.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.91, 46.91, 46.91, 43.17, 43.17, 43.17], "power_watts_avg": 45.04, "power_watts_peak": 46.91, "energy_joules_est": 25.4, "sample_count": 6, "duration_seconds": 0.564}, "timestamp": "2026-01-12T10:20:37.987584"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1592.565, "latencies_ms": [1592.565], "images_per_second": 0.628, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The laptop is in the foreground, to the right of the mouse, and in front of the computer monitor. The mouse is to the right of the laptop, and the computer monitor is to the left of the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13449.7, "ram_available_mb": 109056.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13473.5, "ram_available_mb": 109032.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.17, 43.17, 47.5, 47.5, 47.5, 47.5, 47.5, 55.11, 55.11, 55.11, 55.11, 55.11, 47.83, 47.83, 47.83, 47.83], "power_watts_avg": 49.42, "power_watts_peak": 55.11, "energy_joules_est": 78.72, "sample_count": 16, "duration_seconds": 1.593}, "timestamp": "2026-01-12T10:20:39.606145"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 797.458, "latencies_ms": [797.458], "images_per_second": 1.254, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A silver laptop sits on a desk with a computer monitor and keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13474.0, "ram_available_mb": 109032.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13525.5, "ram_available_mb": 108980.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 41.0}, "power_stats": {"power_watts_samples": [47.83, 33.92, 33.92, 33.92, 33.92, 33.92, 47.93, 47.93], "power_watts_avg": 39.16, "power_watts_peak": 47.93, "energy_joules_est": 31.24, "sample_count": 8, "duration_seconds": 0.798}, "timestamp": "2026-01-12T10:20:40.417127"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1056.083, "latencies_ms": [1056.083], "images_per_second": 0.947, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The laptop is silver and the mouse is black. The room is well lit and the laptop is on a white desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13517.6, "ram_available_mb": 108988.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13510.2, "ram_available_mb": 108996.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.93, 47.93, 47.93, 53.11, 53.11, 53.11, 53.11, 53.11, 47.95, 47.95, 47.95], "power_watts_avg": 50.29, "power_watts_peak": 53.11, "energy_joules_est": 53.13, "sample_count": 11, "duration_seconds": 1.056}, "timestamp": "2026-01-12T10:20:41.528272"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1327.723, "latencies_ms": [1327.723], "images_per_second": 0.753, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A young girl in a green shirt is sitting on a bed in a room with orange walls, a lamp on a table, and a pile of books on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13506.2, "ram_available_mb": 109000.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13495.6, "ram_available_mb": 109010.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.95, 47.95, 43.12, 43.12, 43.12, 43.12, 43.12, 47.4, 47.4, 47.4, 47.4, 47.4, 48.98, 48.98], "power_watts_avg": 46.18, "power_watts_peak": 48.98, "energy_joules_est": 61.34, "sample_count": 14, "duration_seconds": 1.328}, "timestamp": "2026-01-12T10:20:42.945001"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1914.924, "latencies_ms": [1914.924], "images_per_second": 0.522, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. girl: 1\n3. lamp: 1\n4. books: 1\n5. table: 1\n6. chair: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13487.7, "ram_available_mb": 109018.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13482.8, "ram_available_mb": 109023.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.98, 48.98, 48.98, 36.04, 36.04, 36.04, 36.04, 46.6, 46.6, 46.6, 46.6, 46.6, 45.37, 45.37, 45.37, 45.37, 45.37, 34.84, 34.84, 34.84], "power_watts_avg": 42.77, "power_watts_peak": 48.98, "energy_joules_est": 81.93, "sample_count": 20, "duration_seconds": 1.915}, "timestamp": "2026-01-12T10:20:44.964814"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1415.082, "latencies_ms": [1415.082], "images_per_second": 0.707, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bed is to the left of the girl, the lamp is on the nightstand to the right of the bed, and the books are on the floor in front of the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13470.1, "ram_available_mb": 109036.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13468.9, "ram_available_mb": 109037.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 31.7, 31.7, 31.7, 31.7, 31.7, 45.41, 45.41, 45.41, 45.41, 45.41, 49.12, 49.12, 49.12], "power_watts_avg": 40.17, "power_watts_peak": 49.12, "energy_joules_est": 56.88, "sample_count": 15, "duration_seconds": 1.416}, "timestamp": "2026-01-12T10:20:46.531747"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 828.355, "latencies_ms": [828.355], "images_per_second": 1.207, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A young girl is sitting on a bed in a bedroom with orange walls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13468.9, "ram_available_mb": 109037.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13457.9, "ram_available_mb": 109048.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 18.0}, "power_stats": {"power_watts_samples": [49.12, 49.12, 32.11, 32.11, 32.11, 32.11, 32.11, 46.35, 46.35], "power_watts_avg": 39.06, "power_watts_peak": 49.12, "energy_joules_est": 32.37, "sample_count": 9, "duration_seconds": 0.829}, "timestamp": "2026-01-12T10:20:47.444659"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 931.562, "latencies_ms": [931.562], "images_per_second": 1.073, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is painted in a warm orange color, and the floor is made of stone tiles.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13450.1, "ram_available_mb": 109056.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13449.9, "ram_available_mb": 109056.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.35, 46.35, 46.35, 50.88, 50.88, 50.88, 50.88, 50.88, 46.78, 46.78], "power_watts_avg": 48.7, "power_watts_peak": 50.88, "energy_joules_est": 45.4, "sample_count": 10, "duration_seconds": 0.932}, "timestamp": "2026-01-12T10:20:48.457073"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1882.037, "latencies_ms": [1882.037], "images_per_second": 0.531, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " In the image, a baseball game is in progress with a batter, catcher, and umpire on the field, with the batter preparing to swing at a pitch, the catcher crouched behind him, and the umpire standing behind the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13449.9, "ram_available_mb": 109056.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13460.9, "ram_available_mb": 109045.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.78, 46.78, 46.3, 46.3, 46.3, 46.3, 46.3, 46.54, 46.54, 46.54, 46.54, 46.54, 45.07, 45.07, 45.07, 45.07, 45.07, 34.89, 34.89], "power_watts_avg": 44.89, "power_watts_peak": 46.78, "energy_joules_est": 84.51, "sample_count": 19, "duration_seconds": 1.883}, "timestamp": "2026-01-12T10:20:50.377468"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2019.494, "latencies_ms": [2019.494], "images_per_second": 0.495, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. baseball: 1\n6. baseball field: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13456.9, "ram_available_mb": 109049.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13445.1, "ram_available_mb": 109061.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 37.94, 37.94, 37.94, 37.94, 37.94, 46.6, 46.6, 46.6, 46.6, 46.6, 44.2, 44.2, 44.2, 44.2, 44.2, 34.8, 34.8, 34.8], "power_watts_avg": 40.61, "power_watts_peak": 46.6, "energy_joules_est": 82.05, "sample_count": 21, "duration_seconds": 2.02}, "timestamp": "2026-01-12T10:20:52.547917"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1372.254, "latencies_ms": [1372.254], "images_per_second": 0.729, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13437.2, "ram_available_mb": 109069.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13443.6, "ram_available_mb": 109062.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.8, 30.94, 30.94, 30.94, 30.94, 30.94, 45.31, 45.31, 45.31, 45.31, 45.31, 48.95, 48.95, 48.95], "power_watts_avg": 40.21, "power_watts_peak": 48.95, "energy_joules_est": 55.22, "sample_count": 14, "duration_seconds": 1.373}, "timestamp": "2026-01-12T10:20:54.011702"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2103.683, "latencies_ms": [2103.683], "images_per_second": 0.475, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter poised to swing at the incoming pitch, the catcher crouched behind him, and the umpire attentively observing the play. The lush green field stretches out behind them, providing a stark contrast to the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13435.7, "ram_available_mb": 109070.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13420.4, "ram_available_mb": 109085.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.95, 48.95, 35.26, 35.26, 35.26, 35.26, 35.26, 47.55, 47.55, 47.55, 47.55, 47.55, 47.21, 47.21, 47.21, 47.21, 47.21, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 42.24, "power_watts_peak": 48.95, "energy_joules_est": 88.88, "sample_count": 21, "duration_seconds": 2.104}, "timestamp": "2026-01-12T10:20:56.130645"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1758.324, "latencies_ms": [1758.324], "images_per_second": 0.569, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the lush green grass of the field contrasting against the brown dirt of the infield. The sun casts a warm glow on the scene, illuminating the players and their actions with a soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.4, "ram_available_mb": 109085.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13416.1, "ram_available_mb": 109090.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.12, 34.12, 34.12, 34.12, 34.12, 46.75, 46.75, 46.75, 46.75, 46.75, 47.67, 47.67, 47.67, 47.67, 47.67, 34.75, 34.75, 34.75], "power_watts_avg": 41.5, "power_watts_peak": 47.67, "energy_joules_est": 73.0, "sample_count": 18, "duration_seconds": 1.759}, "timestamp": "2026-01-12T10:20:57.996266"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 728.175, "latencies_ms": [728.175], "images_per_second": 1.373, "prompt_tokens": 1099, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A cat is eating a bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.4, "ram_available_mb": 109089.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13439.7, "ram_available_mb": 109066.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.75, 34.75, 34.89, 34.89, 34.89, 34.89, 34.89, 46.87], "power_watts_avg": 36.35, "power_watts_peak": 46.87, "energy_joules_est": 26.5, "sample_count": 8, "duration_seconds": 0.729}, "timestamp": "2026-01-12T10:20:58.808337"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1596.025, "latencies_ms": [1596.025], "images_per_second": 0.627, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " cat: 1, bird: 1, mouse: 1, mouse head: 1, mouse body: 1, mouse tail: 1, mouse legs: 1, mouse feet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13439.7, "ram_available_mb": 109066.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13399.6, "ram_available_mb": 109106.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.87, 46.87, 46.87, 46.87, 55.16, 55.16, 55.16, 55.16, 55.16, 46.68, 46.68, 46.68, 46.68, 46.68, 39.41, 39.41], "power_watts_avg": 48.47, "power_watts_peak": 55.16, "energy_joules_est": 77.36, "sample_count": 16, "duration_seconds": 1.596}, "timestamp": "2026-01-12T10:21:00.422477"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1541.393, "latencies_ms": [1541.393], "images_per_second": 0.649, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The bird is in the foreground, with the cat's head in the middle ground. The cat's body is partially obscured by the bird, and the bird is positioned to the left of the cat's head.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.7, "ram_available_mb": 109114.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13309.1, "ram_available_mb": 109197.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.41, 39.41, 39.41, 39.1, 39.1, 39.1, 39.1, 39.1, 48.03, 48.03, 48.03, 48.03, 48.03, 44.53, 44.53, 44.53], "power_watts_avg": 42.97, "power_watts_peak": 48.03, "energy_joules_est": 66.24, "sample_count": 16, "duration_seconds": 1.542}, "timestamp": "2026-01-12T10:21:02.038692"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 724.912, "latencies_ms": [724.912], "images_per_second": 1.379, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A cat is eating a bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.1, "ram_available_mb": 109197.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13371.9, "ram_available_mb": 109134.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.53, 44.53, 32.87, 32.87, 32.87, 32.87, 32.87, 46.98], "power_watts_avg": 37.55, "power_watts_peak": 46.98, "energy_joules_est": 27.24, "sample_count": 8, "duration_seconds": 0.725}, "timestamp": "2026-01-12T10:21:02.850373"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1775.989, "latencies_ms": [1775.989], "images_per_second": 0.563, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a close-up of a cat with a bird in its mouth, the cat's fur is white and grey, and the bird is brown and red. The lighting is natural and bright, and the cat is on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.0, "ram_available_mb": 109146.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13352.4, "ram_available_mb": 109153.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.98, 46.98, 46.98, 55.52, 55.52, 55.52, 55.52, 55.52, 46.16, 46.16, 46.16, 46.16, 46.16, 41.07, 41.07, 41.07, 41.07, 41.07], "power_watts_avg": 47.48, "power_watts_peak": 55.52, "energy_joules_est": 84.36, "sample_count": 18, "duration_seconds": 1.777}, "timestamp": "2026-01-12T10:21:04.666203"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1024.151, "latencies_ms": [1024.151], "images_per_second": 0.976, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a sandwich with lettuce, tomato, and cheese in their hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.4, "ram_available_mb": 109153.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.37, 34.37, 34.37, 34.37, 34.37, 47.75, 47.75, 47.75, 47.75, 47.75, 51.94], "power_watts_avg": 42.05, "power_watts_peak": 51.94, "energy_joules_est": 43.07, "sample_count": 11, "duration_seconds": 1.024}, "timestamp": "2026-01-12T10:21:05.777273"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2084.053, "latencies_ms": [2084.053], "images_per_second": 0.48, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. hand: 1\n2. sandwich: 1\n3. bread: 1\n4. tomato: 1\n5. lettuce: 1\n6. cheese: 1\n7. sauce: 1\n8. stove: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.4, "ram_available_mb": 109143.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13376.1, "ram_available_mb": 109130.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [51.94, 51.94, 51.94, 51.94, 46.04, 46.04, 46.04, 46.04, 46.04, 50.62, 50.62, 50.62, 50.62, 50.62, 42.95, 42.95, 42.95, 42.95, 42.95, 34.88, 34.88], "power_watts_avg": 46.46, "power_watts_peak": 51.94, "energy_joules_est": 96.86, "sample_count": 21, "duration_seconds": 2.085}, "timestamp": "2026-01-12T10:21:07.896009"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1426.971, "latencies_ms": [1426.971], "images_per_second": 0.701, "prompt_tokens": 1450, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The sandwich is held in the left hand, with the right hand holding the plate. The sandwich is in the foreground, while the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13376.1, "ram_available_mb": 109130.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.2, "ram_available_mb": 109153.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.95, 34.95, 34.95, 34.95, 50.33, 50.33, 50.33, 50.33, 50.33, 51.23, 51.23, 51.23], "power_watts_avg": 43.32, "power_watts_peak": 51.23, "energy_joules_est": 61.83, "sample_count": 15, "duration_seconds": 1.427}, "timestamp": "2026-01-12T10:21:09.464388"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1119.05, "latencies_ms": [1119.05], "images_per_second": 0.894, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is holding a sandwich with lettuce and tomato on it. The sandwich is on a white plate.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13373.2, "ram_available_mb": 109133.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [51.23, 51.23, 34.69, 34.69, 34.69, 34.69, 34.69, 50.77, 50.77, 50.77, 50.77, 50.77], "power_watts_avg": 44.14, "power_watts_peak": 51.23, "energy_joules_est": 49.42, "sample_count": 12, "duration_seconds": 1.12}, "timestamp": "2026-01-12T10:21:10.677079"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1012.359, "latencies_ms": [1012.359], "images_per_second": 0.988, "prompt_tokens": 1442, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The sandwich is on a white plate and the hand holding it is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.4, "ram_available_mb": 109140.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13372.9, "ram_available_mb": 109133.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [50.48, 50.48, 50.48, 50.48, 50.48, 47.08, 47.08, 47.08, 47.08, 47.08, 52.03], "power_watts_avg": 49.08, "power_watts_peak": 52.03, "energy_joules_est": 49.72, "sample_count": 11, "duration_seconds": 1.013}, "timestamp": "2026-01-12T10:21:11.788114"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1110.63, "latencies_ms": [1110.63], "images_per_second": 0.9, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two girls are sitting on the back of a boat, one of them is wearing a hat and they are looking at the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13354.4, "ram_available_mb": 109151.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.03, 52.03, 52.03, 52.03, 47.93, 47.93, 47.93, 47.93, 47.93, 46.33, 46.33, 46.33], "power_watts_avg": 48.9, "power_watts_peak": 52.03, "energy_joules_est": 54.34, "sample_count": 12, "duration_seconds": 1.111}, "timestamp": "2026-01-12T10:21:12.999840"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.224, "latencies_ms": [1902.224], "images_per_second": 0.526, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. girl: 2\n2. hat: 1\n3. girl: 1\n4. girl: 1\n5. girl: 1\n6. girl: 1\n7. girl: 1\n8. girl: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.5, "ram_available_mb": 109159.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.33, 46.33, 37.65, 37.65, 37.65, 37.65, 37.65, 46.66, 46.66, 46.66, 46.66, 46.66, 46.99, 46.99, 46.99, 46.99, 46.99, 35.0, 35.0], "power_watts_avg": 43.12, "power_watts_peak": 46.99, "energy_joules_est": 82.03, "sample_count": 19, "duration_seconds": 1.903}, "timestamp": "2026-01-12T10:21:14.918008"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1729.508, "latencies_ms": [1729.508], "images_per_second": 0.578, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The girl in the white shirt is sitting on the left side of the boat, while the girl in the pink shirt is sitting on the right side. The girl in the white shirt is closer to the camera than the girl in the pink shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.3, "ram_available_mb": 109160.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.5, "ram_available_mb": 109143.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 36.49, 36.49, 36.49, 36.49, 36.49, 47.18, 47.18, 47.18, 47.18, 47.18, 45.57, 45.57, 45.57, 45.57, 45.57, 34.86], "power_watts_avg": 41.73, "power_watts_peak": 47.18, "energy_joules_est": 72.22, "sample_count": 18, "duration_seconds": 1.731}, "timestamp": "2026-01-12T10:21:16.784509"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 882.043, "latencies_ms": [882.043], "images_per_second": 1.134, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two girls are sitting on the back of a boat, looking out at the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.5, "ram_available_mb": 109143.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 43.97, 43.97, 43.97, 43.97, 43.97], "power_watts_avg": 39.92, "power_watts_peak": 43.97, "energy_joules_est": 35.23, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:21:17.697060"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1254.075, "latencies_ms": [1254.075], "images_per_second": 0.797, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image features a boat with a blue ocean in the background, and the sky is clear. The boat is white and has a gray cushion on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.4, "ram_available_mb": 109135.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.0, "ram_available_mb": 109150.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.77, 46.77, 46.77, 46.77, 46.77, 50.45, 50.45, 50.45, 50.45, 50.45, 47.53, 47.53, 47.53], "power_watts_avg": 48.36, "power_watts_peak": 50.45, "energy_joules_est": 60.67, "sample_count": 13, "duration_seconds": 1.255}, "timestamp": "2026-01-12T10:21:19.011426"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 906.224, "latencies_ms": [906.224], "images_per_second": 1.103, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A sheep with white wool stands in a grassy field with a stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.1, "ram_available_mb": 109158.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13372.1, "ram_available_mb": 109134.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.53, 47.53, 34.62, 34.62, 34.62, 34.62, 34.62, 47.05, 47.05], "power_watts_avg": 40.25, "power_watts_peak": 47.53, "energy_joules_est": 36.48, "sample_count": 9, "duration_seconds": 0.906}, "timestamp": "2026-01-12T10:21:19.926033"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 530.478, "latencies_ms": [530.478], "images_per_second": 1.885, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.2, "ram_available_mb": 109138.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13376.3, "ram_available_mb": 109130.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.05, 47.05, 47.05, 53.01, 53.01, 53.01], "power_watts_avg": 50.03, "power_watts_peak": 53.01, "energy_joules_est": 26.55, "sample_count": 6, "duration_seconds": 0.531}, "timestamp": "2026-01-12T10:21:20.535990"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1438.116, "latencies_ms": [1438.116], "images_per_second": 0.695, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sheep is standing in the foreground, close to the camera, and is positioned in front of a stone wall. The wall is behind the sheep, and the grass is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.3, "ram_available_mb": 109130.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [53.01, 53.01, 46.87, 46.87, 46.87, 46.87, 46.87, 56.12, 56.12, 56.12, 56.12, 56.12, 49.23, 49.23, 49.23], "power_watts_avg": 51.24, "power_watts_peak": 56.12, "energy_joules_est": 73.72, "sample_count": 15, "duration_seconds": 1.439}, "timestamp": "2026-01-12T10:21:22.051692"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1251.493, "latencies_ms": [1251.493], "images_per_second": 0.799, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A sheep with white wool stands in a grassy field, looking at the camera. The field is bordered by a stone wall with yellow lichen growing on it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13368.9, "ram_available_mb": 109137.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13419.3, "ram_available_mb": 109087.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.23, 49.23, 32.41, 32.41, 32.41, 32.41, 32.41, 46.72, 46.72, 46.72, 46.72, 49.41, 49.41], "power_watts_avg": 42.02, "power_watts_peak": 49.41, "energy_joules_est": 52.6, "sample_count": 13, "duration_seconds": 1.252}, "timestamp": "2026-01-12T10:21:23.362604"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 850.582, "latencies_ms": [850.582], "images_per_second": 1.176, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The sheep is white, the grass is green, and the wall is gray.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13419.3, "ram_available_mb": 109087.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13419.2, "ram_available_mb": 109087.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [49.41, 49.41, 49.41, 41.36, 41.36, 41.36, 41.36, 41.36, 47.46], "power_watts_avg": 44.72, "power_watts_peak": 49.41, "energy_joules_est": 38.07, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-12T10:21:24.274247"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1476.368, "latencies_ms": [1476.368], "images_per_second": 0.677, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A man in a white shirt and plaid shorts is standing next to a truck with a large cylindrical object on it, while another man in a blue shirt is standing on top of the truck.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.3, "ram_available_mb": 109095.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13342.5, "ram_available_mb": 109163.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.46, 47.46, 47.46, 47.46, 50.48, 50.48, 50.48, 50.48, 50.48, 46.9, 46.9, 46.9, 46.9, 46.9, 37.39], "power_watts_avg": 47.61, "power_watts_peak": 50.48, "energy_joules_est": 70.32, "sample_count": 15, "duration_seconds": 1.477}, "timestamp": "2026-01-12T10:21:25.785821"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2124.289, "latencies_ms": [2124.289], "images_per_second": 0.471, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. truck: 1\n2. man: 2\n3. man on truck: 1\n4. man on ground: 1\n5. container: 1\n6. pipe: 1\n7. container on truck: 1\n8. container on ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.5, "ram_available_mb": 109163.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13318.7, "ram_available_mb": 109187.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [37.39, 37.39, 37.39, 37.39, 44.11, 44.11, 44.11, 44.11, 44.11, 47.43, 47.43, 47.43, 47.43, 47.43, 38.44, 38.44, 38.44, 38.44, 38.44, 35.09, 35.09, 35.09], "power_watts_avg": 41.12, "power_watts_peak": 47.43, "energy_joules_est": 87.39, "sample_count": 22, "duration_seconds": 2.125}, "timestamp": "2026-01-12T10:21:27.999564"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1679.637, "latencies_ms": [1679.637], "images_per_second": 0.595, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man in the white shirt is standing in the foreground, while the man in the blue shirt is standing on the truck in the background. The man in the white shirt is closer to the camera than the man in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13318.7, "ram_available_mb": 109187.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.8, "ram_available_mb": 109147.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.09, 35.09, 31.43, 31.43, 31.43, 31.43, 31.43, 45.69, 45.69, 45.69, 45.69, 45.69, 49.21, 49.21, 49.21, 49.21, 34.86], "power_watts_avg": 40.44, "power_watts_peak": 49.21, "energy_joules_est": 67.94, "sample_count": 17, "duration_seconds": 1.68}, "timestamp": "2026-01-12T10:21:29.764775"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1487.191, "latencies_ms": [1487.191], "images_per_second": 0.672, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " A man in a white shirt and plaid shorts is standing next to a truck with a large cylindrical object on it. The truck is parked in a parking lot, surrounded by trees and other buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.9, "ram_available_mb": 109155.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.0, "ram_available_mb": 109153.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 45.96, 45.96, 45.96, 45.96, 45.96, 47.72, 47.72, 47.72, 47.72, 47.72, 36.68], "power_watts_avg": 42.97, "power_watts_peak": 47.72, "energy_joules_est": 63.91, "sample_count": 15, "duration_seconds": 1.488}, "timestamp": "2026-01-12T10:21:31.280910"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1297.931, "latencies_ms": [1297.931], "images_per_second": 0.77, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is taken in a cloudy day with a man standing on a truck. The truck is carrying a large cylindrical object, which is black and blue in color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 94.0}, "power_stats": {"power_watts_samples": [36.68, 36.68, 36.68, 36.68, 44.92, 44.92, 44.92, 44.92, 44.92, 47.74, 47.74, 47.74, 47.74], "power_watts_avg": 43.25, "power_watts_peak": 47.74, "energy_joules_est": 56.16, "sample_count": 13, "duration_seconds": 1.298}, "timestamp": "2026-01-12T10:21:32.595701"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1029.546, "latencies_ms": [1029.546], "images_per_second": 0.971, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of giraffes is walking in a line across a dirt path, with a pond and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13364.7, "ram_available_mb": 109141.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.74, 37.15, 37.15, 37.15, 37.15, 37.15, 48.11, 48.11, 48.11, 48.11, 48.11], "power_watts_avg": 43.09, "power_watts_peak": 48.11, "energy_joules_est": 44.4, "sample_count": 11, "duration_seconds": 1.03}, "timestamp": "2026-01-12T10:21:33.711247"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1904.228, "latencies_ms": [1904.228], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. giraffe: 4\n2. giraffe: 4\n3. giraffe: 4\n4. giraffe: 4\n5. giraffe: 4\n6. giraffe: 4\n7. giraffe: 4\n8. giraffe: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.9, "ram_available_mb": 109149.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13353.5, "ram_available_mb": 109152.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.16, 49.16, 49.16, 49.16, 49.16, 47.02, 47.02, 47.02, 47.02, 47.02, 47.36, 47.36, 47.36, 47.36, 47.36, 35.03, 35.03, 35.03, 35.03], "power_watts_avg": 45.15, "power_watts_peak": 49.16, "energy_joules_est": 85.98, "sample_count": 19, "duration_seconds": 1.905}, "timestamp": "2026-01-12T10:21:35.629166"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1427.068, "latencies_ms": [1427.068], "images_per_second": 0.701, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The giraffes are positioned in the foreground of the image, with the pond and trees in the background. The giraffes are walking towards the pond, which is located to the left of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.6, "ram_available_mb": 109156.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.1, "ram_available_mb": 109164.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.27, 34.27, 34.27, 34.27, 34.27, 47.23, 47.23, 47.23, 47.23, 47.23, 47.99, 47.99, 47.99, 47.99, 47.99], "power_watts_avg": 43.16, "power_watts_peak": 47.99, "energy_joules_est": 61.65, "sample_count": 15, "duration_seconds": 1.428}, "timestamp": "2026-01-12T10:21:37.196531"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1090.693, "latencies_ms": [1090.693], "images_per_second": 0.917, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of giraffes are walking in a line through a dirt path near a pond, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13342.1, "ram_available_mb": 109164.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [34.16, 34.16, 34.16, 34.16, 34.16, 46.71, 46.71, 46.71, 46.71, 46.71, 47.54], "power_watts_avg": 41.08, "power_watts_peak": 47.54, "energy_joules_est": 44.83, "sample_count": 11, "duration_seconds": 1.091}, "timestamp": "2026-01-12T10:21:38.310008"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 907.049, "latencies_ms": [907.049], "images_per_second": 1.102, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The giraffes are brown and white, the trees are green, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13358.6, "ram_available_mb": 109147.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.54, 47.54, 47.54, 47.54, 44.22, 44.22, 44.22, 44.22, 44.22, 47.8], "power_watts_avg": 45.9, "power_watts_peak": 47.8, "energy_joules_est": 41.67, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-12T10:21:39.323186"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1035.87, "latencies_ms": [1035.87], "images_per_second": 0.965, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A pizza with various toppings is on a plate, with a glass of beer and a glass of water nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.6, "ram_available_mb": 109151.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.8, 47.8, 47.8, 47.8, 46.51, 46.51, 46.51, 46.51, 46.51, 46.18, 46.18], "power_watts_avg": 46.92, "power_watts_peak": 47.8, "energy_joules_est": 48.63, "sample_count": 11, "duration_seconds": 1.037}, "timestamp": "2026-01-12T10:21:40.437649"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1249.468, "latencies_ms": [1249.468], "images_per_second": 0.8, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " pizza: 1, glass: 2, wine: 1, tablecloth: 1, chair: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.8, "ram_available_mb": 109160.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13361.9, "ram_available_mb": 109144.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_watts_samples": [46.18, 46.18, 46.18, 42.57, 42.57, 42.57, 42.57, 42.57, 46.91, 46.91, 46.91, 46.91, 46.91], "power_watts_avg": 45.07, "power_watts_peak": 46.91, "energy_joules_est": 56.33, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-12T10:21:41.751699"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1406.797, "latencies_ms": [1406.797], "images_per_second": 0.711, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The pizza is positioned in the foreground, with the glasses of beer placed behind it. The glasses of beer are located in the middle ground, with the table and chairs in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.9, "ram_available_mb": 109144.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13447.9, "ram_available_mb": 109058.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [43.95, 43.95, 43.95, 43.95, 43.95, 45.59, 45.59, 45.59, 45.59, 45.59, 47.18, 47.18, 47.18, 47.18, 47.18], "power_watts_avg": 45.57, "power_watts_peak": 47.18, "energy_joules_est": 64.13, "sample_count": 15, "duration_seconds": 1.407}, "timestamp": "2026-01-12T10:21:43.262504"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1114.607, "latencies_ms": [1114.607], "images_per_second": 0.897, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In a cozy restaurant, a delicious pizza with various toppings is served on a white plate, accompanied by two glasses of beer.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13447.9, "ram_available_mb": 109058.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13424.8, "ram_available_mb": 109081.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [36.06, 36.06, 36.06, 36.06, 44.57, 44.57, 44.57, 44.57, 44.57, 46.26, 46.26, 46.26], "power_watts_avg": 42.15, "power_watts_peak": 46.26, "energy_joules_est": 47.0, "sample_count": 12, "duration_seconds": 1.115}, "timestamp": "2026-01-12T10:21:44.474141"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2361.699, "latencies_ms": [2361.699], "images_per_second": 0.423, "prompt_tokens": 1109, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a pizza with a variety of toppings, including mushrooms, pineapple, and ham, placed on a white plate. The pizza is placed on a table covered with a blue tablecloth, and there are two glasses of beer in the background. The lighting in the room is warm, and the overall atmosphere appears to be a cozy and inviting dining experience.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13416.9, "ram_available_mb": 109089.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13387.5, "ram_available_mb": 109118.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.26, 46.26, 38.21, 38.21, 38.21, 38.21, 38.21, 46.6, 46.6, 46.6, 46.6, 46.6, 45.89, 45.89, 45.89, 45.89, 45.89, 34.92, 34.92, 34.92, 34.92, 34.92, 34.97, 34.97], "power_watts_avg": 41.27, "power_watts_peak": 46.6, "energy_joules_est": 97.49, "sample_count": 24, "duration_seconds": 2.362}, "timestamp": "2026-01-12T10:21:46.888574"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 849.968, "latencies_ms": [849.968], "images_per_second": 1.177, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white cat is drinking water from a faucet in a bathroom sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13415.3, "ram_available_mb": 109091.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 36.83, 36.83, 36.83, 36.83, 36.83, 46.39], "power_watts_avg": 37.27, "power_watts_peak": 46.39, "energy_joules_est": 31.72, "sample_count": 9, "duration_seconds": 0.851}, "timestamp": "2026-01-12T10:21:47.851920"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2055.059, "latencies_ms": [2055.059], "images_per_second": 0.487, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. black cat: 1\n2. sink: 1\n3. faucet: 1\n4. soap bottle: 1\n5. water: 1\n6. white plate: 1\n7. white wall: 1\n8. white baseboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.3, "ram_available_mb": 109091.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13387.5, "ram_available_mb": 109118.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.39, 46.39, 46.39, 46.39, 51.89, 51.89, 51.89, 51.89, 51.89, 47.03, 47.03, 47.03, 47.03, 47.03, 40.5, 40.5, 40.5, 40.5, 40.5, 35.09, 35.09], "power_watts_avg": 45.37, "power_watts_peak": 51.89, "energy_joules_est": 93.27, "sample_count": 21, "duration_seconds": 2.056}, "timestamp": "2026-01-12T10:21:49.968302"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1422.765, "latencies_ms": [1422.765], "images_per_second": 0.703, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The cat is positioned to the right of the faucet, with its head near the water stream. The sink is located in the foreground, while the bottle of soap is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.7, "ram_available_mb": 109126.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13404.5, "ram_available_mb": 109101.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.09, 35.09, 33.57, 33.57, 33.57, 33.57, 33.57, 46.13, 46.13, 46.13, 46.13, 46.13, 48.51, 48.51, 48.51], "power_watts_avg": 40.95, "power_watts_peak": 48.51, "energy_joules_est": 58.28, "sample_count": 15, "duration_seconds": 1.423}, "timestamp": "2026-01-12T10:21:51.529853"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 850.009, "latencies_ms": [850.009], "images_per_second": 1.176, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white cat is drinking water from a faucet in a bathroom sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.5, "ram_available_mb": 109105.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13400.8, "ram_available_mb": 109105.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 23.0}, "power_stats": {"power_watts_samples": [48.51, 48.51, 33.57, 33.57, 33.57, 33.57, 33.57, 46.76, 46.76], "power_watts_avg": 39.82, "power_watts_peak": 48.51, "energy_joules_est": 33.86, "sample_count": 9, "duration_seconds": 0.85}, "timestamp": "2026-01-12T10:21:52.439112"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1898.61, "latencies_ms": [1898.61], "images_per_second": 0.527, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a black and white cat drinking water from a faucet in a bathroom. The cat is positioned in front of a white sink, with a bottle of soap and a white dish nearby. The lighting in the bathroom is bright, and the overall atmosphere is calm and domestic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13392.9, "ram_available_mb": 109113.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.76, 46.76, 46.76, 51.68, 51.68, 51.68, 51.68, 51.68, 47.35, 47.35, 47.35, 47.35, 47.35, 44.53, 44.53, 44.53, 44.53, 44.53, 35.08], "power_watts_avg": 47.01, "power_watts_peak": 51.68, "energy_joules_est": 89.29, "sample_count": 19, "duration_seconds": 1.899}, "timestamp": "2026-01-12T10:21:54.360349"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1788.749, "latencies_ms": [1788.749], "images_per_second": 0.559, "prompt_tokens": 1432, "response_tokens_est": 45, "n_tiles": 1, "output_text": " In the image, a man wearing a hat and a woman wearing a hat are riding in a horse-drawn carriage, with the horse walking in a muddy field, and the carriage is reflected in a puddle of water.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13389.5, "ram_available_mb": 109116.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13374.1, "ram_available_mb": 109132.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.08, 35.08, 35.08, 36.33, 36.33, 36.33, 36.33, 36.33, 50.38, 50.38, 50.38, 50.38, 50.38, 49.91, 49.91, 49.91, 49.91, 49.91], "power_watts_avg": 43.8, "power_watts_peak": 50.38, "energy_joules_est": 78.37, "sample_count": 18, "duration_seconds": 1.789}, "timestamp": "2026-01-12T10:21:56.231064"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2357.033, "latencies_ms": [2357.033], "images_per_second": 0.424, "prompt_tokens": 1446, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. horse: 1\n2. man: 1\n3. carriage: 1\n4. man's hat: 1\n5. man's shirt: 1\n6. man's pants: 1\n7. man's boots: 1\n8. man's belt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.1, "ram_available_mb": 109133.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13305.3, "ram_available_mb": 109201.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.9, 34.9, 34.9, 34.9, 34.9, 44.88, 44.88, 44.88, 44.88, 44.88, 51.17, 51.17, 51.17, 51.17, 51.17, 42.22, 42.22, 42.22, 42.22, 42.22, 35.02, 35.02, 35.02, 35.02], "power_watts_avg": 41.92, "power_watts_peak": 51.17, "energy_joules_est": 98.82, "sample_count": 24, "duration_seconds": 2.358}, "timestamp": "2026-01-12T10:21:58.648003"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2263.699, "latencies_ms": [2263.699], "images_per_second": 0.442, "prompt_tokens": 1450, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, pulling the carriage towards the right side of the image. The reflection of the carriage and horse can be seen in the water puddle, which is located in the middle ground of the image. The background features a barn and trees, which are positioned far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13305.3, "ram_available_mb": 109201.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.76, 33.76, 33.76, 33.76, 33.76, 45.24, 45.24, 45.24, 45.24, 45.24, 51.38, 51.38, 51.38, 51.38, 51.38, 39.96, 39.96, 39.96, 39.96, 39.96, 35.06, 35.06, 35.06], "power_watts_avg": 41.6, "power_watts_peak": 51.38, "energy_joules_est": 94.23, "sample_count": 23, "duration_seconds": 2.265}, "timestamp": "2026-01-12T10:22:01.027732"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1289.383, "latencies_ms": [1289.383], "images_per_second": 0.776, "prompt_tokens": 1444, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man and woman are riding in a horse-drawn carriage, with a large puddle reflecting the sky and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13378.8, "ram_available_mb": 109127.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [35.06, 31.44, 31.44, 31.44, 31.44, 31.44, 50.02, 50.02, 50.02, 50.02, 50.02, 53.72, 53.72], "power_watts_avg": 42.29, "power_watts_peak": 53.72, "energy_joules_est": 54.59, "sample_count": 13, "duration_seconds": 1.291}, "timestamp": "2026-01-12T10:22:02.398222"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2253.826, "latencies_ms": [2253.826], "images_per_second": 0.444, "prompt_tokens": 1442, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a horse-drawn carriage with two people riding in it, with the horse's reflection visible in a puddle of water. The sky is clear and blue, indicating a sunny day. The carriage is made of wood and has large spoked wheels, while the people are wearing hats and casual clothing.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13370.9, "ram_available_mb": 109135.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.4, "ram_available_mb": 109140.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [53.72, 53.72, 53.72, 38.63, 38.63, 38.63, 38.63, 38.63, 51.71, 51.71, 51.71, 51.71, 51.71, 48.33, 48.33, 48.33, 48.33, 48.33, 35.19, 35.19, 35.19, 35.19, 35.19], "power_watts_avg": 44.8, "power_watts_peak": 53.72, "energy_joules_est": 101.0, "sample_count": 23, "duration_seconds": 2.254}, "timestamp": "2026-01-12T10:22:04.720110"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.388, "latencies_ms": [983.388], "images_per_second": 1.017, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man and woman are standing together in a grassy area, with the man holding an umbrella over them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.4, "ram_available_mb": 109140.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13359.7, "ram_available_mb": 109146.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.2, 35.2, 35.2, 35.2, 35.2, 46.93, 46.93, 46.93, 46.93, 46.93], "power_watts_avg": 41.07, "power_watts_peak": 46.93, "energy_joules_est": 40.41, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-12T10:22:05.731213"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1906.26, "latencies_ms": [1906.26], "images_per_second": 0.525, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. umbrella: 1\n2. bride: 1\n3. groom: 1\n4. woman: 1\n5. man: 1\n6. house: 1\n7. grass: 1\n8. flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.7, "ram_available_mb": 109146.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.4, "ram_available_mb": 109148.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.9, 46.9, 46.9, 46.9, 46.9, 47.7, 47.7, 47.7, 47.7, 47.7, 47.94, 47.94, 47.94, 47.94, 47.94, 35.26, 35.26, 35.26, 35.26], "power_watts_avg": 44.93, "power_watts_peak": 47.94, "energy_joules_est": 85.68, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T10:22:07.649268"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2358.313, "latencies_ms": [2358.313], "images_per_second": 0.424, "prompt_tokens": 1118, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The bride is standing to the left of the groom, with the umbrella held by the groom in front of the bride. The bride is positioned in the foreground, while the groom is in the background. The umbrella is held by the groom, which is in front of the bride, and the bride is holding a bouquet of flowers, which is in her hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.5, "ram_available_mb": 109156.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13349.6, "ram_available_mb": 109156.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 34.73, 34.73, 47.27, 47.27, 47.27, 47.27, 47.27, 47.54, 47.54, 47.54, 47.54, 47.54, 35.01, 35.01, 35.01, 35.01, 35.01, 34.91, 34.91, 34.91, 34.91], "power_watts_avg": 40.1, "power_watts_peak": 47.54, "energy_joules_est": 94.61, "sample_count": 24, "duration_seconds": 2.359}, "timestamp": "2026-01-12T10:22:10.121171"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1568.665, "latencies_ms": [1568.665], "images_per_second": 0.637, "prompt_tokens": 1112, "response_tokens_est": 43, "n_tiles": 1, "output_text": " A couple is standing in a grassy area with a house in the background. The woman is wearing a white wedding dress and holding a bouquet of flowers. The man is wearing a black suit and holding an umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13361.4, "ram_available_mb": 109144.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.12, 33.12, 33.12, 33.12, 33.12, 46.18, 46.18, 46.18, 46.18, 46.18, 47.99, 47.99, 47.99, 47.99, 47.99, 34.87], "power_watts_avg": 41.96, "power_watts_peak": 47.99, "energy_joules_est": 65.84, "sample_count": 16, "duration_seconds": 1.569}, "timestamp": "2026-01-12T10:22:11.788437"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1660.031, "latencies_ms": [1660.031], "images_per_second": 0.602, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a couple standing under a black and white umbrella, with the bride wearing a white dress and the groom in a black suit. The weather appears to be rainy, as the umbrella is open to shield them from the rain.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13353.6, "ram_available_mb": 109152.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 34.87, 43.94, 43.94, 43.94, 43.94, 43.94, 47.49, 47.49, 47.49, 47.49, 47.49, 38.3, 38.3, 38.3], "power_watts_avg": 41.86, "power_watts_peak": 47.49, "energy_joules_est": 69.49, "sample_count": 17, "duration_seconds": 1.66}, "timestamp": "2026-01-12T10:22:13.501531"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1176.834, "latencies_ms": [1176.834], "images_per_second": 0.85, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people are on a beach, with one person lying down and another person sitting up, and a kite flying in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13347.7, "ram_available_mb": 109158.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.3, 38.3, 35.01, 35.01, 35.01, 35.01, 35.01, 47.09, 47.09, 47.09, 47.09, 47.09], "power_watts_avg": 40.6, "power_watts_peak": 47.09, "energy_joules_est": 47.8, "sample_count": 12, "duration_seconds": 1.178}, "timestamp": "2026-01-12T10:22:14.714704"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1926.478, "latencies_ms": [1926.478], "images_per_second": 0.519, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sand: 3\n2. legs: 4\n3. shorts: 2\n4. kite: 1\n5. kite string: 1\n6. person: 2\n7. beach: 1\n8. ocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.7, "ram_available_mb": 109158.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.9, 47.9, 47.9, 47.9, 47.9, 47.69, 47.69, 47.69, 47.69, 47.69, 47.57, 47.57, 47.57, 47.57, 47.57, 35.34, 35.34, 35.34, 35.34, 35.34], "power_watts_avg": 44.62, "power_watts_peak": 47.9, "energy_joules_est": 85.99, "sample_count": 20, "duration_seconds": 1.927}, "timestamp": "2026-01-12T10:22:16.732569"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1541.257, "latencies_ms": [1541.257], "images_per_second": 0.649, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The kite is in the foreground, with the people lying on the beach in the background. The kite is positioned to the right of the people, and the people are lying on the left side of the beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.2, "ram_available_mb": 109165.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13350.6, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.8, 34.8, 42.84, 42.84, 42.84, 42.84, 42.84, 45.53, 45.53, 45.53, 45.53, 45.53, 36.77, 36.77], "power_watts_avg": 40.91, "power_watts_peak": 45.53, "energy_joules_est": 63.11, "sample_count": 16, "duration_seconds": 1.542}, "timestamp": "2026-01-12T10:22:18.397627"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 848.109, "latencies_ms": [848.109], "images_per_second": 1.179, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are on a beach with a kite flying in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.6, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [36.77, 36.77, 36.77, 39.24, 39.24, 39.24, 39.24, 39.24, 46.79], "power_watts_avg": 39.26, "power_watts_peak": 46.79, "energy_joules_est": 33.31, "sample_count": 9, "duration_seconds": 0.849}, "timestamp": "2026-01-12T10:22:19.309499"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1747.377, "latencies_ms": [1747.377], "images_per_second": 0.572, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a sandy beach with a clear blue sky and ocean waves in the background. The colors in the image are vibrant, with the sand being a light brown color, the ocean being a deep blue, and the sky being a light blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.3, "ram_available_mb": 109152.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13362.0, "ram_available_mb": 109144.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.79, 46.79, 46.79, 46.79, 51.58, 51.58, 51.58, 51.58, 51.58, 46.99, 46.99, 46.99, 46.99, 46.99, 38.02, 38.02, 38.02, 38.02], "power_watts_avg": 46.23, "power_watts_peak": 51.58, "energy_joules_est": 80.8, "sample_count": 18, "duration_seconds": 1.748}, "timestamp": "2026-01-12T10:22:21.126542"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1032.569, "latencies_ms": [1032.569], "images_per_second": 0.968, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A living room with a brown couch, a red chair, a black table, a lamp, and a TV.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.1, "ram_available_mb": 109152.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13363.7, "ram_available_mb": 109142.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [38.02, 33.14, 33.14, 33.14, 33.14, 33.14, 47.05, 47.05, 47.05, 47.05, 47.05], "power_watts_avg": 39.91, "power_watts_peak": 47.05, "energy_joules_est": 41.23, "sample_count": 11, "duration_seconds": 1.033}, "timestamp": "2026-01-12T10:22:22.238932"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2189.334, "latencies_ms": [2189.334], "images_per_second": 0.457, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. brown sofa: 1\n2. black chair: 1\n3. black stool: 1\n4. black table: 1\n5. black TV stand: 1\n6. black TV: 1\n7. black lamp: 1\n8. white wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13366.6, "ram_available_mb": 109139.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.4, 48.4, 48.4, 48.4, 48.4, 46.58, 46.58, 46.58, 46.58, 46.58, 46.46, 46.46, 46.46, 46.46, 46.46, 35.11, 35.11, 35.11, 35.11, 35.11, 34.77, 34.77], "power_watts_avg": 43.29, "power_watts_peak": 48.4, "energy_joules_est": 94.78, "sample_count": 22, "duration_seconds": 2.19}, "timestamp": "2026-01-12T10:22:24.453912"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1442.274, "latencies_ms": [1442.274], "images_per_second": 0.693, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The couch is to the left of the coffee table, which is in front of the television. The lamp is to the right of the couch, and the window is behind the coffee table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.6, "ram_available_mb": 109139.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13441.4, "ram_available_mb": 109064.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 35.34, 35.34, 35.34, 35.34, 35.34, 46.61, 46.61, 46.61, 46.61, 46.61, 46.2, 46.2, 46.2], "power_watts_avg": 41.19, "power_watts_peak": 46.61, "energy_joules_est": 59.45, "sample_count": 15, "duration_seconds": 1.443}, "timestamp": "2026-01-12T10:22:26.017526"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 958.647, "latencies_ms": [958.647], "images_per_second": 1.043, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A living room with a brown couch, a red chair, a black table, and a TV.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13433.6, "ram_available_mb": 109072.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13435.6, "ram_available_mb": 109070.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.2, 46.2, 34.82, 34.82, 34.82, 34.82, 34.82, 46.76, 46.76, 46.76], "power_watts_avg": 40.68, "power_watts_peak": 46.76, "energy_joules_est": 39.03, "sample_count": 10, "duration_seconds": 0.959}, "timestamp": "2026-01-12T10:22:27.028393"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1091.891, "latencies_ms": [1091.891], "images_per_second": 0.916, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well lit with natural light coming through the windows, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13435.6, "ram_available_mb": 109070.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13474.9, "ram_available_mb": 109031.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.76, 46.76, 47.52, 47.52, 47.52, 47.52, 47.52, 47.15, 47.15, 47.15, 47.15], "power_watts_avg": 47.25, "power_watts_peak": 47.52, "energy_joules_est": 51.61, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-12T10:22:28.138645"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1042.735, "latencies_ms": [1042.735], "images_per_second": 0.959, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bald man wearing glasses is eating a slice of cake with a spoon in his hand.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13471.0, "ram_available_mb": 109035.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13466.5, "ram_available_mb": 109039.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.15, 47.16, 47.16, 47.16, 47.16, 47.16, 50.7, 50.7, 50.7, 50.7, 50.7], "power_watts_avg": 48.77, "power_watts_peak": 50.7, "energy_joules_est": 50.89, "sample_count": 11, "duration_seconds": 1.043}, "timestamp": "2026-01-12T10:22:29.251906"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2068.961, "latencies_ms": [2068.961], "images_per_second": 0.483, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. plate: 1\n3. spoon: 1\n4. cake: 1\n5. grass: 1\n6. tree: 1\n7. sky: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13466.5, "ram_available_mb": 109039.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13482.1, "ram_available_mb": 109024.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [52.98, 52.98, 52.98, 52.98, 52.98, 46.13, 46.13, 46.13, 46.13, 46.13, 51.11, 51.11, 51.11, 51.11, 51.11, 40.83, 40.83, 40.83, 40.83, 40.83, 35.03], "power_watts_avg": 47.16, "power_watts_peak": 52.98, "energy_joules_est": 97.59, "sample_count": 21, "duration_seconds": 2.069}, "timestamp": "2026-01-12T10:22:31.369713"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1617.183, "latencies_ms": [1617.183], "images_per_second": 0.618, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is in the foreground, eating a slice of cake. The cake is on a plate, which is in the middle of the image. The background is a park with trees and grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13482.0, "ram_available_mb": 109024.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13411.3, "ram_available_mb": 109095.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 37.11, 37.11, 37.11, 37.11, 37.11, 50.16, 50.16, 50.16, 50.16, 50.16, 48.42, 48.42, 48.42, 48.42], "power_watts_avg": 43.24, "power_watts_peak": 50.16, "energy_joules_est": 69.98, "sample_count": 17, "duration_seconds": 1.618}, "timestamp": "2026-01-12T10:22:33.138102"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1091.243, "latencies_ms": [1091.243], "images_per_second": 0.916, "prompt_tokens": 1444, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A bald man wearing glasses is eating a slice of cake in a park with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.4, "ram_available_mb": 109102.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13423.9, "ram_available_mb": 109082.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [48.42, 32.52, 32.52, 32.52, 32.52, 32.52, 49.7, 49.7, 49.7, 49.7, 49.7], "power_watts_avg": 41.77, "power_watts_peak": 49.7, "energy_joules_est": 45.6, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-12T10:22:34.249548"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1226.979, "latencies_ms": [1226.979], "images_per_second": 0.815, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and has a bald head. The sun is shining brightly, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13416.0, "ram_available_mb": 109090.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13425.6, "ram_available_mb": 109080.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [53.23, 53.23, 53.23, 53.23, 53.23, 47.96, 47.96, 47.96, 47.96, 47.96, 51.95, 51.95, 51.95], "power_watts_avg": 50.91, "power_watts_peak": 53.23, "energy_joules_est": 62.49, "sample_count": 13, "duration_seconds": 1.228}, "timestamp": "2026-01-12T10:22:35.562027"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 845.131, "latencies_ms": [845.131], "images_per_second": 1.183, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is walking with a donkey that is carrying a large load of luggage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.6, "ram_available_mb": 109084.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13408.9, "ram_available_mb": 109097.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 1.0}, "power_stats": {"power_watts_samples": [51.95, 51.95, 38.65, 38.65, 38.65, 38.65, 38.65, 46.6, 46.6], "power_watts_avg": 43.37, "power_watts_peak": 51.95, "energy_joules_est": 36.69, "sample_count": 9, "duration_seconds": 0.846}, "timestamp": "2026-01-12T10:22:36.474416"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1906.333, "latencies_ms": [1906.333], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. horse: 1\n3. luggage: 2\n4. backpack: 1\n5. blanket: 1\n6. rope: 1\n7. tree: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13401.1, "ram_available_mb": 109105.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.6, 46.6, 51.27, 51.27, 51.27, 51.27, 51.27, 47.33, 47.33, 47.33, 47.33, 47.33, 45.58, 45.58, 45.58, 45.58, 45.58, 34.94, 34.94], "power_watts_avg": 46.52, "power_watts_peak": 51.27, "energy_joules_est": 88.7, "sample_count": 19, "duration_seconds": 1.907}, "timestamp": "2026-01-12T10:22:38.390929"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1562.809, "latencies_ms": [1562.809], "images_per_second": 0.64, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is standing to the left of the donkey, which is positioned in the foreground of the image. The man is closer to the camera than the donkey, which is standing on a dirt path surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.3, "ram_available_mb": 109131.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13381.5, "ram_available_mb": 109124.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.94, 34.94, 34.94, 39.02, 39.02, 39.02, 39.02, 39.02, 47.41, 47.41, 47.41, 47.41, 47.41, 43.3, 43.3, 43.3], "power_watts_avg": 41.68, "power_watts_peak": 47.41, "energy_joules_est": 65.16, "sample_count": 16, "duration_seconds": 1.563}, "timestamp": "2026-01-12T10:22:40.055320"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1165.313, "latencies_ms": [1165.313], "images_per_second": 0.858, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man is walking with a donkey that has a large load of luggage on its back. The man is wearing a purple jacket and jeans.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13377.6, "ram_available_mb": 109128.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13382.7, "ram_available_mb": 109123.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.3, 43.3, 33.93, 33.93, 33.93, 33.93, 33.93, 47.22, 47.22, 47.22, 47.22, 47.22], "power_watts_avg": 41.03, "power_watts_peak": 47.22, "energy_joules_est": 47.84, "sample_count": 12, "duration_seconds": 1.166}, "timestamp": "2026-01-12T10:22:41.267408"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1488.899, "latencies_ms": [1488.899], "images_per_second": 0.672, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a man and a donkey with colorful luggage on its back. The man is wearing a purple jacket and the donkey is brown. The lighting is natural and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13374.8, "ram_available_mb": 109131.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.1, "ram_available_mb": 109124.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.42, 48.42, 48.42, 48.42, 48.42, 46.43, 46.43, 46.43, 46.43, 47.35, 47.35, 47.35, 47.35, 47.35, 35.77], "power_watts_avg": 46.69, "power_watts_peak": 48.42, "energy_joules_est": 69.54, "sample_count": 15, "duration_seconds": 1.489}, "timestamp": "2026-01-12T10:22:42.785211"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1658.658, "latencies_ms": [1658.658], "images_per_second": 0.603, "prompt_tokens": 766, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge adorned with blue lights, standing majestically over a river, with a boat docked on the river's edge, and people strolling along the riverbank, all under a dark sky speckled with stars.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.2, "ram_available_mb": 109132.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4528.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.77, 35.77, 35.77, 35.77, 43.06, 43.06, 43.06, 43.06, 43.06, 42.79, 42.79, 42.79, 42.79, 42.79, 34.82, 34.82, 34.82], "power_watts_avg": 39.81, "power_watts_peak": 43.06, "energy_joules_est": 66.05, "sample_count": 17, "duration_seconds": 1.659}, "timestamp": "2026-01-12T10:22:44.501307"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1721.861, "latencies_ms": [1721.861], "images_per_second": 0.581, "prompt_tokens": 780, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. lights: 1\n3. people: 1\n4. boat: 1\n5. water: 1\n6. street: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13399.4, "ram_available_mb": 109106.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.8, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 37.49, 37.49, 37.49, 37.49, 37.49, 42.98, 42.98, 42.98, 42.98, 42.98, 40.67, 40.67, 40.67, 40.67, 40.67, 35.19], "power_watts_avg": 39.47, "power_watts_peak": 42.98, "energy_joules_est": 67.98, "sample_count": 18, "duration_seconds": 1.722}, "timestamp": "2026-01-12T10:22:46.315481"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1058.918, "latencies_ms": [1058.918], "images_per_second": 0.944, "prompt_tokens": 784, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bridge is located in the background, with the river in the foreground. The people are standing on the sidewalk, which is adjacent to the river.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.4, "ram_available_mb": 109106.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13397.8, "ram_available_mb": 109108.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4575.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [35.19, 35.19, 35.19, 35.19, 42.25, 42.25, 42.25, 42.25, 42.25, 42.32, 42.32], "power_watts_avg": 39.69, "power_watts_peak": 42.32, "energy_joules_est": 42.07, "sample_count": 11, "duration_seconds": 1.06}, "timestamp": "2026-01-12T10:22:47.427893"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2272.882, "latencies_ms": [2272.882], "images_per_second": 0.44, "prompt_tokens": 778, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge illuminated with blue lights, spanning across a river. The bridge, a marvel of engineering, stands majestically against the backdrop of a dark sky, its lights reflecting off the water's surface. On the riverbank, a group of people can be seen, their forms slightly blurred, adding a sense of movement to the otherwise still scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.8, "ram_available_mb": 109108.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13356.8, "ram_available_mb": 109149.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [42.32, 42.32, 42.32, 40.51, 40.51, 40.51, 40.51, 40.51, 43.0, 43.0, 43.0, 43.0, 43.0, 37.56, 37.56, 37.56, 37.56, 37.56, 35.08, 35.08, 35.08, 35.08, 35.08], "power_watts_avg": 39.46, "power_watts_peak": 43.0, "energy_joules_est": 89.71, "sample_count": 23, "duration_seconds": 2.273}, "timestamp": "2026-01-12T10:22:49.747094"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1617.245, "latencies_ms": [1617.245], "images_per_second": 0.618, "prompt_tokens": 776, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a vibrant night scene featuring a brightly lit bridge with a unique, zigzag design, reflecting its illumination on the calm river below. The sky is dark, and the city lights are visible in the distance, creating a picturesque and lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13356.8, "ram_available_mb": 109149.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.1, 35.1, 35.1, 35.1, 42.11, 42.11, 42.11, 42.11, 42.11, 42.1, 42.1, 42.1, 42.1, 42.1, 35.08, 35.08, 35.08], "power_watts_avg": 39.22, "power_watts_peak": 42.11, "energy_joules_est": 63.45, "sample_count": 17, "duration_seconds": 1.618}, "timestamp": "2026-01-12T10:22:51.513338"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 995.389, "latencies_ms": [995.389], "images_per_second": 1.005, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person's foot is wearing a pink shoe with a bow on it, and they are wearing blue jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.6, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13379.7, "ram_available_mb": 109126.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 36.0}, "power_stats": {"power_watts_samples": [35.08, 35.08, 34.87, 34.87, 34.87, 34.87, 34.87, 46.63, 46.63, 46.63], "power_watts_avg": 38.44, "power_watts_peak": 46.63, "energy_joules_est": 38.27, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-12T10:22:52.526390"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2122.238, "latencies_ms": [2122.238], "images_per_second": 0.471, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. pink shoe: 1\n2. blue jeans: 1\n3. wooden floor: 1\n4. pink bow: 1\n5. blue paint: 1\n6. green paint: 1\n7. black paint: 1\n8. white paint: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.8, "ram_available_mb": 109130.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13292.0, "ram_available_mb": 109214.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.63, 46.63, 48.16, 48.16, 48.16, 48.16, 48.16, 47.92, 47.92, 47.92, 47.92, 47.92, 47.36, 47.36, 47.36, 47.36, 47.36, 34.88, 34.88, 34.88, 34.88, 34.88], "power_watts_avg": 44.76, "power_watts_peak": 48.16, "energy_joules_est": 95.01, "sample_count": 22, "duration_seconds": 2.122}, "timestamp": "2026-01-12T10:22:54.745661"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1527.452, "latencies_ms": [1527.452], "images_per_second": 0.655, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The pink shoe is positioned on the left side of the image, while the blue jeans are located on the right side. The pink shoe is in the foreground, while the blue jeans are in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13292.0, "ram_available_mb": 109214.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.7, "ram_available_mb": 109158.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.37, 34.37, 34.37, 34.37, 43.05, 43.05, 43.05, 43.05, 43.05, 45.95, 45.95, 45.95, 45.95, 45.95, 37.12, 37.12], "power_watts_avg": 41.05, "power_watts_peak": 45.95, "energy_joules_est": 62.71, "sample_count": 16, "duration_seconds": 1.528}, "timestamp": "2026-01-12T10:22:56.410125"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 713.453, "latencies_ms": [713.453], "images_per_second": 1.402, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A person is wearing a pink shoe and blue jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.7, "ram_available_mb": 109158.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13438.4, "ram_available_mb": 109067.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [37.12, 37.12, 37.12, 39.05, 39.05, 39.05, 39.05, 39.05], "power_watts_avg": 38.33, "power_watts_peak": 39.05, "energy_joules_est": 27.37, "sample_count": 8, "duration_seconds": 0.714}, "timestamp": "2026-01-12T10:22:57.219405"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2098.61, "latencies_ms": [2098.61], "images_per_second": 0.477, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image features a person wearing a pair of pink shoes and blue jeans, with a wooden floor in the background. The shoes are bright pink and have a bow on the front, while the jeans are a shade of blue. The lighting in the image is natural, and the overall atmosphere appears to be casual and relaxed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13438.4, "ram_available_mb": 109067.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13422.1, "ram_available_mb": 109084.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [45.42, 45.42, 45.42, 45.42, 45.42, 53.98, 53.98, 53.98, 53.98, 53.98, 47.54, 47.54, 47.54, 47.54, 47.54, 35.03, 35.03, 35.03, 35.03, 35.03, 35.12], "power_watts_avg": 45.0, "power_watts_peak": 53.98, "energy_joules_est": 94.47, "sample_count": 21, "duration_seconds": 2.099}, "timestamp": "2026-01-12T10:22:59.337132"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1046.007, "latencies_ms": [1046.007], "images_per_second": 0.956, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A woman and a boy are standing in a room with a red wall, and the woman is holding a knife.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13422.1, "ram_available_mb": 109084.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13327.5, "ram_available_mb": 109178.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.12, 35.12, 35.12, 40.48, 40.48, 40.48, 40.48, 40.48, 46.55, 46.55, 46.55], "power_watts_avg": 40.67, "power_watts_peak": 46.55, "energy_joules_est": 42.57, "sample_count": 11, "duration_seconds": 1.047}, "timestamp": "2026-01-12T10:23:00.497418"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1336.082, "latencies_ms": [1336.082], "images_per_second": 0.748, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " woman: 1, man: 1, cup: 1, plate: 1, knife: 1, red: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.5, "ram_available_mb": 109178.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.5, "ram_available_mb": 109122.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.55, 46.55, 42.92, 42.92, 42.92, 42.92, 42.92, 47.06, 47.06, 47.06, 47.06, 47.06, 46.16, 46.16], "power_watts_avg": 45.38, "power_watts_peak": 47.06, "energy_joules_est": 60.66, "sample_count": 14, "duration_seconds": 1.337}, "timestamp": "2026-01-12T10:23:01.912998"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1202.414, "latencies_ms": [1202.414], "images_per_second": 0.832, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The woman is standing to the left of the boy, with the table between them. The boy is standing closer to the camera than the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.6, "ram_available_mb": 109130.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13386.3, "ram_available_mb": 109120.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.16, 46.16, 46.16, 39.15, 39.15, 39.15, 39.15, 39.15, 46.46, 46.46, 46.46, 46.46], "power_watts_avg": 43.34, "power_watts_peak": 46.46, "energy_joules_est": 52.14, "sample_count": 12, "duration_seconds": 1.203}, "timestamp": "2026-01-12T10:23:03.125863"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1204.649, "latencies_ms": [1204.649], "images_per_second": 0.83, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A woman and a boy are standing in a room with a red wall. The woman is holding a knife and the boy is holding a cup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.4, "ram_available_mb": 109127.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13313.5, "ram_available_mb": 109192.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.46, 41.17, 41.17, 41.17, 41.17, 41.17, 47.72, 47.72, 47.72, 47.72, 47.72, 48.42], "power_watts_avg": 44.95, "power_watts_peak": 48.42, "energy_joules_est": 54.17, "sample_count": 12, "duration_seconds": 1.205}, "timestamp": "2026-01-12T10:23:04.338718"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1464.335, "latencies_ms": [1464.335], "images_per_second": 0.683, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image has a warm and inviting atmosphere, with soft lighting and a red wall in the background. The woman is wearing a green cardigan and the boy is wearing a blue plaid shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13313.5, "ram_available_mb": 109192.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.42, 48.42, 48.42, 48.42, 44.03, 44.03, 44.03, 44.03, 44.03, 48.15, 48.15, 48.15, 48.15, 48.15, 39.84], "power_watts_avg": 46.29, "power_watts_peak": 48.42, "energy_joules_est": 67.81, "sample_count": 15, "duration_seconds": 1.465}, "timestamp": "2026-01-12T10:23:05.853649"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2674.881, "latencies_ms": [2674.881], "images_per_second": 0.374, "prompt_tokens": 1099, "response_tokens_est": 85, "n_tiles": 1, "output_text": " In the center of an indoor arena, two elephants are engaged in a performance, their trunks intertwined in a display of strength and coordination. The arena, with its high ceiling and rows of empty seats, is bathed in the soft glow of overhead lights, casting a warm ambiance over the scene. A camera on a tripod stands ready to capture the spectacle, its lens trained on the elephants as they perform their routine.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13337.2, "ram_available_mb": 109169.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [39.84, 39.84, 39.84, 39.84, 42.28, 42.28, 42.28, 42.28, 42.28, 47.33, 47.33, 47.33, 47.33, 47.33, 39.79, 39.79, 39.79, 39.79, 39.79, 34.88, 34.88, 34.88, 34.88, 34.88, 34.85, 34.85, 34.85], "power_watts_avg": 40.2, "power_watts_peak": 47.33, "energy_joules_est": 107.55, "sample_count": 27, "duration_seconds": 2.675}, "timestamp": "2026-01-12T10:23:08.575776"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1465.464, "latencies_ms": [1465.464], "images_per_second": 0.682, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " elephant: 3, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.7, "ram_available_mb": 109160.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13348.9, "ram_available_mb": 109157.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.85, 34.85, 32.83, 32.83, 32.83, 32.83, 32.83, 47.25, 47.25, 47.25, 47.25, 47.25, 49.44, 49.44, 49.44], "power_watts_avg": 41.23, "power_watts_peak": 49.44, "energy_joules_est": 60.44, "sample_count": 15, "duration_seconds": 1.466}, "timestamp": "2026-01-12T10:23:10.089459"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1488.431, "latencies_ms": [1488.431], "images_per_second": 0.672, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The elephants are positioned in the foreground of the image, with the camera and the audience in the background. The elephants are standing on a circular platform, which is surrounded by a red and yellow border.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.9, "ram_available_mb": 109157.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.8, "ram_available_mb": 109149.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.44, 32.38, 32.38, 32.38, 32.38, 32.38, 47.32, 47.32, 47.32, 47.32, 47.32, 49.98, 49.98, 49.98, 49.98], "power_watts_avg": 43.19, "power_watts_peak": 49.98, "energy_joules_est": 64.31, "sample_count": 15, "duration_seconds": 1.489}, "timestamp": "2026-01-12T10:23:11.604078"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1567.785, "latencies_ms": [1567.785], "images_per_second": 0.638, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In an indoor arena, two elephants are performing a trick for an audience. The elephants are standing on a circular platform with a red and yellow border, and they are being guided by a person in a red shirt.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13348.9, "ram_available_mb": 109157.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.9, "ram_available_mb": 109149.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.98, 33.07, 33.07, 33.07, 33.07, 33.07, 47.51, 47.51, 47.51, 47.51, 47.51, 48.97, 48.97, 48.97, 48.97, 48.97], "power_watts_avg": 43.61, "power_watts_peak": 49.98, "energy_joules_est": 68.38, "sample_count": 16, "duration_seconds": 1.568}, "timestamp": "2026-01-12T10:23:13.218642"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 886.563, "latencies_ms": [886.563], "images_per_second": 1.128, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephants are brown and gray, and the circus ring is lit with bright lights.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13360.8, "ram_available_mb": 109145.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 34.92, 34.92, 47.45, 47.45, 47.45, 47.45], "power_watts_avg": 40.49, "power_watts_peak": 47.45, "energy_joules_est": 35.92, "sample_count": 9, "duration_seconds": 0.887}, "timestamp": "2026-01-12T10:23:14.130726"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1447.819, "latencies_ms": [1447.819], "images_per_second": 0.691, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the sepia-toned photograph, a group of jockeys on horseback are galloping across a beach, their horses' hooves leaving distinct hoof prints in the wet sand.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.3, "ram_available_mb": 109140.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.45, 45.87, 45.87, 45.87, 45.87, 45.87, 47.37, 47.37, 47.37, 47.37, 47.37, 48.88, 48.88, 48.88, 48.88], "power_watts_avg": 47.28, "power_watts_peak": 48.88, "energy_joules_est": 68.46, "sample_count": 15, "duration_seconds": 1.448}, "timestamp": "2026-01-12T10:23:15.649010"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1903.52, "latencies_ms": [1903.52], "images_per_second": 0.525, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. horse: 1\n4. rider: 1\n5. horse: 1\n6. rider: 1\n7. horse: 1\n8. rider: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13361.3, "ram_available_mb": 109145.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_watts_samples": [48.88, 33.01, 33.01, 33.01, 33.01, 33.01, 46.63, 46.63, 46.63, 46.63, 46.63, 47.94, 47.94, 47.94, 47.94, 47.94, 34.88, 34.88, 34.88], "power_watts_avg": 41.66, "power_watts_peak": 48.88, "energy_joules_est": 79.31, "sample_count": 19, "duration_seconds": 1.904}, "timestamp": "2026-01-12T10:23:17.567006"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1569.431, "latencies_ms": [1569.431], "images_per_second": 0.637, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The horses are positioned on the left side of the image, with the riders appearing to be in the middle of the frame. The background of the image is the beach, which is located behind the horses and riders.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.3, "ram_available_mb": 109145.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.88, 32.85, 32.85, 32.85, 32.85, 32.85, 46.84, 46.84, 46.84, 46.84, 46.84, 49.19, 49.19, 49.19, 49.19, 49.19], "power_watts_avg": 42.45, "power_watts_peak": 49.19, "energy_joules_est": 66.66, "sample_count": 16, "duration_seconds": 1.57}, "timestamp": "2026-01-12T10:23:19.230024"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 909.839, "latencies_ms": [909.839], "images_per_second": 1.099, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are riding horses on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13382.8, "ram_available_mb": 109123.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 34.89, 34.89, 47.21, 47.21, 47.21, 47.21, 47.21], "power_watts_avg": 41.05, "power_watts_peak": 47.21, "energy_joules_est": 37.36, "sample_count": 10, "duration_seconds": 0.91}, "timestamp": "2026-01-12T10:23:20.240336"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1064.495, "latencies_ms": [1064.495], "images_per_second": 0.939, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is in black and white, with a sepia tone, and the horses are running on a wet beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.8, "ram_available_mb": 109123.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13389.8, "ram_available_mb": 109116.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.61, 46.61, 46.61, 46.61, 46.61, 46.52, 46.52, 46.52, 46.52, 46.52, 47.01], "power_watts_avg": 46.61, "power_watts_peak": 47.01, "energy_joules_est": 49.64, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-12T10:23:21.351449"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1039.679, "latencies_ms": [1039.679], "images_per_second": 0.962, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A young man wearing a black jacket and a blue and black helmet is talking on a cell phone in the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.8, "ram_available_mb": 109120.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13385.9, "ram_available_mb": 109120.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.01, 47.01, 47.01, 47.01, 42.91, 42.91, 42.91, 42.91, 42.91, 47.23, 47.23], "power_watts_avg": 45.19, "power_watts_peak": 47.23, "energy_joules_est": 47.01, "sample_count": 11, "duration_seconds": 1.04}, "timestamp": "2026-01-12T10:23:22.463816"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1982.192, "latencies_ms": [1982.192], "images_per_second": 0.504, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. goggles: 1\n3. jacket: 1\n4. phone: 1\n5. tree: 1\n6. snow: 1\n7. tree trunk: 1\n8. snowboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.1, "ram_available_mb": 109128.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13382.9, "ram_available_mb": 109123.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 47.23, 42.38, 42.38, 42.38, 42.38, 42.38, 46.9, 46.9, 46.9, 46.9, 46.9, 44.52, 44.52, 44.52, 44.52, 44.52, 34.59, 34.59], "power_watts_avg": 44.0, "power_watts_peak": 47.23, "energy_joules_est": 87.22, "sample_count": 20, "duration_seconds": 1.983}, "timestamp": "2026-01-12T10:23:24.481847"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1494.307, "latencies_ms": [1494.307], "images_per_second": 0.669, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, wearing a black jacket and a black helmet with a blue visor. The trees are in the background, and the snow is covering the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.0, "ram_available_mb": 109131.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13387.2, "ram_available_mb": 109119.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.59, 34.59, 33.56, 33.56, 33.56, 33.56, 33.56, 46.27, 46.27, 46.27, 46.27, 46.27, 47.67, 47.67, 47.67], "power_watts_avg": 40.76, "power_watts_peak": 47.67, "energy_joules_est": 60.95, "sample_count": 15, "duration_seconds": 1.495}, "timestamp": "2026-01-12T10:23:26.048573"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 999.813, "latencies_ms": [999.813], "images_per_second": 1.0, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young man wearing a black jacket and a black helmet is talking on a cell phone in the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.2, "ram_available_mb": 109123.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13298.0, "ram_available_mb": 109208.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.67, 47.67, 34.13, 34.13, 34.13, 34.13, 34.13, 47.69, 47.69, 47.69], "power_watts_avg": 40.9, "power_watts_peak": 47.69, "energy_joules_est": 40.91, "sample_count": 10, "duration_seconds": 1.0}, "timestamp": "2026-01-12T10:23:27.059393"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1001.048, "latencies_ms": [1001.048], "images_per_second": 0.999, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The person is wearing a black jacket and a blue and black helmet, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13298.0, "ram_available_mb": 109208.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13345.5, "ram_available_mb": 109160.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.69, 47.69, 48.12, 48.12, 48.12, 48.12, 48.12, 48.03, 48.03, 48.03], "power_watts_avg": 48.01, "power_watts_peak": 48.12, "energy_joules_est": 48.08, "sample_count": 10, "duration_seconds": 1.002}, "timestamp": "2026-01-12T10:23:28.071070"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 952.725, "latencies_ms": [952.725], "images_per_second": 1.05, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A green tent and a white motorcycle are parked in a field with a sunset in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.8, "ram_available_mb": 109159.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13335.8, "ram_available_mb": 109170.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.03, 48.03, 47.05, 47.05, 47.05, 47.05, 47.05, 47.53, 47.53, 47.53], "power_watts_avg": 47.39, "power_watts_peak": 48.03, "energy_joules_est": 45.18, "sample_count": 10, "duration_seconds": 0.953}, "timestamp": "2026-01-12T10:23:29.084426"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1490.569, "latencies_ms": [1490.569], "images_per_second": 0.671, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " tent: 1, motorcycle: 1, backpack: 1, tent pole: 1, motorcycle seat: 1, motorcycle handlebars: 1, motorcycle front wheel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.9, "ram_available_mb": 109174.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.53, 47.53, 46.8, 46.8, 46.8, 46.8, 47.09, 47.09, 47.09, 47.09, 47.09, 49.74, 49.74, 49.74, 49.74], "power_watts_avg": 47.78, "power_watts_peak": 49.74, "energy_joules_est": 71.24, "sample_count": 15, "duration_seconds": 1.491}, "timestamp": "2026-01-12T10:23:30.599906"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1531.951, "latencies_ms": [1531.951], "images_per_second": 0.653, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The motorcycle is positioned to the right of the tent, with the motorcycle's front wheel slightly closer to the camera than the tent. The motorcycle is in the foreground, with the tent situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.9, "ram_available_mb": 109174.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [49.74, 33.02, 33.02, 33.02, 33.02, 33.02, 47.52, 47.52, 47.52, 47.52, 47.52, 49.46, 49.46, 49.46, 49.46, 49.46], "power_watts_avg": 43.73, "power_watts_peak": 49.74, "energy_joules_est": 67.01, "sample_count": 16, "duration_seconds": 1.532}, "timestamp": "2026-01-12T10:23:32.217399"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1290.95, "latencies_ms": [1290.95], "images_per_second": 0.775, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A green tent and a white motorcycle are parked in a field with tall grass. The sun is setting in the background, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.0, "ram_available_mb": 109182.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13343.2, "ram_available_mb": 109163.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [33.91, 33.91, 33.91, 33.91, 33.91, 46.45, 46.45, 46.45, 46.45, 46.45, 47.32, 47.32, 47.32], "power_watts_avg": 41.83, "power_watts_peak": 47.32, "energy_joules_est": 54.03, "sample_count": 13, "duration_seconds": 1.291}, "timestamp": "2026-01-12T10:23:33.530642"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1440.778, "latencies_ms": [1440.778], "images_per_second": 0.694, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a green tent and a white motorcycle parked in a field with dry grass. The sky is filled with clouds and the sun is setting, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.3, "ram_available_mb": 109167.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13331.4, "ram_available_mb": 109174.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.32, 47.32, 34.97, 34.97, 34.97, 34.97, 34.97, 47.48, 47.48, 47.48, 47.48, 47.48, 47.42, 47.42, 47.42], "power_watts_avg": 43.28, "power_watts_peak": 47.48, "energy_joules_est": 62.38, "sample_count": 15, "duration_seconds": 1.441}, "timestamp": "2026-01-12T10:23:35.045482"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1373.904, "latencies_ms": [1373.904], "images_per_second": 0.728, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A black and white photo shows a steam locomotive with the number 67371 on it, pulling a train of passenger cars, with people standing on the platform.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13323.6, "ram_available_mb": 109182.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.42, 47.42, 33.46, 33.46, 33.46, 33.46, 33.46, 46.65, 46.65, 46.65, 46.65, 46.65, 48.53, 48.53], "power_watts_avg": 42.32, "power_watts_peak": 48.53, "energy_joules_est": 58.16, "sample_count": 14, "duration_seconds": 1.374}, "timestamp": "2026-01-12T10:23:36.460956"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1944.008, "latencies_ms": [1944.008], "images_per_second": 0.514, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. train: 1\n2. people: 4\n3. platform: 1\n4. sign: 1\n5. chimney: 1\n6. smoke: 1\n7. train car: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.5, "ram_available_mb": 109163.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.53, 48.53, 48.53, 37.31, 37.31, 37.31, 37.31, 37.31, 47.51, 47.51, 47.51, 47.51, 47.51, 44.72, 44.72, 44.72, 44.72, 44.72, 34.81, 34.81], "power_watts_avg": 43.15, "power_watts_peak": 48.53, "energy_joules_est": 83.89, "sample_count": 20, "duration_seconds": 1.944}, "timestamp": "2026-01-12T10:23:38.473637"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1681.967, "latencies_ms": [1681.967], "images_per_second": 0.595, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The train is on the left side of the image, with the platform on the right. The people are standing on the platform, near the train. The train is in the foreground, with the station building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.7, "ram_available_mb": 109171.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13331.8, "ram_available_mb": 109174.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.81, 34.81, 33.75, 33.75, 33.75, 33.75, 33.75, 45.69, 45.69, 45.69, 45.69, 45.69, 46.97, 46.97, 46.97, 46.97, 46.97], "power_watts_avg": 41.27, "power_watts_peak": 46.97, "energy_joules_est": 69.44, "sample_count": 17, "duration_seconds": 1.682}, "timestamp": "2026-01-12T10:23:40.241655"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 947.618, "latencies_ms": [947.618], "images_per_second": 1.055, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A black and white photo of a train station with a steam locomotive and people waiting for the train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.8, "ram_available_mb": 109174.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13351.1, "ram_available_mb": 109155.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.78, 34.78, 34.78, 34.78, 34.78, 47.68, 47.68, 47.68, 47.68, 47.68], "power_watts_avg": 41.23, "power_watts_peak": 47.68, "energy_joules_est": 39.09, "sample_count": 10, "duration_seconds": 0.948}, "timestamp": "2026-01-12T10:23:41.253189"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1066.879, "latencies_ms": [1066.879], "images_per_second": 0.937, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is in black and white, with the train and people in the foreground and the background showing a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.2, "ram_available_mb": 109159.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.58, 47.58, 47.58, 47.58, 47.58, 47.38, 47.38, 47.38, 47.38, 47.38, 47.1], "power_watts_avg": 47.45, "power_watts_peak": 47.58, "energy_joules_est": 50.63, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T10:23:42.364644"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1249.6, "latencies_ms": [1249.6], "images_per_second": 0.8, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a densely populated urban area, where numerous signs and advertisements are displayed on buildings, creating a vibrant and colorful atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13336.1, "ram_available_mb": 109170.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.4, "ram_available_mb": 109149.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [47.1, 47.1, 47.1, 47.1, 42.32, 42.32, 42.32, 42.32, 42.32, 47.23, 47.23, 47.23, 47.23], "power_watts_avg": 45.3, "power_watts_peak": 47.23, "energy_joules_est": 56.62, "sample_count": 13, "duration_seconds": 1.25}, "timestamp": "2026-01-12T10:23:43.681486"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2041.133, "latencies_ms": [2041.133], "images_per_second": 0.49, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. sign: 10\n2. building: 1\n3. window: 1\n4. air conditioner: 1\n5. electrical wire: 1\n6. street sign: 1\n7. pole: 1\n8. street light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.5, "ram_available_mb": 109157.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.3, "ram_available_mb": 109166.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.23, 39.9, 39.9, 39.9, 39.9, 39.9, 46.93, 46.93, 46.93, 46.93, 46.93, 48.58, 48.58, 48.58, 48.58, 34.9, 34.9, 34.9, 34.9, 34.9, 34.87], "power_watts_avg": 42.15, "power_watts_peak": 48.58, "energy_joules_est": 86.05, "sample_count": 21, "duration_seconds": 2.042}, "timestamp": "2026-01-12T10:23:45.802209"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1456.351, "latencies_ms": [1456.351], "images_per_second": 0.687, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The main objects are the street signs and the buildings. The street signs are in the foreground, while the buildings are in the background. The street signs are closer to the viewer than the buildings.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13336.4, "ram_available_mb": 109169.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13346.3, "ram_available_mb": 109160.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 34.87, 41.85, 41.85, 41.85, 41.85, 41.85, 45.76, 45.76, 45.76, 45.76, 45.76, 38.67], "power_watts_avg": 41.08, "power_watts_peak": 45.76, "energy_joules_est": 59.87, "sample_count": 15, "duration_seconds": 1.457}, "timestamp": "2026-01-12T10:23:47.369724"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 965.615, "latencies_ms": [965.615], "images_per_second": 1.036, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " This is a black and white photo of a street in Hong Kong with lots of signs and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.4, "ram_available_mb": 109167.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.7, "ram_available_mb": 109156.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.67, 38.67, 38.67, 38.67, 42.65, 42.65, 42.65, 42.65, 42.65, 46.89], "power_watts_avg": 41.48, "power_watts_peak": 46.89, "energy_joules_est": 40.08, "sample_count": 10, "duration_seconds": 0.966}, "timestamp": "2026-01-12T10:23:48.382990"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1350.681, "latencies_ms": [1350.681], "images_per_second": 0.74, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is in black and white, with a high contrast between the dark and light areas. The buildings are covered in signs and advertisements, creating a chaotic and busy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.8, "ram_available_mb": 109164.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.89, 46.89, 46.89, 46.89, 46.72, 46.72, 46.72, 46.72, 46.72, 47.44, 47.44, 47.44, 47.44, 40.08], "power_watts_avg": 46.5, "power_watts_peak": 47.44, "energy_joules_est": 62.83, "sample_count": 14, "duration_seconds": 1.351}, "timestamp": "2026-01-12T10:23:49.798936"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1318.936, "latencies_ms": [1318.936], "images_per_second": 0.758, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A man is lying on a concrete ledge by a body of water, while a sign reading \"OPEN\" is placed on the ground in front of him.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13348.7, "ram_available_mb": 109157.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.08, 40.08, 40.08, 40.08, 44.99, 44.99, 44.99, 44.99, 44.99, 46.64, 46.64, 46.64, 46.64, 46.64], "power_watts_avg": 44.18, "power_watts_peak": 46.64, "energy_joules_est": 58.28, "sample_count": 14, "duration_seconds": 1.319}, "timestamp": "2026-01-12T10:23:51.216345"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2024.329, "latencies_ms": [2024.329], "images_per_second": 0.494, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. man: 1\n2. grass: 1\n3. lake: 1\n4. sign: 1\n5. wood: 1\n6. water: 1\n7. man's legs: 1\n8. man's feet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13331.0, "ram_available_mb": 109175.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [36.02, 36.02, 36.02, 36.02, 36.02, 46.17, 46.17, 46.17, 46.17, 46.17, 47.8, 47.8, 47.8, 47.8, 47.8, 34.69, 34.69, 34.69, 34.69, 34.69, 34.73], "power_watts_avg": 40.87, "power_watts_peak": 47.8, "energy_joules_est": 82.75, "sample_count": 21, "duration_seconds": 2.025}, "timestamp": "2026-01-12T10:23:53.334810"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1571.205, "latencies_ms": [1571.205], "images_per_second": 0.636, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sign is in the foreground, close to the camera, and the man is in the background, far away from the camera. The man is sitting on the grass, and the sign is lying on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13335.4, "ram_available_mb": 109170.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 34.73, 40.02, 40.02, 40.02, 40.02, 40.02, 45.21, 45.21, 45.21, 45.21, 40.14, 40.14, 40.14], "power_watts_avg": 40.02, "power_watts_peak": 45.21, "energy_joules_est": 62.92, "sample_count": 16, "duration_seconds": 1.572}, "timestamp": "2026-01-12T10:23:55.002051"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1532.72, "latencies_ms": [1532.72], "images_per_second": 0.652, "prompt_tokens": 1112, "response_tokens_est": 41, "n_tiles": 1, "output_text": " A man is sunbathing on a concrete ledge overlooking a body of water. In the foreground, there is a sign that reads \"OPEN\" and \"CLOSED\" in red letters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.6, "ram_available_mb": 109178.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13333.5, "ram_available_mb": 109172.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [40.14, 40.14, 36.67, 36.67, 36.67, 36.67, 36.67, 47.2, 47.2, 47.2, 47.2, 47.2, 45.92, 45.92, 45.92, 45.92], "power_watts_avg": 42.71, "power_watts_peak": 47.2, "energy_joules_est": 65.49, "sample_count": 16, "duration_seconds": 1.533}, "timestamp": "2026-01-12T10:23:56.612146"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1926.325, "latencies_ms": [1926.325], "images_per_second": 0.519, "prompt_tokens": 1110, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a man lounging on a concrete ledge by a body of water, with a sign reading \"OPEN\" in the foreground. The scene is bathed in natural light, and the grass is a vibrant green, contrasting with the blue of the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.5, "ram_available_mb": 109172.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13338.1, "ram_available_mb": 109168.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.92, 31.55, 31.55, 31.55, 31.55, 31.55, 46.62, 46.62, 46.62, 46.62, 46.62, 49.65, 49.65, 49.65, 49.65, 49.65, 34.73, 34.73, 34.73, 34.73], "power_watts_avg": 41.19, "power_watts_peak": 49.65, "energy_joules_est": 79.37, "sample_count": 20, "duration_seconds": 1.927}, "timestamp": "2026-01-12T10:23:58.627340"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1285.785, "latencies_ms": [1285.785], "images_per_second": 0.778, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there is a brown horse standing in a field of tall grass, and a white dog with a pink tongue is sitting in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.8, "ram_available_mb": 109167.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.6, "ram_available_mb": 109134.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.73, 31.76, 31.76, 31.76, 31.76, 31.76, 45.41, 45.41, 45.41, 45.41, 45.41, 48.38, 48.38], "power_watts_avg": 39.79, "power_watts_peak": 48.38, "energy_joules_est": 51.2, "sample_count": 13, "duration_seconds": 1.287}, "timestamp": "2026-01-12T10:23:59.994184"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1584.115, "latencies_ms": [1584.115], "images_per_second": 0.631, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " horse: 1, dog: 1, grass: 1, horse's tail: 1, horse's mane: 1, horse's ear: 1, horse's eye: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.7, "ram_available_mb": 109142.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13306.7, "ram_available_mb": 109199.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [48.38, 48.38, 37.19, 37.19, 37.19, 37.19, 37.19, 47.52, 47.52, 47.52, 47.52, 47.52, 45.72, 45.72, 45.72, 45.72], "power_watts_avg": 43.95, "power_watts_peak": 48.38, "energy_joules_est": 69.64, "sample_count": 16, "duration_seconds": 1.585}, "timestamp": "2026-01-12T10:24:01.609843"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1700.096, "latencies_ms": [1700.096], "images_per_second": 0.588, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The brown horse is positioned to the left of the white dog, with the dog being in the foreground and the horse in the background. The dog is closer to the camera than the horse, and the horse is positioned behind the dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.7, "ram_available_mb": 109199.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13338.0, "ram_available_mb": 109168.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.72, 32.58, 32.58, 32.58, 32.58, 32.58, 47.14, 47.14, 47.14, 47.14, 47.14, 49.61, 49.61, 49.61, 49.61, 49.61, 34.73], "power_watts_avg": 42.77, "power_watts_peak": 49.61, "energy_joules_est": 72.73, "sample_count": 17, "duration_seconds": 1.701}, "timestamp": "2026-01-12T10:24:03.326167"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1520.145, "latencies_ms": [1520.145], "images_per_second": 0.658, "prompt_tokens": 1112, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In a serene field, a brown horse and a golden retriever are enjoying a sunny day. The horse stands tall, while the dog sits comfortably in the grass, both radiating joy and contentment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.0, "ram_available_mb": 109168.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13324.4, "ram_available_mb": 109181.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 34.73, 44.52, 44.52, 44.52, 44.52, 44.52, 47.46, 47.46, 47.46, 47.46, 47.46, 37.77, 37.77], "power_watts_avg": 42.15, "power_watts_peak": 47.46, "energy_joules_est": 64.08, "sample_count": 16, "duration_seconds": 1.52}, "timestamp": "2026-01-12T10:24:04.938869"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1811.377, "latencies_ms": [1811.377], "images_per_second": 0.552, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a brown horse and a white dog in a grassy field, with the horse wearing a bridle and the dog panting with its tongue out. The lighting is natural and bright, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13316.5, "ram_available_mb": 109189.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13348.6, "ram_available_mb": 109157.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [37.77, 37.77, 37.77, 38.94, 38.94, 38.94, 38.94, 38.94, 46.4, 46.4, 46.4, 46.4, 46.4, 43.18, 43.18, 43.18, 43.18, 43.18, 34.73], "power_watts_avg": 41.61, "power_watts_peak": 46.4, "energy_joules_est": 75.39, "sample_count": 19, "duration_seconds": 1.812}, "timestamp": "2026-01-12T10:24:06.855241"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1314.55, "latencies_ms": [1314.55], "images_per_second": 0.761, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the indoor volleyball court, a group of people are playing volleyball, with one person in a blue shirt serving the ball, while others are ready to receive it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13344.5, "ram_available_mb": 109161.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.2, "ram_available_mb": 109153.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.73, 34.73, 34.73, 38.62, 38.62, 38.62, 38.62, 38.62, 44.87, 44.87, 44.87, 44.87, 44.87, 41.89], "power_watts_avg": 40.25, "power_watts_peak": 44.87, "energy_joules_est": 52.97, "sample_count": 14, "duration_seconds": 1.316}, "timestamp": "2026-01-12T10:24:08.323419"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1942.24, "latencies_ms": [1942.24], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. volleyball: 2\n2. players: 12\n3. court: 1\n4. net: 1\n5. wall: 1\n6. ceiling: 1\n7. floor: 1\n8. lights: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.3, "ram_available_mb": 109161.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13346.5, "ram_available_mb": 109159.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.89, 41.89, 41.89, 41.89, 43.6, 43.6, 43.6, 43.6, 43.6, 46.1, 46.1, 46.1, 46.1, 46.1, 37.41, 37.41, 37.41, 37.41, 37.41, 34.76], "power_watts_avg": 41.89, "power_watts_peak": 46.1, "energy_joules_est": 81.38, "sample_count": 20, "duration_seconds": 1.943}, "timestamp": "2026-01-12T10:24:10.342437"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2375.037, "latencies_ms": [2375.037], "images_per_second": 0.421, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The main objects in the image are the volleyball court, the players, and the audience. The court is located in the foreground, with the players positioned in the middle ground, and the audience is in the background. The players are positioned in a line, with the person in the foreground closest to the camera, and the person in the background farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.6, "ram_available_mb": 109167.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.4, "ram_available_mb": 109158.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.76, 34.76, 34.76, 40.25, 40.25, 40.25, 40.25, 40.25, 45.76, 45.76, 45.76, 45.76, 45.76, 41.03, 41.03, 41.03, 41.03, 41.03, 34.73, 34.73, 34.73, 34.73, 34.73, 34.56], "power_watts_avg": 39.49, "power_watts_peak": 45.76, "energy_joules_est": 93.81, "sample_count": 24, "duration_seconds": 2.376}, "timestamp": "2026-01-12T10:24:12.816120"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1992.482, "latencies_ms": [1992.482], "images_per_second": 0.502, "prompt_tokens": 1111, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image captures a lively volleyball game in an indoor gymnasium. The court, marked with vibrant blue lines, is the stage for the players, who are dressed in matching blue uniforms. The players are engaged in the game, their bodies poised in anticipation as they prepare to serve the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.4, "ram_available_mb": 109158.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.56, 34.56, 34.56, 34.56, 44.79, 44.79, 44.79, 44.79, 44.79, 47.4, 47.4, 47.4, 47.4, 47.4, 36.91, 36.91, 36.91, 36.91, 36.91, 34.65], "power_watts_avg": 40.92, "power_watts_peak": 47.4, "energy_joules_est": 81.54, "sample_count": 20, "duration_seconds": 1.993}, "timestamp": "2026-01-12T10:24:14.835069"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 912.104, "latencies_ms": [912.104], "images_per_second": 1.096, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The indoor volleyball court is blue with white lines, and the players are wearing blue uniforms.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.4, "ram_available_mb": 109177.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13337.0, "ram_available_mb": 109169.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.65, 34.65, 34.65, 34.65, 41.43, 41.43, 41.43, 41.43, 41.43, 46.68], "power_watts_avg": 39.24, "power_watts_peak": 46.68, "energy_joules_est": 35.82, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-12T10:24:15.898081"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1577.351, "latencies_ms": [1577.351], "images_per_second": 0.634, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the image, a herd of zebras and wildebeests are grazing in a grassy field, with a flock of pink flamingos standing in the water behind them, and a mountain range in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.1, "ram_available_mb": 109177.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13342.1, "ram_available_mb": 109164.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.68, 46.68, 46.68, 46.01, 46.01, 46.01, 46.01, 46.01, 45.95, 45.95, 45.95, 45.95, 45.95, 40.51, 40.51, 40.51], "power_watts_avg": 45.09, "power_watts_peak": 46.68, "energy_joules_est": 71.14, "sample_count": 16, "duration_seconds": 1.578}, "timestamp": "2026-01-12T10:24:17.515823"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1258.296, "latencies_ms": [1258.296], "images_per_second": 0.795, "prompt_tokens": 1113, "response_tokens_est": 31, "n_tiles": 1, "output_text": " zebra: 4\nflamingo: 100\nwildebeest: 2\ngrass: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.1, "ram_available_mb": 109168.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13338.1, "ram_available_mb": 109168.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [40.51, 40.51, 36.28, 36.28, 36.28, 36.28, 36.28, 47.14, 47.14, 47.14, 47.14, 47.14, 46.45], "power_watts_avg": 41.89, "power_watts_peak": 47.14, "energy_joules_est": 52.73, "sample_count": 13, "duration_seconds": 1.259}, "timestamp": "2026-01-12T10:24:18.830430"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1578.117, "latencies_ms": [1578.117], "images_per_second": 0.634, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the flamingos in the background. The zebras are closer to the camera than the flamingos, which are situated in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.3, "ram_available_mb": 109176.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13331.2, "ram_available_mb": 109175.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.45, 46.45, 46.45, 46.45, 43.79, 43.79, 43.79, 43.79, 43.79, 46.99, 46.99, 46.99, 46.99, 46.99, 37.95, 37.95], "power_watts_avg": 44.73, "power_watts_peak": 46.99, "energy_joules_est": 70.61, "sample_count": 16, "duration_seconds": 1.579}, "timestamp": "2026-01-12T10:24:20.446602"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1844.032, "latencies_ms": [1844.032], "images_per_second": 0.542, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " In the vast savannah, a herd of zebras and wildebeests graze peacefully, while a flock of pink flamingos wades in the nearby lake. The tranquil scene is set against the backdrop of a distant mountain range, under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13329.4, "ram_available_mb": 109176.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13320.4, "ram_available_mb": 109185.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [37.95, 37.95, 37.95, 39.2, 39.2, 39.2, 39.2, 39.2, 47.18, 47.18, 47.18, 47.18, 47.18, 42.76, 42.76, 42.76, 42.76, 42.76, 34.61], "power_watts_avg": 41.8, "power_watts_peak": 47.18, "energy_joules_est": 77.1, "sample_count": 19, "duration_seconds": 1.845}, "timestamp": "2026-01-12T10:24:22.366188"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1808.299, "latencies_ms": [1808.299], "images_per_second": 0.553, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a vibrant scene with a mix of green grass, brown dirt, and pink flamingos in the background. The lighting is natural and bright, suggesting a sunny day, and the colors are vivid and clear, indicating a healthy and thriving environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.4, "ram_available_mb": 109185.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.61, 34.61, 34.61, 39.05, 39.05, 39.05, 39.05, 39.05, 45.72, 45.72, 45.72, 45.72, 45.72, 41.08, 41.08, 41.08, 41.08, 41.08], "power_watts_avg": 40.73, "power_watts_peak": 45.72, "energy_joules_est": 73.68, "sample_count": 18, "duration_seconds": 1.809}, "timestamp": "2026-01-12T10:24:24.233236"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 972.19, "latencies_ms": [972.19], "images_per_second": 1.029, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A ginger and white cat is sitting on a wooden deck and looking at its reflection in a window.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13328.2, "ram_available_mb": 109178.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13324.3, "ram_available_mb": 109182.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [34.38, 34.38, 34.38, 34.38, 34.38, 47.77, 47.77, 47.77, 47.77, 47.77], "power_watts_avg": 41.07, "power_watts_peak": 47.77, "energy_joules_est": 39.94, "sample_count": 10, "duration_seconds": 0.972}, "timestamp": "2026-01-12T10:24:25.244703"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2207.408, "latencies_ms": [2207.408], "images_per_second": 0.453, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. cat: 1\n2. glass: 1\n3. wooden surface: 1\n4. cat's tail: 1\n5. cat's head: 1\n6. cat's body: 1\n7. cat's legs: 1\n8. cat's paws: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13324.3, "ram_available_mb": 109182.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.6, "ram_available_mb": 109177.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.81, 47.81, 47.81, 47.81, 47.81, 47.33, 47.33, 47.33, 47.33, 47.33, 47.57, 47.57, 47.57, 47.57, 47.57, 34.69, 34.69, 34.69, 34.69, 34.69, 34.72, 34.72], "power_watts_avg": 43.48, "power_watts_peak": 47.81, "energy_joules_est": 96.0, "sample_count": 22, "duration_seconds": 2.208}, "timestamp": "2026-01-12T10:24:27.466430"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1152.541, "latencies_ms": [1152.541], "images_per_second": 0.868, "prompt_tokens": 1117, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The cat is in the foreground, sitting on the wooden deck. The glass window is in the background, reflecting the cat's image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13320.7, "ram_available_mb": 109185.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.4, "ram_available_mb": 109161.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.72, 34.72, 35.66, 35.66, 35.66, 35.66, 35.66, 46.94, 46.94, 46.94, 46.94, 46.94], "power_watts_avg": 40.2, "power_watts_peak": 46.94, "energy_joules_est": 46.37, "sample_count": 12, "duration_seconds": 1.154}, "timestamp": "2026-01-12T10:24:28.730239"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 958.975, "latencies_ms": [958.975], "images_per_second": 1.043, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A ginger and white cat is sitting on a wooden deck, looking at its reflection in a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.6, "ram_available_mb": 109169.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.6, "ram_available_mb": 109158.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.21, 46.21, 46.21, 46.21, 46.21, 47.14, 47.14, 47.14, 47.14, 47.14], "power_watts_avg": 46.67, "power_watts_peak": 47.14, "energy_joules_est": 44.79, "sample_count": 10, "duration_seconds": 0.96}, "timestamp": "2026-01-12T10:24:29.741590"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1091.746, "latencies_ms": [1091.746], "images_per_second": 0.916, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The cat is orange and white, and the wooden floor is green. The cat is looking at its reflection in the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.7, "ram_available_mb": 109162.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13335.8, "ram_available_mb": 109170.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.51, 47.51, 47.51, 47.51, 47.51, 47.07, 47.07, 47.07, 47.07, 47.07, 47.35], "power_watts_avg": 47.3, "power_watts_peak": 47.51, "energy_joules_est": 51.66, "sample_count": 11, "duration_seconds": 1.092}, "timestamp": "2026-01-12T10:24:30.855082"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1445.153, "latencies_ms": [1445.153], "images_per_second": 0.692, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image captures a serene lakeside scene with boats docked at a pier, a quaint town nestled on the shore, and majestic mountains in the background, all under a hazy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.9, "ram_available_mb": 109178.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.8, "ram_available_mb": 109152.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.35, 47.35, 47.35, 47.35, 43.67, 43.67, 43.67, 43.67, 43.67, 47.45, 47.45, 47.45, 47.45, 47.45, 39.38], "power_watts_avg": 45.63, "power_watts_peak": 47.45, "energy_joules_est": 65.97, "sample_count": 15, "duration_seconds": 1.446}, "timestamp": "2026-01-12T10:24:32.373517"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1921.953, "latencies_ms": [1921.953], "images_per_second": 0.52, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Boat: 3\n2. Boat: 1\n3. Boat: 1\n4. Boat: 1\n5. Boat: 1\n6. Boat: 1\n7. Boat: 1\n8. Boat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.8, "ram_available_mb": 109152.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [39.38, 39.38, 39.38, 39.38, 42.41, 42.41, 42.41, 42.41, 42.41, 46.86, 46.86, 46.86, 46.86, 46.86, 39.89, 39.89, 39.89, 39.89, 39.89, 34.64], "power_watts_avg": 41.9, "power_watts_peak": 46.86, "energy_joules_est": 80.55, "sample_count": 20, "duration_seconds": 1.923}, "timestamp": "2026-01-12T10:24:34.391534"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1335.167, "latencies_ms": [1335.167], "images_per_second": 0.749, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The boats are positioned in the foreground, with the buildings and mountains in the background. The street lamp is located near the boats, while the trees are situated further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.1, "ram_available_mb": 109170.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13344.2, "ram_available_mb": 109162.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.64, 34.64, 34.64, 37.67, 37.67, 37.67, 37.67, 37.67, 45.17, 45.17, 45.17, 45.17, 45.17, 42.27], "power_watts_avg": 40.03, "power_watts_peak": 45.17, "energy_joules_est": 53.48, "sample_count": 14, "duration_seconds": 1.336}, "timestamp": "2026-01-12T10:24:35.858807"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1710.066, "latencies_ms": [1710.066], "images_per_second": 0.585, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a serene lakeside scene with boats docked at a pier, a building with a red roof in the background, and a mountainous landscape in the distance. The sky is overcast, casting a soft light over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.2, "ram_available_mb": 109166.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13348.4, "ram_available_mb": 109157.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [42.27, 42.27, 42.27, 42.27, 42.58, 42.58, 42.58, 42.58, 42.58, 46.48, 46.48, 46.48, 46.48, 46.48, 38.74, 38.74, 38.74], "power_watts_avg": 42.98, "power_watts_peak": 46.48, "energy_joules_est": 73.52, "sample_count": 17, "duration_seconds": 1.711}, "timestamp": "2026-01-12T10:24:37.575095"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 938.557, "latencies_ms": [938.557], "images_per_second": 1.065, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The sky is overcast, the water is a deep blue, and the boats are white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.4, "ram_available_mb": 109157.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13334.9, "ram_available_mb": 109171.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 31.0}, "power_stats": {"power_watts_samples": [38.74, 38.74, 34.27, 34.27, 34.27, 34.27, 34.27, 47.69, 47.69, 47.69], "power_watts_avg": 39.19, "power_watts_peak": 47.69, "energy_joules_est": 36.79, "sample_count": 10, "duration_seconds": 0.939}, "timestamp": "2026-01-12T10:24:38.585501"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1326.923, "latencies_ms": [1326.923], "images_per_second": 0.754, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A man is standing next to a bicycle in a street with a sign above him that says \"\u6c34\u997a\" and a woman holding an umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.1, "ram_available_mb": 109179.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13343.1, "ram_available_mb": 109163.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_watts_samples": [47.69, 47.69, 46.18, 46.18, 46.18, 46.18, 46.18, 46.65, 46.65, 46.65, 46.65, 46.65, 49.11, 49.11], "power_watts_avg": 46.98, "power_watts_peak": 49.11, "energy_joules_est": 62.37, "sample_count": 14, "duration_seconds": 1.327}, "timestamp": "2026-01-12T10:24:39.998815"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1921.094, "latencies_ms": [1921.094], "images_per_second": 0.521, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. bicycle: 1\n3. umbrella: 1\n4. building: 1\n5. sign: 2\n6. person: 1\n7. pole: 1\n8. street: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.1, "ram_available_mb": 109163.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [49.11, 49.11, 49.11, 35.73, 35.73, 35.73, 35.73, 35.73, 46.3, 46.3, 46.3, 46.3, 46.3, 46.03, 46.03, 46.03, 46.03, 34.7, 34.7, 34.7], "power_watts_avg": 42.29, "power_watts_peak": 49.11, "energy_joules_est": 81.27, "sample_count": 20, "duration_seconds": 1.922}, "timestamp": "2026-01-12T10:24:42.014878"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1044.604, "latencies_ms": [1044.604], "images_per_second": 0.957, "prompt_tokens": 1117, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The man is standing next to a bicycle in the foreground, with a building and a street sign in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13327.0, "ram_available_mb": 109179.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13392.3, "ram_available_mb": 109114.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.7, 34.7, 32.13, 32.13, 32.13, 32.13, 32.13, 45.34, 45.34, 45.34, 45.34], "power_watts_avg": 37.4, "power_watts_peak": 45.34, "energy_joules_est": 39.11, "sample_count": 11, "duration_seconds": 1.046}, "timestamp": "2026-01-12T10:24:43.178070"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 879.459, "latencies_ms": [879.459], "images_per_second": 1.137, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is riding a bicycle down a street with a woman walking in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13384.5, "ram_available_mb": 109121.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13392.4, "ram_available_mb": 109113.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [45.34, 46.98, 46.98, 46.98, 46.98, 46.98, 46.67, 46.67, 46.67], "power_watts_avg": 46.7, "power_watts_peak": 46.98, "energy_joules_est": 41.09, "sample_count": 9, "duration_seconds": 0.88}, "timestamp": "2026-01-12T10:24:44.089422"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1279.045, "latencies_ms": [1279.045], "images_per_second": 0.782, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is in black and white, with a street scene featuring a man on a bicycle, a woman with an umbrella, and a building with Chinese characters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13384.6, "ram_available_mb": 109121.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.6, "ram_available_mb": 109112.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.67, 46.67, 47.12, 47.12, 47.12, 47.12, 47.12, 47.73, 47.73, 47.73, 47.73, 47.73, 49.53], "power_watts_avg": 47.47, "power_watts_peak": 49.53, "energy_joules_est": 60.74, "sample_count": 13, "duration_seconds": 1.28}, "timestamp": "2026-01-12T10:24:45.404137"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1351.289, "latencies_ms": [1351.289], "images_per_second": 0.74, "prompt_tokens": 1432, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a fruit stand, where bunches of ripe yellow bananas are hanging from the ceiling, creating a visually appealing display.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.6, "ram_available_mb": 109114.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13312.9, "ram_available_mb": 109193.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.53, 49.53, 49.53, 39.83, 39.83, 39.83, 39.83, 39.83, 51.75, 51.75, 51.75, 51.75, 51.75, 46.65], "power_watts_avg": 46.65, "power_watts_peak": 51.75, "energy_joules_est": 63.06, "sample_count": 14, "duration_seconds": 1.352}, "timestamp": "2026-01-12T10:24:46.821634"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1913.993, "latencies_ms": [1913.993], "images_per_second": 0.522, "prompt_tokens": 1446, "response_tokens_est": 50, "n_tiles": 1, "output_text": " banana: 100, bunches: 100, black cloth: 1, blue door: 1, white wall: 1, wooden stick: 1, blue rope: 1, white roof: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13306.0, "ram_available_mb": 109200.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.1, "ram_available_mb": 109149.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.65, 46.65, 46.65, 46.65, 43.16, 43.16, 43.16, 43.16, 43.16, 50.93, 50.93, 50.93, 50.93, 50.93, 43.64, 43.64, 43.64, 43.64, 43.64, 34.79], "power_watts_avg": 45.5, "power_watts_peak": 50.93, "energy_joules_est": 87.11, "sample_count": 20, "duration_seconds": 1.915}, "timestamp": "2026-01-12T10:24:48.839113"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1363.697, "latencies_ms": [1363.697], "images_per_second": 0.733, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bananas are hanging from the ceiling, with the clothes hanging below them. The bananas are in the foreground, while the clothes are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.0, "ram_available_mb": 109166.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13365.2, "ram_available_mb": 109141.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.79, 34.79, 41.62, 41.62, 41.62, 41.62, 41.62, 50.12, 50.12, 50.12, 50.12, 50.12], "power_watts_avg": 42.7, "power_watts_peak": 50.12, "energy_joules_est": 58.25, "sample_count": 14, "duration_seconds": 1.364}, "timestamp": "2026-01-12T10:24:50.256121"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 906.181, "latencies_ms": [906.181], "images_per_second": 1.104, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A bunch of bananas are hanging from the ceiling of a store.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13360.6, "ram_available_mb": 109145.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.35, 44.35, 44.35, 44.35, 44.35, 46.12, 46.12, 46.12, 46.12], "power_watts_avg": 45.14, "power_watts_peak": 46.12, "energy_joules_est": 40.93, "sample_count": 9, "duration_seconds": 0.907}, "timestamp": "2026-01-12T10:24:51.167962"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1179.238, "latencies_ms": [1179.238], "images_per_second": 0.848, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bananas are yellow and hanging from the ceiling, the lighting is bright and natural, and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.2, "ram_available_mb": 109157.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13372.7, "ram_available_mb": 109133.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.12, 50.66, 50.66, 50.66, 50.66, 50.66, 56.4, 56.4, 56.4, 56.4, 56.4, 52.85], "power_watts_avg": 52.86, "power_watts_peak": 56.4, "energy_joules_est": 62.34, "sample_count": 12, "duration_seconds": 1.179}, "timestamp": "2026-01-12T10:24:52.383068"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1116.139, "latencies_ms": [1116.139], "images_per_second": 0.896, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A green and white train with red and green cargo cars is traveling on a track through a green field with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.7, "ram_available_mb": 109133.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13365.3, "ram_available_mb": 109141.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [52.85, 52.85, 52.85, 52.85, 44.6, 44.6, 44.6, 44.6, 44.6, 47.49, 47.49, 47.49], "power_watts_avg": 48.08, "power_watts_peak": 52.85, "energy_joules_est": 53.67, "sample_count": 12, "duration_seconds": 1.116}, "timestamp": "2026-01-12T10:24:53.599442"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1993.351, "latencies_ms": [1993.351], "images_per_second": 0.502, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. train cars: 3\n3. train tracks: 1\n4. power lines: 1\n5. mountains: 1\n6. grass: 1\n7. trees: 1\n8. houses: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13361.3, "ram_available_mb": 109145.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13346.1, "ram_available_mb": 109160.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.49, 47.49, 36.87, 36.87, 36.87, 36.87, 36.87, 46.16, 46.16, 46.16, 46.16, 49.42, 49.42, 49.42, 49.42, 49.42, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 42.5, "power_watts_peak": 49.42, "energy_joules_est": 84.73, "sample_count": 20, "duration_seconds": 1.994}, "timestamp": "2026-01-12T10:24:55.620885"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1869.094, "latencies_ms": [1869.094], "images_per_second": 0.535, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, moving from left to right. The background features a mountain range, while the foreground shows a grassy field. The train is closer to the viewer than the mountains, and the grassy field is in the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.2, "ram_available_mb": 109168.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13348.7, "ram_available_mb": 109157.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.74, 33.01, 33.01, 33.01, 33.01, 33.01, 46.83, 46.83, 46.83, 46.83, 46.83, 48.66, 48.66, 48.66, 48.66, 48.66, 34.79, 34.79, 34.79], "power_watts_avg": 41.14, "power_watts_peak": 48.66, "energy_joules_est": 76.94, "sample_count": 19, "duration_seconds": 1.87}, "timestamp": "2026-01-12T10:24:57.590662"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1041.118, "latencies_ms": [1041.118], "images_per_second": 0.961, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A green and white train with red and green cars is traveling through a green field with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.7, "ram_available_mb": 109161.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.79, 31.85, 31.85, 31.85, 31.85, 31.85, 45.94, 45.94, 45.94, 45.94, 45.94], "power_watts_avg": 38.52, "power_watts_peak": 45.94, "energy_joules_est": 40.13, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-12T10:24:58.753010"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 864.452, "latencies_ms": [864.452], "images_per_second": 1.157, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The train is green and white, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13376.5, "ram_available_mb": 109129.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [48.6, 48.6, 48.6, 48.6, 48.6, 46.39, 46.39, 46.39, 46.39], "power_watts_avg": 47.62, "power_watts_peak": 48.6, "energy_joules_est": 41.18, "sample_count": 9, "duration_seconds": 0.865}, "timestamp": "2026-01-12T10:24:59.661762"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1219.228, "latencies_ms": [1219.228], "images_per_second": 0.82, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is standing on the beach with his arms up, and there is a green chair and a kite in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.5, "ram_available_mb": 109129.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13402.0, "ram_available_mb": 109104.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.39, 45.19, 45.19, 45.19, 45.19, 45.19, 47.53, 47.53, 47.53, 47.53, 47.53, 48.91, 48.91], "power_watts_avg": 46.76, "power_watts_peak": 48.91, "energy_joules_est": 57.03, "sample_count": 13, "duration_seconds": 1.22}, "timestamp": "2026-01-12T10:25:00.975106"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1920.029, "latencies_ms": [1920.029], "images_per_second": 0.521, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. hat: 1\n3. shorts: 1\n4. sand: 1\n5. chair: 1\n6. kite: 1\n7. ocean: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.1, "ram_available_mb": 109108.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13393.4, "ram_available_mb": 109112.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [48.91, 48.91, 48.91, 37.52, 37.52, 37.52, 37.52, 37.52, 46.42, 46.42, 46.42, 46.42, 46.42, 44.59, 44.59, 44.59, 44.59, 44.59, 34.69, 34.69], "power_watts_avg": 42.94, "power_watts_peak": 48.91, "energy_joules_est": 82.46, "sample_count": 20, "duration_seconds": 1.921}, "timestamp": "2026-01-12T10:25:02.990284"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1407.185, "latencies_ms": [1407.185], "images_per_second": 0.711, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, with the ocean waves on the right side. The green chair is in the foreground, while the kite is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.4, "ram_available_mb": 109112.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13392.5, "ram_available_mb": 109113.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.69, 34.69, 34.69, 36.77, 36.77, 36.77, 36.77, 36.77, 46.48, 46.48, 46.48, 46.48, 46.48, 45.08, 45.08], "power_watts_avg": 40.69, "power_watts_peak": 46.48, "energy_joules_est": 57.28, "sample_count": 15, "duration_seconds": 1.407}, "timestamp": "2026-01-12T10:25:04.503755"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1116.936, "latencies_ms": [1116.936], "images_per_second": 0.895, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man is standing on a beach with his arms up, holding a cell phone, and a kite is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.5, "ram_available_mb": 109113.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13409.1, "ram_available_mb": 109097.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_watts_samples": [45.08, 45.08, 45.08, 36.09, 36.09, 36.09, 36.09, 36.09, 46.13, 46.13, 46.13, 46.13], "power_watts_avg": 41.68, "power_watts_peak": 46.13, "energy_joules_est": 46.57, "sample_count": 12, "duration_seconds": 1.117}, "timestamp": "2026-01-12T10:25:05.715056"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1121.998, "latencies_ms": [1121.998], "images_per_second": 0.891, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The sky is blue and cloudy, the sand is light brown, and the man is wearing a black shirt and khaki shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13405.1, "ram_available_mb": 109101.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13395.3, "ram_available_mb": 109111.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.34, 44.34, 44.34, 44.34, 44.34, 46.24, 46.24, 46.24, 46.24, 46.24, 48.12, 48.12], "power_watts_avg": 45.76, "power_watts_peak": 48.12, "energy_joules_est": 51.36, "sample_count": 12, "duration_seconds": 1.122}, "timestamp": "2026-01-12T10:25:06.927839"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.355, "latencies_ms": [983.355], "images_per_second": 1.017, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image shows a garden with several potted plants, including broccoli and cabbage, planted in the soil.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.6, "ram_available_mb": 109126.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13395.2, "ram_available_mb": 109111.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.12, 48.12, 48.12, 39.26, 39.26, 39.26, 39.26, 39.26, 46.49, 46.49], "power_watts_avg": 43.36, "power_watts_peak": 48.12, "energy_joules_est": 42.67, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-12T10:25:07.942026"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 937.929, "latencies_ms": [937.929], "images_per_second": 1.066, "prompt_tokens": 1113, "response_tokens_est": 19, "n_tiles": 1, "output_text": " broccoli: 2, pot: 2, dirt: 1, plant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13387.3, "ram_available_mb": 109119.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13399.2, "ram_available_mb": 109107.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.49, 46.49, 46.49, 47.27, 47.27, 47.27, 47.27, 47.27, 47.93, 47.93], "power_watts_avg": 47.17, "power_watts_peak": 47.93, "energy_joules_est": 44.26, "sample_count": 10, "duration_seconds": 0.938}, "timestamp": "2026-01-12T10:25:08.952902"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1785.296, "latencies_ms": [1785.296], "images_per_second": 0.56, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The broccoli plants are positioned in the foreground, with the orange pots placed in the middle ground, and the dirt ground in the background. The broccoli plants are situated to the left of the orange pots, and the dirt ground is located behind the orange pots.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13395.2, "ram_available_mb": 109111.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13386.5, "ram_available_mb": 109119.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.93, 47.93, 47.93, 47.1, 47.1, 47.1, 47.1, 47.1, 46.63, 46.63, 46.63, 46.63, 46.63, 42.71, 42.71, 42.71, 42.71, 42.71], "power_watts_avg": 45.89, "power_watts_peak": 47.93, "energy_joules_est": 81.96, "sample_count": 18, "duration_seconds": 1.786}, "timestamp": "2026-01-12T10:25:10.767655"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2528.351, "latencies_ms": [2528.351], "images_per_second": 0.396, "prompt_tokens": 1111, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The image captures a serene garden scene where two large potted plants, each with a vibrant green hue, are thriving in their terracotta pots. The plants, exhibiting a healthy growth, are nestled on a bed of soil, surrounded by a sandy ground. A pinkish-brown mouse, seemingly at ease, is seen exploring the area, adding a touch of life to the tranquil setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.6, "ram_available_mb": 109127.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.77, 34.77, 34.77, 34.77, 34.77, 47.92, 47.92, 47.92, 47.92, 47.92, 47.69, 47.69, 47.69, 47.69, 47.69, 34.75, 34.75, 34.75, 34.75, 34.75, 34.63, 34.63, 34.63, 34.63, 34.63, 34.69], "power_watts_avg": 39.75, "power_watts_peak": 47.92, "energy_joules_est": 100.52, "sample_count": 26, "duration_seconds": 2.529}, "timestamp": "2026-01-12T10:25:13.389636"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 882.585, "latencies_ms": [882.585], "images_per_second": 1.133, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The image shows a garden with green plants in pots, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.1, "ram_available_mb": 109146.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13368.2, "ram_available_mb": 109138.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.69, 34.69, 34.69, 38.8, 38.8, 38.8, 38.8, 38.8, 45.25], "power_watts_avg": 38.15, "power_watts_peak": 45.25, "energy_joules_est": 33.7, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:25:14.351979"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1180.401, "latencies_ms": [1180.401], "images_per_second": 0.847, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " An elderly man is walking a small brown and white pony with a red bridle, while a young boy sits on the pony's back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.6, "ram_available_mb": 109145.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.4, "ram_available_mb": 109156.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.25, 45.25, 45.25, 45.25, 51.37, 51.37, 51.37, 51.37, 51.37, 47.63, 47.63, 47.63], "power_watts_avg": 48.4, "power_watts_peak": 51.37, "energy_joules_est": 57.15, "sample_count": 12, "duration_seconds": 1.181}, "timestamp": "2026-01-12T10:25:15.566365"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1913.742, "latencies_ms": [1913.742], "images_per_second": 0.523, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. boy: 1\n3. pony: 1\n4. horse: 1\n5. house: 1\n6. chair: 1\n7. person: 1\n8. window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.4, "ram_available_mb": 109156.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13398.6, "ram_available_mb": 109107.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.63, 47.63, 38.63, 38.63, 38.63, 38.63, 38.63, 47.69, 47.69, 47.69, 47.69, 47.69, 47.96, 47.96, 47.96, 47.96, 47.96, 34.95, 34.95, 34.95], "power_watts_avg": 43.58, "power_watts_peak": 47.96, "energy_joules_est": 83.41, "sample_count": 20, "duration_seconds": 1.914}, "timestamp": "2026-01-12T10:25:17.583563"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1594.23, "latencies_ms": [1594.23], "images_per_second": 0.627, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is holding the pony's reins, which are in front of him, and the pony is in front of the man. The pony is in the foreground, while the man and the boy are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.6, "ram_available_mb": 109111.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13379.9, "ram_available_mb": 109126.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.95, 30.27, 30.27, 30.27, 30.27, 30.27, 45.24, 45.24, 45.24, 45.24, 45.24, 49.75, 49.75, 49.75, 49.75, 49.75], "power_watts_avg": 41.33, "power_watts_peak": 49.75, "energy_joules_est": 65.91, "sample_count": 16, "duration_seconds": 1.595}, "timestamp": "2026-01-12T10:25:19.250627"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1351.851, "latencies_ms": [1351.851], "images_per_second": 0.74, "prompt_tokens": 1111, "response_tokens_est": 35, "n_tiles": 1, "output_text": " An elderly man and a young boy are walking down a sidewalk with a small brown horse. The man is holding the horse's reins and the boy is sitting on the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.9, "ram_available_mb": 109126.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [34.83, 34.83, 34.83, 34.83, 34.83, 48.05, 48.05, 48.05, 48.05, 48.05, 47.94, 47.94, 47.94, 47.94], "power_watts_avg": 43.3, "power_watts_peak": 48.05, "energy_joules_est": 58.56, "sample_count": 14, "duration_seconds": 1.352}, "timestamp": "2026-01-12T10:25:20.663103"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2197.989, "latencies_ms": [2197.989], "images_per_second": 0.455, "prompt_tokens": 1109, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image features a young boy riding a small brown and white pony, with the pony wearing a red bridle. The setting appears to be a sunny day, with the sun casting shadows on the ground. The pony is standing on a paved area, possibly a sidewalk or a street, and the boy is wearing a light blue shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.5, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.6, "ram_available_mb": 109140.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.94, 32.8, 32.8, 32.8, 32.8, 32.8, 47.38, 47.38, 47.38, 47.38, 47.38, 49.45, 49.45, 49.45, 49.45, 49.45, 34.82, 34.82, 34.82, 34.82, 34.82, 34.64], "power_watts_avg": 41.13, "power_watts_peak": 49.45, "energy_joules_est": 90.42, "sample_count": 22, "duration_seconds": 2.199}, "timestamp": "2026-01-12T10:25:22.883284"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1278.264, "latencies_ms": [1278.264], "images_per_second": 0.782, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A young boy with blonde hair and blue jeans is walking down a dirt path in a field of blue flowers, carrying a brown teddy bear on his back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.6, "ram_available_mb": 109140.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13384.5, "ram_available_mb": 109121.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.64, 34.64, 34.64, 40.06, 40.06, 40.06, 40.06, 40.06, 46.55, 46.55, 46.55, 46.55, 46.55], "power_watts_avg": 41.31, "power_watts_peak": 46.55, "energy_joules_est": 52.84, "sample_count": 13, "duration_seconds": 1.279}, "timestamp": "2026-01-12T10:25:24.247774"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1943.102, "latencies_ms": [1943.102], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. boy: 1\n2. blue: 1\n3. blue: 1\n4. blue: 1\n5. blue: 1\n6. blue: 1\n7. blue: 1\n8. blue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.6, "ram_available_mb": 109129.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13388.4, "ram_available_mb": 109117.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [41.36, 41.36, 41.36, 41.36, 41.36, 47.68, 47.68, 47.68, 47.68, 47.68, 47.4, 47.4, 47.4, 47.4, 47.4, 34.33, 34.33, 34.33, 34.33, 34.33], "power_watts_avg": 42.7, "power_watts_peak": 47.68, "energy_joules_est": 82.98, "sample_count": 20, "duration_seconds": 1.944}, "timestamp": "2026-01-12T10:25:26.270060"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1377.916, "latencies_ms": [1377.916], "images_per_second": 0.726, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The child is standing on the left side of the image, with the path leading to the right. The child is positioned in the foreground, with the flowers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.4, "ram_available_mb": 109117.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13438.9, "ram_available_mb": 109067.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.06, 34.06, 34.06, 34.06, 43.68, 43.68, 43.68, 43.68, 43.68, 45.42, 45.42, 45.42, 45.42, 45.42], "power_watts_avg": 41.55, "power_watts_peak": 45.42, "energy_joules_est": 57.3, "sample_count": 14, "duration_seconds": 1.379}, "timestamp": "2026-01-12T10:25:27.735736"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1104.123, "latencies_ms": [1104.123], "images_per_second": 0.906, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young boy with blonde hair is walking down a dirt path in a forest, carrying a teddy bear on his back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13434.9, "ram_available_mb": 109071.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.97, 35.97, 35.97, 35.97, 35.97, 47.31, 47.31, 47.31, 47.31, 47.31, 47.78], "power_watts_avg": 42.2, "power_watts_peak": 47.78, "energy_joules_est": 46.61, "sample_count": 11, "duration_seconds": 1.104}, "timestamp": "2026-01-12T10:25:28.849002"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1919.955, "latencies_ms": [1919.955], "images_per_second": 0.521, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a young boy with blonde hair, wearing a blue and white striped shirt and blue jeans, walking on a dirt path surrounded by a field of blue flowers. The lighting is natural and soft, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.5, "ram_available_mb": 109160.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.78, 47.78, 47.78, 47.78, 43.81, 43.81, 43.81, 43.81, 43.81, 47.16, 47.16, 47.16, 47.16, 47.16, 38.18, 38.18, 38.18, 38.18, 38.18, 34.68], "power_watts_avg": 43.58, "power_watts_peak": 47.78, "energy_joules_est": 83.68, "sample_count": 20, "duration_seconds": 1.92}, "timestamp": "2026-01-12T10:25:30.866719"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 994.838, "latencies_ms": [994.838], "images_per_second": 1.005, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " An orange is placed on the asphalt of a parking lot, with a blurred background of cars and trees.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13334.3, "ram_available_mb": 109172.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13386.0, "ram_available_mb": 109120.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.68, 34.68, 34.68, 39.24, 39.24, 39.24, 39.24, 39.24, 45.01, 45.01], "power_watts_avg": 39.03, "power_watts_peak": 45.01, "energy_joules_est": 38.86, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-12T10:25:31.930141"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 539.72, "latencies_ms": [539.72], "images_per_second": 1.853, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " orange: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.1, "ram_available_mb": 109128.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13390.6, "ram_available_mb": 109115.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [45.01, 45.01, 45.01, 47.14, 47.14, 47.14], "power_watts_avg": 46.07, "power_watts_peak": 47.14, "energy_joules_est": 24.89, "sample_count": 6, "duration_seconds": 0.54}, "timestamp": "2026-01-12T10:25:32.540576"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1653.471, "latencies_ms": [1653.471], "images_per_second": 0.605, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The orange is positioned in the foreground, with the parking lot and cars in the background. The orange is located to the left of the white line on the asphalt, and the parking lot extends to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.6, "ram_available_mb": 109115.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.14, 47.14, 48.29, 48.29, 48.29, 48.29, 48.29, 54.01, 54.01, 54.01, 54.01, 54.01, 46.31, 46.31, 46.31, 46.31, 46.31], "power_watts_avg": 49.25, "power_watts_peak": 54.01, "energy_joules_est": 81.47, "sample_count": 17, "duration_seconds": 1.654}, "timestamp": "2026-01-12T10:25:34.259674"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 968.376, "latencies_ms": [968.376], "images_per_second": 1.033, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A single orange is placed on the ground in a parking lot, with cars parked in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.3, "ram_available_mb": 109133.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13422.4, "ram_available_mb": 109083.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.43, 34.43, 34.43, 34.43, 34.43, 46.85, 46.85, 46.85, 46.85, 46.85], "power_watts_avg": 40.64, "power_watts_peak": 46.85, "energy_joules_est": 39.38, "sample_count": 10, "duration_seconds": 0.969}, "timestamp": "2026-01-12T10:25:35.273462"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1264.209, "latencies_ms": [1264.209], "images_per_second": 0.791, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The orange is a vibrant orange color, and the asphalt is a dark gray color. The sky is cloudy, and the orange is placed on the asphalt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.5, "ram_available_mb": 109091.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13428.8, "ram_available_mb": 109077.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.22, 47.22, 47.22, 47.22, 47.22, 47.17, 47.17, 47.17, 47.17, 47.17, 47.18, 47.18, 47.18], "power_watts_avg": 47.19, "power_watts_peak": 47.22, "energy_joules_est": 59.68, "sample_count": 13, "duration_seconds": 1.265}, "timestamp": "2026-01-12T10:25:36.587539"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1137.649, "latencies_ms": [1137.649], "images_per_second": 0.879, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit is sitting at a table with a bowl of food and several empty beer bottles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13428.8, "ram_available_mb": 109077.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13408.0, "ram_available_mb": 109098.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.18, 47.18, 31.67, 31.67, 31.67, 31.67, 31.67, 50.62, 50.62, 50.62, 50.62, 50.62], "power_watts_avg": 42.15, "power_watts_peak": 50.62, "energy_joules_est": 47.99, "sample_count": 12, "duration_seconds": 1.138}, "timestamp": "2026-01-12T10:25:37.812265"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1289.761, "latencies_ms": [1289.761], "images_per_second": 0.775, "prompt_tokens": 1446, "response_tokens_est": 27, "n_tiles": 1, "output_text": " man:1, bowl:1, bottle:4, keys:1, remote:1, table:1, wall:1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13403.6, "ram_available_mb": 109102.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13434.5, "ram_available_mb": 109071.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [53.66, 53.66, 53.66, 53.66, 43.72, 43.72, 43.72, 43.72, 43.72, 50.7, 50.7, 50.7, 50.7], "power_watts_avg": 48.92, "power_watts_peak": 53.66, "energy_joules_est": 63.12, "sample_count": 13, "duration_seconds": 1.29}, "timestamp": "2026-01-12T10:25:39.127248"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2412.826, "latencies_ms": [2412.826], "images_per_second": 0.414, "prompt_tokens": 1450, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The man is seated at a wooden table, with the bowl of food in front of him. The bottles of beer are placed to the right of the man, while the keys are located to the left. The bowl of food is positioned in the center of the table, with the man's hands resting on the table in front of him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.7, "ram_available_mb": 109080.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13413.4, "ram_available_mb": 109092.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.7, 40.44, 40.44, 40.44, 40.44, 40.44, 51.55, 51.55, 51.55, 51.55, 51.55, 53.88, 53.88, 53.88, 53.88, 53.88, 34.88, 34.88, 34.88, 34.88, 34.88, 34.91, 34.91, 34.91], "power_watts_avg": 44.13, "power_watts_peak": 53.88, "energy_joules_est": 106.5, "sample_count": 24, "duration_seconds": 2.413}, "timestamp": "2026-01-12T10:25:41.551830"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1133.399, "latencies_ms": [1133.399], "images_per_second": 0.882, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit is sitting at a table with a bowl of food and several bottles of beer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.4, "ram_available_mb": 109092.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13405.5, "ram_available_mb": 109100.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 31.51, 31.51, 31.51, 31.51, 31.51, 50.87, 50.87, 50.87, 50.87, 50.87], "power_watts_avg": 40.14, "power_watts_peak": 50.87, "energy_joules_est": 45.53, "sample_count": 12, "duration_seconds": 1.134}, "timestamp": "2026-01-12T10:25:42.812371"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1050.011, "latencies_ms": [1050.011], "images_per_second": 0.952, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The man is wearing a grey suit and white shirt. The table is made of wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13405.5, "ram_available_mb": 109100.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13417.3, "ram_available_mb": 109089.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [54.31, 54.31, 54.31, 54.31, 43.88, 43.88, 43.88, 43.88, 43.88, 50.61, 50.61], "power_watts_avg": 48.9, "power_watts_peak": 54.31, "energy_joules_est": 51.37, "sample_count": 11, "duration_seconds": 1.051}, "timestamp": "2026-01-12T10:25:43.925821"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1147.172, "latencies_ms": [1147.172], "images_per_second": 0.872, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image shows a hotel room with a large bed, a desk with a chair, and a window with a view of the outside.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13408.5, "ram_available_mb": 109097.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13400.6, "ram_available_mb": 109105.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [50.61, 50.61, 50.61, 48.83, 48.83, 48.83, 48.83, 48.83, 46.74, 46.74, 46.74, 46.74], "power_watts_avg": 48.58, "power_watts_peak": 50.61, "energy_joules_est": 55.74, "sample_count": 12, "duration_seconds": 1.147}, "timestamp": "2026-01-12T10:25:45.138943"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1915.437, "latencies_ms": [1915.437], "images_per_second": 0.522, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 2\n2. pillows: 4\n3. chair: 1\n4. desk: 1\n5. lamp: 1\n6. window: 1\n7. carpet: 1\n8. wall: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.7, "ram_available_mb": 109113.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13383.0, "ram_available_mb": 109123.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.74, 38.66, 38.66, 38.66, 38.66, 38.66, 47.13, 47.13, 47.13, 47.13, 47.13, 49.68, 49.68, 49.68, 49.68, 49.68, 34.7, 34.7, 34.7, 34.7], "power_watts_avg": 43.15, "power_watts_peak": 49.68, "energy_joules_est": 82.66, "sample_count": 20, "duration_seconds": 1.916}, "timestamp": "2026-01-12T10:25:47.158962"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1507.74, "latencies_ms": [1507.74], "images_per_second": 0.663, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The bed is positioned to the left of the desk, with the desk located in the foreground of the image. The window is situated to the right of the bed, providing natural light to the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13379.0, "ram_available_mb": 109127.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13392.3, "ram_available_mb": 109114.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_watts_samples": [34.7, 31.86, 31.86, 31.86, 31.86, 31.86, 46.43, 46.43, 46.43, 46.43, 46.43, 49.31, 49.31, 49.31, 49.31], "power_watts_avg": 41.56, "power_watts_peak": 49.31, "energy_joules_est": 62.68, "sample_count": 15, "duration_seconds": 1.508}, "timestamp": "2026-01-12T10:25:48.673433"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 831.015, "latencies_ms": [831.015], "images_per_second": 1.203, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A hotel room with a large bed, a desk, and a window.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13392.3, "ram_available_mb": 109114.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [49.31, 33.6, 33.6, 33.6, 33.6, 33.6, 47.58, 47.58, 47.58], "power_watts_avg": 40.01, "power_watts_peak": 49.31, "energy_joules_est": 33.26, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-12T10:25:49.583349"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1068.556, "latencies_ms": [1068.556], "images_per_second": 0.936, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted in a light color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.2, "ram_available_mb": 109149.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.8, "ram_available_mb": 109139.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [47.58, 47.58, 48.28, 48.28, 48.28, 48.28, 48.28, 46.78, 46.78, 46.78, 46.78], "power_watts_avg": 47.61, "power_watts_peak": 48.28, "energy_joules_est": 50.89, "sample_count": 11, "duration_seconds": 1.069}, "timestamp": "2026-01-12T10:25:50.696447"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1302.66, "latencies_ms": [1302.66], "images_per_second": 0.768, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " Three stuffed animals, including a bear, a snowman, and a bear wearing a hat, are sitting on a blue surface with a red and orange background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.9, "ram_available_mb": 109143.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.6, "ram_available_mb": 109142.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [46.78, 46.94, 46.94, 46.94, 46.94, 46.94, 47.32, 47.32, 47.32, 47.32, 47.32, 48.22, 48.22], "power_watts_avg": 47.27, "power_watts_peak": 48.22, "energy_joules_est": 61.61, "sample_count": 13, "duration_seconds": 1.303}, "timestamp": "2026-01-12T10:25:52.009635"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1534.664, "latencies_ms": [1534.664], "images_per_second": 0.652, "prompt_tokens": 1114, "response_tokens_est": 41, "n_tiles": 1, "output_text": " teddy bear: 1, hat: 1, scarf: 1, shirt: 1, shirt: 1, shirt: 1, shirt: 1, shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.6, "ram_available_mb": 109142.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.22, 48.22, 48.22, 37.44, 37.44, 37.44, 37.44, 37.44, 48.0, 48.0, 48.0, 48.0, 48.0, 44.96, 44.96, 44.96], "power_watts_avg": 44.17, "power_watts_peak": 48.22, "energy_joules_est": 67.83, "sample_count": 16, "duration_seconds": 1.535}, "timestamp": "2026-01-12T10:25:53.623593"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2056.925, "latencies_ms": [2056.925], "images_per_second": 0.486, "prompt_tokens": 1118, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The teddy bear wearing a green hat is positioned to the left of the teddy bear with the red scarf, which is in front of the teddy bear with the black hat. The teddy bear with the red scarf is in the foreground, while the teddy bear with the black hat is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.4, "ram_available_mb": 109148.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.96, 31.85, 31.85, 31.85, 31.85, 31.85, 46.72, 46.72, 46.72, 46.72, 46.72, 49.57, 49.57, 49.57, 49.57, 49.57, 34.65, 34.65, 34.65, 34.65, 34.65], "power_watts_avg": 40.9, "power_watts_peak": 49.57, "energy_joules_est": 84.15, "sample_count": 21, "duration_seconds": 2.057}, "timestamp": "2026-01-12T10:25:55.742910"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 774.26, "latencies_ms": [774.26], "images_per_second": 1.292, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Three stuffed animals are sitting on a table with a colorful background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.5, "ram_available_mb": 109156.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.1, "ram_available_mb": 109140.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.17, 34.17, 34.17, 34.17, 34.17, 45.84, 45.84, 45.84], "power_watts_avg": 38.55, "power_watts_peak": 45.84, "energy_joules_est": 29.88, "sample_count": 8, "duration_seconds": 0.775}, "timestamp": "2026-01-12T10:25:56.604229"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1260.914, "latencies_ms": [1260.914], "images_per_second": 0.793, "prompt_tokens": 1110, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The teddy bears are in a room with a red and orange background. The teddy bears are made of plush material and are stuffed with a soft filling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.1, "ram_available_mb": 109140.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.84, 45.84, 45.42, 45.42, 45.42, 45.42, 45.42, 47.98, 47.98, 47.98, 47.98, 47.98, 49.41], "power_watts_avg": 46.77, "power_watts_peak": 49.41, "energy_joules_est": 58.99, "sample_count": 13, "duration_seconds": 1.261}, "timestamp": "2026-01-12T10:25:57.918351"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 847.287, "latencies_ms": [847.287], "images_per_second": 1.18, "prompt_tokens": 1432, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A glass bowl filled with oranges sits on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.4, "ram_available_mb": 109159.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13389.6, "ram_available_mb": 109116.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.41, 49.41, 49.41, 39.8, 39.8, 39.8, 39.8, 39.8, 51.07], "power_watts_avg": 44.25, "power_watts_peak": 51.07, "energy_joules_est": 37.51, "sample_count": 9, "duration_seconds": 0.848}, "timestamp": "2026-01-12T10:25:58.833723"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 853.957, "latencies_ms": [853.957], "images_per_second": 1.171, "prompt_tokens": 1446, "response_tokens_est": 11, "n_tiles": 1, "output_text": " bowl: 1\noranges: 12", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13381.7, "ram_available_mb": 109124.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13389.3, "ram_available_mb": 109117.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [51.07, 51.07, 51.07, 51.07, 55.15, 55.15, 55.15, 55.15, 55.15], "power_watts_avg": 53.34, "power_watts_peak": 55.15, "energy_joules_est": 45.58, "sample_count": 9, "duration_seconds": 0.854}, "timestamp": "2026-01-12T10:25:59.745692"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1179.458, "latencies_ms": [1179.458], "images_per_second": 0.848, "prompt_tokens": 1450, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The oranges are in the foreground, on a tablecloth, and the bowl is in the middle of the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.3, "ram_available_mb": 109117.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [50.78, 50.78, 50.78, 50.78, 50.78, 55.0, 55.0, 55.0, 55.0, 55.0, 51.06, 51.06], "power_watts_avg": 52.59, "power_watts_peak": 55.0, "energy_joules_est": 62.05, "sample_count": 12, "duration_seconds": 1.18}, "timestamp": "2026-01-12T10:26:00.961461"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 822.837, "latencies_ms": [822.837], "images_per_second": 1.215, "prompt_tokens": 1444, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A bowl of oranges is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.0, "ram_available_mb": 109143.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13386.4, "ram_available_mb": 109119.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [51.06, 51.06, 51.06, 43.28, 43.28, 43.28, 43.28, 43.28, 51.87], "power_watts_avg": 46.83, "power_watts_peak": 51.87, "energy_joules_est": 38.56, "sample_count": 9, "duration_seconds": 0.823}, "timestamp": "2026-01-12T10:26:01.873552"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 883.433, "latencies_ms": [883.433], "images_per_second": 1.132, "prompt_tokens": 1442, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The oranges are bright orange and the bowl is clear glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.5, "ram_available_mb": 109127.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13394.0, "ram_available_mb": 109112.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [51.87, 51.87, 51.87, 51.87, 54.51, 54.51, 54.51, 54.51, 54.51], "power_watts_avg": 53.33, "power_watts_peak": 54.51, "energy_joules_est": 47.13, "sample_count": 9, "duration_seconds": 0.884}, "timestamp": "2026-01-12T10:26:02.783967"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 818.234, "latencies_ms": [818.234], "images_per_second": 1.222, "prompt_tokens": 766, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A surfer is riding a large wave in the ocean, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.0, "ram_available_mb": 109112.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13378.3, "ram_available_mb": 109128.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4528.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [50.44, 50.44, 50.44, 50.44, 50.44, 52.83, 52.83, 52.83, 52.83], "power_watts_avg": 51.5, "power_watts_peak": 52.83, "energy_joules_est": 42.15, "sample_count": 9, "duration_seconds": 0.818}, "timestamp": "2026-01-12T10:26:03.695669"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1877.389, "latencies_ms": [1877.389], "images_per_second": 0.533, "prompt_tokens": 780, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Ocean: 1\n5. Sky: 1\n6. Clouds: 1\n7. Water: 1\n8. Surfboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13378.3, "ram_available_mb": 109128.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13363.4, "ram_available_mb": 109142.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.8, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [52.83, 41.07, 41.07, 41.07, 41.07, 41.07, 41.97, 41.97, 41.97, 41.97, 41.97, 44.07, 44.07, 44.07, 44.07, 44.07, 34.84, 34.84, 34.84], "power_watts_avg": 41.73, "power_watts_peak": 52.83, "energy_joules_est": 78.36, "sample_count": 19, "duration_seconds": 1.878}, "timestamp": "2026-01-12T10:26:05.615039"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1283.817, "latencies_ms": [1283.817], "images_per_second": 0.779, "prompt_tokens": 784, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the background, with the sky occupying the upper portion of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.5, "ram_available_mb": 109150.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.6, "ram_available_mb": 109162.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4575.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.84, 32.25, 32.25, 32.25, 32.25, 32.25, 41.94, 41.94, 41.94, 41.94, 41.94, 44.72, 44.72], "power_watts_avg": 38.09, "power_watts_peak": 44.72, "energy_joules_est": 48.93, "sample_count": 13, "duration_seconds": 1.285}, "timestamp": "2026-01-12T10:26:06.979232"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1078.608, "latencies_ms": [1078.608], "images_per_second": 0.927, "prompt_tokens": 778, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A surfer is riding a large wave in the ocean. The surfer is wearing a black wetsuit and is standing on a surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13335.7, "ram_available_mb": 109170.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.2, "ram_available_mb": 109159.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [44.72, 44.72, 44.72, 40.34, 40.34, 40.34, 40.34, 40.34, 43.08, 43.08, 43.08], "power_watts_avg": 42.28, "power_watts_peak": 44.72, "energy_joules_est": 45.62, "sample_count": 11, "duration_seconds": 1.079}, "timestamp": "2026-01-12T10:26:08.091300"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1464.362, "latencies_ms": [1464.362], "images_per_second": 0.683, "prompt_tokens": 776, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a surfer riding a large wave in the ocean, with the surfer wearing a black wetsuit and a white surfboard. The sky is overcast, and the water is a deep blue color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13343.3, "ram_available_mb": 109163.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.6, "ram_available_mb": 109162.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4574.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [43.08, 43.08, 38.24, 38.24, 38.24, 38.24, 38.24, 42.97, 42.97, 42.97, 42.97, 42.97, 42.59, 42.59, 42.59], "power_watts_avg": 41.33, "power_watts_peak": 43.08, "energy_joules_est": 60.54, "sample_count": 15, "duration_seconds": 1.465}, "timestamp": "2026-01-12T10:26:09.606058"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 801.154, "latencies_ms": [801.154], "images_per_second": 1.248, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is sitting on a laptop computer, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13335.7, "ram_available_mb": 109170.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.3, "ram_available_mb": 109135.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 21.0}, "power_stats": {"power_watts_samples": [42.59, 42.59, 33.27, 33.27, 33.27, 33.27, 33.27, 47.05], "power_watts_avg": 37.32, "power_watts_peak": 47.05, "energy_joules_est": 29.93, "sample_count": 8, "duration_seconds": 0.802}, "timestamp": "2026-01-12T10:26:10.415532"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1939.915, "latencies_ms": [1939.915], "images_per_second": 0.515, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. screen: 1\n5. mouse: 1\n6. mousepad: 1\n7. paper: 1\n8. couch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.4, "ram_available_mb": 109142.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.05, 47.05, 47.05, 47.05, 57.24, 57.24, 57.24, 57.24, 57.24, 48.46, 48.46, 48.46, 48.46, 48.46, 41.32, 41.32, 41.32, 41.32, 34.87, 34.87], "power_watts_avg": 47.59, "power_watts_peak": 57.24, "energy_joules_est": 92.34, "sample_count": 20, "duration_seconds": 1.94}, "timestamp": "2026-01-12T10:26:12.434803"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1710.915, "latencies_ms": [1710.915], "images_per_second": 0.584, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The cat is in the foreground, sitting on the left side of the laptop, and the laptop is on the right side of the image. The cat is looking at the screen of the laptop, which is in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.0, "ram_available_mb": 109152.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 36.95, 36.95, 36.95, 36.95, 36.95, 45.91, 45.91, 45.91, 45.91, 45.91, 43.66, 43.66, 43.66, 43.66], "power_watts_avg": 40.8, "power_watts_peak": 45.91, "energy_joules_est": 69.82, "sample_count": 17, "duration_seconds": 1.711}, "timestamp": "2026-01-12T10:26:14.202220"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 792.844, "latencies_ms": [792.844], "images_per_second": 1.261, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is sitting on a laptop computer, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.5, "ram_available_mb": 109155.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_watts_samples": [43.66, 34.4, 34.4, 34.4, 34.4, 34.4, 48.24, 48.24], "power_watts_avg": 39.02, "power_watts_peak": 48.24, "energy_joules_est": 30.94, "sample_count": 8, "duration_seconds": 0.793}, "timestamp": "2026-01-12T10:26:15.012201"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 785.747, "latencies_ms": [785.747], "images_per_second": 1.273, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is white and brown, and the laptop is black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.1, "ram_available_mb": 109147.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13375.6, "ram_available_mb": 109130.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.24, 48.24, 48.24, 51.83, 51.83, 51.83, 51.83, 51.83], "power_watts_avg": 50.48, "power_watts_peak": 51.83, "energy_joules_est": 39.69, "sample_count": 8, "duration_seconds": 0.786}, "timestamp": "2026-01-12T10:26:15.824185"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1311.187, "latencies_ms": [1311.187], "images_per_second": 0.763, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a group of horses, including a brown one, are gathered around a hay feeder in a field, with a house and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.6, "ram_available_mb": 109130.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13349.1, "ram_available_mb": 109157.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.7, 47.7, 47.7, 47.7, 55.98, 55.98, 55.98, 55.98, 55.98, 47.4, 47.4, 47.4, 47.4, 47.4], "power_watts_avg": 50.55, "power_watts_peak": 55.98, "energy_joules_est": 66.31, "sample_count": 14, "duration_seconds": 1.312}, "timestamp": "2026-01-12T10:26:17.239923"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1348.21, "latencies_ms": [1348.21], "images_per_second": 0.742, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " horse: 4, hay: 1, fence: 1, trees: 1, house: 1, power lines: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.3, "ram_available_mb": 109165.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13365.2, "ram_available_mb": 109141.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [35.69, 35.69, 35.69, 35.69, 35.69, 46.45, 46.45, 46.45, 46.45, 46.45, 47.9, 47.9, 47.9, 47.9], "power_watts_avg": 43.02, "power_watts_peak": 47.9, "energy_joules_est": 58.02, "sample_count": 14, "duration_seconds": 1.349}, "timestamp": "2026-01-12T10:26:18.653245"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1539.366, "latencies_ms": [1539.366], "images_per_second": 0.65, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The brown horse is in the foreground, eating hay from a feeder. The brown horse is in the background, eating hay from a feeder. The brown horse is in the foreground, eating hay from a feeder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.3, "ram_available_mb": 109149.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13348.0, "ram_available_mb": 109158.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.9, 32.77, 32.77, 32.77, 32.77, 32.77, 47.09, 47.09, 47.09, 47.09, 47.09, 49.55, 49.55, 49.55, 49.55, 49.55], "power_watts_avg": 43.44, "power_watts_peak": 49.55, "energy_joules_est": 66.88, "sample_count": 16, "duration_seconds": 1.54}, "timestamp": "2026-01-12T10:26:20.267631"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1723.39, "latencies_ms": [1723.39], "images_per_second": 0.58, "prompt_tokens": 1111, "response_tokens_est": 49, "n_tiles": 1, "output_text": " In a rural setting, a group of horses, including a brown foal, are gathered around a hay feeder, enjoying their meal. The scene is set in a field with a fence in the background, and power lines can be seen above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.1, "ram_available_mb": 109162.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.57, 34.57, 34.57, 34.57, 34.57, 46.97, 46.97, 46.97, 46.97, 46.97, 47.34, 47.34, 47.34, 47.34, 47.34, 35.01, 35.01, 35.01], "power_watts_avg": 41.63, "power_watts_peak": 47.34, "energy_joules_est": 71.77, "sample_count": 18, "duration_seconds": 1.724}, "timestamp": "2026-01-12T10:26:22.084120"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1696.061, "latencies_ms": [1696.061], "images_per_second": 0.59, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a group of horses in a field with a mix of brown and black coats, with the brown horses being the most prominent. The lighting is natural and bright, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.6, "ram_available_mb": 109146.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13410.6, "ram_available_mb": 109095.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 33.06, 33.06, 33.06, 33.06, 33.06, 46.3, 46.3, 46.3, 46.3, 46.3, 49.02, 49.02, 49.02, 49.02, 49.02], "power_watts_avg": 41.88, "power_watts_peak": 49.02, "energy_joules_est": 71.04, "sample_count": 17, "duration_seconds": 1.696}, "timestamp": "2026-01-12T10:26:23.796234"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 977.933, "latencies_ms": [977.933], "images_per_second": 1.023, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a black wetsuit is riding a yellow surfboard on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.6, "ram_available_mb": 109095.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.96, 34.96, 34.96, 34.96, 34.96, 47.36, 47.36, 47.36, 47.36, 47.36], "power_watts_avg": 41.16, "power_watts_peak": 47.36, "energy_joules_est": 40.29, "sample_count": 10, "duration_seconds": 0.979}, "timestamp": "2026-01-12T10:26:24.810157"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2194.607, "latencies_ms": [2194.607], "images_per_second": 0.456, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Water: 1\n5. Surfboard: 1\n6. Surfboard: 1\n7. Surfboard: 1\n8. Surfboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13349.6, "ram_available_mb": 109156.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [48.15, 48.15, 48.15, 48.15, 48.15, 48.12, 48.12, 48.12, 48.12, 48.12, 47.58, 47.58, 47.58, 47.58, 47.58, 35.98, 35.98, 35.98, 35.98, 35.98, 34.89, 34.89], "power_watts_avg": 44.05, "power_watts_peak": 48.15, "energy_joules_est": 96.7, "sample_count": 22, "duration_seconds": 2.195}, "timestamp": "2026-01-12T10:26:27.027312"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1527.823, "latencies_ms": [1527.823], "images_per_second": 0.655, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, with the ocean and coastline in the background. The surfer is crouched low on the board, with the wave forming a near-perfect arc around him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.6, "ram_available_mb": 109156.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13436.6, "ram_available_mb": 109069.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.01, 34.01, 34.01, 34.01, 34.01, 46.84, 46.84, 46.84, 46.84, 46.84, 48.59, 48.59, 48.59, 48.59], "power_watts_avg": 41.78, "power_watts_peak": 48.59, "energy_joules_est": 63.86, "sample_count": 16, "duration_seconds": 1.529}, "timestamp": "2026-01-12T10:26:28.692305"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 926.896, "latencies_ms": [926.896], "images_per_second": 1.079, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man in a wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13436.6, "ram_available_mb": 109069.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13425.9, "ram_available_mb": 109080.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 63.0}, "power_stats": {"power_watts_samples": [48.59, 33.14, 33.14, 33.14, 33.14, 33.14, 46.7, 46.7, 46.7, 46.7], "power_watts_avg": 40.11, "power_watts_peak": 48.59, "energy_joules_est": 37.19, "sample_count": 10, "duration_seconds": 0.927}, "timestamp": "2026-01-12T10:26:29.703197"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1432.959, "latencies_ms": [1432.959], "images_per_second": 0.698, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The surfer is wearing a black wetsuit, and the water is a greenish-blue color. The sky is partly cloudy, and the surfer is riding a yellow surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13418.0, "ram_available_mb": 109088.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13407.8, "ram_available_mb": 109098.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.7, 47.09, 47.09, 47.09, 47.09, 47.09, 46.91, 46.91, 46.91, 46.91, 46.91, 48.3, 48.3, 48.3, 48.3], "power_watts_avg": 47.33, "power_watts_peak": 48.3, "energy_joules_est": 67.83, "sample_count": 15, "duration_seconds": 1.433}, "timestamp": "2026-01-12T10:26:31.213863"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1749.472, "latencies_ms": [1749.472], "images_per_second": 0.572, "prompt_tokens": 1099, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a collection of pumpkins, including a large one with a face carved into it, a smaller one with a skull design, and a third pumpkin with a carved face, all arranged on a table with a vase of flowers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.8, "ram_available_mb": 109098.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13390.8, "ram_available_mb": 109115.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.3, 33.43, 33.43, 33.43, 33.43, 33.43, 46.64, 46.64, 46.64, 46.64, 46.64, 48.17, 48.17, 48.17, 48.17, 48.17, 35.01, 35.01], "power_watts_avg": 42.19, "power_watts_peak": 48.3, "energy_joules_est": 73.84, "sample_count": 18, "duration_seconds": 1.75}, "timestamp": "2026-01-12T10:26:33.029142"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 544.657, "latencies_ms": [544.657], "images_per_second": 1.836, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pumpkin: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13390.8, "ram_available_mb": 109115.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13450.5, "ram_available_mb": 109055.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 35.01, 37.06, 37.06, 37.06], "power_watts_avg": 36.04, "power_watts_peak": 37.06, "energy_joules_est": 19.64, "sample_count": 6, "duration_seconds": 0.545}, "timestamp": "2026-01-12T10:26:33.637169"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1433.968, "latencies_ms": [1433.968], "images_per_second": 0.697, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The pumpkin with the face is positioned in the foreground, while the other pumpkins are in the background. The pumpkin with the face is also positioned to the left of the pumpkin with the flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13450.5, "ram_available_mb": 109055.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13421.8, "ram_available_mb": 109084.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [37.06, 44.39, 44.39, 44.39, 44.39, 44.39, 57.25, 57.25, 57.25, 57.25, 57.25, 49.75, 49.75, 49.75, 49.75], "power_watts_avg": 49.62, "power_watts_peak": 57.25, "energy_joules_est": 71.18, "sample_count": 15, "duration_seconds": 1.435}, "timestamp": "2026-01-12T10:26:35.148663"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 830.915, "latencies_ms": [830.915], "images_per_second": 1.203, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A collection of pumpkins with faces carved into them are displayed on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13421.8, "ram_available_mb": 109084.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13418.6, "ram_available_mb": 109087.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [49.75, 32.0, 32.0, 32.0, 32.0, 32.0, 46.95, 46.95, 46.95], "power_watts_avg": 38.95, "power_watts_peak": 49.75, "energy_joules_est": 32.39, "sample_count": 9, "duration_seconds": 0.831}, "timestamp": "2026-01-12T10:26:36.057497"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 912.427, "latencies_ms": [912.427], "images_per_second": 1.096, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The pumpkins are orange, the flowers are pink and white, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.6, "ram_available_mb": 109091.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13432.2, "ram_available_mb": 109074.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.95, 46.95, 49.92, 49.92, 49.92, 49.92, 49.92, 46.63, 46.63, 46.63], "power_watts_avg": 48.34, "power_watts_peak": 49.92, "energy_joules_est": 44.12, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-12T10:26:37.063507"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1176.433, "latencies_ms": [1176.433], "images_per_second": 0.85, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a mirror, and a door, all of which are in a state of disrepair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13424.4, "ram_available_mb": 109081.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13436.8, "ram_available_mb": 109069.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.63, 46.63, 46.01, 46.01, 46.01, 46.01, 46.01, 46.4, 46.4, 46.4, 46.4, 46.4], "power_watts_avg": 46.27, "power_watts_peak": 46.63, "energy_joules_est": 54.46, "sample_count": 12, "duration_seconds": 1.177}, "timestamp": "2026-01-12T10:26:38.276316"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1363.486, "latencies_ms": [1363.486], "images_per_second": 0.733, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " sink: 1, mirror: 1, door: 1, trash bag: 1, toilet: 1, shelf: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13428.9, "ram_available_mb": 109077.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13432.8, "ram_available_mb": 109073.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [46.66, 46.66, 46.66, 46.66, 46.66, 47.49, 47.49, 47.49, 47.49, 47.49, 47.37, 47.37, 47.37, 47.37], "power_watts_avg": 47.16, "power_watts_peak": 47.49, "energy_joules_est": 64.32, "sample_count": 14, "duration_seconds": 1.364}, "timestamp": "2026-01-12T10:26:39.688496"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1599.209, "latencies_ms": [1599.209], "images_per_second": 0.625, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The sink is located to the left of the door, and the trash bag is positioned in the foreground, closer to the camera. The mirror is above the sink, and the door is to the right of the sink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13433.0, "ram_available_mb": 109073.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13477.8, "ram_available_mb": 109028.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.37, 33.1, 33.1, 33.1, 33.1, 33.1, 47.1, 47.1, 47.1, 47.1, 47.1, 49.1, 49.1, 49.1, 49.1, 49.1], "power_watts_avg": 43.37, "power_watts_peak": 49.1, "energy_joules_est": 69.37, "sample_count": 16, "duration_seconds": 1.599}, "timestamp": "2026-01-12T10:26:41.301264"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 773.389, "latencies_ms": [773.389], "images_per_second": 1.293, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A bathroom with a white sink, mirror, and door.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13469.9, "ram_available_mb": 109036.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13392.4, "ram_available_mb": 109113.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 34.97, 34.97, 47.77, 47.77, 47.77], "power_watts_avg": 39.77, "power_watts_peak": 47.77, "energy_joules_est": 30.77, "sample_count": 8, "duration_seconds": 0.774}, "timestamp": "2026-01-12T10:26:42.111719"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 835.594, "latencies_ms": [835.594], "images_per_second": 1.197, "prompt_tokens": 1110, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The room is lit by a yellowish light, and the walls are white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.4, "ram_available_mb": 109113.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13338.7, "ram_available_mb": 109167.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.77, 47.77, 46.24, 46.24, 46.24, 46.24, 46.24, 47.33, 47.33], "power_watts_avg": 46.82, "power_watts_peak": 47.77, "energy_joules_est": 39.16, "sample_count": 9, "duration_seconds": 0.836}, "timestamp": "2026-01-12T10:26:43.019642"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 853.057, "latencies_ms": [853.057], "images_per_second": 1.172, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A little girl is sitting on a bed with a laptop in front of her.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13338.7, "ram_available_mb": 109167.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13390.1, "ram_available_mb": 109116.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.33, 47.33, 47.33, 51.7, 51.7, 51.7, 51.7, 51.7, 46.75], "power_watts_avg": 49.7, "power_watts_peak": 51.7, "energy_joules_est": 42.41, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-12T10:26:43.932436"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1956.868, "latencies_ms": [1956.868], "images_per_second": 0.511, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. laptop: 1\n2. child: 1\n3. bed: 1\n4. wall: 1\n5. screen: 1\n6. keyboard: 1\n7. laptop screen: 1\n8. laptop body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.2, "ram_available_mb": 109124.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13374.4, "ram_available_mb": 109131.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.75, 46.75, 46.75, 51.61, 51.61, 51.61, 51.61, 51.61, 47.08, 47.08, 47.08, 47.08, 47.08, 40.43, 40.43, 40.43, 40.43, 40.43, 35.02, 35.02], "power_watts_avg": 45.29, "power_watts_peak": 51.61, "energy_joules_est": 88.65, "sample_count": 20, "duration_seconds": 1.957}, "timestamp": "2026-01-12T10:26:45.951236"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1363.87, "latencies_ms": [1363.87], "images_per_second": 0.733, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The laptop is on the left side of the bed, and the child is sitting on the right side of the bed. The child is closer to the laptop than the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13374.4, "ram_available_mb": 109131.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13384.8, "ram_available_mb": 109121.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [35.02, 35.02, 35.02, 37.44, 37.44, 37.44, 37.44, 37.44, 45.97, 45.97, 45.97, 45.97, 45.97, 43.53], "power_watts_avg": 40.4, "power_watts_peak": 45.97, "energy_joules_est": 55.12, "sample_count": 14, "duration_seconds": 1.364}, "timestamp": "2026-01-12T10:26:47.416908"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 858.905, "latencies_ms": [858.905], "images_per_second": 1.164, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A little girl is sitting on a bed with a laptop in front of her.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.0, "ram_available_mb": 109129.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13373.7, "ram_available_mb": 109132.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [43.53, 43.53, 43.53, 43.53, 42.12, 42.12, 42.12, 42.12, 42.12], "power_watts_avg": 42.75, "power_watts_peak": 43.53, "energy_joules_est": 36.73, "sample_count": 9, "duration_seconds": 0.859}, "timestamp": "2026-01-12T10:26:48.327608"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 881.854, "latencies_ms": [881.854], "images_per_second": 1.134, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The image is in black and white, with a white background and a white bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.7, "ram_available_mb": 109132.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13397.4, "ram_available_mb": 109108.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [47.24, 47.24, 47.24, 47.24, 47.24, 51.42, 51.42, 51.42, 51.42], "power_watts_avg": 49.1, "power_watts_peak": 51.42, "energy_joules_est": 43.33, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T10:26:49.239461"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1035.408, "latencies_ms": [1035.408], "images_per_second": 0.966, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A skier wearing a brown jacket, blue helmet, and goggles is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13393.4, "ram_available_mb": 109112.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13325.6, "ram_available_mb": 109180.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.72, 46.72, 46.72, 46.72, 46.72, 48.87, 48.87, 48.87, 48.87, 48.87, 48.27], "power_watts_avg": 47.84, "power_watts_peak": 48.87, "energy_joules_est": 49.55, "sample_count": 11, "duration_seconds": 1.036}, "timestamp": "2026-01-12T10:26:50.353301"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1988.656, "latencies_ms": [1988.656], "images_per_second": 0.503, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. helmet: 1\n5. goggles: 1\n6. jacket: 1\n7. pants: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.7, "ram_available_mb": 109188.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.3, "ram_available_mb": 109156.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.27, 48.27, 48.27, 48.27, 44.31, 44.31, 44.31, 44.31, 44.31, 46.9, 46.9, 46.9, 46.9, 46.9, 38.25, 38.25, 38.25, 38.25, 38.25, 34.97], "power_watts_avg": 43.77, "power_watts_peak": 48.27, "energy_joules_est": 87.06, "sample_count": 20, "duration_seconds": 1.989}, "timestamp": "2026-01-12T10:26:52.372182"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1533.977, "latencies_ms": [1533.977], "images_per_second": 0.652, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the trees in the background. The skier is moving towards the right side of the image, while the trees are located on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.4, "ram_available_mb": 109163.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.2, "ram_available_mb": 109155.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 34.97, 41.68, 41.68, 41.68, 41.68, 41.68, 46.76, 46.76, 46.76, 46.76, 46.76, 40.15, 40.15], "power_watts_avg": 41.4, "power_watts_peak": 46.76, "energy_joules_est": 63.52, "sample_count": 16, "duration_seconds": 1.534}, "timestamp": "2026-01-12T10:26:54.039907"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 771.881, "latencies_ms": [771.881], "images_per_second": 1.296, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A skier is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.2, "ram_available_mb": 109159.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13362.7, "ram_available_mb": 109143.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [40.15, 40.15, 36.43, 36.43, 36.43, 36.43, 36.43, 46.61], "power_watts_avg": 38.63, "power_watts_peak": 46.61, "energy_joules_est": 29.84, "sample_count": 8, "duration_seconds": 0.772}, "timestamp": "2026-01-12T10:26:54.851366"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 959.241, "latencies_ms": [959.241], "images_per_second": 1.042, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a brown jacket and blue helmet, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.7, "ram_available_mb": 109143.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13363.0, "ram_available_mb": 109143.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.61, 46.61, 46.61, 46.61, 56.45, 56.45, 56.45, 56.45, 56.45, 47.47], "power_watts_avg": 51.62, "power_watts_peak": 56.45, "energy_joules_est": 49.54, "sample_count": 10, "duration_seconds": 0.96}, "timestamp": "2026-01-12T10:26:55.862810"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1376.965, "latencies_ms": [1376.965], "images_per_second": 0.726, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with a large bed, a blue armchair, and a nightstand with a lamp, all set against a backdrop of a window with curtains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.2, "ram_available_mb": 109159.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.47, 47.47, 47.47, 47.47, 47.8, 47.8, 47.8, 47.8, 47.8, 47.5, 47.5, 47.5, 47.5, 47.5], "power_watts_avg": 47.6, "power_watts_peak": 47.8, "energy_joules_est": 65.56, "sample_count": 14, "duration_seconds": 1.377}, "timestamp": "2026-01-12T10:26:57.279340"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1975.573, "latencies_ms": [1975.573], "images_per_second": 0.506, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bed: 1\n2. lamps: 2\n3. chair: 1\n4. suitcase: 1\n5. ottoman: 1\n6. window: 1\n7. wall: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.1, "ram_available_mb": 109154.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [37.51, 37.51, 37.51, 37.51, 37.51, 47.88, 47.88, 47.88, 47.88, 47.88, 47.59, 47.59, 47.59, 47.59, 47.59, 35.04, 35.04, 35.04, 35.04, 35.04], "power_watts_avg": 42.0, "power_watts_peak": 47.88, "energy_joules_est": 83.01, "sample_count": 20, "duration_seconds": 1.976}, "timestamp": "2026-01-12T10:26:59.298686"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1643.366, "latencies_ms": [1643.366], "images_per_second": 0.609, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the armchair to its left and the lamp to its right. The window is located behind the bed, and the suitcase is placed to the left of the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13427.8, "ram_available_mb": 109078.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 35.0, 44.7, 44.7, 44.7, 44.7, 44.7, 46.42, 46.42, 46.42, 46.42, 46.42, 37.75, 37.75, 37.75], "power_watts_avg": 41.7, "power_watts_peak": 46.42, "energy_joules_est": 68.56, "sample_count": 17, "duration_seconds": 1.644}, "timestamp": "2026-01-12T10:27:01.062575"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 924.481, "latencies_ms": [924.481], "images_per_second": 1.082, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A hotel room with a large bed, two lamps, a chair, and a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.9, "ram_available_mb": 109086.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13444.8, "ram_available_mb": 109061.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [37.75, 37.75, 36.2, 36.2, 36.2, 36.2, 36.2, 47.23, 47.23, 47.23], "power_watts_avg": 39.82, "power_watts_peak": 47.23, "energy_joules_est": 36.82, "sample_count": 10, "duration_seconds": 0.925}, "timestamp": "2026-01-12T10:27:02.075279"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1054.519, "latencies_ms": [1054.519], "images_per_second": 0.948, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted in a neutral color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13440.9, "ram_available_mb": 109065.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13429.8, "ram_available_mb": 109076.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.23, 47.23, 46.18, 46.18, 46.18, 46.18, 46.18, 46.89, 46.89, 46.89, 46.89], "power_watts_avg": 46.63, "power_watts_peak": 47.23, "energy_joules_est": 49.2, "sample_count": 11, "duration_seconds": 1.055}, "timestamp": "2026-01-12T10:27:03.187214"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1270.721, "latencies_ms": [1270.721], "images_per_second": 0.787, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a skier is performing a jump on a red rail on a snowy mountain, with other skiers and a ski lift in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13421.9, "ram_available_mb": 109084.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13417.6, "ram_available_mb": 109088.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.89, 45.46, 45.46, 45.46, 45.46, 45.46, 47.33, 47.33, 47.33, 47.33, 47.33, 48.61, 48.61], "power_watts_avg": 46.77, "power_watts_peak": 48.61, "energy_joules_est": 59.46, "sample_count": 13, "duration_seconds": 1.271}, "timestamp": "2026-01-12T10:27:04.504924"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2273.346, "latencies_ms": [2273.346], "images_per_second": 0.44, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. skier: 1\n3. snowboarder: 1\n4. ski lift: 1\n5. ski pole: 1\n6. ski pole holder: 1\n7. ski pole tip: 1\n8. snowboarder's foot: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13409.7, "ram_available_mb": 109096.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13400.4, "ram_available_mb": 109105.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.61, 48.61, 48.61, 38.95, 38.95, 38.95, 38.95, 38.95, 47.36, 47.36, 47.36, 47.36, 47.36, 44.28, 44.28, 44.28, 44.28, 44.28, 35.08, 35.08, 35.08, 35.08, 35.08], "power_watts_avg": 42.35, "power_watts_peak": 48.61, "energy_joules_est": 96.31, "sample_count": 23, "duration_seconds": 2.274}, "timestamp": "2026-01-12T10:27:06.826268"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2139.149, "latencies_ms": [2139.149], "images_per_second": 0.467, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main object, a snowboarder, is in the foreground, performing a trick on a red rail. The background features a ski lift and other skiers, indicating a bustling ski resort. The snowboarder is positioned to the left of the red rail, with the ski lift and other skiers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13384.2, "ram_available_mb": 109122.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.8, "ram_available_mb": 109134.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 34.97, 43.49, 43.49, 43.49, 43.49, 43.49, 46.39, 46.39, 46.39, 46.39, 46.39, 37.85, 37.85, 37.85, 37.85, 37.85, 34.94, 34.94, 34.94], "power_watts_avg": 40.15, "power_watts_peak": 46.39, "energy_joules_est": 85.9, "sample_count": 22, "duration_seconds": 2.139}, "timestamp": "2026-01-12T10:27:09.092200"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 918.815, "latencies_ms": [918.815], "images_per_second": 1.088, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are skiing down a snowy hill, with a red structure in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.9, "ram_available_mb": 109142.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.94, 31.44, 31.44, 31.44, 31.44, 31.44, 45.84, 45.84, 45.84, 45.84], "power_watts_avg": 37.55, "power_watts_peak": 45.84, "energy_joules_est": 34.53, "sample_count": 10, "duration_seconds": 0.92}, "timestamp": "2026-01-12T10:27:10.155147"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1473.587, "latencies_ms": [1473.587], "images_per_second": 0.679, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a vibrant scene of a snow-covered mountain with a clear blue sky, and the snow is a bright white color. The lighting is natural and bright, indicating that it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13373.2, "ram_available_mb": 109133.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.84, 46.34, 46.34, 46.34, 46.34, 46.34, 46.45, 46.45, 46.45, 46.45, 46.45, 49.38, 49.38, 49.38, 49.38], "power_watts_avg": 47.15, "power_watts_peak": 49.38, "energy_joules_est": 69.5, "sample_count": 15, "duration_seconds": 1.474}, "timestamp": "2026-01-12T10:27:11.669418"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1855.331, "latencies_ms": [1855.331], "images_per_second": 0.539, "prompt_tokens": 1100, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a vibrant scene of urban artistry, where a graffiti-covered wall serves as a canvas for a multitude of colors and designs, with a prominent sign reading \"THE ONE N' ONLY\" and a parking meter standing as a silent observer amidst the creative chaos.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13377.2, "ram_available_mb": 109129.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.4, "ram_available_mb": 109141.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [49.38, 33.04, 33.04, 33.04, 33.04, 33.04, 47.26, 47.26, 47.26, 47.26, 47.26, 49.51, 49.51, 49.51, 49.51, 49.51, 34.94, 34.94, 34.94], "power_watts_avg": 42.28, "power_watts_peak": 49.51, "energy_joules_est": 78.46, "sample_count": 19, "duration_seconds": 1.856}, "timestamp": "2026-01-12T10:27:13.586890"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1777.256, "latencies_ms": [1777.256], "images_per_second": 0.563, "prompt_tokens": 1114, "response_tokens_est": 51, "n_tiles": 1, "output_text": " 1. Graffiti wall\n2. Graffiti art\n3. Graffiti lettering\n4. Graffiti design\n5. Graffiti lettering\n6. Graffiti design\n7. Graffiti lettering\n8. Graffiti design", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13338.5, "ram_available_mb": 109167.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.94, 31.5, 31.5, 31.5, 31.5, 31.5, 45.96, 45.96, 45.96, 45.96, 45.96, 49.51, 49.51, 49.51, 49.51, 49.51, 34.95, 34.95], "power_watts_avg": 41.09, "power_watts_peak": 49.51, "energy_joules_est": 73.07, "sample_count": 18, "duration_seconds": 1.778}, "timestamp": "2026-01-12T10:27:15.454970"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1519.949, "latencies_ms": [1519.949], "images_per_second": 0.658, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The graffiti is located on the side of a building, with the parking meter situated in the foreground. The parking meter is positioned near the entrance of the building, with the graffiti extending further into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.5, "ram_available_mb": 109167.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.0, "ram_available_mb": 109161.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.95, 34.95, 34.95, 40.86, 40.86, 40.86, 40.86, 40.86, 47.57, 47.57, 47.57, 47.57, 47.57, 41.61, 41.61, 41.61], "power_watts_avg": 41.99, "power_watts_peak": 47.57, "energy_joules_est": 63.83, "sample_count": 16, "duration_seconds": 1.52}, "timestamp": "2026-01-12T10:27:17.069092"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1745.75, "latencies_ms": [1745.75], "images_per_second": 0.573, "prompt_tokens": 1112, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a vibrant scene of urban artistry, where a graffiti-covered wall serves as a canvas for various tags and designs. The wall, adorned with a mix of colors and patterns, stands as a testament to the creative energy of the city.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.1, "ram_available_mb": 109169.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.6, "ram_available_mb": 109149.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [41.61, 41.61, 34.75, 34.75, 34.75, 34.75, 34.75, 46.33, 46.33, 46.33, 46.33, 46.33, 46.79, 46.79, 46.79, 46.79, 46.79, 34.99], "power_watts_avg": 42.09, "power_watts_peak": 46.79, "energy_joules_est": 73.48, "sample_count": 18, "duration_seconds": 1.746}, "timestamp": "2026-01-12T10:27:18.885707"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1565.311, "latencies_ms": [1565.311], "images_per_second": 0.639, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a vibrant and colorful graffiti-covered wall with a mix of black, white, blue, and red colors. The lighting is natural, likely from the sun, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.6, "ram_available_mb": 109149.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13432.3, "ram_available_mb": 109074.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.99, 34.99, 34.99, 34.99, 43.06, 43.06, 43.06, 43.06, 43.06, 46.94, 46.94, 46.94, 46.94, 46.94, 38.74, 38.74], "power_watts_avg": 41.71, "power_watts_peak": 46.94, "energy_joules_est": 65.31, "sample_count": 16, "duration_seconds": 1.566}, "timestamp": "2026-01-12T10:27:20.498836"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 825.886, "latencies_ms": [825.886], "images_per_second": 1.211, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.3, "ram_available_mb": 109076.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13428.1, "ram_available_mb": 109078.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [38.74, 38.74, 38.74, 38.65, 38.65, 38.65, 38.65, 38.65, 47.29], "power_watts_avg": 39.64, "power_watts_peak": 47.29, "energy_joules_est": 32.77, "sample_count": 9, "duration_seconds": 0.827}, "timestamp": "2026-01-12T10:27:21.414755"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2009.478, "latencies_ms": [2009.478], "images_per_second": 0.498, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Water: 1\n6. Sky: 1\n7. Clouds: 1\n8. Sunlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.2, "ram_available_mb": 109086.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13407.1, "ram_available_mb": 109099.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.29, 47.29, 47.29, 47.29, 51.14, 51.14, 51.14, 51.14, 51.14, 46.51, 46.51, 46.51, 46.51, 46.51, 39.88, 39.88, 39.88, 39.88, 39.88, 34.98], "power_watts_avg": 45.59, "power_watts_peak": 51.14, "energy_joules_est": 91.63, "sample_count": 20, "duration_seconds": 2.01}, "timestamp": "2026-01-12T10:27:23.434354"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1730.568, "latencies_ms": [1730.568], "images_per_second": 0.578, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, riding a wave that is moving towards the right side of the frame. The wave is the main focus of the image, with the surfer positioned on the left side of the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13406.8, "ram_available_mb": 109099.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.98, 34.98, 34.98, 39.17, 39.17, 39.17, 39.17, 39.17, 47.19, 47.19, 47.19, 47.19, 47.19, 42.89, 42.89, 42.89, 42.89, 42.89], "power_watts_avg": 41.73, "power_watts_peak": 47.19, "energy_joules_est": 72.24, "sample_count": 18, "duration_seconds": 1.731}, "timestamp": "2026-01-12T10:27:25.302428"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 726.927, "latencies_ms": [726.927], "images_per_second": 1.376, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.9, "ram_available_mb": 109107.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13382.5, "ram_available_mb": 109123.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 90.0}, "power_stats": {"power_watts_samples": [34.45, 34.45, 34.45, 34.45, 34.45, 46.43, 46.43, 46.43], "power_watts_avg": 38.94, "power_watts_peak": 46.43, "energy_joules_est": 28.32, "sample_count": 8, "duration_seconds": 0.727}, "timestamp": "2026-01-12T10:27:26.112342"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1939.202, "latencies_ms": [1939.202], "images_per_second": 0.516, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a surfer riding a wave in the ocean, with the surfer wearing a black wetsuit and the wave displaying a deep blue color. The lighting in the image suggests it is either early morning or late afternoon, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.5, "ram_available_mb": 109123.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13427.0, "ram_available_mb": 109079.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.43, 46.43, 45.13, 45.13, 45.13, 45.13, 45.13, 47.48, 47.48, 47.48, 47.48, 47.48, 48.54, 48.54, 48.54, 48.54, 48.54, 34.94, 34.94, 34.94], "power_watts_avg": 45.17, "power_watts_peak": 48.54, "energy_joules_est": 87.62, "sample_count": 20, "duration_seconds": 1.94}, "timestamp": "2026-01-12T10:27:28.128257"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 979.14, "latencies_ms": [979.14], "images_per_second": 1.021, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A double-decker bus is parked at a bus stop, with a man standing next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.0, "ram_available_mb": 109083.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13418.0, "ram_available_mb": 109088.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.94, 31.47, 31.47, 31.47, 31.47, 31.47, 45.9, 45.9, 45.9, 45.9], "power_watts_avg": 37.59, "power_watts_peak": 45.9, "energy_joules_est": 36.86, "sample_count": 10, "duration_seconds": 0.981}, "timestamp": "2026-01-12T10:27:29.193135"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2061.199, "latencies_ms": [2061.199], "images_per_second": 0.485, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 2\n3. flowers: 1\n4. bus stop: 1\n5. bus number: 1\n6. bus route: 1\n7. bus destination: 1\n8. bus license plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.1, "ram_available_mb": 109096.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13388.3, "ram_available_mb": 109118.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [45.9, 47.41, 47.41, 47.41, 47.41, 47.41, 47.81, 47.81, 47.81, 47.81, 47.81, 49.22, 49.22, 49.22, 49.22, 49.22, 34.87, 34.87, 34.87, 34.87, 34.87], "power_watts_avg": 44.88, "power_watts_peak": 49.22, "energy_joules_est": 92.52, "sample_count": 21, "duration_seconds": 2.062}, "timestamp": "2026-01-12T10:27:31.311721"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1457.025, "latencies_ms": [1457.025], "images_per_second": 0.686, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The bus is on the left side of the image, with the passengers standing on the right side. The bus is in the foreground, while the bus stop and the building are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13388.3, "ram_available_mb": 109118.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13429.2, "ram_available_mb": 109077.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.93, 34.93, 34.93, 34.93, 43.76, 43.76, 43.76, 43.76, 43.76, 46.15, 46.15, 46.15, 46.15, 46.15, 37.36], "power_watts_avg": 41.78, "power_watts_peak": 46.15, "energy_joules_est": 60.9, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-12T10:27:32.874535"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 875.305, "latencies_ms": [875.305], "images_per_second": 1.142, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A double-decker bus is parked at a bus stop on a city street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13419.6, "ram_available_mb": 109086.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13428.1, "ram_available_mb": 109078.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [37.36, 37.36, 37.36, 37.36, 44.26, 44.26, 44.26, 44.26, 44.26], "power_watts_avg": 41.2, "power_watts_peak": 44.26, "energy_joules_est": 36.07, "sample_count": 9, "duration_seconds": 0.876}, "timestamp": "2026-01-12T10:27:33.784227"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1537.112, "latencies_ms": [1537.112], "images_per_second": 0.651, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a yellow double-decker bus with a black front, parked on a street with a red brick sidewalk. The sky is overcast, and the lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13428.1, "ram_available_mb": 109078.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13386.5, "ram_available_mb": 109119.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.07, 47.07, 47.07, 47.07, 47.07, 50.73, 50.73, 50.73, 50.73, 50.73, 47.83, 47.83, 47.83, 47.83, 47.83, 34.87], "power_watts_avg": 47.69, "power_watts_peak": 50.73, "energy_joules_est": 73.32, "sample_count": 16, "duration_seconds": 1.538}, "timestamp": "2026-01-12T10:27:35.395575"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 978.793, "latencies_ms": [978.793], "images_per_second": 1.022, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A yellow and red biplane with the registration number SP-AWE is flying in the cloudy sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13386.5, "ram_available_mb": 109119.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13399.9, "ram_available_mb": 109106.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 34.87, 42.61, 42.61, 42.61, 42.61, 42.61, 46.62], "power_watts_avg": 39.92, "power_watts_peak": 46.62, "energy_joules_est": 39.09, "sample_count": 10, "duration_seconds": 0.979}, "timestamp": "2026-01-12T10:27:36.410819"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1988.677, "latencies_ms": [1988.677], "images_per_second": 0.503, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. propeller: 1\n5. propeller blade: 1\n6. engine: 1\n7. landing gear: 1\n8. propeller shaft: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.0, "ram_available_mb": 109114.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13382.9, "ram_available_mb": 109123.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.62, 46.62, 46.62, 46.62, 47.26, 47.26, 47.26, 47.26, 47.26, 47.74, 47.74, 47.74, 47.74, 47.74, 40.31, 40.31, 40.31, 40.31, 40.31, 34.88], "power_watts_avg": 44.9, "power_watts_peak": 47.74, "energy_joules_est": 89.31, "sample_count": 20, "duration_seconds": 1.989}, "timestamp": "2026-01-12T10:27:38.430024"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1113.394, "latencies_ms": [1113.394], "images_per_second": 0.898, "prompt_tokens": 1117, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The yellow and red biplane is positioned in the foreground, flying from left to right, while the cloudy sky forms the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.9, "ram_available_mb": 109123.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13426.0, "ram_available_mb": 109080.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 39.02, 39.02, 39.02, 39.02, 39.02, 46.78, 46.78, 46.78, 46.78], "power_watts_avg": 40.57, "power_watts_peak": 46.78, "energy_joules_est": 45.21, "sample_count": 12, "duration_seconds": 1.114}, "timestamp": "2026-01-12T10:27:39.695413"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 749.193, "latencies_ms": [749.193], "images_per_second": 1.335, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A yellow and red biplane is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13422.0, "ram_available_mb": 109084.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13422.6, "ram_available_mb": 109083.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [46.78, 39.98, 39.98, 39.98, 39.98, 39.98, 46.23, 46.23], "power_watts_avg": 42.39, "power_watts_peak": 46.78, "energy_joules_est": 31.77, "sample_count": 8, "duration_seconds": 0.749}, "timestamp": "2026-01-12T10:27:40.506451"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1251.481, "latencies_ms": [1251.481], "images_per_second": 0.799, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The airplane is painted in vibrant yellow and red, with a blue propeller and a red tail. The sky is overcast, with a grayish hue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.7, "ram_available_mb": 109091.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13415.3, "ram_available_mb": 109091.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.23, 46.23, 46.23, 51.66, 51.66, 51.66, 51.66, 51.66, 47.0, 47.0, 47.0, 47.0, 47.0], "power_watts_avg": 48.61, "power_watts_peak": 51.66, "energy_joules_est": 60.85, "sample_count": 13, "duration_seconds": 1.252}, "timestamp": "2026-01-12T10:27:41.820447"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1467.905, "latencies_ms": [1467.905], "images_per_second": 0.681, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures an aerial view of a bustling airport, with a large parking lot brimming with cars and a building in the foreground, all under a clear blue sky dotted with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13415.3, "ram_available_mb": 109091.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13434.1, "ram_available_mb": 109072.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [44.5, 44.5, 44.5, 44.5, 44.5, 46.41, 46.41, 46.41, 46.41, 46.41, 47.07, 47.07, 47.07, 47.07, 47.07], "power_watts_avg": 45.99, "power_watts_peak": 47.07, "energy_joules_est": 67.54, "sample_count": 15, "duration_seconds": 1.469}, "timestamp": "2026-01-12T10:27:43.333694"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1389.212, "latencies_ms": [1389.212], "images_per_second": 0.72, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " airplane wing: 1, car: 100, building: 1, parking lot: 100, trees: 10, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13430.1, "ram_available_mb": 109076.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13435.4, "ram_available_mb": 109070.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [35.49, 35.49, 35.49, 35.49, 35.49, 45.95, 45.95, 45.95, 45.95, 45.95, 47.18, 47.18, 47.18, 47.18], "power_watts_avg": 42.57, "power_watts_peak": 47.18, "energy_joules_est": 59.15, "sample_count": 14, "duration_seconds": 1.39}, "timestamp": "2026-01-12T10:27:44.745825"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1437.725, "latencies_ms": [1437.725], "images_per_second": 0.696, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The airplane wing is on the left side of the image, while the parking lot is on the right side. The parking lot is in the foreground, with the cityscape in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13411.4, "ram_available_mb": 109094.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.18, 36.9, 36.9, 36.9, 36.9, 47.68, 47.68, 47.68, 47.68, 47.68, 48.09, 48.09, 48.09, 48.09, 48.09], "power_watts_avg": 44.91, "power_watts_peak": 48.09, "energy_joules_est": 64.6, "sample_count": 15, "duration_seconds": 1.439}, "timestamp": "2026-01-12T10:27:46.260819"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1969.297, "latencies_ms": [1969.297], "images_per_second": 0.508, "prompt_tokens": 1111, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures a bustling scene from an airplane window, offering a bird's eye view of a sprawling parking lot nestled amidst a verdant landscape. The parking lot, teeming with cars of various colors, is nestled amidst a mix of residential and commercial buildings, creating a vibrant urban tapestry.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13411.1, "ram_available_mb": 109095.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13429.5, "ram_available_mb": 109076.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.01, 34.01, 34.01, 34.01, 34.01, 46.94, 46.94, 46.94, 46.94, 46.94, 47.71, 47.71, 47.71, 47.71, 47.71, 34.78, 34.78, 34.78, 34.78, 34.78], "power_watts_avg": 40.86, "power_watts_peak": 47.71, "energy_joules_est": 80.48, "sample_count": 20, "duration_seconds": 1.97}, "timestamp": "2026-01-12T10:27:48.277395"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1915.941, "latencies_ms": [1915.941], "images_per_second": 0.522, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image is a high-angle aerial view of a parking lot, with a clear blue sky and white clouds in the background. The parking lot is filled with numerous cars of various colors, and there are several buildings in the vicinity, including a large one with a red roof.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.5, "ram_available_mb": 109080.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13405.5, "ram_available_mb": 109100.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 34.86, 45.21, 45.21, 45.21, 45.21, 45.21, 46.45, 46.45, 46.45, 46.45, 46.45, 36.06, 36.06, 36.06, 36.06, 36.06], "power_watts_avg": 40.64, "power_watts_peak": 46.45, "energy_joules_est": 77.91, "sample_count": 20, "duration_seconds": 1.917}, "timestamp": "2026-01-12T10:27:50.346846"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 881.719, "latencies_ms": [881.719], "images_per_second": 1.134, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a pink flip phone with a picture of a girl on it.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13397.6, "ram_available_mb": 109108.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.82, 34.82, 34.82, 34.82, 41.23, 41.23, 41.23, 41.23, 41.23], "power_watts_avg": 38.38, "power_watts_peak": 41.23, "energy_joules_est": 33.88, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:27:51.310942"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1930.78, "latencies_ms": [1930.78], "images_per_second": 0.518, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. cell phone: 1\n3. cup: 1\n4. book: 1\n5. bag: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13409.8, "ram_available_mb": 109096.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13418.2, "ram_available_mb": 109088.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.08, 45.08, 45.08, 45.08, 45.08, 52.2, 52.2, 52.2, 52.2, 52.2, 47.95, 47.95, 47.95, 47.95, 47.95, 35.1, 35.1, 35.1, 35.1, 35.1], "power_watts_avg": 45.08, "power_watts_peak": 52.2, "energy_joules_est": 87.07, "sample_count": 20, "duration_seconds": 1.931}, "timestamp": "2026-01-12T10:27:53.329318"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1671.352, "latencies_ms": [1671.352], "images_per_second": 0.598, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The pink flip phone is held in the foreground by a person's hand, while the person's legs are visible in the background. The person is sitting on a couch, and there is a cup of soda on the table behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.3, "ram_available_mb": 109092.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13402.1, "ram_available_mb": 109104.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [34.86, 34.86, 34.86, 34.86, 34.86, 45.67, 45.67, 45.67, 45.67, 45.67, 46.53, 46.53, 46.53, 46.53, 46.53, 35.66, 35.66], "power_watts_avg": 41.57, "power_watts_peak": 46.53, "energy_joules_est": 69.48, "sample_count": 17, "duration_seconds": 1.672}, "timestamp": "2026-01-12T10:27:55.043594"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1276.851, "latencies_ms": [1276.851], "images_per_second": 0.783, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A person is holding a pink flip phone with a picture of a girl on it. The person is sitting on a couch with a book in front of them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.2, "ram_available_mb": 109112.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13413.7, "ram_available_mb": 109092.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [35.66, 35.66, 35.66, 37.02, 37.02, 37.02, 37.02, 37.02, 47.2, 47.2, 47.2, 47.2, 45.09], "power_watts_avg": 40.46, "power_watts_peak": 47.2, "energy_joules_est": 51.69, "sample_count": 13, "duration_seconds": 1.278}, "timestamp": "2026-01-12T10:27:56.358331"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1326.474, "latencies_ms": [1326.474], "images_per_second": 0.754, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a pink flip phone in the foreground. The phone is held by a person wearing blue jeans and white sneakers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.7, "ram_available_mb": 109092.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13395.6, "ram_available_mb": 109110.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 44.0}, "power_stats": {"power_watts_samples": [45.09, 45.09, 45.09, 45.09, 45.41, 45.41, 45.41, 45.41, 45.41, 47.53, 47.53, 47.53, 47.53, 47.53], "power_watts_avg": 46.08, "power_watts_peak": 47.53, "energy_joules_est": 61.13, "sample_count": 14, "duration_seconds": 1.327}, "timestamp": "2026-01-12T10:27:57.772108"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1093.204, "latencies_ms": [1093.204], "images_per_second": 0.915, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " Two zebras are standing in a dry grass field, with one zebra looking directly at the camera and the other looking away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.6, "ram_available_mb": 109110.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13402.7, "ram_available_mb": 109103.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.95, 35.95, 35.95, 35.95, 35.95, 46.6, 46.6, 46.6, 46.6, 46.6, 47.83], "power_watts_avg": 41.87, "power_watts_peak": 47.83, "energy_joules_est": 45.78, "sample_count": 11, "duration_seconds": 1.093}, "timestamp": "2026-01-12T10:27:58.886649"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 546.499, "latencies_ms": [546.499], "images_per_second": 1.83, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.8, "ram_available_mb": 109111.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13337.5, "ram_available_mb": 109168.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.83, 47.83, 47.83, 47.83, 44.5, 44.5], "power_watts_avg": 46.72, "power_watts_peak": 47.83, "energy_joules_est": 25.56, "sample_count": 6, "duration_seconds": 0.547}, "timestamp": "2026-01-12T10:27:59.496715"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1841.698, "latencies_ms": [1841.698], "images_per_second": 0.543, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the one on the right. The background of the image features a grassy field with trees and hills, providing a natural habitat for the zebras.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.5, "ram_available_mb": 109168.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13330.4, "ram_available_mb": 109175.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [44.5, 44.5, 44.5, 52.12, 52.12, 52.12, 52.12, 52.12, 50.67, 50.67, 50.67, 50.67, 50.67, 42.51, 42.51, 42.51, 42.51, 42.51, 34.84], "power_watts_avg": 47.1, "power_watts_peak": 52.12, "energy_joules_est": 86.76, "sample_count": 19, "duration_seconds": 1.842}, "timestamp": "2026-01-12T10:28:01.415635"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 910.545, "latencies_ms": [910.545], "images_per_second": 1.098, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two zebras are standing in a tall, dry grass field, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13322.6, "ram_available_mb": 109183.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13346.3, "ram_available_mb": 109160.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.84, 39.55, 39.55, 39.55, 39.55, 39.55, 45.58, 45.58], "power_watts_avg": 39.34, "power_watts_peak": 45.58, "energy_joules_est": 35.85, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-12T10:28:02.477088"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1011.923, "latencies_ms": [1011.923], "images_per_second": 0.988, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The zebras are black and white with a pattern of stripes, and the grass is a golden brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.4, "ram_available_mb": 109167.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.58, 45.58, 45.58, 46.48, 46.48, 46.48, 46.48, 46.48, 46.25, 46.25, 46.25], "power_watts_avg": 46.17, "power_watts_peak": 46.48, "energy_joules_est": 46.74, "sample_count": 11, "duration_seconds": 1.012}, "timestamp": "2026-01-12T10:28:03.590376"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 855.349, "latencies_ms": [855.349], "images_per_second": 1.169, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is walking on the beach with a yellow surfboard in his hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13353.5, "ram_available_mb": 109152.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 52.0}, "power_stats": {"power_watts_samples": [46.25, 46.25, 41.2, 41.2, 41.2, 41.2, 41.2, 46.34, 46.34], "power_watts_avg": 43.47, "power_watts_peak": 46.34, "energy_joules_est": 37.19, "sample_count": 9, "duration_seconds": 0.856}, "timestamp": "2026-01-12T10:28:04.505061"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1993.211, "latencies_ms": [1993.211], "images_per_second": 0.502, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfboard: 1\n2. Man: 1\n3. Ocean: 2\n4. Waves: 2\n5. Sunlight: 1\n6. Sky: 1\n7. Water: 1\n8. Sand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.6, "ram_available_mb": 109160.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13340.3, "ram_available_mb": 109166.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.34, 46.34, 46.34, 50.88, 50.88, 50.88, 50.88, 50.88, 47.14, 47.14, 47.14, 47.14, 47.14, 43.83, 43.83, 43.83, 43.83, 43.83, 34.96, 34.96], "power_watts_avg": 45.91, "power_watts_peak": 50.88, "energy_joules_est": 91.53, "sample_count": 20, "duration_seconds": 1.994}, "timestamp": "2026-01-12T10:28:06.524683"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1496.264, "latencies_ms": [1496.264], "images_per_second": 0.668, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The man is standing in the foreground of the image, with the ocean waves in the background. The yellow surfboard is held in front of the man, and the water is splashing around him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.3, "ram_available_mb": 109166.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.96, 34.96, 35.53, 35.53, 35.53, 35.53, 35.53, 46.59, 46.59, 46.59, 46.59, 46.59, 46.88, 46.88, 46.88], "power_watts_avg": 41.41, "power_watts_peak": 46.88, "energy_joules_est": 62.0, "sample_count": 15, "duration_seconds": 1.497}, "timestamp": "2026-01-12T10:28:08.090441"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1148.463, "latencies_ms": [1148.463], "images_per_second": 0.871, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A young man is walking on the beach with a yellow surfboard. The ocean is in the background, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.5, "ram_available_mb": 109166.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13348.1, "ram_available_mb": 109158.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.88, 46.88, 35.82, 35.82, 35.82, 35.82, 35.82, 47.82, 47.82, 47.82, 47.82, 47.82], "power_watts_avg": 42.66, "power_watts_peak": 47.82, "energy_joules_est": 49.01, "sample_count": 12, "duration_seconds": 1.149}, "timestamp": "2026-01-12T10:28:09.301092"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1417.593, "latencies_ms": [1417.593], "images_per_second": 0.705, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a man in the ocean, holding a yellow surfboard. The sky is clear and blue, and the water is a deep blue with white waves crashing onto the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.2, "ram_available_mb": 109166.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [47.39, 47.39, 47.39, 47.39, 47.39, 47.21, 47.21, 47.21, 47.21, 47.21, 47.24, 47.24, 47.24, 47.24, 47.24], "power_watts_avg": 47.28, "power_watts_peak": 47.39, "energy_joules_est": 67.04, "sample_count": 15, "duration_seconds": 1.418}, "timestamp": "2026-01-12T10:28:10.815921"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 882.834, "latencies_ms": [882.834], "images_per_second": 1.133, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white cow is standing on a beach with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.4, "ram_available_mb": 109162.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_watts_samples": [34.22, 34.22, 34.22, 34.22, 34.22, 46.46, 46.46, 46.46, 46.46], "power_watts_avg": 39.66, "power_watts_peak": 46.46, "energy_joules_est": 35.03, "sample_count": 9, "duration_seconds": 0.883}, "timestamp": "2026-01-12T10:28:11.727174"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 538.722, "latencies_ms": [538.722], "images_per_second": 1.856, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " cow: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13344.0, "ram_available_mb": 109162.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 57.0}, "power_stats": {"power_watts_samples": [46.46, 46.08, 46.08, 46.08, 46.08, 46.08], "power_watts_avg": 46.14, "power_watts_peak": 46.46, "energy_joules_est": 24.87, "sample_count": 6, "duration_seconds": 0.539}, "timestamp": "2026-01-12T10:28:12.336388"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1230.328, "latencies_ms": [1230.328], "images_per_second": 0.813, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The cow is standing in the foreground, close to the camera, on the beach. The water is in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.0, "ram_available_mb": 109174.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13350.3, "ram_available_mb": 109156.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [48.25, 48.25, 48.25, 48.25, 48.25, 60.31, 60.31, 60.31, 60.31, 60.31, 46.75, 46.75, 46.75], "power_watts_avg": 52.54, "power_watts_peak": 60.31, "energy_joules_est": 64.67, "sample_count": 13, "duration_seconds": 1.231}, "timestamp": "2026-01-12T10:28:13.649662"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 833.132, "latencies_ms": [833.132], "images_per_second": 1.2, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A black and white cow stands on a beach, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.4, "ram_available_mb": 109163.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13352.9, "ram_available_mb": 109153.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 1.0}, "power_stats": {"power_watts_samples": [46.75, 46.75, 33.89, 33.89, 33.89, 33.89, 33.89, 46.83, 46.83], "power_watts_avg": 39.63, "power_watts_peak": 46.83, "energy_joules_est": 33.03, "sample_count": 9, "duration_seconds": 0.833}, "timestamp": "2026-01-12T10:28:14.558845"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 913.203, "latencies_ms": [913.203], "images_per_second": 1.095, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The cow is black and white, standing on a beach with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13348.9, "ram_available_mb": 109157.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13345.0, "ram_available_mb": 109161.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [46.83, 46.83, 50.96, 50.96, 50.96, 50.96, 50.96, 46.59, 46.59, 46.59], "power_watts_avg": 48.82, "power_watts_peak": 50.96, "energy_joules_est": 44.6, "sample_count": 10, "duration_seconds": 0.914}, "timestamp": "2026-01-12T10:28:15.570962"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1199.232, "latencies_ms": [1199.232], "images_per_second": 0.834, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A woman in a white blouse and black pants is standing on skis in the snow, holding ski poles and wearing a scarf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.1, "ram_available_mb": 109169.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.59, 46.59, 45.58, 45.58, 45.58, 45.58, 45.58, 46.05, 46.05, 46.05, 46.05, 46.05], "power_watts_avg": 45.94, "power_watts_peak": 46.59, "energy_joules_est": 55.12, "sample_count": 12, "duration_seconds": 1.2}, "timestamp": "2026-01-12T10:28:16.784037"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2026.945, "latencies_ms": [2026.945], "images_per_second": 0.493, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. woman: 1\n2. ski poles: 2\n3. skis: 2\n4. backpack: 1\n5. trees: 2\n6. clouds: 1\n7. snow: 1\n8. woman's hair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.5, "ram_available_mb": 109165.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.34, 46.34, 46.34, 46.34, 46.34, 47.91, 47.91, 47.91, 47.91, 47.91, 48.08, 48.08, 48.08, 48.08, 48.08, 34.89, 34.89, 34.89, 34.89, 34.89, 34.93], "power_watts_avg": 43.86, "power_watts_peak": 48.08, "energy_joules_est": 88.93, "sample_count": 21, "duration_seconds": 2.028}, "timestamp": "2026-01-12T10:28:18.899427"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1434.06, "latencies_ms": [1434.06], "images_per_second": 0.697, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The woman is standing in the foreground, with the ski poles and trees in the background. The woman is holding the ski poles in her right hand, and the trees are behind her.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13340.4, "ram_available_mb": 109165.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.9, "ram_used_mb": 13372.5, "ram_available_mb": 109133.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.93, 34.93, 34.93, 34.93, 39.78, 39.78, 39.78, 39.78, 45.38, 45.38, 45.38, 45.38, 45.38, 41.15, 41.15], "power_watts_avg": 40.54, "power_watts_peak": 45.38, "energy_joules_est": 58.17, "sample_count": 15, "duration_seconds": 1.435}, "timestamp": "2026-01-12T10:28:20.464497"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1104.284, "latencies_ms": [1104.284], "images_per_second": 0.906, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A woman in a white blouse and black pants is standing on a snowy hill, holding ski poles and wearing skis.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13372.5, "ram_available_mb": 109133.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [41.15, 41.15, 41.15, 39.76, 39.76, 39.76, 39.76, 39.76, 46.46, 46.46, 46.46], "power_watts_avg": 41.97, "power_watts_peak": 46.46, "energy_joules_est": 46.36, "sample_count": 11, "duration_seconds": 1.105}, "timestamp": "2026-01-12T10:28:21.575117"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1501.934, "latencies_ms": [1501.934], "images_per_second": 0.666, "prompt_tokens": 1110, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the light and dark areas. The woman is wearing a white blouse and black pants, and the snow on the ground is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13369.0, "ram_available_mb": 109137.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13341.2, "ram_available_mb": 109165.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.46, 46.46, 43.97, 43.97, 43.97, 43.97, 43.97, 48.16, 48.16, 48.16, 48.16, 48.16, 46.27, 46.27, 46.27], "power_watts_avg": 46.16, "power_watts_peak": 48.16, "energy_joules_est": 69.34, "sample_count": 15, "duration_seconds": 1.502}, "timestamp": "2026-01-12T10:28:23.084634"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1386.538, "latencies_ms": [1386.538], "images_per_second": 0.721, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A dog with a black, white, and gray coat is holding a yellow frisbee in its mouth on a sandy beach with the ocean and a small island in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13333.3, "ram_available_mb": 109173.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_watts_samples": [46.27, 46.27, 36.51, 36.51, 36.51, 36.51, 36.51, 47.98, 47.98, 47.98, 47.98, 47.98, 46.4, 46.4], "power_watts_avg": 43.41, "power_watts_peak": 47.98, "energy_joules_est": 60.23, "sample_count": 14, "duration_seconds": 1.387}, "timestamp": "2026-01-12T10:28:24.501401"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1390.853, "latencies_ms": [1390.853], "images_per_second": 0.719, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " dog: 1, frisbee: 1, beach: 1, ocean: 1, island: 1, sand: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13361.8, "ram_available_mb": 109144.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13347.2, "ram_available_mb": 109159.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [46.4, 46.4, 46.4, 39.78, 39.78, 39.78, 39.78, 39.78, 47.89, 47.89, 47.89, 47.89, 47.89, 43.05], "power_watts_avg": 44.33, "power_watts_peak": 47.89, "energy_joules_est": 61.68, "sample_count": 14, "duration_seconds": 1.392}, "timestamp": "2026-01-12T10:28:25.912295"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1784.77, "latencies_ms": [1784.77], "images_per_second": 0.56, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The dog is in the foreground, holding a yellow frisbee in its mouth. The beach is in the background, with the ocean and a small island visible. The dog is looking towards the camera, which is positioned to the left of the dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.3, "ram_available_mb": 109163.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13359.0, "ram_available_mb": 109147.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [43.05, 43.05, 43.05, 43.05, 43.72, 43.72, 43.72, 43.72, 43.72, 47.87, 47.87, 47.87, 47.87, 47.87, 39.74, 39.74, 39.74, 39.74], "power_watts_avg": 43.84, "power_watts_peak": 47.87, "energy_joules_est": 78.27, "sample_count": 18, "duration_seconds": 1.785}, "timestamp": "2026-01-12T10:28:27.729599"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1087.993, "latencies_ms": [1087.993], "images_per_second": 0.919, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A dog is playing on the beach with a frisbee. The beach is sandy and there are waves in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.0, "ram_available_mb": 109147.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.8, "ram_available_mb": 109165.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [39.74, 33.94, 33.94, 33.94, 33.94, 33.94, 47.77, 47.77, 47.77, 47.77, 47.77], "power_watts_avg": 40.75, "power_watts_peak": 47.77, "energy_joules_est": 44.35, "sample_count": 11, "duration_seconds": 1.088}, "timestamp": "2026-01-12T10:28:28.840455"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 912.001, "latencies_ms": [912.001], "images_per_second": 1.096, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The dog is black and white, the beach is sandy, and the ocean is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13364.7, "ram_available_mb": 109141.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.85, 48.85, 48.85, 48.85, 48.85, 46.71, 46.71, 46.71, 46.71, 46.71], "power_watts_avg": 47.78, "power_watts_peak": 48.85, "energy_joules_est": 43.59, "sample_count": 10, "duration_seconds": 0.912}, "timestamp": "2026-01-12T10:28:29.853519"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1459.647, "latencies_ms": [1459.647], "images_per_second": 0.685, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In a kitchen, a group of women, including a woman in a camouflage uniform, are gathered around a table with a large pot of food, while a woman in a white shirt stands nearby.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13364.9, "ram_available_mb": 109141.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.7, 47.7, 47.7, 47.7, 45.94, 45.94, 45.94, 45.94, 45.94, 46.42, 46.42, 46.42, 46.42, 46.42, 36.42], "power_watts_avg": 45.93, "power_watts_peak": 47.7, "energy_joules_est": 67.06, "sample_count": 15, "duration_seconds": 1.46}, "timestamp": "2026-01-12T10:28:31.372398"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1910.141, "latencies_ms": [1910.141], "images_per_second": 0.524, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. woman: 2\n2. woman: 2\n3. woman: 2\n4. woman: 2\n5. woman: 2\n6. woman: 2\n7. woman: 2\n8. woman: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.9, "ram_available_mb": 109097.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.42, 36.42, 36.42, 36.42, 44.9, 44.9, 44.9, 44.9, 44.9, 47.17, 47.17, 47.17, 47.17, 47.17, 37.19, 37.19, 37.19, 37.19, 37.19], "power_watts_avg": 41.68, "power_watts_peak": 47.17, "energy_joules_est": 79.64, "sample_count": 19, "duration_seconds": 1.911}, "timestamp": "2026-01-12T10:28:33.290813"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2276.127, "latencies_ms": [2276.127], "images_per_second": 0.439, "prompt_tokens": 1117, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground of the image, with the kitchen appliances and countertop in the background. The person in the camouflage uniform is standing near the countertop, while the other individuals are positioned further back in the kitchen. The large pot is placed on the countertop, and the green bowl is on the countertop as well.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.1, "ram_available_mb": 109105.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13411.7, "ram_available_mb": 109094.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.94, 34.94, 34.94, 34.94, 34.94, 46.3, 46.3, 46.3, 46.3, 46.3, 47.07, 47.07, 47.07, 47.07, 47.07, 35.77, 35.77, 35.77, 35.77, 35.77, 35.01, 35.01, 35.01], "power_watts_avg": 40.24, "power_watts_peak": 47.07, "energy_joules_est": 91.61, "sample_count": 23, "duration_seconds": 2.277}, "timestamp": "2026-01-12T10:28:35.653064"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 992.839, "latencies_ms": [992.839], "images_per_second": 1.007, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of women in military uniforms are standing in a kitchen, one of them is holding a book.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.8, "ram_available_mb": 109098.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13415.7, "ram_available_mb": 109090.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [35.01, 32.53, 32.53, 32.53, 32.53, 32.53, 46.56, 46.56, 46.56, 46.56], "power_watts_avg": 38.39, "power_watts_peak": 46.56, "energy_joules_est": 38.13, "sample_count": 10, "duration_seconds": 0.993}, "timestamp": "2026-01-12T10:28:36.714785"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 910.656, "latencies_ms": [910.656], "images_per_second": 1.098, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the walls are made of concrete.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13415.7, "ram_available_mb": 109090.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 54.0}, "power_stats": {"power_watts_samples": [46.56, 48.14, 48.14, 48.14, 48.14, 48.14, 48.09, 48.09, 48.09, 48.09], "power_watts_avg": 47.96, "power_watts_peak": 48.14, "energy_joules_est": 43.69, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-12T10:28:37.724528"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 983.601, "latencies_ms": [983.601], "images_per_second": 1.017, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image depicts a bathroom with a toilet, a shelf with various toiletries, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13404.5, "ram_available_mb": 109101.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [48.09, 46.64, 46.64, 46.64, 46.64, 46.64, 46.27, 46.27, 46.27, 46.27], "power_watts_avg": 46.63, "power_watts_peak": 48.09, "energy_joules_est": 45.9, "sample_count": 10, "duration_seconds": 0.984}, "timestamp": "2026-01-12T10:28:38.738487"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1930.138, "latencies_ms": [1930.138], "images_per_second": 0.518, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. toilet: 1\n2. shelf: 3\n3. bottles: 4\n4. towel: 2\n5. toilet paper: 1\n6. phone: 1\n7. mirror: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.7, "ram_available_mb": 109109.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13402.1, "ram_available_mb": 109104.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.27, 47.49, 47.49, 47.49, 47.49, 47.49, 47.61, 47.61, 47.61, 47.61, 47.61, 48.06, 48.06, 48.06, 48.06, 48.06, 35.07, 35.07, 35.07, 35.07], "power_watts_avg": 45.12, "power_watts_peak": 48.06, "energy_joules_est": 87.11, "sample_count": 20, "duration_seconds": 1.931}, "timestamp": "2026-01-12T10:28:40.756812"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1507.893, "latencies_ms": [1507.893], "images_per_second": 0.663, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the shelf above it in the middle ground. The sink is situated to the left of the toilet, while the towel rack is to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13393.1, "ram_available_mb": 109113.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13408.8, "ram_available_mb": 109097.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.5, 33.5, 33.5, 33.5, 33.5, 45.85, 45.85, 45.85, 45.85, 45.85, 47.38, 47.38, 47.38, 47.38, 47.38], "power_watts_avg": 42.25, "power_watts_peak": 47.38, "energy_joules_est": 63.74, "sample_count": 15, "duration_seconds": 1.509}, "timestamp": "2026-01-12T10:28:42.322933"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 851.526, "latencies_ms": [851.526], "images_per_second": 1.174, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a toilet, sink, and shower is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.9, "ram_available_mb": 109101.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13405.7, "ram_available_mb": 109100.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.96, 34.96, 34.96, 34.96, 34.96, 48.33, 48.33, 48.33, 48.33], "power_watts_avg": 40.9, "power_watts_peak": 48.33, "energy_joules_est": 34.84, "sample_count": 9, "duration_seconds": 0.852}, "timestamp": "2026-01-12T10:28:43.233530"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1063.481, "latencies_ms": [1063.481], "images_per_second": 0.94, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The bathroom is well-lit with a warm yellow light, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.8, "ram_available_mb": 109108.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13409.2, "ram_available_mb": 109097.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [48.33, 46.65, 46.65, 46.65, 46.65, 46.65, 47.68, 47.68, 47.68, 47.68, 47.68], "power_watts_avg": 47.27, "power_watts_peak": 48.33, "energy_joules_est": 50.29, "sample_count": 11, "duration_seconds": 1.064}, "timestamp": "2026-01-12T10:28:44.344930"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 984.372, "latencies_ms": [984.372], "images_per_second": 1.016, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A dog wearing a green hat is sitting in the back seat of a car, looking out the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.3, "ram_available_mb": 109105.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [48.77, 48.77, 48.77, 48.77, 48.77, 46.29, 46.29, 46.29, 46.29, 46.29], "power_watts_avg": 47.53, "power_watts_peak": 48.77, "energy_joules_est": 46.81, "sample_count": 10, "duration_seconds": 0.985}, "timestamp": "2026-01-12T10:28:45.358200"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1371.557, "latencies_ms": [1371.557], "images_per_second": 0.729, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " dog: 1, hat: 1, car: 1, window: 1, light: 1, shamrock: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.4, "ram_available_mb": 109111.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13393.1, "ram_available_mb": 109113.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.33, 47.33, 47.33, 47.33, 45.84, 45.84, 45.84, 45.84, 45.84, 47.57, 47.57, 47.57, 47.57, 47.57], "power_watts_avg": 46.88, "power_watts_peak": 47.57, "energy_joules_est": 64.33, "sample_count": 14, "duration_seconds": 1.372}, "timestamp": "2026-01-12T10:28:46.777993"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1681.504, "latencies_ms": [1681.504], "images_per_second": 0.595, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The dog is in the driver's seat, which is on the left side of the vehicle. The person is in the passenger seat, which is on the right side of the vehicle. The dog is closer to the camera than the person.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.2, "ram_available_mb": 109121.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13395.2, "ram_available_mb": 109111.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [38.23, 38.23, 38.23, 38.23, 38.23, 47.53, 47.53, 47.53, 47.53, 47.53, 48.2, 48.2, 48.2, 48.2, 48.2, 35.17, 35.17], "power_watts_avg": 43.54, "power_watts_peak": 48.2, "energy_joules_est": 73.23, "sample_count": 17, "duration_seconds": 1.682}, "timestamp": "2026-01-12T10:28:48.494990"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 995.255, "latencies_ms": [995.255], "images_per_second": 1.005, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A dog wearing a green hat is sitting in the back seat of a car, looking out the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.2, "ram_available_mb": 109111.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13385.6, "ram_available_mb": 109120.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.17, 35.17, 35.17, 40.47, 40.47, 40.47, 40.47, 40.47, 47.7, 47.7], "power_watts_avg": 40.33, "power_watts_peak": 47.7, "energy_joules_est": 40.16, "sample_count": 10, "duration_seconds": 0.996}, "timestamp": "2026-01-12T10:28:49.507320"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1702.078, "latencies_ms": [1702.078], "images_per_second": 0.588, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a dog wearing a green hat and a green shamrock on the side of a vehicle, with a person in the driver's seat. The vehicle is decorated with green and orange balloons, and the lighting suggests it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13385.6, "ram_available_mb": 109120.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13367.9, "ram_available_mb": 109138.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.7, 47.7, 47.7, 47.6, 47.6, 47.6, 47.6, 47.6, 47.85, 47.85, 47.85, 47.85, 47.85, 44.01, 44.01, 44.01, 44.01], "power_watts_avg": 46.85, "power_watts_peak": 47.85, "energy_joules_est": 79.77, "sample_count": 17, "duration_seconds": 1.703}, "timestamp": "2026-01-12T10:28:51.221546"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1223.765, "latencies_ms": [1223.765], "images_per_second": 0.817, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, a large elephant is standing in a shallow pool of water, with a large log lying nearby, and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13360.0, "ram_available_mb": 109146.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13383.6, "ram_available_mb": 109122.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [44.01, 34.23, 34.23, 34.23, 34.23, 34.23, 48.34, 48.34, 48.34, 48.34, 48.34, 49.0, 49.0], "power_watts_avg": 42.68, "power_watts_peak": 49.0, "energy_joules_est": 52.26, "sample_count": 13, "duration_seconds": 1.224}, "timestamp": "2026-01-12T10:28:52.539878"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1252.011, "latencies_ms": [1252.011], "images_per_second": 0.799, "prompt_tokens": 1113, "response_tokens_est": 31, "n_tiles": 1, "output_text": " elephant: 1\nwater: 1\nrocks: 3\ntree: 1\nfence: 1\npeople: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13375.7, "ram_available_mb": 109130.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13386.0, "ram_available_mb": 109120.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.0, 49.0, 49.0, 37.06, 37.06, 37.06, 37.06, 37.06, 46.6, 46.6, 46.6, 46.6, 46.6], "power_watts_avg": 43.49, "power_watts_peak": 49.0, "energy_joules_est": 54.46, "sample_count": 13, "duration_seconds": 1.252}, "timestamp": "2026-01-12T10:28:53.855439"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2058.436, "latencies_ms": [2058.436], "images_per_second": 0.486, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The elephant is positioned in the foreground, with the water body and rocks in the middle ground, and the people and fence in the background. The elephant is facing the water body, with its trunk extended towards it, and the rocks are positioned in the foreground, with the water body in the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.1, "ram_available_mb": 109124.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13380.2, "ram_available_mb": 109126.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [44.48, 44.48, 44.48, 44.48, 44.48, 45.62, 45.62, 45.62, 45.62, 45.62, 47.05, 47.05, 47.05, 47.05, 36.49, 36.49, 36.49, 36.49, 36.49, 34.79, 34.79], "power_watts_avg": 42.42, "power_watts_peak": 47.05, "energy_joules_est": 87.32, "sample_count": 21, "duration_seconds": 2.059}, "timestamp": "2026-01-12T10:28:55.977014"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1064.583, "latencies_ms": [1064.583], "images_per_second": 0.939, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " In a zoo enclosure, a large elephant is drinking water from a pool, with a log and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13380.2, "ram_available_mb": 109126.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.79, 34.79, 34.79, 40.13, 40.13, 40.13, 40.13, 40.13, 47.18, 47.18, 47.18], "power_watts_avg": 40.6, "power_watts_peak": 47.18, "energy_joules_est": 43.25, "sample_count": 11, "duration_seconds": 1.065}, "timestamp": "2026-01-12T10:28:57.088527"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 851.65, "latencies_ms": [851.65], "images_per_second": 1.174, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The elephant is gray, the water is blue, and the ground is brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13421.7, "ram_available_mb": 109084.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.18, 47.18, 43.31, 43.31, 43.31, 43.31, 43.31, 47.62, 47.62], "power_watts_avg": 45.13, "power_watts_peak": 47.62, "energy_joules_est": 38.45, "sample_count": 9, "duration_seconds": 0.852}, "timestamp": "2026-01-12T10:28:57.998952"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1234.577, "latencies_ms": [1234.577], "images_per_second": 0.81, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " Four people are standing on a snowy mountain, wearing ski gear and holding ski poles, with a clear blue sky and snow-covered mountains in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13421.7, "ram_available_mb": 109084.6, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13469.1, "ram_available_mb": 109037.2, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.62, 47.62, 47.62, 52.11, 52.11, 52.11, 52.11, 52.11, 47.2, 47.2, 47.2, 47.2, 47.2], "power_watts_avg": 49.18, "power_watts_peak": 52.11, "energy_joules_est": 60.75, "sample_count": 13, "duration_seconds": 1.235}, "timestamp": "2026-01-12T10:28:59.313426"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1974.048, "latencies_ms": [1974.048], "images_per_second": 0.507, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skis: 4\n2. ski poles: 4\n3. skiers: 4\n4. jackets: 4\n5. hats: 4\n6. goggles: 4\n7. gloves: 4\n8. snow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13469.1, "ram_available_mb": 109037.2, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13448.2, "ram_available_mb": 109058.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [42.44, 42.44, 42.44, 42.44, 42.44, 47.17, 47.17, 47.17, 47.17, 47.17, 47.4, 47.4, 47.4, 47.4, 47.4, 35.29, 35.29, 35.29, 35.29, 35.29], "power_watts_avg": 43.07, "power_watts_peak": 47.4, "energy_joules_est": 85.04, "sample_count": 20, "duration_seconds": 1.974}, "timestamp": "2026-01-12T10:29:01.328852"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1811.357, "latencies_ms": [1811.357], "images_per_second": 0.552, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The skiers are positioned in the foreground of the image, with the mountains in the background. The skier on the left is slightly closer to the camera than the skier in the middle, while the skier on the right is positioned farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13448.2, "ram_available_mb": 109058.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13431.7, "ram_available_mb": 109074.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [35.13, 35.13, 35.13, 35.13, 44.52, 44.52, 44.52, 44.52, 44.52, 46.53, 46.53, 46.53, 46.53, 46.53, 38.28, 38.28, 38.28, 38.28, 38.28], "power_watts_avg": 41.43, "power_watts_peak": 46.53, "energy_joules_est": 75.09, "sample_count": 19, "duration_seconds": 1.812}, "timestamp": "2026-01-12T10:29:03.293509"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 878.146, "latencies_ms": [878.146], "images_per_second": 1.139, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Four people are standing on a snowy mountain, wearing ski gear and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13423.8, "ram_available_mb": 109082.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13422.5, "ram_available_mb": 109083.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [34.07, 34.07, 34.07, 34.07, 34.07, 46.6, 46.6, 46.6, 46.6], "power_watts_avg": 39.64, "power_watts_peak": 46.6, "energy_joules_est": 34.82, "sample_count": 9, "duration_seconds": 0.878}, "timestamp": "2026-01-12T10:29:04.204262"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1876.317, "latencies_ms": [1876.317], "images_per_second": 0.533, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a group of four skiers standing on a snowy mountain, with the clear blue sky above them and the snow-covered mountains in the background. The skiers are wearing colorful ski gear, including jackets, pants, and helmets, and are holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13414.6, "ram_available_mb": 109091.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13318.4, "ram_available_mb": 109187.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.6, 45.55, 45.55, 45.55, 45.55, 45.55, 47.58, 47.58, 47.58, 47.58, 47.58, 49.41, 49.41, 49.41, 49.41, 49.41, 35.04, 35.04, 35.04], "power_watts_avg": 45.5, "power_watts_peak": 49.41, "energy_joules_est": 85.38, "sample_count": 19, "duration_seconds": 1.877}, "timestamp": "2026-01-12T10:29:06.118948"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1447.473, "latencies_ms": [1447.473], "images_per_second": 0.691, "prompt_tokens": 1100, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A person is holding a black smartphone in their hand, and the screen displays a photo of a tree with the time \"9:45\" and the date \"Mon, 11\".", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13318.4, "ram_available_mb": 109187.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.2, "ram_available_mb": 109156.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.04, 31.8, 31.8, 31.8, 31.8, 31.8, 46.56, 46.56, 46.56, 46.56, 46.56, 49.54, 49.54, 49.54, 49.54], "power_watts_avg": 41.67, "power_watts_peak": 49.54, "energy_joules_est": 60.36, "sample_count": 15, "duration_seconds": 1.449}, "timestamp": "2026-01-12T10:29:07.686007"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1908.246, "latencies_ms": [1908.246], "images_per_second": 0.524, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. hand: 1\n2. smartphone: 1\n3. keyboard: 1\n4. screen: 1\n5. finger: 1\n6. wrist: 1\n7. table: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.2, "ram_available_mb": 109156.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13352.5, "ram_available_mb": 109153.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.54, 32.66, 32.66, 32.66, 32.66, 32.66, 47.0, 47.0, 47.0, 47.0, 47.0, 49.1, 49.1, 49.1, 49.1, 49.1, 35.01, 35.01, 35.01], "power_watts_avg": 42.02, "power_watts_peak": 49.54, "energy_joules_est": 80.21, "sample_count": 19, "duration_seconds": 1.909}, "timestamp": "2026-01-12T10:29:09.604261"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1276.713, "latencies_ms": [1276.713], "images_per_second": 0.783, "prompt_tokens": 1118, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The smartphone is held in the left hand, with the screen facing the camera. The background is a wooden table, and the smartphone is positioned in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13344.6, "ram_available_mb": 109161.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.4, "ram_available_mb": 109147.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [35.01, 35.01, 32.97, 32.97, 32.97, 32.97, 32.97, 47.35, 47.35, 47.35, 47.35, 47.35, 49.39], "power_watts_avg": 40.08, "power_watts_peak": 49.39, "energy_joules_est": 51.18, "sample_count": 13, "duration_seconds": 1.277}, "timestamp": "2026-01-12T10:29:10.966353"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1005.241, "latencies_ms": [1005.241], "images_per_second": 0.995, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is holding a black smartphone in their hand, and the screen is displaying a picture of a tree.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13354.5, "ram_available_mb": 109151.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13368.5, "ram_available_mb": 109137.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.39, 49.39, 49.39, 41.72, 41.72, 41.72, 41.72, 41.72, 47.6, 47.6, 47.6], "power_watts_avg": 45.41, "power_watts_peak": 49.39, "energy_joules_est": 45.67, "sample_count": 11, "duration_seconds": 1.006}, "timestamp": "2026-01-12T10:29:12.078563"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 746.844, "latencies_ms": [746.844], "images_per_second": 1.339, "prompt_tokens": 1110, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The phone is black and the screen is reflecting a tree.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13360.7, "ram_available_mb": 109145.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13367.2, "ram_available_mb": 109139.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.6, 47.6, 42.05, 42.05, 42.05, 42.05, 42.05, 46.44], "power_watts_avg": 43.98, "power_watts_peak": 47.6, "energy_joules_est": 32.88, "sample_count": 8, "duration_seconds": 0.748}, "timestamp": "2026-01-12T10:29:12.889755"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1751.883, "latencies_ms": [1751.883], "images_per_second": 0.571, "prompt_tokens": 1432, "response_tokens_est": 44, "n_tiles": 1, "output_text": " A red and blue parking meter is on the sidewalk, with a sign that says \"DENVER'S HAD HOME\" and another sign that says \"CAMPAIGN TO END HOMELESSNESS.\"", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 13359.3, "ram_available_mb": 109147.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13283.8, "ram_available_mb": 109222.5, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.44, 46.44, 46.44, 46.44, 53.82, 53.82, 53.82, 53.82, 53.82, 51.14, 51.14, 51.14, 51.14, 51.14, 43.47, 43.47, 43.47, 43.47], "power_watts_avg": 49.14, "power_watts_peak": 53.82, "energy_joules_est": 86.09, "sample_count": 18, "duration_seconds": 1.752}, "timestamp": "2026-01-12T10:29:14.704291"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1457.646, "latencies_ms": [1457.646], "images_per_second": 0.686, "prompt_tokens": 1446, "response_tokens_est": 33, "n_tiles": 1, "output_text": " 1. parking meter\n2. sign\n3. fence\n4. bushes\n5. flowers\n6. trees\n7. sidewalk\n8. grass", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13283.8, "ram_available_mb": 109222.5, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13288.2, "ram_available_mb": 109218.1, "ram_percent": 10.8}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [43.47, 32.99, 32.99, 32.99, 32.99, 32.99, 50.08, 50.08, 50.08, 50.08, 50.08, 53.25, 53.25, 53.25, 53.25], "power_watts_avg": 44.79, "power_watts_peak": 53.25, "energy_joules_est": 65.29, "sample_count": 15, "duration_seconds": 1.458}, "timestamp": "2026-01-12T10:29:16.222214"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1574.485, "latencies_ms": [1574.485], "images_per_second": 0.635, "prompt_tokens": 1450, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The parking meter is located on the right side of the image, with a sign on the left side. The sign is positioned in the foreground, while the parking meter is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13288.2, "ram_available_mb": 109218.1, "ram_percent": 10.8}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13359.4, "ram_available_mb": 109146.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [53.25, 34.21, 34.21, 34.21, 34.21, 34.21, 50.14, 50.14, 50.14, 50.14, 50.14, 53.18, 53.18, 53.18, 53.18, 53.18], "power_watts_avg": 46.31, "power_watts_peak": 53.25, "energy_joules_est": 72.93, "sample_count": 16, "duration_seconds": 1.575}, "timestamp": "2026-01-12T10:29:17.835432"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1819.409, "latencies_ms": [1819.409], "images_per_second": 0.55, "prompt_tokens": 1444, "response_tokens_est": 47, "n_tiles": 1, "output_text": " A red and blue parking meter is on the side of the road, with a sign that says \"DENVER'S HAD HOME\" and a sign that says \"CAMPAIGN TO END HOMELESSNESS\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13359.4, "ram_available_mb": 109146.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13362.1, "ram_available_mb": 109144.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [36.24, 36.24, 36.24, 36.24, 36.24, 45.62, 45.62, 45.62, 45.62, 45.62, 51.74, 51.74, 51.74, 51.74, 51.74, 41.24, 41.24, 41.24, 41.24], "power_watts_avg": 43.84, "power_watts_peak": 51.74, "energy_joules_est": 79.78, "sample_count": 19, "duration_seconds": 1.82}, "timestamp": "2026-01-12T10:29:19.752794"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2102.301, "latencies_ms": [2102.301], "images_per_second": 0.476, "prompt_tokens": 1442, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a red and blue parking meter with a white sticker on it, standing on a sidewalk next to a metal fence. The parking meter is surrounded by green plants and flowers, and there is a sign nearby that reads \"CAMPAIGN TO END HOMELESSNESS\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.1, "ram_available_mb": 109144.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.1, "ram_available_mb": 109161.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.45, 33.45, 33.45, 33.45, 33.45, 44.86, 44.86, 44.86, 44.86, 44.86, 51.5, 51.5, 51.5, 51.5, 51.5, 39.76, 39.76, 39.76, 39.76, 39.76, 34.94], "power_watts_avg": 42.04, "power_watts_peak": 51.5, "energy_joules_est": 88.4, "sample_count": 21, "duration_seconds": 2.103}, "timestamp": "2026-01-12T10:29:21.921830"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1192.871, "latencies_ms": [1192.871], "images_per_second": 0.838, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " In the image, a group of zebras are grazing in a grassy field, their black and white stripes contrasting with the green and brown vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.2, "ram_available_mb": 109169.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13356.2, "ram_available_mb": 109150.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.94, 34.94, 34.94, 40.64, 40.64, 40.64, 40.64, 40.64, 47.17, 47.17, 47.17, 47.17], "power_watts_avg": 41.39, "power_watts_peak": 47.17, "energy_joules_est": 49.41, "sample_count": 12, "duration_seconds": 1.194}, "timestamp": "2026-01-12T10:29:23.187131"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1465.676, "latencies_ms": [1465.676], "images_per_second": 0.682, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " zebra: 1\ngrass: 1\ntrees: 1\ngrass: 1\ntrees: 1\ngrass: 1\ntrees: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.2, "ram_available_mb": 109154.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13350.9, "ram_available_mb": 109155.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [47.17, 39.94, 39.94, 39.94, 39.94, 39.94, 47.97, 47.97, 47.97, 47.97, 47.97, 50.0, 50.0, 50.0, 50.0], "power_watts_avg": 45.78, "power_watts_peak": 50.0, "energy_joules_est": 67.12, "sample_count": 15, "duration_seconds": 1.466}, "timestamp": "2026-01-12T10:29:24.699439"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1735.96, "latencies_ms": [1735.96], "images_per_second": 0.576, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the background featuring a mix of green and brown vegetation. The zebras are standing close to each other, with some of them grazing on the grass while others are facing different directions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.0, "ram_available_mb": 109163.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13351.0, "ram_available_mb": 109155.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [50.0, 33.14, 33.14, 33.14, 33.14, 33.14, 47.16, 47.16, 47.16, 47.16, 47.16, 49.06, 49.06, 49.06, 49.06, 49.06, 34.98, 34.98], "power_watts_avg": 42.6, "power_watts_peak": 50.0, "energy_joules_est": 73.98, "sample_count": 18, "duration_seconds": 1.737}, "timestamp": "2026-01-12T10:29:26.515791"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 966.345, "latencies_ms": [966.345], "images_per_second": 1.035, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of zebras are grazing in a grassy field, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.2, "ram_available_mb": 109163.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13366.9, "ram_available_mb": 109139.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.98, 34.98, 34.98, 39.09, 39.09, 39.09, 39.09, 39.09, 46.76, 46.76], "power_watts_avg": 39.4, "power_watts_peak": 46.76, "energy_joules_est": 38.09, "sample_count": 10, "duration_seconds": 0.967}, "timestamp": "2026-01-12T10:29:27.527832"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1673.129, "latencies_ms": [1673.129], "images_per_second": 0.598, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a group of zebras grazing in a grassy field with a clear blue sky overhead. The zebras are adorned with distinctive black and white stripes, which contrast sharply with the green grass and the brown trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.0, "ram_available_mb": 109143.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13353.4, "ram_available_mb": 109152.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [46.76, 46.76, 46.76, 47.83, 47.83, 47.83, 47.83, 47.83, 47.44, 47.44, 47.44, 47.44, 47.44, 43.13, 43.13, 43.13, 43.13], "power_watts_avg": 46.42, "power_watts_peak": 47.83, "energy_joules_est": 77.69, "sample_count": 17, "duration_seconds": 1.674}, "timestamp": "2026-01-12T10:29:29.247064"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 967.763, "latencies_ms": [967.763], "images_per_second": 1.033, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a black wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.8, "ram_available_mb": 109152.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.13, 33.7, 33.7, 33.7, 33.7, 33.7, 47.13, 47.13, 47.13, 47.13], "power_watts_avg": 40.01, "power_watts_peak": 47.13, "energy_joules_est": 38.75, "sample_count": 10, "duration_seconds": 0.968}, "timestamp": "2026-01-12T10:29:30.260686"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1971.61, "latencies_ms": [1971.61], "images_per_second": 0.507, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. surfboard: 1\n7. person: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13353.0, "ram_available_mb": 109153.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.13, 47.74, 47.74, 47.74, 47.74, 47.74, 47.44, 47.44, 47.44, 47.44, 47.44, 48.62, 48.62, 48.62, 48.62, 34.89, 34.89, 34.89, 34.89, 34.89], "power_watts_avg": 44.6, "power_watts_peak": 48.62, "energy_joules_est": 87.95, "sample_count": 20, "duration_seconds": 1.972}, "timestamp": "2026-01-12T10:29:32.281276"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1606.62, "latencies_ms": [1606.62], "images_per_second": 0.622, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave in the background. The surfer is riding the wave from left to right, with the wave's crest to the right of the surfer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13349.0, "ram_available_mb": 109157.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13358.5, "ram_available_mb": 109147.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_watts_samples": [34.18, 34.18, 34.18, 34.18, 34.18, 46.26, 46.26, 46.26, 46.26, 46.26, 47.22, 47.22, 47.22, 47.22, 47.22, 34.91], "power_watts_avg": 42.08, "power_watts_peak": 47.22, "energy_joules_est": 67.63, "sample_count": 16, "duration_seconds": 1.607}, "timestamp": "2026-01-12T10:29:33.948306"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 993.127, "latencies_ms": [993.127], "images_per_second": 1.007, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A surfer in a black wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.5, "ram_available_mb": 109147.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.91, 34.91, 34.91, 34.91, 43.1, 43.1, 43.1, 43.1, 43.1, 48.22], "power_watts_avg": 40.33, "power_watts_peak": 48.22, "energy_joules_est": 40.09, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-12T10:29:34.958774"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 989.95, "latencies_ms": [989.95], "images_per_second": 1.01, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The surfer is wearing a black wetsuit, and the wave is a greenish-blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.0, "ram_available_mb": 109170.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.3, "ram_available_mb": 109152.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [48.22, 48.22, 48.22, 48.22, 47.73, 47.73, 47.73, 47.73, 47.73, 48.03], "power_watts_avg": 47.95, "power_watts_peak": 48.22, "energy_joules_est": 47.49, "sample_count": 10, "duration_seconds": 0.99}, "timestamp": "2026-01-12T10:29:35.971576"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 956.301, "latencies_ms": [956.301], "images_per_second": 1.046, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain, one of them is holding a pair of skis.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.4, "ram_available_mb": 109159.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.9, "ram_available_mb": 109147.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.03, 48.03, 48.03, 48.08, 48.08, 48.08, 48.08, 48.08, 47.9, 47.9], "power_watts_avg": 48.03, "power_watts_peak": 48.08, "energy_joules_est": 45.94, "sample_count": 10, "duration_seconds": 0.957}, "timestamp": "2026-01-12T10:29:36.984326"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1985.632, "latencies_ms": [1985.632], "images_per_second": 0.504, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 2\n2. backpack: 1\n3. ski: 1\n4. snowboard: 1\n5. pole: 1\n6. snowboarder: 1\n7. mountain: 1\n8. sun: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.0, "ram_available_mb": 109155.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.9, 47.9, 47.9, 47.25, 47.25, 47.25, 47.25, 47.25, 47.51, 47.51, 47.51, 47.51, 47.51, 41.78, 41.78, 41.78, 41.78, 41.78, 35.09, 35.09], "power_watts_avg": 44.83, "power_watts_peak": 47.9, "energy_joules_est": 89.04, "sample_count": 20, "duration_seconds": 1.986}, "timestamp": "2026-01-12T10:29:39.004002"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2242.336, "latencies_ms": [2242.336], "images_per_second": 0.446, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The skier on the left is positioned closer to the camera, while the skier on the right is farther away. The skier on the left is also closer to the foreground, while the skier on the right is in the background. The skier on the left is also positioned to the left of the skier on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.09, 35.09, 35.09, 37.52, 37.52, 37.52, 37.52, 37.52, 46.82, 46.82, 46.82, 46.82, 46.82, 44.34, 44.34, 44.34, 44.34, 44.34, 35.16, 35.16, 35.16, 35.16, 35.16], "power_watts_avg": 40.19, "power_watts_peak": 46.82, "energy_joules_est": 90.16, "sample_count": 23, "duration_seconds": 2.243}, "timestamp": "2026-01-12T10:29:41.374323"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1015.805, "latencies_ms": [1015.805], "images_per_second": 0.984, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain at sunset, one of them is holding a pair of skis.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.1, "ram_available_mb": 109150.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13374.4, "ram_available_mb": 109131.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [35.17, 35.17, 35.17, 35.17, 42.43, 42.43, 42.43, 42.43, 42.43, 45.94, 45.94], "power_watts_avg": 40.43, "power_watts_peak": 45.94, "energy_joules_est": 41.1, "sample_count": 11, "duration_seconds": 1.017}, "timestamp": "2026-01-12T10:29:42.536572"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2030.09, "latencies_ms": [2030.09], "images_per_second": 0.493, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features two individuals dressed in white snow gear, with one of them holding a pair of skis. The sun is setting in the background, casting a warm glow on the scene. The sky is a clear blue, and the snow is pristine white, creating a serene and picturesque winter landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.5, "ram_available_mb": 109139.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13362.0, "ram_available_mb": 109144.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.94, 45.94, 45.94, 41.41, 41.41, 41.41, 41.41, 41.41, 46.42, 46.42, 46.42, 46.42, 46.42, 43.48, 43.48, 43.48, 43.48, 43.48, 34.83, 34.83, 34.83], "power_watts_avg": 42.8, "power_watts_peak": 46.42, "energy_joules_est": 86.91, "sample_count": 21, "duration_seconds": 2.03}, "timestamp": "2026-01-12T10:29:44.654713"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1878.932, "latencies_ms": [1878.932], "images_per_second": 0.532, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " A baseball player in a red shirt and white pants is swinging a bat at a ball, while a catcher in a black shirt and black pants is crouched behind him, and a umpire in a black shirt and black pants is standing behind the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.0, "ram_available_mb": 109144.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.83, 30.95, 30.95, 30.95, 30.95, 30.95, 45.45, 45.45, 45.45, 45.45, 45.45, 49.63, 49.63, 49.63, 49.63, 49.63, 34.97, 34.97, 34.97], "power_watts_avg": 40.52, "power_watts_peak": 49.63, "energy_joules_est": 76.18, "sample_count": 19, "duration_seconds": 1.88}, "timestamp": "2026-01-12T10:29:46.620140"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2085.206, "latencies_ms": [2085.206], "images_per_second": 0.48, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball glove: 1\n3. baseball: 1\n4. baseball player: 1\n5. catcher: 1\n6. umpire: 1\n7. fence: 1\n8. spectators: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.8, "ram_available_mb": 109153.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13372.3, "ram_available_mb": 109134.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 32.43, 32.43, 32.43, 32.43, 46.63, 46.63, 46.63, 46.63, 46.63, 49.65, 49.65, 49.65, 49.65, 49.65, 34.99, 34.99, 34.99, 34.99, 34.99], "power_watts_avg": 40.76, "power_watts_peak": 49.65, "energy_joules_est": 85.02, "sample_count": 21, "duration_seconds": 2.086}, "timestamp": "2026-01-12T10:29:48.786846"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1702.942, "latencies_ms": [1702.942], "images_per_second": 0.587, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire behind him. The ball is in the air, and the batter is ready to swing. The fence is in the background, separating the field from the spectators.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13372.3, "ram_available_mb": 109134.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.47, 34.47, 34.47, 34.47, 34.47, 46.33, 46.33, 46.33, 46.33, 46.33, 47.12, 47.12, 47.12, 47.12, 47.12, 35.61, 35.61], "power_watts_avg": 41.81, "power_watts_peak": 47.12, "energy_joules_est": 71.24, "sample_count": 17, "duration_seconds": 1.704}, "timestamp": "2026-01-12T10:29:50.549862"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1379.019, "latencies_ms": [1379.019], "images_per_second": 0.725, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A baseball game is taking place on a sunny day in a park. The batter is swinging at the ball, while the catcher and umpire are ready to catch it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.0, "ram_available_mb": 109142.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13317.5, "ram_available_mb": 109188.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.61, 35.61, 35.61, 39.15, 39.15, 39.15, 39.15, 39.15, 48.24, 48.24, 48.24, 48.24, 48.24, 44.79], "power_watts_avg": 42.04, "power_watts_peak": 48.24, "energy_joules_est": 57.99, "sample_count": 14, "duration_seconds": 1.379}, "timestamp": "2026-01-12T10:29:51.962119"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1737.718, "latencies_ms": [1737.718], "images_per_second": 0.575, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white and red uniforms, the sun casting a warm glow on the field, and the lush green trees in the background adding a touch of nature to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13317.5, "ram_available_mb": 109188.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.0, "ram_available_mb": 109141.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 58.0}, "power_stats": {"power_watts_samples": [44.79, 44.79, 44.79, 44.79, 42.49, 42.49, 42.49, 42.49, 42.49, 47.39, 47.39, 47.39, 47.39, 47.39, 40.03, 40.03, 40.03, 40.03], "power_watts_avg": 43.82, "power_watts_peak": 47.39, "energy_joules_est": 76.16, "sample_count": 18, "duration_seconds": 1.738}, "timestamp": "2026-01-12T10:29:53.778936"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1176.14, "latencies_ms": [1176.14], "images_per_second": 0.85, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A large glass milkshake with whipped cream and a straw sits on a table next to a slice of cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.9, "ram_available_mb": 109141.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13351.4, "ram_available_mb": 109154.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [33.65, 33.65, 33.65, 33.65, 33.65, 47.55, 47.55, 47.55, 47.55, 47.55, 52.2, 52.2], "power_watts_avg": 42.54, "power_watts_peak": 52.2, "energy_joules_est": 50.05, "sample_count": 12, "duration_seconds": 1.177}, "timestamp": "2026-01-12T10:29:54.995997"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2098.903, "latencies_ms": [2098.903], "images_per_second": 0.476, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. glass: 1\n2. cake: 1\n3. fork: 2\n4. knife: 1\n5. napkin: 1\n6. table: 1\n7. chair: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.5, "ram_available_mb": 109162.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13394.6, "ram_available_mb": 109111.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [52.2, 52.2, 52.2, 42.61, 42.61, 42.61, 42.61, 42.61, 51.45, 51.45, 51.45, 51.45, 51.45, 47.25, 47.25, 47.25, 47.25, 47.25, 35.1, 35.1, 35.1], "power_watts_avg": 46.12, "power_watts_peak": 52.2, "energy_joules_est": 96.82, "sample_count": 21, "duration_seconds": 2.1}, "timestamp": "2026-01-12T10:29:57.119252"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1295.129, "latencies_ms": [1295.129], "images_per_second": 0.772, "prompt_tokens": 1450, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The milkshake is to the left of the cake, the cake is in the foreground, and the person is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13386.7, "ram_available_mb": 109119.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13402.2, "ram_available_mb": 109104.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [35.1, 35.1, 31.81, 31.81, 31.81, 31.81, 31.81, 51.12, 51.12, 51.12, 51.12, 54.28, 54.28], "power_watts_avg": 41.71, "power_watts_peak": 54.28, "energy_joules_est": 54.04, "sample_count": 13, "duration_seconds": 1.296}, "timestamp": "2026-01-12T10:29:58.484057"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1127.993, "latencies_ms": [1127.993], "images_per_second": 0.887, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman is sitting at a table in a restaurant with a milkshake and a slice of cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13402.2, "ram_available_mb": 109104.1, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13382.4, "ram_available_mb": 109123.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [54.28, 54.28, 54.28, 40.07, 40.07, 40.07, 40.07, 40.07, 51.74, 51.74, 51.74, 51.74], "power_watts_avg": 47.51, "power_watts_peak": 54.28, "energy_joules_est": 53.6, "sample_count": 12, "duration_seconds": 1.128}, "timestamp": "2026-01-12T10:29:59.698329"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2098.352, "latencies_ms": [2098.352], "images_per_second": 0.477, "prompt_tokens": 1442, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere. The lighting is soft and natural, coming from the windows in the background. The colors in the image are vibrant and inviting, with the brown of the table and the white of the cake and napkins standing out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13382.4, "ram_available_mb": 109123.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13375.1, "ram_available_mb": 109131.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [51.74, 44.52, 44.52, 44.52, 44.52, 44.52, 50.84, 50.84, 50.84, 50.84, 50.84, 53.82, 53.82, 53.82, 53.82, 53.82, 35.51, 35.51, 35.51, 35.51, 35.51], "power_watts_avg": 46.44, "power_watts_peak": 53.82, "energy_joules_est": 97.47, "sample_count": 21, "duration_seconds": 2.099}, "timestamp": "2026-01-12T10:30:01.824085"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1316.778, "latencies_ms": [1316.778], "images_per_second": 0.759, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A large, multi-tiered wedding cake with blue and white decorations sits on a table in a room with a chandelier and other tables in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13375.1, "ram_available_mb": 109131.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13355.3, "ram_available_mb": 109151.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.2, 35.2, 35.2, 35.2, 35.2, 47.33, 47.33, 47.33, 47.33, 47.33, 47.58, 47.58, 47.58, 47.58], "power_watts_avg": 43.07, "power_watts_peak": 47.58, "energy_joules_est": 56.72, "sample_count": 14, "duration_seconds": 1.317}, "timestamp": "2026-01-12T10:30:03.238705"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1986.08, "latencies_ms": [1986.08], "images_per_second": 0.504, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. cake: 1\n2. tablecloth: 1\n3. flowers: 1\n4. table: 1\n5. chairs: 1\n6. chandelier: 1\n7. windows: 1\n8. people: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13351.3, "ram_available_mb": 109155.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13356.3, "ram_available_mb": 109150.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.58, 33.63, 33.63, 33.63, 33.63, 33.63, 46.67, 46.67, 46.67, 46.67, 46.67, 49.16, 49.16, 49.16, 49.16, 49.16, 35.08, 35.08, 35.08, 35.08], "power_watts_avg": 41.76, "power_watts_peak": 49.16, "energy_joules_est": 82.96, "sample_count": 20, "duration_seconds": 1.986}, "timestamp": "2026-01-12T10:30:05.254214"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1526.332, "latencies_ms": [1526.332], "images_per_second": 0.655, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The cake is positioned in the foreground, with the tablecloth and chairs in the background. The chandelier is located above the cake, while the people are seated at the tables in the far background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13348.4, "ram_available_mb": 109157.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.16, 34.16, 34.16, 34.16, 34.16, 46.77, 46.77, 46.77, 46.77, 46.77, 47.12, 47.12, 47.12, 47.12, 47.12, 34.8], "power_watts_avg": 42.19, "power_watts_peak": 47.12, "energy_joules_est": 64.41, "sample_count": 16, "duration_seconds": 1.527}, "timestamp": "2026-01-12T10:30:06.919565"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1259.355, "latencies_ms": [1259.355], "images_per_second": 0.794, "prompt_tokens": 1112, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A large, multi-tiered wedding cake sits on a table in a room with tables and chairs, and a chandelier hanging from the ceiling.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13356.5, "ram_available_mb": 109149.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [34.8, 34.8, 34.8, 34.8, 43.22, 43.22, 43.22, 43.22, 43.22, 46.72, 46.72, 46.72, 46.72], "power_watts_avg": 41.71, "power_watts_peak": 46.72, "energy_joules_est": 52.54, "sample_count": 13, "duration_seconds": 1.26}, "timestamp": "2026-01-12T10:30:08.231648"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 972.828, "latencies_ms": [972.828], "images_per_second": 1.028, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The cake is white and blue, with gold accents, and is lit by a chandelier.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.1, "ram_available_mb": 109141.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13413.7, "ram_available_mb": 109092.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [46.72, 36.49, 36.49, 36.49, 36.49, 36.49, 47.05, 47.05, 47.05, 47.05], "power_watts_avg": 41.74, "power_watts_peak": 47.05, "energy_joules_est": 40.63, "sample_count": 10, "duration_seconds": 0.974}, "timestamp": "2026-01-12T10:30:09.241076"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1204.153, "latencies_ms": [1204.153], "images_per_second": 0.83, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A woman wearing a blue sweater with red and white patterns is standing in a kitchen and holding a plate with a piece of food on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13413.7, "ram_available_mb": 109092.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13343.3, "ram_available_mb": 109163.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_watts_samples": [47.05, 47.11, 47.11, 47.11, 47.11, 47.11, 47.22, 47.22, 47.22, 47.22, 47.22, 48.8, 48.8], "power_watts_avg": 47.41, "power_watts_peak": 48.8, "energy_joules_est": 57.11, "sample_count": 13, "duration_seconds": 1.205}, "timestamp": "2026-01-12T10:30:10.554018"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2004.161, "latencies_ms": [2004.161], "images_per_second": 0.499, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. pot: 1\n3. plate: 1\n4. spoon: 1\n5. stove: 1\n6. wall: 1\n7. poster: 1\n8. wall-mounted shelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.3, "ram_available_mb": 109163.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13349.5, "ram_available_mb": 109156.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [48.8, 48.8, 48.8, 36.87, 36.87, 36.87, 36.87, 36.87, 46.05, 46.05, 46.05, 46.05, 46.05, 44.32, 44.32, 44.32, 44.32, 44.32, 34.84, 34.84], "power_watts_avg": 42.61, "power_watts_peak": 48.8, "energy_joules_est": 85.45, "sample_count": 20, "duration_seconds": 2.005}, "timestamp": "2026-01-12T10:30:12.571842"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1383.168, "latencies_ms": [1383.168], "images_per_second": 0.723, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, with the stove and pot in the middle ground. The poster is in the background, and the wall is behind the person.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13341.6, "ram_available_mb": 109164.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13350.4, "ram_available_mb": 109155.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.84, 34.84, 34.91, 34.91, 34.91, 34.91, 34.91, 47.32, 47.32, 47.32, 47.32, 47.32, 47.29, 47.29], "power_watts_avg": 41.1, "power_watts_peak": 47.32, "energy_joules_est": 56.87, "sample_count": 14, "duration_seconds": 1.384}, "timestamp": "2026-01-12T10:30:14.035495"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 910.793, "latencies_ms": [910.793], "images_per_second": 1.098, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman wearing a sweater is standing in a kitchen and holding a plate of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.5, "ram_available_mb": 109163.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [47.29, 47.29, 47.29, 39.26, 39.26, 39.26, 39.26, 39.26, 47.57, 47.57], "power_watts_avg": 43.33, "power_watts_peak": 47.57, "energy_joules_est": 39.47, "sample_count": 10, "duration_seconds": 0.911}, "timestamp": "2026-01-12T10:30:15.048453"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1362.359, "latencies_ms": [1362.359], "images_per_second": 0.734, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a kitchen with a warm and cozy atmosphere. The lighting is natural, coming from the window in the background, and the colors are vibrant and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13363.0, "ram_available_mb": 109143.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13371.7, "ram_available_mb": 109134.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [47.57, 47.57, 47.57, 45.57, 45.57, 45.57, 45.57, 45.57, 46.21, 46.21, 46.21, 46.21, 46.21, 44.95], "power_watts_avg": 46.18, "power_watts_peak": 47.57, "energy_joules_est": 62.95, "sample_count": 14, "duration_seconds": 1.363}, "timestamp": "2026-01-12T10:30:16.465009"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1093.796, "latencies_ms": [1093.796], "images_per_second": 0.914, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A woman wearing a pink shirt and black pants is holding a rope and walking next to a white horse in a dirt area.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13363.8, "ram_available_mb": 109142.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13376.7, "ram_available_mb": 109129.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [44.95, 44.95, 44.95, 44.95, 41.75, 41.75, 41.75, 41.75, 41.75, 47.15, 47.15], "power_watts_avg": 43.89, "power_watts_peak": 47.15, "energy_joules_est": 48.04, "sample_count": 11, "duration_seconds": 1.094}, "timestamp": "2026-01-12T10:30:17.581063"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1944.872, "latencies_ms": [1944.872], "images_per_second": 0.514, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. horse: 1\n3. rope: 1\n4. fence: 1\n5. boots: 1\n6. shirt: 1\n7. pants: 1\n8. leash: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.7, "ram_available_mb": 109129.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 2.0, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.15, 47.15, 42.66, 42.66, 42.66, 42.66, 42.66, 47.94, 47.94, 47.94, 47.94, 47.94, 45.68, 45.68, 45.68, 45.68, 45.68, 35.03, 35.03, 35.03], "power_watts_avg": 44.04, "power_watts_peak": 47.94, "energy_joules_est": 85.69, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T10:30:19.594443"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1433.218, "latencies_ms": [1433.218], "images_per_second": 0.698, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the horse in the background. The horse is positioned to the left of the woman, and the fence is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13355.6, "ram_available_mb": 109150.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13365.4, "ram_available_mb": 109140.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 32.86, 32.86, 32.86, 32.86, 32.86, 46.08, 46.08, 46.08, 46.08, 46.08, 49.01, 49.01, 49.01], "power_watts_avg": 40.79, "power_watts_peak": 49.01, "energy_joules_est": 58.49, "sample_count": 15, "duration_seconds": 1.434}, "timestamp": "2026-01-12T10:30:21.158824"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 907.563, "latencies_ms": [907.563], "images_per_second": 1.102, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a pink shirt and black pants is walking a horse in a dirt field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.5, "ram_available_mb": 109148.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13374.9, "ram_available_mb": 109131.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.01, 49.01, 33.06, 33.06, 33.06, 33.06, 33.06, 46.68, 46.68, 46.68], "power_watts_avg": 40.34, "power_watts_peak": 49.01, "energy_joules_est": 36.62, "sample_count": 10, "duration_seconds": 0.908}, "timestamp": "2026-01-12T10:30:22.171025"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1725.816, "latencies_ms": [1725.816], "images_per_second": 0.579, "prompt_tokens": 1110, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a woman in a pink shirt and black pants, with a white horse in the background. The lighting is natural and bright, suggesting it is daytime. The woman is holding a rope, which is likely used for controlling the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13367.0, "ram_available_mb": 109139.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13376.1, "ram_available_mb": 109130.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.68, 46.68, 46.72, 46.72, 46.72, 46.72, 46.72, 46.25, 46.25, 46.25, 46.25, 46.25, 49.28, 49.28, 49.28, 49.28, 49.28, 34.97], "power_watts_avg": 46.65, "power_watts_peak": 49.28, "energy_joules_est": 80.53, "sample_count": 18, "duration_seconds": 1.726}, "timestamp": "2026-01-12T10:30:23.986507"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1805.866, "latencies_ms": [1805.866], "images_per_second": 0.554, "prompt_tokens": 1100, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a bustling city street with a mix of vehicles and pedestrians, including a prominent yellow traffic sign with a camera icon, a sign indicating a 7AM-7PM parking time, and a street sign with a \"No Parking\" sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13376.1, "ram_available_mb": 109130.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.8, "ram_available_mb": 109145.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [34.97, 34.97, 34.97, 40.25, 40.25, 40.25, 40.25, 40.25, 46.36, 46.36, 46.36, 46.36, 46.36, 42.16, 42.16, 42.16, 42.16, 42.16], "power_watts_avg": 41.6, "power_watts_peak": 46.36, "energy_joules_est": 75.15, "sample_count": 18, "duration_seconds": 1.807}, "timestamp": "2026-01-12T10:30:25.799835"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1945.849, "latencies_ms": [1945.849], "images_per_second": 0.514, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 2\n2. car: 3\n3. building: 2\n4. tree: 2\n5. street: 1\n6. traffic light: 1\n7. person: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13360.8, "ram_available_mb": 109145.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13341.8, "ram_available_mb": 109164.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.03, 35.03, 35.03, 35.03, 35.03, 48.39, 48.39, 48.39, 48.39, 48.39, 48.28, 48.28, 48.28, 48.28, 48.28, 34.91, 34.91, 34.91, 34.91, 34.91], "power_watts_avg": 41.65, "power_watts_peak": 48.39, "energy_joules_est": 81.06, "sample_count": 20, "duration_seconds": 1.946}, "timestamp": "2026-01-12T10:30:27.810608"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1973.09, "latencies_ms": [1973.09], "images_per_second": 0.507, "prompt_tokens": 1118, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The main objects are positioned in a way that the street sign is on the left side of the image, the traffic light is on the right side, and the buildings are in the background. The street sign is closer to the viewer than the traffic light, and the buildings are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13332.9, "ram_available_mb": 109173.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13345.1, "ram_available_mb": 109161.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.48, 34.48, 34.48, 34.48, 34.48, 44.86, 44.86, 44.86, 44.86, 44.86, 45.94, 45.94, 45.94, 45.94, 45.94, 35.89, 35.89, 35.89, 35.89, 35.89], "power_watts_avg": 40.29, "power_watts_peak": 45.94, "energy_joules_est": 79.53, "sample_count": 20, "duration_seconds": 1.974}, "timestamp": "2026-01-12T10:30:29.880324"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1398.912, "latencies_ms": [1398.912], "images_per_second": 0.715, "prompt_tokens": 1112, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a bustling city street during the day, with cars and buses navigating through the traffic. The skyline of tall buildings looms in the background, suggesting a metropolitan area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.7, "ram_available_mb": 109163.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [34.92, 34.92, 34.92, 34.92, 34.92, 45.63, 45.63, 45.63, 45.63, 47.26, 47.26, 47.26, 47.26, 47.26], "power_watts_avg": 42.39, "power_watts_peak": 47.26, "energy_joules_est": 59.31, "sample_count": 14, "duration_seconds": 1.399}, "timestamp": "2026-01-12T10:30:31.296270"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1978.221, "latencies_ms": [1978.221], "images_per_second": 0.506, "prompt_tokens": 1110, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a city street with a mix of modern and older buildings, and the sky is overcast with a grayish hue. The street is lined with trees and there are several traffic signs visible, including a yellow one with a camera symbol and a white one with a bicycle symbol.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.6, "ram_available_mb": 109155.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13334.1, "ram_available_mb": 109172.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [36.35, 36.35, 36.35, 36.35, 36.35, 47.68, 47.68, 47.68, 47.68, 47.68, 47.58, 47.58, 47.58, 47.58, 47.58, 34.83, 34.83, 34.83, 34.83, 34.83], "power_watts_avg": 41.61, "power_watts_peak": 47.68, "energy_joules_est": 82.34, "sample_count": 20, "duration_seconds": 1.979}, "timestamp": "2026-01-12T10:30:33.315010"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 900.076, "latencies_ms": [900.076], "images_per_second": 1.111, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A person is standing in a bathroom with a stainless steel toilet and a blue toilet brush.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.1, "ram_available_mb": 109176.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.9, "ram_available_mb": 109148.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 91.0}, "power_stats": {"power_watts_samples": [34.88, 34.88, 34.88, 34.88, 34.88, 47.6, 47.6, 47.6, 47.6], "power_watts_avg": 40.54, "power_watts_peak": 47.6, "energy_joules_est": 36.49, "sample_count": 9, "duration_seconds": 0.9}, "timestamp": "2026-01-12T10:30:34.225242"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 852.279, "latencies_ms": [852.279], "images_per_second": 1.173, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " toilet: 1\ntoilet brush: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13350.0, "ram_available_mb": 109156.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13361.6, "ram_available_mb": 109144.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.6, 46.48, 46.48, 46.48, 46.48, 46.48, 48.38, 48.38, 48.38], "power_watts_avg": 47.24, "power_watts_peak": 48.38, "energy_joules_est": 40.28, "sample_count": 9, "duration_seconds": 0.853}, "timestamp": "2026-01-12T10:30:35.136981"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1565.812, "latencies_ms": [1565.812], "images_per_second": 0.639, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The toilet is located in the center of the image, with the person's feet visible in the foreground. The blue brush is placed to the left of the toilet, while the metal bars are located to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.7, "ram_available_mb": 109152.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13356.0, "ram_available_mb": 109150.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [48.38, 48.38, 48.35, 48.35, 48.35, 48.35, 48.35, 47.26, 47.26, 47.26, 47.26, 47.26, 47.83, 47.83, 47.83, 47.83], "power_watts_avg": 47.88, "power_watts_peak": 48.38, "energy_joules_est": 75.0, "sample_count": 16, "duration_seconds": 1.566}, "timestamp": "2026-01-12T10:30:36.753153"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 824.596, "latencies_ms": [824.596], "images_per_second": 1.213, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is standing in a bathroom with a toilet and a blue brush.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13352.0, "ram_available_mb": 109154.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13342.4, "ram_available_mb": 109163.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 59.0}, "power_stats": {"power_watts_samples": [47.83, 33.63, 33.63, 33.63, 33.63, 33.63, 47.45, 47.45, 47.45], "power_watts_avg": 39.82, "power_watts_peak": 47.83, "energy_joules_est": 32.86, "sample_count": 9, "duration_seconds": 0.825}, "timestamp": "2026-01-12T10:30:37.663913"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 912.436, "latencies_ms": [912.436], "images_per_second": 1.096, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The bathroom is well-lit with natural light, and the floor is made of tiles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.4, "ram_available_mb": 109163.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.2, "ram_used_mb": 13435.0, "ram_available_mb": 109071.3, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [47.45, 47.45, 46.11, 46.11, 46.11, 46.11, 46.11, 46.61, 46.61, 46.61], "power_watts_avg": 46.53, "power_watts_peak": 47.45, "energy_joules_est": 42.49, "sample_count": 10, "duration_seconds": 0.913}, "timestamp": "2026-01-12T10:30:38.675470"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 993.417, "latencies_ms": [993.417], "images_per_second": 1.007, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A pink bicycle is parked in a store with other bicycles, and a woman is walking in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13435.0, "ram_available_mb": 109071.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13427.2, "ram_available_mb": 109079.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [46.61, 46.61, 45.78, 45.78, 45.78, 45.78, 45.78, 46.15, 46.15, 46.15], "power_watts_avg": 46.06, "power_watts_peak": 46.61, "energy_joules_est": 45.76, "sample_count": 10, "duration_seconds": 0.994}, "timestamp": "2026-01-12T10:30:39.691082"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1912.421, "latencies_ms": [1912.421], "images_per_second": 0.523, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bicycle: 1\n2. wall: 1\n3. floor: 1\n4. bicycle: 1\n5. bicycle: 1\n6. bicycle: 1\n7. bicycle: 1\n8. bicycle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.2, "ram_available_mb": 109079.1, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [46.15, 47.54, 47.54, 47.54, 47.54, 47.54, 47.88, 47.88, 47.88, 47.88, 47.88, 49.97, 49.97, 49.97, 49.97, 49.97, 35.0, 35.0, 35.0, 35.0], "power_watts_avg": 45.66, "power_watts_peak": 49.97, "energy_joules_est": 87.34, "sample_count": 20, "duration_seconds": 1.913}, "timestamp": "2026-01-12T10:30:41.707054"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1543.184, "latencies_ms": [1543.184], "images_per_second": 0.648, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The pink bicycle is positioned in the foreground, with the other bicycles in the background. The pink bicycle is to the left of the other bicycles, and the other bicycles are to the right of the pink bicycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13355.8, "ram_available_mb": 109150.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.0, 31.79, 31.79, 31.79, 31.79, 31.79, 45.24, 45.24, 45.24, 45.24, 45.24, 48.67, 48.67, 48.67, 48.67, 48.67], "power_watts_avg": 41.47, "power_watts_peak": 48.67, "energy_joules_est": 64.03, "sample_count": 16, "duration_seconds": 1.544}, "timestamp": "2026-01-12T10:30:43.371200"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1860.682, "latencies_ms": [1860.682], "images_per_second": 0.537, "prompt_tokens": 1112, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a quaint bicycle shop with a variety of bicycles on display. The shop is adorned with a pink bicycle, which stands out against the backdrop of other bicycles. The shop's interior is visible through the open door, revealing a glimpse of the bustling street outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13427.5, "ram_available_mb": 109078.8, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13470.8, "ram_available_mb": 109035.6, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.06, 35.06, 35.06, 35.06, 35.06, 45.78, 45.78, 45.78, 45.78, 45.78, 47.1, 47.1, 47.1, 47.1, 47.1, 36.98, 36.98, 36.98, 36.98], "power_watts_avg": 41.45, "power_watts_peak": 47.1, "energy_joules_est": 77.14, "sample_count": 19, "duration_seconds": 1.861}, "timestamp": "2026-01-12T10:30:45.286878"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1619.457, "latencies_ms": [1619.457], "images_per_second": 0.617, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a collection of bicycles, with a prominent pink bicycle in the foreground, and a variety of colors and materials, including wood and metal. The lighting is bright and natural, coming from the window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13462.9, "ram_available_mb": 109043.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13460.9, "ram_available_mb": 109045.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.11, 34.11, 34.11, 34.11, 34.11, 46.37, 46.37, 46.37, 46.37, 46.37, 46.5, 46.5, 46.5, 46.5, 46.5, 35.48, 35.48], "power_watts_avg": 41.52, "power_watts_peak": 46.5, "energy_joules_est": 67.29, "sample_count": 17, "duration_seconds": 1.62}, "timestamp": "2026-01-12T10:30:47.051244"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 831.718, "latencies_ms": [831.718], "images_per_second": 1.202, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A giraffe stands in a dry savanna with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13453.0, "ram_available_mb": 109053.3, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13371.5, "ram_available_mb": 109134.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [35.48, 35.48, 35.48, 37.21, 37.21, 37.21, 37.21, 37.21, 46.44], "power_watts_avg": 37.66, "power_watts_peak": 46.44, "energy_joules_est": 31.35, "sample_count": 9, "duration_seconds": 0.832}, "timestamp": "2026-01-12T10:30:47.960422"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1349.348, "latencies_ms": [1349.348], "images_per_second": 0.741, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " giraffe: 1, tree: 2, bush: 1, sky: 1, grass: 1, cloud: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13371.5, "ram_available_mb": 109134.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13370.3, "ram_available_mb": 109136.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.44, 46.44, 46.44, 46.44, 50.83, 50.83, 50.83, 50.83, 50.83, 46.48, 46.48, 46.48, 46.48, 46.48], "power_watts_avg": 48.02, "power_watts_peak": 50.83, "energy_joules_est": 64.81, "sample_count": 14, "duration_seconds": 1.35}, "timestamp": "2026-01-12T10:30:49.370594"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1654.945, "latencies_ms": [1654.945], "images_per_second": 0.604, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The giraffe is positioned in the foreground of the image, with the background consisting of a grassy field and trees. The giraffe is facing towards the right side of the image, with its body oriented towards the left side of the frame.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13370.3, "ram_available_mb": 109136.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13401.0, "ram_available_mb": 109105.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [40.05, 40.05, 40.05, 40.05, 40.05, 45.49, 45.49, 45.49, 45.49, 45.49, 46.89, 46.89, 46.89, 46.89, 46.89, 35.36, 35.36], "power_watts_avg": 43.11, "power_watts_peak": 46.89, "energy_joules_est": 71.37, "sample_count": 17, "duration_seconds": 1.655}, "timestamp": "2026-01-12T10:30:51.088099"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1255.869, "latencies_ms": [1255.869], "images_per_second": 0.796, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A giraffe stands in a dry savanna, surrounded by trees and bushes. The giraffe is tall and has a long neck, with a brown and white coat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.0, "ram_available_mb": 109105.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13405.6, "ram_available_mb": 109100.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [35.36, 35.36, 35.36, 36.23, 36.23, 36.23, 36.23, 46.93, 46.93, 46.93, 46.93, 46.93, 45.79], "power_watts_avg": 40.88, "power_watts_peak": 46.93, "energy_joules_est": 51.37, "sample_count": 13, "duration_seconds": 1.256}, "timestamp": "2026-01-12T10:30:52.403548"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1044.242, "latencies_ms": [1044.242], "images_per_second": 0.958, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The giraffe is brown and white with a long neck and legs. The sky is cloudy and the grass is dry.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13401.7, "ram_available_mb": 109104.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13407.0, "ram_available_mb": 109099.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [45.79, 45.79, 45.79, 45.79, 44.32, 44.32, 44.32, 44.32, 44.32, 46.94, 46.94], "power_watts_avg": 45.33, "power_watts_peak": 46.94, "energy_joules_est": 47.35, "sample_count": 11, "duration_seconds": 1.045}, "timestamp": "2026-01-12T10:30:53.516858"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1197.96, "latencies_ms": [1197.96], "images_per_second": 0.835, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A young girl with red hair and a little girl with blonde hair are sitting on a luggage cart filled with suitcases in a parking lot.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13399.1, "ram_available_mb": 109107.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13407.1, "ram_available_mb": 109099.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [46.94, 46.94, 46.94, 42.73, 42.73, 42.73, 42.73, 42.73, 46.84, 46.84, 46.84, 46.84], "power_watts_avg": 45.15, "power_watts_peak": 46.94, "energy_joules_est": 54.12, "sample_count": 12, "duration_seconds": 1.199}, "timestamp": "2026-01-12T10:30:54.732080"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1976.745, "latencies_ms": [1976.745], "images_per_second": 0.506, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. car: 2\n2. luggage: 3\n3. suitcase: 1\n4. child: 2\n5. woman: 1\n6. sign: 1\n7. license plate: 1\n8. mirror: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.3, "ram_available_mb": 109107.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13321.6, "ram_available_mb": 109184.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.84, 41.31, 41.31, 41.31, 41.31, 41.31, 47.86, 47.86, 47.86, 47.86, 47.86, 49.48, 49.48, 49.48, 49.48, 49.48, 34.9, 34.9, 34.9, 34.9], "power_watts_avg": 43.98, "power_watts_peak": 49.48, "energy_joules_est": 86.97, "sample_count": 20, "duration_seconds": 1.977}, "timestamp": "2026-01-12T10:30:56.751779"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1547.914, "latencies_ms": [1547.914], "images_per_second": 0.646, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The luggage is positioned in the foreground, with the children sitting on it. The luggage is located to the left of the children, and the children are sitting on the luggage, which is in front of them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13321.6, "ram_available_mb": 109184.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13361.3, "ram_available_mb": 109145.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [33.34, 33.34, 33.34, 33.34, 33.34, 46.55, 46.55, 46.55, 46.55, 46.55, 48.21, 48.21, 48.21, 48.21, 48.21, 34.95], "power_watts_avg": 42.21, "power_watts_peak": 48.21, "energy_joules_est": 65.39, "sample_count": 16, "duration_seconds": 1.549}, "timestamp": "2026-01-12T10:30:58.420693"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 887.355, "latencies_ms": [887.355], "images_per_second": 1.127, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young girl with red hair is sitting on a luggage cart in a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.4, "ram_available_mb": 109152.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13369.3, "ram_available_mb": 109137.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [34.95, 34.95, 34.95, 34.95, 44.21, 44.21, 44.21, 44.21, 44.21], "power_watts_avg": 40.09, "power_watts_peak": 44.21, "energy_joules_est": 35.59, "sample_count": 9, "duration_seconds": 0.888}, "timestamp": "2026-01-12T10:30:59.331814"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1337.496, "latencies_ms": [1337.496], "images_per_second": 0.748, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken on a rainy day, with the wet pavement reflecting the blue sky. The car's exterior is a dark blue color, and the luggage is black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13365.3, "ram_available_mb": 109141.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13357.3, "ram_available_mb": 109149.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [46.79, 46.79, 46.79, 46.79, 46.79, 51.07, 51.07, 51.07, 51.07, 51.07, 47.65, 47.65, 47.65, 47.65], "power_watts_avg": 48.57, "power_watts_peak": 51.07, "energy_joules_est": 64.97, "sample_count": 14, "duration_seconds": 1.338}, "timestamp": "2026-01-12T10:31:00.748027"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 964.578, "latencies_ms": [964.578], "images_per_second": 1.037, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A yellow and blue bus is driving down a street in a town with a mountain in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13357.3, "ram_available_mb": 109149.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13364.6, "ram_available_mb": 109141.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 32.0}, "power_stats": {"power_watts_samples": [47.65, 32.59, 32.59, 32.59, 32.59, 32.59, 46.61, 46.61, 46.61, 46.61], "power_watts_avg": 39.71, "power_watts_peak": 47.65, "energy_joules_est": 38.32, "sample_count": 10, "duration_seconds": 0.965}, "timestamp": "2026-01-12T10:31:01.760799"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1978.124, "latencies_ms": [1978.124], "images_per_second": 0.506, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bus: 1\n2. street lamp: 1\n3. building: 1\n4. tree: 1\n5. flower bed: 1\n6. bench: 1\n7. car: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13364.6, "ram_available_mb": 109141.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_watts_samples": [46.61, 47.07, 47.07, 47.07, 47.07, 47.07, 47.49, 47.49, 47.49, 47.49, 47.49, 48.89, 48.89, 48.89, 48.89, 48.89, 34.74, 34.74, 34.74, 34.74], "power_watts_avg": 45.14, "power_watts_peak": 48.89, "energy_joules_est": 89.31, "sample_count": 20, "duration_seconds": 1.978}, "timestamp": "2026-01-12T10:31:03.780926"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1996.393, "latencies_ms": [1996.393], "images_per_second": 0.501, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The yellow and blue bus is parked on the left side of the street, while the white van is driving on the right side. The bus is closer to the camera than the van, and the van is further away. The bus is in the foreground, while the van is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13356.5, "ram_available_mb": 109149.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13360.5, "ram_available_mb": 109145.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [33.82, 33.82, 33.82, 33.82, 33.82, 46.48, 46.48, 46.48, 46.48, 46.48, 47.53, 47.53, 47.53, 47.53, 47.53, 35.0, 35.0, 35.0, 35.0, 35.0], "power_watts_avg": 40.71, "power_watts_peak": 47.53, "energy_joules_est": 81.31, "sample_count": 20, "duration_seconds": 1.997}, "timestamp": "2026-01-12T10:31:05.850514"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1039.956, "latencies_ms": [1039.956], "images_per_second": 0.962, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A yellow and blue bus drives down a street in a small town, passing by a row of shops and houses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13352.7, "ram_available_mb": 109153.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13376.4, "ram_available_mb": 109129.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.98, 34.98, 34.98, 34.98, 45.62, 45.62, 45.62, 45.62, 45.62, 46.84, 46.84], "power_watts_avg": 41.97, "power_watts_peak": 46.84, "energy_joules_est": 43.68, "sample_count": 11, "duration_seconds": 1.041}, "timestamp": "2026-01-12T10:31:07.011037"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1440.291, "latencies_ms": [1440.291], "images_per_second": 0.694, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a vibrant yellow and blue bus driving down a street, with a clear blue sky overhead. The bus is surrounded by lush green grass and colorful flowers, creating a picturesque scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13368.5, "ram_available_mb": 109137.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13362.7, "ram_available_mb": 109143.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.84, 46.84, 46.84, 43.02, 43.02, 43.02, 43.02, 43.02, 46.75, 46.75, 46.75, 46.75, 46.75, 41.24, 41.24], "power_watts_avg": 44.79, "power_watts_peak": 46.84, "energy_joules_est": 64.52, "sample_count": 15, "duration_seconds": 1.441}, "timestamp": "2026-01-12T10:31:08.525229"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1134.336, "latencies_ms": [1134.336], "images_per_second": 0.882, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A bird stands on a rock in the foreground of a beach, with the ocean and mountains in the background under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13370.3, "ram_available_mb": 109136.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13340.7, "ram_available_mb": 109165.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [41.24, 41.24, 41.24, 39.43, 39.43, 39.43, 39.43, 39.43, 46.8, 46.8, 46.8, 46.8], "power_watts_avg": 42.34, "power_watts_peak": 46.8, "energy_joules_est": 48.06, "sample_count": 12, "duration_seconds": 1.135}, "timestamp": "2026-01-12T10:31:09.738718"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1952.781, "latencies_ms": [1952.781], "images_per_second": 0.512, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 1\n2. rocks: 1\n3. beach: 1\n4. water: 1\n5. mountains: 1\n6. trees: 1\n7. pier: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13340.7, "ram_available_mb": 109165.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13343.5, "ram_available_mb": 109162.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.8, 40.42, 40.42, 40.42, 40.42, 40.42, 46.22, 46.22, 46.22, 46.22, 46.22, 48.7, 48.7, 48.7, 48.7, 48.7, 34.73, 34.73, 34.73, 34.73], "power_watts_avg": 43.12, "power_watts_peak": 48.7, "energy_joules_est": 84.23, "sample_count": 20, "duration_seconds": 1.953}, "timestamp": "2026-01-12T10:31:11.754741"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1311.847, "latencies_ms": [1311.847], "images_per_second": 0.762, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bird is in the foreground, standing on a rock in the middle of the image. The beach is in the background, with the ocean and mountains beyond it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.5, "ram_available_mb": 109162.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13348.1, "ram_available_mb": 109158.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [32.96, 32.96, 32.96, 32.96, 32.96, 45.79, 45.79, 45.79, 45.79, 45.79, 47.91, 47.91, 47.91, 47.91], "power_watts_avg": 41.81, "power_watts_peak": 47.91, "energy_joules_est": 54.88, "sample_count": 14, "duration_seconds": 1.312}, "timestamp": "2026-01-12T10:31:13.220430"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 859.25, "latencies_ms": [859.25], "images_per_second": 1.164, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird stands on a rock by the sea, with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.1, "ram_available_mb": 109162.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.2, "ram_available_mb": 109153.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [47.91, 31.65, 31.65, 31.65, 31.65, 31.65, 46.05, 46.05, 46.05], "power_watts_avg": 38.25, "power_watts_peak": 47.91, "energy_joules_est": 32.89, "sample_count": 9, "duration_seconds": 0.86}, "timestamp": "2026-01-12T10:31:14.132451"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1051.159, "latencies_ms": [1051.159], "images_per_second": 0.951, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image features a beach with a bird perched on a rock, the sky is cloudy and the water is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13345.4, "ram_available_mb": 109160.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13361.5, "ram_available_mb": 109144.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.05, 46.05, 49.27, 49.27, 49.27, 49.27, 49.27, 47.26, 47.26, 47.26, 47.26], "power_watts_avg": 47.95, "power_watts_peak": 49.27, "energy_joules_est": 50.43, "sample_count": 11, "duration_seconds": 1.052}, "timestamp": "2026-01-12T10:31:15.245597"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1066.846, "latencies_ms": [1066.846], "images_per_second": 0.937, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing glasses and a black shirt is sitting in a chair and holding a brown paper bag and a blue pen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13357.5, "ram_available_mb": 109148.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [47.26, 44.9, 44.9, 44.9, 44.9, 44.9, 47.01, 47.01, 47.01, 47.01, 47.01], "power_watts_avg": 46.07, "power_watts_peak": 47.26, "energy_joules_est": 49.18, "sample_count": 11, "duration_seconds": 1.067}, "timestamp": "2026-01-12T10:31:16.360124"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1933.068, "latencies_ms": [1933.068], "images_per_second": 0.517, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. chair: 1\n3. remote control: 1\n4. bag: 1\n5. glasses: 1\n6. tv: 1\n7. wall: 1\n8. cord: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13425.3, "ram_available_mb": 109081.0, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [49.21, 49.21, 49.21, 49.21, 49.21, 47.53, 47.53, 47.53, 47.53, 47.53, 47.72, 47.72, 47.72, 47.72, 47.72, 35.59, 35.59, 35.59, 35.59, 35.59], "power_watts_avg": 45.01, "power_watts_peak": 49.21, "energy_joules_est": 87.02, "sample_count": 20, "duration_seconds": 1.933}, "timestamp": "2026-01-12T10:31:18.374368"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1441.362, "latencies_ms": [1441.362], "images_per_second": 0.694, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the left side of the couch, with the remote control on the right side. The bag is in front of the man, and the remote control is behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13425.3, "ram_available_mb": 109081.0, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.8, "ram_used_mb": 13417.8, "ram_available_mb": 109088.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.93, 34.93, 34.93, 34.93, 43.09, 43.09, 43.09, 43.09, 43.09, 45.84, 45.84, 45.84, 45.84, 45.84, 38.23], "power_watts_avg": 41.5, "power_watts_peak": 45.84, "energy_joules_est": 59.85, "sample_count": 15, "duration_seconds": 1.442}, "timestamp": "2026-01-12T10:31:19.936238"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 962.646, "latencies_ms": [962.646], "images_per_second": 1.039, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing glasses and a black shirt is sitting in a chair and holding a bag of chips.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13417.8, "ram_available_mb": 109088.5, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13394.6, "ram_available_mb": 109111.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [38.23, 38.23, 38.23, 38.23, 43.49, 43.49, 43.49, 43.49, 43.49, 47.0], "power_watts_avg": 41.74, "power_watts_peak": 47.0, "energy_joules_est": 40.2, "sample_count": 10, "duration_seconds": 0.963}, "timestamp": "2026-01-12T10:31:20.943281"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1042.588, "latencies_ms": [1042.588], "images_per_second": 0.959, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The man is wearing glasses and a black shirt, and the picture is taken in a room with a white wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13394.6, "ram_available_mb": 109111.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13391.6, "ram_available_mb": 109114.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [47.0, 47.0, 47.0, 47.0, 47.58, 47.58, 47.58, 47.58, 47.58, 47.27, 47.27], "power_watts_avg": 47.31, "power_watts_peak": 47.58, "energy_joules_est": 49.35, "sample_count": 11, "duration_seconds": 1.043}, "timestamp": "2026-01-12T10:31:22.055516"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1098.758, "latencies_ms": [1098.758], "images_per_second": 0.91, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man in an orange shirt and black shorts is playing tennis on a green court with a blue and white tennis racket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13383.7, "ram_available_mb": 109122.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13309.3, "ram_available_mb": 109197.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [47.27, 47.27, 47.27, 41.44, 41.44, 41.44, 41.44, 41.44, 46.86, 46.86, 46.86], "power_watts_avg": 44.51, "power_watts_peak": 47.27, "energy_joules_est": 48.91, "sample_count": 11, "duration_seconds": 1.099}, "timestamp": "2026-01-12T10:31:23.167436"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2306.848, "latencies_ms": [2306.848], "images_per_second": 0.433, "prompt_tokens": 1114, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. Tennis racket: 1\n2. Tennis ball: 1\n3. Player: 1\n4. Tennis shoes: 1\n5. Tennis shorts: 1\n6. Tennis shirt: 1\n7. Tennis cap: 1\n8. Tennis net: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13309.3, "ram_available_mb": 109197.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.7, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.7, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.86, 46.86, 43.62, 43.62, 43.62, 43.62, 43.62, 47.85, 47.85, 47.85, 47.85, 47.85, 48.19, 48.19, 48.19, 48.19, 48.19, 34.93, 34.93, 34.93, 34.93, 34.93, 35.11], "power_watts_avg": 43.55, "power_watts_peak": 48.19, "energy_joules_est": 100.49, "sample_count": 23, "duration_seconds": 2.307}, "timestamp": "2026-01-12T10:31:25.483948"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1680.995, "latencies_ms": [1680.995], "images_per_second": 0.595, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball in the center and the net in the foreground. The player is closer to the camera than the ball, which is in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.0, "ram_available_mb": 109167.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13342.8, "ram_available_mb": 109163.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [35.11, 35.11, 35.11, 39.41, 39.41, 39.41, 39.41, 39.41, 47.13, 47.13, 47.13, 47.13, 47.13, 43.38, 43.38, 43.38, 43.38], "power_watts_avg": 41.86, "power_watts_peak": 47.13, "energy_joules_est": 70.39, "sample_count": 17, "duration_seconds": 1.682}, "timestamp": "2026-01-12T10:31:27.247021"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 886.621, "latencies_ms": [886.621], "images_per_second": 1.128, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man in an orange shirt and black shorts is playing tennis on a green court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13342.8, "ram_available_mb": 109163.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_watts_samples": [43.38, 33.45, 33.45, 33.45, 33.45, 33.45, 47.61, 47.61, 47.61], "power_watts_avg": 39.27, "power_watts_peak": 47.61, "energy_joules_est": 34.83, "sample_count": 9, "duration_seconds": 0.887}, "timestamp": "2026-01-12T10:31:28.157668"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 916.796, "latencies_ms": [916.796], "images_per_second": 1.091, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The tennis player is wearing an orange shirt and black shorts, and the court is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13339.9, "ram_available_mb": 109166.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13330.6, "ram_available_mb": 109175.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.61, 47.61, 48.72, 48.72, 48.72, 48.72, 48.72, 47.8, 47.8, 47.8], "power_watts_avg": 48.22, "power_watts_peak": 48.72, "energy_joules_est": 44.23, "sample_count": 10, "duration_seconds": 0.917}, "timestamp": "2026-01-12T10:31:29.168962"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1462.964, "latencies_ms": [1462.964], "images_per_second": 0.684, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a well-organized kitchen with a variety of appliances and utensils, including a sink, stove, and refrigerator, all arranged neatly on the countertops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13330.6, "ram_available_mb": 109175.7, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13354.7, "ram_available_mb": 109151.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 92.0}, "power_stats": {"power_watts_samples": [47.8, 47.8, 44.79, 44.79, 44.79, 44.79, 44.79, 50.51, 50.51, 50.51, 50.51, 50.51, 53.98, 53.98, 53.98], "power_watts_avg": 48.94, "power_watts_peak": 53.98, "energy_joules_est": 71.6, "sample_count": 15, "duration_seconds": 1.463}, "timestamp": "2026-01-12T10:31:30.683039"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2281.355, "latencies_ms": [2281.355], "images_per_second": 0.438, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. Kitchen counter: 1\n2. Shelf: 1\n3. Cabinet: 2\n4. Countertop: 1\n5. Sink: 1\n6. Faucet: 1\n7. Cabinet door: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13354.7, "ram_available_mb": 109151.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13328.0, "ram_available_mb": 109178.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [53.98, 53.98, 31.81, 31.81, 31.81, 31.81, 50.76, 50.76, 50.76, 50.76, 50.76, 54.32, 54.32, 54.32, 54.32, 54.32, 34.9, 34.9, 34.9, 34.9, 34.9, 34.96, 34.96], "power_watts_avg": 43.7, "power_watts_peak": 54.32, "energy_joules_est": 99.72, "sample_count": 23, "duration_seconds": 2.282}, "timestamp": "2026-01-12T10:31:33.008282"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1870.518, "latencies_ms": [1870.518], "images_per_second": 0.535, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The kitchen is located in the center of the image, with the sink and stove on the right side and the counter on the left. The refrigerator is positioned in the background, while the door is located on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13328.0, "ram_available_mb": 109178.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13356.0, "ram_available_mb": 109150.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [34.96, 34.96, 34.96, 39.22, 39.22, 39.22, 39.22, 39.22, 51.52, 51.52, 51.52, 51.52, 51.52, 47.26, 47.26, 47.26, 47.26, 47.26, 35.0], "power_watts_avg": 43.68, "power_watts_peak": 51.52, "energy_joules_est": 81.73, "sample_count": 19, "duration_seconds": 1.871}, "timestamp": "2026-01-12T10:31:34.931165"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1345.935, "latencies_ms": [1345.935], "images_per_second": 0.743, "prompt_tokens": 1444, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image captures a cozy kitchen scene inside a vintage camper van, where a variety of appliances and utensils are neatly arranged on the countertops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.0, "ram_available_mb": 109159.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13370.5, "ram_available_mb": 109135.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.0, 35.0, 35.0, 35.0, 39.39, 39.39, 39.39, 39.39, 39.39, 50.05, 50.05, 50.05, 50.05, 50.05], "power_watts_avg": 41.94, "power_watts_peak": 50.05, "energy_joules_est": 56.49, "sample_count": 14, "duration_seconds": 1.347}, "timestamp": "2026-01-12T10:31:36.398245"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1596.781, "latencies_ms": [1596.781], "images_per_second": 0.626, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The interior of a camper van is painted in a warm yellow color, with a black and white checkered floor. The lighting is bright and natural, coming from the ceiling lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13366.0, "ram_available_mb": 109140.3, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13358.3, "ram_available_mb": 109148.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [45.92, 45.92, 45.92, 45.92, 43.63, 43.63, 43.63, 43.63, 43.63, 50.94, 50.94, 50.94, 50.94, 50.94, 42.19, 42.19], "power_watts_avg": 46.31, "power_watts_peak": 50.94, "energy_joules_est": 73.97, "sample_count": 16, "duration_seconds": 1.597}, "timestamp": "2026-01-12T10:31:38.019053"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1014.905, "latencies_ms": [1014.905], "images_per_second": 0.985, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A sandwich with lettuce, tomato, and ham is on a paper plate with pickles and mustard on a desk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13349.3, "ram_available_mb": 109157.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13353.3, "ram_available_mb": 109153.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [42.19, 42.19, 42.19, 41.08, 41.08, 41.08, 41.08, 41.08, 47.97, 47.97, 47.97], "power_watts_avg": 43.26, "power_watts_peak": 47.97, "energy_joules_est": 43.92, "sample_count": 11, "duration_seconds": 1.015}, "timestamp": "2026-01-12T10:31:39.133645"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1973.065, "latencies_ms": [1973.065], "images_per_second": 0.507, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sandwich: 1\n2. lettuce: 1\n3. tomato: 1\n4. onion: 1\n5. pickle: 2\n6. mustard: 1\n7. paper plate: 1\n8. computer monitor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13353.3, "ram_available_mb": 109153.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [47.97, 47.97, 41.52, 41.52, 41.52, 41.52, 41.52, 46.3, 46.3, 46.3, 46.3, 46.3, 47.17, 47.17, 47.17, 47.17, 47.17, 34.78, 34.78, 34.78], "power_watts_avg": 43.76, "power_watts_peak": 47.97, "energy_joules_est": 86.36, "sample_count": 20, "duration_seconds": 1.973}, "timestamp": "2026-01-12T10:31:41.151603"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1415.269, "latencies_ms": [1415.269], "images_per_second": 0.707, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The sandwich is on the left side of the plate, which is on the right side of the table. The plate is in the foreground, while the computer monitor is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13412.8, "ram_available_mb": 109093.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13423.8, "ram_available_mb": 109082.5, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [34.78, 31.8, 31.8, 31.8, 31.8, 31.8, 46.58, 46.58, 46.58, 46.58, 46.58, 49.73, 49.73, 49.73, 49.73], "power_watts_avg": 41.71, "power_watts_peak": 49.73, "energy_joules_est": 59.06, "sample_count": 15, "duration_seconds": 1.416}, "timestamp": "2026-01-12T10:31:42.717508"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 881.355, "latencies_ms": [881.355], "images_per_second": 1.135, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A sandwich is on a paper plate on a desk with a computer in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13415.9, "ram_available_mb": 109090.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13412.0, "ram_available_mb": 109094.3, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [49.73, 31.62, 31.62, 31.62, 31.62, 31.62, 46.46, 46.46, 46.46], "power_watts_avg": 38.58, "power_watts_peak": 49.73, "energy_joules_est": 34.02, "sample_count": 9, "duration_seconds": 0.882}, "timestamp": "2026-01-12T10:31:43.628446"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1437.597, "latencies_ms": [1437.597], "images_per_second": 0.696, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sandwich is on a white paper plate, and the plate is on a wooden table. The sandwich is on a white napkin, and the napkin is on a white paper plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13404.1, "ram_available_mb": 109102.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13400.4, "ram_available_mb": 109105.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_watts_samples": [46.46, 46.46, 51.25, 51.25, 51.25, 51.25, 51.25, 47.68, 47.68, 47.68, 47.68, 47.68, 46.48, 46.48, 46.48], "power_watts_avg": 48.47, "power_watts_peak": 51.25, "energy_joules_est": 69.71, "sample_count": 15, "duration_seconds": 1.438}, "timestamp": "2026-01-12T10:31:45.142859"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1490.851, "latencies_ms": [1490.851], "images_per_second": 0.671, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a desk with two computer monitors, a keyboard, a mouse, and a smartphone, all arranged in a way that suggests a workspace or a tech-savvy individual's desk setup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13396.5, "ram_available_mb": 109109.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13399.4, "ram_available_mb": 109106.9, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4625.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [46.48, 46.48, 34.6, 34.6, 34.6, 34.6, 34.6, 46.88, 46.88, 46.88, 46.88, 46.88, 47.14, 47.14, 47.14], "power_watts_avg": 42.78, "power_watts_peak": 47.14, "energy_joules_est": 63.79, "sample_count": 15, "duration_seconds": 1.491}, "timestamp": "2026-01-12T10:31:46.661234"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1329.953, "latencies_ms": [1329.953], "images_per_second": 0.752, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " monitor: 2, keyboard: 1, mouse: 1, phone: 1, tablet: 1, camera: 1, laptop: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.5, "ram_available_mb": 109114.8, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13397.7, "ram_available_mb": 109108.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.5, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_watts_samples": [47.14, 47.14, 34.76, 34.76, 34.76, 34.76, 34.76, 47.87, 47.87, 47.87, 47.87, 47.87, 48.55, 48.55], "power_watts_avg": 43.18, "power_watts_peak": 48.55, "energy_joules_est": 57.45, "sample_count": 14, "duration_seconds": 1.331}, "timestamp": "2026-01-12T10:31:48.076014"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1840.111, "latencies_ms": [1840.111], "images_per_second": 0.543, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The keyboard is positioned in the foreground, close to the camera, while the two monitors are placed in the background, farther away from the camera. The mouse is situated near the keyboard, and the tablet is positioned to the right of the keyboard, both in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13397.7, "ram_available_mb": 109108.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13460.2, "ram_available_mb": 109046.1, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4628.1, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_watts_samples": [48.55, 48.55, 48.55, 37.45, 37.45, 37.45, 37.45, 37.45, 46.83, 46.83, 46.83, 46.83, 46.83, 44.52, 44.52, 44.52, 44.52, 44.52, 35.15], "power_watts_avg": 43.41, "power_watts_peak": 48.55, "energy_joules_est": 79.9, "sample_count": 19, "duration_seconds": 1.84}, "timestamp": "2026-01-12T10:31:49.988750"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1852.986, "latencies_ms": [1852.986], "images_per_second": 0.54, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a scene of a well-organized workspace, featuring a desk with two computer monitors, a keyboard, a mouse, and a tablet. The desk is situated in a room with a white wall and a window, suggesting a quiet and focused environment for work.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13457.6, "ram_available_mb": 109048.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13488.6, "ram_available_mb": 109017.7, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4627.2, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [35.15, 35.15, 35.15, 38.47, 38.47, 38.47, 38.47, 38.47, 45.92, 45.92, 45.92, 45.92, 45.92, 42.74, 42.74, 42.74, 42.74, 42.74, 34.87], "power_watts_avg": 40.84, "power_watts_peak": 45.92, "energy_joules_est": 75.69, "sample_count": 19, "duration_seconds": 1.853}, "timestamp": "2026-01-12T10:31:51.953825"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2123.738, "latencies_ms": [2123.738], "images_per_second": 0.471, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image depicts a desk with two computer monitors, a keyboard, a mouse, and a tablet. The monitors are displaying different web pages, and the desk is lit by a blue light. The overall color scheme of the image is neutral, with the white of the desk and the monitors standing out against the darker background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13488.6, "ram_available_mb": 109017.7, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13459.9, "ram_available_mb": 109046.4, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4626.0, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.87, 34.87, 34.87, 34.87, 39.89, 39.89, 39.89, 39.89, 46.16, 46.16, 46.16, 46.16, 46.16, 40.94, 40.94, 40.94, 40.94, 40.94, 34.82, 34.82, 34.82, 34.82], "power_watts_avg": 39.72, "power_watts_peak": 46.16, "energy_joules_est": 84.4, "sample_count": 22, "duration_seconds": 2.125}, "timestamp": "2026-01-12T10:31:54.219656"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1392.756, "latencies_ms": [1392.756], "images_per_second": 0.718, "prompt_tokens": 1432, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image captures a unique perspective of a bathroom, where the floor is adorned with a large mural of a group of people, creating an intriguing visual effect.", "error": null, "sys_before": {"cpu_percent": 0.9, "ram_used_mb": 13455.9, "ram_available_mb": 109050.4, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 93.0}, "power_stats": {"power_watts_samples": [34.82, 31.71, 31.71, 31.71, 31.71, 31.71, 47.69, 47.69, 47.69, 47.69, 47.69, 52.68, 52.68, 52.68], "power_watts_avg": 42.13, "power_watts_peak": 52.68, "energy_joules_est": 58.71, "sample_count": 14, "duration_seconds": 1.393}, "timestamp": "2026-01-12T10:31:55.684669"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2215.661, "latencies_ms": [2215.661], "images_per_second": 0.451, "prompt_tokens": 1446, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Floor: 1\n3. Tile: 1\n4. Wall: 1\n5. Ceiling: 1\n6. People: 1\n7. Shoes: 1\n8. Urinal: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13389.1, "ram_available_mb": 109117.2, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13420.4, "ram_available_mb": 109085.9, "ram_percent": 11.0}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [52.68, 52.68, 35.35, 35.35, 35.35, 35.35, 35.35, 52.22, 52.22, 52.22, 52.22, 52.22, 54.33, 54.33, 54.33, 54.33, 54.33, 34.88, 34.88, 34.88, 34.88, 34.88, 34.89], "power_watts_avg": 44.53, "power_watts_peak": 54.33, "energy_joules_est": 98.67, "sample_count": 23, "duration_seconds": 2.216}, "timestamp": "2026-01-12T10:31:58.004586"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1842.53, "latencies_ms": [1842.53], "images_per_second": 0.543, "prompt_tokens": 1450, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The toilet is located in the upper right corner of the image, while the group of people is positioned in the lower left corner. The floor is the closest object to the viewer, while the toilet is the farthest object in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13420.4, "ram_available_mb": 109085.9, "ram_percent": 11.0}, "sys_after": {"cpu_percent": 1.5, "ram_used_mb": 13343.8, "ram_available_mb": 109162.5, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_watts_samples": [34.89, 34.89, 34.89, 35.08, 35.08, 35.08, 35.08, 35.08, 49.21, 49.21, 49.21, 49.21, 49.21, 49.11, 49.11, 49.11, 49.11, 49.11, 34.94], "power_watts_avg": 42.45, "power_watts_peak": 49.21, "energy_joules_est": 78.25, "sample_count": 19, "duration_seconds": 1.843}, "timestamp": "2026-01-12T10:31:59.971584"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 966.181, "latencies_ms": [966.181], "images_per_second": 1.035, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A group of people are standing on a tiled floor in a bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13343.3, "ram_available_mb": 109163.0, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13379.2, "ram_available_mb": 109127.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_watts_samples": [34.94, 34.94, 34.94, 37.46, 37.46, 37.46, 37.46, 37.46, 50.0, 50.0], "power_watts_avg": 39.21, "power_watts_peak": 50.0, "energy_joules_est": 37.92, "sample_count": 10, "duration_seconds": 0.967}, "timestamp": "2026-01-12T10:32:01.036398"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1471.029, "latencies_ms": [1471.029], "images_per_second": 0.68, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit bathroom with white tiles on the floor and walls. The lighting is bright and even, and the tiles are clean and shiny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13371.4, "ram_available_mb": 109134.9, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.6, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_watts_samples": [50.0, 50.0, 50.0, 50.94, 50.94, 50.94, 50.94, 50.94, 51.18, 51.18, 51.18, 51.18, 51.18, 48.11, 48.11], "power_watts_avg": 50.45, "power_watts_peak": 51.18, "energy_joules_est": 74.24, "sample_count": 15, "duration_seconds": 1.471}, "timestamp": "2026-01-12T10:32:02.552810"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1041.76, "latencies_ms": [1041.76], "images_per_second": 0.96, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird with a gray body and black beak is perched on a branch in a forest.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13368.7, "ram_available_mb": 109137.6, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13351.5, "ram_available_mb": 109154.8, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_watts_samples": [48.11, 48.11, 48.11, 37.71, 37.71, 37.71, 37.71, 37.71, 51.25, 51.25, 51.25], "power_watts_avg": 44.24, "power_watts_peak": 51.25, "energy_joules_est": 46.12, "sample_count": 11, "duration_seconds": 1.042}, "timestamp": "2026-01-12T10:32:03.665633"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 667.203, "latencies_ms": [667.203], "images_per_second": 1.499, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " bird: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13346.8, "ram_available_mb": 109159.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.1, "ram_used_mb": 13354.2, "ram_available_mb": 109152.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 0.0}, "power_stats": {"power_watts_samples": [51.25, 51.25, 46.9, 46.9, 46.9, 46.9, 46.9], "power_watts_avg": 48.14, "power_watts_peak": 51.25, "energy_joules_est": 32.15, "sample_count": 7, "duration_seconds": 0.668}, "timestamp": "2026-01-12T10:32:04.375494"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1290.457, "latencies_ms": [1290.457], "images_per_second": 0.775, "prompt_tokens": 1450, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The bird is positioned in the foreground, perched on a branch, while the background is filled with green foliage, creating a natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13344.8, "ram_available_mb": 109161.5, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.4, "ram_used_mb": 13356.2, "ram_available_mb": 109150.1, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 96.0}, "power_stats": {"power_watts_samples": [50.84, 50.84, 50.84, 50.84, 50.84, 64.11, 64.11, 64.11, 64.11, 64.11, 51.73, 51.73, 51.73], "power_watts_avg": 56.15, "power_watts_peak": 64.11, "energy_joules_est": 72.47, "sample_count": 13, "duration_seconds": 1.291}, "timestamp": "2026-01-12T10:32:05.689696"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1048.824, "latencies_ms": [1048.824], "images_per_second": 0.953, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird with a gray body and black beak is perched on a branch in a forest.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13346.9, "ram_available_mb": 109159.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13352.6, "ram_available_mb": 109153.7, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 29.0}, "power_stats": {"power_watts_samples": [51.73, 51.73, 39.99, 39.99, 39.99, 39.99, 39.99, 52.04, 52.04, 52.04, 52.04], "power_watts_avg": 46.51, "power_watts_peak": 52.04, "energy_joules_est": 48.8, "sample_count": 11, "duration_seconds": 1.049}, "timestamp": "2026-01-12T10:32:06.805199"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/dgxwaggle/Desktop/SageEdge/Benchmarking/data/coco/val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 967.797, "latencies_ms": [967.797], "images_per_second": 1.033, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bird is gray and black, and the background is green and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13347.9, "ram_available_mb": 109158.4, "ram_percent": 10.9}, "sys_after": {"cpu_percent": 1.3, "ram_used_mb": 13361.3, "ram_available_mb": 109145.0, "ram_percent": 10.9}, "cuda_stats": {"cuda": true, "gpu_name": "NVIDIA GB10", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5244.0, "gpu_max_mem_alloc_mb": 4725.4, "gpu_max_mem_reserved_mb": 5244.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_watts_samples": [52.04, 53.48, 53.48, 53.48, 53.48, 47.8, 47.8, 47.8, 47.8, 47.8], "power_watts_avg": 50.5, "power_watts_peak": 53.48, "energy_joules_est": 48.9, "sample_count": 10, "duration_seconds": 0.968}, "timestamp": "2026-01-12T10:32:07.819578"}
